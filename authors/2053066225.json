{
    "authorId": "2053066225",
    "papers": [
        {
            "paperId": "bf45a7a3d64ce9abe10dbbab853a7c351f7e5a90",
            "title": "KDSTM: Neural Semi-supervised Topic Modeling with Knowledge Distillation",
            "abstract": "In text classification tasks, fine tuning pretrained language models like BERT and GPT-3 yields competitive accuracy; however, both methods require pretraining on large text datasets. In contrast, general topic modeling methods possess the advantage of analyzing documents to extract meaningful patterns of words without the need of pretraining. To leverage topic modeling's unsupervised insights extraction on text classification tasks, we develop the Knowledge Distillation Semi-supervised Topic Modeling (KDSTM). KDSTM requires no pretrained embeddings, few labeled documents and is efficient to train, making it ideal under resource constrained settings. Across a variety of datasets, our method outperforms existing supervised topic modeling methods in classification accuracy, robustness and efficiency and achieves similar performance compare to state of the art weakly supervised text classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110546424",
                    "name": "Weijie Xu"
                },
                {
                    "authorId": "2144812478",
                    "name": "Xiaoyu Jiang"
                },
                {
                    "authorId": "2053066225",
                    "name": "Jay Desai"
                },
                {
                    "authorId": "2153287302",
                    "name": "Bin Han"
                },
                {
                    "authorId": "2171428787",
                    "name": "Fuqin Yan"
                },
                {
                    "authorId": "2171429265",
                    "name": "Francis Iannacci"
                }
            ]
        },
        {
            "paperId": "ceba8c79009800d151c81fd8db990370c91a04f1",
            "title": "S2vNTM: Semi-supervised vMF Neural Topic Modeling",
            "abstract": "Language model based methods are powerful techniques for text classification. However, the models have several shortcomings. (1) It is difficult to integrate human knowledge such as keywords. (2) It needs a lot of resources to train the models. (3) It relied on large text data to pretrain. In this paper, we propose Semi-Supervised vMF Neural Topic Modeling (S2vNTM) to overcome these difficulties. S2vNTM takes a few seed keywords as input for topics. S2vNTM leverages the pattern of keywords to identify potential topics, as well as optimize the quality of topics' keywords sets. Across a variety of datasets, S2vNTM outperforms existing semi-supervised topic modeling methods in classification accuracy with limited keywords provided. S2vNTM is at least twice as fast as baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110546424",
                    "name": "Weijie Xu"
                },
                {
                    "authorId": "2053066225",
                    "name": "Jay Desai"
                },
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                },
                {
                    "authorId": "2144812478",
                    "name": "Xiaoyu Jiang"
                },
                {
                    "authorId": "2171429265",
                    "name": "Francis Iannacci"
                }
            ]
        },
        {
            "paperId": "5d84bddab46d9b3d5af2d4cd609aaea3b626942b",
            "title": "Attention-based Region of Interest (ROI) Detection for Speech Emotion Recognition",
            "abstract": "Automatic emotion recognition for real-life appli-cations is a challenging task. Human emotion expressions aresubtle, and can be conveyed by a combination of several emo-tions. In most existing emotion recognition studies, each audioutterance/video clip is labelled/classified in its entirety. However,utterance/clip-level labelling and classification can be too coarseto capture the subtle intra-utterance/clip temporal dynamics. Forexample, an utterance/video clip usually contains only a fewemotion-salient regions and many emotionless regions. In thisstudy, we propose to use attention mechanism in deep recurrentneural networks to detection the Regions-of-Interest (ROI) thatare more emotionally salient in human emotional speech/video,and further estimate the temporal emotion dynamics by aggre-gating those emotionally salient regions-of-interest. We comparethe ROI from audio and video and analyse them. We comparethe performance of the proposed attention networks with thestate-of-the-art LSTM models on multi-class classification task ofrecognizing six basic human emotions, and the proposed attentionmodels exhibit significantly better performance. Furthermore, theattention weight distribution can be used to interpret how anutterance can be expressed as a mixture of possible emotions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2053066225",
                    "name": "Jay Desai"
                },
                {
                    "authorId": "2675653",
                    "name": "Houwei Cao"
                },
                {
                    "authorId": "2157861957",
                    "name": "Ravi Shah"
                }
            ]
        },
        {
            "paperId": "696d81daf3b0ab1d28b024756e896cd6dbaaf794",
            "title": "Smartphone-based obstacle detection for visually impaired people",
            "abstract": "A blind person walking in an unfamiliar environment faces many problems, this issue may be of identifying true obstacle or may be of identifying potholes, bumps in his way. In past few years, different types of ETA's have been developed for helping visually impaired people. Regardless of various ETA's available, they are still not affordable to the majority of blind people. And most of these ETA's only focuses on only one problem i.e. either pot-hole detection or obstacle in front of the user. Apart from that, they do not provide information about the environment in which user is present. This paper describes a real-time system which makes use of the ultrasonic sensor, camera, and smartphone for detection, recognition and processing of objects that hinders the path of visually impaired person. Ultrasonic sensors detect and measure the distance of obstacle while image captured from a camera is used for object recognition. The output given to the user is in the form of vibration and audio. The intensity of the output depends on the distance of an object from the user.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109523989",
                    "name": "Samir Patel"
                },
                {
                    "authorId": "2123128872",
                    "name": "Amit Kumar"
                },
                {
                    "authorId": "49864163",
                    "name": "P. Yadav"
                },
                {
                    "authorId": "2053066225",
                    "name": "Jay Desai"
                },
                {
                    "authorId": "14805952",
                    "name": "Dipali M. Patil"
                }
            ]
        }
    ]
}