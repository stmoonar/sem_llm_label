{
    "authorId": "3046200",
    "papers": [
        {
            "paperId": "08f20031a1f09af6762a4012aadb87b359b7d4cf",
            "title": "Overview of the Authorship Verification Task at PAN 2023",
            "abstract": "The authorship verification task for PAN 2023 focuses on a very challenging scenario: given a pair of texts belonging to different discourse types, the task is to determine whether they were authored by the same person. In addition, for the first time, we consider discourse types from both written (i.e., essays and emails) and spoken language (i.e., interviews and speech transcriptions). New datasets in English are provided and we adopt the same evaluation setup and measures as similar tasks in recent editions of PAN. A total of eleven teams submitted 27 runs and were evaluated along with several baselines on the TIRA experimental platform. This paper includes a review of the submitted methods and a detailed discussion of the evaluation results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1992786",
                    "name": "E. Stamatatos"
                },
                {
                    "authorId": "2256235979",
                    "name": "Krzysztof Kredens"
                },
                {
                    "authorId": "2261403376",
                    "name": "Piotr Pezik"
                },
                {
                    "authorId": "2078805637",
                    "name": "A. Heini"
                },
                {
                    "authorId": "9537652",
                    "name": "Janek Bevendorff"
                },
                {
                    "authorId": "1405867539",
                    "name": "Benno Stein"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        },
        {
            "paperId": "0de69d234c2e808b11db54d1efc94be53f438831",
            "title": "Evaluating Generative Ad Hoc Information Retrieval",
            "abstract": "Recent advances in large language models have enabled the development of viable generative retrieval systems. Instead of a traditional document ranking, generative retrieval systems often directly return a grounded generated text as a response to a query. Quantifying the utility of the textual responses is essential for appropriately evaluating such generative ad hoc retrieval. Yet, the established evaluation methodology for ranking-based ad hoc retrieval is not suited for the reliable and reproducible evaluation of generated responses. To lay a foundation for developing new evaluation methods for generative retrieval systems, we survey the relevant literature from the fields of information retrieval and natural language processing, identify search tasks and system architectures in generative retrieval, develop a new user model, and study its operationalization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124424844",
                    "name": "Lukas Gienapp"
                },
                {
                    "authorId": "8842143",
                    "name": "Harrisen Scells"
                },
                {
                    "authorId": "40015417",
                    "name": "Niklas Deckers"
                },
                {
                    "authorId": "9537652",
                    "name": "Janek Bevendorff"
                },
                {
                    "authorId": "2146514461",
                    "name": "Shuai Wang"
                },
                {
                    "authorId": "2265647821",
                    "name": "Johannes Kiesel"
                },
                {
                    "authorId": "18417916",
                    "name": "S. Syed"
                },
                {
                    "authorId": "2141580390",
                    "name": "Maik Frobe"
                },
                {
                    "authorId": "2265646673",
                    "name": "Guide Zucoon"
                },
                {
                    "authorId": "1405867539",
                    "name": "Benno Stein"
                },
                {
                    "authorId": "145072133",
                    "name": "Matthias Hagen"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        },
        {
            "paperId": "1a942158c872d155831f6d27e451f1ccf6f21f97",
            "title": "Small-Text: Active Learning for Text Classification in Python",
            "abstract": "We introduce small-text, an easy-to-use active learning library, which offers pool-based active learning for single- and multi-label text classification in Python. It features numerous pre-implemented state-of-the-art query strategies, including some that leverage the GPU. Standardized interfaces allow the combination of a variety of classifiers, query strategies, and stopping criteria, facilitating a quick mix and match, and enabling a rapid development of both active learning experiments and applications. With the objective of making various classifiers and query strategies accessible for active learning, small-text integrates several well-known machine learning libraries, namely scikit-learn, Pytorch, and Hugging Face transformers. The latter integrations are optionally installable extensions, so GPUs can be used but are not required. Using this new library, we investigate the performance of the recently published SetFit training paradigm, which we compare to vanilla transformer fine-tuning, finding that it matches the latter in classification accuracy while outperforming it in area under the curve. The library is available under the MIT License at https://github.com/webis-de/small-text, in version 1.3.0 at the time of writing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2058170882",
                    "name": "Christopher Schr\u00f6der"
                },
                {
                    "authorId": "2091445106",
                    "name": "Lydia Muller"
                },
                {
                    "authorId": "2121285225",
                    "name": "A. Niekler"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        },
        {
            "paperId": "35737b55a14043600b5efa0c29b31e5d33af1db4",
            "title": "pybool_ir: A Toolkit for Domain-Specific Search Experiments",
            "abstract": "Undertaking research in domain-specific scenarios such as systematic review literature search, legal search, and patent search can often have a high barrier of entry due to complicated indexing procedures and complex Boolean query syntax. Indexing and searching document collections like PubMed in off-the-shelf tools such as Elasticsearch and Lucene often yields less accurate (and less effective) results than the PubMed search engine, i.e., retrieval results do not match what would be retrieved if one issued the same query to PubMed. Furthermore, off-the-shelf tools have their own nuanced query languages and do not allow directly using the often large and complicated Boolean queries seen in domain-specific search scenarios. The pybool_ir toolkit aims to address these problems and to lower the barrier to entry for developing new methods for domain-specific search. The toolkit is an open source package available at https://github.com/hscells/pybool_ir.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8842143",
                    "name": "Harrisen Scells"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        },
        {
            "paperId": "3c653b672e735ef5ed01016b4faadc216bb1bae9",
            "title": "Citance-Contextualized Summarization of Scientific Papers",
            "abstract": "Current approaches to automatic summarization of scientific papers generate informative summaries in the form of abstracts. However, abstracts are not intended to show the relationship between a paper and the references cited in it. We propose a new contextualized summarization approach that can generate an informative summary conditioned on a given sentence containing the citation of a reference (a so-called\"citance\"). This summary outlines the content of the cited paper relevant to the citation location. Thus, our approach extracts and models the citances of a paper, retrieves relevant passages from cited papers, and generates abstractive summaries tailored to each citance. We evaluate our approach using $\\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing 540K~computer science papers and 4.6M~citances therein.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "18417916",
                    "name": "S. Syed"
                },
                {
                    "authorId": "1751620654",
                    "name": "Ahmad Dawar Hakimi"
                },
                {
                    "authorId": "2065425673",
                    "name": "Khalid Al-Khatib"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        },
        {
            "paperId": "40af24f2cb70a1d9f7d02bb08d98fdb61cdf94e8",
            "title": "Frame-oriented Summarization of Argumentative Discussions",
            "abstract": "Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are (1) relevant to a frame of interest, (2) relevant to the topic under discussion, and (3) informative to the reader. Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100 controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "18417916",
                    "name": "S. Syed"
                },
                {
                    "authorId": "2047307140",
                    "name": "Timon Ziegenbein"
                },
                {
                    "authorId": "2145327410",
                    "name": "Philipp Heinisch"
                },
                {
                    "authorId": "2626599",
                    "name": "Henning Wachsmuth"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        },
        {
            "paperId": "4ff12ff0f18c1677fbdf60afbe02c933c8b93bc3",
            "title": "On Stance Detection in Image Retrieval for Argumentation",
            "abstract": "Given a text query on a controversial topic, the task of Image Retrieval for Argumentation is to rank images according to how well they can be used to support a discussion on the topic. An important subtask therein is to determine the stance of the retrieved images, i.e., whether an image supports the pro or con side of the topic. In this paper, we conduct a comprehensive reproducibility study of the state of the art as represented by the CLEF'22 Touch\u00e9 lab and an in-house extension of it. Based on the submitted approaches, we developed a unified and modular retrieval process and reimplemented the submitted approaches according to this process. Through this unified reproduction (which also includes models not previously considered), we achieve an effectiveness improvement in argumentative image detection of up to 0.832 precision@10. However, despite this reproduction success, our study also revealed a previously unknown negative result: for stance detection, none of the reproduced or new approaches can convincingly beat a random baseline. To understand the apparent challenges inherent to image stance detection, we conduct a thorough error analysis and provide insight into potential new ways to approach this task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2033833717",
                    "name": "Miriam Louise Carnot"
                },
                {
                    "authorId": "2181132009",
                    "name": "Lorenz Heinemann"
                },
                {
                    "authorId": "2181136065",
                    "name": "Jan Braker"
                },
                {
                    "authorId": "2181136363",
                    "name": "Tobias Schreieder"
                },
                {
                    "authorId": "1840075",
                    "name": "Johannes Kiesel"
                },
                {
                    "authorId": "1490763899",
                    "name": "Maik Fr\u00f6be"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                },
                {
                    "authorId": "1405867539",
                    "name": "Benno Stein"
                }
            ]
        },
        {
            "paperId": "523ca8853749cc3464e58ad921a09df8585c59cf",
            "title": "Overview of the Multi-Author Writing Style Analysis Task at PAN 2023",
            "abstract": "The analysis of the writing style of multi-authored texts aims at identifying those places where authorship changes in a document. This task is an important step in reliably identifying the authors of a given text. This year, we ask participants to solve an intrinsic style change detection task: For a given text, find all places where the writing style changes at the paragraph-level. To control for topic information as a style change signal, we provide participants with data sets with three levels of difficulty and thus different thematic variants. This paper presents the multiple author writing style analysis task, the underlying data set, the approaches used by participants, and the results obtained.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3340275",
                    "name": "Eva Zangerle"
                },
                {
                    "authorId": "28912611",
                    "name": "Maximilian Mayerl"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                },
                {
                    "authorId": "1405867539",
                    "name": "Benno Stein"
                }
            ]
        },
        {
            "paperId": "5e34f0ab2724e626e2e7cbad4aacb15a5bcdf27d",
            "title": "Report on the Dagstuhl Seminar on Frontiers of Information Access Experimentation for Research and Education",
            "abstract": "This report documents the program and the outcomes of Dagstuhl Seminar 23031 \"Frontiers of Information Access Experimentation for Research and Education\", which brought together 38 participants from 12 countries. The seminar addressed technology-enhanced information access (information retrieval, recommender systems, natural language processing) and specifically focused on developing more responsible experimental practices leading to more valid results, both for research as well as for scientific education. The seminar featured a series of long and short talks delivered by participants, who helped in setting a common ground and in letting emerge topics of interest to be explored as the main output of the seminar. This led to the definition of five groups which investigated challenges, opportunities, and next steps in the following areas: reality check, i.e. conducting real-world studies, human-machine-collaborative relevance judgment frameworks, overcoming methodological challenges in information retrieval and recommender systems through awareness and education, results-blind reviewing, and guidance for authors. Date: 15--20 January 2023. Website: https://www.dagstuhl.de/23031.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2052765096",
                    "name": "Christine Bauer"
                },
                {
                    "authorId": "1750995",
                    "name": "Ben Carterette"
                },
                {
                    "authorId": "2137867216",
                    "name": "Joeran Beel"
                },
                {
                    "authorId": "1491609376",
                    "name": "Timo Breuer"
                },
                {
                    "authorId": "1751287",
                    "name": "C. Clarke"
                },
                {
                    "authorId": "2815511",
                    "name": "Anita Crescenzi"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "2051747173",
                    "name": "G. Nunzio"
                },
                {
                    "authorId": "145798497",
                    "name": "Laura Dietz"
                },
                {
                    "authorId": "80808662",
                    "name": "G. Faggioli"
                },
                {
                    "authorId": "3001795",
                    "name": "B. Ferwerda"
                },
                {
                    "authorId": "1490763899",
                    "name": "Maik Fr\u00f6be"
                },
                {
                    "authorId": "145072133",
                    "name": "Matthias Hagen"
                },
                {
                    "authorId": "1699657",
                    "name": "A. Hanbury"
                },
                {
                    "authorId": "2731925",
                    "name": "C. Hauff"
                },
                {
                    "authorId": "1705282",
                    "name": "D. Jannach"
                },
                {
                    "authorId": "2167781708",
                    "name": "Noriko Kando"
                },
                {
                    "authorId": "1713134",
                    "name": "E. Kanoulas"
                },
                {
                    "authorId": "2477993",
                    "name": "Bart P. Knijnenburg"
                },
                {
                    "authorId": "2993548",
                    "name": "Udo Kruschwitz"
                },
                {
                    "authorId": "1954475",
                    "name": "Maria Maistro"
                },
                {
                    "authorId": "119665711",
                    "name": "L. Michiels"
                },
                {
                    "authorId": "73425445",
                    "name": "A. Papenmeier"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                },
                {
                    "authorId": "143752702",
                    "name": "Paolo Rosso"
                },
                {
                    "authorId": "40404161",
                    "name": "A. Said"
                },
                {
                    "authorId": "34588911",
                    "name": "Philipp Schaer"
                },
                {
                    "authorId": "145566115",
                    "name": "C. Seifert"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                },
                {
                    "authorId": "1405867539",
                    "name": "Benno Stein"
                },
                {
                    "authorId": "1803171",
                    "name": "N. Tintarev"
                },
                {
                    "authorId": "2060623050",
                    "name": "J. Urbano"
                },
                {
                    "authorId": "2626599",
                    "name": "Henning Wachsmuth"
                },
                {
                    "authorId": "1918235",
                    "name": "M. Willemsen"
                },
                {
                    "authorId": "151068958",
                    "name": "Justin W. Zobel"
                }
            ]
        },
        {
            "paperId": "5fbfcaa992e609f0abe02cbcdcede0f792cfee19",
            "title": "Shared Tasks as Tutorials: A Methodical Approach",
            "abstract": "In this paper, we discuss the benefits and challenges of shared tasks as a teaching method. A shared task is a scientific event and a friendly competition to solve a research problem, the task. In terms of linking research and teaching, shared-task-based tutorials fulfill several faculty desires: they leverage students' interdisciplinary and heterogeneous skills, foster teamwork, and engage them in creative work that has the potential to produce original research contributions. Based on ten information retrieval (IR) courses at two universities since 2019 with shared tasks as tutorials, we derive a domain-neutral process model to capture the respective tutorial structure. Meanwhile, our teaching method has been adopted by other universities in IR courses, but also in other areas of AI such as natural language processing and robotics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2180723622",
                    "name": "Theresa Elstner"
                },
                {
                    "authorId": "2784728",
                    "name": "F. Loebe"
                },
                {
                    "authorId": "22312473",
                    "name": "Yamen Ajjour"
                },
                {
                    "authorId": "2003696840",
                    "name": "Christopher Akiki"
                },
                {
                    "authorId": "143856141",
                    "name": "Alexander Bondarenko"
                },
                {
                    "authorId": "1490763899",
                    "name": "Maik Fr\u00f6be"
                },
                {
                    "authorId": "2124424844",
                    "name": "Lukas Gienapp"
                },
                {
                    "authorId": "50244788",
                    "name": "Nikolay Kolyada"
                },
                {
                    "authorId": "2046237363",
                    "name": "Janis Mohr"
                },
                {
                    "authorId": "2222731491",
                    "name": "Stephan Sandfuchs"
                },
                {
                    "authorId": "1912394",
                    "name": "Matti Wiegmann"
                },
                {
                    "authorId": "3038291",
                    "name": "J\u00f6rg Frochte"
                },
                {
                    "authorId": "2145800142",
                    "name": "Nicola Ferro"
                },
                {
                    "authorId": "35033492",
                    "name": "Sven Hofmann"
                },
                {
                    "authorId": "144146081",
                    "name": "Benno Stein"
                },
                {
                    "authorId": "145072133",
                    "name": "Matthias Hagen"
                },
                {
                    "authorId": "3046200",
                    "name": "Martin Potthast"
                }
            ]
        }
    ]
}