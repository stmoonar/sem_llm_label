{
    "authorId": "1740615089",
    "papers": [
        {
            "paperId": "549f4ca2e14b43fb7cacd3c4aeac16af3bf8e9eb",
            "title": "Measuring and Fostering Diversity in Affective Computing Research",
            "abstract": "This work presents a longitudinal study of diversity among the Affective Computing research community members. We explore several dimensions of diversity, including gender, geography, institutional types of affiliations and selected combinations of dimensions. We cover the last 10 years of the IEEE Transactions on Affective Computing (TAFFC) journal and the International Conference on Affective Computing and Intelligent Interaction (ACII), the primary sources of publications in Affective Computing. We also present an analysis of diversity among the members of the Association for the Advancement of Affective Computing (AAAC). Our findings reveal a \u201cleaky pipeline\u201d in the field, with a low \u2013albeit slowly increasing over the years\u2013 representation of women. They also show that academic institutions clearly dominate publications, ahead of industry and governmental centres. In terms of geography, most publications come from the USA, contributions from Latin America or Africa being almost non-existent. Lastly, we find that diversity in the characteristics of researchers (gender and geographic location) influences diversity in the topics. To conclude, we analyse initiatives that have been undertaken in other AI-related research communities to foster diversity, and recommend a set of initiatives that could be applied to the Affective Computing field to increase diversity in its different facets. The diversity data collected in this work are publicly available, ensuring strict personal data protection and governance rules.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2321433",
                    "name": "I. Hupont"
                },
                {
                    "authorId": "12092873",
                    "name": "Song\u00fcl Tolan"
                },
                {
                    "authorId": "2205432878",
                    "name": "Pedro Frau"
                },
                {
                    "authorId": "74248595",
                    "name": "Lorenzo Porcaro"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                }
            ]
        },
        {
            "paperId": "4579d1a9dc70c414b63e1d3e962d786ca56e8f75",
            "title": "Documenting High-Risk AI: A European Regulatory Perspective",
            "abstract": "This article discusses transparency obligations introduced in the Artificial Intelligence Act, the recently proposed European regulatory framework for artificial intelligence (AI). An analysis of the extent to which current approaches for AI documentation satisfy requirements is presented and their suitability as a basis for future technical standards is assessed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215413727",
                    "name": "Isabelle Hupont"
                },
                {
                    "authorId": "2215412976",
                    "name": "Marina Micheli"
                },
                {
                    "authorId": "2661674",
                    "name": "Blagoj Delipetrev"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                },
                {
                    "authorId": "2215407347",
                    "name": "Josep Soler Garrido"
                }
            ]
        },
        {
            "paperId": "c4d2510e1968f29fa4951a7bc991a20cbfc134c0",
            "title": "Trustworthy Artificial Intelligence Requirements in the Autonomous Driving Domain",
            "abstract": "We identify the maturity level of the different requirements for artificial intelligence (AI) in autonomous driving and outline the main challenges to be addressed in the future to ensure that automotive AI systems are developed in a trustworthy way.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405226912",
                    "name": "D. Fern\u00e1ndez-Llorca"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                }
            ]
        },
        {
            "paperId": "e4a6870741997ccbfad39837a9dfc2afe18a004c",
            "title": "The role of explainable AI in the context of the AI Act",
            "abstract": "The proposed EU regulation for Artificial Intelligence (AI), the AI Act, has sparked some debate about the role of explainable AI (XAI) in high-risk AI systems. Some argue that black-box AI models will have to be replaced with transparent ones, others argue that using XAI techniques might help in achieving compliance. This work aims to bring some clarity as regards XAI in the context of the AI Act and focuses in particular on the AI Act requirements for transparency and human oversight. After outlining key points of the debate and describing the current limitations of XAI techniques, this paper carries out an interdisciplinary analysis of how the AI Act addresses the issue of opaque AI systems. In particular, we argue that neither does the AI Act mandate a requirement for XAI, which is the subject of intense scientific research and is not without technical limitations, nor does it ban the use of black-box AI systems. Instead, the AI Act aims to achieve its stated policy objectives with the focus on transparency (including documentation) and human oversight. Finally, in order to concretely illustrate our findings and conclusions, a use case on AI-based proctoring is presented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "14644743",
                    "name": "Cecilia Panigutti"
                },
                {
                    "authorId": "2897267",
                    "name": "Ronan Hamon"
                },
                {
                    "authorId": "2215413727",
                    "name": "Isabelle Hupont"
                },
                {
                    "authorId": "1938560317",
                    "name": "David Fern\u00e1ndez Llorca"
                },
                {
                    "authorId": "2127104511",
                    "name": "Delia Fano Yela"
                },
                {
                    "authorId": "2288623",
                    "name": "H. Junklewitz"
                },
                {
                    "authorId": "2219930073",
                    "name": "Salvatore Scalzo"
                },
                {
                    "authorId": "100789945",
                    "name": "Gabriele Mazzini"
                },
                {
                    "authorId": "2058031324",
                    "name": "Ignacio Sanchez"
                },
                {
                    "authorId": "2219929912",
                    "name": "Josep Soler Garrido"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                }
            ]
        },
        {
            "paperId": "e92d26ca27a6e51c1c0460ea29f89b72dffc5c5d",
            "title": "Trustworthy Algorithmic Ranking Systems",
            "abstract": "This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency as relevant dimensions of trustworthy AI systems, tailored to algorithmic ranking systems such as search engines and recommender systems. We will equip the mostly technical audience of WSDM with the necessary understanding of the social and ethical implications of their research and development on the one hand, and of recent ethical guidelines and regulatory frameworks addressing the aforementioned dimensions on the other hand. While the tutorial foremost takes a European perspective, starting from the concept of trustworthy AI and discussing EU regulation in this area currently in the implementation stages, we also consider related initiatives worldwide. Since ensuring non-discrimination, diversity, and transparency in retrieval and recommendation systems is an endeavor in which academic institutions and companies in different parts of the world should collaborate, this tutorial is relevant for researchers and practitioners interested in the ethical, social, and legal impact of their work. The tutorial, therefore, targets both academic scholars and practitioners around the globe, by reviewing recent research and providing practical examples addressing these particular trustworthiness aspects, and showcasing how new regulations affect the audience's daily work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                }
            ]
        },
        {
            "paperId": "16e3af4106b800fa1f3e04a1ab8556c0fe0a2001",
            "title": "Documenting use cases in the affective computing domain using Unified Modeling Language",
            "abstract": "The study of the ethical impact of AI and the design of trustworthy systems needs the analysis of the scenarios where AI systems are used, which is related to the software engineering concept of \u201cuse case\u201d and the \u201cintended purpose\u201d legal term. However, there is no standard methodology for use case documentation covering the context of use, scope, functional requirements and risks of an AI system. In this work, we propose a novel documentation methodology for AI use cases, with a special focus on the affective computing domain. Our approach builds upon an assessment of use case information needs documented in the research literature and the recently proposed European regulatory framework for AI. From this assessment, we adopt and adapt the Unified Modeling Language (UML), which has been used in the last two decades mostly by software engineers. Each use case is then represented by an UML diagram and a structured table, and we provide a set of examples illustrating its application to several affective computing scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2321433",
                    "name": "I. Hupont"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                }
            ]
        },
        {
            "paperId": "216301cc275232ac8614bf6fc04e05c1f97ee5ee",
            "title": "Monitoring Diversity of AI Conferences: Lessons Learnt and Future Challenges in the DivinAI Project",
            "abstract": "DivinAI is an open and collaborative initiative promoted by the European Commission's Joint Research Centre to measure and monitor diversity indicators related to AI conferences, with special focus on gender balance, geographical representation, and presence of academia vs companies. This paper summarizes the main achievements and lessons learnt during the first year of life of the DivinAI project, and proposes a set of recommendations for its further development and maintenance by the AI community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2321433",
                    "name": "I. Hupont"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                },
                {
                    "authorId": "12092873",
                    "name": "Song\u00fcl Tolan"
                },
                {
                    "authorId": "74248595",
                    "name": "Lorenzo Porcaro"
                },
                {
                    "authorId": "153328034",
                    "name": "Ana Freire"
                }
            ]
        },
        {
            "paperId": "5923f315e0a9324a61d789f0581dc185ad170a4a",
            "title": "Measuring the Occupational Impact of AI: Tasks, Cognitive Abilities and AI Benchmarks (Extended Abstract)",
            "abstract": "We present a framework for analysing the impact of AI on occupations. This framework maps 59 generic tasks from different occupational datasets to 14 cognitive abilities and these to a comprehensive list of 328 AI benchmarks used to evaluate research intensity in AI. The use of cognitive abilities as an intermediate layer allows for an identification of potential AI exposure for tasks for which AI applications have not been explicitly programmed. We provide insights into the abilities through which AI is most likely to affect jobs, and we show how some of the abilities where AI research is currently very intense are linked to tasks with comparatively limited labour input in the labour markets of advanced economies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12092873",
                    "name": "Song\u00fcl Tolan"
                },
                {
                    "authorId": "10305777",
                    "name": "Annarosa Pesole"
                },
                {
                    "authorId": "1399205325",
                    "name": "Fernando Mart\u00ednez-Plumed"
                },
                {
                    "authorId": "1403758241",
                    "name": "Enrique Fern\u00e1ndez-Mac\u00edas"
                },
                {
                    "authorId": "1398777358",
                    "name": "J. Hern\u00e1ndez-Orallo"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                }
            ]
        },
        {
            "paperId": "9b1b4854b322e9bdce6c3da59fdd6336615d3128",
            "title": "Scientific Challenges, Practical Methodologies and Policy Perspectives for Trustworthy Artificial Intelligence",
            "abstract": "Artificial intelligence (AI) systems, when applied in practical applications, have an impact on human behaviour. On the one hand, AI provides cognitive assistance to humans, such as helping us to interpret data more efficiently and discover hidden knowledge in large data resources. On the other hand, these AI systems also affect human decision making and cognitive and socio-emotional development. In this seminar I will provide an overview of the research carried out at HUMAINT (Human Behaviour and Machine Intelligence), an interdisciplinary research project carried out at the European Commission\u2019s Joint Research Centre. The goal of the project is to study the impact of AI on human behaviour, and aims to provide evidence-based scientific support to the European policymaking process in this field. I will present our policy context, project approach and outcomes, focusing on four core applications (facial processing, automated driving, child-AI interaction and music recommendation) and connected to practical methodologies for fairness, diversity, transparency and human oversight.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                }
            ]
        },
        {
            "paperId": "c7dc3248a9d170c431334ffffefe303e11af99c7",
            "title": "Retrieval and Recommendation Systems at the Crossroads of Artificial Intelligence, Ethics, and Regulation",
            "abstract": "This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency of AI systems, tailored to the research fields of information retrieval and recommender systems. By means of this tutorial, we would like to equip the mostly technical audience of SIGIR with the necessary understanding of the ethical implications of their research and development on the one hand, and of recent political and legal regulations that address the aforementioned challenges on the other hand.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                }
            ]
        }
    ]
}