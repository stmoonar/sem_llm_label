{
    "authorId": "1849611",
    "papers": [
        {
            "paperId": "0ae3d08bff81406b8806f6958e2bf9140593a6b3",
            "title": "Physics-guided Active Sample Reweighting for Urban Flow Prediction",
            "abstract": "Urban flow prediction is a spatio-temporal modeling task that estimates the throughput of transportation services like buses, taxis, and ride-sharing, where data-driven models have become the most popular solution in the past decade. Meanwhile, the implicitly learned mapping between historical observations to the prediction targets tend to over-simplify the dynamics of real-world urban flows, leading to suboptimal predictions. Some recent spatio-temporal prediction solutions bring remedies with the notion of physics-guided machine learning (PGML), which describes spatio-temporal data with nuanced and principled physics laws, thus enhancing both the prediction accuracy and interpretability. However, these spatio-temporal PGML methods are built upon a strong assumption that the observed data fully conforms to the differential equations that define the physical system, which can quickly become ill-posed in urban flow prediction tasks. The observed urban flow data, especially when sliced into time-dependent snapshots to facilitate predictions, is typically incomplete and sparse, and prone to inherent noise incurred in the collection process. As a result, such physical inconsistency between the data and PGML model significantly limits the predictive power and robustness of the solution. Moreover, due to the interval-based predictions and intermittent nature of data filing in many transportation services, the instantaneous dynamics of urban flows can hardly be captured, rendering differential equation-based continuous modeling a loose fit for this setting. To overcome the challenges, we develop a discretized physics-guided network (PN), and propose a data-aware framework Physics-guided Active Sample Reweighting (P-GASR) to enhance PN. Experimental results in four real-world datasets demonstrate that our method achieves state-of-the-art performance with a demonstrable improvement in robustness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2281470021",
                    "name": "Wei Jiang"
                },
                {
                    "authorId": "2280284086",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2280283715",
                    "name": "Wentao Zhang"
                },
                {
                    "authorId": "2281001972",
                    "name": "Lizhen Cui"
                },
                {
                    "authorId": "2129485845",
                    "name": "Zi-Liang Huang"
                },
                {
                    "authorId": "2267513105",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "24c406a66842b5e7d7ec1c2c6e5150d688c62b0f",
            "title": "Robust Federated Contrastive Recommender System against Model Poisoning Attack",
            "abstract": "Federated Recommender Systems (FedRecs) have garnered increasing attention recently, thanks to their privacy-preserving benefits. However, the decentralized and open characteristics of current FedRecs present two dilemmas. First, the performance of FedRecs is compromised due to highly sparse on-device data for each client. Second, the system's robustness is undermined by the vulnerability to model poisoning attacks launched by malicious users. In this paper, we introduce a novel contrastive learning framework designed to fully leverage the client's sparse data through embedding augmentation, referred to as CL4FedRec. Unlike previous contrastive learning approaches in FedRecs that necessitate clients to share their private parameters, our CL4FedRec aligns with the basic FedRec learning protocol, ensuring compatibility with most existing FedRec implementations. We then evaluate the robustness of FedRecs equipped with CL4FedRec by subjecting it to several state-of-the-art model poisoning attacks. Surprisingly, our observations reveal that contrastive learning tends to exacerbate the vulnerability of FedRecs to these attacks. This is attributed to the enhanced embedding uniformity, making the polluted target item embedding easily proximate to popular items. Based on this insight, we propose an enhanced and robust version of CL4FedRec (rCL4FedRec) by introducing a regularizer to maintain the distance among item embeddings with different popularity levels. Extensive experiments conducted on four commonly used recommendation datasets demonstrate that CL4FedRec significantly enhances both the model's performance and the robustness of FedRecs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106755543",
                    "name": "Wei Yuan"
                },
                {
                    "authorId": "2177256804",
                    "name": "Chao-Peng Yang"
                },
                {
                    "authorId": "2268398927",
                    "name": "Liang Qu"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2248231751",
                    "name": "Quoc Viet Hung Nguyen"
                },
                {
                    "authorId": "2278795560",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "334ebaae0a97fd7af3cd8ec0a9b02fb4fbba2f42",
            "title": "Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition",
            "abstract": "The increasing prevalence of large-scale graphs poses a significant challenge for graph neural network training, attributed to their substantial computational requirements. In response, graph condensation (GC) emerges as a promising data-centric solution aiming to substitute the large graph with a small yet informative condensed graph to facilitate data-efficient GNN training. However, existing GC methods suffer from intricate optimization processes, necessitating excessive computing resources. In this paper, we revisit existing GC optimization strategies and identify two pervasive issues: 1. various GC optimization strategies converge to class-level node feature matching between the original and condensed graphs, making the optimization target coarse-grained despite the complex computations; 2. to bridge the original and condensed graphs, existing GC methods rely on a Siamese graph network architecture that requires time-consuming bi-level optimization with iterative gradient computations. To overcome these issues, we propose a training-free GC framework termed Class-partitioned Graph Condensation (CGC), which refines the node feature matching from the class-to-class paradigm into a novel class-to-node paradigm. Remarkably, this refinement also simplifies the GC optimization as a class partition problem, which can be efficiently solved by any clustering methods. Moreover, CGC incorporates a pre-defined graph structure to enable a closed-form solution for condensed node features, eliminating the back-and-forth gradient descent in existing GC approaches without sacrificing accuracy. Extensive experiments demonstrate that CGC achieves state-of-the-art performance with a more efficient condensation process. For instance, compared with the seminal GC method (i.e., GCond), CGC condenses the largest Reddit graph within 10 seconds, achieving a 2,680X speedup and a 1.4% accuracy increase.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192083394",
                    "name": "Xin Gao"
                },
                {
                    "authorId": "2280284086",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2280283715",
                    "name": "Wentao Zhang"
                },
                {
                    "authorId": "28584977",
                    "name": "Junliang Yu"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "2267513105",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "4d61e6d951ee1e38d68d26b400abfbe1f1b07a67",
            "title": "Heterogeneous decentralised machine unlearning with seed model distillation",
            "abstract": "As some recent information security legislation endowed users with unconditional rights to be forgotten by any trained machine learning model, personalised IoT service providers have to put unlearning functionality into their consideration. The most straightforward method to unlearn users' contribution is to retrain the model from the initial state, which is not realistic in high throughput applications with frequent unlearning requests. Though some machine unlearning frameworks have been proposed to speed up the retraining process, they fail to match decentralised learning scenarios. A decentralised unlearning framework called heterogeneous decentralised unlearning framework with seed (HDUS) is designed, which uses distilled seed models to construct erasable ensembles for all clients. Moreover, the framework is compatible with heterogeneous on\u2010device models, representing stronger scalability in real\u2010world applications. Extensive experiments on three real\u2010world datasets show that our HDUS achieves state\u2010of\u2010the\u2010art performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "2267513105",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "4fb40bbfd21947c824efc235d4e318e7cc282c34",
            "title": "Physical Trajectory Inference Attack and Defense in Decentralized POI Recommendation",
            "abstract": "As an indispensable personalized service within Location-Based Social Networks (LBSNs), the Point-of-Interest (POI) recommendation aims to assist individuals in discovering attractive and engaging places. However, the accurate recommendation capability relies on the powerful server collecting a vast amount of users' historical check-in data, posing significant risks of privacy breaches. Although several collaborative learning (CL) frameworks for POI recommendation enhance recommendation resilience and allow users to keep personal data on-device, they still share personal knowledge to improve recommendation performance, thus leaving vulnerabilities for potential attackers. Given this, we design a new Physical Trajectory Inference Attack (PTIA) to expose users' historical trajectories. Specifically, for each user, we identify the set of interacted POIs by analyzing the aggregated information from the target POIs and their correlated POIs. We evaluate the effectiveness of PTIA on two real-world datasets across two types of decentralized CL frameworks for POI recommendation. Empirical results demonstrate that PTIA poses a significant threat to users' historical trajectories. Furthermore, Local Differential Privacy (LDP), the traditional privacy-preserving method for CL frameworks, has also been proven ineffective against PTIA. In light of this, we propose a novel defense mechanism (AGD) against PTIA based on an adversarial game to eliminate sensitive POIs and their information in correlated POIs. After conducting intensive experiments, AGD has been proven precise and practical, with minimal impact on recommendation performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161605203",
                    "name": "Jing Long"
                },
                {
                    "authorId": "2280284088",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2281641893",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "2267513105",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "50e76ab6f51510e9febd6c40ea3168f31441ecc7",
            "title": "PTF-FSR: A Parameter Transmission-Free Federated Sequential Recommender System",
            "abstract": "Sequential recommender systems have made significant progress. Recently, due to increasing concerns about user data privacy, some researchers have implemented federated learning for sequential recommendation, a.k.a., Federated Sequential Recommender Systems (FedSeqRecs), in which a public sequential recommender model is shared and frequently transmitted between a central server and clients to achieve collaborative learning. Although these solutions mitigate user privacy to some extent, they present two significant limitations that affect their practical usability: (1) They require a globally shared sequential recommendation model. However, in real-world scenarios, the recommendation model constitutes a critical intellectual property for platform and service providers. Therefore, service providers may be reluctant to disclose their meticulously developed models. (2) The communication costs are high as they correlate with the number of model parameters. This becomes particularly problematic as the current FedSeqRec will be inapplicable when sequential recommendation marches into a large language model era. To overcome the above challenges, this paper proposes a parameter transmission-free federated sequential recommendation framework (PTF-FSR), which ensures both model and data privacy protection to meet the privacy needs of service providers and system users alike. Furthermore, since PTF-FSR only transmits prediction results under privacy protection, which are independent of model sizes, this new federated learning architecture can accommodate more complex and larger sequential recommendation models. Extensive experiments conducted on three widely used recommendation datasets, employing various sequential recommendation models from both ID-based and ID-free paradigms, demonstrate the effectiveness and generalization capability of our proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106755543",
                    "name": "Wei Yuan"
                },
                {
                    "authorId": "2177256804",
                    "name": "Chao-Peng Yang"
                },
                {
                    "authorId": "2268398927",
                    "name": "Liang Qu"
                },
                {
                    "authorId": "2248231751",
                    "name": "Quoc Viet Hung Nguyen"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2278795560",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "575d626c47d1b6b74246d7ce168a64f6bcafbe4c",
            "title": "Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations",
            "abstract": "The rapid expansion of Location-Based Social Networks (LBSNs) has highlighted the importance of effective next Point-of-Interest (POI) recommendations, which leverage historical check-in data to predict users' next POIs to visit. Traditional centralized deep neural networks (DNNs) offer impressive POI recommendation performance but face challenges due to privacy concerns and limited timeliness. In response, on-device POI recommendations have been introduced, utilizing federated learning (FL) and decentralized approaches to ensure privacy and recommendation timeliness. However, these methods often suffer from computational strain on devices and struggle to adapt to new users and regions. This paper introduces a novel collaborative learning framework, Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations (DCPR), leveraging the diffusion model known for its success across various domains. DCPR operates with a cloud-edge-device architecture to offer region-specific and highly personalized POI recommendations while reducing on-device computational burdens. DCPR minimizes on-device computational demands through a unique blend of global and local learning processes. Our evaluation with two real-world datasets demonstrates DCPR's superior performance in recommendation accuracy, efficiency, and adaptability to new users and regions, marking a significant step forward in on-device POI recommendation technology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161605203",
                    "name": "Jing Long"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2280284086",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2155651371",
                    "name": "Yang Wang"
                },
                {
                    "authorId": "2146059429",
                    "name": "Meng Wang"
                },
                {
                    "authorId": "2267513105",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "7492e77261c90c9491e790e9c76b3a564c0efb0c",
            "title": "FELLAS: Enhancing Federated Sequential Recommendation with LLM as External Services",
            "abstract": "Federated sequential recommendation (FedSeqRec) has gained growing attention due to its ability to protect user privacy. Unfortunately, the performance of FedSeqRec is still unsatisfactory because the models used in FedSeqRec have to be lightweight to accommodate communication bandwidth and clients' on-device computational resource constraints. Recently, large language models (LLMs) have exhibited strong transferable and generalized language understanding abilities and therefore, in the NLP area, many downstream tasks now utilize LLMs as a service to achieve superior performance without constructing complex models. Inspired by this successful practice, we propose a generic FedSeqRec framework, FELLAS, which aims to enhance FedSeqRec by utilizing LLMs as an external service. Specifically, FELLAS employs an LLM server to provide both item-level and sequence-level representation assistance. The item-level representation service is queried by the central server to enrich the original ID-based item embedding with textual information, while the sequence-level representation service is accessed by each client. However, invoking the sequence-level representation service requires clients to send sequences to the external LLM server. To safeguard privacy, we implement dx-privacy satisfied sequence perturbation, which protects clients' sensitive data with guarantees. Additionally, a contrastive learning-based method is designed to transfer knowledge from the noisy sequence representation to clients' sequential recommendation models. Furthermore, to empirically validate the privacy protection capability of FELLAS, we propose two interacted item inference attacks. Extensive experiments conducted on three datasets with two widely used sequential recommendation models demonstrate the effectiveness and privacy-preserving capability of FELLAS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Wei Yuan"
                },
                {
                    "authorId": "2177256804",
                    "name": "Chao-Peng Yang"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2324833110",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2248231751",
                    "name": "Quoc Viet Hung Nguyen"
                }
            ]
        },
        {
            "paperId": "9cc2171bcffc1fb73664702afd8488ab4be44ad7",
            "title": "Poisoning Attacks and Defenses in Recommender Systems: A Survey",
            "abstract": "Modern recommender systems (RS) have profoundly enhanced user experience across digital platforms, yet they face significant threats from poisoning attacks. These attacks, aimed at manipulating recommendation outputs for unethical gains, exploit vulnerabilities in RS through injecting malicious data or intervening model training. This survey presents a unique perspective by examining these threats through the lens of an attacker, offering fresh insights into their mechanics and impacts. Concretely, we detail a systematic pipeline that encompasses four stages of a poisoning attack: setting attack goals, assessing attacker capabilities, analyzing victim architecture, and implementing poisoning strategies. The pipeline not only aligns with various attack tactics but also serves as a comprehensive taxonomy to pinpoint focuses of distinct poisoning attacks. Correspondingly, we further classify defensive strategies into two main categories: poisoning data filtering and robust training from the defender's perspective. Finally, we highlight existing limitations and suggest innovative directions for further exploration in this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2040449292",
                    "name": "Zongwei Wang"
                },
                {
                    "authorId": "28584977",
                    "name": "Junliang Yu"
                },
                {
                    "authorId": "2155431892",
                    "name": "Min Gao"
                },
                {
                    "authorId": "2106755543",
                    "name": "Wei Yuan"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2268756599",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "2260297841",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "f20d934631943945f95f82d00a5868cb22f0aabb",
            "title": "RobGC: Towards Robust Graph Condensation",
            "abstract": "Graph neural networks (GNNs) have attracted widespread attention for their impressive capability of graph representation learning. However, the increasing prevalence of large-scale graphs presents a significant challenge for GNN training due to their computational demands, limiting the applicability of GNNs in various scenarios. In response to this challenge, graph condensation (GC) is proposed as a promising acceleration solution, focusing on generating an informative compact graph that enables efficient training of GNNs while retaining performance. Despite the potential to accelerate GNN training, existing GC methods overlook the quality of large training graphs during both the training and inference stages. They indiscriminately emulate the training graph distributions, making the condensed graphs susceptible to noises within the training graph and significantly impeding the application of GC in intricate real-world scenarios. To address this issue, we propose robust graph condensation (RobGC), a plug-and-play approach for GC to extend the robustness and applicability of condensed graphs in noisy graph structure environments. Specifically, RobGC leverages the condensed graph as a feedback signal to guide the denoising process on the original training graph. A label propagation-based alternating optimization strategy is in place for the condensation and denoising processes, contributing to the mutual purification of the condensed graph and training graph. Additionally, as a GC method designed for inductive graph inference, RobGC facilitates test-time graph denoising by leveraging the noise-free condensed graph to calibrate the structure of the test graph. Extensive experiments show that RobGC is compatible with various GC methods, significantly boosting their robustness under different types and levels of graph structural noises.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192083394",
                    "name": "Xin Gao"
                },
                {
                    "authorId": "2267513105",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2280284086",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "2280283715",
                    "name": "Wentao Zhang"
                },
                {
                    "authorId": "2257282067",
                    "name": "Bin Cui"
                }
            ]
        }
    ]
}