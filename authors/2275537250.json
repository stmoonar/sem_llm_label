{
    "authorId": "2275537250",
    "papers": [
        {
            "paperId": "33546ba889b58a5ae4fd842e44af8b1a265c28cd",
            "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
            "abstract": "As the demand for more personalized recommendation grows and a dramatic boom in commercial scenarios arises, the study on multi-scenario recommendation (MSR) has attracted much attention, which uses the data from all scenarios to simultaneously improve their recommendation performance. However, existing methods tend to integrate insufficient scenario knowledge and neglect learning personalized cross-scenario preferences, thus leading to suboptimal performance and inadequate interpretability. Meanwhile, though large language model (LLM) has shown great capability of reasoning and capturing semantic information, the high inference latency and high computation cost of tuning hinder its implementation in industrial recommender systems. To fill these gaps, we propose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR in this work. Specifically, we first leverage LLM to uncover multi-level knowledge including scenario correlations and users' cross-scenario interests from the designed scenario- and user-level prompt without fine-tuning the LLM, then adopt hierarchical meta networks to generate multi-level meta layers to explicitly improves the scenario-aware and personalized recommendation capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets validate two significant advantages of LLM4MSR: (i) the effectiveness and compatibility with different multi-scenario backbone models (achieving 1.5%, 1%, and 40% AUC improvement on three datasets), (ii) high efficiency and deployability on industrial recommender systems, and (iii) improved interpretability. The implemented code and data is available to ease reproduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2275537250",
                    "name": "Zichuan Fu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "b6bc1590ae632fd8325fab23edf5c333a9a7723c",
            "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
            "abstract": "Click-Through Rate (CTR) prediction is a crucial task in online recommendation platforms as it involves estimating the probability of user engagement with advertisements or items by clicking on them. Given the availability of various services like online shopping, ride-sharing, food delivery, and professional services on commercial platforms, recommendation systems in these platforms are required to make CTR predictions across multiple domains rather than just a single domain. However, multi-domain click-through rate (MDCTR) prediction remains a challenging task in online recommendation due to the complex mutual influence between domains. Traditional MDCTR models typically encode domains as discrete identifiers, ignoring rich semantic information underlying. Consequently, they can hardly generalize to new domains. Besides, existing models can be easily dominated by some specific domains, which results in significant performance drops in the other domains (i.e. the\"seesaw phenomenon\"). In this paper, we propose a novel solution Uni-CTR to address the above challenges. Uni-CTR leverages a backbone Large Language Model (LLM) to learn layer-wise semantic representations that capture commonalities between domains. Uni-CTR also uses several domain-specific networks to capture the characteristics of each domain. Note that we design a masked loss strategy so that these domain-specific networks are decoupled from backbone LLM. This allows domain-specific networks to remain unchanged when incorporating new or removing domains, thereby enhancing the flexibility and scalability of the system significantly. Experimental results on three public datasets show that Uni-CTR outperforms the state-of-the-art (SOTA) MDCTR models significantly. Furthermore, Uni-CTR demonstrates remarkable effectiveness in zero-shot prediction. We have applied Uni-CTR in industrial scenarios, confirming its efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275537250",
                    "name": "Zichuan Fu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2275119462",
                    "name": "Mengchen Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        }
    ]
}