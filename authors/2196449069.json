{
    "authorId": "2196449069",
    "papers": [
        {
            "paperId": "3def10f5aec43ee78891e66d0efb31ad4f06d5b0",
            "title": "Continuous-Time Linear Positional Embedding for Irregular Time Series Forecasting",
            "abstract": "Irregularly sampled time series forecasting, characterized by non-uniform intervals, is prevalent in practical applications. However, previous research have been focused on regular time series forecasting, typically relying on transformer architectures. To extend transformers to handle irregular time series, we tackle the positional embedding which represents the temporal information of the data. We propose CTLPE, a method learning a continuous linear function for encoding temporal information. The two challenges of irregular time series, inconsistent observation patterns and irregular time gaps, are solved by learning a continuous-time function and concise representation of position. Additionally, the linear continuous function is empirically shown superior to other continuous functions by learning a neural controlled differential equation-based positional embedding, and theoretically supported with properties of ideal positional embedding. CTLPE outperforms existing techniques across various irregularly-sampled time series datasets, showcasing its enhanced efficacy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196449069",
                    "name": "Byunghyun Kim"
                },
                {
                    "authorId": "2323518366",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "72f38d513a8ab095a3d4f459958cbb31b1f7cdc4",
            "title": "Universal Time-Series Representation Learning: A Survey",
            "abstract": "Time-series data exists in every corner of real-world systems and services, ranging from satellites in the sky to wearable devices on human bodies. Learning representations by extracting and inferring valuable information from these time series is crucial for understanding the complex dynamics of particular phenomena and enabling informed decisions. With the learned representations, we can perform numerous downstream analyses more effectively. Among several approaches, deep learning has demonstrated remarkable performance in extracting hidden patterns and features from time-series data without manual feature engineering. This survey first presents a novel taxonomy based on three fundamental elements in designing state-of-the-art universal representation learning methods for time series. According to the proposed taxonomy, we comprehensively review existing studies and discuss their intuitions and insights into how these methods enhance the quality of learned representations. Finally, as a guideline for future studies, we summarize commonly used experimental setups and datasets and discuss several promising research directions. An up-to-date corresponding resource is available at https://github.com/itouchz/awesome-deep-time-series-representations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134607506",
                    "name": "Patara Trirat"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "153041205",
                    "name": "Junhyeok Kang"
                },
                {
                    "authorId": "1900303688",
                    "name": "Youngeun Nam"
                },
                {
                    "authorId": "2278435709",
                    "name": "Jihye Na"
                },
                {
                    "authorId": "2278437886",
                    "name": "Minyoung Bae"
                },
                {
                    "authorId": "2278590857",
                    "name": "Joeun Kim"
                },
                {
                    "authorId": "2196449069",
                    "name": "Byunghyun Kim"
                },
                {
                    "authorId": "2222379427",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "9736cc2d5b52bb2c9fd305d07f23b4a6c70cefc9",
            "title": "Context Consistency Regularization for Label Sparsity in Time Series",
            "abstract": "Labels are typically sparse in real-world time series due to the high annotation cost. Recently, consistency regularization techniques have been used to generate artificial labels from unlabeled augmented instances. To fully exploit the sequential characteristic of time series in consistency regularization, we propose a novel method of data augmentation called context-attached augmentation , which adds preceding and succeeding instances to a target instance to form its augmented instance. Unlike the existing augmentation techniques that modify a target instance by directly perturbing its attributes, the context-attached augmentation generates instances augmented with varying contexts while maintaining the target instance. Based on our augmentation method, we propose a context consistency regularization framework, which first adds different contexts to a target instance sampled from a given time series and then shares unitary reliability-based cross-window labels across the augmented instances to maintain consistency. We demonstrate that the proposed framework outperforms the existing state-of-the-art consistency regularization frameworks through comprehensive experiments on real-world time-series datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2196449069",
                    "name": "Byunghyun Kim"
                },
                {
                    "authorId": "2143422249",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "2152439884",
                    "name": "Byung Suk Lee"
                }
            ]
        }
    ]
}