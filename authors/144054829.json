{
    "authorId": "144054829",
    "papers": [
        {
            "paperId": "0160e76ffc72d073860c70ffc32c4a5eb83b1ecd",
            "title": "HostileNet: Multilabel Hostile Post Detection in Hindi",
            "abstract": "In this article, we deal with the task of hostile post detection in Hindi. The objective is to predict whether a social media post is hostile or not. Furthermore, if the post is hostile, we identify one or more fine-grained hostile dimensions out of the following four\u2014fake, hate, offensive, and defamation. We propose HostileNet, a novel deep-learning framework that leverages HindiBERT-based contextual representations and hand-crafted features like lexicon, emoticon, and hashtag embeddings for hostile post classification. Moreover, we also propose a novel mechanism to fine-tune HindiBERT\u2019s attention vectors with respect to each hostile dimension. We evaluate HostileNet on the CONSTRAINT-2021 shared task dataset on hostile post detection in Hindi for both coarse-grained (hostile versus nonhostile) and fine-grained (fake versus hate versus offensive versus defamation) setups. HostileNet outperforms the best-performing system as reported in the CONSTRAINT-2021 shared task for both the setups. Furthermore, we provide a thorough analysis of the obtained results in the form of an ablation study, error analysis, attention heatmap analysis, lexicon feature analysis, and so on. We also perform in-the-wild evaluation and conduct a user survey to assess the robustness of our proposed model. We make the code and the curated multilabel hostile lexicon available for research use at https://github.com/LCS2-IIITD/HostileNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7010596",
                    "name": "M. Bhardwaj"
                },
                {
                    "authorId": "2047401513",
                    "name": "Megha Sundriyal"
                },
                {
                    "authorId": "2103384516",
                    "name": "Manjot Bedi"
                },
                {
                    "authorId": "46815454",
                    "name": "Md. Shad Akhtar"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "1319e3f987be71ad825a4107f781403c4c739820",
            "title": "On Efficient Large Maximal Biplex Discovery",
            "abstract": "Cohesive subgraph discovery is an important problem in bipartite graph mining. In this paper, we focus on one kind of cohesive structure, called <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq1-3077071.gif\"/></alternatives></inline-formula>-biplex, where each vertex of one side is disconnected from at most <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq2-3077071.gif\"/></alternatives></inline-formula> vertices of the other side. We consider the large maximal <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq3-3077071.gif\"/></alternatives></inline-formula>-biplex enumeration problem which is to list all those maximal <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq4-3077071.gif\"/></alternatives></inline-formula>-biplexes with the number of vertices at each side at least a non-negative integer <inline-formula><tex-math notation=\"LaTeX\">$\\theta$</tex-math><alternatives><mml:math><mml:mi>\u03b8</mml:mi></mml:math><inline-graphic xlink:href=\"yu-ieq5-3077071.gif\"/></alternatives></inline-formula>. This formulation, we observe, has various applications and targets to find non-redundant results by excluding non-maximal ones. Existing approaches suffer from massive redundant computations and can only run on small and moderate datasets. Towards improving scalability, we propose an efficient tree-based algorithm with two advanced strategies and powerful pruning techniques. Experimental results on real and synthetic datasets show the superiority of our algorithm over existing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114076598",
                    "name": "Kaiqiang Yu"
                },
                {
                    "authorId": "2073610291",
                    "name": "Cheng Long"
                },
                {
                    "authorId": "2113885594",
                    "name": "P. Deepak"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "1fb5a5298747b8c7d60f98640a543f20d42ab053",
            "title": "Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment",
            "abstract": "In-context learning (ICL) unfolds as large language models become capable of inferring test labels conditioned on a few labeled samples without any gradient update. ICL-enabled large language models provide a promising step forward toward bypassing recurrent annotation costs in a low-resource setting. Yet, only a handful of past studies have explored ICL in a cross-lingual setting, in which the need for transferring label-knowledge from a high-resource language to a low-resource one is immensely crucial. To bridge the gap, we provide the first in-depth analysis of ICL for cross-lingual text classification. We find that the prevalent mode of selecting random input-label pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces. To mitigate this, we propose a novel prompt construction strategy \u2014 Cross-lingual In-context Source Target Alignment (X-InSTA). With an injected coherence in the semantics of the input examples and a task-based alignment across the source and target languages, X-InSTA is able to outperform random prompt selection by a large margin across three different tasks using 44 different cross-lingual pairs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2210797473",
                    "name": "Eshaan Tanwar"
                },
                {
                    "authorId": "2216713643",
                    "name": "Manish Borthakur"
                },
                {
                    "authorId": "50757931",
                    "name": "Subhabrata Dutta"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "2f6bce4e5b32a5af6d2012ff55cbb24ad179f7b7",
            "title": "Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection",
            "abstract": "Hate speech in social media is a growing phenomenon, and detecting such toxic content has recently gained significant traction in the research community. Existing studies have explored fine-tuning language models (LMs) to perform hate speech detection, and these solutions have yielded significant performance. However, most of these studies are limited to detecting hate speech only in English, neglecting the bulk of hateful content that is generated in other languages, particularly in low-resource languages. Developing a classifier that captures hate speech and nuances in a low-resource language with limited data is extremely challenging. To fill the research gap, we propose HateMAML, a model-agnostic meta-learning (MAML)-based framework that effectively performs hate speech detection in low-resource languages. HateMAML utilizes a self-supervision strategy to overcome the limitation of data scarcity and produces better LM initialization for fast adaptation to an unseen target language (i.e., cross-lingual transfer) or other hate speech datasets (i.e., domain generalization). Extensive experiments are conducted on five datasets across eight different low-resource languages. The results show that HateMAML outperforms the state-of-the-art baselines by more than 3% in the cross-domain multilingual transfer setting. We also conduct ablation studies to analyze the characteristics of HateMAML.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2019829",
                    "name": "Rabiul Awal"
                },
                {
                    "authorId": "38656724",
                    "name": "R. Lee"
                },
                {
                    "authorId": "2210797473",
                    "name": "Eshaan Tanwar"
                },
                {
                    "authorId": "2091462076",
                    "name": "Tanmay Garg"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "35dee171e843f07d13622f57e475fcbcab7aad31",
            "title": "Multi-Document Summarization Using Selective Attention Span and Reinforcement Learning",
            "abstract": "Abstractive text summarization systems using recently improved RNN-based sequence-to-sequence architecture have shown great promise for single-document summarization. However, such neural models fail to perpetuate the performance in the multi-document summarization setting owing to the long-range dependencies within the documents, overlapping/contradicting facts and extrinsic model hallucinations. These shortcomings augment the model to generate inconsistent, repetitive and non-factual summaries. In this work, we introduce <monospace>REISA</monospace>, a sequence-to-sequence model with a novel <italic>reinforced selective attention span</italic> that attends over the input and recalibrates the local attention weights to focus on important segments while generating output at each time step. <monospace>REISA</monospace> utilizes a reinforcement learning-based policy gradient algorithm to reward the model and formulate attention distributions over the encoder input. We further benchmark <monospace>REISA</monospace> on two widely-used multi-document summarization corpora \u2013 Multinews and CQASumm, and observe an improvement of <inline-formula><tex-math notation=\"LaTeX\">$+2.91$</tex-math></inline-formula> and <inline-formula><tex-math notation=\"LaTeX\">$+6.64$</tex-math></inline-formula> ROUGE-L scores, respectively. The qualitative analyses on semantic similarity by BERTScore, faithfulness by question-answer evaluation and human evaluation show significant improvement over the baseline-generated summaries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1986291522",
                    "name": "Yash Kumar Atri"
                },
                {
                    "authorId": "1744939",
                    "name": "Vikram Goyal"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "3a0f3c7affd3ac0bf1f98c8c99537088e74a1724",
            "title": "Persona-aware Generative Model for Code-mixed Language",
            "abstract": "Code-mixing and script-mixing are prevalent across online social networks and multilingual societies. However, a user's preference toward code-mixing depends on the socioeconomic status, demographics of the user, and the local context, which existing generative models mostly ignore while generating code-mixed texts. In this work, we make a pioneering attempt to develop a persona-aware generative model to generate texts resembling real-life code-mixed texts of individuals. We propose a Persona-aware Generative Model for Code-mixed Generation, PARADOX, a novel Transformer-based encoder-decoder model that encodes an utterance conditioned on a user's persona and generates code-mixed texts without monolingual reference data. We propose an alignment module that re-calibrates the generated sequence to resemble real-life code-mixed texts. PARADOX generates code-mixed texts that are semantically more meaningful and linguistically more valid. To evaluate the personification capabilities of PARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM KS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% better perplexity and 32% better semantic coherence than the non-persona-based counterparts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34920835",
                    "name": "Ayan Sengupta"
                },
                {
                    "authorId": "46815454",
                    "name": "Md. Shad Akhtar"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "3ed00c773df2025c0e76e368bd1488bfc9667ef5",
            "title": "Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation",
            "abstract": "Counterspeech has been demonstrated to be an efficacious approach for combating hate speech. While various conventional and controlled approaches have been studied in recent years to generate counterspeech, a counterspeech with a certain intent may not be sufficient in every scenario. Due to the complex and multifaceted nature of hate speech, utilizing multiple forms of counter-narratives with varying intents may be advantageous in different circumstances. In this paper, we explore intent-conditioned counterspeech generation. At first, we develop IntentCONAN, a diversified intent-specific counterspeech dataset with 6831 counterspeeches conditioned on five intents, i.e., informative, denouncing, question, positive, and humour. Subsequently, we propose QUARC, a two-stage framework for intent-conditioned counterspeech generation. QUARC leverages vector-quantized representations learned for each intent category along with PerFuMe, a novel fusion module to incorporate intent-specific information into the model. Our evaluation demonstrates that QUARC outperforms several baselines by an average of ~10% across evaluation metrics. An extensive human evaluation supplements our hypothesis of better and more appropriate responses than comparative systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109271927",
                    "name": "Rishabh Gupta"
                },
                {
                    "authorId": "2052355969",
                    "name": "Shaily Desai"
                },
                {
                    "authorId": "2060268427",
                    "name": "Manvi Goel"
                },
                {
                    "authorId": "3468628",
                    "name": "Anil Bandhakavi"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                },
                {
                    "authorId": "46815454",
                    "name": "Md. Shad Akhtar"
                }
            ]
        },
        {
            "paperId": "4eb92746e469b85bde6b8f8a44bc9c9095d68c97",
            "title": "Hatemongers ride on echo chambers to escalate hate speech diffusion",
            "abstract": "Abstract Recent years have witnessed a swelling rise of hateful and abusive content over online social networks. While detection and moderation of hate speech have been the early go-to countermeasures, the solution requires a deeper exploration of the dynamics of hate generation and propagation. We analyze more than 32 million posts from over 6.8 million users across three popular online social networks to investigate the interrelations between hateful behavior, information dissemination, and polarized organization mediated by echo chambers. We find that hatemongers play a more crucial role in governing the spread of information compared to singled-out hateful content. This observation holds for both the growth of information cascades as well as the conglomeration of hateful actors. Dissection of the core-wise distribution of these networks points towards the fact that hateful users acquire a more well-connected position in the social network and often flock together to build up information cascades. We observe that this cohesion is far from mere organized behavior; instead, in these networks, hatemongers dominate the echo chambers\u2014groups of users actively align themselves to specific ideological positions. The observed dominance of hateful users to inflate information cascades is primarily via user interactions amplified within these echo chambers. We conclude our study with a cautionary note that popularity-based recommendation of content is susceptible to be exploited by hatemongers given their potential to escalate content popularity via echo-chambered interactions.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1993687001",
                    "name": "Vasu Goel"
                },
                {
                    "authorId": "2123019995",
                    "name": "Dhruv Sahnan"
                },
                {
                    "authorId": "50757931",
                    "name": "Subhabrata Dutta"
                },
                {
                    "authorId": "3468628",
                    "name": "Anil Bandhakavi"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "5ac1e7755ba647c21d0f524260a17b7678d87a42",
            "title": "Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection",
            "abstract": "Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in which surface and implied forms differ, and observe similar performance improvement. We analyze the generated latent space to understand its evolution under FiADD, which corroborates the advantage of employing FiADD for implicit hate speech detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36715403",
                    "name": "Sarah Masud"
                },
                {
                    "authorId": "2243338012",
                    "name": "Ashutosh Bajpai"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "64daf0dd3cf9adef433d568627e2c3a784219878",
            "title": "Response-act Guided Reinforced Dialogue Generation for Mental Health Counseling",
            "abstract": "Virtual Mental Health Assistants (VMHAs) have become a prevalent method for receiving mental health counseling in the digital healthcare space. An assistive counseling conversation commences with natural open-ended topics to familiarize the client with the environment and later converges into more fine-grained domain-specific topics. Unlike other conversational systems, which are categorized as open-domain or task-oriented systems, VMHAs possess a hybrid conversational flow. These counseling bots need to comprehend various aspects of the conversation, such as dialogue-acts, intents, etc., to engage the client in an effective and appropriate conversation. Although the surge in digital health research highlights applications of many general-purpose response generation systems, they are barely suitable in the mental health domain \u2013 the prime reason is the lack of understanding in the mental health counseling conversation. Moreover, in general, dialogue-act guided response generators are either limited to a template-based paradigm or lack appropriate semantics in dialogue generation. To this end, we propose READER \u2013 a REsponse-Act guided reinforced Dialogue genERation model for the mental health counseling conversations. READER is built on transformer to jointly predict a potential dialogue-act dt + 1 for the next utterance (aka response-act) and to generate an appropriate response (ut + 1). Through the transformer-reinforcement-learning (TRL) with Proximal Policy Optimization (PPO), we guide the response generator to abide by dt + 1 and ensure the semantic richness of the responses via BERTScore in our reward computation. We evaluate READER on HOPE, a benchmark counseling conversation dataset and observe that it outperforms several baselines across several evaluation metrics \u2013 METEOR, ROUGE, and BERTScore.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191418397",
                    "name": "Aseem Srivastava"
                },
                {
                    "authorId": "26658735",
                    "name": "Ishan Pandey"
                },
                {
                    "authorId": "46815454",
                    "name": "Md. Shad Akhtar"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        }
    ]
}