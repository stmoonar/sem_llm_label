{
    "authorId": "2145909936",
    "papers": [
        {
            "paperId": "426c88416f27e636fe64e02597f14de08e65b883",
            "title": "Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation",
            "abstract": "Within the context of autonomous driving, encountering unknown objects becomes inevitable during deployment in the open world. Therefore, it is crucial to equip standard semantic segmentation models with anomaly awareness. Many previous approaches have utilized synthetic out-of-distribution (OoD) data augmentation to tackle this problem. In this work, we advance the OoD synthesis process by reducing the domain gap between the OoD data and driving scenes, effectively mitigating the style difference that might otherwise act as an obvious shortcut during training. Additionally, we propose a simple fine-tuning loss that effectively induces a pre-trained semantic segmentation model to generate a \"none of the given classes\" prediction, leveraging per-pixel OoD scores for anomaly segmentation. With minimal fine-tuning effort, our pipeline enables the use of pre-trained models for anomaly segmentation while maintaining the performance on the original task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "3384946",
                    "name": "K. Sakmann"
                },
                {
                    "authorId": "52020792",
                    "name": "William H. Beluch"
                },
                {
                    "authorId": "32038986",
                    "name": "Robin Hutmacher"
                },
                {
                    "authorId": "2111175926",
                    "name": "Yumeng Li"
                }
            ]
        },
        {
            "paperId": "55ce1dc9d329aa6033a7bbb6d4e80c375fd5c065",
            "title": "CLC: Cluster Assignment via Contrastive Representation Learning",
            "abstract": "\u2014Clustering remains an important and challenging task of grouping samples into clusters without manual annotations. Recent works have achieved excellent results on small datasets by performing clustering on feature representations learned from self-supervised learning. However, for datasets with a large number of clusters, such as ImageNet, current methods still can not achieve high clustering performance. In this paper, we propose Contrastive Learning-based Clustering (CLC), which uses contrastive learning to directly learn cluster assignment. We decompose the representation into two parts: one encodes the categorical information under an equipartition constraint, and the other captures the instance-wise factors. We propose a contrastive loss using both parts of the representation. We theoretically analyze the proposed contrastive loss and reveal that CLC sets different weights for the negative samples while learning cluster assignments. Further gradient analysis shows that the larger weights tend to focus more on the hard negative samples. Therefore, the proposed loss has high expressiveness that enables us to efficiently learn cluster assignments. Experimental evaluation shows that CLC achieves overall state-of-the-art or highly competitive clustering performance on multiple benchmark datasets. In particular, we achieve 53.4% accuracy on the full ImageNet dataset and outperform existing methods by large margins (+ 10.2%).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064424445",
                    "name": "Fei Ding"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2051639502",
                    "name": "Yin Yang"
                },
                {
                    "authorId": "2095713717",
                    "name": "V. Krovi"
                },
                {
                    "authorId": "2140495064",
                    "name": "Feng Luo"
                }
            ]
        },
        {
            "paperId": "c4a349353c8053d9bedfd68110fbcab5f358cff6",
            "title": "Divide & Bind Your Attention for Improved Generative Semantic Nursing",
            "abstract": "Emerging large-scale text-to-image generative models, e.g., Stable Diffusion (SD), have exhibited overwhelming results with high fidelity. Despite the magnificent progress, current state-of-the-art models still struggle to generate images fully adhering to the input prompt. Prior work, Attend&Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming to optimize cross-attention during inference time to better incorporate the semantics. It demonstrates promising results in generating simple prompts, e.g.,\"a cat and a dog\". However, its efficacy declines when dealing with more complex prompts, and it does not explicitly address the problem of improper attribute binding. To address the challenges posed by complex prompts or scenarios involving multiple entities and to achieve improved attribute binding, we propose Divide&Bind. We introduce two novel loss objectives for GSN: a novel attendance loss and a binding loss. Our approach stands out in its ability to faithfully synthesize desired objects with improved attribute alignment from complex prompts and exhibits superior performance across multiple evaluation benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111175926",
                    "name": "Yumeng Li"
                },
                {
                    "authorId": "3316866",
                    "name": "M. Keuper"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "145327993",
                    "name": "A. Khoreva"
                }
            ]
        },
        {
            "paperId": "f310a5f06888b6dbfbbcd7a75d4d160ad598ae9e",
            "title": "Contrastive Representation Disentanglement for Clustering",
            "abstract": "Clustering continues to be a significant and challenging task. Recent studies have demonstrated impressive results by applying clustering to feature representations acquired through self-supervised learning, particularly on small datasets. However, when dealing with datasets containing a large number of clusters, such as ImageNet, current methods struggle to achieve satisfactory clustering performance. In this paper, we introduce a novel method called Contrastive representation Disentanglement for Clustering (CDC) that leverages contrastive learning to directly disentangle the feature representation for clustering. In CDC, we decompose the representation into two distinct components: one component encodes categorical information under an equipartition constraint, and the other component captures instance-specific factors. To train our model, we propose a contrastive loss that effectively utilizes both components of the representation. We conduct a theoretical analysis of the proposed loss and highlight how it assigns different weights to negative samples during the process of disentangling the feature representation. Further analysis of the gradients reveals that larger weights emphasize a stronger focus on hard negative samples. As a result, the proposed loss exhibits strong expressiveness, enabling efficient disentanglement of categorical information. Through experimental evaluation on various benchmark datasets, our method demonstrates either state-of-the-art or highly competitive clustering performance. Notably, on the complete ImageNet dataset, we achieve an accuracy of 53.4%, surpassing existing methods by a substantial margin of +10.2%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064424445",
                    "name": "Fei Ding"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2051639502",
                    "name": "Yin Yang"
                },
                {
                    "authorId": "2095713717",
                    "name": "V. Krovi"
                },
                {
                    "authorId": "2140495064",
                    "name": "Feng Luo"
                }
            ]
        },
        {
            "paperId": "116903a377f3327903f586c10253bcd53cd5c535",
            "title": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation through Cross-Task Consistency",
            "abstract": "This paper addresses the task of semantic segmentation in computer vision, aiming to achieve precise pixel-wise classification. We investigate the joint training of models for semantic edge detection and semantic segmentation, which has shown a promise. However, implicit cross-task consistency learning in multitask networks is limited. To address this, we propose a novel \u201cdecoupled cross-task consistency loss\u201d that explicitly enhances cross-task consistency. Our semantic segmentation network, TriangleNet, achieves a substantial 2.88% improvement over the Baseline in mean Intersection over Union (mIoU) on the Cityscapes test set. Notably, TriangleNet operates at 77.4% mIoU/46.2 FPS on Cityscapes, showcasing real-time inference capabilities at full resolution. With multiscale inference, performance is further enhanced to 77.8%. Furthermore, TriangleNet consistently outperforms the Baseline on the FloodNet dataset, demonstrating its robust generalization capabilities. The proposed method underscores the significance of multitask learning and explicit cross-task consistency enhancement for advancing semantic segmentation and highlights the potential of multitasking in real-time semantic segmentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "144796604",
                    "name": "Rui Zheng"
                }
            ]
        },
        {
            "paperId": "1ca1a371f8cbfb714126350afd5225eafe7f65ce",
            "title": "Low-resource Interactive Active Labeling for Fine-tuning Language Models",
            "abstract": "Recently, active learning (AL) methods have been used to effectively fine-tune pre-trained language models for various NLP tasks such as sentiment analysis and document classification. However, given the task of fine-tuning language models, understanding the impact of different aspects on AL methods such as labeling cost, sample acquisition latency, and the diversity of the datasets necessitates a deeper investigation. This paper examines the performance of existing AL methods within a low-resource, interactive labeling setting. We observe that existing methods often underperform in such a setting while exhibiting higher latency and a lack of generalizability. To overcome these challenges, we propose a novel active learning method T YROGUE that employs a hybrid sampling strategy to minimize labeling cost and acquisition latency while providing a framework for adapting to dataset diversity via user guidance. Through our experiments, we observe that compared to SOTA methods, T Y - ROGUE reduces the labeling cost by up to 43% and the acquisition latency by as much as 11 X , while achieving comparable accuracy. Finally, we discuss the strengths and weaknesses of T YROGUE by exploring the impact of dataset characteristics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "83776034",
                    "name": "Seiji Maekawa"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                }
            ]
        },
        {
            "paperId": "28f41f1008ce666cf21b146b623aeb36289c4f30",
            "title": "Panoptic-PHNet: Towards Real-Time and High-Precision LiDAR Panoptic Segmentation via Clustering Pseudo Heatmap",
            "abstract": "As a rising task, panoptic segmentation is faced with challenges in both semantic segmentation and instance seg-mentation. However, in terms of speed and accuracy, ex-isting LiDAR methods in the field are still limited. In this paper, we propose a fast and high-performance LiDAR-basedframework, referred to as Panoptic-PHNet, with three attractive aspects: 1) We introduce a clustering pseudo heatmap as a new paradigm, which, followed by a cen-ter grouping module, yields instance centers for efficient clustering without object-level learning tasks. 2) A knn-transformer module is proposed to model the interaction among foreground points for accurate offset regression. 3) For backbone design, we fuse the fine- grained voxel features and the 2D Bird's Eye View (BEV) features with different receptive fields to utilize both detailed and global information. Extensive experiments on both SemanticKITTI dataset and nuScenes dataset show that our Panoptic-PHNet sur-passes state-of-the-art methods by remarkable margins with a real-time speed. We achieve the 1st place on the public leaderboard of SemanticKITTI and leading performance on the recently released leaderboard of nuScenes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2165769778",
                    "name": "Jinke Li"
                },
                {
                    "authorId": "2165378483",
                    "name": "Xiao He"
                },
                {
                    "authorId": "2167854921",
                    "name": "Yang Wen"
                },
                {
                    "authorId": "2154877375",
                    "name": "Yuan Gao"
                },
                {
                    "authorId": "2149478558",
                    "name": "Xiaoqiang Cheng"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                }
            ]
        },
        {
            "paperId": "ae3d8af12b176d16961b53850c98d98449f9940e",
            "title": "Multi-level Distillation of Semantic Knowledge for Pre-training Multilingual Language Model",
            "abstract": "Pre-trained multilingual language models play an important role in cross-lingual natural language understanding tasks. However, existing methods did not focus on learning the semantic structure of representation, and thus could not optimize their performance. In this paper, we propose Multi-level Multilingual Knowledge Distillation (MMKD), a novel method for improving multilingual language models. Specifically, we employ a teacher-student framework to adopt rich semantic representation knowledge in English BERT. We propose token-, word-, sentence-, and structure-level alignment objectives to encourage multiple levels of consistency between source-target pairs and correlation similarity between teacher and student models. We conduct experiments on cross-lingual evaluation benchmarks including XNLI, PAWS-X, and XQuAD. Experimental results show that MMKD outperforms other baseline models of similar size on XNLI and XQuAD and obtains comparable performance on PAWS-X. Especially, MMKD obtains significant performance gains on low-resource languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139278032",
                    "name": "Mingqi Li"
                },
                {
                    "authorId": "2064424445",
                    "name": "Fei Ding"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2110463959",
                    "name": "Long Cheng"
                },
                {
                    "authorId": "7150554",
                    "name": "Hongxin Hu"
                },
                {
                    "authorId": "2140495064",
                    "name": "Feng Luo"
                }
            ]
        },
        {
            "paperId": "cafaf7b25d989f4ea9b47ddf13c5fc1b0236dd35",
            "title": "Semantics-aware Dataset Discovery from Data Lakes with Contextualized Column-based Representation Learning",
            "abstract": "Dataset discovery from data lakes is essential in many real application scenarios. In this paper, we propose Starmie, an end-to-end framework for dataset discovery from data lakes (with table union search as the main use case). Our proposed framework features a contrastive learning method to train column encoders from pre-trained language models in a fully unsupervised manner. The column encoder of Starmie captures the rich contextual semantic information within tables by leveraging a contrastive multi-column pre-training strategy. We utilize the cosine similarity between column embedding vectors as the column unionability score and propose a filter-and-verification framework that allows exploring a variety of design choices to compute the unionability score between two tables accordingly. Empirical results on real table benchmarks show that Starmie outperforms the best-known solutions in the effectiveness of table union search by 6.8 in MAP and recall. Moreover, Starmie is the first to employ the HNSW (Hierarchical Navigable Small World) index to accelerate query processing of table union search which provides a 3,000X performance gain over the linear scan baseline and a 400X performance gain over an LSH index (the state-of-the-art solution for data lake indexing).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1726027874",
                    "name": "Grace Fan"
                },
                {
                    "authorId": "2143720808",
                    "name": "Jin Wang"
                },
                {
                    "authorId": "47001493",
                    "name": "Yuliang Li"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2110417078",
                    "name": "Ren\u00e9e J. Miller"
                }
            ]
        },
        {
            "paperId": "dada26862a415e66fef6568754eb0eb8e908c40e",
            "title": "Annotating Columns with Pre-trained Language Models",
            "abstract": "Inferring meta information about tables, such as column headers or relationships between columns, is an active research topic in data management as we find many tables are missing some of this information. In this paper, we study the problem of annotating table columns (i.e., predicting column types and the relationships between columns) using only information from the table itself. We develop a multi-task learning framework (called Doduo) based on pre-trained language models, which takes the entire table as input and predicts column types/relations using a single model. Experimental results show that Doduo establishes new state-of-the-art performance on two benchmarks for the column type prediction and column relation prediction tasks with up to 4.0% and 11.9% improvements, respectively. We report that Doduo can already outperform the previous state-of-the-art performance with a minimal number of tokens, only 8 tokens per column. We release a toolbox (https://github.com/megagonlabs/doduo) and confirm the effectiveness of Doduo on a real-world data science problem through a case study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38844482",
                    "name": "Yoshihiko Suhara"
                },
                {
                    "authorId": "2144487468",
                    "name": "Jinfeng Li"
                },
                {
                    "authorId": "2111353540",
                    "name": "Yuliang Li"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "121365865",
                    "name": "cCaugatay Demiralp"
                },
                {
                    "authorId": "2127380138",
                    "name": "Chen Chen"
                },
                {
                    "authorId": "34582619",
                    "name": "W. Tan"
                }
            ]
        }
    ]
}