{
    "authorId": "48043042",
    "papers": [
        {
            "paperId": "0768a1f7de235fbf1e6ca2d2846d6c6a475b5e22",
            "title": "Applications of Feature Engineering Techniques for Text Data",
            "abstract": "Feature plays a very important role in the analysis and prediction of data as it carries the most valuable information about the data. This data may be in a structured format or in an unstructured format. Feature engineering process is used to extract features from these data. Selection of features is one of the crucial steps in the feature engineering process. This feature selection process can adopt four different approaches. On that basis, it can be classified into four basic categories, namely filter method, wrapper method, embedded method, and hybrid method. This chapter discusses about different techniques coming under these four categories along with the research work on feature selection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "6154191",
                    "name": "M. Panda"
                }
            ]
        },
        {
            "paperId": "ad0839ee019bc2873c5535aadcf1c50d5a0fff56",
            "title": "Machine Learning and Caching based Efficient Data Retrieval Framework",
            "abstract": "The explosive growth of wireless data and traffic, accompanied by the rapid advancements in intelligence and the processing power of user equipments (UEs), poses a very difficult challenge to the data providers to maintain the high data rate with sustainable quality-of-service (QoS). A lot of data can be saved by using caching based communication techniques, which would save the service providers a fortune and will make internet connectivity even more affordable. Also, there is room for saving bandwidth and using the limited number of servers and towers efficiently outputting a steadily healthy QoS. We propose an efficient data retrieval framework that uses caching based on the popularity of the pages where the popularity of pages is determined by the number of hits it gets over a month, which is the learning phase of the model and how frequently a given web page is requested. The proposed framework uses a causal decision tree in the background to determine the popularity of pages according to which the algorithm decides whether a given page is worthy of being cached or not. Results show that our proposed model outperforms the conventional data retrieval models in terms of cache missed probability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "2672514",
                    "name": "Rahul Bajpai"
                },
                {
                    "authorId": "1626077208",
                    "name": "Naveen Gupta"
                },
                {
                    "authorId": "3017441",
                    "name": "Vibhutesh Kumar Singh"
                }
            ]
        },
        {
            "paperId": "3d2d3ef92448594a650932be8bbb01f4dce74ff3",
            "title": "Artificial Intelligence in Medical Science",
            "abstract": "The use of intelligent artificial devices has solved many real-world problems and also improved the living style of human beings. The capability of providing unbiased and accurate result has also increased the demand for these devices. For getting faster and well-organized outcomes, scientists and researchers are giving more and more interest in developing such devices. Use of expert systems, concepts from nature-inspired algorithms, neural networks, genetic algorithms, fuzzy logic, internet of things are used extensively to solve various problems in science and engineering. In medical science these techniques are used for data analysis, disease diagnosis, data retrieval, object detection, pattern analysis, data management, monitoring patient health status by physicians, interactions between patients and physicians, keeping record of the medications of the patients, and so on. This chapter performs a detailed analysis on the use of intelligent devices in medical science and about the root concepts on which these devices are designed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "6154191",
                    "name": "M. Panda"
                }
            ]
        },
        {
            "paperId": "7c988be072ee07ef5a25774927bbed803eec6686",
            "title": "Medical Image Thresholding Using Genetic Algorithm and Fuzzy Membership Functions: A Comparative Study",
            "abstract": "Thresholding is one of the important steps in image analysis process and used extensively in different image processing techniques. Medical image segmentation plays a very important role in surgery planning, identification of tumours, diagnosis of organs, etc. In this article, a novel approach for medical image segmentation is proposed using a hybrid technique of genetic algorithm and fuzzy logic. Fuzzy logic can handle uncertain and imprecise information. Genetic algorithms help in global optimization, gives good results in noisy environments and supports multi-objective optimization. Gaussian, trapezoidal and triangular membership functions are used separately for calculating the entropy and finding the fitness value. CPU time, Root Mean Square Error, sensitivity, specificity, and accuracy are calculated using the three membership functions separately at threshold levels 2, 3, 4, 5, 7 and 9. MRI images are considered for applying the proposed method and the results are analysed. The experimental results obtained prove the effectiveness and efficiency of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "6154191",
                    "name": "M. Panda"
                }
            ]
        },
        {
            "paperId": "19a737df9955f8f4d07e661bfa466338db2adc05",
            "title": "Selection of an Efficient Image Classifier-A Critical Analysis",
            "abstract": "The most important part of image analysis is classification which helps in grouping the pixels in an image into different categories on the basis of their information content. Classification concept which was originated from pattern recognition field has a widespread application in satellite image analysis and medical diagnosis. Classification also helps in reducing the search time by grouping same type of images, so that, the searching operation can be conducted on the specific group of images instead of searching all the images. On the basis of parameters used for classification, the image classification techniques can be divided into different types. A large number of studies have been conducted for classifying images using different types of classification algorithms. The aim of this paper is to perform a detailed review of the classification algorithms and do a comparative study of the work done by the researchers on image classification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "6154191",
                    "name": "M. Panda"
                }
            ]
        },
        {
            "paperId": "58624a3e0651b891c6a976c2e0f49488c3dc27d2",
            "title": "Testing Interestingness Measures in Practice: A Large-Scale Analysis of Buying Patterns",
            "abstract": "Understanding customer buying patterns is of great interest to the retail industry. Association rule mining is a common technique for extracting correlations such as people in the South of France buy ros\u00e9 wine or customers who buy pat\u00e9 also buy salted butter and sour bread. Unfortunately, sifting through a high number of buying patterns is not useful in practice, because of the predominance of popular products in the top rules. As a result, a number of \"interestingness\" measures (over 30) have been proposed to rank rules. However, there is no agreement on which measures are more appropriate for retail data. Moreover, since pattern mining algorithms output thousands of association rules for each product, the ability for an analyst to rely on ranking measures to identify the most interesting ones is crucial. In this paper, we develop CAPA (Comparative Analysis of PAtterns), a framework that provides analysts with the ability to compare different rule rankings. We report on how we used C A PA to compare 34 interestingness measures applied to patterns extracted from customer receipts of more than 1,800 stores for a period of one year.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3359814",
                    "name": "M. Kirchgessner"
                },
                {
                    "authorId": "2067225211",
                    "name": "V. Leroy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                }
            ]
        },
        {
            "paperId": "ba279f97a3d097ed8f4b1a39835b487b6b03f7ab",
            "title": "Discovering characterizing regions for consumer products",
            "abstract": "Consumer behaviour holds special importance in the retail industry. Consumer location impacts consumer behaviour by dictating purchase trends. This paper investigates the problem of examining product sales across a chain of stores to extract the geographic regions that characterize a product. Characterizing region for a product is a coherent geographic region where the consumers actively consume the said product. We introduce DICE, a diffusion-based technique to uncover all such regions for a given product, when they exist. In contrast to current state of the art, DICE involves minimal usage of parameters and shows remarkable tolerance to noise. We present experiments conducted on real datasets from a general commercial supermarket in France. Empirical evaluation and user-studies establish that the presented method significantly outperforms its natural baseline and previous state of the art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "2067225211",
                    "name": "V. Leroy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "3a843456bc151c5d5e4eb48750e4cfa8f9c2fd83",
            "title": "State-of-the-art in string similarity search and join",
            "abstract": "String similarity search and its variants are fundamental problems with many applications in areas such as data integration, data quality, computational linguistics, or bioinformatics. A plethora of methods have been developed over the last decades. Obtaining an overview of the state-of-the-art in this field is difficult, as results are published in various domains without much cross-talk, papers use different data sets and often study subtle variations of the core problems, and the sheer number of proposed methods exceeds the capacity of a single research group. In this paper, we report on the results of the probably largest benchmark ever performed in this field. To overcome the resource bottleneck, we organized the benchmark as an international competition, a workshop at EDBT/ICDT 2013. Various teams from different fields and from all over the world developed or tuned programs for two crisply defined problems. All algorithms were evaluated by an external group on two machines. Altogether, we compared 14 different programs on two string matching problems (k-approximate search and k-approximate join) using data sets of increasing sizes and with different characteristics from two different domains. We compare programs primarily by wall clock time, but also provide results on memory usage, indexing time, batch query effects and scalability in terms of CPU cores. Results were averaged over several runs and confirmed on a second, different hardware platform. A particularly interesting observation is that disciplines can and should learn more from each other, with the three best teams rooting in computational linguistics, databases, and bioinformatics, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1680551",
                    "name": "S. Wandelt"
                },
                {
                    "authorId": "51478403",
                    "name": "D. Deng"
                },
                {
                    "authorId": "1970637",
                    "name": "Stefan Gerdjikov"
                },
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "2918327",
                    "name": "Petar Mitankin"
                },
                {
                    "authorId": "39794417",
                    "name": "Manish Patil"
                },
                {
                    "authorId": "2781554",
                    "name": "Enrico Siragusa"
                },
                {
                    "authorId": "1835401",
                    "name": "A. Tiskin"
                },
                {
                    "authorId": "2158505980",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "2110271768",
                    "name": "Jiaying Wang"
                },
                {
                    "authorId": "1693022",
                    "name": "U. Leser"
                }
            ]
        },
        {
            "paperId": "db25263b74d61e77916dc7af8a17acfd9d2effdb",
            "title": "Towards automated selection of data fusion techniques",
            "abstract": "An investigation of multi-modal fusion schemes is done using synthetic data generation to determine how the data characteristics influence fusion. The goal is to select the best fusion scheme using data characteristics. Preliminary results are presented here that compare data concatenation to Kernel fusion in the presence of increasing dimensionality, linear/nonlinear decision boundaries and correlations between different modality features. It is found that data concatenation is better than Kernel fusion in low dimensions in general. It is also found that Kernel fusion is better than data concatenation when the optimal decision boundary is non-linear, and the dimensions are high. Correlations between modalities determine the information content, and Kernel fusion reduces the information content most when there is negative correlation between modalities. These results are applied to fingerprint live-ness detection on the ATVS database having three sensor modalities. As there are few features used per modality and the overall dimensionality is low, it is expected and confirmed that data concatenation is better than Kernel fusion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2202489",
                    "name": "K. Venkataramani"
                },
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "2052743748",
                    "name": "Lovish Kumar"
                }
            ]
        },
        {
            "paperId": "dd9e7899b4926ece84a3dc67fba93b4662e66168",
            "title": "Efficient edit distance based string similarity search using deletion neighborhoods",
            "abstract": "This paper serves as a report for the participation of Special Interest Group In Data (SIGDATA), Indian Institute of Technology, Kanpur in the String Similarity Workshop, EDBT, 2013. We present a novel technique to efficiently process edit distance based string similarity queries. Our technique draws upon some previously conducted works in the field and introduces new methods to tackle the issues therein. We focus on achieving minimum possible execution time while being rather liberal with memory consumption. We propose and support the use of deletion neighborhoods for fast edit distance lookups in dictionaries. Our work emphasizes the power of deletion neighborhoods over other popular finger print based schemes for similarity search queries. Furthermore, we establish that it is possible to reduce the large space requirement of a deletion neighborhood based finger print scheme using simple hashing techniques, thereby making the scheme suitable for practical application. We compare our implementation with the state of the art libraries (Flamingo) and report speed ups of up to an order of magnitude.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "2067222550",
                    "name": "Tejas Gandhi"
                },
                {
                    "authorId": "2644814",
                    "name": "Akhil Arora"
                },
                {
                    "authorId": "145660316",
                    "name": "Arnab Bhattacharya"
                }
            ]
        },
        {
            "paperId": "31f2bd8c0fdb68049e9ff3a12181710dda6e5af8",
            "title": "A Plant Identification System using Shape and Morphological Features on Segmented Leaflets: Team IITK, CLEF 2012",
            "abstract": "Automatic plant identification tasks have witnessed increased interest from the machine learning community in recent years. This paper describes our (team IITK\u2019s) participation in the Plant Identification Task, CLEF 2012, organized by the Combined Lab Evaluation Forum (CLEF) where the challenge was to identify plant species based on leaf images. We first categorize the different types of images and then use a variety of novel preprocessing methods such as shadow and background correction, petiole removal and automatic leaflet segmentation for identifying the leaf blobs. We next use complex network framework along with novel tooth detection method and morphological operations to compute several useful features. Finally, we use a random forest for classification. Based on the proposed approach, we achieved 2 rank on the overall score in the competition.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2644814",
                    "name": "Akhil Arora"
                },
                {
                    "authorId": "2110759914",
                    "name": "Ankit Gupta"
                },
                {
                    "authorId": "2038355",
                    "name": "Nitesh Bagmar"
                },
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "145660316",
                    "name": "Arnab Bhattacharya"
                }
            ]
        },
        {
            "paperId": "bfed2accc28801fe26123974db1639eeb43c9041",
            "title": "The eighth annual MLSP competition: First place team",
            "abstract": "Our basic strategy is to examine the spatial neighborhood of the point, P, for its classification. Each point Q in P's neighborhood contributes a binary vote. The sum of these votes, VP, is compared against a threshold \u03c4 and access is granted if the value VP is greater than the threshold.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110761108",
                    "name": "Ankit Gupta"
                },
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "144997426",
                    "name": "A. Mukerjee"
                }
            ]
        },
        {
            "paperId": "8af761d9d75c9ec30bfd7bc10a9823a775f2c352",
            "title": "Similarity Consideration for Visualization and Manifold Geometry Preservation",
            "abstract": "Manifold learning techniques are used to preserve the original geometry of dataset after reduction by preserving the distance among data points. MDS (Multidimensional Scaling), ISOMAP (Isometric Feature Mapping), LLE (Locally Linear Embedding) are some of the geometrical structure preserving dimension reduction methods. In this paper, we have compared MDS and ISOMAP and considered similarity as an approach to find the reduced representation of original data using ISOMAP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                },
                {
                    "authorId": "6181894",
                    "name": "Chittaranjan Pradhan"
                }
            ]
        },
        {
            "paperId": "ae95208264ca5280c2ddd5bbf16f51ea80ee85ab",
            "title": "Optimized ISOMAP algorithm using similarity matrix",
            "abstract": "Dimension reduction techniques are used to obtain a reduced representation of the data that maintains the integrity of the original data. ISOMAP (Isometric Feature Mapping) is one of the dimension reduction techniques, which is a nonlinear generalization of Classical MDS (Multi-Dimensional Scaling) and works well both for real world and artificial data. It uses k-nearest neighbors concept for creating the neighborhood graph. In this paper, we have considered the similarity among data points as another approach for constructing the neighborhood graph, instead of using the concept of k-nearest neighbors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6181894",
                    "name": "Chittaranjan Pradhan"
                },
                {
                    "authorId": "48043042",
                    "name": "Shashwati Mishra"
                }
            ]
        }
    ]
}