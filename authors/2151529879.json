{
    "authorId": "2151529879",
    "papers": [
        {
            "paperId": "7252b2d01aa5e47d8ae22a8d231af3bdf16bae57",
            "title": "Tutorial on Large Language Models for Recommendation",
            "abstract": "Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, by formulating various recommendation tasks such as rating prediction, sequential recommendation, straightforward recommendation, and explanation generation into language instructions, LLMs make it possible to build universal recommendation engines that can handle different recommendation tasks. Additionally, LLMs have a remarkable capacity for understanding natural language, enabling them to comprehend user preferences, item descriptions, and contextual information to generate more accurate and relevant recommendations, leading to improved user satisfaction and engagement. This tutorial introduces Foundation Models such as LLMs for recommendation. We will introduce how recommender system advanced from shallow models to deep models and to large models, how LLMs enable generative recommendation in contrast to traditional discriminative recommendation, and how to build LLM-based recommender systems. We will cover multiple perspectives of LLM-based recommendation, including data preparation, model design, model pre-training, fine-tuning and prompting, multi-modality and multi-task learning, as well as trustworthy perspectives of LLM-based recommender systems such as fairness and transparency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007245028",
                    "name": "Wenyue Hua"
                },
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "152875291",
                    "name": "L. Chen"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "9e540662619327a3056d9e40bb58058868f6f805",
            "title": "Prompt Distillation for Efficient LLM-based Recommendation",
            "abstract": "Large language models (LLM) have manifested unparalleled modeling capability on various tasks, e.g., multi-step reasoning, but the input to these models is mostly limited to plain text, which could be very long and contain noisy information. Long text could take long time to process, and thus may not be efficient enough for recommender systems that require immediate response. In LLM-based recommendation models, user and item IDs are usually filled in a template (i.e., discrete prompt) to allow the models to understand a given task, but the models usually need extensive fine-tuning to bridge the user/item IDs and the template words and to unleash the power of LLM for recommendation. To address the problems, we propose to distill the discrete prompt for a specific task to a set of continuous prompt vectors so as to bridge IDs and words and to reduce the inference time. We also design a training strategy with an attempt to improve the efficiency of training these models. Experimental results on three real-world datasets demonstrate the effectiveness of our PrOmpt Distillation (POD) approach on both sequential recommendation and top-N recommendation tasks. Although the training efficiency can be significantly improved, the improvement of inference efficiency is limited. This finding may inspire researchers in the community to further improve the inference efficiency of LLM-based recommendation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2260830380",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2146027242",
                    "name": "Li Chen"
                }
            ]
        },
        {
            "paperId": "a1081c6fc6921d6b76d9ebda4d712333fd7bbbf5",
            "title": "Large Language Models for Generative Recommendation: A Survey and Visionary Discussions",
            "abstract": "Large language models (LLM) not only have revolutionized the field of natural language processing (NLP) but also have the potential to reshape many other fields, e.g., recommender systems (RS). However, most of the related work treats an LLM as a component of the conventional recommendation pipeline (e.g., as a feature extractor), which may not be able to fully leverage the generative power of LLM. Instead of separating the recommendation process into multiple stages, such as score computation and re-ranking, this process can be simplified to one stage with LLM: directly generating recommendations from the complete pool of items. This survey reviews the progress, methods, and future directions of LLM-based generative recommendation by examining three questions: 1) What generative recommendation is, 2) Why RS should advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS tasks. We hope that this survey can provide the context and guidance needed to explore this interesting and emerging topic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2237956346",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "152875291",
                    "name": "L. Chen"
                }
            ]
        },
        {
            "paperId": "122d11444321635f3e6fa375aaf31bbd932c3116",
            "title": "Effects of Feature-Based Explanation and Its Output Modality on User Satisfaction With Service Recommender Systems",
            "abstract": "Recent advances in natural language based virtual assistants have attracted more researches on application of recommender systems (RS) into the service product domain (e.g., looking for a restaurant or a hotel), given that RS can assist users in more effectively obtaining information. However, though there is emerging study on how the presentation of recommendation (vocal vs. visual) would affect user experiences with RS, little attention has been paid to how the output modality of its explanation (i.e., explaining why a particular item is recommended) interacts with the explanation content to influence user satisfaction. In this work, we particularly consider feature-based explanation, a popular type of explanation that aims to reveal how relevant a recommendation is to the user in terms of its features (e.g., a restaurant's food quality, service, distance, or price), for which we have concretely examined three content design factors as summarized from the literature survey: feature type, contextual relevance, and number of features. Results of our user studies show that, for explanation presented in different modalities (text and voice), the effects of those design factors on user satisfaction with RS are different. Specifically, for text explanations, the number of features and contextual relevance influenced users' satisfaction with the recommender system, but the feature type did not; while for voice explanations, we found no factors influenced user satisfaction. We finally discuss the practical implications of those findings and possible directions for future research.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116763479",
                    "name": "Zhirun Zhang"
                },
                {
                    "authorId": "2146027242",
                    "name": "Li Chen"
                },
                {
                    "authorId": "17594018",
                    "name": "Tonglin Jiang"
                },
                {
                    "authorId": "2110420629",
                    "name": "Yutong Li"
                },
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "28d25de2e57c0ea5a99355ec7e0646385e8727d6",
            "title": "Improving Personalized Explanation Generation through Visualization",
            "abstract": "In modern recommender systems, there are usually comments or reviews from users that justify their ratings for different items. Trained on such textual corpus, explainable recommendation models learn to discover user interests and generate personalized explanations. Though able to provide plausible explanations, existing models tend to generate repeated sentences for different items or empty sentences with insufficient details. This begs an interesting question: can we immerse the models in a multimodal environment to gain proper awareness of real-world concepts and alleviate above shortcomings? To this end, we propose a visually-enhanced approach named METER with the help of visualization generation and text\u2013image matching discrimination: the explainable recommendation model is encouraged to visualize what it refers to while incurring a penalty if the visualization is incongruent with the textual explanation. Experimental results and a manual assessment demonstrate that our approach can improve not only the text quality but also the diversity and explainability of the generated explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1947101",
                    "name": "Shijie Geng"
                },
                {
                    "authorId": "2011378",
                    "name": "Zuohui Fu"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "1591136873",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "8498daeeb893870524ffaa63086f8528795003d4",
            "title": "Personalized Prompt Learning for Explainable Recommendation",
            "abstract": "Providing user-understandable explanations to justify recommendations could help users better understand the recommended items, increase the system\u2019s ease of use, and gain users\u2019 trust. A typical approach to realize it is natural language generation. However, previous works mostly adopt recurrent neural networks to meet the ends, leaving the potentially more effective pre-trained Transformer models under-explored. In fact, user and item IDs, as important identifiers in recommender systems, are inherently in different semantic space as words that pre-trained models were already trained on. Thus, how to effectively fuse IDs into such models becomes a critical issue. Inspired by recent advancement in prompt learning, we come up with two solutions: find alternative words to represent IDs (called discrete prompt learning) and directly input ID vectors to a pre-trained model (termed continuous prompt learning). In the latter case, ID vectors are randomly initialized but the model is trained in advance on large corpora, so they are actually in different learning stages. To bridge the gap, we further propose two training strategies: sequential tuning and recommendation as regularization. Extensive experiments show that our continuous prompt learning approach equipped with the training strategies consistently outperforms strong baselines on three datasets of explainable recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "1591136873",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2146027242",
                    "name": "Li Chen"
                }
            ]
        },
        {
            "paperId": "0c9a2adda11ed49d091948211fcfd517113b5243",
            "title": "Personalized Transformer for Explainable Recommendation",
            "abstract": "Personalization of natural language generation plays a vital role in a large spectrum of tasks, such as explainable recommendation, review summarization and dialog systems. In these tasks, user and item IDs are important identifiers for personalization. Transformer, which is demonstrated with strong language modeling capability, however, is not personalized and fails to make use of the user and item IDs since the ID tokens are not even in the same semantic space as the words. To address this problem, we present a PErsonalized Transformer for Explainable Recommendation (PETER), on which we design a simple and effective learning objective that utilizes the IDs to predict the words in the target explanation, so as to endow the IDs with linguistic meanings and to achieve personalized Transformer. Besides generating explanations, PETER can also make recommendations, which makes it a unified model for the whole recommendation-explanation pipeline. Extensive experiments show that our small unpretrained model outperforms fine-tuned BERT on the generation task, in terms of both effectiveness and efficiency, which highlights the importance and the nice utility of our design.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "1591136873",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2146027242",
                    "name": "Li Chen"
                }
            ]
        },
        {
            "paperId": "3df06e5882eb10ee9ddee211c9ebc1ac2a067586",
            "title": "Learning Recommendation Algorithm Based on Improved BP Neural Network in Music Marketing Strategy",
            "abstract": "The growth and popularity of streaming music have changed the way people consume music, and users can listen to online music anytime and anywhere. By integrating various recommendation algorithms/strategies (user profiling, collaborative filtering, content filtering, etc.), we capture users' interests and preferences and recommend the content of interest to them. To address the sparsity of behavioral data in digital music marketing, which leads to inadequate mining of user music preference features, a metric ranking learning recommendation algorithm with fused content representation is proposed. Relative partial order relations are constructed using observed and unobserved behavioral data to enable the model to be fully trained, while audio feature extraction submodels related to the recommendation task are constructed to further alleviate the data sparsity problem, and finally, the preference relationships between users and songs are mined through metric learning. Convolutional neural networks are used to extract the high-level semantic features of songs, and then the high-level semantic features of songs extracted from the previous layer are reformed into a session time sequence list according to the time sequence of user listening in order to build a bidirectional recurrent neural network model based on the attention mechanism so that it can reduce the influence of noisy data and learn the strong dependencies between songs.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "a9824e94ff9ab60a5ef276b9fdc6bca4b04a7f70",
            "title": "On the Relationship between Explanation and Recommendation: Learning to Rank Explanations for Improved Performance",
            "abstract": "Explaining to users why some items are recommended is critical, as it can help users to make better decisions, increase their satisfaction, and gain their trust in recommender systems (RS). However, existing explainable RS usually consider explanation as a side output of the recommendation model, which has two problems: (1) It is difficult to evaluate the produced explanations, because they are usually model-dependent, and (2) as a result, how the explanations impact the recommendation performance is less investigated. In this article, explaining recommendations is formulated as a ranking task and learned from data, similarly to item ranking for recommendation. This makes it possible for standard evaluation of explanations via ranking metrics (e.g., Normalized Discounted Cumulative Gain). Furthermore, this article extends traditional item ranking to an item\u2013explanation joint-ranking formalization to study if purposely selecting explanations could reach certain learning goals, e.g., improving recommendation performance. A great challenge, however, is that the sparsity issue in the user-item-explanation data would be inevitably severer than that in traditional user\u2013item interaction data, since not every user\u2013item pair can be associated with all explanations. To mitigate this issue, this article proposes to perform two sets of matrix factorization by considering the ternary relationship as two groups of binary relationships. Experiments on three large datasets verify the solution\u2019s effectiveness on both explanation ranking and item recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "1591136873",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2146027242",
                    "name": "Li Chen"
                }
            ]
        },
        {
            "paperId": "0f9060c32ea8c1f52c4b1266df1818b968eb7ea9",
            "title": "Towards Controllable Explanation Generation for Recommender Systems via Neural Template",
            "abstract": "It has been commonly agreed that the explanation associated with recommendation can be effective in increasing the recommender systems (RS)\u2019s transparency and thus users\u2019 satisfaction and acceptance. Among the various types of explanation in RS, the commonly used textual explanation can be roughly classified into two categories, i.e., template-based and generation-based. As for the former, the fixed template may lose flexibility, while, though the latter may enrich the explanation, it may produce less useful content due to the lack of controllability. In this work, we combine the advantages of the two types of method by developing a neural generation approach named Neural Template (NETE) whose explanations are not only flexible but also controllable and useful. Our human evaluation results confirm that the explanations from our model are perceived helpful by users. Furthermore, our case study illustrates that the explanation generation process is controllable. To demonstrate the controllability of our model, we present a demo that can be easily viewed on a Web browser.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151529879",
                    "name": "Lei Li"
                },
                {
                    "authorId": "152875291",
                    "name": "L. Chen"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                }
            ]
        }
    ]
}