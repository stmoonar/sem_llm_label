{
    "authorId": "2153095583",
    "papers": [
        {
            "paperId": "cd200572cb6ef882b8dd9fcf5632f703820b5bc4",
            "title": "User-Controllable Recommendation via Counterfactual Retrospective and Prospective Explanations",
            "abstract": "Modern recommender systems utilize users' historical behaviors to generate personalized recommendations. However, these systems often lack user controllability, leading to diminished user satisfaction and trust in the systems. Acknowledging the recent advancements in explainable recommender systems that enhance users' understanding of recommendation mechanisms, we propose leveraging these advancements to improve user controllability. In this paper, we present a user-controllable recommender system that seamlessly integrates explainability and controllability within a unified framework. By providing both retrospective and prospective explanations through counterfactual reasoning, users can customize their control over the system by interacting with these explanations. Furthermore, we introduce and assess two attributes of controllability in recommendation systems: the complexity of controllability and the accuracy of controllability. Experimental evaluations on MovieLens and Yelp datasets substantiate the effectiveness of our proposed framework. Additionally, our experiments demonstrate that offering users control options can potentially enhance recommendation accuracy in the future. Source code and data are available at \\url{https://github.com/chrisjtan/ucr}.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "33642939",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "20f83c85fb694a77ff8050699e2f85aa68f1b5f4",
            "title": "RawlsGCN: Towards Rawlsian Difference Principle on Graph Convolutional Network",
            "abstract": "Graph Convolutional Network (GCN) plays pivotal roles in many real-world applications. Despite the successes of GCN deployment, GCN often exhibits performance disparity with respect to node degrees, resulting in worse predictive accuracy for low-degree nodes. We formulate the problem of mitigating the degree-related performance disparity in GCN from the perspective of the Rawlsian difference principle, which is originated from the theory of distributive justice. Mathematically, we aim to balance the utility between low-degree nodes and high-degree nodes while minimizing the task-specific loss. Specifically, we reveal the root cause of this degree-related unfairness by analyzing the gradients of weight matrices in GCN. Guided by the gradients of weight matrices, we further propose a pre-processing method RawlsGCN-Graph and an in-processing method RawlsGCN-Grad that achieves fair predictive accuracy in low-degree nodes without modification on the GCN architecture or introduction of additional parameters. Extensive experiments on real-world graphs demonstrate the effectiveness of our proposed RawlsGCN methods in significantly reducing degree-related bias while retaining comparable overall performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "2116782926",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "8dd0727601d40d437a182f05548da563ac60d4b3",
            "title": "Explainable Fairness in Recommendation",
            "abstract": "Existing research on fairness-aware recommendation has mainly focused on the quantification of fairness and the development of fair recommendation models, neither of which studies a more substantial problem--identifying the underlying reason of model disparity in recommendation. This information is critical for recommender system designers to understand the intrinsic recommendation mechanism and provides insights on how to improve model fairness to decision makers. Fortunately, with the rapid development of Explainable AI, we can use model explainability to gain insights into model (un)fairness. In this paper, we study the problem ofexplainable fairness, which helps to gain insights about why a system is fair or unfair, and guides the design of fair recommender systems with a more informed and unified methodology. Particularly, we focus on a common setting with feature-aware recommendation and exposure unfairness, but the proposed explainable fairness framework is general and can be applied to other recommendation settings and fairness definitions. We propose a Counterfactual Explainable Fairness framework, called CEF, which generates explanations about model fairness that can improve the fairness without significantly hurting the performance. The CEF framework formulates an optimization problem to learn the \"minimal'' change of the input features that changes the recommendation results to a certain level of fairness. Based on the counterfactual recommendation result of each feature, we calculate an explainability score in terms of the fairness-utility trade-off to rank all the feature-based explanations, and select the top ones as fairness explanations. Experimental results on several real-world datasets validate that our method is able to effectively provide explanations to the model disparities and these explanations can achieve better fairness-utility trade-off when using them for recommendation than all the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "2116783457",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2011378",
                    "name": "Zuohui Fu"
                },
                {
                    "authorId": "1947101",
                    "name": "Shijie Geng"
                },
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "e71744732ba270ebb2ce77ef647768ebc82e5b5f",
            "title": "A Structured Graph Attention Network for Vehicle Re-Identification",
            "abstract": "Vehicle re-identification aims to identify the same vehicle across different surveillance cameras and plays an important role in public security. Existing approaches mainly focus on exploring informative regions or learning an appropriate distance metric. However, they not only neglect the inherent structured relationship between discriminative regions within an image, but also ignore the extrinsic structured relationship among images. The inherent and extrinsic structured relationships are crucial to learning effective vehicle representation. In this paper, we propose a Structured Graph ATtention network (SGAT) to fully exploit these relationships and allow the message propagation to update the features of graph nodes. SGAT creates two graphs for one probe image. One is an inherent structured graph based on the geometric relationship between the landmarks that can use features of their neighbors to enhance themselves. The other is an extrinsic structured graph guided by the attribute similarity to update image representations. Experimental results on two public vehicle re-identification datasets including VeRi-776 and VehicleID have shown that our proposed method achieves significant improvements over the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "143962510",
                    "name": "Zhengjun Zha"
                },
                {
                    "authorId": "2146331327",
                    "name": "Tianzhu Zhang"
                },
                {
                    "authorId": "1471355792",
                    "name": "Jiawei Liu"
                },
                {
                    "authorId": "33642939",
                    "name": "Jiebo Luo"
                }
            ]
        },
        {
            "paperId": "18b5035d5139634741e1435327958752f114a754",
            "title": "Utilizing High-level Visual Feature for Indoor Shopping Mall Navigation",
            "abstract": "Towards robust and convenient indoor shopping mall navigation, we propose a novel learning-based scheme to utilize the high-level visual information from the storefront images captured by personal devices of users. Specifically, we decompose the visual navigation problem into localization and map generation respectively. Given a storefront input image, a novel feature fusion scheme (denoted as FusionNet) is proposed by fusing the distinguishing DNN-based appearance feature and text feature for robust recognition of store brands, which serves for accurate localization. Regarding the map generation, we convert the user-captured indicator map of the shopping mall into a topological map by parsing the stores and their connectivity. Experimental results conducted on the real shopping malls demonstrate that the proposed system achieves robust localization and precise map generation, enabling accurate navigation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390848082",
                    "name": "Ziwei Xu"
                },
                {
                    "authorId": "2743695",
                    "name": "Haitian Zheng"
                },
                {
                    "authorId": "7623748",
                    "name": "Minjian Pang"
                },
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "38759990",
                    "name": "Xiongfei Su"
                },
                {
                    "authorId": "2169844",
                    "name": "Guyue Zhou"
                },
                {
                    "authorId": "2153679942",
                    "name": "Lu Fang"
                }
            ]
        }
    ]
}