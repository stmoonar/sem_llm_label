{
    "authorId": "2275146214",
    "papers": [
        {
            "paperId": "43655d9068c477899df8cf6533ab7d8d94d19317",
            "title": "Grounding From an AI and Cognitive Science Lens",
            "abstract": "Grounding is a challenging problem, requiring a formal definition and different levels of abstraction. This article explores grounding from both cognitive science and machine learning perspectives. It identifies the subtleties of grounding, its significance for collaborative agents, and similarities and differences in grounding approaches in both communities. The article examines the potential of neurosymbolic approaches tailored for grounding tasks, showcasing how they can more comprehensively address grounding. Finally, we discuss areas for further exploration and development in grounding.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27549522",
                    "name": "Goonmeet Bajaj"
                },
                {
                    "authorId": "2890773",
                    "name": "V. Shalin"
                },
                {
                    "authorId": "2275282544",
                    "name": "Srinivasan Parthasarathy"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                }
            ]
        },
        {
            "paperId": "8cb4464b83a3fcfc235f213f295155f6afef8a17",
            "title": "Causal Neurosymbolic AI: A Synergy Between Causality and Neurosymbolic Methods",
            "abstract": "Causal neurosymbolic AI (NeSyAI) combines the benefits of causality with NeSyAI. More specifically, it 1) enriches NeSyAI systems with explicit representations of causality, 2) integrates causal knowledge with domain knowledge, and 3) enables the use of NeSyAI techniques for causal AI tasks. The explicit causal representation yields insights that predictive models may fail to analyze from observational data. It can also assist people in decision-making scenarios where discerning the cause of an outcome is necessary to choose among various interventions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47247243",
                    "name": "Utkarshani Jaimini"
                },
                {
                    "authorId": "2287579718",
                    "name": "Cory Henson"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                }
            ]
        },
        {
            "paperId": "a96979e00c5f7ebf8acd8e9ad81837f8a409d9e5",
            "title": "The EMPWR Platform: Data and Knowledge-Driven Processes for the Knowledge Graph Lifecycle",
            "abstract": "The unparalleled volume of data generated has heightened the need for approaches that can consume these data in a scalable and automated fashion. Although modern data-driven, deep-learning-based systems are cost-efficient and can learn complex patterns, they are black boxes in nature, and the underlying input data highly dictate their world model. Knowledge graphs (KGs), as one such technology, have surfaced as a compelling approach for using structured knowledge representation to support the integration of knowledge from diverse sources and formats. We present Empower (EMPWR), a comprehensive KG development and lifecycle support platform that uses a broad variety of techniques from symbolic and modern data-driven systems. We discuss the sets of system design guiding principles used to develop EMPWR, its system architectures, and workflow components. We illustrate some of EMPWR\u2019s abilities by describing a process of creating and maintaining a KG for the pharmaceuticals domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                }
            ]
        },
        {
            "paperId": "6ed5dc34a666ad41961dc101cbd785504fa893c8",
            "title": "A Cross Attention Approach to Diagnostic Explainability using Clinical Practice Guidelines for Depression",
            "abstract": "The lack of explainability using relevant clinical knowledge hinders the adoption of Artificial Intelligence-powered analysis of unstructured clinical dialogue. A wealth of relevant, untapped Mental Health (MH) data is available in online communities, providing the opportunity to address the explainability problem with substantial potential impact as a screening tool for both online and offline applications. We develop a method to enhance attention in popular transformer models and generate clinician-understandable explanations for classification by incorporating external clinical knowledge. Inspired by how clinicians rely on their expertise when interacting with patients, we leverage relevant clinical knowledge to model patient inputs, providing meaningful explanations for classification. This will save manual review time and engender trust. We develop such a system in the context of MH using clinical practice guidelines (CPG) for diagnosing depression, a mental health disorder of global concern. We propose an application-specific language model called ProcesS knowledge-infused cross ATtention (PSAT), which incorporates CPGs when computing attention. Through rigorous evaluation on three expert-curated datasets related to depression, we demonstrate application-relevant explainability of PSAT. PSAT also surpasses the performance of nine baseline models and can provide explanations where other baselines fall short. We transform a CPG resource focused on depression, such as the Patient Health Questionnaire (e.g. PHQ-9) and related questions, into a machine-readable ontology using SNOMED-CT. With this resource, PSAT enhances the ability of models like GPT-3.5 to generate application-relevant explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "100859747",
                    "name": "Sumit Dalal"
                },
                {
                    "authorId": "2141126407",
                    "name": "Deepa Tilwani"
                },
                {
                    "authorId": "2279836595",
                    "name": "Manas Gaur"
                },
                {
                    "authorId": "2264556136",
                    "name": "Sarika Jain"
                },
                {
                    "authorId": "2890773",
                    "name": "V. Shalin"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                }
            ]
        }
    ]
}