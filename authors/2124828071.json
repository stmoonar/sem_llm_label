{
    "authorId": "2124828071",
    "papers": [
        {
            "paperId": "128f1136077469f2929a1b09dcc8d8bf5d5508e8",
            "title": "Text2Layer: Layered Image Generation using Latent Diffusion Model",
            "abstract": "Layer compositing is one of the most popular image editing workflows among both amateurs and professionals. Motivated by the success of diffusion models, we explore layer compositing from a layered image generation perspective. Instead of generating an image, we propose to generate background, foreground, layer mask, and the composed image simultaneously. To achieve layered image generation, we train an autoencoder that is able to reconstruct layered images and train diffusion models on the latent representation. One benefit of the proposed problem is to enable better compositing workflows in addition to the high-quality image output. Another benefit is producing higher-quality layer masks compared to masks produced by a separate step of image segmentation. Experimental results show that the proposed method is able to generate high-quality layered images and initiates a benchmark for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "29367810",
                    "name": "Wentian Zhao"
                },
                {
                    "authorId": "2124828071",
                    "name": "Xin Lu"
                },
                {
                    "authorId": "2065529439",
                    "name": "J. Chien"
                }
            ]
        }
    ]
}