{
    "authorId": "2153832",
    "papers": [
        {
            "paperId": "005874a9d2a8fedac1756da3ccfcdbde4bbbf8d2",
            "title": "Turning Databases Into Generative AI Machines",
            "abstract": "Data is no more the commodity oil. Today, it is an asset for any enterprise. However, turning data into intelligence remains a challenge for most people. In this paper, we explore whether databases can be turned into generative AI machines that can talk to anyone. We identify three core challenges when applying generative AI on data, namely accuracy, scale, and privacy, and show how a generative large data model could solve all of these. We describe our conceptual framework of generative AI on databases, the GOD machine , and ground it in production workloads at SmartApps. Our results promise new directions in fusing AI with data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "2238572802",
                    "name": "Shi Qiao"
                },
                {
                    "authorId": "2277564395",
                    "name": "Sathwik Reddy Madhula"
                },
                {
                    "authorId": "2277564705",
                    "name": "Kanupriya Raheja"
                },
                {
                    "authorId": "2277599291",
                    "name": "Sandhya Jain"
                }
            ]
        },
        {
            "paperId": "cfd55aeec363d9e0c29b127aa8c0fc8bfbb24085",
            "title": "Sibyl: Forecasting Time-Evolving Query Workloads",
            "abstract": "Database systems often rely on historical query traces to perform workload-based performance tuning. However, real production workloads are time-evolving, making historical queries ineffective for optimizing future workloads. To address this challenge, we propose SIBYL, an end-to-end machine learning-based framework that accurately forecasts a sequence of future queries, with the entire query statements, in various prediction windows. Drawing insights from real-workloads, we propose template-based featurization techniques and develop a stacked-LSTM with an encoder-decoder architecture for accurate forecasting of query workloads. We also develop techniques to improve forecasting accuracy over large prediction windows and achieve high scalability over large workloads with high variability in arrival rates of queries. Finally, we propose techniques to handle workload drifts. Our evaluation on four real workloads demonstrates that SIBYL can forecast workloads with an 87.3% median F1 score, and can result in 1.7\u00d7 and 1.3\u00d7 performance improvement when applied to materialized view selection and index selection applications, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51293533",
                    "name": "Hanxian Huang"
                },
                {
                    "authorId": "5295950",
                    "name": "Tarique Siddiqui"
                },
                {
                    "authorId": "2273940323",
                    "name": "Rana Alotaibi"
                },
                {
                    "authorId": "2278429940",
                    "name": "Carlo Curino"
                },
                {
                    "authorId": "50334798",
                    "name": "Jyoti Leeka"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "2278568030",
                    "name": "Jishen Zhao"
                },
                {
                    "authorId": "1401945543",
                    "name": "Jes\u00fas Camacho-Rodr\u00edguez"
                },
                {
                    "authorId": "2274824557",
                    "name": "Yuanyuan Tian"
                }
            ]
        },
        {
            "paperId": "5215a52205943e08c886948dc7881938ec5ee230",
            "title": "Diversity, Equity and Inclusion Activities in Database Conferences: A 2022 Report",
            "abstract": "The Diversity, Equity and Inclusion (DEI) initiative started as the Diversity/Inclusion initiative in 2020 [4]. The current report summarizes our activities in 2022. Our responsibility as a community is to ensure that attendees of DB conferences feel included, irrespective of their scientific perspective and personal background. One of the first steps was to establish the role of the DEI chairs at DB Conferences, with the DEI team dedicated to providing leadership to help our community achieve this goal. In this leadership role, the DEI team is advising DEI chairs at DB conferences, serving as a memory of DEI events at conferences, building an agreed-upon vision, and committing to working together to devise a set of measures for achieving DEI. That is pursued via actions led by our core members (Figure 1) and liaisons of individual executive bodies (Figure 2): REACH OUT collects data and experiences from our community. INCLUDE monitors and recommends inclusion efforts. ORGANIZE focuses on in-conference organization efforts, such as adopting a code of conduct. INFORM communicates through various channels. SUPPORT coordinates DEI support from executive bodies and sponsors. SCOUT collates DEI efforts from other communities. COORDINATE manages all actions. Two new actions: MEDIA preserves and disseminates the digital media produced by DEI@DB events. ETHICS establishes and promotes ethics guidelines for publications in our community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "143970078",
                    "name": "D. Agrawal"
                },
                {
                    "authorId": "1710637",
                    "name": "Yael Amsterdamer"
                },
                {
                    "authorId": "1730344",
                    "name": "S. Bhowmick"
                },
                {
                    "authorId": "1401945543",
                    "name": "Jes\u00fas Camacho-Rodr\u00edguez"
                },
                {
                    "authorId": "1726425",
                    "name": "B. Catania"
                },
                {
                    "authorId": "2091879100",
                    "name": "K. Panos"
                },
                {
                    "authorId": "2081044488",
                    "name": "Chrysanthis"
                },
                {
                    "authorId": "1692732",
                    "name": "C. Curino"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "152945656",
                    "name": "G. Dobbie"
                },
                {
                    "authorId": "1709353",
                    "name": "A. El Abbadi"
                },
                {
                    "authorId": "2223141115",
                    "name": "Avrilia"
                },
                {
                    "authorId": "2223141462",
                    "name": "Floratou"
                },
                {
                    "authorId": "2178387374",
                    "name": "Juliana Freire"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "1685532",
                    "name": "V. Kalogeraki"
                },
                {
                    "authorId": "51205357",
                    "name": "Sujaya Maiyya"
                },
                {
                    "authorId": "2079019460",
                    "name": "Alexandra"
                },
                {
                    "authorId": "2223137576",
                    "name": "Meliou"
                },
                {
                    "authorId": "37168010",
                    "name": "Madhulika Mohanty"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "2149251297",
                    "name": "Fatma \u00d6zcan"
                },
                {
                    "authorId": "3139922",
                    "name": "L. Peterfreund"
                },
                {
                    "authorId": "145492471",
                    "name": "Wenny Rahayu"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "2062657988",
                    "name": "Sana Sellami"
                },
                {
                    "authorId": "2388459",
                    "name": "Utku Sirin"
                },
                {
                    "authorId": "2131764025",
                    "name": "Wang-Chiew Tan"
                },
                {
                    "authorId": "2080239484",
                    "name": "Bhavani"
                },
                {
                    "authorId": "101679060",
                    "name": "Thuraisingham"
                },
                {
                    "authorId": "1392679676",
                    "name": "Neeraja"
                },
                {
                    "authorId": "2223141037",
                    "name": "Yadwadkar"
                },
                {
                    "authorId": "3010003",
                    "name": "Victor Zakhary"
                },
                {
                    "authorId": "2117848168",
                    "name": "Meihui Zhang"
                }
            ]
        },
        {
            "paperId": "608eb118ffa447827ac7afd6ef42123cce9472e9",
            "title": "PikePlace: Generating Intelligence for Marketplace Datasets",
            "abstract": "There is a renewed interest in data marketplaces with cloud data warehouses that make sharing and accessing data on-demand and extremely easy. However, analyzing marketplace datasets is challenge since current tools for creating the data models are manual and slow. In this paper, we propose to demonstrate a learning-based approach to discover, deploy, and optimize data models. We present the resulting system, PikePlace, show an evaluation over Snowflake marketplace and TPC-H datasets, and describe several demonstration scenarios that the audience can play with.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238572802",
                    "name": "Shi Qiao"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                }
            ]
        },
        {
            "paperId": "86633a906653c2d0f6a4a8104aa9e0bd2869b9a5",
            "title": "Making Data Clouds Smarter at Keebo: Automated Warehouse Optimization using Data Learning",
            "abstract": "Data clouds in general, and cloud data warehouses (CDWs) in particular, have lowered the upfront expertise and infrastructure barriers, making it easy for a wider range of users to query large and diverse sources of data. This has made modern data pipelines more complex, harder to optimize, and therefore less resource efficient. As a result, the ongoing cost of data clouds can easily become prohibitively expensive. Further, since CDWs are general-purpose solutions that must serve a wide range of workloads, their out-of-box performance is sub-optimal for any single workload. Data teams therefore spend significant effort manually optimizing their queries and cloud infrastructure to curb costs while achieving reasonable performance. Aside from the opportunity cost of diverting data teams from business goals, manual optimization of millions of constantly changing queries is simply daunting. To the best of our knowledge, Keebo's Warehouse Optimization is the first fully-automated solution capable of making real-time optimization decisions that minimize the CDWs' overall cost while meeting the users' performance goals. Keebo learns from how users and applications interact with their CDW and uses its trained models to automatically optimize the warehouse settings, adjusts its resources (e.g., compute, memory), scale it up or down, suspend or resume it, and also self-correct in real-time based on the impact of its own actions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2198667",
                    "name": "Barzan Mozafari"
                },
                {
                    "authorId": "2218369869",
                    "name": "Radu Alexandru Burcuta"
                },
                {
                    "authorId": "2218375247",
                    "name": "Alan Cabrera"
                },
                {
                    "authorId": "72778277",
                    "name": "A. Constantin"
                },
                {
                    "authorId": "2218180143",
                    "name": "Derek Francis"
                },
                {
                    "authorId": "2218899884",
                    "name": "David Gr\u00f6mling"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "2218373839",
                    "name": "Maciej Konkolowicz"
                },
                {
                    "authorId": "2218896292",
                    "name": "Valentin Marian Spac"
                },
                {
                    "authorId": "40155297",
                    "name": "Yongjoo Park"
                },
                {
                    "authorId": "2218881829",
                    "name": "Russell Razo Carranzo"
                },
                {
                    "authorId": "47212380",
                    "name": "Nicholas M. Richardson"
                },
                {
                    "authorId": "2153931746",
                    "name": "Abhishek Roy"
                },
                {
                    "authorId": "1390925256",
                    "name": "Aayushi Srivastava"
                },
                {
                    "authorId": "31871632",
                    "name": "Isha Tarte"
                },
                {
                    "authorId": "36010484",
                    "name": "B. Westphal"
                },
                {
                    "authorId": "2218946493",
                    "name": "Chi Zhang"
                }
            ]
        },
        {
            "paperId": "b7aeca3f9116da88c89357b0cf4438401bc7ba3b",
            "title": "GEqO: ML-Accelerated Semantic Equivalence Detection",
            "abstract": "Large scale analytics engines have become a core dependency for modern data-driven enterprises to derive business insights and drive actions. These engines support a large number of analytic jobs processing huge volumes of data on a daily basis, and workloads are often inundated with overlapping computations across multiple jobs. Reusing common computation is crucial for efficient cluster resource utilization and reducing job execution time. Detecting common computation is the first and key step for reducing this computational redundancy. However, detecting equivalence on large-scale analytics engines requires efficient and scalable solutions that are fully automated. In addition, to maximize computation reuse, equivalence needs to be detected at the semantic level instead of just the syntactic level (i.e., the ability to detect semantic equivalence of seemingly different-looking queries). Unfortunately, existing solutions fall short of satisfying these requirements. In this paper, we take a major step towards filling this gap by proposing GEqO, a portable and lightweight machine-learning-based framework for efficiently identifying semantically equivalent computations at scale. GEqO introduces two machine-learning-based filters that quickly prune out nonequivalent subexpressions and employs a semi-supervised learning feedback loop to iteratively improve its model with an intelligent sampling mechanism. Further, with its novel database-agnostic featurization method, GEqO can transfer the learning from one workload and database to another. Our extensive empirical evaluation shows that, on TPC-DS-like queries, GEqO yields significant performance gains-up to 200x faster than automated verifiers-and finds up to 2x more equivalences than optimizer and signature-based equivalence detection approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273946851",
                    "name": "Brandon Haynes"
                },
                {
                    "authorId": "2273940323",
                    "name": "Rana Alotaibi"
                },
                {
                    "authorId": "118267534",
                    "name": "Anna Pavlenko"
                },
                {
                    "authorId": "50334798",
                    "name": "Jyoti Leeka"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "2274824557",
                    "name": "Yuanyuan Tian"
                }
            ]
        },
        {
            "paperId": "3330cf365150d11afbaf0c0011157208948dab7f",
            "title": "Pipemizer: An Optimizer for Analytics Data Pipelines",
            "abstract": "\n We demonstrate\n Pipemizer\n , an optimizer and recommender aimed at improving the performance of queries or jobs in pipelines. These job pipelines are ubiquitous in modern data analytics due to jobs reading output files written by other jobs. Given that more than 650k jobs run on Microsoft's SCOPE job service per day and about 70% have inter-job dependencies, identifying optimization opportunities across query jobs is of considerable interest to both cluster operators and users.\n Pipemizer\n addresses this need by providing recommendations to users, allowing users to understand their system, and facilitating automated application of recommendations.\n Pipemizer\n introduces novel optimizations that include holistic pipeline-aware statistics generation, inter-job operator push-up, and job split & merge. This demonstration showcases optimizations and recommendations generated by\n Pipemizer\n , enabling users to understand and optimize job pipelines.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2096398759",
                    "name": "Sunny Gakhar"
                },
                {
                    "authorId": "150140157",
                    "name": "Joyce Cahoon"
                },
                {
                    "authorId": "2065014",
                    "name": "Wangchao Le"
                },
                {
                    "authorId": "2136102556",
                    "name": "Xiangnan Li"
                },
                {
                    "authorId": "30498320",
                    "name": "K. Ravichandran"
                },
                {
                    "authorId": "1471618633",
                    "name": "Hiren Patel"
                },
                {
                    "authorId": "2183959019",
                    "name": "Marc"
                },
                {
                    "authorId": "2183988688",
                    "name": "Friedman"
                },
                {
                    "authorId": "144843868",
                    "name": "Brandon Haynes"
                },
                {
                    "authorId": "49830907",
                    "name": "S. Qiao"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "50334798",
                    "name": "Jyoti Leeka"
                },
                {
                    "authorId": "2183989819",
                    "name": "Keebo"
                },
                {
                    "authorId": "2183986784",
                    "name": "pipemizer"
                }
            ]
        },
        {
            "paperId": "344fcf9c139da6c21fa9516a1f57b586507a0d53",
            "title": "Query Optimizer as a Service",
            "abstract": "Query optimization is a critical technology that is common across all modern data processing systems. However, it is traditionally implemented in silos and is deeply embedded in different systems. Furthermore, over the years, query optimizers have become less understood and rarely touched pieces of code that are brittle to changes and very expensive to maintain, thus slowing down the pace of innovation. In this paper, we argue that it is time to think of query optimizer as a service in modern cloud architectures. Such a design can help build a common set of well-maintained optimizations that are externalized from the query engines and that could be learned and improved using the large workloads present in modern clouds. We present, Oasis, a reference architecture for query optimizer as a service and describe our success in deploying the early version of it in Cosmos. Finally, we discuss the risks and responsibilities involved with Oasis to ensure it is a win-win for everyone.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "50334798",
                    "name": "Jyoti Leeka"
                }
            ]
        },
        {
            "paperId": "8e2aefa5baeb2a250f15920976a94721bff004d5",
            "title": "Deploying a Steered Query Optimizer in Production at Microsoft",
            "abstract": "Modern analytical workloads are highly heterogeneous and massively complex, making generic out of the box query optimizers untenable for many customers and scenarios. As a result, it is important to specialize these optimizers to instances of the workloads. In this paper, we continue a recent line of work in steering a query optimizer towards better plans for a given workload, and make major strides in pushing previous research ideas to production deployment. Along the way we solve several operational challenges including, making steering actions more manageable, keeping the costs of steering within budget, and avoiding unexpected performance regressions in production. Our resulting system, QO-Advisor, essentially externalizes the query planner to a massive offline pipeline for better exploration and specialization. We discuss various aspects of our design and show detailed results over production SCOPE workloads at Microsoft, where the system is currently enabled by default.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2516526",
                    "name": "Wangda Zhang"
                },
                {
                    "authorId": "2192580",
                    "name": "Matteo Interlandi"
                },
                {
                    "authorId": "3040175",
                    "name": "Paul Mineiro"
                },
                {
                    "authorId": "49830907",
                    "name": "S. Qiao"
                },
                {
                    "authorId": "3434707",
                    "name": "Nasim Ghazanfari"
                },
                {
                    "authorId": "46189953",
                    "name": "Karlen Lie"
                },
                {
                    "authorId": "143634544",
                    "name": "Marc T. Friedman"
                },
                {
                    "authorId": "2686501",
                    "name": "Rafah Hosn"
                },
                {
                    "authorId": "1471618633",
                    "name": "Hiren Patel"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                }
            ]
        },
        {
            "paperId": "a538810087c7d8b240bf512ae997144fcbea466f",
            "title": "Towards Optimal Resource Allocation for Big Data Analytics",
            "abstract": "Optimizing resource allocation for analytical workloads is vital for reducing operational costs in modern cloud-oriented query processing services. At the same time, it is incredibly hard for users to allocate resources per query in the newer breed of Big Data processing systems, and they frequently end up mis-allocating by orders of magnitude. While prior work has focused on predicting peak resource allocation, it misses opportunities for more aggressive resource allocation to trade-off resource savings with query performance. Additionally, these methods fail to predict resource allocations for queries that have not been observed in the past. In this paper, we tackle both these problems. We present a sys-tem for optimal resource allocation in big data systems that can predict performance impact for candidate resource allocations, for both new and past observed queries. We introduce the notion of a performance characteristic curve (PCC) as a parameterized representation that can compactly capture the relationship be-tween resources and performance. To tackle the challenge of training data sparsity, we introduce a novel data augmentation technique to efficiently synthesize the entire PCC using a single run of the query. Lastly, we demonstrate the advantages of a constrained loss function coupled with GNNs, over traditional ML methods, for capturing the domain specific behavior through an extensive experimental evaluation over SCOPE big data work-loads at Microsoft. Our results show that our fast and novel sky-line simulation technique for data augmentation is sufficiently accurate, with a median percentage error in run time estimates of 9% on past jobs and our ML models can estimate the run time of jobs for different token counts well, before they have executed, with a median percentage error of 39% or less.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1995269610",
                    "name": "Anish Pimpley"
                },
                {
                    "authorId": "72917180",
                    "name": "Shuo Li"
                },
                {
                    "authorId": "3133317",
                    "name": "Rathijit Sen"
                },
                {
                    "authorId": "153309692",
                    "name": "Soundar Srinivasan"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                }
            ]
        }
    ]
}