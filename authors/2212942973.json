{
    "authorId": "2212942973",
    "papers": [
        {
            "paperId": "53982a1e34b25dfdcece0f30358c244fcbe32c86",
            "title": "PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering",
            "abstract": "Document Question Answering (QA) presents a challenge in understanding visually-rich documents (VRD), particularly those dominated by lengthy textual content like research journal articles. Existing studies primarily focus on real-world documents with sparse text, while challenges persist in comprehending the hierarchical semantic relations among multiple pages to locate multimodal components. To address this gap, we propose PDF-MVQA, which is tailored for research journal articles, encompassing multiple pages and multimodal information retrieval. Unlike traditional machine reading comprehension (MRC) tasks, our approach aims to retrieve entire paragraphs containing answers or visually rich document entities like tables and figures. Our contributions include the introduction of a comprehensive PDF Document VQA dataset, allowing the examination of semantically hierarchical layout structures in text-dominant documents. We also present new VRD-QA frameworks designed to grasp textual contents and relations among document layouts simultaneously, extending page-level understanding to the entire multi-page document. Through this work, we aim to enhance the capabilities of existing vision-and-language models in handling challenges posed by text-dominant documents in VRD-QA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166956722",
                    "name": "Yihao Ding"
                },
                {
                    "authorId": "2212942973",
                    "name": "Kaixuan Ren"
                },
                {
                    "authorId": "2213332565",
                    "name": "Jiabin Huang"
                },
                {
                    "authorId": "39209233",
                    "name": "Siwen Luo"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        },
        {
            "paperId": "e48e4cf40ae9cc1c7f68e36952f62440a6a8f7b9",
            "title": "Form-NLU: Dataset for the Form Natural Language Understanding",
            "abstract": "Compared to general document analysis tasks, form document structure understanding and retrieval are challenging. Form documents are typically made by two types of authors; A form designer, who develops the form structure and keys, and a form user, who fills out form values based on the provided keys. Hence, the form values may not be aligned with the form designer's intention (structure and keys) if a form user gets confused. In this paper, we introduce Form-NLU, the first novel dataset for form structure understanding and its key and value information extraction, interpreting the form designer's intent and the alignment of user-written value on it. It consists of 857 form images, 6k form keys and values, and 4k table keys and values. Our dataset also includes three form types: digital, printed, and handwritten, which cover diverse form appearances and layouts. We propose a robust positional and logical relation-based form key-value information extraction framework. Using this dataset, Form-NLU, we first examine strong object detection models for the form layout understanding, then evaluate the key information extraction task on the dataset, providing fine-grained results for different types of forms and keys. Furthermore, we examine it with the off-the-shelf pdf layout extraction tool and prove its feasibility in real-world cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166956722",
                    "name": "Yihao Ding"
                },
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "2213332565",
                    "name": "Jiabin Huang"
                },
                {
                    "authorId": "2212942973",
                    "name": "Kaixuan Ren"
                },
                {
                    "authorId": "2115606197",
                    "name": "Xingxian Luo"
                },
                {
                    "authorId": "3312958",
                    "name": "Hyunsuk Chung"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        }
    ]
}