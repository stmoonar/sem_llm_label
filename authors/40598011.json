{
    "authorId": "40598011",
    "papers": [
        {
            "paperId": "065ff071c244bd49d3946ba2f3854f3b994a5323",
            "title": "Beyond Trial-and-Error: Predicting User Abandonment After a Moderation Intervention",
            "abstract": "Current content moderation practices follow the trial-and-error approach, meaning that moderators apply sequences of interventions until they obtain the desired outcome. However, being able to preemptively estimate the effects of an intervention would allow moderators the unprecedented opportunity to plan their actions ahead of application. As a first step towards this goal, here we propose and tackle the novel task of predicting the effect of a moderation intervention. We study the reactions of 16,540 users to a massive ban of online communities on Reddit, training a set of binary classifiers to identify those users who would abandon the platform after the intervention - a problem of great practical relevance. We leverage a dataset of 13.8M posts to compute a large and diverse set of 142 features, which convey information about the activity, toxicity, relations, and writing style of the users. We obtain promising results, with the best-performing model achieving micro F1 = 0.800 and macro F1 = 0.676. Our model demonstrates robust generalizability when applied to users from previously unseen communities. Furthermore, we identify activity features as the most informative predictors, followed by relational and toxicity features, while writing style features exhibit limited utility. Our results demonstrate the feasibility of predicting the effects of a moderation intervention, paving the way for a new research direction in predictive content moderation aimed at empowering moderators with intelligent tools to plan ahead their actions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2297845718",
                    "name": "Benedetta Tessa"
                },
                {
                    "authorId": "2280144168",
                    "name": "Lorenzo Cima"
                },
                {
                    "authorId": "13159202",
                    "name": "Amaury Trujillo"
                },
                {
                    "authorId": "1684081",
                    "name": "M. Avvenuti"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                }
            ]
        },
        {
            "paperId": "2c37cb2a29baaf2b329ac1c21ea88e57289d67d7",
            "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
            "abstract": "Coordination is a fundamental aspect of life. The advent of social media has made it integral also to online human interactions, such as those that characterize thriving online communities and social movements. At the same time, coordination is also core to effective disinformation, manipulation, and hate campaigns. This survey collects, categorizes, and critically discusses the body of work produced as a result of the growing interest on coordinated online behavior. We reconcile industry and academic definitions, propose a comprehensive framework to study coordinated online behavior, and review and critically discuss the existing detection and characterization methods. Our analysis identifies open challenges and promising directions of research, serving as a guide for scholars, practitioners, and policymakers in understanding and addressing the complexities inherent to online coordination.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185573792",
                    "name": "Lorenzo Mannocci"
                },
                {
                    "authorId": "2060828836",
                    "name": "Michele Mazza"
                },
                {
                    "authorId": "2296962",
                    "name": "A. Monreale"
                },
                {
                    "authorId": "2704289",
                    "name": "Maurizio Tesconi"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                }
            ]
        },
        {
            "paperId": "6013c83c2a06602ae3fda25009519890a549f712",
            "title": "The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit",
            "abstract": "In the current landscape of online abuses and harms, effective content moderation is necessary to cultivate safe and inclusive online spaces. Yet, the effectiveness of many moderation interventions is still unclear. Here, we assess the effectiveness of The Great Ban, a massive deplatforming operation that affected nearly 2,000 communities on Reddit. By analyzing 16M comments posted by 17K users during 14 months, we provide nuanced results on the effects \u2014both desired and otherwise\u2014 of the ban. Among our main findings is that 15.6% of the affected users left Reddit and that those who remained reduced their toxicity by 6.6% on average. The ban also caused 5% users to increase their toxicity by more than 70% of their pre-ban level. Overall, our multifaceted results provide new insights into the efficacy of deplatforming. As such, our findings can inform the development of future moderation interventions and the policing of online platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280144168",
                    "name": "Lorenzo Cima"
                },
                {
                    "authorId": "13159202",
                    "name": "Amaury Trujillo"
                },
                {
                    "authorId": "1684081",
                    "name": "M. Avvenuti"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                }
            ]
        },
        {
            "paperId": "74804cc714cae570673e4b15b6e5b8f2b32245ae",
            "title": "Integrity 2024: Integrity in Social Networks and Media",
            "abstract": "Integrity 2024 is the fifth edition of the Workshop on Integrity in Social Networks and Media, held in conjunction with the ACM Conference on Web Search and Data Mining (WSDM) since the 2020 edition [1-4]. The goal of the workshop is to bring together academic and industry researchers working on integrity, fairness, trust and safety in social networks to discuss the most pressing risks and cutting-edge technologies to reliably measure and mitigate them. The event consists of invited talks from academic experts and industry leaders as well as peer-reviewed papers and posters through an open call-for-papers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209212295",
                    "name": "Llu\u00eds Garcia-Pueyo"
                },
                {
                    "authorId": "2276779989",
                    "name": "Symeon Papadopoulos"
                },
                {
                    "authorId": "2209214648",
                    "name": "Prathyusha Senthil Kumar"
                },
                {
                    "authorId": "1682878",
                    "name": "A. Gionis"
                },
                {
                    "authorId": "1701195",
                    "name": "Panayiotis Tsaparas"
                },
                {
                    "authorId": "2912732",
                    "name": "Vasilis Verroios"
                },
                {
                    "authorId": "2313479443",
                    "name": "Giuseppe Manco"
                },
                {
                    "authorId": "2290565901",
                    "name": "Anton Andryeyev"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                },
                {
                    "authorId": "2239640744",
                    "name": "T. Sellis"
                },
                {
                    "authorId": "144000523",
                    "name": "Anthony McCosker"
                }
            ]
        },
        {
            "paperId": "924bac24be1c989c955890cabf131a0f02bcde10",
            "title": "Coordinated Behavior in Information Operations on Twitter",
            "abstract": "Online information operations (IOs) refer to organized attempts to tamper with the regular flow of information and to influence public opinion. Coordinated online behavior is a tactic frequently used by IO perpetrators to boost the spread and outreach of their messages. However, the exploitation of coordinated behavior within large-scale IOs is still largely unexplored. Here, we build a novel dataset comprising around 624K users and 4M tweets to study how online coordination was used in two recent IOs carried out on Twitter. We investigate the interplay between coordinated behavior and IOs with state-of-the-art network science and coordination detection methods, providing evidence that the perpetrators of both IOs were indeed strongly coordinated. Furthermore, we propose quantitative indicators and analyses to study the different patterns of coordination, uncovering a malicious group of users that managed to hold a central position in the discussion network, and others who remained at the periphery of the network, with limited interactions with genuine users. The nuanced results enabled by our analysis provide insights into the strategies, development, and effectiveness of the IOs. Overall, our results demonstrate that the analysis of coordinated behavior in IOs can contribute to safeguarding the integrity of online platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280144168",
                    "name": "Lorenzo Cima"
                },
                {
                    "authorId": "2185573792",
                    "name": "Lorenzo Mannocci"
                },
                {
                    "authorId": "1684081",
                    "name": "M. Avvenuti"
                },
                {
                    "authorId": "2704289",
                    "name": "Maurizio Tesconi"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                }
            ]
        },
        {
            "paperId": "96806270b50c0d12dcba5037c6bc824f760e5891",
            "title": "Cyber Intelligence and Social Media Analytics: Current Research Trends and Challenges",
            "abstract": "Online Social Networks (OSNs) are a rich source of data for Cyber Security and Cyber Intelligence applications, as they can reveal valuable insights into users\u2019 behaviors, preferences, and opinions. Analyzing OSN data poses significant challenges, such as dealing with misinformation campaigns, protecting users\u2019 privacy, and extracting relevant information from large and heterogeneous datasets. The Cyber Intelligence (CI) unit of the IIT-CNR has been conducting cutting-edge research on these topics, using state-of-the-art techniques from artificial intelligence, machine learning, natural language processing, and computer vision. In this paper, we present some of the main activities of the CI group and the technologies we have developed and applied to various CI areas. In addition, we present our involvement in projects that leverage artificial intelligence technologies for the development and implementation of Cyber Security techniques and systems based on social media and online social networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41017909",
                    "name": "S. Tardelli"
                },
                {
                    "authorId": "1684081",
                    "name": "M. Avvenuti"
                },
                {
                    "authorId": "1815263",
                    "name": "Guglielmo Cola"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                },
                {
                    "authorId": "2811629",
                    "name": "T. Fagni"
                },
                {
                    "authorId": "1420400062",
                    "name": "Margherita Gambini"
                },
                {
                    "authorId": "2185573792",
                    "name": "Lorenzo Mannocci"
                },
                {
                    "authorId": "2060828836",
                    "name": "Michele Mazza"
                },
                {
                    "authorId": "2243473755",
                    "name": "Caterina Senette"
                },
                {
                    "authorId": "2704289",
                    "name": "Maurizio Tesconi"
                }
            ]
        },
        {
            "paperId": "a6ff42900f660427bb7c96cd2afff7ccd1d8e1e7",
            "title": "The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media",
            "abstract": "Since September 2023, the Digital Services Act (DSA) obliges large online platforms to submit detailed data on each moderation action they take within the European Union (EU) to the DSA Transparency Database. From its inception, this centralized database has sparked scholarly interest as an unprecedented and potentially unique trove of data on real-world online moderation. Here, we thoroughly analyze all 353.12M records submitted by the eight largest social media platforms in the EU during the first 100 days of the database. Specifically, we conduct a platform-wise comparative study of their: volume of moderation actions, grounds for decision, types of applied restrictions, types of moderated content, timeliness in undertaking and submitting moderation actions, and use of automation. Furthermore, we systematically cross-check the contents of the database with the platforms' own transparency reports. Our analyses reveal that (i) the platforms adhered only in part to the philosophy and structure of the database, (ii) the structure of the database is partially inadequate for the platforms' reporting needs, (iii) the platforms exhibited substantial differences in their moderation actions, (iv) a remarkable fraction of the database data is inconsistent, (v) the platform X (formerly Twitter) presents the most inconsistencies. Our findings have far-reaching implications for policymakers and scholars across diverse disciplines. They offer guidance for future regulations that cater to the reporting needs of online platforms in general, but also highlight opportunities to improve and refine the database itself.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13159202",
                    "name": "Amaury Trujillo"
                },
                {
                    "authorId": "2811629",
                    "name": "T. Fagni"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                }
            ]
        },
        {
            "paperId": "ac71643ab49fbb3433a389439a86ac3765e25e32",
            "title": "Tracking Fringe and Coordinated Activity on Twitter Leading Up To the US Capitol Attack",
            "abstract": "The aftermath of the 2020 US Presidential Election witnessed an unprecedented attack on the democratic values of the country through the violent insurrection at Capitol Hill on January 6th, 2021. The attack was fueled by the proliferation of conspiracy theories and misleading claims about the integrity of the election pushed by political elites and fringe communities on social media. In this study, we explore the evolution of fringe content and conspiracy theories on Twitter in the seven months leading up to the Capitol attack. We examine the suspicious coordinated activity carried out by users sharing fringe content, finding evidence of common adversarial manipulation techniques ranging from targeted amplification to manufactured consensus. Further, we map out the temporal evolution of, and the relationship between, fringe and conspiracy theories, which eventually coalesced into the rhetoric of a stolen election, with the hashtag #stopthesteal, alongside QAnon-related narratives. Our findings further highlight how social media platforms offer fertile ground for the widespread proliferation of conspiracies during and in the aftermath of major societal events, which can potentially lead to offline coordinated actions and organized violence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2172968606",
                    "name": "Padinjaredath Suresh Vishnuprasad"
                },
                {
                    "authorId": "2172986349",
                    "name": "Gianluca Nogara"
                },
                {
                    "authorId": "2055509145",
                    "name": "Felipe Cardoso"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                },
                {
                    "authorId": "47396895",
                    "name": "Silvia Giordano"
                },
                {
                    "authorId": "3349623",
                    "name": "Luca Luceri"
                }
            ]
        },
        {
            "paperId": "c6b7469c4932b36bea2013eec6fe711c0047ae7a",
            "title": "Demystifying Misconceptions in Social Bots Research",
            "abstract": "Research on social bots aims at advancing knowledge and providing solutions to one of the most debated forms of online manipulation. Yet, social bot research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental towards ensuring reliable solutions and reaffirming the validity of the scientific method. In this contribution, we review some recent results in social bots research, highlighting and revising factual errors as well as methodological and conceptual biases. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss research about online disinformation and manipulation in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research, as well as providing directions toward sound methodologies for future research in the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                },
                {
                    "authorId": "1728076",
                    "name": "R. D. Pietro"
                },
                {
                    "authorId": "2549445",
                    "name": "A. Spognardi"
                },
                {
                    "authorId": "2704289",
                    "name": "Maurizio Tesconi"
                },
                {
                    "authorId": "2485749",
                    "name": "M. Petrocchi"
                }
            ]
        },
        {
            "paperId": "e15fabff4dcceca48ae22118b4cb13a9fa3323fb",
            "title": "Temporal Dynamics of Coordinated Online Behavior: Stability, Archetypes, and Influence",
            "abstract": "Large-scale online campaigns, malicious or otherwise, require a significant degree of coordination among participants, which sparked interest in the study of coordinated online behavior. State-of-the-art methods for detecting coordinated behavior perform static analyses, disregarding the temporal dynamics of coordination. Here, we carry out a dynamic analysis of coordinated behavior. To reach our goal, we build a multiplex temporal network and we perform dynamic community detection to identify groups of users that exhibited coordinated behaviors in time. We find that i) coordinated communities (CCs) feature variable degrees of temporal instability; ii) dynamic analyses are needed to account for such instability, and results of static analyses can be unreliable and scarcely representative of unstable communities; iii) some users exhibit distinct archetypal behaviors that have important practical implications; iv) content and network characteristics contribute to explaining why users leave and join CCs. Our results demonstrate the advantages of dynamic analyses and open up new directions of research on the unfolding of online debates, on the strategies of CCs, and on the patterns of online influence.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "41017909",
                    "name": "S. Tardelli"
                },
                {
                    "authorId": "46206525",
                    "name": "Leonardo Nizzoli"
                },
                {
                    "authorId": "2704289",
                    "name": "Maurizio Tesconi"
                },
                {
                    "authorId": "145746490",
                    "name": "M. Conti"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "40598011",
                    "name": "S. Cresci"
                }
            ]
        }
    ]
}