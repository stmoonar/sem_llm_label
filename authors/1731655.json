{
    "authorId": "1731655",
    "papers": [
        {
            "paperId": "5a30f9e14b964eb76ce78e177a25786b95e04e3a",
            "title": "ReliK: A Reliability Measure for Knowledge Graph Embeddings",
            "abstract": "Can we assess a priori how well a knowledge graph embedding will perform on a specific downstream task and in a specific part of the knowledge graph? Knowledge graph embeddings (KGEs) represent entities (e.g., ''da Vinci,'' ''Mona Lisa'') and relationships (e.g., ''painted'') of a knowledge graph (KG) as vectors. KGEs are generated by optimizing an embedding score, which assesses whether a triple (e.g., ''da Vinci,'' \"painted,'' ''Mona Lisa'') exists in the graph. KGEs have been proven effective in a variety of web-related downstream tasks, including, for instance, predicting relationship(s) among entities. However, the problem of anticipating the performance of a given KGE in a certain downstream task and locally to a specific individual triple, has not been tackled so far. In this paper, we fill this gap withReliK, a Reli ability measure for K GEs. ReliK relies solely on KGE embedding scores, is task- and KGE-agnostic, and requires no further KGE training. As such, it is particularly appealing for semantic web applications which call for testing multiple KGE methods on various parts of the KG and on each individual downstream task. Through extensive experiments, we attest thatReliK correlates well with both common downstream tasks, such as tail/relation prediction and triple classification, as well as advanced downstream tasks, such as rule mining and question answering, while preserving locality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298271646",
                    "name": "Maximilian K. Egger"
                },
                {
                    "authorId": "2298417586",
                    "name": "Wenyue Ma"
                },
                {
                    "authorId": "2292397256",
                    "name": "Davide Mottin"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                },
                {
                    "authorId": "3033855",
                    "name": "Ilaria Bordino"
                },
                {
                    "authorId": "2288858829",
                    "name": "Francesco Gullo"
                },
                {
                    "authorId": "2298269932",
                    "name": "Aris Anagnostopoulos"
                }
            ]
        },
        {
            "paperId": "de6e69921165ebe561120c70fcab68b75fe42306",
            "title": "Autonomous micro-focus angle-resolved photoemission spectroscopy.",
            "abstract": "Angle-resolved photoemission spectroscopy (ARPES) is a technique used to map the occupied electronic structure of solids. Recent progress in x-ray focusing optics has led to the development of ARPES into a microscopic tool, permitting the electronic structure to be spatially mapped across the surface of a sample. This comes at the expense of a time-consuming scanning process to cover not only a three-dimensional energy-momentum (E, kx, ky) space but also the two-dimensional surface area. Here, we implement a protocol to autonomously search both k- and real-space in order to find positions of particular interest, either because of their high photoemission intensity or because of sharp spectral features. The search is based on the use of Gaussian process regression and can easily be expanded to include additional parameters or optimization criteria. This autonomous experimental control is implemented on the SGM4 micro-focus beamline of the synchrotron radiation source ASTRID2.",
            "fieldsOfStudy": [
                "Medicine",
                "Physics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50857693",
                    "name": "S. Agustsson"
                },
                {
                    "authorId": "2292392014",
                    "name": "Alfred J. H. Jones"
                },
                {
                    "authorId": "50221586",
                    "name": "Davide Curcio"
                },
                {
                    "authorId": "88726688",
                    "name": "S. Ulstrup"
                },
                {
                    "authorId": "2238783742",
                    "name": "Jill Miwa"
                },
                {
                    "authorId": "2292397256",
                    "name": "Davide Mottin"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                },
                {
                    "authorId": "2214653904",
                    "name": "Philip Hofmann"
                }
            ]
        },
        {
            "paperId": "18afd2377688d6a8e7372caa7a9d3aac73ea1a1a",
            "title": "Marigold: Efficient k-means Clustering in High Dimensions",
            "abstract": "\n How can we efficiently and scalably cluster high-dimensional data? The\n k\n -means algorithm clusters data by iteratively reducing intra-cluster Euclidean distances until convergence. While it finds applications from recommendation engines to image segmentation, its application to high-dimensional data is hindered by the need to repeatedly compute Euclidean distances among points and centroids. In this paper, we propose Marigold (\n k\n -means for high-dimensional data), a scalable algorithm for\n k\n -means clustering in high dimensions. Marigold prunes distance calculations by means of (i) a tight distance-bounding scheme; (ii) a stepwise calculation over a multiresolution transform; and (iii) exploiting the triangle inequality. To our knowledge, such an arsenal of pruning techniques has not been hitherto applied to\n k\n -means. Our work is motivated by time-critical Angle-Resolved Photoemission Spectroscopy (ARPES) experiments, where it is vital to detect clusters among high-dimensional spectra in real time. In a thorough experimental study with real-world data sets we demonstrate that Marigold efficiently clusters high-dimensional data, achieving approximately one order of magnitude improvement over prior art.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214652187",
                    "name": "Kasper Overgaard Mortensen"
                },
                {
                    "authorId": "1586599742",
                    "name": "Fatemeh Zardbani"
                },
                {
                    "authorId": "144160585",
                    "name": "M. A. Haque"
                },
                {
                    "authorId": "50857693",
                    "name": "S. Agustsson"
                },
                {
                    "authorId": "3094226",
                    "name": "D. Mottin"
                },
                {
                    "authorId": "2214653904",
                    "name": "Philip Hofmann"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        },
        {
            "paperId": "2135da3489b236497e65a3af701f6733d98b9f64",
            "title": "Comprehensive Evaluation of Algorithms for Unrestricted Graph Alignment",
            "abstract": "The graph alignment problem calls for finding a matching be-tween the nodes of one graph and those of another graph, in a way that they correspond to each other by some fitness measure. Over the last years, several graph alignment algorithms have been proposed and evaluated on diverse datasets and quality measures. Typically, a newly proposed algorithm is compared to previously proposed ones on some specific datasets, types of noise, and quality measures where the new proposal achieves superiority over the previous ones. However, no systematic comparison of the proposed algorithms has been attempted on the same benchmarks. This paper fills this gap by conducting an extensive, thorough, and commensurable evaluation of state-of-the-art graph alignment algorithms. Our results highlight the value of overlooked solutions and an unprecedented effect of graph density on performance, hence call for further work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2179911406",
                    "name": "Konstantinos Skitsas"
                },
                {
                    "authorId": "1435037339",
                    "name": "Karol Orlowski"
                },
                {
                    "authorId": "30146511",
                    "name": "Judith Hermanns"
                },
                {
                    "authorId": "3094226",
                    "name": "D. Mottin"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        },
        {
            "paperId": "35c8b73e2d69df0f0ce1957c8e44886efeda1182",
            "title": "MCWDST: A Minimum-Cost Weighted Directed Spanning Tree Algorithm for Real-Time Fake News Mitigation in Social Media",
            "abstract": "The widespread availability of internet access and handheld devices confers to social media a power similar to the one newspapers used to have. People seek affordable information on social media and can reach it within seconds. Yet this convenience comes with dangers; any user may freely post whatever they please and the content can stay online for a long period, regardless of its truthfulness. A need arises to detect untruthful information, also known as fake news. In this paper, we present an end-to-end solution that accurately detects fake news and immunizes network nodes that spread them in real-time. To detect fake news, we propose two new stack deep learning architectures that utilize convolutional and bidirectional LSTM layers. To mitigate the spread of fake news, we propose a real-time network-aware strategy that (1) constructs a minimum-cost weighted directed spanning tree for a detected node, and (2) immunizes nodes in that tree by scoring their harmfulness using a novel ranking function. We demonstrate the effectiveness of our solution on five real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204464023",
                    "name": "Ciprian-Octavian Truicua"
                },
                {
                    "authorId": "3202565",
                    "name": "E. Apostol"
                },
                {
                    "authorId": "2209376164",
                    "name": "Radu-Cuatualin Nicolescu"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        },
        {
            "paperId": "364f21fd8fb68711f39886e584018a8342b628be",
            "title": "k-Best Egalitarian Stable Marriages for Task Assignment",
            "abstract": "\n In a two-sided market with each agent ranking individuals on the other side according to their preferences, such as location or incentive, the\n stable marriage\n problem calls to find a\n perfect matching\n among the two sides such that no pair of agents prefers each other to their assigned matches. Recent studies show that the number of solutions can be large in practice. Yet the classic solution by the Gale-Shapley (GS) algorithm is\n optimal\n for agents on the one side and\n pessimal\n for those on the other side. Some algorithms find a stable marriage that optimizes a measure of the cumulative satisfaction of all agents, such as\n egalitarian cost.\n However, in many real-world circumstances, a decision-maker needs to examine a set of solutions that are stable and attentive to both sides and choose among them based on expert knowledge. With such a disposition, it is necessary to identify a set of high-quality stable marriages and provide transparent explanations for any reassigned matches to the decision-maker. In this paper, we provide efficient algorithms that find the\n k\n -best stable marriages by\n egalitarian cost.\n Our exhaustive experimental study using real-world data and realistic preferences demonstrates the efficacy and efficiency of our solution.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112452916",
                    "name": "Siyuan Wu"
                },
                {
                    "authorId": "1830414684",
                    "name": "Leong Hou U"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        },
        {
            "paperId": "77e01aab1db8b4b8eb961c8f378a9cffec42f91f",
            "title": "DANES: Deep Neural Network Ensemble Architecture for Social and Textual Context-aware Fake News Detection",
            "abstract": "The growing popularity of social media platforms has simplified the creation and distribution of news articles but also creates a conduit for spreading fake news. In consequence, the need arises for effective context-aware fake news detection mechanisms, where the contextual information can be built either from the textual content of posts or from available social data (e.g., information about the users, reactions to posts, or the social network). In this paper, we propose DANES, a Deep Neural Network Ensemble Architecture for Social and Textual Context-aware Fake News Detection. DANES comprises a Text Branch for a textual content-based context and a Social Branch for the social context. These two branches are used to create a novel Network Embedding. Preliminary ablation results on 3 real-world datasets, i.e., BuzzFace, Twitter15, and Twitter16, are promising, with an accuracy that outperforms state-of-the-art solutions when employing both social and textual content features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204464023",
                    "name": "Ciprian-Octavian Truicua"
                },
                {
                    "authorId": "3202565",
                    "name": "E. Apostol"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        },
        {
            "paperId": "a5bb0340d0c42072ea027de0fd25899637caca3c",
            "title": "Optimally Interpolating between Ex-Ante Fairness and Welfare",
            "abstract": "For the fundamental problem of allocating a set of resources among individuals with varied preferences, the quality of an allocation relates to the degree of fairness and the collective welfare achieved. Unfortunately, in many resource-allocation settings, it is computationally hard to maximize welfare while achieving fairness goals. In this work, we consider ex-ante notions of fairness; popular examples include the \\emph{randomized round-robin algorithm} and \\emph{sortition mechanism}. We propose a general framework to systematically study the \\emph{interpolation} between fairness and welfare goals in a multi-criteria setting. We develop two efficient algorithms ($\\varepsilon-Mix$ and $Simple-Mix$) that achieve different trade-off guarantees with respect to fairness and welfare. $\\varepsilon-Mix$ achieves an optimal multi-criteria approximation with respect to fairness and welfare, while $Simple-Mix$ achieves optimality up to a constant factor with zero computational overhead beyond the underlying \\emph{welfare-maximizing mechanism} and the \\emph{ex-ante fair mechanism}. Our framework makes no assumptions on either of the two underlying mechanisms, other than that the fair mechanism produces a distribution over the set of all allocations. Indeed, if these mechanisms are themselves approximation algorithms, our framework will retain the approximation factor, guaranteeing sensitivity to the quality of the underlying mechanisms, while being \\emph{oblivious} to them. We also give an extensive experimental analysis for the aforementioned ex-ante fair mechanisms on real data sets, confirming our theoretical analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112197898",
                    "name": "M. Hogsgaard"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                },
                {
                    "authorId": "47121130",
                    "name": "Wenyue Ma"
                },
                {
                    "authorId": "51138692",
                    "name": "Nidhi Rathi"
                },
                {
                    "authorId": "2225976",
                    "name": "Chris Schwiegelshohn"
                }
            ]
        },
        {
            "paperId": "c1065a7083f5a675efdc2f4276e437fa437c0ce0",
            "title": "Holistic Prediction on a Time-Evolving Attributed Graph",
            "abstract": "Graph-based prediction is essential in NLP tasks such as temporal knowledge graph completion. A cardinal question in this field is, how to predict the future links, nodes, and attributes of a time-evolving attributed graph? Unfortunately, existing techniques assume that each link, node, and attribute prediction is independent, and fall short of predicting the appearance of new nodes that were not observed in the past. In this paper, we address two interrelated questions; (1) can we exploit task interdependence to improve prediction accuracy? and (2) can we predict new nodes with their attributes? We propose a unified framework that predicts node attributes and topology changes such as the appearance and disappearance of links and the emergence and loss of nodes. This frame-work comprises components for independent and interactive prediction and for predicting new nodes. Our experimental study using real-world data confirms that our interdependent prediction framework achieves higher accuracy than methods based on independent prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2049206121",
                    "name": "Shohei Yamasaki"
                },
                {
                    "authorId": "2081851",
                    "name": "Yuya Sasaki"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                },
                {
                    "authorId": "48075831",
                    "name": "Makoto Onizuka"
                }
            ]
        },
        {
            "paperId": "ecd3c2bbd3a961ade418c91a75a5ed57c3887c47",
            "title": "Adaptive Indexing of Objects with Spatial Extent",
            "abstract": "\n Can we quickly explore large multidimensional data in main memory?\n Adaptive indexing\n responds to this need by building an index incrementally, in response to queries; in its default form, it indexes a single attribute or, in the presence of several attributes, one attribute per index level. Unfortunately, this approach falters when indexing spatial data objects, encountered in data exploration tasks involving multidimensional range queries. In this paper, we introduce the Adaptive Incremental R-tree (AIR-tree): the first method for the adaptive indexing of non-point spatial objects; the AIR-tree incrementally and progressively constructs an in-memory spatial index over a static array, in response to incoming queries, using a suite of heuristics for creating and splitting nodes. Our thorough experimental study on synthetic and real data and workloads shows that the AIR-tree consistently outperforms prior adaptive indexing methods focusing on multidimensional points and a pre-built static R-tree in cumulative time over at least the first thousand queries.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1586599742",
                    "name": "Fatemeh Zardbani"
                },
                {
                    "authorId": "1718168",
                    "name": "N. Mamoulis"
                },
                {
                    "authorId": "2203901",
                    "name": "Stratos Idreos"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        }
    ]
}