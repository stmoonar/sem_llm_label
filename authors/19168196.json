{
    "authorId": "19168196",
    "papers": [
        {
            "paperId": "1804ea0c26e9b038547ff7a7e3eedf8d9de9717d",
            "title": "BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text",
            "abstract": "Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance on a wide variety of biomedical NLP tasks. However, these models have hundreds of billions of parameters, are computationally expensive to run, require users to send their input data over the internet, and are trained on unknown data sources. Can smaller, more targeted models compete? To address this question, we build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive model trained exclusively on PubMed abstracts and full articles. When fine-tuned, BioMedLM can produce strong multiple-choice biomedical question-answering results competitive with much larger models, such as achieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical Genetics exam. BioMedLM can also be fine-tuned to produce useful answers to patient questions on medical topics. This demonstrates that smaller models can potentially serve as transparent, privacy-preserving, economical and environmentally friendly foundations for particular NLP applications, such as in biomedicine. The model is available on the Hugging Face Hub: https://huggingface.co/stanford-crfm/BioMedLM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293612994",
                    "name": "Elliot Bolton"
                },
                {
                    "authorId": "1594028118",
                    "name": "Abhinav Venigalla"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2293696935",
                    "name": "David Hall"
                },
                {
                    "authorId": "2261191670",
                    "name": "Betty Xiong"
                },
                {
                    "authorId": "2293619342",
                    "name": "Tony Lee"
                },
                {
                    "authorId": "2289146390",
                    "name": "R. Daneshjou"
                },
                {
                    "authorId": "2277215716",
                    "name": "Jonathan Frankle"
                },
                {
                    "authorId": "2249641250",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "1701041",
                    "name": "Michael Carbin"
                },
                {
                    "authorId": "2250402802",
                    "name": "Christopher D. Manning"
                }
            ]
        },
        {
            "paperId": "4308208fac24626e0c927ee728038aadc4e87266",
            "title": "HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models",
            "abstract": "In order to thrive in hostile and ever-changing natural environments, mammalian brains evolved to store large amounts of knowledge about the world and continually integrate new information while avoiding catastrophic forgetting. Despite the impressive accomplishments, large language models (LLMs), even with retrieval-augmented generation (RAG), still struggle to efficiently and effectively integrate a large amount of new experiences after pre-training. In this work, we introduce HippoRAG, a novel retrieval framework inspired by the hippocampal indexing theory of human long-term memory to enable deeper and more efficient knowledge integration over new experiences. HippoRAG synergistically orchestrates LLMs, knowledge graphs, and the Personalized PageRank algorithm to mimic the different roles of neocortex and hippocampus in human memory. We compare HippoRAG with existing RAG methods on multi-hop question answering and show that our method outperforms the state-of-the-art methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves comparable or better performance than iterative retrieval like IRCoT while being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into IRCoT brings further substantial gains. Finally, we show that our method can tackle new types of scenarios that are out of reach of existing methods. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1666169546",
                    "name": "Bernal Jimenez Gutierrez"
                },
                {
                    "authorId": "1406331721",
                    "name": "Yiheng Shu"
                },
                {
                    "authorId": "2022231256",
                    "name": "Yu Gu"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "1758652",
                    "name": "Yu Su"
                }
            ]
        },
        {
            "paperId": "5508ecfdd6f432d8f9932060bedf1d742ab5aac8",
            "title": "When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards",
            "abstract": "Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value - we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple-choice question benchmarks (e.g., MMLU), minor perturbations to the benchmark, such as changing the order of choices or the method of answer selection, result in changes in rankings up to 8 positions. We explain this phenomenon by conducting systematic experiments over three broad categories of benchmark perturbations and identifying the sources of this behavior. Our analysis results in several best-practice recommendations, including the advantage of a hybrid scoring method for answer selection. Our study highlights the dangers of relying on simple benchmark evaluations and charts the path for more robust evaluation schemes on the existing benchmarks. The code for this paper is available at https://github.com/National-Center-for-AI-Saudi-Arabia/lm-evaluation-harness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282541972",
                    "name": "Norah A. Alzahrani"
                },
                {
                    "authorId": "2282540711",
                    "name": "H. A. Alyahya"
                },
                {
                    "authorId": "2282542508",
                    "name": "Sultan Yazeed Alnumay"
                },
                {
                    "authorId": "2282541704",
                    "name": "Shaykhah Alsubaie"
                },
                {
                    "authorId": "2282540330",
                    "name": "Yusef Almushaykeh"
                },
                {
                    "authorId": "2282540669",
                    "name": "Faisal A. Mirza"
                },
                {
                    "authorId": "2282541021",
                    "name": "Nouf M. Alotaibi"
                },
                {
                    "authorId": "2282540243",
                    "name": "Nora Altwairesh"
                },
                {
                    "authorId": "1724548",
                    "name": "Areeb Alowisheq"
                },
                {
                    "authorId": "2054179756",
                    "name": "Saiful Bari"
                },
                {
                    "authorId": "2310418723",
                    "name": "Haidar Khan"
                },
                {
                    "authorId": "2282542389",
                    "name": "A. Jeddah"
                },
                {
                    "authorId": "2282542216",
                    "name": "B. Makkah"
                },
                {
                    "authorId": "2282542594",
                    "name": "C. Paris"
                },
                {
                    "authorId": "2148555437",
                    "name": "D. Riyadh"
                },
                {
                    "authorId": "1582814486",
                    "name": "B. Riyadh"
                },
                {
                    "authorId": "2282542530",
                    "name": "D. Makkah"
                },
                {
                    "authorId": "2261985361",
                    "name": "Peter Clark"
                },
                {
                    "authorId": "3390191",
                    "name": "Isaac Cowhey"
                },
                {
                    "authorId": "2282542651",
                    "name": "O. Etzioni"
                },
                {
                    "authorId": "2236429",
                    "name": "Tushar Khot"
                },
                {
                    "authorId": "2274215058",
                    "name": "Mostafa Dehghani"
                },
                {
                    "authorId": "97947517",
                    "name": "Yi Tay"
                },
                {
                    "authorId": "2194424",
                    "name": "A. Gritsenko"
                },
                {
                    "authorId": "2283031905",
                    "name": "Zhe Zhao"
                },
                {
                    "authorId": "2815290",
                    "name": "N. Houlsby"
                },
                {
                    "authorId": "2286261854",
                    "name": "Fernando D\u00edaz"
                },
                {
                    "authorId": "1680617",
                    "name": "Donald Metzler"
                },
                {
                    "authorId": null,
                    "name": "Leo Gao"
                },
                {
                    "authorId": "50195579",
                    "name": "J. Tow"
                },
                {
                    "authorId": "2282542564",
                    "name": "Baber Abbasi"
                },
                {
                    "authorId": "2273535088",
                    "name": "Stella Biderman"
                },
                {
                    "authorId": "2044098905",
                    "name": "Sid Black"
                },
                {
                    "authorId": "2282542841",
                    "name": "Anthony DiPofi"
                },
                {
                    "authorId": "2282542898",
                    "name": "Charles Foster"
                },
                {
                    "authorId": "2044198157",
                    "name": "Laurence Golding"
                },
                {
                    "authorId": "2273791195",
                    "name": "Jeffrey Hsu"
                },
                {
                    "authorId": "2189476690",
                    "name": "Alain Le Noac\u2019h"
                },
                {
                    "authorId": "2282714065",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "3422872",
                    "name": "Dan Hendrycks"
                },
                {
                    "authorId": null,
                    "name": "Collin Burns"
                },
                {
                    "authorId": "104444594",
                    "name": "Steven Basart"
                },
                {
                    "authorId": "2273822457",
                    "name": "Andy Zou"
                },
                {
                    "authorId": "2323050733",
                    "name": "M. Tahmid"
                },
                {
                    "authorId": "2282542567",
                    "name": "Rahman Laskar"
                },
                {
                    "authorId": "2282542813",
                    "name": "Md. Mizanur Rahman"
                },
                {
                    "authorId": "2284375773",
                    "name": "Amran Bhuiyan"
                },
                {
                    "authorId": "2260342171",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "2223138553",
                    "name": "Rishi Bommasani"
                },
                {
                    "authorId": "2280998729",
                    "name": "Tony Lee"
                },
                {
                    "authorId": "2754804",
                    "name": "Dimitris Tsipras"
                },
                {
                    "authorId": "1914569491",
                    "name": "Dilara Soylu"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2250923503",
                    "name": "Yian Zhang"
                },
                {
                    "authorId": "2251007290",
                    "name": "Deepak Narayanan"
                },
                {
                    "authorId": "2250015839",
                    "name": "Yuhuai Wu"
                },
                {
                    "authorId": "32423266",
                    "name": "Ananya Kumar"
                },
                {
                    "authorId": "2250557275",
                    "name": "Benjamin Newman"
                },
                {
                    "authorId": "2250117174",
                    "name": "Binhang Yuan"
                },
                {
                    "authorId": "1748871792",
                    "name": "Bobby Yan"
                },
                {
                    "authorId": "2262511796",
                    "name": "Ce Zhang"
                },
                {
                    "authorId": "2251005170",
                    "name": "Christian Cosgrove"
                },
                {
                    "authorId": "2282542845",
                    "name": "Christopher D. Man-ning"
                },
                {
                    "authorId": "2250761261",
                    "name": "Christopher R\u00e9"
                },
                {
                    "authorId": "1413421064",
                    "name": "Diana Acosta-Navas"
                },
                {
                    "authorId": "152951058",
                    "name": "Drew A. Hudson"
                },
                {
                    "authorId": "49456763",
                    "name": "E. Zelikman"
                },
                {
                    "authorId": "41152329",
                    "name": "Esin Durmus"
                },
                {
                    "authorId": "2282542771",
                    "name": "Faisal Lad-hak"
                },
                {
                    "authorId": "2047004093",
                    "name": "Frieda Rong"
                },
                {
                    "authorId": "2282935403",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2250097082",
                    "name": "Huaxiu Yao"
                },
                {
                    "authorId": "2252087284",
                    "name": "Jue Wang"
                },
                {
                    "authorId": "50818255",
                    "name": "Keshav Santhanam"
                },
                {
                    "authorId": "2250741832",
                    "name": "Laurel J. Orr"
                },
                {
                    "authorId": "2118604716",
                    "name": "Lucia Zheng"
                },
                {
                    "authorId": "2282542500",
                    "name": "Mert Yuksekgonul"
                },
                {
                    "authorId": "51903517",
                    "name": "Mirac Suzgun"
                },
                {
                    "authorId": "2252992164",
                    "name": "Nathan Kim"
                },
                {
                    "authorId": "2820009",
                    "name": "Neel Guha"
                },
                {
                    "authorId": "22193324",
                    "name": "Niladri S. Chatterji"
                },
                {
                    "authorId": "144112155",
                    "name": "O. Khattab"
                },
                {
                    "authorId": "2250986700",
                    "name": "Peter Henderson"
                },
                {
                    "authorId": "144862341",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "2121293578",
                    "name": "Ryan Chi"
                },
                {
                    "authorId": "2282542921",
                    "name": "Sang Michael"
                },
                {
                    "authorId": "2282918541",
                    "name": "Shibani Xie"
                },
                {
                    "authorId": "2282542473",
                    "name": "Surya Santurkar"
                },
                {
                    "authorId": "2282542633",
                    "name": "Tatsunori Ganguli"
                },
                {
                    "authorId": "2282617771",
                    "name": "Thomas Hashimoto"
                },
                {
                    "authorId": "2282542264",
                    "name": "Tianyi Icard"
                },
                {
                    "authorId": "2282542346",
                    "name": "Vishrav Zhang"
                },
                {
                    "authorId": "2282542852",
                    "name": "William Chaudhary"
                },
                {
                    "authorId": "2282901438",
                    "name": "Xuechen Wang"
                },
                {
                    "authorId": "2282543897",
                    "name": "Yifan Li"
                },
                {
                    "authorId": "2282542368",
                    "name": "Mai Yuhui"
                },
                {
                    "authorId": "2282542917",
                    "name": "Zhang Yuta"
                },
                {
                    "authorId": "2282542923",
                    "name": "Koreeda. 2023"
                },
                {
                    "authorId": "2282542850",
                    "name": "Holistic evaluation"
                },
                {
                    "authorId": "2269733851",
                    "name": "Colin Raffel"
                },
                {
                    "authorId": "1846258",
                    "name": "Noam M. Shazeer"
                },
                {
                    "authorId": "2275223445",
                    "name": "A. Roberts"
                },
                {
                    "authorId": "2275576898",
                    "name": "K. Lee"
                },
                {
                    "authorId": "46617804",
                    "name": "Sharan Narang"
                },
                {
                    "authorId": "1380243217",
                    "name": "Michael Matena"
                },
                {
                    "authorId": "2260365292",
                    "name": "Yanqi Zhou"
                },
                {
                    "authorId": "2260270513",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2283185019",
                    "name": "Peter J. Liu"
                },
                {
                    "authorId": "2282609388",
                    "name": "Joshua Robinson"
                },
                {
                    "authorId": "2131041347",
                    "name": "Christopher Rytting"
                },
                {
                    "authorId": "2253653120",
                    "name": "David Wingate"
                },
                {
                    "authorId": "1585276967",
                    "name": "Leveraging"
                },
                {
                    "authorId": "2909575",
                    "name": "Amrita Saha"
                },
                {
                    "authorId": "7591930",
                    "name": "Vardaan Pahuja"
                },
                {
                    "authorId": "2361078",
                    "name": "Mitesh M. Khapra"
                },
                {
                    "authorId": "145590185",
                    "name": "Karthik Sankaranarayanan"
                },
                {
                    "authorId": "2285868436",
                    "name": "Victor Sanh"
                },
                {
                    "authorId": "1991019030",
                    "name": "Albert Webson"
                },
                {
                    "authorId": "2260131842",
                    "name": "Stephen H. Bach"
                },
                {
                    "authorId": null,
                    "name": "Lintang Sutawika"
                },
                {
                    "authorId": "25098419",
                    "name": "Zaid Alyafeai"
                },
                {
                    "authorId": "2260103542",
                    "name": "Antoine Chaffin"
                },
                {
                    "authorId": "114762823",
                    "name": "Arnaud Stiegler"
                },
                {
                    "authorId": "2805456",
                    "name": "Saleh Soltan"
                },
                {
                    "authorId": "2773408",
                    "name": "Shankar Ananthakrishnan"
                },
                {
                    "authorId": "2282970441",
                    "name": "Jack FitzGer-ald"
                },
                {
                    "authorId": "2261363543",
                    "name": "Rahul Gupta"
                },
                {
                    "authorId": "2282542682",
                    "name": "Wael Hamza"
                },
                {
                    "authorId": "102648923",
                    "name": "Charith Peris"
                },
                {
                    "authorId": "38696444",
                    "name": "Stephen Rawls"
                },
                {
                    "authorId": "146177177",
                    "name": "Andrew Rosenbaum"
                },
                {
                    "authorId": "1471909492",
                    "name": "Nathan Scales"
                },
                {
                    "authorId": "3094520",
                    "name": "Nathanael Sch\u00e4rli"
                },
                {
                    "authorId": "2265058484",
                    "name": "Sebastian Gehrmann"
                },
                {
                    "authorId": "2282528643",
                    "name": "Won Chung"
                },
                {
                    "authorId": "2841893",
                    "name": "Aakanksha Chowdhery"
                },
                {
                    "authorId": "2261982078",
                    "name": "V. Quoc"
                },
                {
                    "authorId": "2282542612",
                    "name": "Ed H Le"
                },
                {
                    "authorId": "2282542324",
                    "name": "Chi"
                },
                {
                    "authorId": "2282542248",
                    "name": "Denny"
                },
                {
                    "authorId": "2113243762",
                    "name": "Hugo Touvron"
                },
                {
                    "authorId": "2249724552",
                    "name": "Louis Martin"
                },
                {
                    "authorId": "2282542714",
                    "name": "Kevin Stone"
                },
                {
                    "authorId": "2282542430",
                    "name": "Peter Al-bert"
                },
                {
                    "authorId": "2634674",
                    "name": "Amjad Almahairi"
                },
                {
                    "authorId": "2223764353",
                    "name": "Yasmine Babaei"
                },
                {
                    "authorId": "2223756247",
                    "name": "Nikolay Bashlykov"
                },
                {
                    "authorId": "47505161",
                    "name": "Soumya Batra"
                },
                {
                    "authorId": "51229603",
                    "name": "Prajjwal Bhargava"
                },
                {
                    "authorId": "2116473",
                    "name": "Shruti Bhosale"
                },
                {
                    "authorId": "2265492068",
                    "name": "Daniel M. Bikel"
                },
                {
                    "authorId": "2040305955",
                    "name": "Lukas Blecher"
                },
                {
                    "authorId": "66286536",
                    "name": "Cristian Cant\u00f3n Ferrer"
                },
                {
                    "authorId": "2108267192",
                    "name": "Moya Chen"
                },
                {
                    "authorId": "7153363",
                    "name": "Guillem Cucurull"
                },
                {
                    "authorId": "71039937",
                    "name": "David Esiobu"
                },
                {
                    "authorId": "2166312768",
                    "name": "Jude Fernandes"
                },
                {
                    "authorId": "2223974989",
                    "name": "Jeremy Fu"
                },
                {
                    "authorId": "2223742000",
                    "name": "Wenyin Fu"
                },
                {
                    "authorId": "2223748737",
                    "name": "Brian Fuller"
                },
                {
                    "authorId": "2107063269",
                    "name": "Cynthia Gao"
                },
                {
                    "authorId": "28554843",
                    "name": "Vedanuj Goswami"
                },
                {
                    "authorId": "39589154",
                    "name": "Naman Goyal"
                },
                {
                    "authorId": "2129047988",
                    "name": "Anthony Hartshorn"
                },
                {
                    "authorId": "2268759462",
                    "name": "Saghar Hosseini"
                },
                {
                    "authorId": "2266467782",
                    "name": "Rui Hou"
                },
                {
                    "authorId": "2065277797",
                    "name": "Hakan Inan"
                },
                {
                    "authorId": "2059886128",
                    "name": "Marcin Kardas"
                },
                {
                    "authorId": "2190957318",
                    "name": "Viktor Kerkez"
                },
                {
                    "authorId": "2072010",
                    "name": "Madian Khabsa"
                },
                {
                    "authorId": "2207049",
                    "name": "Isabel M. Kloumann"
                },
                {
                    "authorId": "2282542614",
                    "name": "Punit Artem Korenev"
                },
                {
                    "authorId": "2257006866",
                    "name": "Singh Koura"
                },
                {
                    "authorId": "114952298",
                    "name": "Marie-Anne Lachaux"
                },
                {
                    "authorId": "46183616",
                    "name": "Thibaut Lavril"
                },
                {
                    "authorId": "2223749565",
                    "name": "Jenya Lee"
                },
                {
                    "authorId": "2145259939",
                    "name": "Diana Liskovich"
                },
                {
                    "authorId": "2282552151",
                    "name": "Yinghai Lu"
                },
                {
                    "authorId": "2272672481",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "2282542625",
                    "name": "Xavier Mar-tinet"
                },
                {
                    "authorId": "39980906",
                    "name": "Todor Mihaylov"
                },
                {
                    "authorId": "2282543499",
                    "name": "Pushkar Mishra"
                },
                {
                    "authorId": "2282542598",
                    "name": "Igor Moly-bog"
                },
                {
                    "authorId": "2282534534",
                    "name": "Yixin Nie"
                },
                {
                    "authorId": "2282542314",
                    "name": "Andrew Poulton"
                },
                {
                    "authorId": "2282542912",
                    "name": "Jeremy Reizen-stein"
                },
                {
                    "authorId": "150282885",
                    "name": "Rashi Rungta"
                },
                {
                    "authorId": "1859294",
                    "name": "Kalyan Saladi"
                },
                {
                    "authorId": "2282590360",
                    "name": "Alex Wang"
                },
                {
                    "authorId": "100984698",
                    "name": "Yada Pruksachatkun"
                },
                {
                    "authorId": "10666396",
                    "name": "Nikita Nangia"
                },
                {
                    "authorId": "2282545790",
                    "name": "Amanpreet Singh"
                },
                {
                    "authorId": "2282543048",
                    "name": "Julian Michael"
                },
                {
                    "authorId": "2282542691",
                    "name": "Felix Hill"
                },
                {
                    "authorId": "2253752918",
                    "name": "Omer Levy"
                },
                {
                    "authorId": "2266751652",
                    "name": "Samuel R. Bowman"
                },
                {
                    "authorId": "2282542375",
                    "name": "Superglue"
                },
                {
                    "authorId": "2282545790",
                    "name": "Amanpreet Singh"
                },
                {
                    "authorId": "2282528790",
                    "name": "Felix"
                },
                {
                    "authorId": "81970097",
                    "name": "Wanjun Zhong"
                },
                {
                    "authorId": "2282538909",
                    "name": "Ruixiang Cui"
                },
                {
                    "authorId": "2214448244",
                    "name": "Yiduo Guo"
                },
                {
                    "authorId": "2265433813",
                    "name": "Yaobo Liang"
                },
                {
                    "authorId": "2269746913",
                    "name": "Shuai Lu"
                },
                {
                    "authorId": "2282668595",
                    "name": "Yanlin Wang"
                },
                {
                    "authorId": "2282542305",
                    "name": "Amin Saied"
                },
                {
                    "authorId": "2249538838",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "2282542317",
                    "name": "Nan Duan. 2023"
                }
            ]
        },
        {
            "paperId": "5b3991fe7d8f6fc0a7fbd42938e2988ea37efe14",
            "title": "Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model",
            "abstract": "We introduce Transfusion, a recipe for training a multi-modal model over discrete and continuous data. Transfusion combines the language modeling loss function (next token prediction) with diffusion to train a single transformer over mixed-modality sequences. We pretrain multiple Transfusion models up to 7B parameters from scratch on a mixture of text and image data, establishing scaling laws with respect to a variety of uni- and cross-modal benchmarks. Our experiments show that Transfusion scales significantly better than quantizing images and training a language model over discrete image tokens. By introducing modality-specific encoding and decoding layers, we can further improve the performance of Transfusion models, and even compress each image to just 16 patches. We further demonstrate that scaling our Transfusion recipe to 7B parameters and 2T multi-modal tokens produces a model that can generate images and text on a par with similar scale diffusion models and language models, reaping the benefits of both worlds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110714400",
                    "name": "Chunting Zhou"
                },
                {
                    "authorId": "2296724476",
                    "name": "Lili Yu"
                },
                {
                    "authorId": "2237983657",
                    "name": "Arun Babu"
                },
                {
                    "authorId": "2551387",
                    "name": "Kushal Tirumala"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2316490131",
                    "name": "Leonid Shamis"
                },
                {
                    "authorId": "2316491370",
                    "name": "Jacob Kahn"
                },
                {
                    "authorId": "2316671133",
                    "name": "Xuezhe Ma"
                },
                {
                    "authorId": "2239106612",
                    "name": "Luke Zettlemoyer"
                },
                {
                    "authorId": "2296719126",
                    "name": "Omer Levy"
                }
            ]
        },
        {
            "paperId": "c29aa2e58d91e733685914b40eadb83d719c59dd",
            "title": "STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases",
            "abstract": "Answering real-world complex queries, such as complex product search, often requires accurate retrieval from semi-structured knowledge bases that involve blend of unstructured (e.g., textual descriptions of products) and structured (e.g., entity relations of products) information. However, previous works have mostly studied textual and relational retrieval tasks as separate topics. To address the gap, we develop STARK, a large-scale Semi-structure retrieval benchmark on Textual and Relational K nowledge Bases. Our benchmark covers three domains/datasets: product search, academic paper search, and queries in precision medicine. We design a novel pipeline to synthesize realistic user queries that integrate diverse relational information and complex textual properties, together with their ground-truth answers (items). We conduct rigorous human evaluation to validate the quality of our synthesized queries. We further enhance the benchmark with high-quality human-generated queries to provide an authentic reference. STARK serves as a comprehensive testbed for evaluating the performance of retrieval systems driven by large language models (LLMs). Our experiments suggest that STARK presents significant challenges to the current retrieval and LLM systems, indicating the demand for building more capable retrieval systems. The benchmark data and code are available on https://github.com/snap-stanford/stark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774538",
                    "name": "Shirley Wu"
                },
                {
                    "authorId": "2297830746",
                    "name": "Shiyu Zhao"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "48865984",
                    "name": "Kaidi Cao"
                },
                {
                    "authorId": "2302855404",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2265619476",
                    "name": "James Zou"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "db22b645cb9d213095089a9ba88d02d18e6543a6",
            "title": "AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval",
            "abstract": "Large language model (LLM) agents have demonstrated impressive capability in utilizing external tools and knowledge to boost accuracy and reduce hallucinations. However, developing the prompting techniques that make LLM agents able to effectively use external tools and knowledge is a heuristic and laborious task. Here, we introduce AvaTaR, a novel and automatic framework that optimizes an LLM agent to effectively use the provided tools and improve its performance on a given task/domain. During optimization, we design a comparator module to iteratively provide insightful and holistic prompts to the LLM agent via reasoning between positive and negative examples sampled from training data. We demonstrate AvaTaR on four complex multimodal retrieval datasets featuring textual, visual, and relational information. We find AvaTaR consistently outperforms state-of-the-art approaches across all four challenging tasks and exhibits strong generalization ability when applied to novel cases, achieving an average relative improvement of 14% on the Hit@1 metric. Code and dataset are available at https://github.com/zou-group/avatar.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774538",
                    "name": "Shirley Wu"
                },
                {
                    "authorId": "2297830746",
                    "name": "Shiyu Zhao"
                },
                {
                    "authorId": "2302855404",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "2265619476",
                    "name": "James Zou"
                }
            ]
        },
        {
            "paperId": "e8e694137e71f8008cb6a570b0ea3e557a8938fb",
            "title": "Language Models are Graph Learners",
            "abstract": "Language Models (LMs) are increasingly challenging the dominance of domain-specific models, including Graph Neural Networks (GNNs) and Graph Transformers (GTs), in graph learning tasks. Following this trend, we propose a novel approach that empowers off-the-shelf LMs to achieve performance comparable to state-of-the-art GNNs on node classification tasks, without requiring any architectural modification. By preserving the LM's original architecture, our approach retains a key benefit of LM instruction tuning: the ability to jointly train on diverse datasets, fostering greater flexibility and efficiency. To achieve this, we introduce two key augmentation strategies: (1) Enriching LMs' input using topological and semantic retrieval methods, which provide richer contextual information, and (2) guiding the LMs' classification process through a lightweight GNN classifier that effectively prunes class candidates. Our experiments on real-world datasets show that backbone Flan-T5 models equipped with these augmentation strategies outperform state-of-the-art text-output node classifiers and are comparable to top-performing vector-output node classifiers. By bridging the gap between specialized task-specific node classifiers and general LMs, this work paves the way for more versatile and widely applicable graph learning models. We will open-source the code upon publication.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2324221216",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "2443055",
                    "name": "Kaveh Hassani"
                },
                {
                    "authorId": "2293449673",
                    "name": "Si Zhang"
                },
                {
                    "authorId": "2324910963",
                    "name": "Hanqing Zeng"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2324063263",
                    "name": "Limei Wang"
                },
                {
                    "authorId": "2324009031",
                    "name": "Dongqi Fu"
                },
                {
                    "authorId": "2324058738",
                    "name": "Ning Yao"
                },
                {
                    "authorId": "2324056941",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2294365662",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "07b14c24833400b79978b0a5f084803337e30a15",
            "title": "REPLUG: Retrieval-Augmented Black-Box Language Models",
            "abstract": "We introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented LMs that train language models with special cross-attention mechanisms to encode the retrieved text, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This simple design can be easily applied to any existing language models. Furthermore, we show that the LM can be used to supervise the retrieval model, which can then find documents that help the LM make better predictions. Our experiments demonstrate that REPLUG with the tuned retriever significantly improves the performance of GPT-3 (175B) on language modeling by 6.3%, as well as the performance of Codex on five-shot MMLU by 5.1%. Code is publicly released at github.com/swj0419/REPLUG.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3040379",
                    "name": "Weijia Shi"
                },
                {
                    "authorId": "48872685",
                    "name": "Sewon Min"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "4418074",
                    "name": "Minjoon Seo"
                },
                {
                    "authorId": "2191899140",
                    "name": "Rich James"
                },
                {
                    "authorId": "35084211",
                    "name": "M. Lewis"
                },
                {
                    "authorId": "1982950",
                    "name": "Luke Zettlemoyer"
                },
                {
                    "authorId": "2072801764",
                    "name": "Wen-tau Yih"
                }
            ]
        },
        {
            "paperId": "1a527ac2736239019a9aedd3494443d5a22b57ad",
            "title": "Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models",
            "abstract": "Language models have been shown to exhibit positive scaling, where performance improves as models are scaled up in terms of size, compute, or data. In this work, we introduce NeQA, a dataset consisting of questions with negation in which language models do not exhibit straightforward positive scaling. We show that this task can exhibit inverse scaling, U-shaped scaling, or positive scaling, and the three scaling trends shift in this order as we use more powerful prompting methods or model families. We hypothesize that solving NeQA depends on two subtasks: question answering (task 1) and negation understanding (task 2). We find that task 1 has linear scaling, while task 2 has sigmoid-shaped scaling with an emergent transition point, and composing these two scaling trends yields the final scaling trend of NeQA. Our work reveals and provides a way to analyze the complex scaling trends of language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49889860",
                    "name": "Yuhui Zhang"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "48741571",
                    "name": "Zhengping Zhou"
                },
                {
                    "authorId": "134168070",
                    "name": "Jeff Z. HaoChen"
                },
                {
                    "authorId": "145085305",
                    "name": "James Y. Zou"
                },
                {
                    "authorId": "145419642",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "34149749",
                    "name": "Serena Yeung"
                }
            ]
        },
        {
            "paperId": "299a77bf4050c9686d35b905b96d8902734845c5",
            "title": "Holistic Evaluation of Text-To-Image Models",
            "abstract": "The stunning qualitative improvement of recent text-to-image models has led to their widespread attention and adoption. However, we lack a comprehensive quantitative understanding of their capabilities and risks. To fill this gap, we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models (HEIM). Whereas previous evaluations focus mostly on text-image alignment and image quality, we identify 12 aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios encompassing these aspects and evaluate 26 state-of-the-art text-to-image models on this benchmark. Our results reveal that no single model excels in all aspects, with different models demonstrating different strengths. We release the generated images and human evaluation results for full transparency at https://crfm.stanford.edu/heim/v1.1.0 and the code at https://github.com/stanford-crfm/helm, which is integrated with the HELM codebase.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110585783",
                    "name": "Tony Lee"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "83262128",
                    "name": "Chenlin Meng"
                },
                {
                    "authorId": "2054708905",
                    "name": "Yifan Mai"
                },
                {
                    "authorId": "2197475360",
                    "name": "Joon Sung Park"
                },
                {
                    "authorId": "2265716291",
                    "name": "Agrim Gupta"
                },
                {
                    "authorId": "2261420360",
                    "name": "Yunzhi Zhang"
                },
                {
                    "authorId": "2251007290",
                    "name": "Deepak Narayanan"
                },
                {
                    "authorId": "2186054469",
                    "name": "H. Teufel"
                },
                {
                    "authorId": "1438952071",
                    "name": "Marco Bellagente"
                },
                {
                    "authorId": "2153110145",
                    "name": "Minguk Kang"
                },
                {
                    "authorId": "2071929129",
                    "name": "Taesung Park"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "2250994799",
                    "name": "Jun-Yan Zhu"
                },
                {
                    "authorId": "2253964624",
                    "name": "Fei-Fei Li"
                },
                {
                    "authorId": "3045089",
                    "name": "Jiajun Wu"
                },
                {
                    "authorId": "2490652",
                    "name": "Stefano Ermon"
                },
                {
                    "authorId": "2249641250",
                    "name": "Percy Liang"
                }
            ]
        }
    ]
}