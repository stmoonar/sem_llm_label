{
    "authorId": "1704274486",
    "papers": [
        {
            "paperId": "09a543ca9d84b7c7f70f4ac7de048f92b7bc9659",
            "title": "ICE-SEARCH: A Language Model-Driven Feature Selection Approach",
            "abstract": "This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, which is among the first works that melds large language models (LLMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LLMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. The study emphasizes the critical role of incorporating domain-specific insights, illustrating ICE-SEARCH's robustness, generalizability, and convergence. This opens avenues for further research into comprehensive and intricate FS landscapes, marking a significant stride in the application of artificial intelligence in medical predictive analytics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121655341",
                    "name": "T. Yang"
                },
                {
                    "authorId": "2218989289",
                    "name": "Tim Tianyi Yang"
                },
                {
                    "authorId": "2283319154",
                    "name": "Shaoshan Liu"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2180038312",
                    "name": "Xue Liu"
                }
            ]
        },
        {
            "paperId": "0ba0acf039e6c99930dd85931fc58ee043006503",
            "title": "RevisEval: Improving LLM-as-a-Judge via Response-Adapted References",
            "abstract": "With significant efforts in recent studies, LLM-as-a-Judge has become a cost-effective alternative to human evaluation for assessing the text generation quality in a wide range of tasks. However, there still remains a reliability gap between LLM-as-a-Judge and human evaluation. One important reason is the lack of guided oracles in the evaluation process. Motivated by the role of reference pervasively used in classic text evaluation, we introduce RevisEval, a novel text generation evaluation paradigm via the response-adapted references. RevisEval is driven by the key observation that an ideal reference should maintain the necessary relevance to the response to be evaluated. Specifically, RevisEval leverages the text revision capabilities of large language models (LLMs) to adaptively revise the response, then treat the revised text as the reference (response-adapted reference) for the subsequent evaluation. Extensive experiments demonstrate that RevisEval outperforms traditional reference-free and reference-based evaluation paradigms that use LLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks. More importantly, our response-adapted references can further boost the classical text metrics, e.g., BLEU and BERTScore, compared to traditional references and even rival the LLM-as-a-Judge. A detailed analysis is also conducted to confirm RevisEval's effectiveness in bias reduction, the impact of inference cost, and reference relevance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2309202396",
                    "name": "Qiyuan Zhang"
                },
                {
                    "authorId": "2249908560",
                    "name": "Yufei Wang"
                },
                {
                    "authorId": null,
                    "name": "Tiezheng YU"
                },
                {
                    "authorId": null,
                    "name": "Yuxin Jiang"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2307468483",
                    "name": "Liangyou Li"
                },
                {
                    "authorId": "2282544603",
                    "name": "Yasheng Wang"
                },
                {
                    "authorId": null,
                    "name": "Xin Jiang"
                },
                {
                    "authorId": "2238661808",
                    "name": "Lifeng Shang"
                },
                {
                    "authorId": "2284295184",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2324831308",
                    "name": "Chen Ma"
                }
            ]
        },
        {
            "paperId": "161438c5cf4412eeb0e551c2ea4f16c5123de1fa",
            "title": "Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation",
            "abstract": "As user behaviors become complicated on business platforms, online recommendations focus more on how to touch the core conversions, which are highly related to the interests of platforms. These core conversions are usually continuous targets, such as \\textit{watch time}, \\textit{revenue}, and so on, whose predictions can be enhanced by previous discrete conversion actions. Therefore, multi-task learning (MTL) can be adopted as the paradigm to learn these hybrid targets. However, existing works mainly emphasize investigating the sequential dependence among discrete conversion actions, which neglects the complexity of dependence between discrete conversions and the final continuous conversion. Moreover, simultaneously optimizing hybrid tasks with stronger task dependence will suffer from volatile issues where the core regression task might have a larger influence on other tasks. In this paper, we study the MTL problem with hybrid targets for the first time and propose the model named Hybrid Targets Learning Network (HTLNet) to explore task dependence and enhance optimization. Specifically, we introduce label embedding for each task to explicitly transfer the label information among these tasks, which can effectively explore logical task dependence. We also further design the gradient adjustment regime between the final regression task and other classification tasks to enhance the optimization. Extensive experiments on two offline public datasets and one real-world industrial dataset are conducted to validate the effectiveness of HTLNet. Moreover, online A/B tests on the financial recommender system also show that our model has improved significantly. Our implementation is available here\\footnote{\\url{https://github.com/fuyuanlyu/HTLNet}}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2204648054",
                    "name": "Yang Qiao"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2257136810",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                }
            ]
        },
        {
            "paperId": "36c87f474378d3b352dc125d22cec672fd3c54c3",
            "title": "MultiFS: Automated Multi-Scenario Feature Selection in Deep Recommender Systems",
            "abstract": "Multi-scenario recommender systems (MSRSs) have been increasingly used in real-world industrial platforms for their excellent advantages in mitigating data sparsity and reducing maintenance costs. However, conventional MSRSs usually use all relevant features indiscriminately and ignore that different kinds of features have varying importance under different scenarios, which may cause confusion and performance degradation. In addition, existing feature selection methods for deep recommender systems may lack the exploration of scenario relations. In this paper, we propose a novel automated multi-scenario feature selection (MultiFS) framework to bridge this gap, which is able to consider scenario relations and utilize a hierarchical gating mechanism to select features for each scenario. Specifically, MultiFS first efficiently obtains feature importance across all the scenarios through a scenario-shared gate. Then, some scenario-specific gate aims to identify feature importance to individual scenarios from a subset of the former with lower importance. Subsequently, MultiFS imposes constraints on the two gates to make the learning mechanism more feasible and combines the two to select exclusive features for different scenarios. We evaluate MultiFS and demonstrate its ability to enhance the multi-scenario model performance through experiments over two public multi-scenario benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2290696975",
                    "name": "Chaohua Yang"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2261426672",
                    "name": "Weihong Luo"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2240535483",
                    "name": "Zhong Ming"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "4c51430adfe11ff9f56399b710178d8b12411430",
            "title": "Collaborative Performance Prediction for Large Language Models",
            "abstract": "Comprehensively understanding and accurately predicting the performance of large language models across diverse downstream tasks has emerged as a pivotal challenge in NLP research. The pioneering scaling law on downstream works demonstrated intrinsic similarities within model families and utilized such similarities for performance prediction. However, they tend to overlook the similarities between model families and only consider design factors listed in the original scaling law. To overcome these limitations, we introduce a novel framework, Collaborative Performance Prediction (CPP), which significantly enhances prediction accuracy by leveraging the historical performance of various models on downstream tasks and other design factors for both model and task. We also collect a collaborative data sourced from online platforms containing both historical performance and additional design factors. With the support of the collaborative data, CPP not only surpasses traditional scaling laws in predicting the performance of scaled LLMs but also facilitates a detailed analysis of factor importance, an area previously overlooked.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2309202396",
                    "name": "Qiyuan Zhang"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2261661544",
                    "name": "Chen Ma"
                }
            ]
        },
        {
            "paperId": "ca457e9b0ba0680659ed02c9d12a48c8f7d8cab9",
            "title": "Mixed-Precision Embeddings for Large-Scale Recommendation Models",
            "abstract": "Embedding techniques have become essential components of large databases in the deep learning era. By encoding discrete entities, such as words, items, or graph nodes, into continuous vector spaces, embeddings facilitate more efficient storage, retrieval, and processing in large databases. Especially in the domain of recommender systems, millions of categorical features are encoded as unique embedding vectors, which facilitates the modeling of similarities and interactions among features. However, numerous embedding vectors can result in significant storage overhead. In this paper, we aim to compress the embedding table through quantization techniques. Given that features vary in importance levels, we seek to identify an appropriate precision for each feature to balance model accuracy and memory usage. To this end, we propose a novel embedding compression method, termed Mixed-Precision Embeddings (MPE). Specifically, to reduce the size of the search space, we first group features by frequency and then search precision for each feature group. MPE further learns the probability distribution over precision levels for each feature group, which can be used to identify the most suitable precision with a specially designed sampling strategy. Extensive experiments on three public datasets demonstrate that MPE significantly outperforms existing embedding compression methods. Remarkably, MPE achieves about 200x compression on the Criteo dataset without comprising the prediction accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2195780326",
                    "name": "Shiwei Li"
                },
                {
                    "authorId": "2323521242",
                    "name": "Zhuoqi Hu"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2315079186",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2312867341",
                    "name": "Haozhao Wang"
                },
                {
                    "authorId": "2315248559",
                    "name": "Shijie Xu"
                },
                {
                    "authorId": "2261426672",
                    "name": "Weihong Luo"
                },
                {
                    "authorId": "2315068141",
                    "name": "Yuhua Li"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2283487404",
                    "name": "Ruixuan Li"
                }
            ]
        },
        {
            "paperId": "ca93750afdfa7046cc58c9a4cdccf151d44b60cf",
            "title": "Toward a Better Understanding of Fourier Neural Operators: Analysis and Improvement from a Spectral Perspective",
            "abstract": "In solving partial differential equations (PDEs), Fourier Neural Operators (FNOs) have exhibited notable effectiveness compared to Convolutional Neural Networks (CNNs). This paper presents clear empirical evidence through spectral analysis to elucidate the superiority of FNO over CNNs: FNO is significantly more capable of learning low-frequencies. This empirical evidence also unveils FNO\u2019s distinct low-frequency bias, which limits FNO\u2019s effectiveness in learning high-frequency information from PDE data. To tackle this challenge, we introduce SpecBoost, an ensemble learning framework that employs multiple FNOs to better capture high-frequency information. Specifically, a secondary FNO is utilized to learn the overlooked high-frequency information from the prediction residual of the initial FNO. Experiments demonstrate that SpecBoost noticeably enhances FNO\u2019s prediction accuracy on diverse PDE applications, achieving an up to 71% improvement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2228007098",
                    "name": "Shaoxiang Qin"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2295991423",
                    "name": "Wenhui Peng"
                },
                {
                    "authorId": "2295887116",
                    "name": "Dingyang Geng"
                },
                {
                    "authorId": "2295930515",
                    "name": "Ju Wang"
                },
                {
                    "authorId": "2258104176",
                    "name": "Naiping Gao"
                },
                {
                    "authorId": "2231079523",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2295845338",
                    "name": "L. Wang"
                }
            ]
        },
        {
            "paperId": "f0159325283ab5b80e0adcb5986688239dab21f5",
            "title": "OptDist: Learning Optimal Distribution for Customer Lifetime Value Prediction",
            "abstract": "Customer Lifetime Value (CLTV) prediction is a critical task in business applications. Accurately predicting CLTV is challenging in real-world business scenarios, as the distribution of CLTV is complex and mutable. Firstly, there is a large number of users without any consumption consisting of a long-tailed part that is too complex to fit. Secondly, the small set of high-value users spent orders of magnitude more than a typical user leading to a wide range of the CLTV distribution which is hard to capture in a single distribution. Existing approaches for CLTV estimation either assume a prior probability distribution and fit a single group of distribution-related parameters for all samples, or directly learn from the posterior distribution with manually predefined buckets in a heuristic manner. However, all these methods fail to handle complex and mutable distributions. In this paper, we propose a novel optimal distribution selection model OptDist for CLTV prediction, which utilizes an adaptive optimal sub-distribution selection mechanism to improve the accuracy of complex distribution modeling. Specifically, OptDist trains several candidate sub-distribution networks in the distribution learning module (DLM) for modeling the probability distribution of CLTV. Then, a distribution selection module (DSM) is proposed to select the sub-distribution for each sample, thus making the selection automatically and adaptively. Besides, we design an alignment mechanism that connects both modules, which effectively guides the optimization. We conduct extensive experiments on both two public and one private dataset to verify that OptDist outperforms state-of-the-art baselines. Furthermore, OptDist has been deployed on a large-scale financial platform for customer acquisition marketing campaigns and the online experiments also demonstrate the effectiveness of OptDist.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "81049933",
                    "name": "Yunpeng Weng"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2316368318",
                    "name": "Zhenhao Xu"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2257136810",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2257124500",
                    "name": "Zexu Sun"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                }
            ]
        },
        {
            "paperId": "8abd7b17824f19e1632939f1cc03e3223f675e52",
            "title": "Optimizing Feature Set for Click-Through Rate Prediction",
            "abstract": "Click-through prediction (CTR) models transform features into latent vectors and enumerate possible feature interactions to improve performance based on the input feature set. Therefore, when selecting an optimal feature set, we should consider the influence of both features and their interaction. However, most previous works focus on either feature field selection or only select feature interaction based on the fixed feature set to produce the feature set. The former restricts search space to the feature field, which is too coarse to determine subtle features. They also do not filter useless feature interactions, leading to higher computation costs and degraded model performance. The latter identifies useful feature interaction from all available features, resulting in many redundant features in the feature set. In this paper, we propose a novel method named OptFS to address these problems. To unify the selection of features and their interaction, we decompose the selection of each feature interaction into the selection of two correlated features. Such a decomposition makes the model end-to-end trainable given various feature interaction operations. By adopting feature-level search space, we set a learnable gate to determine whether each feature should be within the feature set. Because of the large-scale search space, we develop a learning-by-continuation training scheme to learn such gates. Hence, OptFS generates the feature set containing features that improve the final prediction results. Experimentally, we evaluate OptFS on three public datasets, demonstrating OptFS can optimize feature sets which enhance the model performance and further reduce both the storage and computational cost.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2109888596",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": null,
                    "name": "Liang Chen"
                },
                {
                    "authorId": "1996703",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                }
            ]
        },
        {
            "paperId": "9a38c738a9bca9144dd8aaf34cd0a154d1a63abc",
            "title": "Feature Representation Learning for Click-through Rate Prediction: A Review and New Perspectives",
            "abstract": "Representation learning has been a critical topic in machine learning. In Click-through Rate Prediction, most features are represented as embedding vectors and learned simultaneously with other parameters in the model. With the development of CTR models, feature representation learning has become a trending topic and has been extensively studied by both industrial and academic researchers in recent years. This survey aims at summarizing the feature representation learning in a broader picture and pave the way for future research. To achieve such a goal, we first present a taxonomy of current research methods on feature representation learning following two main issues: (i) which feature to represent and (ii) how to represent these features. Then we give a detailed description of each method regarding these two issues. Finally, the review concludes with a discussion on the future directions of this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2109888596",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "107747459",
                    "name": "Haolun Wu"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "1996703",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                }
            ]
        }
    ]
}