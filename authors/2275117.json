{
    "authorId": "2275117",
    "papers": [
        {
            "paperId": "0c07bc508311e768580c2d8d87eb733afd2a5717",
            "title": "ACL Ready: RAG Based Assistant for the ACL Checklist",
            "abstract": "The ARR Responsible NLP Research checklist website states that the\"checklist is designed to encourage best practices for responsible research, addressing issues of research ethics, societal impact and reproducibility.\"Answering the questions is an opportunity for authors to reflect on their work and make sure any shared scientific assets follow best practices. Ideally, considering the checklist before submission can favorably impact the writing of a research paper. However, the checklist is often filled out at the last moment. In this work, we introduce ACLReady, a retrieval-augmented language model application that can be used to empower authors to reflect on their work and assist authors with the ACL checklist. To test the effectiveness of the system, we conducted a qualitative study with 13 users which shows that 92% of users found the application useful and easy to use as well as 77% of the users found that the application provided the information they expected. Our code is publicly available under the CC BY-NC 4.0 license on GitHub.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315811643",
                    "name": "Michael Galarnyk"
                },
                {
                    "authorId": "2315811378",
                    "name": "Rutwik Routu"
                },
                {
                    "authorId": "2315811463",
                    "name": "Kosha Bheda"
                },
                {
                    "authorId": "2315811240",
                    "name": "Priyanshu Mehta"
                },
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "43db5699f341339f35cc58fda0b45010bb04f161",
            "title": "Numerical Claim Detection in Finance: A New Financial Dataset, Weak-Supervision Model, and Market Analysis",
            "abstract": "In this paper, we investigate the influence of claims in analyst reports and earnings calls on financial market returns, considering them as significant quarterly events for publicly traded companies. To facilitate a comprehensive analysis, we construct a new financial dataset for the claim detection task in the financial domain. We benchmark various language models on this dataset and propose a novel weak-supervision model that incorporates the knowledge of subject matter experts (SMEs) in the aggregation function, outperforming existing approaches. We also demonstrate the practical utility of our proposed model by constructing a novel measure of optimism. Here, we observe the dependence of earnings surprise and return on our optimism measure. Our dataset, models, and code are publicly (under CC BY 4.0 license) available on GitHub.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2226127129",
                    "name": "Arnav Hiray"
                },
                {
                    "authorId": "2153533908",
                    "name": "Pratvi Shah"
                },
                {
                    "authorId": "2284671367",
                    "name": "Arkaprabha Banerjee"
                },
                {
                    "authorId": "2284766427",
                    "name": "Anushka Singh"
                },
                {
                    "authorId": "2284689634",
                    "name": "Dheeraj Eidnani"
                },
                {
                    "authorId": "2284689182",
                    "name": "Bhaskar Chaudhury"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "582054d50242a08e3a551defac83ceed94872d1f",
            "title": "CoCoHD: Congress Committee Hearing Dataset",
            "abstract": "U.S. congressional hearings significantly influence the national economy and social fabric, impacting individual lives. Despite their importance, there is a lack of comprehensive datasets for analyzing these discourses. To address this, we propose the Congress Committee Hearing Dataset (CoCoHD), covering hearings from 1997 to 2024 across 86 committees, with 32,697 records. This dataset enables researchers to study policy language on critical issues like healthcare, LGBTQ+ rights, and climate justice. We demonstrate its potential with a case study on 1,000 energy-related sentences, analyzing the Energy and Commerce Committee's stance on fossil fuel consumption. By fine-tuning pre-trained language models, we create energy-relevant measures for each hearing. Our market analysis shows that natural language analysis using CoCoHD can predict and highlight trends in the energy sector.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2226127129",
                    "name": "Arnav Hiray"
                },
                {
                    "authorId": "2219749997",
                    "name": "Yunsong Liu"
                },
                {
                    "authorId": null,
                    "name": "Mingxiao Song"
                },
                {
                    "authorId": null,
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "5fa230579616993cb25c40aac4ed265f745c2926",
            "title": "Saliency-Aware Interpolative Augmentation for Multimodal Financial Prediction",
            "abstract": "Predicting price variations of financial instruments for risk modeling and stock trading is challenging due to the stochastic nature of the stock market. While recent advancements in the Financial AI realm have expanded the scope of data and methods they use, such as textual and audio cues from financial earnings calls, limitations exist. Most datasets are small, and show domain distribution shifts due to the nature of their source, suggesting the exploration for data augmentation for robust augmentation strategies such as Mixup. To tackle such challenges in the financial domain, we propose SH-Mix: Saliency-guided Hierarchical Mixup augmentation technique for multimodal financial prediction tasks. SH-Mix combines multi-level embedding mixup strategies based on the contribution of each modality and context subsequences. Through extensive quantitative and qualitative experiments on financial earnings and conference call datasets consisting of text and speech, we show that SH-Mix outperforms state-of-the-art methods by 3-7%. Additionally, we show that SH-Mix is generalizable across different modalities and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302368303",
                    "name": "Samyak Jain"
                },
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "782b6fc0f7db0f4d5a2c033d84f824c04d0bed5d",
            "title": "The Universal NFT Vector Database: A Scaleable Vector Database for NFT Similarity Matching",
            "abstract": "Non-Fungible Tokens (NFTs) are a type of digital asset that represents a proof of ownership over a particular digital item such as art, music, or real estate. Due to the non-fungible nature of NFTs, duplicate tokens should not possess the same value. However, with the surge of new blockchains and a massive influx of NFTs being created, a wealth of NFT data is being generated without a method of tracking similarity. This enables people to create almost identical NFTs by changing one pixel or one byte of data. Despite the similarity among NFTs, each NFT is assigned a completely different token ID. To address the NFT duplication issue, we developed a modular, easily-extendable, hardware-agnostic, cloud-centered NFT processing system that represents NFTs as vectors. We established a database containing a vector representation of the NFTs in accordance with the Ethereum Request for Comment 721 (ERC-721) token standards to initiate the process of aggregating NFT data from various blockchains. Finally, we developed an NFT visualization dashboard application with a user-friendly graphical user interface (GUI) to provide non-technical users access to the aggregated NFT data. The Universal NFT Vector Database is an off-chain framework for NFT data aggregation based on similarity, which provides an organized way to query and analyze NFT data that was previously unavailable through on-chain solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66577045",
                    "name": "S. Sahoo"
                },
                {
                    "authorId": "2212094848",
                    "name": "Nitin Paul"
                },
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2167127702",
                    "name": "Andrew Hornback"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "7dcb732c92e9c5b53aff482e543db4909dfa62dc",
            "title": "Learning Through Interpolative Augmentation of Dynamic Curvature Spaces",
            "abstract": "Mixup is an efficient data augmentation technique, which improves generalization by interpolating random examples. While numerous approaches have been developed for Mixup in the Euclidean and in the hyperbolic space, they do not fully use the intrinsic properties of the examples, i.e., they manually set the geometry (Euclidean or hyperbolic) based on the overall dataset, which may be sub-optimal since each example may require a different geometry. We propose DynaMix, a framework that automatically selects an example-specific geometry and performs Mixup between the different geometries to improve training dynamics and generalization. Through extensive experiments in image and text modalities we show that DynaMix outperforms state-of-the-art methods over six downstream applications. We find that DynaMix is more useful in low-resource and semi-supervised settings likely because it displays a probabilistic view of the geometry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "c478c9bbbca2c8702205c39adc1098628f4fb901",
            "title": "Abnormal Trading Detection in the NFT Market",
            "abstract": "The Non-Fungible-Token (NFT) market has experienced explosive growth in recent years. According to DappRadar, the total transaction volume on OpenSea, the largest NFT marketplace, reached 34.7 billion dollars in February 2023. However, the NFT market is mostly unregulated and there are significant concerns about money laundering, fraud and wash trading. The lack of industry-wide regulations, and the fact that amateur traders and retail investors comprise a significant fraction of the NFT market, make this market particularly vulnerable to fraudulent activities. Therefore it is essential to investigate and highlight the relevant risks involved in NFT trading. In this paper, we attempted to uncover common fraudulent behaviors such as wash trading that could mislead other traders. Using market data, we designed quantitative features from the network, monetary, and temporal perspectives that were fed into K-means clustering unsupervised learning algorithm to sort traders into groups. Lastly, we discussed the clustering results' significance and how regulations can reduce undesired behaviors. Our work can potentially help regulators narrow down their search space for bad actors in the market as well as provide insights for amateur traders to protect themselves from unforeseen frauds.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "2152128021",
                    "name": "Ming-da Song"
                },
                {
                    "authorId": "2219749997",
                    "name": "Yunsong Liu"
                },
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "ccf45bf1e3d1b040cb28af274ba0e4fe97927616",
            "title": "Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis",
            "abstract": "Monetary policy pronouncements by Federal Open Market Committee (FOMC) are a major driver of financial market returns. We construct the largest tokenized and annotated dataset of FOMC speeches, meeting minutes, and press conference transcripts in order to understand how monetary policy influences financial markets. In this study, we develop a novel task of hawkish-dovish classification and benchmark various pre-trained language models on the proposed dataset. Using the best-performing model (RoBERTa-large), we construct a measure of monetary policy stance for the FOMC document release days. To evaluate the constructed measure, we study its impact on the treasury market, stock market, and macroeconomic indicators. Our dataset, models, and code are publicly available on Huggingface and GitHub under CC BY-NC 4.0 license.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2217251616",
                    "name": "Suvan Paturi"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "df7d7e71eba619363e7dbe8b14f4baeb3100ca73",
            "title": "Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks",
            "abstract": "Recently large language models (LLMs) like ChatGPT have shown impressive performance on many natural language processing tasks with zero-shot. In this paper, we investigate the effectiveness of zero-shot LLMs in the financial domain. We compare the performance of ChatGPT along with some open-source generative LLMs in zero-shot mode with RoBERTa fine-tuned on annotated data. We address three inter-related research questions on data annotation, performance gaps, and the feasibility of employing generative models in the finance domain. Our findings demonstrate that ChatGPT performs well even without labeled data but fine-tuned models generally outperform it. Our research also highlights how annotating with generative models can be time-intensive. Our codebase is publicly available on GitHub under CC BY-NC 4.0 license.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "f9d4bfe5618b920a47d39be894658fb4275541ab",
            "title": "FiNER-ORD: Financial Named Entity Recognition Open Research Dataset",
            "abstract": "Over the last two decades, the development of the CoNLL-2003 named entity recognition (NER) dataset has helped enhance the capabilities of deep learning and natural language processing (NLP). The finance domain, characterized by its unique semantic and lexical variations for the same entities, presents specific challenges to the NER task; thus, a domain-specific customized dataset is crucial for advancing research in this field. In our work, we develop the first high-quality English Financial NER Open Research Dataset (FiNER-ORD). We benchmark multiple pre-trained language models (PLMs) and large-language models (LLMs) on FiNER-ORD. We believe our proposed FiNER-ORD dataset will open future opportunities to use FiNER-ORD as a benchmark for financial domain-specific NER and NLP tasks. Our dataset, models, and code are publicly available on GitHub and Hugging Face under CC BY-NC 4.0 license.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6099396",
                    "name": "Agam Shah"
                },
                {
                    "authorId": "2209192762",
                    "name": "Ruchit Vithani"
                },
                {
                    "authorId": "2209191130",
                    "name": "Abhinav Gullapalli"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        }
    ]
}