{
    "authorId": "143858195",
    "papers": [
        {
            "paperId": "1cdc55380d2df7c12154466c5e76207d01d651dd",
            "title": "Trusting Decentralised Knowledge Graphs and Web Data at the Web Conference",
            "abstract": "Knowledge Graphs have become a foundation for sharing data on the web and building intelligent services across many sectors and also within some of the most successful corporations in the world. The over centralisation of data on the web, however, has been raised as a concern by a number of prominent researchers in the field. For example, at the beginning of 2022 a \u20ac2.7B civil lawsuit was launched against Meta on the basis that it has abused its market dominance to impose unfair terms and conditions on UK users in order to exploit their personal data. Data centralisation can lead to a number of problems including: lock-in/siloing effects, lack of user control over their personal data, limited incentives and opportunities for interoperability and openness, and the resulting detrimental effects on privacy and innovation. A number of diverse approaches and technologies exist for decentralising data, such as federated querying and distributed ledgers. The main question is, though, what does decentralisation really mean for web data and Knowledge Graphs? What are the main issues and tradeoffs involved? These questions and others are addressed in this workshop.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41223762",
                    "name": "J. Domingue"
                },
                {
                    "authorId": "2190195962",
                    "name": "Aisling Third"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "40568510",
                    "name": "P. Rohde"
                },
                {
                    "authorId": "2215621354",
                    "name": "Juan Cano"
                },
                {
                    "authorId": "3413290",
                    "name": "Andrea Cimmino"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "47bdd56f051b3c37fa21370d8755afac94a21ff7",
            "title": "Towards Certified Distributed Query Processing",
            "abstract": "In recent years, knowledge graphs (KGs) have gained more and more importance. As a consequence of that, the number of publicly accessible KGs is increasing. Due to their adoption in many areas, KGs are used in numerous different applications. However, these knowledge graph applications are not developed by the data owners and they might collect data from several linked KGs. It is therefore essential that systems accessing KGs are certified, i.e., each component is certified for a specific use by an entity or agency. In addition, a trace of the performed operations and used data is needed in order to verify that all requirements were met, e.g., some data cannot be transferred from the source to any other component due to privacy restrictions. This work describes the vision of certified distributed querying in the context of an analytics platform. Challenges for such systems are identified and discussed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40568510",
                    "name": "P. Rohde"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                }
            ]
        },
        {
            "paperId": "507395c2a54eff2925109bb0696a4960a581c433",
            "title": "Efficient Semantic Summary Graphs for Querying Large Knowledge Graphs",
            "abstract": "Knowledge Graphs (KGs) integrate heterogeneous data, but one challenge is the development of efficient tools for allowing end users to extract useful insights from these sources of knowledge. In such a context, reducing the size of a Resource Description Framework (RDF) graph while preserving all information can speed up query engines by limiting data shuffle, especially in a distributed setting. This paper presents two algorithms for RDF graph summarization: Grouping Based Summarization (GBS) and Query Based Summarization (QBS). The latter is an optimized and lossless approach for the former method. We empirically study the effectiveness of the proposed lossless RDF graph summarization to retrieve complete data, by rewriting an RDF Query Language called SPARQL query with fewer triple patterns using a semantic similarity. We conduct our experimental study in instances of four datasets with different sizes. Compared with the state-of-the-art query engine Sparklify executed over the original RDF graphs as a baseline, QBS query execution time is reduced by up to 80% and the summarized RDF graph is decreased by up to 99%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65774124",
                    "name": "E. Niazmand"
                },
                {
                    "authorId": "3451795",
                    "name": "Gezim Sejdiu"
                },
                {
                    "authorId": "2235966",
                    "name": "D. Graux"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                }
            ]
        },
        {
            "paperId": "5449c3542d1b28e4ba65817568fc6f89e36a6b5e",
            "title": "Dragoman: Efficiently Evaluating Declarative Mapping Languages over Frameworks for Knowledge Graph Creation",
            "abstract": "In recent years, there have been valuable efforts and contributions to make the process of RDF knowledge graph creation traceable and transparent; extending and applying declarative mapping languages is an example. One challenging step is the traceability of procedures that aim to overcome interoperability issues, a.k.a. data-level integration. In most pipelines, data integration is performed by ad-hoc programs, preventing traceability and reusability. However, formal frameworks provided by function-based declarative mapping languages such as FunUL and RML+FnO empower expressiveness. Data-level integration can be defined as functions and integrated as part of the mappings performing schema-level integration. However, combining functions with the mappings introduces a new source of complexity that can considerably impact the required number of resources and execution time. We tackle the problem of efficiently executing mappings with functions and formalize the transformation of them into function-free mappings. These transformations are the basis of an optimization process that aims to perform an eager evaluation of function-based mapping rules. These techniques are implemented in a framework named Dragoman. We demonstrate the correctness of the transformations while ensuring that the function-free data integration processes are equivalent to the original one. The effectiveness of Dragoman is empirically evaluated in 230 testbeds composed of various types of functions integrated with mapping rules of different complexity. The outcomes suggest that evaluating function-free mapping rules reduces execution time in complex knowledge graph creation pipelines composed of large data sources and multiple types of mapping rules. The savings can be up to 75%, suggesting that eagerly executing functions in mapping rules enable making these pipelines applicable and scalable in real-world settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51879080",
                    "name": "S. Jozashoori"
                },
                {
                    "authorId": "2069254138",
                    "name": "Enrique Iglesias"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                }
            ]
        },
        {
            "paperId": "625940b142939d7521959364e413cb60d22270e4",
            "title": "Leibniz Data Manager - A Research Data Management System",
            "abstract": ". FAIR principles aim to enhance machine-actionability of research data management, and enable data consumers and providers to scale up to incoming data avalanches. This demo paper describes Leibniz Data Manager (LDM), a research data management repository that re-sorts to Semantic Web technologies to empower FAIR principles. During the demonstration, the attendees will create various digital objects, and observe the crucial role of metadata in efficient and effective management and analysis of research data management. LDM is publicly available: https://service.tib.eu/ldmservice/ .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051282531",
                    "name": "A. Beer"
                },
                {
                    "authorId": "2171862861",
                    "name": "Mauricio Brunet"
                },
                {
                    "authorId": "2162252176",
                    "name": "Vibhav Srivastava"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                }
            ]
        },
        {
            "paperId": "6c47e91d52cfe85b3f4d1df9827a6e6a97c2e675",
            "title": "Traditional Machine Learning Models and Bidirectional Encoder Representations From Transformer (BERT)\u2013Based Automatic Classification of Tweets About Eating Disorders: Algorithm Development and Validation Study",
            "abstract": "Background Eating disorders affect an increasing number of people. Social networks provide information that can help. Objective We aimed to find machine learning models capable of efficiently categorizing tweets about eating disorders domain. Methods We collected tweets related to eating disorders, for 3 consecutive months. After preprocessing, a subset of 2000 tweets was labeled: (1) messages written by people suffering from eating disorders or not, (2) messages promoting suffering from eating disorders or not, (3) informative messages or not, and (4) scientific or nonscientific messages. Traditional machine learning and deep learning models were used to classify tweets. We evaluated accuracy, F1 score, and computational time for each model. Results A total of 1,058,957 tweets related to eating disorders were collected. were obtained in the 4 categorizations, with The bidirectional encoder representations from transformer\u2013based models had the best score among the machine learning and deep learning techniques applied to the 4 categorization tasks (F1 scores 71.1%-86.4%). Conclusions Bidirectional encoder representations from transformer\u2013based models have better performance, although their computational cost is significantly higher than those of traditional techniques, in classifying eating disorder\u2013related tweets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1404826354",
                    "name": "J. Ben\u00edtez-Andrades"
                },
                {
                    "authorId": "1411032718",
                    "name": "Jos\u00e9-Manuel Alija-P\u00e9rez"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "1405628745",
                    "name": "R. Pastor-Vargas"
                },
                {
                    "authorId": "1403838858",
                    "name": "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s"
                }
            ]
        },
        {
            "paperId": "bf1a54d6f2e8429c3cd8b6508d0a7c128a50f53c",
            "title": "Resorting to Context-Aware Background Knowledge for Unveiling Semantically Related Social Media Posts",
            "abstract": "Social media networks have become a prime source for sharing news, opinions, and research accomplishments in various domains, and hundreds of millions of posts are announced daily. Given this wealth of information in social media, finding related announcements has become a relevant task, particularly in trending news (e.g., COVID-19 or lung cancer). To facilitate the search of connected posts, social networks enable users to annotate their posts, e.g., with hashtags in tweets. Albeit effective, an annotation-based search is limited because results will only include the posts that share the same annotations. This paper focuses on retrieving context-related posts based on a specific topic, and presents PINYON, a knowledge-driven framework, that retrieves associated posts effectively. PINYON implements a two-fold pipeline. First, it encodes, in a graph, a CORPUS of posts and an input post; posts are annotated with entities for existing knowledge graphs and connected based on the similarity of their entities. In a decoding phase, the encoded graph is used to discover communities of related posts. We cast this problem into the Vertex Coloring Problem, where communities of similar posts include the posts annotated with entities colored with the same colors. Built on results reported in the graph theory, PINYON implements the decoding phase guided by a heuristic-based method that determines relatedness among posts based on contextual knowledge, and efficiently groups the most similar posts in the same communities. PINYON is empirically evaluated on various datasets and compared with state-of-the-art implementations of the decoding phase. The quality of the generated communities is also analyzed based on multiple metrics. The observed outcomes indicate that PINYON accurately identifies semantically related posts in different contexts. Moreover, the reported results put in perspective the impact of known properties about the optimality of existing heuristics for vertex graph coloring and their implications on PINYON scalability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30966265",
                    "name": "Ahmad Sakor"
                },
                {
                    "authorId": "145447998",
                    "name": "Kuldeep Singh"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                }
            ]
        },
        {
            "paperId": "0339e90fef88b048dd93032458aabdf353a8ee99",
            "title": "Reuse of Semantic Models for Emerging Smart Grids Applications",
            "abstract": "\u2014Data in the energy domain grows at unprecedented rates. Despite the great potential that IoT platforms and other big data-driven technologies have brought in the energy sector, data exchange and data integration are still not wholly achieved. As a result, fragmented applications are developed against energy data silos, and data exchange is limited to few applications. Therefore, this paper identifies semantic models that can be reused for building interoperable energy management services and applications. The ambition is to innovate the Institute Mihajlo Pupin proprietary SCADA system and to enable integration of PUPIN services/applications in the European Union (EU) Energy Data Space. The selection of reusable models has been done based on a set of scenarios related to electricity balancing services, predictive maintenance services, and services for residential, commercial and industrial sector.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2667608",
                    "name": "V. Janev"
                },
                {
                    "authorId": "2119542322",
                    "name": "Duvsan Popadi'c"
                },
                {
                    "authorId": "2119541850",
                    "name": "Dea Puji'c"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "3319633",
                    "name": "Kemele M. Endris"
                }
            ]
        },
        {
            "paperId": "2e8ec76fdfefcfe0cf79629ab0604bdd3109268f",
            "title": "Analyzing a Knowledge Graph of Industry\u00a04.0 Standards",
            "abstract": "Realizing smart factories according to the Industry 4.0 vision requires intelligent human-to-machine and machine-to-machine communication. To achieve this goal, components such as actuators, sensors, and cyber-physical systems along with their data, need to be described; moreover, interoperability conflicts arisen from various semantic representations of these components demand also solutions. To empowering communication in smart factories, a variety of standards and standardization frameworks have been proposed. These standards enable the description of the main properties of components, systems, and processes, as well as interactions between them. Standardization frameworks classify, align, and integrate industrial standards according to their purposes and features. Various standardization frameworks have been proposed all over the world by industrial communities, e.g., RAMI4.0 or IICF. While being expressive to categorize existing standards, standardization frameworks may present divergent classifications of the same standard. Mismatches between standard classifications generate semantic interoperability conflicts that negatively impact the effectiveness of communication in smart factories. In this article, we tackle the problem of standard interoperability across different standardization frameworks, and devise a knowledge-driven approach that allows for the description of standards and standardization frameworks into an Industry 4.0 knowledge graph (I40KG). The STO ontology represents properties of standards and standardization frameworks, as well as relationships among them. The I40KG integrates more than 200 standards and four standardization frameworks. To populate the I40KG, the landscape of standards has been analyzed from a semantic perspective and the resulting I40KG represents knowledge expressed in more than 200 industrial related documents including technical reports, research articles, and white papers. Additionally, the I40KG has been linked to existing knowledge graphs and an automated reasoning has been implemented to reveal implicit relations between standards as well as mappings across standardization frameworks. We analyze both the number of discovered relations between standards and the accuracy of these relations. Observed results indicate that both reasoning and linking processes enable for increasing the connectivity in the knowledge graph by up to 80%, whilst up to 96% of the relations can be validated. These outcomes suggest that integrating standards and standardization frameworks into the I40KG enables the resolution of semantic interoperability conflicts, empowering the communication in smart factories.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2667608",
                    "name": "V. Janev"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "3319633",
                    "name": "Kemele M. Endris"
                },
                {
                    "authorId": "1380440942",
                    "name": "Dea Puji\u0107"
                }
            ]
        },
        {
            "paperId": "336be1446bb0f1bb5d370f256fef2ebaf370b5fb",
            "title": "Discover Relations in the Industry 4.0 Standards Via Unsupervised Learning on Knowledge Graph Embeddings",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143741471",
                    "name": "Ariam Rivas"
                },
                {
                    "authorId": "1403922102",
                    "name": "Irl\u00e1n Grangel-Gonz\u00e1lez"
                },
                {
                    "authorId": "2553511",
                    "name": "D. Collarana"
                },
                {
                    "authorId": "71564931",
                    "name": "Jens Lehmann"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                }
            ]
        }
    ]
}