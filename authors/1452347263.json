{
    "authorId": "1452347263",
    "papers": [
        {
            "paperId": "29632ece419ac9537d8b3caadfa9edd3812392a2",
            "title": "Knowledge-Enhanced Causal Reinforcement Learning Model for Interactive Recommendation",
            "abstract": "Owing to its inherently dynamic nature and economical training cost, offline reinforcement learning (RL) is typically employed to implement an interactive recommender system (IRS). A crucial challenge in offline RL-based IRSs is the data sparsity issue, i.e., it is hard to mine user preferences well from the limited number of user-item interactions. In this article, we propose a knowledge-enhanced causal reinforcement learning model (KCRL) to mitigate data sparsity in IRSs. We make technical extensions to the offline RL framework in terms of the reward function and state representation. Specifically, we first propose a group preference-injected causal user model (GCUM) to learn user satisfaction (i.e., reward) estimation. We introduce beneficial group preference information, namely, the group effect, via causal inference to compensate for incomplete user interests extracted from sparse data. Then, we learn the RL recommendation policy with the reward given by the GCUM. We propose a knowledge-enhanced state encoder (KSE) to generate knowledge-enriched user state representations at each time step, which is assisted by a self-constructed user-item knowledge graph. Extensive experimental results on real-world datasets demonstrate that our model significantly outperforms the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144536249",
                    "name": "Weizhi Nie"
                },
                {
                    "authorId": "47631470",
                    "name": "Xin-ling Wen"
                },
                {
                    "authorId": "46701354",
                    "name": "J. Liu"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "1491035012",
                    "name": "Jiancan Wu"
                },
                {
                    "authorId": "2071128650",
                    "name": "Guoqing Jin"
                },
                {
                    "authorId": "2217839403",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2118791811",
                    "name": "Anjin Liu"
                }
            ]
        },
        {
            "paperId": "1051cfeef92a22250f05dc5bda87b8c4856f389b",
            "title": "Spatiotemporal Multiscale Correlation Embedding With Process Variable Reorder for Industrial Soft Sensing",
            "abstract": "Soft sensor techniques have been extensively utilized for predicting key variables in the process industry. To extract fine-grained and holistic features for efficient prediction, proper modeling strategies for multiscale spatial and temporal correlations are heavily desired. In this article, we summarize the multiscale correlations as a short and long temporal dependency, local and global spatial relevance, and spatiotemporal coupled correlations. Such correlations should be explicitly and comprehensively characterized as different key variables often require diverse or multiscale spatiotemporal features. To this end, a spatiotemporal multiscale correlation embedding (STMCE) framework is proposed for soft sensing with characterization and refining of multiscale spatial and temporal features. On the one hand, we design a reorder data patch embedding (RDPE) strategy to extract local spatiotemporal coupled correlations by reordering the permutation of process variables and embedding local correlations into high-dimensional vectors. On the other hand, we propose a global feature fusion and refining network (GFFRNet) via a self-attention mechanism and feature refining technique, which enables the model to effectively aggregate and privilege predictive features for key variable prediction. Superior to existing methods that partially focus on spatial or temporal dependencies, our approach explicitly models both local and global spatiotemporal coupled relevance under a multiscale perspective, encouraging the model to explore more fine-grained and comprehensive information from process data and further improve prediction accuracy. In comparison with ten baseline models, our STMCE empirically presents the state-of-the-art results on both benchmark and real-world industrial datasets, for example, obtaining a relative MAE reduction of 13.32% compared with the second-best method in the benchmark multiphase flow dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "2057359684",
                    "name": "Pengyu Song"
                },
                {
                    "authorId": "2115602412",
                    "name": "Chunhui Zhao"
                },
                {
                    "authorId": "33981635",
                    "name": "Jinliang Ding"
                }
            ]
        },
        {
            "paperId": "14cbf1cfd5dd4b451bfd6ef89e2bc277799df9bd",
            "title": "Alleviating Matthew Effect of Offline Reinforcement Learning in Interactive Recommendation",
            "abstract": "Offline reinforcement learning (RL), a technology that offline learns a policy from logged data without the need to interact with online environments, has become a favorable choice in decision-making processes like interactive recommendation. Offline RL faces the value overestimation problem. To address it, existing methods employ conservatism, e.g., by constraining the learned policy to be close to behavior policies or punishing the rarely visited state-action pairs. However, when applying such offline RL to recommendation, it will cause a severe Matthew effect, i.e., the rich get richer and the poor get poorer, by promoting popular items or categories while suppressing the less popular ones. It is a notorious issue that needs to be addressed in practical recommender systems. In this paper, we aim to alleviate the Matthew effect in offline RL-based recommendation. Through theoretical analyses, we find that the conservatism of existing methods fails in pursuing users' long-term satisfaction. It inspires us to add a penalty term to relax the pessimism on states with high entropy of the logging policy and indirectly penalizes actions leading to less diverse states. This leads to the main technical contribution of the work: Debiased model-based Offline RL (DORL) method. Experiments show that DORL not only captures user interests well but also alleviates the Matthew effect. The implementation is available via https://github.com/chongminggao/DORL-codes",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31446099",
                    "name": "Chongming Gao"
                },
                {
                    "authorId": "2112441120",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2156072391",
                    "name": "Biao Li"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "2108622235",
                    "name": "Shiqin Wang"
                },
                {
                    "authorId": "2221728472",
                    "name": "Zhong Zhang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "28fa51f1b70869c1c8f610b25ddb841c83a8de2b",
            "title": "Discriminative-Invariant Representation Learning for Unbiased Recommendation",
            "abstract": "Selection bias hinders recommendation models from learning unbiased user preference. Recent works empirically reveal that pursuing invariant user and item representation across biased and unbiased data is crucial for counteracting selection bias. However, our theoretical analysis reveals that simply optimizing representation invariance is insufficient for addressing the selection bias \u2014 recommendation performance is bounded by both representation invariance and discriminability. Worse still, current invariant representation learning methods in recommendation neglect even hurt the representation discriminability due to data sparsity and label shift. In this light, we propose a new Discriminative-Invariant Representation Learning framework for unbiased recommendation, which incorporates label-conditional clustering and prior-guided contrasting into conventional invariant representation learning to mitigate the impact of data sparsity and label shift, respectively. We conduct extensive experiments on three real-world datasets, validating the rationality and effectiveness of the proposed framework. Code and supplementary materials are available at: https://github.com/HungPaan/DIRL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2230045941",
                    "name": "Hang Pan"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2153422494",
                    "name": "Wentao Shi"
                },
                {
                    "authorId": "8612672",
                    "name": "Junkang Wu"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "3eb2dbe48eaa1406ab4e4bb90f094e70eda85738",
            "title": "A Generic Learning Framework for Sequential Recommendation with Distribution Shifts",
            "abstract": "Leading sequential recommendation (SeqRec) models adopt empirical risk minimization (ERM) as the learning framework, which inherently assumes that the training data (historical interaction sequences) and the testing data (future interactions) are drawn from the same distribution. However, such i.i.d. assumption hardly holds in practice, due to the online serving and dynamic nature of recommender system.For example, with the streaming of new data, the item popularity distribution would change, and the user preference would evolve after consuming some items. Such distribution shifts could undermine the ERM framework, hurting the model's generalization ability for future online serving. In this work, we aim to develop a generic learning framework to enhance the generalization of recommenders in the dynamic environment. Specifically, on top of ERM, we devise a Distributionally Robust Optimization mechanism for SeqRec (DROS). At its core is our carefully-designed distribution adaption paradigm, which considers the dynamics of data distribution and explores possible distribution shifts between training and testing. Through this way, we can endow the backbone recommenders with better generalization ability.It is worth mentioning that DROS is an effective model-agnostic learning framework, which is applicable to general recommendation scenarios.Theoretical analyses show that DROS enables the backbone recommenders to achieve robust performance in future testing data.Empirical studies verify the effectiveness against dynamic distribution shifts of DROS. Codes are anonymously open-sourced at https://github.com/YangZhengyi98/DROS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150358651",
                    "name": "Zhengyi Yang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "1491035012",
                    "name": "Jiancan Wu"
                },
                {
                    "authorId": "2113821128",
                    "name": "Xin Xin"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "2144796537",
                    "name": "Xiang Wang"
                }
            ]
        },
        {
            "paperId": "4f03688df8997e1f4b5aeaf81f44242390ea5c27",
            "title": "Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community",
            "abstract": "The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights. This paper provides a summary of the workshop's outcomes, including the rethinking of IR's core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                },
                {
                    "authorId": "143831387",
                    "name": "Ting Bai"
                },
                {
                    "authorId": "2106400572",
                    "name": "Zhao Cao"
                },
                {
                    "authorId": "2131636065",
                    "name": "Yi Chang"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "1721165",
                    "name": "Zhumin Chen"
                },
                {
                    "authorId": "13167100",
                    "name": "Zhiyong Cheng"
                },
                {
                    "authorId": "1752810",
                    "name": "Shoubin Dong"
                },
                {
                    "authorId": "1897235",
                    "name": "Zhicheng Dou"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2112313769",
                    "name": "Shengling Gao"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "37510256",
                    "name": "Yanyan Lan"
                },
                {
                    "authorId": "2829009",
                    "name": "Chenliang Li"
                },
                {
                    "authorId": "1783406",
                    "name": "Yiqun Liu"
                },
                {
                    "authorId": "1920802076",
                    "name": "Ziyu Lyu"
                },
                {
                    "authorId": "2903964",
                    "name": "Weizhi Ma"
                },
                {
                    "authorId": "2152611495",
                    "name": "Jun Ma"
                },
                {
                    "authorId": "2780667",
                    "name": "Z. Ren"
                },
                {
                    "authorId": "1749477",
                    "name": "Pengjie Ren"
                },
                {
                    "authorId": "2108331735",
                    "name": "Zhiqiang Wang"
                },
                {
                    "authorId": "143894230",
                    "name": "Min Wang"
                },
                {
                    "authorId": "2113341834",
                    "name": "Jirong Wen"
                },
                {
                    "authorId": "1734221",
                    "name": "Lei Wu"
                },
                {
                    "authorId": "2113821128",
                    "name": "Xin Xin"
                },
                {
                    "authorId": "2150636233",
                    "name": "Jun Xu"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2151333116",
                    "name": "Peng Zhang"
                },
                {
                    "authorId": "50212920",
                    "name": "Fan Zhang"
                },
                {
                    "authorId": "2157434730",
                    "name": "Wei-na Zhang"
                },
                {
                    "authorId": "39767557",
                    "name": "M. Zhang"
                },
                {
                    "authorId": "2125161115",
                    "name": "Xiaofei Zhu"
                }
            ]
        },
        {
            "paperId": "60fc6adff977fcf0222bc4f140ad8117bd462b32",
            "title": "Adap-\u03c4 : Adaptively Modulating Embedding Magnitude for Recommendation",
            "abstract": "Recent years have witnessed the great successes of embedding-based methods in recommender systems. Despite their decent performance, we argue one potential limitation of these methods \u2014 the embedding magnitude has not been explicitly modulated, which may aggravate popularity bias and training instability, hindering the model from making a good recommendation. It motivates us to leverage the embedding normalization in recommendation. By normalizing user/item embeddings to a specific value, we empirically observe impressive performance gains (9% on average) on four real-world datasets. Although encouraging, we also reveal a serious limitation when applying normalization in recommendation \u2014 the performance is highly sensitive to the choice of the temperature \u03c4 which controls the scale of the normalized embeddings. To fully foster the merits of the normalization while circumvent its limitation, this work studied on how to adaptively set the proper \u03c4. Towards this end, we first make a comprehensive analyses of \u03c4 to fully understand its role on recommendation. We then accordingly develop an adaptive fine-grained strategy Adap-\u03c4 for the temperature with satisfying four desirable properties including adaptivity, personalized, efficiency and model-agnostic. Extensive experiments have been conducted to validate the effectiveness of the proposal. The code is available at https://github.com/junkangwu/Adap_tau.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "8612672",
                    "name": "Junkang Wu"
                },
                {
                    "authorId": "1491035012",
                    "name": "Jiancan Wu"
                },
                {
                    "authorId": "2115867010",
                    "name": "Sheng Zhou"
                },
                {
                    "authorId": "2562591",
                    "name": "Xuezhi Cao"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "773a0eb84f35796f92d2b0e31550b2e3822375bb",
            "title": "FFHR: Fully and Flexible Hyperbolic Representation for Knowledge Graph Completion",
            "abstract": "Learning hyperbolic embeddings for knowledge graph (KG) has gained increasing attention due to its superiority in capturing hierarchies. However, some important operations in hyperbolic space still lack good definitions, making existing methods unable to fully leverage the merits of hyperbolic space. Specifically, they suffer from two main limitations: 1) existing Graph Convolutional Network (GCN) methods in hyperbolic space rely on tangent space approximation, which would incur approximation error in representation learning, and 2) due to the lack of inner product operation definition in hyperbolic space, existing methods can only measure the plausibility of facts (links) with hyperbolic distance, which is difficult to capture complex data patterns. In this work, we contribute: 1) a Full Poincar\\'{e} Multi-relational GCN that achieves graph information propagation in hyperbolic space without requiring any approximation, and 2) a hyperbolic generalization of Euclidean inner product that is beneficial to capture both hierarchical and complex patterns. On this basis, we further develop a \\textbf{F}ully and \\textbf{F}lexible \\textbf{H}yperbolic \\textbf{R}epresentation framework (\\textbf{FFHR}) that is able to transfer recent Euclidean-based advances to hyperbolic space. We demonstrate it by instantiating FFHR with four representative KGC methods. Extensive experiments on benchmark datasets validate the superiority of our FFHRs over their Euclidean counterparts as well as state-of-the-art hyperbolic embedding methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153422494",
                    "name": "Wentao Shi"
                },
                {
                    "authorId": "8612672",
                    "name": "Junkang Wu"
                },
                {
                    "authorId": "2562591",
                    "name": "Xuezhi Cao"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "39165620",
                    "name": "Wenqiang Lei"
                },
                {
                    "authorId": "2118256234",
                    "name": "Wei Wu"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "7abd0788ced88508cc7463952982ec5a6ac6b496",
            "title": "SDTN: Speaker Dynamics Tracking Network for Emotion Recognition in Conversation",
            "abstract": "Emotion Recognition in Conversation (ERC) has considerable prospects due to its wide range of applications. Most existing works integrate speaker information statically and capture a relatively consistent atmosphere in conversation. However, these works poorly track the emotional state dynamics of each party in a conversation and focus on emotion consistency. The speakers\u2019 emotional states are independent but influence each other during the conversation. To address the above issues, we propose a Speaker Dynamics Tracking Network (SDTN) for ERC. Specifically, SDTN can dynamically track the local and global speaker states during emotional flow in conversation and capture implicit stimulation of emotional shift. Extensive experiments on MELD and EmoryNLP datasets demonstrate the superiority and effectiveness of our proposed SDTN model, and confirm that every designed module consistently benefits the performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "1872016",
                    "name": "Peijie Huang"
                },
                {
                    "authorId": "2216487341",
                    "name": "Guotai Huang"
                },
                {
                    "authorId": "2188622377",
                    "name": "Qianer Li"
                },
                {
                    "authorId": "2110176966",
                    "name": "Yuhong Xu"
                }
            ]
        },
        {
            "paperId": "a9914fcdd3fd8e0139f1fd063d71b473bccb531b",
            "title": "On the Theories Behind Hard Negative Sampling for Recommendation",
            "abstract": "Negative sampling has been heavily used to train recommender models on large-scale data, wherein sampling hard examples usually not only accelerates the convergence but also improves the model accuracy. Nevertheless, the reasons for the effectiveness of Hard Negative Sampling (HNS) have not been revealed yet. In this work, we fill the research gap by conducting thorough theoretical analyses on HNS. Firstly, we prove that employing HNS on the Bayesian Personalized Ranking (BPR) learner is equivalent to optimizing One-way Partial AUC (OPAUC). Concretely, the BPR equipped with Dynamic Negative Sampling (DNS) is an exact estimator, while with softmax-based sampling is a soft estimator. Secondly, we prove that OPAUC has a stronger connection with Top-K evaluation metrics than AUC and verify it with simulation experiments. These analyses establish the theoretical foundation of HNS in optimizing Top-K recommendation performance for the first time. On these bases, we offer two insightful guidelines for effective usage of HNS: 1) the sampling hardness should be controllable, e.g., via pre-defined hyper-parameters, to adapt to different Top-K metrics and datasets; 2) the smaller the K we emphasize in Top-K evaluation metrics, the harder the negative samples we should draw. Extensive experiments on three real-world benchmarks verify the two guidelines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153422494",
                    "name": "Wentao Shi"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "8612672",
                    "name": "Junkang Wu"
                },
                {
                    "authorId": "31446099",
                    "name": "Chongming Gao"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        }
    ]
}