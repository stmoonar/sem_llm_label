{
    "authorId": "1772588",
    "papers": [
        {
            "paperId": "08fcc88c211444e27ac634f5e8b0b22c62249c96",
            "title": "Addressing Chest Radiograph Projection Bias in Deep Classification Models",
            "abstract": "Deep learning-based models are widely used for disease classification in chest radiographs. This exam can be performed in one of two projections (posteroanterior or anteroposterior), depending on the direction that the X-ray beam travels through the body. Since projection visibly affects the way anatomical structures appear in the scans, it may introduce bias in classifiers, especially when spurious correlations between a given disease and a projection occur. This paper examines the influence of chest radiograph projection on the performance of deep learning-based classification models and proposes an approach to mitigate projection-induced bias. Results show that a DenseNet-121 model is better at classifying images from the most representative projection in the data set, suggesting that projection is taken into account by the classifier. Moreover, this model can classify chest X-ray projection better than any of the fourteen radiological findings considered, without being explicitly trained for that task, putting it at high risk for projection bias. We propose a label-conditional gradient reversal framework to make the model insensitive to projection, by forcing the extracted features to be simultaneously good for disease classification and bad for projection classification, resulting in a framework with reduced projection-induced bias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130666498",
                    "name": "Sofia Cardoso Pereira"
                },
                {
                    "authorId": "2058128418",
                    "name": "Joana Rocha"
                },
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                },
                {
                    "authorId": "144731836",
                    "name": "A. Mendon\u00e7a"
                }
            ]
        },
        {
            "paperId": "0b5970fd876b52b676f878079b52e7289dc56025",
            "title": "DeepFixCX: Explainable privacy\u2010preserving image compression for medical image analysis",
            "abstract": "Explanations of a model's biases or predictions are essential to medical image analysis. Yet, explainable machine learning approaches for medical image analysis are challenged by needs to preserve privacy of patient data, and by current trends in deep learning to use unsustainably large models and large datasets. We propose DeepFixCX for explainable and privacy\u2010preserving medical image compression that is nimble and performant. We contribute a review of the field and a conceptual framework for simultaneous privacy and explainability via tools of compression. DeepFixCX compresses images without learning by removing or obscuring spatial and edge information. DeepFixCX is ante\u2010hoc explainable and gives privatized post hoc explanations of spatial and edge bias without accessing the original image. DeepFixCX privatizes images to prevent image reconstruction and mitigate patient re\u2010identification. DeepFixCX is nimble. Compression can occur on a laptop CPU or GPU to compress and privatize 1700 images per second of size 320\u2009\u00d7\u2009320. DeepFixCX enables use of low memory MLP classifiers for vision data; permitting small performance loss gives end\u2010to\u2010end MLP performance over 70\u00d7 faster and batch size over 100\u00d7 larger. DeepFixCX consistently improves predictive classification performance of a Deep Neural Network (DNN) by 0.02 AUC ROC on Glaucoma and Cervix Type detection datasets, and can improve multi\u2010label chest x\u2010ray classification performance in seven of 10 tested settings. In all three datasets, compression to less than 5% of original number of pixels gives matching or improved performance. Our main novelty is to define an explainability versus privacy problem and address it with lossy compression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "2186979527",
                    "name": "Shreshta Mohan"
                },
                {
                    "authorId": "1998967224",
                    "name": "Elvin Johnson"
                },
                {
                    "authorId": "2210047886",
                    "name": "Yuhao Liu"
                },
                {
                    "authorId": "145668048",
                    "name": "P. Costa"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                }
            ]
        },
        {
            "paperId": "1d3d02bea2df5ce75877ea8217f2bedb931052b8",
            "title": "Skeleton Tracking Solutions for a Low-Cost Stroke Rehabilitation Support System",
            "abstract": "Computer systems based on motion assessment are promising solutions to support stroke survivors' autonomous rehabilitation exercises. In this regard, researchers keep trying to achieve engaging and low-cost solutions suitable mainly for home use. Aiming to achieve a system with a minimal technical setup, we compare Microsoft Kinect, OpenPose, and MediaPipe skeleton tracking approaches for upper extremity quality of movement assessment after stroke. We determine if classification models assess accurately exercise performance with OpenPose and MediaPipe data against Kinect, using a dataset of 15 stroke survivors. We compute Root Mean Squared Error to determine the alignment of trajectories and kinematic variables. MediaPipe World Landmarks revealed high alignment with Kinect, revealing to be a potential alternative method.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2078458455",
                    "name": "A. C\u00f3ias"
                },
                {
                    "authorId": "38049774",
                    "name": "Min Hun Lee"
                },
                {
                    "authorId": "2159498436",
                    "name": "Alexandre Bernardino"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                }
            ]
        },
        {
            "paperId": "e00b40a7edac5d5a3b557e26727c62ce98855c26",
            "title": "ExplainFix: Explainable spatially fixed deep networks",
            "abstract": "Is there an initialization for deep networks that requires no learning? ExplainFix adopts two design principles: the \u201cfixed filters\u201d principle that all spatial filter weights of convolutional neural networks can be fixed at initialization and never learned, and the \u201cnimbleness\u201d principle that only few network parameters suffice. We contribute (a) visual model\u2010based explanations, (b) speed and accuracy gains, and (c) novel tools for deep convolutional neural networks. ExplainFix gives key insights that spatially fixed networks should have a steered initialization, that spatial convolution layers tend to prioritize low frequencies, and that most network parameters are not necessary in spatially fixed models. ExplainFix models have up to \u00d7100 fewer spatial filter kernels than fully learned models and matching or improved accuracy. Our extensive empirical analysis confirms that ExplainFix guarantees nimbler models (train up to 17% faster with channel pruning), matching or improved predictive performance (spanning 13 distinct baseline models, four architectures and two medical image datasets), improved robustness to larger learning rate, and robustness to varying model size. We are first to demonstrate that all spatial filters in state\u2010of\u2010the\u2010art convolutional deep networks can be fixed at initialization, not learned.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "145668048",
                    "name": "P. Costa"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                }
            ]
        },
        {
            "paperId": "24e46dbf23e717824a397fcc6d3d3812f522764e",
            "title": "Privacy-preserving Case-based Explanations: Enabling visual interpretability by protecting privacy",
            "abstract": "Deep Learning achieves state-of-the-art results in many domains, yet its black-box nature limits its application to real-world contexts. An intuitive way to improve the interpretability of Deep Learning models is by explaining their decisions with similar cases. However, case-based explanations cannot be used in contexts where the data exposes personal identity, as they may compromise the privacy of individuals. In this work, we identify the main limitations and challenges in the anonymization of case-based explanations of image data through a survey on case-based interpretability and image anonymization methods. We empirically analyze the anonymization methods in regards to their capacity to remove personally identifiable information while preserving relevant semantic properties of the data. Through this analysis, we conclude that most privacy-preserving methods are not sufficiently good to be applied to case-based explanations. To promote research on this topic, we formalize the privacy protection of visual case-based explanations as a multi-objective problem to preserve privacy, intelligibility, and relevant explanatory evidence regarding a predictive task. We empirically verify the potential of interpretability saliency maps as qualitative evaluation tools for anonymization. Finally, we identify and propose new lines of research to guide future work in the generation of privacy-preserving case-based explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2138004124",
                    "name": "Helena Montenegro"
                },
                {
                    "authorId": "153471956",
                    "name": "W. Silva"
                },
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "2623167",
                    "name": "Matt Fredrikson"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "144438693",
                    "name": "Jaime S. Cardoso"
                }
            ]
        },
        {
            "paperId": "27cebebd6ed50686048935013cb0affc27291a3b",
            "title": "HeartSpot: Privatized and Explainable Data Compression for Cardiomegaly Detection",
            "abstract": "Advances in data-driven deep learning for chest X-ray image analysis underscore the need for explainability, privacy, large datasets and significant computational resources. We frame privacy and explainability as a lossy single-image compression problem to reduce both computational and data requirements without training. For Cardiomegaly detection in chest X-ray images, we propose HeartSpot and four spatial bias priors. HeartSpot priors define how to sample pixels based on domain knowledge from medical literature and from machines. HeartSpot privatizes chest X-ray images by discarding up to 97% of pixels, such as those that reveal the shape of the thoracic cage, bones, small lesions and other sensitive features. HeartSpot priors are ante-hoc explainable and give a human-interpretable image of the preserved spatial features that clearly outlines the heart. HeartSpot offers strong compression, with up to 32x fewer pixels and 11 $x$ smaller filesize. Cardiomegaly detectors using HeartSpot are up to 9x faster to train or at least as accurate (up to +.01 AUC ROC) when compared to a baseline DenseNet121. HeartSpot is post-hoc explainable by re-using existing attribution methods without requiring access to the original non-privatized image. In summary, HeartSpot improves speed and accuracy, reduces image size, improves privacy and ensures explainability.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1998967224",
                    "name": "Elvin Johnson"
                },
                {
                    "authorId": "2186979527",
                    "name": "Shreshta Mohan"
                },
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                }
            ]
        },
        {
            "paperId": "66229e455796dfc89a472f92fd555ab617e7c095",
            "title": "Towards Efficient Annotations for a Human-AI Collaborative, Clinical Decision Support System: A Case Study on Physical Stroke Rehabilitation Assessment",
            "abstract": "Artificial intelligence (AI) and machine learning (ML) algorithms are increasingly being explored to support various decision-making tasks in health (e.g. rehabilitation assessment). However, the development of such AI/ML-based decision support systems is challenging due to the expensive process to collect an annotated dataset. In this paper, we describe the development process of a human-AI collaborative, clinical decision support system that augments an ML model with a rule-based (RB) model from domain experts. We conducted its empirical evaluation in the context of assessing physical stroke rehabilitation with the dataset of three exercises from 15 post-stroke survivors and therapists. Our results bring new insights on the efficient development and annotations of a decision support system: when an annotated dataset is not available initially, the RB model can be used to assess post-stroke survivor\u2019s quality of motion and identify samples with low confidence scores to support efficient annotations for training an ML model. Specifically, our system requires only 22 - 33% of annotations from therapists to train an ML model that achieves equally good performance with an ML model with all annotations from a therapist. Our work discusses the values of a human-AI collaborative approach for effectively collecting an annotated dataset and supporting a complex decision-making task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38049774",
                    "name": "Min Hun Lee"
                },
                {
                    "authorId": "1742634",
                    "name": "D. Siewiorek"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "2159498436",
                    "name": "Alexandre Bernardino"
                },
                {
                    "authorId": "8584037",
                    "name": "S. Badia"
                }
            ]
        },
        {
            "paperId": "8520892f859e783533a0da731cb575466425307a",
            "title": "Explainable Deep Learning for Non-Invasive Detection of Pulmonary Artery Hypertension from Heart Sounds",
            "abstract": "Late diagnoses of patients affected by pulmonary artery hypertension (PH) have a poor outcome. This observation has led to a call for earlier, non-invasive PH detection. Cardiac auscultation offers a non-invasive and cost-effective alternative to both right heart catheterization and doppler analysis in analysis of PH. We propose to detect PH via analysis of digital heart sound recordings with over-parameterized deep neural networks. In contrast with previous approaches in the literature, we assess the impact of a pre-processing step aiming to separate S2 sound into the aortic (A2) and pulmonary (P2) components. We obtain an area under the ROC curve of. 95, improving over our adaptation of a state-of-the-art Gaussian mixture model PH detector by +.17. Post-hoc explanations and analysis show that the availability of separated A2 and P2 components contributes significantly to prediction. Analysis of stethoscope heart sound recordings with deep networks is an effective, low-cost and non-invasive solution for the detection of pulmonary hypertension.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "101068995",
                    "name": "Miguel Coimbra"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "29841711",
                    "name": "S. Schmidt"
                },
                {
                    "authorId": "2184497726",
                    "name": "F. Renna"
                }
            ]
        },
        {
            "paperId": "61d7e95b1cb2427eac4fb6a76753f4ea8b504e88",
            "title": "Epistemic and Heteroscedastic Uncertainty Estimation in Retinal Blood Vessel Segmentation",
            "abstract": "Current state-of-the-art medical image segmentation methods require high quality datasets to obtain good performance. However, medical specialists often disagree on diagnosis, hence, datasets contain contradictory annotations. This, in turn, leads to difficulties in the optimization process of Deep Learning models and hinder performance. We propose a method to estimate uncertainty in Convolutional Neural Network (CNN) segmentation models, that makes the training of CNNs more robust to contradictory annotations. In this work, we model two types of uncertainty, heteroscedastic and epistemic, without adding any additional supervisory signal other than the ground-truth segmentation mask. As expected, the uncertainty is higher closer to vessel boundaries, and on top of thinner and less visible vessels where it is more likely for medical specialists to disagree. Therefore, our method is more suitable to learn from datasets created with heterogeneous annotators. We show that there is a correlation between the uncertainty estimated by our method and the disagreement in the segmentation provided by two different medical specialists. Furthermore, by explicitly modeling the uncertainty, the Intersection over Union of the segmentation network improves 5.7 percentage points.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145668048",
                    "name": "P. Costa"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "3698192",
                    "name": "Jaime S. Cardoso"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                }
            ]
        },
        {
            "paperId": "9d066b6d59e77d9a781df7672bc3b98ee1f9a350",
            "title": "A Human-AI Collaborative Approach for Clinical Decision Making on Rehabilitation Assessment",
            "abstract": "Advances in artificial intelligence (AI) have made it increasingly applicable to supplement expert\u2019s decision-making in the form of a decision support system on various tasks. For instance, an AI-based system can provide therapists quantitative analysis on patient\u2019s status to improve practices of rehabilitation assessment. However, there is limited knowledge on the potential of these systems. In this paper, we present the development and evaluation of an interactive AI-based system that supports collaborative decision making with therapists for rehabilitation assessment. This system automatically identifies salient features of assessment to generate patient-specific analysis for therapists, and tunes with their feedback. In two evaluations with therapists, we found that our system supports therapists significantly higher agreement on assessment (0.71 average F1-score) than a traditional system without analysis (0.66 average F1-score, p < 0.05). After tuning with therapist\u2019s feedback, our system significantly improves its performance from 0.8377 to 0.9116 average F1-scores (p < 0.01). This work discusses the potential of a human-AI collaborative system to support more accurate decision making while learning from each other\u2019s strengths.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38049774",
                    "name": "Min Hun Lee"
                },
                {
                    "authorId": "1742634",
                    "name": "D. Siewiorek"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "145036494",
                    "name": "Alexandre Bernardino"
                },
                {
                    "authorId": "8584037",
                    "name": "S. Badia"
                }
            ]
        }
    ]
}