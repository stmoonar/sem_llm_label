{
    "authorId": "2248299153",
    "papers": [
        {
            "paperId": "14037a3be778f37f88403c6d2098d416b0f5cc5e",
            "title": "Oh, Behave! Country Representation Dynamics Created by Feedback Loops in Music Recommender Systems",
            "abstract": "Recent work suggests that music recommender systems are prone to disproportionally frequent recommendations of music from countries more prominently represented in the training data, notably the US. However, it remains unclear to what extent feedback loops in music recommendation influence the dynamics of such imbalance. In this work, we investigate the dynamics of representation of local (i.e., country-specific) and US-produced music in user profiles and recommendations. To this end, we conduct a feedback loop simulation study using the standardized LFM-2b dataset. The results suggest that most of the investigated recommendation models decrease the proportion of music from local artists in their recommendations. Furthermore, we find that models preserving average proportions of US and local music do not necessarily provide country-calibrated recommendations. We also look into popularity calibration and, surprisingly, find that the most popularity-calibrated model in our study (ItemKNN) provides the least country-calibrated recommendations. In addition, users from less represented countries (e.g., Finland) are, in the long term, most affected by the under-representation of their local music in recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "2316563264",
                    "name": "Jonas Geiger"
                },
                {
                    "authorId": "2316562274",
                    "name": "Max Walder"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "2044d10c08584acee2081db2363ffb679d687df7",
            "title": "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization",
            "abstract": "Language models frequently inherit societal biases from their training data. Numerous techniques have been proposed to mitigate these biases during both the pre-training and fine-tuning stages. However, fine-tuning a pre-trained debiased language model on a downstream task can reintroduce biases into the model. Additionally, existing debiasing methods for downstream tasks either (i) require labels of protected attributes (e.g., age, race, or political views) that are often not available or (ii) rely on indicators of bias, which restricts their applicability to gender debiasing since they rely on gender-specific words. To address this, we introduce a novel debiasing regularization technique based on the class-wise variance of embeddings. Crucially, our method does not require attribute labels and targets any attribute, thus addressing the shortcomings of existing debiasing methods. Our experiments on encoder language models and three datasets demonstrate that our method outperforms existing strong debiasing baselines that rely on target attribute labels while maintaining performance on the target task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "2323514000",
                    "name": "Markus Frohman"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "731de48c3e494554cb91359b20936b620c3b727c",
            "title": "Modality Invariant Multimodal Learning to Handle Missing Modalities: A Single-Branch Approach",
            "abstract": "Multimodal networks have demonstrated remarkable performance improvements over their unimodal counterparts. Existing multimodal networks are designed in a multi-branch fashion that, due to the reliance on fusion strategies, exhibit deteriorated performance if one or more modalities are missing. In this work, we propose a modality invariant multimodal learning method, which is less susceptible to the impact of missing modalities. It consists of a single-branch network sharing weights across multiple modalities to learn inter-modality representations to maximize performance as well as robustness to missing modalities. Extensive experiments are performed on four challenging datasets including textual-visual (UPMC Food-101, Hateful Memes, Ferramenta) and audio-visual modalities (VoxCeleb1). Our proposed method achieves superior performance when all modalities are present as well as in the case of missing modalities during training or testing compared to the existing state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2073358898",
                    "name": "M. S. Saeed"
                },
                {
                    "authorId": "2296715033",
                    "name": "Shah Nawaz"
                },
                {
                    "authorId": "2264967417",
                    "name": "Muhammad Zaigham Zaheer"
                },
                {
                    "authorId": "2296787771",
                    "name": "Muhammad Haris Khan"
                },
                {
                    "authorId": "2265648177",
                    "name": "Karthik Nandakumar"
                },
                {
                    "authorId": "2296713645",
                    "name": "Muhammad Haroon Yousaf"
                },
                {
                    "authorId": "2312402750",
                    "name": "Hassan Sajjad"
                },
                {
                    "authorId": "8704891",
                    "name": "Tom De Schepper"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "9285d980404bf9c3fa4ff48fb396cc2a3a6652b2",
            "title": "Trustworthy User Modeling and Recommendation From Technical and Regulatory Perspectives",
            "abstract": "This tutorial provides an interdisciplinary overview of fairness, non-discrimination, transparency, privacy, and security in the context of recommender systems. According to European policies, these are essential dimensions of trustworthy AI systems but also extend to the global debate on regulating AI technology. Since the aspects mentioned earlier require more than technical considerations, we discuss these topics from ethical, legal, and regulatory perspectives. While the tutorial\u2019s primary focus is on presenting technical solutions that address the mentioned topics of trustworthiness, it also equips the primarily technical audience of UMAP with the necessary understanding of the social and ethical implications of their research and development and recent ethical guidelines and regulatory frameworks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "2431124",
                    "name": "V. W. Anelli"
                },
                {
                    "authorId": "2286141001",
                    "name": "Elisabeth Lex"
                }
            ]
        },
        {
            "paperId": "9b4ad8a194baf6ba68cca532394b82040ddb88ec",
            "title": "The Importance of Cognitive Biases in the Recommendation Ecosystem",
            "abstract": "Cognitive biases have been studied in psychology, sociology, and behavioral economics for decades. Traditionally, they have been considered a negative human trait that leads to inferior decision-making, reinforcement of stereotypes, or can be exploited to manipulate consumers, respectively. We argue that cognitive biases also manifest in different parts of the recommendation ecosystem and at different stages of the recommendation process. More importantly, we contest this traditional detrimental perspective on cognitive biases and claim that certain cognitive biases can be beneficial when accounted for by recommender systems. Concretely, we provide empirical evidence that biases such as feature-positive effect, Ikea effect, and cultural homophily can be observed in various components of the recommendation pipeline, including input data (such as ratings or side information), recommendation algorithm or model (and consequently recommended items), and user interactions with the system. In three small experiments covering recruitment and entertainment domains, we study the pervasiveness of the aforementioned biases. We ultimately advocate for a prejudice-free consideration of cognitive biases to improve user and item models as well as recommendation algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "2096412201",
                    "name": "Stefan Brandl"
                },
                {
                    "authorId": "2316641165",
                    "name": "Mohammad Lotfi"
                },
                {
                    "authorId": "2129633087",
                    "name": "Gustavo Junior Escobedo Ticona"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                }
            ]
        },
        {
            "paperId": "b7ab2f517319f16cc8a9ae3aafea552628b82975",
            "title": "Psychology-informed Information Access Systems Workshop",
            "abstract": "The Psychology-informed Information Access Systems (PsyIAS) workshop bridges the fields of machine learning and psychology, aiming to connect the research communities of information retrieval, recommender systems, natural language processing, as well as cognitive and behavioral psychology. It serves as a forum for multidisciplinary discussions about the use of psychological constructs, theories, and empirical findings for modeling and predicting user preferences, intents, and behaviors. PsyIAS particularly focuses on research that incorporates such psychology-inspired models into the search, retrieval, and recommendation processes, creates corresponding algorithms and systems, or looks into the role of cognitive processes underlying human information access. More information can be found at https://sites.google.com/view/psyias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "90762292",
                    "name": "Marta Moscati"
                },
                {
                    "authorId": "2290586023",
                    "name": "Bruno Sguerra"
                },
                {
                    "authorId": "2240528033",
                    "name": "Romain Hennequin"
                },
                {
                    "authorId": "2286141001",
                    "name": "Elisabeth Lex"
                }
            ]
        },
        {
            "paperId": "c35959584091402b9508ce2951c0e0557cf746c5",
            "title": "Face-voice Association in Multilingual Environments (FAME) Challenge 2024 Evaluation Plan",
            "abstract": "The advancements of technology have led to the use of multimodal systems in various real-world applications. Among them, the audio-visual systems are one of the widely used multimodal systems. In the recent years, associating face and voice of a person has gained attention due to presence of unique correlation between them. The Face-voice Association in Multilingual Environments (FAME) Challenge 2024 focuses on exploring face-voice association under a unique condition of multilingual scenario. This condition is inspired from the fact that half of the world's population is bilingual and most often people communicate under multilingual scenario. The challenge uses a dataset namely, Multilingual Audio-Visual (MAV-Celeb) for exploring face-voice association in multilingual environments. This report provides the details of the challenge, dataset, baselines and task details for the FAME Challenge.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2073358898",
                    "name": "M. S. Saeed"
                },
                {
                    "authorId": "2296715033",
                    "name": "Shah Nawaz"
                },
                {
                    "authorId": "2296714979",
                    "name": "Muhammad Salman Tahir"
                },
                {
                    "authorId": "2127436",
                    "name": "Rohan Kumar Das"
                },
                {
                    "authorId": "2264967417",
                    "name": "Muhammad Zaigham Zaheer"
                },
                {
                    "authorId": "90762292",
                    "name": "Marta Moscati"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "2296787771",
                    "name": "Muhammad Haris Khan"
                },
                {
                    "authorId": "2265648177",
                    "name": "Karthik Nandakumar"
                },
                {
                    "authorId": "2296713645",
                    "name": "Muhammad Haroon Yousaf"
                }
            ]
        },
        {
            "paperId": "d09036914f0b73b57e0fce628b6aa4cfeed353ca",
            "title": "The Impact of Differential Privacy on Recommendation Accuracy and Popularity Bias",
            "abstract": "Collaborative filtering-based recommender systems leverage vast amounts of behavioral user data, which poses severe privacy risks. Thus, often, random noise is added to the data to ensure Differential Privacy (DP). However, to date, it is not well understood, in which ways this impacts personalized recommendations. In this work, we study how DP impacts recommendation accuracy and popularity bias, when applied to the training data of state-of-the-art recommendation models. Our findings are three-fold: First, we find that nearly all users' recommendations change when DP is applied. Second, recommendation accuracy drops substantially while recommended item popularity experiences a sharp increase, suggesting that popularity bias worsens. Third, we find that DP exacerbates popularity bias more severely for users who prefer unpopular items than for users that prefer popular items.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152607415",
                    "name": "P. Mullner"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                }
            ]
        },
        {
            "paperId": "f4d5afc84af3d98d6a546e84e7849da516a9d221",
            "title": "Emotion-Based Music Recommendation from Quality Annotations and Large-Scale User-Generated Tags",
            "abstract": "Emotions constitute an important aspect when listening to music. While manual annotations from user studies grounded in psychological research on music and emotions provide a well-defined and fine-grained description of the emotions evoked when listening to a music track, user-generated tags provide an alternative view stemming from large-scale data. In this work, we examine the relationship between these two emotional characterizations of music and analyze their impact on the performance of emotion-based music recommender systems individually and jointly. Our analysis shows that (i) the agreement between the two characterizations, as measured with Cohen\u2019s \u03ba coefficient and Kendall rank correlation, is often low, (ii) Leveraging the emotion profile based on the intensity of evoked emotions from high-quality annotations leads to performances that are stable across different recommendation algorithms; (iii) Simultaneously leveraging the emotion profiles based on high-quality and large-scale annotations allows to provide recommendations that are less exposed to the low accuracy that algorithms might reach when leveraging one type of data, only.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "90762292",
                    "name": "Marta Moscati"
                },
                {
                    "authorId": "2068249250",
                    "name": "Hannah Strauss"
                },
                {
                    "authorId": "2281800796",
                    "name": "Peer-Ole Jacobsen"
                },
                {
                    "authorId": "1794905562",
                    "name": "Andreas Peintner"
                },
                {
                    "authorId": "2281799617",
                    "name": "Eva Zangerle"
                },
                {
                    "authorId": "2275253210",
                    "name": "Marcel Zentner"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "8fdb115cccea75ef61d637f7cf1a2c6f5f4be680",
            "title": "Differential privacy in collaborative filtering recommender systems: a review",
            "abstract": "State-of-the-art recommender systems produce high-quality recommendations to support users in finding relevant content. However, through the utilization of users' data for generating recommendations, recommender systems threaten users' privacy. To alleviate this threat, often, differential privacy is used to protect users' data via adding random noise. This, however, leads to a substantial drop in recommendation quality. Therefore, several approaches aim to improve this trade-off between accuracy and user privacy. In this work, we first overview threats to user privacy in recommender systems, followed by a brief introduction to the differential privacy framework that can protect users' privacy. Subsequently, we review recommendation approaches that apply differential privacy, and we highlight research that improves the trade-off between recommendation quality and user privacy. Finally, we discuss open issues, e.g., considering the relation between privacy and fairness, and the users' different needs for privacy. With this review, we hope to provide other researchers an overview of the ways in which differential privacy has been applied to state-of-the-art collaborative filtering recommender systems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2127636407",
                    "name": "Peter M\u00fcllner"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                }
            ]
        }
    ]
}