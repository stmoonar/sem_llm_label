{
    "authorId": "2258712913",
    "papers": [
        {
            "paperId": "16e989b9094c3653972c82b10b7004b6f0b42927",
            "title": "Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation",
            "abstract": "Emotional Support Conversation (ESC) is a task aimed at alleviating individuals' emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover, we conduct a methodological study to offer insights into the necessary approaches for LLMs to serve as proficient emotional supporters. Our findings emphasize that (1) low preference for specific strategies hinders the progress of emotional support, (2) external assistance helps reduce preference bias, and (3) existing LLMs alone cannot become good emotional supporters. These insights suggest promising avenues for future research to enhance the emotional intelligence of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266420525",
                    "name": "Dongjin Kang"
                },
                {
                    "authorId": "2284823818",
                    "name": "Sunghwan Kim"
                },
                {
                    "authorId": "2258722263",
                    "name": "Taeyoon Kwon"
                },
                {
                    "authorId": "2266717741",
                    "name": "Seungjun Moon"
                },
                {
                    "authorId": "2284988495",
                    "name": "Hyunsouk Cho"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "265491986893b89ae80be97f039a45940e688096",
            "title": "SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for Sequential Recommendation",
            "abstract": "Language Models (LMs) are increasingly employed in recommendation systems due to their advanced language understanding and generation capabilities. Recent recommender systems based on generative retrieval have leveraged the inferential abilities of LMs to directly generate the index tokens of the next item, based on item sequences within the user's interaction history. Previous studies have mostly focused on item indices based solely on textual semantic or collaborative information. However, although the standalone effectiveness of these aspects has been demonstrated, the integration of this information has remained unexplored. Our in-depth analysis finds that there is a significant difference in the knowledge captured by the model from heterogeneous item indices and diverse input prompts, which can have a high potential for complementarity. In this paper, we propose SC-Rec, a unified recommender system that learns diverse preference knowledge from two distinct item indices and multiple prompt templates. Furthermore, SC-Rec adopts a novel reranking strategy that aggregates a set of ranking results, inferred based on different indices and prompts, to achieve the self-consistency of the model. Our empirical evaluation on three real-world datasets demonstrates that SC-Rec considerably outperforms the state-of-the-art methods for sequential recommendation, effectively incorporating complementary knowledge from varied outputs of the model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2312343395",
                    "name": "Tongyoung Kim"
                },
                {
                    "authorId": "2312340494",
                    "name": "Soojin Yoon"
                },
                {
                    "authorId": "71965979",
                    "name": "SeongKu Kang"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                }
            ]
        },
        {
            "paperId": "279094413f8be6c75ac90ed9fa2066819007f13b",
            "title": "Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization",
            "abstract": "Implicit knowledge hidden within the explicit table cells, such as data insights, is the key to generating a high-quality table summary. However, unveiling such implicit knowledge is a non-trivial task. Due to the complex nature of structured tables, it is challenging even for large language models (LLMs) to mine the implicit knowledge in an insightful and faithful manner. To address this challenge, we propose a novel table reasoning framework Question-then-Pinpoint. Our work focuses on building a plug-and-play table reasoner that can self-question the insightful knowledge and answer it by faithfully pinpointing evidence on the table to provide explainable guidance for the summarizer. To train a reliable reasoner, we collect table knowledge by guiding a teacher LLM to follow the coarse-to-fine reasoning paths and refine it through two quality enhancement strategies to selectively distill the high-quality knowledge to the reasoner. Extensive experiments on two table summarization datasets, including our newly proposed InsTaSumm, validate the general effectiveness of our framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287925064",
                    "name": "Kwangwook Seo"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                }
            ]
        },
        {
            "paperId": "373b56dd4f6861e5e0622f7eb2959f05aac2edc1",
            "title": "THEANINE: Revisiting Memory Management in Long-term Conversations with Timeline-augmented Response Generation",
            "abstract": "Large language models (LLMs) are capable of processing lengthy dialogue histories during prolonged interaction with users without additional memory modules; however, their responses tend to overlook or incorrectly recall information from the past. In this paper, we revisit memory-augmented response generation in the era of LLMs. While prior work focuses on getting rid of outdated memories, we argue that such memories can provide contextual cues that help dialogue systems understand the development of past events and, therefore, benefit response generation. We present Theanine, a framework that augments LLMs' response generation with memory timelines -- series of memories that demonstrate the development and causality of relevant past events. Along with Theanine, we introduce TeaFarm, a counterfactual-driven question-answering pipeline addressing the limitation of G-Eval in long-term conversations. Supplementary videos of our methods and the TeaBag dataset for TeaFarm evaluation are in https://theanine-693b0.web.app/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290628040",
                    "name": "Seo Hyun Kim"
                },
                {
                    "authorId": "2210267033",
                    "name": "Kai Tzu-iunn Ong"
                },
                {
                    "authorId": "2258722263",
                    "name": "Taeyoon Kwon"
                },
                {
                    "authorId": "2307412656",
                    "name": "Namyoung Kim"
                },
                {
                    "authorId": "2290488826",
                    "name": "Keummin Ka"
                },
                {
                    "authorId": "2307564257",
                    "name": "Seonghyeon Bae"
                },
                {
                    "authorId": "2067643024",
                    "name": "Yohan Jo"
                },
                {
                    "authorId": "2266441171",
                    "name": "Seung-won Hwang"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "378702db60e4e9761dcdb0b73f0b9a1549bbbb58",
            "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
            "abstract": "Recently, the demand for psychological counseling has significantly increased as more individuals express concerns about their mental health. This surge has accelerated efforts to improve the accessibility of counseling by using large language models (LLMs) as counselors. To ensure client privacy, training open-source LLMs faces a key challenge: the absence of realistic counseling datasets. To address this, we introduce Cactus, a multi-turn dialogue dataset that emulates real-life interactions using the goal-oriented and structured approach of Cognitive Behavioral Therapy (CBT). We create a diverse and realistic dataset by designing clients with varied, specific personas, and having counselors systematically apply CBT techniques in their interactions. To assess the quality of our data, we benchmark against established psychological criteria used to evaluate real counseling sessions, ensuring alignment with expert evaluations. Experimental results demonstrate that Camel, a model trained with Cactus, outperforms other models in counseling skills, highlighting its effectiveness and potential as a counseling agent. We make our data, model, and code publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287822199",
                    "name": "Suyeon Lee"
                },
                {
                    "authorId": "2284823818",
                    "name": "Sunghwan Kim"
                },
                {
                    "authorId": "2261077753",
                    "name": "Minju Kim"
                },
                {
                    "authorId": "2266420525",
                    "name": "Dongjin Kang"
                },
                {
                    "authorId": "2309659264",
                    "name": "Dongil Yang"
                },
                {
                    "authorId": "2287875032",
                    "name": "Harim Kim"
                },
                {
                    "authorId": "2309787428",
                    "name": "Minseok Kang"
                },
                {
                    "authorId": "2309481707",
                    "name": "Dayi Jung"
                },
                {
                    "authorId": "2309504727",
                    "name": "Min Hee Kim"
                },
                {
                    "authorId": "2307987815",
                    "name": "Seungbeen Lee"
                },
                {
                    "authorId": "2287828497",
                    "name": "Kyoung-Mee Chung"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "3912cfcd45fad9176dccab8c15365b25a0756836",
            "title": "Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation",
            "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems. However, existing methods have not fully capitalized on the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities. To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews. EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key tasks in order: EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, aggregates and summarizes them according to specific criteria to create user and item profiles. It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions. This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation. Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2289774545",
                    "name": "Jieyong Kim"
                },
                {
                    "authorId": "2290213007",
                    "name": "Hyunseo Kim"
                },
                {
                    "authorId": "2290167192",
                    "name": "Hyunjin Cho"
                },
                {
                    "authorId": "71965979",
                    "name": "SeongKu Kang"
                },
                {
                    "authorId": "2315925945",
                    "name": "Buru Chang"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                }
            ]
        },
        {
            "paperId": "44952b8beacd484bd25937604d680100637b48f8",
            "title": "YA-TA: Towards Personalized Question-Answering Teaching Assistants using Instructor-Student Dual Retrieval-augmented Knowledge Fusion",
            "abstract": "Engagement between instructors and students plays a crucial role in enhancing students'academic performance. However, instructors often struggle to provide timely and personalized support in large classes. To address this challenge, we propose a novel Virtual Teaching Assistant (VTA) named YA-TA, designed to offer responses to students that are grounded in lectures and are easy to understand. To facilitate YA-TA, we introduce the Dual Retrieval-augmented Knowledge Fusion (DRAKE) framework, which incorporates dual retrieval of instructor and student knowledge and knowledge fusion for tailored response generation. Experiments conducted in real-world classroom settings demonstrate that the DRAKE framework excels in aligning responses with knowledge retrieved from both instructor and student sides. Furthermore, we offer additional extensions of YA-TA, such as a Q&A board and self-practice tools to enhance the overall learning experience. Our video is publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2309659264",
                    "name": "Dongil Yang"
                },
                {
                    "authorId": "2287822199",
                    "name": "Suyeon Lee"
                },
                {
                    "authorId": "2117956135",
                    "name": "Minjin Kim"
                },
                {
                    "authorId": "2319372269",
                    "name": "Jungsoo Won"
                },
                {
                    "authorId": "2307412656",
                    "name": "Namyoung Kim"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "505013ca939bf7e6138b38c58a24d80726c669ee",
            "title": "Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models",
            "abstract": "Algorithmic reasoning refers to the ability to understand the complex patterns behind the problem and decompose them into a sequence of reasoning steps towards the solution. Such nature of algorithmic reasoning makes it a challenge for large language models (LLMs), even though they have demonstrated promising performance in other reasoning tasks. Within this context, some recent studies use programming languages (e.g., Python) to express the necessary logic for solving a given instance/question (e.g., Program-of-Thought) as inspired by their strict and precise syntaxes. However, it is non-trivial to write an executable code that expresses the correct logic on the fly within a single inference call. Also, the code generated specifically for an instance cannot be reused for others, even if they are from the same task and might require identical logic to solve. This paper presents Think-and-Execute, a novel framework that decomposes the reasoning process of language models into two steps. (1) In Think, we discover a task-level logic that is shared across all instances for solving a given task and then express the logic with pseudocode; (2) In Execute, we further tailor the generated pseudocode to each instance and simulate the execution of the code. With extensive experiments on seven algorithmic reasoning tasks, we demonstrate the effectiveness of Think-and-Execute. Our approach better improves LMs' reasoning compared to several strong baselines performing instance-specific reasoning (e.g., CoT and PoT), suggesting the helpfulness of discovering task-level logic. Also, we show that compared to natural language, pseudocode can better guide the reasoning of LMs, even though they are trained to follow natural language instructions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184029886",
                    "name": "Hyungjoo Chae"
                },
                {
                    "authorId": "2294805313",
                    "name": "Yeonghyeon Kim"
                },
                {
                    "authorId": "2184037220",
                    "name": "Seungone Kim"
                },
                {
                    "authorId": "2210267033",
                    "name": "Kai Tzu-iunn Ong"
                },
                {
                    "authorId": "2151245501",
                    "name": "Beong-woo Kwak"
                },
                {
                    "authorId": "2294776125",
                    "name": "Moohyeon Kim"
                },
                {
                    "authorId": "2295169937",
                    "name": "Seonghwan Kim"
                },
                {
                    "authorId": "2258722263",
                    "name": "Taeyoon Kwon"
                },
                {
                    "authorId": "2004821977",
                    "name": "Jiwan Chung"
                },
                {
                    "authorId": "2258802490",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "512e632d4173422f77a1b5daa23a1582fee47355",
            "title": "Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts",
            "abstract": "Cross-lingual entity alignment (EA) enables the integration of multiple knowledge graphs (KGs) across different languages, providing users with seamless access to diverse and comprehensive knowledge. Existing methods, mostly supervised, face challenges in obtaining labeled entity pairs. To address this, recent studies have shifted towards a self-supervised and unsupervised frameworks. Despite their effectiveness, these approaches have limitations: (1) they mainly focus on entity features, neglecting the semantic information of relations, (2) they assume isomorphism between source and target graphs, leading to noise and reduced alignment accuracy, and (3) they are susceptible to noise in the textual features, especially when encountering inconsistent translations or Out-Of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an unsupervised and robust cross-lingual EA framework that jointly performs Entity-level and Relation-level Alignment using semantic textual features of relations and entities. Its refinement process iteratively enhances results by fusing entity-level and relation-level alignments based on neighbor triple matching. The additional verification process examines the entities\u2019 neighbor triples as the linearized text. This Align-and-Verify pipeline that rigorously assesses alignment results, achieving near-perfect alignment even in the presence of noisy textual features of entities. Our extensive experiments demonstrate that robustness and general applicability of ERAlign improved the accuracy and effectiveness of EA tasks, contributing significantly to knowledge-oriented applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2312340494",
                    "name": "Soojin Yoon"
                },
                {
                    "authorId": "2290013986",
                    "name": "Sungho Ko"
                },
                {
                    "authorId": "2312343395",
                    "name": "Tongyoung Kim"
                },
                {
                    "authorId": "71965979",
                    "name": "SeongKu Kang"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                }
            ]
        },
        {
            "paperId": "5c190ab7133a38aacb49a7434f575039c53802de",
            "title": "Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with Extract-Then-Assign Strategy",
            "abstract": "In the task of aspect sentiment quad prediction (ASQP), generative methods for predicting sentiment quads have shown promising results. However, they still suffer from imprecise predictions and limited interpretability, caused by data scarcity and inadequate modeling of the quadruplet composition process. In this paper, we propose Self-Consistent Reasoning-based Aspect-sentiment quadruple Prediction (SCRAP), optimizing its model to generate reasonings and the corresponding sentiment quadruplets in sequence. SCRAP adopts the Extract-Then-Assign reasoning strategy, which closely mimics human cognition. In the end, SCRAP significantly improves the model's ability to handle complex reasoning tasks and correctly predict quadruplets through consistency voting, resulting in enhanced interpretability and accuracy in ASQP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2289774545",
                    "name": "Jieyong Kim"
                },
                {
                    "authorId": "2289609652",
                    "name": "Ryang Heo"
                },
                {
                    "authorId": "2289611054",
                    "name": "Yongsik Seo"
                },
                {
                    "authorId": "71965979",
                    "name": "SeongKu Kang"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                }
            ]
        }
    ]
}