{
    "authorId": "143947042",
    "papers": [
        {
            "paperId": "190140670d224fe934a519e47be196eec9db3f56",
            "title": "Contrastive Learning for User Sequence Representation in Personalized Product Search",
            "abstract": "Providing personalization in product search has attracted increasing attention in both industry and research communities. Most existing personalized product search methods model users' individual search interests based on their historical search logs to generate personalized search results. However, the search logs may be sparse or noisy in the real scenario, which is difficult for existing methods to learn accurate and robust user representations. To address this issue, we propose a contrastive learning framework CoPPS that aims to learn high-quality user representations for personalized product search. Specifically, we design three data augmentation and contrastive learning strategies to construct self-supervision signals from the original search behaviours. The contrastive learning tasks utilize an external knowledge graph and exploit the correlations within and between user sequences, thereby facilitating the discovery of more meaningful search patterns and ultimately enhancing the quality of personalized search. Experimental results on the public Amazon datasets verify the effectiveness of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2227491450",
                    "name": "Shitong Dai"
                },
                {
                    "authorId": "1830383266",
                    "name": "Jiongnan Liu"
                },
                {
                    "authorId": "1897235",
                    "name": "Zhicheng Dou"
                },
                {
                    "authorId": "49528487",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2146017790",
                    "name": "Lin Liu"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "806ac4b81a46fa97c4272124c2511608280a5019",
            "title": "Attention Weighted Mixture of Experts with Contrastive Learning for Personalized Ranking in E-commerce",
            "abstract": "Ranking model plays an essential role in e-commerce search and recommendation. An effective ranking model should give a personalized ranking list for each user according to the user preference. Existing algorithms usually extract a user representation vector from the user behavior sequence, then feed the vector into a feed-forward network (FFN) together with other features for feature interactions, and finally produce a personalized ranking score. Despite tremendous progress in the past, there is still room for improvement. Firstly, the personalized patterns of feature interactions for different users are not explicitly modeled. Secondly, most of existing algorithms have poor personalized ranking results for long-tail users with few historical behaviors due to the data sparsity.To overcome the two challenges, we propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive learning for personalized ranking. Firstly, AW-MoE leverages the MoE framework to capture personalized feature interactions for different users. To model the user preference, the user behavior sequence is simultaneously fed into expert networks and the gate network. Within the gate network, one gate unit and one activation unit are designed to adaptively learn the fine-grained activation vector for experts using an attention mechanism. Secondly, a random masking strategy is applied to the user behavior sequence to simulate long-tail users, and an auxiliary contrastive loss is imposed to the output of the gate network to improve the model generalization for these users. This is validated by a higher performance gain on the long-tail user test set.Experiment results on a JD real production dataset and a public dataset demonstrate the effectiveness of AW-MoE, which significantly outperforms state-of-art methods. Notably, AW-MoE has been successfully deployed in the JD e-commerce search engine, serving the real traffic of hundreds of millions of active users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112953487",
                    "name": "Juan Gong"
                },
                {
                    "authorId": "2117037227",
                    "name": "Zhe Chen"
                },
                {
                    "authorId": "2112663524",
                    "name": "Chao Ma"
                },
                {
                    "authorId": "50479706",
                    "name": "Zhuojian Xiao"
                },
                {
                    "authorId": "49528487",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "3252269",
                    "name": "Guoyu Tang"
                },
                {
                    "authorId": "2146017790",
                    "name": "Lin Liu"
                },
                {
                    "authorId": "1752741172",
                    "name": "Sulong Xu"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2131218",
                    "name": "Yunjiang Jiang"
                }
            ]
        },
        {
            "paperId": "832f615045aca07d2febfdf0c02d32d4934e8010",
            "title": "Learning Multi-Stage Multi-Grained Semantic Embeddings for E-Commerce Search",
            "abstract": "Retrieving relevant items that match users\u2019 queries from billion-scale corpus forms the core of industrial e-commerce search systems, in which embedding-based retrieval (EBR) methods are prevailing. These methods adopt a two-tower framework to learn embedding vectors for query and item separately and thus leverage efficient approximate nearest neighbor (ANN) search to retrieve relevant items. However, existing EBR methods usually ignore inconsistent user behaviors in industrial multi-stage search systems, resulting in insufficient retrieval efficiency with a low commercial return. To tackle this challenge, we propose to improve EBR methods by learning Multi-level Multi-Grained Semantic Embeddings (MMSE). We propose the multi-stage information mining to exploit the ordered, clicked, unclicked and random sampled items in practical user behavior data, and then capture query-item similarity via a post-fusion strategy. We then propose multi-grained learning objectives that integrate the retrieval loss with global comparison ability and the ranking loss with local comparison ability to generate semantic embeddings. Both experiments on a real-world billion-scale dataset and online A/B tests verify the effectiveness of MMSE in achieving significant performance improvements on metrics such as offline recall and online conversion rate (CVR).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2212277609",
                    "name": "Binbin Wang"
                },
                {
                    "authorId": "49141009",
                    "name": "Mingming Li"
                },
                {
                    "authorId": "1998946156",
                    "name": "Zhixiong Zeng"
                },
                {
                    "authorId": "1883787",
                    "name": "Jingwei Zhuo"
                },
                {
                    "authorId": "31093111",
                    "name": "Songlin Wang"
                },
                {
                    "authorId": "1752741172",
                    "name": "Sulong Xu"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "46704879",
                    "name": "Weipeng P. Yan"
                }
            ]
        },
        {
            "paperId": "a6de40e055d11066ec6671ca11e6bfba43ab1ec4",
            "title": "Pre-training Tasks for User Intent Detection and Embedding Retrieval in E-commerce Search",
            "abstract": "BERT-style models pre-trained on the general corpus (e.g., Wikipedia) and fine-tuned on specific task corpus, have recently emerged as breakthrough techniques in many NLP tasks: question answering, text classification, sequence labeling and so on. However, this tech- nique may not always work, especially for two scenarios: a corpus that contains very different text from the general corpus Wikipedia, or a task that learns embedding spacial distribution for a specific purpose (e.g., approximate nearest neighbor search). In this paper, to tackle the above two scenarios that we have encountered in an industrial e-commerce search system, we propose customized and novel pre-training tasks for two critical modules: user intent detec- tion and semantic embedding retrieval. The customized pre-trained models after fine-tuning, being less than 10% of BERT-base's size in order to be feasible for cost-efficient CPU serving, significantly improve the other baseline models: 1) no pre-training model and 2) fine-tuned model from the official pre-trained BERT using general corpus, on both offline datasets and online system. We have open sourced our datasets 1 for the sake of reproducibility and future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114967623",
                    "name": "Yiming Qiu"
                },
                {
                    "authorId": "2115458862",
                    "name": "Chenyu Zhao"
                },
                {
                    "authorId": "2119078075",
                    "name": "Han Zhang"
                },
                {
                    "authorId": "1883787",
                    "name": "Jingwei Zhuo"
                },
                {
                    "authorId": "2118910995",
                    "name": "Tianhao Li"
                },
                {
                    "authorId": "49470119",
                    "name": "Xiaowei Zhang"
                },
                {
                    "authorId": "31093111",
                    "name": "Songlin Wang"
                },
                {
                    "authorId": "1752741172",
                    "name": "Sulong Xu"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "49230310",
                    "name": "Wen-Yun Yang"
                }
            ]
        },
        {
            "paperId": "16b0573b8a99746bd56c725bbbacab985be58557",
            "title": "AutoDim: Field-aware Embedding Dimension Searchin Recommender Systems",
            "abstract": "Practical large-scale recommender systems usually contain thousands of feature fields from users, items, contextual information, and their interactions. Most of them empirically allocate a unified dimension to all feature fields, which is memory inefficient. Thus it is highly desired to assign various embedding dimensions to different feature fields according to their importance and predictability. Due to the large amounts of feature fields and the nuanced relationship between embedding dimensions with feature distributions and neural network architectures, manually allocating embedding dimensions in practical recommender systems can be challenging. To this end, we propose an AutoML-based framework (AutoDim) in this paper, which can automatically select dimensions for different feature fields in a data-driven fashion. Specifically, we first proposed an end-to-end differentiable framework that can calculate the weights over various dimensions in a soft and continuous manner for feature fields, and an AutoML-based optimization algorithm; then, we derive a hard and discrete embedding component architecture according to the maximal weights and retrain the whole recommender framework. We conduct extensive experiments on benchmark datasets to validate the effectiveness of AutoDim.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2109155757",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "0765baddc2b83166f123f3fddd5557638d8d8f43",
            "title": "Deep Search Query Intent Understanding",
            "abstract": "Understanding a user's query intent behind a search is critical for modern search engine success. Accurate query intent prediction allows the search engine to better serve the user's need by rendering results from more relevant categories. This paper aims to provide a comprehensive learning framework for modeling query intent under different stages of a search. We focus on the design for 1) predicting users' intents as they type in queries on-the-fly in typeahead search using character-level models; and 2) accurate word-level intent prediction models for complete queries. Various deep learning components for query text understanding are experimented. Offline evaluation and online A/B test experiments show that the proposed methods are effective in understanding query intent and efficient to scale for online search systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109116511",
                    "name": "Xiaowei Liu"
                },
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "0bce51554266705b746f3ade64d581b63cd2a4af",
            "title": "Incorporating User Feedback into Sequence to Sequence Model Training",
            "abstract": "As the largest professional network, LinkedIn hosts millions of user profiles and job postings. Users effectively find what they need by entering search queries. However, finding what they are looking for can be a challenge, especially if they are unfamiliar with specific keywords from their industry. Query Suggestion is a popular feature where a search engine can suggest alternate, related queries. At LinkedIn, we have productionized a deep learning Seq2Seq model to transform an input query into several alternatives. This model is trained by examining search history directly typed by users. Once online, we can determine whether or not users clicked on suggested queries. This new feedback data indicates which suggestions caught the user's attention. In this work, we propose training a model with both the search history and user feedback datasets. We examine several ways to incorporate feedback without any architectural change, including adding a novel pairwise ranking loss term during training. The proposed new training technique produces the best combined score out of several alternatives in offline metrics. Deployed in the LinkedIn search engine, it significantly outperforms the control model with respect to key business metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3315931",
                    "name": "Michaeel Kazi"
                },
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "110ef8f751d1abf3f18b10ee90f883f2709f2312",
            "title": "DeText: A Deep Text Ranking Framework with BERT",
            "abstract": "Ranking is the most important component in a search system. Most search systems deal with large amounts of natural language data, hence an effective ranking system requires a deep understanding of text semantics. Recently, deep learning based natural language processing (deep NLP) models have generated promising results on ranking systems. BERT is one of the most successful models that learn contextual embedding, which has been applied to capture complex query-document relations for search ranking. However, this is generally done by exhaustively interacting each query word with each document word, which is inefficient for online serving in search product systems. In this paper, we investigate how to build an efficient BERT-based ranking model for industry use cases. The solution is further extended to a general ranking framework, DeText, that is open sourced and can be applied to various ranking productions. Offline and online experiments of DeText on three real-world search systems present significant improvement over state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2109116511",
                    "name": "Xiaowei Liu"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "145630384",
                    "name": "A. Sankar"
                },
                {
                    "authorId": "2111907175",
                    "name": "Zimeng Yang"
                },
                {
                    "authorId": "2153928779",
                    "name": "Qi Guo"
                },
                {
                    "authorId": "2146644146",
                    "name": "Liang Zhang"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "34252531",
                    "name": "Bee-Chung Chen"
                },
                {
                    "authorId": "2596058",
                    "name": "D. Agarwal"
                }
            ]
        },
        {
            "paperId": "28631a1eb7cefd38ee5e153970ef04e1f28c13f1",
            "title": "Deep Learning for Anomaly Detection",
            "abstract": "Anomaly detection has been widely studied and used in diverse applications. Building an effective anomaly detection system requires the researchers/developers to learn the complex structure from noisy data, identify the dynamic anomaly patterns and detect anomalies while lacking sufficient labels. Recent advancement in deep learning techniques has made it possible to largely improve anomaly detection performance compared to the classical approaches. This tutorial will help the audience gain a comprehensive understanding of deep learning-based anomaly detection techniques in various application domains. First, it introduces what is the anomaly detection problem, the approaches taken before the deep model era and the challenges it faced. Then it surveys the state-of-the-art deep learning models extensively and discusses the techniques used to overcome the limitations from traditional algorithms. Second to last, it studies deep model anomaly detection techniques in real world examples from LinkedIn production systems. The tutorial concludes with a discussion of future trends.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108695012",
                    "name": "Ruoying Wang"
                },
                {
                    "authorId": "40286456",
                    "name": "Kexin Nie"
                },
                {
                    "authorId": "2116564869",
                    "name": "Tie Wang"
                },
                {
                    "authorId": "2152917722",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "3c26ecafbb3f6d7198fc9840ab3bfee7fd8bf396",
            "title": "Deep Transfer Learning for Search and Recommendation",
            "abstract": "Training data sparsity is a common problem for many real-world applications in Search and Recommendation domains. Even for applications with a lot of training data, in the cold-start scenario we usually do not get enough labeled data. Transfer Learning is a promising approach for addressing this problem. In addition, features might interact with each other in a complex way that traditional approaches might not be able to represent, Deep Transfer Learning, which leverages Deep Neural Networks for Transfer Learning, might be able to catch such deep patterns hidden in complex feature interactions. Due to these reasons, recently Deep Transfer Learning research has gained a lot of attention and has been successfully applied to many real-world applications. This tutorial offers an overview of Deep Transfer Learning approaches in Search and Recommendation domains from the industry perspective. In this tutorial We first introduce the basic concepts and major categories of Deep Transfer Learning. Then we focus on recent developments of Deep Transfer Learning approaches in the Search and Recommendation domains. After that we will introduce two real-world examples of how to apply Deep Transfer Learning methods to improve Search and Recommendation performance at LinkedIn. Finally we will conclude the tutorial with discussion of future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3076945",
                    "name": "Yanen Li"
                },
                {
                    "authorId": "2152917722",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "2110723590",
                    "name": "Sen Zhou"
                },
                {
                    "authorId": "2054649979",
                    "name": "Jian Qiao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        }
    ]
}