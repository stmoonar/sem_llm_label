{
    "authorId": "2298966095",
    "papers": [
        {
            "paperId": "25bc9944aba4a047e7dfea7e5ceb1708d541b87e",
            "title": "Fairness in AI: challenges in bridging the gap between algorithms and law",
            "abstract": "In this paper we examine algorithmic fairness from the perspective of law aiming to identify best practices and strategies for the specification and adoption of fairness definitions and algorithms in real-world systems and use cases. We start by providing a brief introduction of current anti-discrimination law in the European Union and the United States and discussing the concepts of bias and fairness from an legal and ethical viewpoint. We then proceed by presenting a set of algorithmic fairness definitions by example, aiming to communicate their objectives to non-technical audiences. Then, we introduce a set of core criteria that need to be taken into account when selecting a specific fairness definition for real-world use case applications. Finally, we enumerate a set of key considerations and best practices for the design and employment of fairness methods on real-world AI applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2298966484",
                    "name": "Maria Psalla"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2298966095",
                    "name": "Jakub Marecek"
                },
                {
                    "authorId": "2298966283",
                    "name": "German M Matilla"
                },
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                }
            ]
        },
        {
            "paperId": "f3586434ae779e452416e9035fdc23c9000e39cc",
            "title": "Fairness in Ranking: Robustness through Randomization without the Protected Attribute",
            "abstract": "There has been great interest in fairness in machine learning, especially in relation to classification problems. In ranking-related problems, such as in online advertising, recommender systems, and HR automation, much work on fairness remains to be done. Two complications arise: first, the protected attribute may not be available in many applications. Second, there are multiple measures of fairness of rankings, and optimization-based methods utilizing a single measure of fairness of rankings may produce rankings that are unfair with respect to other measures. In this work, we propose a randomized method for post-processing rankings, which do not require the availability of the protected attribute. In an extensive numerical study, we show the robustness of our methods with respect to P-Fairness and effectiveness with respect to Normalized Discounted Cumulative Gain (NDCG) from the baseline ranking, improving on previously proposed methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293722300",
                    "name": "Andrii Kliachkin"
                },
                {
                    "authorId": "2139143386",
                    "name": "Eleni Psaroudaki"
                },
                {
                    "authorId": "2298966095",
                    "name": "Jakub Marecek"
                },
                {
                    "authorId": "2273195757",
                    "name": "Dimitris Fotakis"
                }
            ]
        }
    ]
}