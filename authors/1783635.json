{
    "authorId": "1783635",
    "papers": [
        {
            "paperId": "21b4777948797377deedf4a9f1f58ad13f6b8b5d",
            "title": "Overview of the Tenth Dialog System Technology Challenge: DSTC10",
            "abstract": "This article introduces the Tenth Dialog System Technology Challenge (DSTC-10). This edition of the DSTC focuses on applying end-to-end dialog technologies for five distinct tasks in dialog systems, namely 1. Incorporation of Meme images into open domain dialogs, 2. Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations, 3. Situated Interactive Multimodal dialogs, 4. Reasoning for Audio Visual Scene-Aware Dialog, and 5. Automatic Evaluation and Moderation of Open-domainDialogue Systems. This article describes the task definition, provided datasets, baselines, and evaluation setup for each track. We also summarize the results of the submitted systems to highlight the general trends of the state-of-the-art technologies for the tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237192",
                    "name": "Koichiro Yoshino"
                },
                {
                    "authorId": "1725643",
                    "name": "Yun-Nung (Vivian) Chen"
                },
                {
                    "authorId": "34963487",
                    "name": "Paul A. Crook"
                },
                {
                    "authorId": "2150275",
                    "name": "Satwik Kottur"
                },
                {
                    "authorId": "2887412",
                    "name": "Jinchao Li"
                },
                {
                    "authorId": "2127328167",
                    "name": "Behnam Hedayatnia"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "2066415714",
                    "name": "Zhengcong Fei"
                },
                {
                    "authorId": "2109965103",
                    "name": "Zekang Li"
                },
                {
                    "authorId": "27672597",
                    "name": "Jinchao Zhang"
                },
                {
                    "authorId": "2257374643",
                    "name": "Yang Feng"
                },
                {
                    "authorId": "2116575668",
                    "name": "Jie Zhou"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2152284471",
                    "name": "Di Jin"
                },
                {
                    "authorId": "1710287",
                    "name": "A. Papangelis"
                },
                {
                    "authorId": "145916630",
                    "name": "Karthik Gopalakrishnan"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "3057557",
                    "name": "Babak Damavandi"
                },
                {
                    "authorId": "1979505",
                    "name": "A. Geramifard"
                },
                {
                    "authorId": "1765212",
                    "name": "Chiori Hori"
                },
                {
                    "authorId": "31017418",
                    "name": "Ankit Shah"
                },
                {
                    "authorId": "2111574800",
                    "name": "Chen Zhang"
                },
                {
                    "authorId": "1711271",
                    "name": "Haizhou Li"
                },
                {
                    "authorId": "2319137716",
                    "name": "Jo\u00e3o Sedoc"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "06a8f2e3c4266196b008851f1ec7ef9f340809da",
            "title": "Advancing Regular Language Reasoning in Linear Recurrent Neural Networks",
            "abstract": "In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language and long-range modeling, while offering rapid parallel training and constant inference cost. With the resurgence of interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations in modeling regular language. Motivated by this analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN capable of performing length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic. The code is released at https://github.com/tinghanf/RegluarLRNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32037089",
                    "name": "Ting-Han Fan"
                },
                {
                    "authorId": "27531332",
                    "name": "Ta-Chung Chi"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "2670612b5e11297cd9b98f4d7ff796725f77fe35",
            "title": "Structured Dialogue Discourse Parsing",
            "abstract": "Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27531332",
                    "name": "Ta-Chung Chi"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "4b8d3ede673ddeab9dfb5184da6b748d7a526754",
            "title": "A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech",
            "abstract": "Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2119257114",
                    "name": "Li-Wei Chen"
                },
                {
                    "authorId": "1746678",
                    "name": "Shinji Watanabe"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "9799c17fd287bb9e8d231fe032c6dbf9c0c9d675",
            "title": "Overview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4",
            "abstract": "The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics\u2019 correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220406508",
                    "name": "Mario Rodr'iguez-Cantelar"
                },
                {
                    "authorId": "2111574800",
                    "name": "Chen Zhang"
                },
                {
                    "authorId": "1672552269",
                    "name": "Chengguang Tang"
                },
                {
                    "authorId": "2026468506",
                    "name": "Ke Shi"
                },
                {
                    "authorId": "3022427",
                    "name": "Sarik Ghazarian"
                },
                {
                    "authorId": "2319137716",
                    "name": "Jo\u00e3o Sedoc"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "f743324682d5d50db9b114fa60b908f09c10c9a0",
            "title": "Learning to Ask Questions for Zero-shot Dialogue State Tracking",
            "abstract": "We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187308615",
                    "name": "Diogo Tavares"
                },
                {
                    "authorId": "3442611",
                    "name": "David Semedo"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                },
                {
                    "authorId": "2190828088",
                    "name": "Jo\u00e3o Magalh\u00e3es"
                }
            ]
        },
        {
            "paperId": "48ad536d00742a31eb8c6408c5d7ad96e654fe7a",
            "title": "Receptive Field Alignment Enables Transformer Length Extrapolation",
            "abstract": "Length extrapolation is a desirable property that permits training a transformer language model on short sequences and retaining similar perplexities when the model is tested on substantially longer sequences. A relative positional embedding mechanism applied on the transformer self-attention matrix, ALiBi, demonstrates the length extrapolation property with the widest usage to date. In this paper, we show that ALiBi surprisingly does not utilize tokens further than the training sequence length, which can be explained by its implicit windowed attention effect that aligns the receptive \ufb01eld during training and testing stages. Inspired by ALiBi and the receptive \ufb01led alignment hypothesis, we propose another transformer positional embedding design named Sandwich that uses longer than training sequence length information, and it is a greatly simpli\ufb01ed formulation of the earliest proposed Sinusoidal positional embedding. Finally, we show that both ALiBi and Sandwich enable ef\ufb01cient inference thanks to their implicit windowed attention effect.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27531332",
                    "name": "Ta-Chung Chi"
                },
                {
                    "authorId": "32037089",
                    "name": "Ting-Han Fan"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "64c36adaeb803ff1d49771ed6a7ae7271e17b35d",
            "title": "Training Discrete Deep Generative Models via Gapped Straight-Through Estimator",
            "abstract": "While deep generative models have succeeded in image processing, natural language processing, and reinforcement learning, training that involves discrete random variables remains challenging due to the high variance of its gradient estimation process. Monte Carlo is a common solution used in most variance reduction approaches. However, this involves time-consuming resampling and multiple function evaluations. We propose a Gapped Straight-Through (GST) estimator to reduce the variance without incurring resampling overhead. This estimator is inspired by the essential properties of Straight-Through Gumbel-Softmax. We determine these properties and show via an ablation study that they are essential. Experiments demonstrate that the proposed GST estimator enjoys better performance compared to strong baselines on two discrete deep generative modeling tasks, MNIST-VAE and ListOps.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32037089",
                    "name": "Ting-Han Fan"
                },
                {
                    "authorId": "27531332",
                    "name": "Ta-Chung Chi"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                },
                {
                    "authorId": "1693135",
                    "name": "P. Ramadge"
                }
            ]
        },
        {
            "paperId": "6814ff8e9aa9cc28ff577023eea3f5167755721f",
            "title": "An Empirical study to understand the Compositional Prowess of Neural Dialog Models",
            "abstract": "In this work, we examine the problems associated with neural dialog models under the common theme of compositionality. Specifically, we investigate three manifestations of compositionality: (1) Productivity, (2) Substitutivity, and (3) Systematicity. These manifestations shed light on the generalization, syntactic robustness, and semantic capabilities of neural dialog models. We design probing experiments by perturbing the training data to study the above phenomenon. We make informative observations based on automated metrics and hope that this work increases research interest in understanding the capacity of these models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9134483",
                    "name": "Vinayshekhar Bannihatti Kumar"
                },
                {
                    "authorId": null,
                    "name": "Vaibhav Kumar"
                },
                {
                    "authorId": "26320815",
                    "name": "Mukul Bhutani"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "bdad4d4f75fc3f308923cb9b4d7e0487a5ded6b4",
            "title": "A Unified One-Shot Prosody and Speaker Conversion System with Self-Supervised Discrete Speech Units",
            "abstract": "We present a unified system to realize one-shot voice conversion (VC) on the pitch, rhythm, and speaker attributes. Existing works generally ignore the correlation between prosody and language content, leading to the degradation of naturalness in converted speech. Additionally, the lack of proper language features prevents these systems from accurately preserving language content after conversion. To address these issues, we devise a cascaded modular system leveraging self-supervised discrete speech units as language representation. These discrete units provide duration information essential for rhythm modeling. Our system first extracts utterance-level prosody and speaker representations from the raw waveform. Given the prosody representation, a prosody predictor estimates pitch, energy, and duration for each discrete unit in the utterance. A synthesizer further reconstructs speech based on the predicted prosody, speaker representation, and discrete units. Experiments show that our system outperforms previous approaches in naturalness, intelligibility, speaker transferability, and prosody transferability. Code and samples are publicly available.1",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119257114",
                    "name": "Li-Wei Chen"
                },
                {
                    "authorId": "1746678",
                    "name": "Shinji Watanabe"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        }
    ]
}