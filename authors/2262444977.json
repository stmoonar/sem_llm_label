{
    "authorId": "2262444977",
    "papers": [
        {
            "paperId": "416ce070e8924163afdbcf9966d0431f37641ad0",
            "title": "An Interpretable Ensemble of Graph and Language Models for Improving Search Relevance in E-Commerce",
            "abstract": "The problem of search relevance in the E-commerce domain is a challenging one since it involves understanding the intent of a user's short nuanced query and matching it with the appropriate products in the catalog. This problem has traditionally been addressed using language models (LMs) and graph neural networks (GNNs) to capture semantic and inter-product behavior signals, respectively. However, the rapid development of new architectures has created a gap between research and the practical adoption of these techniques. Evaluating the generalizability of these models for deployment requires extensive experimentation on complex, real-world datasets, which can be non-trivial and expensive. Furthermore, such models often operate on latent space representations that are incomprehensible to humans, making it difficult to evaluate and compare the effectiveness of different models. This lack of interpretability hinders the development and adoption of new techniques in the field. To bridge this gap, we propose Plug and Play Graph LAnguage Model (PP-GLAM), an explainable ensemble of plug and play models. Our approach uses a modular framework with uniform data processing pipelines. It employs additive explanation metrics to independently decide whether to include (i) language model candidates, (ii) GNN model candidates, and (iii) inter-product behavioral signals. For the task of search relevance, we show that PP-GLAM outperforms several state-of-the-art baselines as well as a proprietary model on real-world multilingual, multi-regional e-commerce datasets. To promote better model comprehensibility and adoption, we also provide an analysis of the explainability and computational complexity of our model. We also provide the public codebase and provide a deployment strategy for practical implementation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262444503",
                    "name": "Nurendra Choudhary"
                },
                {
                    "authorId": "2057479333",
                    "name": "E-Wen Huang"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "5e35bbd0ad056cd880e8f675418364076e547197",
            "title": "H-STAR: LLM-driven Hybrid SQL-Text Adaptive Reasoning on Tables",
            "abstract": "Tabular reasoning involves interpreting unstructured queries against structured tables, requiring a synthesis of textual understanding and symbolic reasoning. Existing methods rely on either of the approaches and are constrained by their respective limitations. Textual reasoning excels in semantic interpretation unlike symbolic reasoning (SQL logic), but falls short in mathematical reasoning where SQL excels. In this paper, we introduce a novel algorithm H-STAR, comprising table extraction and adaptive reasoning, integrating both symbolic and semantic (text-based) approaches. To enhance evidence extraction, H-STAR employs a multi-view approach, incorporating step-by-step row and column retrieval. It also adapts reasoning strategies based on question types, utilizing symbolic reasoning for quantitative and logical tasks, and semantic reasoning for direct lookup and complex lexical queries. Our extensive experiments demonstrate that H-STAR significantly outperforms state-of-the-art methods across three tabular question-answering (QA) and fact-verification datasets, underscoring its effectiveness and efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2310336728",
                    "name": "Nikhil Abhyankar"
                },
                {
                    "authorId": "2266840908",
                    "name": "Vivek Gupta"
                },
                {
                    "authorId": "2266750435",
                    "name": "Dan Roth"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "797676dd84b0dff0706c45dca1cdc63a31d23c68",
            "title": "Synthesizing Conversations from Unlabeled Documents using Automatic Response Segmentation",
            "abstract": "In this study, we tackle the challenge of inadequate and costly training data that has hindered the development of conversational question answering (ConvQA) systems. Enterprises have a large corpus of diverse internal documents. Instead of relying on a searching engine, a more compelling approach for people to comprehend these documents is to create a dialogue system. In this paper, we propose a robust dialog synthesising method. We learn the segmentation of data for the dialog task instead of using segmenting at sentence boundaries. The synthetic dataset generated by our proposed method achieves superior quality when compared to WikiDialog, as assessed through machine and human evaluations. By employing our inpainted data for ConvQA retrieval system pre-training, we observed a notable improvement in performance across OR-QuAC benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261413304",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "2110546424",
                    "name": "Weijie Xu"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "2287927370",
                    "name": "Srinivasan H. Sengamedu"
                }
            ]
        },
        {
            "paperId": "860ba78f9789bbfc99c299b18558ca19430d8fea",
            "title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models",
            "abstract": "Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines. However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely high-dimensional combinatorial and nonlinear hypothesis spaces. Traditional methods of equation discovery, commonly known as symbolic regression, largely focus on extracting equations from data alone, often neglecting the rich domain-specific prior knowledge that scientists typically depend on. To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data in an efficient manner. Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs. The LLM iteratively proposes new equation skeleton hypotheses, drawing from its physical understanding, which are then optimized against data to estimate skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse scientific domains, where it discovers physically accurate equations that provide significantly better fits to in-domain and out-of-domain data compared to the well-established symbolic regression baselines. Incorporating scientific prior knowledge also enables LLM-SR to search the equation space more efficiently than baselines. Code is available at: https://github.com/deep-symbolic-mathematics/LLM-SR",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037848556",
                    "name": "Parshin Shojaee"
                },
                {
                    "authorId": "1999900316",
                    "name": "Kazem Meidani"
                },
                {
                    "authorId": "2152953535",
                    "name": "Shashank Gupta"
                },
                {
                    "authorId": "3614493",
                    "name": "A. Farimani"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "aeb755976e5ac0f73d39ab6679bc92d9061c62ea",
            "title": "Beyond the Surface: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation",
            "abstract": "Recent studies have highlighted the issue of stereotypical depictions for people of different identity groups in Text-to-Image (T2I) model generations. However, these existing approaches have several key limitations, including a noticeable lack of coverage of global identity groups in their evaluation, and the range of their associated stereotypes. Additionally, they often lack a critical distinction between inherently visual stereotypes, such as \u2018under-weight\u2019 or \u2018sombrero\u2019, and culturally dependent stereotypes like \u2018attractive\u2019 or \u2018terrorist\u2019. In this work, we address these limitations with a multifaceted approach that leverages existing textual resources to ground our evaluation of geo-cultural stereotypes in the generated images from T2I models. We employ existing stereotype benchmarks to identify and evaluate visual stereotypes at global scale, spanning 135 nationality based identity groups. We demonstrate that stereotypical attributes are thrice as likely to be present in images of these identities as compared to other attributes. We further investigate how disparately offensive the de-pictions of generated images are for different nationalities. Finally, through a detailed case study, we reveal how the \u2018default\u2019 representations of all identity groups have a stereotypical appearance. Moreover, for the Global South, images across different attributes are visually similar, even when explicitly prompted otherwise. CONTENT WARNING: Some examples may contain offensive stereotypes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2265650491",
                    "name": "Vinodkumar Prabhakaran"
                },
                {
                    "authorId": "2268676053",
                    "name": "Remi Denton"
                },
                {
                    "authorId": "2279338830",
                    "name": "Sarah Laszlo"
                },
                {
                    "authorId": "2160404",
                    "name": "Shachi Dave"
                },
                {
                    "authorId": "101513478",
                    "name": "Rida Qadri"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "50991767",
                    "name": "Sunipa Dev"
                }
            ]
        },
        {
            "paperId": "b265ad93aa9d349ba7cab7829f81b1be88c37bb1",
            "title": "ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation",
            "abstract": "Recent studies have shown that Text-to-Image (T2I) model generations can reflect social stereotypes present in the real world. However, existing approaches for evaluating stereotypes have a noticeable lack of coverage of global identity groups and their associated stereotypes. To address this gap, we introduce the ViSAGe (Visual Stereotypes Around the Globe) dataset to enable the evaluation of known nationality-based stereotypes in T2I models, across 135 nationalities. We enrich an existing textual stereotype resource by distinguishing between stereotypical associations that are more likely to have visual depictions, such as `sombrero', from those that are less visually concrete, such as 'attractive'. We demonstrate ViSAGe's utility through a multi-faceted evaluation of T2I generations. First, we show that stereotypical attributes in ViSAGe are thrice as likely to be present in generated images of corresponding identities as compared to other attributes, and that the offensiveness of these depictions is especially higher for identities from Africa, South America, and South East Asia. Second, we assess the stereotypical pull of visual depictions of identity groups, which reveals how the 'default' representations of all identity groups in ViSAGe have a pull towards stereotypical depictions, and that this pull is even more prominent for identity groups from the Global South. CONTENT WARNING: Some examples contain offensive stereotypes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2265650491",
                    "name": "Vinodkumar Prabhakaran"
                },
                {
                    "authorId": "2268676053",
                    "name": "Remi Denton"
                },
                {
                    "authorId": "2279338830",
                    "name": "Sarah Laszlo"
                },
                {
                    "authorId": "2160404",
                    "name": "Shachi Dave"
                },
                {
                    "authorId": "101513478",
                    "name": "Rida Qadri"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "50991767",
                    "name": "Sunipa Dev"
                }
            ]
        },
        {
            "paperId": "b4f8117309262f04af989f107ab980d64c92fd8f",
            "title": "Context-Aware Clustering using Large Language Models",
            "abstract": "Despite the remarkable success of Large Language Models (LLMs) in text understanding and generation, their potential for text clustering tasks remains underexplored. We observed that powerful closed-source LLMs provide good quality clusterings of entity sets but are not scalable due to the massive compute power required and the associated costs. Thus, we propose CACTUS (Context-Aware ClusTering with aUgmented triplet losS), a systematic approach that leverages open-source LLMs for efficient and effective supervised clustering of entity subsets, particularly focusing on text-based entities. Existing text clustering methods fail to effectively capture the context provided by the entity subset. Moreover, though there are several language modeling based approaches for clustering, very few are designed for the task of supervised clustering. This paper introduces a novel approach towards clustering entity subsets using LLMs by capturing context via a scalable inter-entity attention mechanism. We propose a novel augmented triplet loss function tailored for supervised clustering, which addresses the inherent challenges of directly applying the triplet loss to this problem. Furthermore, we introduce a self-supervised clustering task based on text augmentation techniques to improve the generalization of our model. For evaluation, we collect ground truth clusterings from a closed-source LLM and transfer this knowledge to an open-source LLM under the supervised clustering framework, allowing a faster and cheaper open-source model to perform the same task. Experiments on various e-commerce query and product clustering datasets demonstrate that our proposed approach significantly outperforms existing unsupervised and supervised baselines under various external clustering evaluation metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121914227",
                    "name": "Sindhu Tipirneni"
                },
                {
                    "authorId": "2299329980",
                    "name": "Ravinarayana Adkathimar"
                },
                {
                    "authorId": "2262444503",
                    "name": "Nurendra Choudhary"
                },
                {
                    "authorId": "46566733",
                    "name": "G. Hiranandani"
                },
                {
                    "authorId": "2370909",
                    "name": "Rana Ali Amjad"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2299926084",
                    "name": "Changhe Yuan"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "287a30043ad1c3e349095af7e3e42d3be3b6c0c9",
            "title": "SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training",
            "abstract": "In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic multi-modal understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training model, which employs contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic supervision enhances the embeddings of numeric data and vice versa. We evaluate SNIP across diverse tasks, including symbolic-to-numeric mathematical property prediction and numeric-to-symbolic equation discovery, commonly known as symbolic regression. Results show that SNIP effectively transfers to various tasks, consistently outperforming fully supervised baselines and competing strongly with established task-specific methods, especially in the low data regime scenarios where available data is limited. Code and model are available at: https://github.com/deep-symbolic-mathematics/Multimodal-Math-Pretraining",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1999900316",
                    "name": "Kazem Meidani"
                },
                {
                    "authorId": "2037848556",
                    "name": "Parshin Shojaee"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "3614493",
                    "name": "A. Farimani"
                }
            ]
        },
        {
            "paperId": "883dab9410349f0660c6d6b05e4409525185f0c3",
            "title": "Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach",
            "abstract": "The progress in hyperbolic neural networks (HNNs) research is hindered by their absence of inductive bias mechanisms, which are essential for generalizing to new tasks and facilitating scalable learning over large datasets. In this paper, we aim to alleviate these issues by learning generalizable inductive biases from the nodes' local subgraph and transfer them for faster learning over new subgraphs with a disjoint set of nodes, edges, and labels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph Meta Learner (H-GRAM), that, for the tasks of node classification and link prediction, learns transferable information from a set of support local subgraphs in the form of hyperbolic meta gradients and label hyperbolic protonets to enable faster learning over a query set of new tasks dealing with disjoint subgraphs. Furthermore, we show that an extension of our meta-learning framework also mitigates the scalability challenges seen in HNNs faced by existing approaches. Our comparative analysis shows that H-GRAM effectively learns and transfers information in multiple challenging few-shot settings compared to other state-of-the-art baselines. Additionally, we demonstrate that, unlike standard HNNs, our approach is able to scale over large graph datasets and improve performance over its Euclidean counterparts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262444503",
                    "name": "Nurendra Choudhary"
                },
                {
                    "authorId": "2262445672",
                    "name": "Nikhil Rao"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                }
            ]
        }
    ]
}