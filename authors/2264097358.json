{
    "authorId": "2264097358",
    "papers": [
        {
            "paperId": "321129c86cfddde76638cdcd7ba3d56d8788015c",
            "title": "Cumulative Distribution Function based General Temporal Point Processes",
            "abstract": "Temporal Point Processes (TPPs) hold a pivotal role in modeling event sequences across diverse domains, including social networking and e-commerce, and have significantly contributed to the advancement of recommendation systems and information retrieval strategies. Through the analysis of events such as user interactions and transactions, TPPs offer valuable insights into behavioral patterns, facilitating the prediction of future trends. However, accurately forecasting future events remains a formidable challenge due to the intricate nature of these patterns. The integration of Neural Networks with TPPs has ushered in the development of advanced deep TPP models. While these models excel at processing complex and nonlinear temporal data, they encounter limitations in modeling intensity functions, grapple with computational complexities in integral computations, and struggle to capture long-range temporal dependencies effectively. In this study, we introduce the CuFun model, representing a novel approach to TPPs that revolves around the Cumulative Distribution Function (CDF). CuFun stands out by uniquely employing a monotonic neural network for CDF representation, utilizing past events as a scaling factor. This innovation significantly bolsters the model's adaptability and precision across a wide range of data scenarios. Our approach addresses several critical issues inherent in traditional TPP modeling: it simplifies log-likelihood calculations, extends applicability beyond predefined density function forms, and adeptly captures long-range temporal patterns. Our contributions encompass the introduction of a pioneering CDF-based TPP model, the development of a methodology for incorporating past event information into future event prediction, and empirical validation of CuFun's effectiveness through extensive experimentation on synthetic and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2253844324",
                    "name": "Yu Pan"
                },
                {
                    "authorId": "2238898625",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2282243915",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2223875866",
                    "name": "Langming Liu"
                }
            ]
        },
        {
            "paperId": "8c91b5f7d3116662a465e749b5dde2f178cfac8a",
            "title": "EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems",
            "abstract": "In this age where data is abundant, the ability to distill meaningful insights from the sea of information is essential. Our research addresses the computational and resource inefficiencies that current Sequential Recommender Systems (SRSs) suffer from. especially those employing attention-based models like SASRec, These systems are designed for next-item recommendations in various applications, from e-commerce to social networks. However, such systems suffer from substantial computational costs and resource consumption during the inference stage. To tackle these issues, our research proposes a novel method that combines automatic pruning techniques with advanced model architectures. We also explore the potential of resource-constrained Neural Architecture Search (NAS), a technique prevalent in the realm of recommendation systems, to fine-tune models for reduced FLOPs, latency, and energy usage while retaining or even enhancing accuracy. The main contribution of our work is developing the Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems (EASRec). This approach aims to find optimal compact architectures for attention-based SRSs, ensuring accuracy retention. EASRec introduces data-aware gates that leverage historical information from input data batch to improve the performance of the recommendation network. Additionally, it utilizes a dynamic resource constraint approach, which standardizes the search process and results in more appropriate architectures. The effectiveness of our methodology is validated through exhaustive experiments on three benchmark datasets, which demonstrates EASRec's superiority in SRSs. Our research set a new standard for future exploration into efficient and accurate recommender systems, signifying a substantial advancement within this swiftly advancing field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282233261",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2240539453",
                    "name": "Chenyi Zhuang"
                },
                {
                    "authorId": "2266811973",
                    "name": "Jinjie Gu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2187882131",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2282271789",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "032fa238d13835662d636553e9ca1b778ac8f88b",
            "title": "Large Multimodal Model Compression via Iterative Efficient Pruning and Distillation",
            "abstract": "The deployment of Large Multimodal Models (LMMs) within Ant Group has significantly advanced multimodal tasks in payment, security, and advertising, notably enhancing advertisement audition tasks in Alipay. However, the deployment of such sizable models introduces challenges, particularly in increased latency and carbon emissions, which are antithetical to the ideals of Green AI. This paper introduces a novel multi-stage compression strategy for our proprietary LLM, AntGMM. Our methodology pivots on three main aspects: employing small training sample sizes, addressing multi-level redundancy through multi-stage pruning, and introducing an advanced distillation loss design. In our research, we constructed a dataset, the Multimodal Advertisement Audition Dataset (MAAD), from real-world scenarios within Alipay, and conducted experiments to validate the reliability of our proposed strategy. Furthermore, the effectiveness of our strategy is evident in its operational success in Alipay's real-world multimodal advertisement audition for three months from September 2023. Notably, our approach achieved a substantial reduction in latency, decreasing it from 700ms to 90ms, while maintaining online performance with only a slight performance decrease. Moreover, our compressed model is estimated to reduce electricity consumption by approximately 75 million kWh annually compared to the direct deployment of AntGMM, demonstrating our commitment to green AI initiatives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2273557310",
                    "name": "Jiajia Liu"
                },
                {
                    "authorId": "2273419378",
                    "name": "Jingdong Chen"
                },
                {
                    "authorId": "2240539453",
                    "name": "Chenyi Zhuang"
                },
                {
                    "authorId": "2266811973",
                    "name": "Jinjie Gu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "0ad3bd46c121a1a85b2d246242f34170e2090469",
            "title": "SMLP4Rec: An Efficient All-MLP Architecture for Sequential Recommendations",
            "abstract": "Self-attention models have achieved the state-of-the-art performance in sequential recommender systems by capturing the sequential dependencies among user\u2013item interactions. However, they rely on adding positional embeddings to the item sequence to retain the sequential information, which may break the semantics of item embeddings due to the heterogeneity between these two types of embeddings. In addition, most existing works assume that such dependencies exist solely in the item embeddings, but neglect their existence among the item features. In our previous study, we proposed a novel sequential recommendation model, i.e., MLP4Rec, based on the recent advances of MLP-Mixer architectures, which is naturally sensitive to the order of items in a sequence because matrix elements related to different positions of a sequence will be given different weights in training. We developed a tri-directional fusion scheme to coherently capture sequential, cross-channel, and cross-feature correlations with linear computational complexity as well as much fewer model parameters than existing self-attention methods. However, the cascading mixer structure, the large number of normalization layers between different mixer layers, and the noise generated by these operations limit the efficiency of information extraction and the effectiveness of MLP4Rec. In this extended version, we propose a novel framework \u2013 SMLP4Rec for sequential recommendation to address the aforementioned issues. The new framework changes the flawed cascading structure to a parallel mode, and integrates normalization layers to minimize their impact on the model\u2019s efficiency while maximizing their effectiveness. As a result, the training speed and prediction accuracy of SMLP4Rec are vastly improved in comparison to MLP4Rec. Extensive experimental results demonstrate that the proposed method is significantly superior to the state-of-the-art approaches. The implementation code is available online to ease reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2187870890",
                    "name": "Muyang Li"
                },
                {
                    "authorId": "2152527913",
                    "name": "Minghao Zhao"
                },
                {
                    "authorId": "2239054423",
                    "name": "Runze Wu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2249554788",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "2240617631",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "5d343ef364705045bb5def6c4cb138bb6cec1b3b",
            "title": "Federated Knowledge Graph Completion via Latent Embedding Sharing and Tensor Factorization",
            "abstract": "Knowledge graphs (KGs), which consist of triples, are inherently incomplete and always require completion procedure to predict missing triples. In real-world scenarios, KGs are distributed across clients, complicating completion tasks due to privacy restrictions. Many frameworks have been proposed to address the issue of federated knowledge graph completion. However, the existing frameworks, including FedE, FedR, and FEKG, have certain limitations. = FedE poses a risk of information leakage, FedR\u2019s optimization efficacy diminishes when there is minimal overlap among relations, and FKGE suffers from computational costs and mode collapse issues. To address these issues, we propose a novel method, i.e., Federated Latent Embedding Sharing Tensor factorization (FLEST), which is a novel approach using federated tensor factorization for KG completion. FLEST decompose the embedding matrix and enables sharing of latent dictionary embeddings to lower privacy risks. Empirical results demonstrate FLEST\u2019s effectiveness and efficiency, offering a balanced solution between performance and privacy. FLEST expands the application of federated tensor factorization in KG completion tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2120902779",
                    "name": "Dun Zeng"
                },
                {
                    "authorId": "2238898625",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "85bbc8af01084d2328c49cb3c70241c76e3ef4d5",
            "title": "Embedding in Recommender Systems: A Survey",
            "abstract": "Recommender systems have become an essential component of many online platforms, providing personalized recommendations to users. A crucial aspect is embedding techniques that coverts the high-dimensional discrete features, such as user and item IDs, into low-dimensional continuous vectors and can enhance the recommendation performance. Applying embedding techniques captures complex entity relationships and has spurred substantial research. In this survey, we provide an overview of the recent literature on embedding techniques in recommender systems. This survey covers embedding methods like collaborative filtering, self-supervised learning, and graph-based techniques. Collaborative filtering generates embeddings capturing user-item preferences, excelling in sparse data. Self-supervised methods leverage contrastive or generative learning for various tasks. Graph-based techniques like node2vec exploit complex relationships in network-rich environments. Addressing the scalability challenges inherent to embedding methods, our survey delves into innovative directions within the field of recommendation systems. These directions aim to enhance performance and reduce computational complexity, paving the way for improved recommender systems. Among these innovative approaches, we will introduce Auto Machine Learning (AutoML), hash techniques, and quantization techniques in this survey. We discuss various architectures and techniques and highlight the challenges and future directions in these aspects. This survey aims to provide a comprehensive overview of the state-of-the-art in this rapidly evolving field and serve as a useful resource for researchers and practitioners working in the area of recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2262447995",
                    "name": "Xinjian Zhao"
                },
                {
                    "authorId": "2262510496",
                    "name": "Jiansheng Li"
                },
                {
                    "authorId": "2262865343",
                    "name": "Shucheng Zhou"
                },
                {
                    "authorId": "2240617631",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2297955888",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                }
            ]
        },
        {
            "paperId": "99e10eb07961b5947512bd448df180d32ca8b319",
            "title": "Large Multimodal Model Compression via Efficient Pruning and Distillation at AntGroup",
            "abstract": "ThedeploymentofLargeMultimodalModels(LMMs)withinAntGroup hassignificantlyadvancedmultimodaltasksinpayment,security, andadvertising,notablyenhancingadvertisementauditiontasksin Alipay.However,thedeploymentofsuchsizablemodelsintroduces challenges,particularlyinincreasedlatencyandcarbonemissions, whichareantitheticaltotheidealsofGreenAI.Thispaperintro-ducesanovelmulti-stagecompressionstrategyforourproprietary LLM,AntGMM.Ourmethodologypivotsonthreemainaspects: employingsmalltrainingsamplesizes,addressingmulti-levelredun-dancythroughmulti-stagepruning,andintroducinganadvanced distillationlossdesign.Inourresearch,weconstructedadataset, theMultimodalAdvertisementAuditionDataset(MAAD),from real-worldscenarioswithinAlipay,andconductedexperimentsto validatethereliabilityofourproposedstrategy.Furthermore,the effectivenessofourstrategyisevidentinitsoperationalsuccessin Alipay\u2019sreal-worldmultimodaladvertisementauditionforthree monthsfromSeptember2023.Notably,ourapproachachieveda substantialreductioninlatency,decreasingitfrom700msto90ms, whilemaintainingonlineperformancewithonlyaslightperfor-mancedecrease.Moreover,ourcompressedmodelisestimatedto reduceelectricityconsumptionbyapproximately75millionkWh",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2273557310",
                    "name": "Jiajia Liu"
                },
                {
                    "authorId": "2273419378",
                    "name": "Jingdong Chen"
                },
                {
                    "authorId": "2240539453",
                    "name": "Chenyi Zhuang"
                },
                {
                    "authorId": "2266811973",
                    "name": "Jinjie Gu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        }
    ]
}