{
    "authorId": "2389278",
    "papers": [
        {
            "paperId": "058647249d5534b29805390e5f4dade08728ece5",
            "title": "ReApprox-PIM: Reconfigurable Approximate Lookup-Table (LUT)-Based Processing-in-Memory (PIM) Machine Learning Accelerator",
            "abstract": "Convolutional neural networks (CNNs) have achieved significant success in various applications. Numerous hardware accelerators are introduced to accelerate CNN execution with improved energy efficiency compared to traditional software implementations. Despite the achieved success, deploying traditional hardware accelerators for bulky CNNs on current and emerging smart devices is impeded by limited resources, including memory, power, area, and computational capabilities. Recent works introduced processing-in-memory (PIM), a non-Von-Neumann architecture, which is a promising approach to tackle the problem of data movement between logic and memory blocks. However, as observed from the literature, the existing PIM architectures cannot congregate all the computational operations due to limited programmability and flexibility. Furthermore, the capabilities of the PIM are challenged by the limited available on-chip memory. To enable faster computations and address the limited on-chip memory constraints, this work introduces a novel reconfigurable approximate computing (AC)-based PIM, termed reconfigurable approximate PIM (ReApprox-PIM). The proposed ReApprox-PIM is capable of addressing the two challenges mentioned above in the following manner: 1) it utilizes a programmable lookup-table (LUT)-based processing architecture that can support different AC techniques via programmability and 2) followed by resource-efficient, fast CNN computing via the implementation of highly optimized AC techniques. This results in improved computing footprint, operational parallelism, and reduced computational latency and power consumption compared to prior PIMs relying on exact computations for CNN inference acceleration at a minimal sacrifice of accuracy. We have evaluated the proposed ReApprox-PIM on various CNN architectures, for inference applications, including standard LeNet, AlexNet, ResNet-18, \u221234, and \u221250. Our experimental results show that the ReApprox-PIM achieves a speedup of <inline-formula> <tex-math notation=\"LaTeX\">$1.63\\times $ </tex-math></inline-formula> with <inline-formula> <tex-math notation=\"LaTeX\">$1.66\\times $ </tex-math></inline-formula> lower area for the processing components compared to the existing PIM architectures. Furthermore, the proposed ReApprox-PIM achieves <inline-formula> <tex-math notation=\"LaTeX\">$2.5\\times $ </tex-math></inline-formula> higher energy efficiency and <inline-formula> <tex-math notation=\"LaTeX\">$1.3\\times $ </tex-math></inline-formula> higher throughput compared to the state-of-the-art LUT-based PIM architectures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1928509498",
                    "name": "Sathwika Bavikadi"
                },
                {
                    "authorId": "1928910427",
                    "name": "Purab Ranjan Sutradhar"
                },
                {
                    "authorId": "3192015",
                    "name": "Mark A. Indovina"
                },
                {
                    "authorId": "40413136",
                    "name": "A. Ganguly"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "0a2a59267405b553a8dc10d99278d5cfc12056f9",
            "title": "The Emergence of Hardware Fuzzing: A Critical Review of its Significance",
            "abstract": "In recent years, there has been a notable surge in attention towards hardware security, driven by the increasing complexity and integration of processors, SoCs, and third-party IPs aimed at delivering advanced solutions. However, this complexity also introduces vulnerabilities and bugs into hardware systems, necessitating early detection during the IC design cycle to uphold system integrity and mitigate re-engineering costs. While the Design Verification (DV) community employs dynamic and formal verification strategies, they encounter challenges such as scalability for intricate designs and significant human intervention, leading to prolonged verification durations. As an alternative approach, hardware fuzzing, inspired by software testing methodologies, has gained prominence for its efficacy in identifying bugs within complex hardware designs. Despite the introduction of various hardware fuzzing techniques, obstacles such as inefficient conversion of hardware modules into software models impede their effectiveness. This Systematization of Knowledge (SoK) initiative delves into the fundamental principles of existing hardware fuzzing, methodologies, and their applicability across diverse hardware designs. Additionally, it evaluates factors such as the utilization of golden reference models (GRMs), coverage metrics, and toolchains to gauge their potential for broader adoption, akin to traditional formal verification methods. Furthermore, this work examines the reliability of existing hardware fuzzing techniques in identifying vulnerabilities and identifies research gaps for future advancements in design verification techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2176845623",
                    "name": "Raghul Saravanan"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "0cd334b6c18c955662a5bf7f38ba724cd7862d1d",
            "title": "3DL-PIM: A Look-Up Table Oriented Programmable Processing in Memory Architecture Based on the 3-D Stacked Memory for Data-Intensive Applications",
            "abstract": "Memory-centric computing systems have demonstrated superior performance and efficiency in memory-intensive applications compared to state-of-the-art CPUs and GPUs. 3-D stacked DRAM architectures unlock higher I/O data bandwidth than the traditional 2-D memory architecture and therefore are better suited for incorporating memory-centric processors. However, merely integrating high-precision ALUs in the 3-D stacked memory does not ensure an optimized design since such a design can only achieve a limited utilization of the internal bandwidth of a memory chip and limited operational parallelization. To address this, we propose 3DL-PIM, a 3-D stacked memory-based Processing in Memory (PIM) architecture that locates a plurality of Look-up Table (LUT)-based low-footprint Processing Elements (PE) within the memory banks in order to achieve high parallel computing performance by maximizing data-bandwidth utilization. Instead of relying on the traditional logic-based ALUs, the PEs are formed by clustering a group of programmable LUTs and therefore can be programmed on-the-fly to perform various logic/arithmetic operations. Our simulations show that 3DL-PIM can achieve respectively up to 2.6\u00d7 higher processing performance at 2.65\u00d7 higher area efficiency compared to a state-of-the-art 3-D stacked memory-based accelerator.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1928910427",
                    "name": "Purab Ranjan Sutradhar"
                },
                {
                    "authorId": "1928509498",
                    "name": "Sathwika Bavikadi"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                },
                {
                    "authorId": "3192015",
                    "name": "Mark A. Indovina"
                },
                {
                    "authorId": "40413136",
                    "name": "A. Ganguly"
                }
            ]
        },
        {
            "paperId": "110791ed41047d1fb0ad05283d5129e7e80fa2a5",
            "title": "Bring it On: Kinetic Energy Harvesting to Spark Machine Learning Computations in IoTs",
            "abstract": "The widespread adoption of Internet of Things (IoTs) and edge computing devices has made them an integral part of our daily lives. The popularity of these devices has surged, especially with the advancements in wearable technology, such as smartwatches, health and fitness trackers, and smart glasses. These devices are equipped with various sensors that allow researchers and manufacturers to capture user data, which is then processed using on-device Machine Learning (ML) algorithms to enhance the user experience. However, running ML algorithms on these small IoTs and edge devices consumes a significant amount of power and energy. It is crucial to note that these devices are designed with tight energy and power constraints. Optimizing battery usage is paramount to prolonging the longevity of these devices. This paper proposes a framework that efficiently harnesses kinetic energy harvesting to intermittently support ML computations/tasks, thereby reducing the load on in-built battery. The primary goal of the proposed framework is to reduce the reliance on the device\u2019s built-in battery power by offloading the ML computation to harvested kinetic energy. This framework integrates energy and memory-efficient checkpointing with Energy- aware Early Exit Neural Networks to manage harvested kinetic energy optimally. Through experiments and analysis, the results demonstrate that the proposed framework effectively utilizes harvested kinetic energy to perform necessary ML computations during inference/testing, thus reducing the energy footprint.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1474544063",
                    "name": "Sanket Shukla"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "1a6c3dfb4551e4af82a4138684df562bfca21f54",
            "title": "Generative AI-Based Effective Malware Detection for Embedded Computing Systems",
            "abstract": "One of the pivotal security threats for the embedded computing systems is malicious software a.k.a malware. With efficiency and efficacy, Machine Learning (ML) has been widely adopted for malware detection in recent times. Despite being efficient, the existing techniques require a tremendous number of benign and malware samples for training and modeling an efficient malware detector. Furthermore, such constraints limit the detection of emerging malware samples due to the lack of sufficient malware samples required for efficient training. To address such concerns, we introduce a code-aware data generation technique that generates multiple mutated samples of the limitedly seen malware by the devices. Loss minimization ensures that the generated samples closely mimic the limitedly seen malware and mitigate the impractical samples. Such developed malware is further incorporated into the training set to formulate the model that can efficiently detect the emerging malware despite having limited exposure. The experimental results demonstrates that the proposed technique achieves an accuracy of 90% in detecting limitedly seen malware, which is approximately 3x more than the accuracy attained by state-of-the-art techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114853982",
                    "name": "Sreenitha Kasarapu"
                },
                {
                    "authorId": "1474544063",
                    "name": "Sanket Shukla"
                },
                {
                    "authorId": "1474539078",
                    "name": "Rakibul Hassan"
                },
                {
                    "authorId": "1928425942",
                    "name": "Avesta Sasan"
                },
                {
                    "authorId": "1747542",
                    "name": "H. Homayoun"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "337143f70dbc6d1ac87eb2b37de3caf92411e806",
            "title": "Dynamic Exit Selection for Comprehensive and Energy Efficient Gait-Based User Authentication on IoT Devices",
            "abstract": "In this study, we introduce Apollo, a dynamic and efficient gait-based user authentication system for Internet-of-Things (IoT) devices, which leverages the dynamic Early-Exit Neural Networks (EENets). As IoT devices proliferate across various applications, the need for effective authentication methods that cater to their resource constraints becomes crucial. Traditional authentication techniques, while robust, often fall short due to their high resource demands, making them unsuitable for IoT contexts. Gait-based authentication emerges as a viable solution, offering a non-intrusive and secure method. However, the implementation of gait-based authentication faces challenges, particularly due to the limited computational resources and stringent energy constraints of IoT devices. Our framework addresses these challenges by orchestrating Dynamic EENets, intermittent computing, and energy harvesting, enabling authentication with minimal or even negative energy consumption. Our approach is distinguished by the use of dynamic exit selection for EENets, which are lightweight, energy-aware, and capable of dynamically selecting the most appropriate time to exit based on current computational and energy resources. This adaptability ensures efficient authentication, reducing the overall computational load. Additionally, to overcome energy limitations, Apollo incorporates piezoelectric energy harvesting from user movements, further enhancing its viability for IoT applications. Our experimental results underscore Apollo's effectiveness, demonstrating over 85% accuracy in user authentication while significantly reducing computational demands by more than 34%. This blend of dynamic exit strategies, energy harvesting, and intermittent computing not only highlights the novelty of our research but also sets a new benchmark for gait-based authentication in IoT devices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2190510391",
                    "name": "Pavlos Zouridakis"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "7bcab9a495b879686468aca404aebe861e613933",
            "title": "Empowering Malware Detection Efficiency within Processing-in-Memory Architecture",
            "abstract": "The widespread integration of embedded systems across various industries has facilitated seamless connectivity among devices and bolstered computational capabilities. Despite their extensive applications, embedded systems encounter significant security threats, with one of the most critical vulnerabilities being malicious software, commonly known as malware. In recent times, malware detection techniques leveraging Machine Learning have gained popularity. Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) have proven particularly efficient in image processing tasks. However, one major drawback of neural network architectures is their substantial computational resource requirements. Continuous training of malware detection models with updated malware and benign samples demands immense computational resources, presenting a challenge for real-world applications. In response to these concerns, we propose a Processing-in-Memory (PIM)-based architecture to mitigate memory access latency, thereby reducing the resources consumed during model updates. To further enhance throughput and minimize energy consumption, we incorporate precision scaling techniques tailored for CNN models. Our proposed PIM architecture exhibits a 1.09x higher throughput compared to existing Lookup Table (LUT)-based PIM architectures. Additionally, precision scaling combined with PIM enhances energy efficiency by 1.5x compared to full-precision operations, without sacrificing performance. This innovative approach offers a promising solution to the resource-intensive nature of malware detection model updates, paving the way for more efficient and sustainable cybersecurity practices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114853982",
                    "name": "Sreenitha Kasarapu"
                },
                {
                    "authorId": "1928509498",
                    "name": "Sathwika Bavikadi"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "828081ccbdb502add713336c04054528c8be03c3",
            "title": "Reconfigurable Processing-in-Memory Architecture for Data Intensive Applications",
            "abstract": "Emerging applications reliant on deep neural networks (DNNs) and convolutional neural networks (CNNs) demand substantial data for computation and analysis. Deploying DNNs and CNNs often leads to resource constraints, data movement overheads between memory and compute units. Architectural paradigms like Processing-in-Memory (PIM) have emerged to mitigate these challenges. However, existing PIM architectures necessitate trade-offs involving power, performance, area, energy efficiency, and programmability. Our proposed solution focuses on achieving higher energy efficiency while preserving programmability and flexibility. We introduce a novel multi-core reconfigurable architecture with fine-grained integration within DRAM sub-arrays, resulting in superior performance and energy-efficiency compared to conventional PIM architectures. Each core in our design comprises multiple processing elements (PEs), standalone processors equipped with programmable functional units constructed using high-speed reconfigurable multi-functional look-up-tables (M-LUTs). These M-LUTs enable multiple functional outputs, such as convolution, pooling, and activation functions, in a time-multiplexed manner, eliminating the need for different LUTs for each function. Special function LUTs provide simultaneous outputs, enabling ultra-low latency parallel processing for tasks like multiplication and accumulation, along with functions like activation, pooling, and batch-normalization required for CNN acceleration. This comprehensive approach enhances efficiency and performance, rendering our reconfigurable architecture suitable for demanding Big Data and AI acceleration applications",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1928509498",
                    "name": "Sathwika Bavikadi"
                },
                {
                    "authorId": "1928910427",
                    "name": "Purab Ranjan Sutradhar"
                },
                {
                    "authorId": "40413136",
                    "name": "A. Ganguly"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "ac02d2de729b4809035deb2f40b3c6aba661fa4a",
            "title": "Optimizing Malware Detection in IoT Networks: Leveraging Resource-Aware Distributed Computing for Enhanced Security",
            "abstract": "In recent years, networked IoT systems have revolutionized connectivity, portability, and functionality, offering a myriad of advantages. However, these systems are increasingly targeted by adversaries due to inherent security vulnerabilities and limited computational and storage resources. Malicious applications, commonly known as malware, pose a significant threat to IoT devices and networks. While numerous malware detection techniques have been proposed, existing approaches often overlook the resource constraints inherent in IoT environments, assuming abundant resources for detection tasks. This oversight is compounded by ongoing workloads such as sensing and on-device computations, further diminishing available resources for malware detection. To address these challenges, we present a novel resource- and workload-aware malware detection framework integrated with distributed computing for IoT networks. Our approach begins by analyzing available resources for malware detection using a lightweight regression model. Depending on resource availability, ongoing workload executions, and communication costs, the malware detection task is dynamically allocated either on-device or offloaded to neighboring IoT nodes with sufficient resources. To safeguard data integrity and user privacy, rather than transferring the entire malware detection task, the classifier is partitioned and distributed across multiple nodes, and subsequently integrated at the parent node for comprehensive malware detection. Experimental analysis demonstrates the efficacy of our proposed technique, achieving a remarkable speed-up of 9.8x compared to on-device inference, while maintaining a high malware detection accuracy of 96.7%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114853982",
                    "name": "Sreenitha Kasarapu"
                },
                {
                    "authorId": "1474544063",
                    "name": "Sanket Shukla"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        },
        {
            "paperId": "dce8c4ac50ea69bd8e28ec0fca0d05560b9353a8",
            "title": "Processing-in-Memory Architecture with Precision-Scaling for Malware Detection",
            "abstract": "The wide adaptations of embedded systems in multiple fields have led to smart connectivity across devices and enhanced computation capabilities. Despite the vast applications in different areas, embedded systems face huge security threats. One of the critical security vulnerabilities is caused by malicious software a.k.a malware. Successful malware detection by employing Machine Learning (ML) is widely adopted in many systems. One of the prominent challenges in implementing neural network (NN) architectures is the requirement to have a large number of computational resources. Furthermore, the frequent movement of data between logic and memory units adds large overheads. Conversely, the IoT and edge devices are often limited in terms of the number of available resources. As a panacea, we introduce a PIM-based architecture to address such concerns and improve memory access latency. Such a paradigm further enriches the malware detection latency by mitigating the data transfer latency. To further improve the throughput and energy consumption, we employ precision scaling for the PIM-based malware detection in this work. We observe a malware detection accuracy of 98% with the proposed technique. Our proposed PIM architecture has $1.09 \\times$ higher throughput than other traditional PIM architectures. Furthermore, precision scaling and PIM improve the energy efficiency by $1.5 \\times$ compared to the full-precision operation without any penalty in performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114853982",
                    "name": "Sreenitha Kasarapu"
                },
                {
                    "authorId": "1928509498",
                    "name": "Sathwika Bavikadi"
                },
                {
                    "authorId": "2389278",
                    "name": "Sai Manoj Pudukotai Dinakarrao"
                }
            ]
        }
    ]
}