{
    "authorId": "2092368",
    "papers": [
        {
            "paperId": "7a82b4ddbb33d6a89ecad05b56cbc7c47bb4bb13",
            "title": "How Good are LLMs in Generating Personalized Advertisements?",
            "abstract": "In this paper, we explore the potential of large language models (LLMs) in generating personalized online advertisements (ads) tailored to specific personality traits, focusing on openness and neuroticism. We conducted a user study involving two tasks to understand the performance of LLM-generated ads compared to human-written ads in different online environments. Task 1 simulates a social media environment where users encounter ads while scrolling through their feed. Task 2 mimics a shopping website environment where users are presented with multiple sponsored products side-by-side. Our results indicate that LLM-generated ads targeting the openness trait positively impact user engagement and preferences, with performance comparable to human-written ads. Furthermore, in both scenarios, the overall effectiveness of LLM-generated ads was found to be similar to that of human-written ads, highlighting the potential of LLM-generated personalised content to rival traditional advertising methods with the added advantage of scalability. This study underscores the need for cautious consideration in the deployment of LLM-generated content at scale. While our findings confirm the scalability and potential effectiveness of LLM-generated content, there is an equally pressing concern about the ease with which it can be misused.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301162964",
                    "name": "Elyas Meguellati"
                },
                {
                    "authorId": "2112660847",
                    "name": "Lei Han"
                },
                {
                    "authorId": "2285206271",
                    "name": "Abraham Bernstein"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "2237834489",
                    "name": "Gianluca Demartini"
                }
            ]
        },
        {
            "paperId": "cba74e0f34cab9b27b9075d6b933caf59267b7ba",
            "title": "Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods",
            "abstract": "Organizations face the challenge of ensuring compliance with an increasing amount of requirements from various regulatory documents. Which requirements are relevant depends on aspects such as the geographic location of the organization, its domain, size, and business processes. Considering these contextual factors, as a first step, relevant documents (e.g., laws, regulations, directives, policies) are identified, followed by a more detailed analysis of which parts of the identified documents are relevant for which step of a given business process. Nowadays the identification of regulatory requirements relevant to business processes is mostly done manually by domain and legal experts, posing a tremendous effort on them, especially for a large number of regulatory documents which might frequently change. Hence, this work examines how legal and domain experts can be assisted in the assessment of relevant requirements. For this, we compare an embedding-based NLP ranking method, a generative AI method using GPT-4, and a crowdsourced method with the purely manual method of creating relevancy labels by experts. The proposed methods are evaluated based on two case studies: an Australian insurance case created with domain experts and a global banking use case, adapted from SAP Signavio's workflow example of an international guideline. A gold standard is created for both BPMN2.0 processes and matched to real-world textual requirements from multiple regulatory documents. The evaluation and discussion provide insights into strengths and weaknesses of each method regarding applicability, automation, transparency, and reproducibility and provide guidelines on which method combinations will maximize benefits for given characteristics such as process usage, impact, and dynamics of an application scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2219779350",
                    "name": "Catherine Sai"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "2112660847",
                    "name": "Lei Han"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "2237649528",
                    "name": "Stefanie Rinderle-Ma"
                }
            ]
        },
        {
            "paperId": "0540d0f570ba79c3518a2c33e4224132c415a0a2",
            "title": "DataOps-4G: On Supporting Generalists in Data Quality Discovery",
            "abstract": "Data preparation has become a necessary but labor and resource-intensive step to perform data analytics. To date, such activities still require considerable manual effort from experts. In this paper, we focus on a specific data preparation activity, namely data quality discovery. We explore different settings in which data workers undertake data quality discovery tasks and the implications of those settings for the efficiency and effectiveness of data workers. To this end, we propose DataOps-4G, a data quality discovery platform for generalists that allows users to interact with data without the need to write code. We wrap up pre-defined code snippets that implement useful functionalities to explore data quality and bundle the code into so-called DataOps. Then, we conduct a lab-based user study to evaluate our DataOps-4G platform from two perspectives: (i) effectiveness, the accuracy of the outcomes achieved by participants; and (ii) efficiency, their effort and strategies in task completion. Our experimental results uncover how effectiveness and efficiency can be affected by their task completion patterns and strategies. This opens up the possibility of popularizing data quality discovery processes by employing non-experts (e.g., from crowdsourcing platforms) and consequently allowing experts to focus on more complex activities (e.g., building machine learning models).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155808180",
                    "name": "Shaochen Yu"
                },
                {
                    "authorId": "51226297",
                    "name": "Tianwa Chen"
                },
                {
                    "authorId": "2112660847",
                    "name": "Lei Han"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                }
            ]
        },
        {
            "paperId": "10bf7808a599c4c94402eb18404d946fb6309a8e",
            "title": "Human-in-the-loop Regular Expression Extraction for Single Column Format Inconsistency",
            "abstract": "Format inconsistency is one of the most frequently appearing data quality issues encountered during data cleaning. Existing automated approaches commonly lack applicability and generalisability, while approaches with human inputs typically require specialized skills such as writing regular expressions. This paper proposes a novel hybrid human-machine system, namely \u201cData-Scanner-4C\u201d, which leverages crowdsourcing to address syntactic format inconsistencies in a single column effectively. We first ask crowd workers to create examples from single-column data through \u201cdata selection\u201d and \u201cresult validation\u201d tasks. Then, we propose and use a novel rule-based learning algorithm to infer the regular expressions that propagate formats from created examples to the entire column. Our system integrates crowdsourcing and algorithmic format extraction techniques in a single workflow. Having human experts write regular expressions is no longer required, thereby reducing both the time as well as the opportunity for error. We conducted experiments through both synthetic and real-world datasets, and our results show how the proposed approach is applicable and effective across data types and formats.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155808180",
                    "name": "Shaochen Yu"
                },
                {
                    "authorId": "2112660847",
                    "name": "Lei Han"
                },
                {
                    "authorId": "1780384",
                    "name": "M. Indulska"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                }
            ]
        },
        {
            "paperId": "5215a52205943e08c886948dc7881938ec5ee230",
            "title": "Diversity, Equity and Inclusion Activities in Database Conferences: A 2022 Report",
            "abstract": "The Diversity, Equity and Inclusion (DEI) initiative started as the Diversity/Inclusion initiative in 2020 [4]. The current report summarizes our activities in 2022. Our responsibility as a community is to ensure that attendees of DB conferences feel included, irrespective of their scientific perspective and personal background. One of the first steps was to establish the role of the DEI chairs at DB Conferences, with the DEI team dedicated to providing leadership to help our community achieve this goal. In this leadership role, the DEI team is advising DEI chairs at DB conferences, serving as a memory of DEI events at conferences, building an agreed-upon vision, and committing to working together to devise a set of measures for achieving DEI. That is pursued via actions led by our core members (Figure 1) and liaisons of individual executive bodies (Figure 2): REACH OUT collects data and experiences from our community. INCLUDE monitors and recommends inclusion efforts. ORGANIZE focuses on in-conference organization efforts, such as adopting a code of conduct. INFORM communicates through various channels. SUPPORT coordinates DEI support from executive bodies and sponsors. SCOUT collates DEI efforts from other communities. COORDINATE manages all actions. Two new actions: MEDIA preserves and disseminates the digital media produced by DEI@DB events. ETHICS establishes and promotes ethics guidelines for publications in our community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "143970078",
                    "name": "D. Agrawal"
                },
                {
                    "authorId": "1710637",
                    "name": "Yael Amsterdamer"
                },
                {
                    "authorId": "1730344",
                    "name": "S. Bhowmick"
                },
                {
                    "authorId": "1401945543",
                    "name": "Jes\u00fas Camacho-Rodr\u00edguez"
                },
                {
                    "authorId": "1726425",
                    "name": "B. Catania"
                },
                {
                    "authorId": "2091879100",
                    "name": "K. Panos"
                },
                {
                    "authorId": "2081044488",
                    "name": "Chrysanthis"
                },
                {
                    "authorId": "1692732",
                    "name": "C. Curino"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "152945656",
                    "name": "G. Dobbie"
                },
                {
                    "authorId": "1709353",
                    "name": "A. El Abbadi"
                },
                {
                    "authorId": "2223141115",
                    "name": "Avrilia"
                },
                {
                    "authorId": "2223141462",
                    "name": "Floratou"
                },
                {
                    "authorId": "2178387374",
                    "name": "Juliana Freire"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "1685532",
                    "name": "V. Kalogeraki"
                },
                {
                    "authorId": "51205357",
                    "name": "Sujaya Maiyya"
                },
                {
                    "authorId": "2079019460",
                    "name": "Alexandra"
                },
                {
                    "authorId": "2223137576",
                    "name": "Meliou"
                },
                {
                    "authorId": "37168010",
                    "name": "Madhulika Mohanty"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "2149251297",
                    "name": "Fatma \u00d6zcan"
                },
                {
                    "authorId": "3139922",
                    "name": "L. Peterfreund"
                },
                {
                    "authorId": "145492471",
                    "name": "Wenny Rahayu"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "2062657988",
                    "name": "Sana Sellami"
                },
                {
                    "authorId": "2388459",
                    "name": "Utku Sirin"
                },
                {
                    "authorId": "2131764025",
                    "name": "Wang-Chiew Tan"
                },
                {
                    "authorId": "2080239484",
                    "name": "Bhavani"
                },
                {
                    "authorId": "101679060",
                    "name": "Thuraisingham"
                },
                {
                    "authorId": "1392679676",
                    "name": "Neeraja"
                },
                {
                    "authorId": "2223141037",
                    "name": "Yadwadkar"
                },
                {
                    "authorId": "3010003",
                    "name": "Victor Zakhary"
                },
                {
                    "authorId": "2117848168",
                    "name": "Meihui Zhang"
                }
            ]
        },
        {
            "paperId": "595e9bf4dd91f43c90a35b9c3697c593265277a9",
            "title": "Variational Counterfactual Prediction Under Runtime Domain Corruption",
            "abstract": "To date, various neural methods have been proposed for causal effect estimation based on observational data, where a default assumption is the same distribution and availability of variables at both training and inference (i.e., runtime) stages. However, distribution shift (i.e., domain shift) could happen during runtime, and bigger challenges arise from the impaired accessibility of variables. This is commonly caused by increasing privacy and ethical concerns, which can make arbitrary variables unavailable in the entire runtime data and imputation impractical. We term the co-occurrence of domain shift and inaccessible variables runtime domain corruption, which seriously impairs the generalizability of a trained counterfactual predictor. To counter runtime domain corruption, we subsume counterfactual prediction under the notion of domain adaptation. Specifically, we upper-bound the error w.r.t. the target domain (i.e., runtime covariates) by the sum of source domain error and inter-domain distribution distance. In addition, we build an adversarially unified variational causal effect model, named VEGAN, with a novel two-stage adversarial domain adaptation scheme to reduce the latent distribution disparity between treated and control groups first, and between training and runtime variables afterwards. We demonstrate that VEGAN outperforms other state-of-the-art baselines on individual-level treatment effect estimation in the presence of runtime domain corruption on benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2220537781",
                    "name": "Hechuan Wen"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "47785475",
                    "name": "L. K. Chai"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "32278515",
                    "name": "Junbin Gao"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "616f11bcb826c7140dc2be7aecbfa647ade4338e",
            "title": "To Predict or to Reject: Causal Effect Estimation with Uncertainty on Networked Data",
            "abstract": "Due to the imbalanced nature of networked observational data, the causal effect predictions for some individuals can severely violate the positivity/overlap assumption, rendering unreliable estimations. Nevertheless, this potential risk of individual-level treatment effect estimation on networked data has been largely under-explored. To create a more trustworthy causal effect estimator, we propose the uncertainty-aware graph deep kernel learning (GraphDKL) framework with Lipschitz constraint to model the prediction uncertainty with Gaussian process and identify unreliable estimations. To the best of our knowledge, GraphDKL is the first framework to tackle the violation of positivity assumption when performing causal effect estimation with graphs. With extensive experiments, we demonstrate the superiority of our proposed method in uncertainty-aware causal effect estimation on networked data. The code of GraphDKL is available at https://github.com/uqhwen2/GraphDKL.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2220537781",
                    "name": "Hechuan Wen"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2242728642",
                    "name": "Li Kheng Chai"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "145487536",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "70bdb27c8ef2a22dc0c534bf3bbf9d2696f028c3",
            "title": "Assessing the Quality of Student-Generated Content at Scale: A Comparative Analysis of Peer-Review Models",
            "abstract": "Engaging students in creating learning resources has demonstrated pedagogical benefits. However, to effectively utilize a repository of student-generated content (SGC), a selection process is needed to separate high- from low-quality resources as some of the resources created by students can be ineffective, inappropriate, or incorrect. A common and scalable approach is to use a peer-review process where students are asked to assess the quality of resources authored by their peers. Given that judgments of students, as experts-in-training, cannot wholly be relied upon, a redundancy-based method is widely employed where the same assessment task is given to multiple students. However, this approach introduces a new challenge, referred to as the consensus problem: How can we assign a final quality to a resource given ratings by multiple students? To address this challenge, we investigate the predictive performance of 18 inference models across five well-established categories of consensus approaches for inferring the quality of SGC at scale. The analysis is based on the engagement of 2141 undergraduate students across five courses in creating 12 803 resources and 77 297 peer reviews. Results indicate that the quality of reviews is quite diverse, and students tend to overrate. Consequently, simple statistics such as mean and median fail to identify poor-quality resources. Findings further suggest that incorporating advanced probabilistic and text analysis methods to infer the reviewers' reliability and reviews' quality improves performance; however, there is still an evident need for instructor oversight and training of students to write compelling and reliable reviews.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "116007784",
                    "name": "A. Darvishi"
                },
                {
                    "authorId": "1508543895",
                    "name": "Hassan Khosravi"
                },
                {
                    "authorId": "143646155",
                    "name": "A. Rahimi"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "65953975",
                    "name": "D. Ga\u0161evi\u0107"
                }
            ]
        },
        {
            "paperId": "acad67d2505ffeab673eab6a1a048efe516bbac2",
            "title": "DEI Perspectives in Information Technology Education",
            "abstract": "Information Technology (IT) has become deeply intertwined with business and society across many, if not all sectors of the economy. The accelerated pace of development has resulted in regulatory frameworks and societal expectations lagging behind the design and use of IT artefacts. Education plays a fundamental role in ensuring that advancements in the field create benefits for all parts of society. To achieve societal benefits and mitigate potential disadvantage, it is imperative that Diversity, Equity and Inclusion (DEI) perspectives are embedded in the design and delivery of IT education. However, there are growing indications that the needs of learner populations have been shifting, and educational systems are struggling to adapt. The scale and diversity of the learner population has increased multi-fold, and at the same time shifts in learner expectations, have led to a rapid growth of new learning opportunities, e.g., through short online credentials, and community-based discussion forums. These challenges have initiated calls for urgent action for the educational landscape to evolve [1]. In this talk I will discuss some of these challenges. I will also share experiences and strategies for embedding DEI perspectives in (1) education of IT/CS including implications for curriculums; (2) education for future work environments that are inseparable from IT; and (3) education with technology enhanced education platforms and tools, including how the data management community can play a prominent role in the burgeoning Educational Technology (EdTech) and Artificial Intelligence in Education (AIEd) [2] research and development.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                }
            ]
        },
        {
            "paperId": "ff53a0a01fb34ea4d8efc59c368a7b1ef7e2b156",
            "title": "On the Impact of Showing Evidence from Peers in Crowdsourced Truthfulness Assessments",
            "abstract": "Misinformation has been rapidly spreading online. The common approach to dealing with it is deploying expert fact-checkers who follow forensic processes to identify the veracity of statements. Unfortunately, such an approach does not scale well. To deal with this, crowdsourcing has been looked at as an opportunity to complement the work done by trained journalists. In this article, we look at the effect of presenting the crowd with evidence from others while judging the veracity of statements. We implement variants of the judgment task design to understand whether and how the presented evidence may or may not affect the way crowd workers judge truthfulness and their performance. Our results show that, in certain cases, the presented evidence and the way in which it is presented may mislead crowd workers who would otherwise be more accurate if judging independently from others. Those who make appropriate use of the provided evidence, however, can benefit from it and generate better judgments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2163388279",
                    "name": "Jiechen Xu"
                },
                {
                    "authorId": "2112660847",
                    "name": "Lei Han"
                },
                {
                    "authorId": "2092368",
                    "name": "S. Sadiq"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                }
            ]
        }
    ]
}