{
    "authorId": "2064186990",
    "papers": [
        {
            "paperId": "874d19ebbe25d08b60ae531afadcad8ad7ac0c97",
            "title": "Unveiling the Impact of Local Homophily on GNN Fairness: In-Depth Analysis and New Benchmarks",
            "abstract": "Graph Neural Networks (GNNs) often struggle to generalize when graphs exhibit both homophily (same-class connections) and heterophily (different-class connections). Specifically, GNNs tend to underperform for nodes with local homophily levels that differ significantly from the global homophily level. This issue poses a risk in user-centric applications where underrepresented homophily levels are present. Concurrently, fairness within GNNs has received substantial attention due to the potential amplification of biases via message passing. However, the connection between local homophily and fairness in GNNs remains underexplored. In this work, we move beyond global homophily and explore how local homophily levels can lead to unfair predictions. We begin by formalizing the challenge of fair predictions for underrepresented homophily levels as an out-of-distribution (OOD) problem. We then conduct a theoretical analysis that demonstrates how local homophily levels can alter predictions for differing sensitive attributes. We additionally introduce three new GNN fairness benchmarks, as well as a novel semi-synthetic graph generator, to empirically study the OOD problem. Across extensive analysis we find that two factors can promote unfairness: (a) OOD distance, and (b) heterophilous nodes situated in homophilous graphs. In cases where these two conditions are met, fairness drops by up to 24% on real world datasets, and 30% in semi-synthetic datasets. Together, our theoretical insights, empirical analysis, and algorithmic contributions unveil a previously overlooked source of unfairness rooted in the graph's homophily information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "610f0a91b476e3edfcf49523b6789633022ac5a5",
            "title": "On Performance Discrepancies Across Local Homophily Levels in Graph Neural Networks",
            "abstract": "Graph Neural Network (GNN) research has highlighted a relationship between high homophily (i.e., the tendency of nodes of the same class to connect) and strong predictive performance in node classification. However, recent work has found the relationship to be more nuanced, demonstrating that simple GNNs can learn in certain heterophilous settings. To resolve these conflicting findings and align closer to real-world datasets, we go beyond the assumption of a global graph homophily level and study the performance of GNNs when the local homophily level of a node deviates from the global homophily level. Through theoretical and empirical analysis, we systematically demonstrate how shifts in local homophily can introduce performance degradation, leading to performance discrepancies across local homophily levels. We ground the practical implications of this work through granular analysis on five real-world datasets with varying global homophily levels, demonstrating that (a) GNNs can fail to generalize to test nodes that deviate from the global homophily of a graph, and (b) high local homophily does not necessarily confer high performance for a node. We further show that GNNs designed for globally heterophilous graphs can alleviate performance discrepancy by improving performance across local homophily levels, offering a new perspective on how these GNNs achieve stronger global performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "145476099",
                    "name": "Benjamin Fish"
                },
                {
                    "authorId": "2219860006",
                    "name": "Michael T. Shaub"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "2ca382af4352b28ad13c54502fb635f94c64a62a",
            "title": "FairEdit: Preserving Fairness in Graph Neural Networks through Greedy Graph Editing",
            "abstract": "Graph Neural Networks (GNNs) have proven to excel in predictive modeling tasks where the underlying data is a graph. However, as GNNs are extensively used in human-centered applications, the issue of fairness has arisen. While edge deletion is a common method used to promote fairness in GNNs, it fails to consider when data is inherently missing fair connections. In this work we consider the unexplored method of edge addition, accompanied by deletion, to promote fairness. We propose two model-agnostic algorithms to perform edge editing: a brute force approach and a continuous approximation approach, FairEdit. FairEdit performs efficient edge editing by leveraging gradient information of a fairness loss to find edges that improve fairness. We find that FairEdit outperforms standard training for many data sets and GNN methods, while performing comparably to many state-of-the-art methods, demonstrating FairEdit's ability to improve fairness across many domains and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "2152946868",
                    "name": "Jiayi Pan"
                },
                {
                    "authorId": "2149498583",
                    "name": "A. Bhathena"
                },
                {
                    "authorId": "1390856741",
                    "name": "Yiyang Lu"
                }
            ]
        },
        {
            "paperId": "425467ade82a5333c1cb1f2d1cf05e50dc4375c5",
            "title": "Zeroth-Order SciML: Non-intrusive Integration of Scientific Software with Deep Learning",
            "abstract": "Using deep learning (DL) to accelerate and/or improve scientific workflows can yield discoveries that are otherwise impossible. Unfortunately, DL models have yielded limited success in complex scientific domains due to large data requirements. In this work, we propose to overcome this issue by integrating the abundance of scientific knowledge sources (SKS) with the DL training process. Existing knowledge integration approaches are limited to using differentiable knowledge source to be compatible with first-order DL training paradigm. In contrast, our proposed approach treats knowledge source as a black-box in turn allowing to integrate virtually any knowledge source. To enable an end-to-end training of SKS-coupled-DL, we propose to use zeroth-order optimization (ZOO) based gradient-free training schemes, which is non-intrusive, i.e., does not require making any changes to the SKS. We evaluate the performance of our ZOO training scheme on two real-world material science applications. We show that proposed scheme is able to effectively integrate scientific knowledge with DL training and is able to outperform purely data-driven model for data-limited scientific applications. We also discuss some limitations of the proposed method and mention potentially worthwhile future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51074839",
                    "name": "Ioannis C. Tsaknakis"
                },
                {
                    "authorId": "1749353",
                    "name": "B. Kailkhura"
                },
                {
                    "authorId": "2118464654",
                    "name": "Sijia Liu"
                },
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "7753616",
                    "name": "James Diffenderfer"
                },
                {
                    "authorId": "4894686",
                    "name": "A. Hiszpanski"
                },
                {
                    "authorId": "66603575",
                    "name": "Min-Fong Hong"
                }
            ]
        },
        {
            "paperId": "d450acc48bd7a1e0702bdb72d60df2235854a04b",
            "title": "On Graph Neural Network Fairness in the Presence of Heterophilous Neighborhoods",
            "abstract": "We study the task of node classification for graph neural networks (GNNs) and establish a connection between group fairness, as measured by statistical parity and equal opportunity, and local assortativity, i.e., the tendency of linked nodes to have similar attributes. Such assortativity is often induced by homophily, the tendency for nodes of similar properties to connect. Homophily can be common in social networks where systemic factors have forced individuals into communities which share a sensitive attribute. Through synthetic graphs, we study the interplay between locally occurring homophily and fair predictions, finding that not all node neighborhoods are equal in this respect -- neighborhoods dominated by one category of a sensitive attribute often struggle to obtain fair treatment, especially in the case of diverging local class and sensitive attribute homophily. After determining that a relationship between local homophily and fairness exists, we investigate if the issue of unfairness can be associated to the design of the applied GNN model. We show that by adopting heterophilous GNN designs capable of handling disassortative group labels, group fairness in locally heterophilous neighborhoods can be improved by up to 25% over homophilous designs in real and synthetic datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "145476099",
                    "name": "Benjamin Fish"
                },
                {
                    "authorId": "8036637",
                    "name": "Michael T. Schaub"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "4878686f9b126a1fdcbdb374a4c98855a4961ca8",
            "title": "How does Heterophily Impact the Robustness of Graph Neural Networks?: Theoretical Connections and Practical Implications",
            "abstract": "We bridge two research directions on graph neural networks (GNNs), by formalizing the relation between heterophily of node labels (i.e., connected nodes tend to have dissimilar labels) and the robustness of GNNs to adversarial attacks. Our theoretical and empirical analyses show that for homophilous graph data, impactful structural attacks always lead to reduced homophily, while for heterophilous graph data the change in the homophily level depends on the node degrees. These insights have practical implications for defending against attacks on real-world graphs: we deduce that separate aggregators for ego- and neighbor-embeddings, a design principle which has been identified to significantly improve prediction for heterophilous graph data, can also offer increased robustness to GNNs. Our comprehensive experiments show that GNNs merely adopting this design achieve improved empirical and certifiable robustness compared to the best-performing unvaccinated model. Additionally, combining this design with explicit defense mechanisms against adversarial attacks leads to an improved robustness with up to 18.33% performance increase under attacks compared to the best-performing vaccinated model.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "3441160",
                    "name": "Junchen Jin"
                },
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "8036637",
                    "name": "Michael T. Schaub"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "8f1bc3ad0e6355f6c38d3af43f2cf9483ac06f18",
            "title": "Predicting Energetics Materials' Crystalline Density from Chemical Structure by Machine Learning",
            "abstract": "To expedite new molecular compound development, a long-sought goal within the chemistry community has been to predict molecules' bulk properties of interest a priori to synthesis from a chemical structure alone. In this work, we demonstrate that machine learning methods can indeed be used to directly learn the relationship between chemical structures and bulk crystalline properties of molecules, even in the absence of any crystal structure information or quantum mechanical calculations. We focus specifically on a class of organic compounds categorized as energetic materials called high explosives (HE) and predicting their crystalline density. An ongoing challenge within the chemistry machine learning community is deciding how best to featurize molecules as inputs into machine learning models-whether expert handcrafted features or learned molecular representations via graph-based neural network models-yield better results and why. We evaluate both types of representations in combination with a number of machine learning models to predict the crystalline densities of HE-like molecules curated from the Cambridge Structural Database, and we report the performance and pros and cons of our methods. Our message passing neural network (MPNN) based models with learned molecular representations generally perform best, outperforming current state-of-the-art methods at predicting crystalline density and performing well even when testing on a data set not representative of the training data. However, these models are traditionally considered black boxes and less easily interpretable. To address this common challenge, we also provide a comparison analysis between our MPNN-based model and models with fixed feature representations that provides insights as to what features are learned by the MPNN to accurately predict density.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "3128582",
                    "name": "Phan-Minh Nguyen"
                },
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "1810714984",
                    "name": "J. Kim"
                },
                {
                    "authorId": "2162054",
                    "name": "P. Karande"
                },
                {
                    "authorId": "4894686",
                    "name": "A. Hiszpanski"
                },
                {
                    "authorId": "50495911",
                    "name": "T. Y. Han"
                }
            ]
        },
        {
            "paperId": "bdc31a650c2a2696d2385469c6344e014d26c9e8",
            "title": "Reliable Graph Neural Network Explanations Through Adversarial Training",
            "abstract": "Graph neural network (GNN) explanations have largely been facilitated through post-hoc introspection. While this has been deemed successful, many post-hoc explanation methods have been shown to fail in capturing a model's learned representation. Due to this problem, it is worthwhile to consider how one might train a model so that it is more amenable to post-hoc analysis. Given the success of adversarial training in the computer vision domain to train models with more reliable representations, we propose a similar training paradigm for GNNs and analyze the respective impact on a model's explanations. In instances without ground truth labels, we also determine how well an explanation method is utilizing a model's learned representation through a new metric and demonstrate adversarial training can help better extract domain-relevant insights in chemistry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "47130096",
                    "name": "Shusen Liu"
                },
                {
                    "authorId": "1749353",
                    "name": "B. Kailkhura"
                },
                {
                    "authorId": "4894686",
                    "name": "A. Hiszpanski"
                },
                {
                    "authorId": "2108889377",
                    "name": "Yong Han"
                }
            ]
        },
        {
            "paperId": "19f0a0a464fdb540b478cad68e4ff80a83ceb540",
            "title": "Automated Identification of Molecular Crystals' Packing Motifs",
            "abstract": "Packing motifs-patterns in how molecules orient relative to one another in a crystal structure-are an important concept in many subdisciplines of materials science because of correlations observed between specific packing motifs and properties of interest. That said, packing motif data sets have remained small and noisy due to intensive manual labeling processes and insufficient labeling schemes. The most prominent labeling algorithms calculate relative interplanar angles of nearest neighbor molecules to determine the packing motif of a molecular crystal, but this simple approach can fail when neighbors are naively sampled isotropically around the crystal structure. To remedy this issue, we propose an optimization algorithm, which rotates the molecular crystal structure to find representative molecules that inform the packing motif. We package this algorithm into an automated framework-Autopack-which both optimally rotates the crystal structure and labels the packing motif based on the appropriate neighboring molecules. In this work, we detail the Autopack framework and its performance, which shows improvements compared to previous state-of-the-art labeling methods, providing the first quantitative point of comparison for packing motif labeling algorithms. Furthermore, using Autopack (available at https://ipo.llnl.gov/technologies/software/autopack), we perform the first large-scale study of potential relationships between chemicals' compositions and packing motifs, which shows that these relationships are more complex than previously hypothesized from studies that used only tens of polycyclic aromatic hydrocarbon molecules. Autopack's capabilities help pose next steps for crystal engineering research focusing not only on a molecule's adoption of a specific packing motif but also on new structure-property relationships.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "1749353",
                    "name": "B. Kailkhura"
                },
                {
                    "authorId": "2162054",
                    "name": "P. Karande"
                },
                {
                    "authorId": "4894686",
                    "name": "A. Hiszpanski"
                },
                {
                    "authorId": "50495911",
                    "name": "T. Y. Han"
                }
            ]
        },
        {
            "paperId": "63b217a427aee51283aa52abe4548acc2782c807",
            "title": "Explainable Deep Learning for Uncovering Actionable Scientific Insights for Materials Discovery and Design",
            "abstract": "The scientific community has been increasingly interested in harnessing the power of deep learning to solve various domain challenges. However, despite the effectiveness in building predictive models, fundamental challenges exist in extracting actionable knowledge from deep neural networks due to their opaque nature. In this work, we propose techniques for exploring the behavior of deep learning models by injecting domain-specific actionable attributes as tunable \"knobs\" in the analysis pipeline. By incorporating the domain knowledge in a generative modeling framework, we are not only able to better understand the behavior of these black-box models, but also provide scientists with actionable insights that can potentially lead to fundamental discoveries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47130096",
                    "name": "Shusen Liu"
                },
                {
                    "authorId": "1749353",
                    "name": "B. Kailkhura"
                },
                {
                    "authorId": "2107967251",
                    "name": "Jize Zhang"
                },
                {
                    "authorId": "4894686",
                    "name": "A. Hiszpanski"
                },
                {
                    "authorId": "2064393144",
                    "name": "Emily Robertson"
                },
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "50495911",
                    "name": "T. Y. Han"
                }
            ]
        }
    ]
}