{
    "authorId": "40693214",
    "papers": [
        {
            "paperId": "84e186cee4290de82376f74e10e06547be9d37c6",
            "title": "Computer Vision Target Detection-Aided High-Frequency Satellite\u2013Ground Communications",
            "abstract": "Satellite-to-ground communication systems typically operate in environments with high-interference levels, complex topologies, and stringent platform constraints. Therefore, intelligent, anti-interference, and low-power systems are required to achieve the desired transmission performance. This article proposes a system for optimizing high-frequency satellite-to-ground communications using computer vision (CV) technology, like millimeter-wave (mmWave) satellite communication systems. The system uniquely combines CV-based target localization with adaptive beamforming and power control to optimize communication links with ground targets, such as base stations, ships, and aircraft. This approach significantly outperforms traditional radio frequency-based methods in accuracy and efficiency, particularly in dynamic mmWave scenarios. Simulation results confirm the superiority of our system in terms of sum rate and energy efficiency, demonstrating its potential to revolutionize high-frequency satellite communications by providing reliable, high-quality service to terrestrial targets. Finally, simulation results are presented to demonstrate the efficiency of the proposed schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2283995079",
                    "name": "Ying Ke"
                },
                {
                    "authorId": "2144320648",
                    "name": "Su Chen"
                },
                {
                    "authorId": "2242199626",
                    "name": "Shuai Wang"
                },
                {
                    "authorId": "2143803197",
                    "name": "Gaofeng Pan"
                },
                {
                    "authorId": "2294078837",
                    "name": "Kun Gao"
                }
            ]
        },
        {
            "paperId": "08c6dcdacb43e2f2448d6159f1d843f634bb0c5c",
            "title": "Computer Vision-Based Joint Space Sensing and Communication Systems: Non-Source, Autonomy, and Low Latency",
            "abstract": "The new space race is intensifying as thousands of satellites are poised for deployment into outer space each year. Companies are deploying low-earth orbit satellites at an unprecedented rate to create mega-constellations. Because outer space is becoming increasingly crowded and hazardous, establishing safe, efficient, and rapid inter-satellite communications is now a major challenge, essential for managing, maintaining, and inspecting vast space communication networks. Joint sensing and communication (JSC) presents a remarkable opportunity to enhance communication performance metrics by leveraging sensed surrounding information, including spectrum efficiency, beam training, and more. As such, applying JSC for space environmental sensing could significantly enhance the performance of inter-satellite communications in ever-crowded outer space. However, traditional radio frequency-based JSC faces significant challenges - such as latency and security concerns - when applied to outer-space satellite communications. This work proposes a novel approach to joint space sensing and communication-based on computer vision (CV) for target detection, tracking, and prediction to ensure effective satellite communications by integrating various communication and sensing techniques. We illustrate several network connection prototypes using appropriate computing management to enhance energy efficiency, latency, and covertness performance in various scenarios. Finally, we investigate and discuss the significant technological challenges and future research directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2224934679",
                    "name": "Han Yu"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2670776",
                    "name": "Xiaqing Miao"
                },
                {
                    "authorId": "2242199626",
                    "name": "Shuai Wang"
                },
                {
                    "authorId": "2143803197",
                    "name": "Gaofeng Pan"
                },
                {
                    "authorId": "2151864031",
                    "name": "Jianping An"
                },
                {
                    "authorId": "2274012365",
                    "name": "Tommy Svensson"
                },
                {
                    "authorId": "2274725094",
                    "name": "John Thompson"
                },
                {
                    "authorId": "1745843",
                    "name": "H. Yanikomeroglu"
                }
            ]
        },
        {
            "paperId": "71a5d0af83695d4623286460910af63da2ce940a",
            "title": "AF-OSD: An Anchor-Free Oriented Ship Detector Based on Multi-Scale Dense-Point Rotation Gaussian Heatmap",
            "abstract": "Due to the complexity of airborne remote sensing scenes, strong background and noise interference, positive and negative sample imbalance, and multiple ship scales, ship detection is a critical and challenging task in remote sensing. This work proposes an end-to-end anchor-free oriented ship detector (AF-OSD) framework based on a multi-scale dense-point rotation Gaussian heatmap (MDP-RGH) to tackle these aforementioned challenges. First, to solve the sample imbalance problem and suppress the interference of negative samples such as background and noise, the oriented ship is modeled via the proposed MDP-RGH according to its shape and direction to generate ship labels with more accurate information, while the imbalance between positive and negative samples is adaptively learned for the ships with different scales. Then, the AF-OSD based on MDP-RGH is further devised to detect the multi-scale oriented ship, which is the accurate identification and information extraction for multi-scale vessels. Finally, a multi-task object size adaptive loss function is designed to guide the training process, improving its detection quality and performance for multi-scale oriented ships. Simulation results show that extensive experiments on HRSC2016 and DOTA ship datasets reveal that the proposed method achieves significantly outperforms the compared state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2143803197",
                    "name": "Gaofeng Pan"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2592481",
                    "name": "Hengchao Li"
                },
                {
                    "authorId": "2144320648",
                    "name": "Su Chen"
                }
            ]
        },
        {
            "paperId": "e6b8b8cee6fe4f570dc32f6da56fb833f4c6461f",
            "title": "Computer Vision-Aided mmWave UAV Communication Systems",
            "abstract": "Unmanned aerial vehicle (UAV) communication systems usually operate in harsh scenarios, which require accurate information about the topology and wireless channel to achieve the desired transmission performance. Therefore, when millimeter-wave (mmWave) communication with its intrinsic Line-of-Sight (LoS) condition is adopted, accurate target localization is essential to determine the spatial relationship between the UAV and the grounded receivers (Rxs). In this article, a computer-vision (CV)-aided jointly optimization scheme of flight trajectory and power allocation is designed for mmWave UAV communication systems by utilizing the visual information captured via cameras equipped at the UAV. Compared with traditional schemes, the implementation cost and overhead can be greatly saved as no radio frequency transmissions are required in the proposed localization scheme. In addition, the transmit power at the UAV is jointly optimized with its flight trajectory in two different cases. Finally, simulation results are presented to demonstrate the efficiency of the proposed schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "1471101683",
                    "name": "Yang Lu"
                },
                {
                    "authorId": "2143803197",
                    "name": "Gaofeng Pan"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "34825558",
                    "name": "D. B. D. Costa"
                },
                {
                    "authorId": "2144320648",
                    "name": "Su Chen"
                }
            ]
        },
        {
            "paperId": "1d493b2d2407222ab20742889b4a0a79ba958a1d",
            "title": "Image Reconstruction Using Variable Exponential Function Regularization for Wide-Field Polarization Modulation Imaging",
            "abstract": "Polarization modulation imaging technology plays an important role in microscopic super-resolution imaging. However, the specimen medium contains retardancy, while charge-coupled devices may provide discrete under-sampling, and the coupled wavefronts consisting of the polarization state of the light and the anisotropic distribution of the specimen can lead to vectorial phase fitting degradation. Considering that the point spread function (PSF) of the main degradation parts can be regarded as an asymmetric generalized Gaussian distribution with uncertain parameters, an adaptive image reconstruction method is proposed based on variable exponential function regularization. The proposed method concentrates on the diversity of the PSF and uses a variable exponent regularization to improve flexibility of the kernel. Moreover, it can balance image edge preservation and provide staircase artifact suppression, which reduces the over- and under-reconstruction of the microscopic images effectively. By optimizing the Split\u2013Bregman algorithm, we create an efficient method that minimizes the iterative loss function under the premise of achieving high estimation accuracy. Compared with other methods, the experimental results reveal better effectiveness and robustness of the proposed method, with improvements of 18% in the peak signal-to-noise ratio, 21% in the structural similarity index measurement, and 337% in the mean structural similarity index measurement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112259345",
                    "name": "Qiong Wu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2112144548",
                    "name": "Mu Li"
                },
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "70159791",
                    "name": "Hanwen Zhao"
                },
                {
                    "authorId": "14988841",
                    "name": "Jichuan Xiong"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2027169833",
                    "name": "Peilin Yu"
                }
            ]
        },
        {
            "paperId": "9c3aff9e2faa7177875f13e73fa383a601653cac",
            "title": "Single-Image Dehazing Using Extreme Reflectance Channel Prior",
            "abstract": "Image dehazing algorithms based on dark channel prior principle have achieved good results for most scenes. However, the popular dark channel prior tends to underestimate transmissions of bright areas or objects, such as the skies, white areas and self-luminous bodies, which may cause color distortions during dehazing. A complementary prior called the extreme reflectance channel prior (ERC), which combines the dark channel prior with the bright channel prior, is proposed to estimate the transmission map. The extreme reflectance channel is the union of dark and bright channel\u2019s pixels which satisfy the corresponding channel. Based on the scattering analysis results that the intensities of pixels in ERC are often close to 0 or 1 for the natural haze-free images or close to global atmospheric light if hazes occur in the air, the pixels in a hazy image can be recovered according to ERC to calculate the transmission map and then solve the haze imaging mode. Experiments show that ERC method outperforms state-of-the-art methods in PSNR, SSIM and visual perception effects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116534877",
                    "name": "Yutong Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2112259345",
                    "name": "Qiong Wu"
                }
            ]
        },
        {
            "paperId": "9f033fcd5523ccbac58582772f162d4f555daad5",
            "title": "Nonuniform blind deblurring for single images based on adaptive edge-enhanced regularization",
            "abstract": "Abstract. Natural images inevitably suffer from spatially variant blur caused by the relative motion between a camera and objects. We present an effective and efficient patch-wise edge-enhanced image regularization and a robust kernel similarity constraint to perform an accurate kernel estimation from coarse-to-fine iterations. The proposed adaptive regularization introduces a gradient magnitude penalty function into total variation to preserve and enhance salient edges while smoothing out harmful subtle structures. In addition, the similarity constraint is engaged in each patch without camera rotation effects, ensuring that the erroneous kernels can be identified by measuring the similarity among the kernels of neighbor patches and be replaced with the well-estimated ones. After obtaining accurate kernels, numerous nonblind deblurring methods can be applied to restore an image. Numerical experiments demonstrate that the proposed algorithm performs favorably without ringing artifacts and possesses high processing efficiency for natural nonuniform blurred images.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "52185102",
                    "name": "Ruoxiang Li"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                }
            ]
        },
        {
            "paperId": "26f85dd6494eef0f58be3d93cc8db8da523705ea",
            "title": "Target-Aware Fusion of Infrared and Visible Images",
            "abstract": "Image fusion technology involves the use of complementary information from multiple sensors to generate a composite image that can highlight the details in the region of interest. Some recent methods have tackled the problem of characterization of different source image features that are lacking in conventional methods. However, during fusion processing, these methods may lose some information of interest such as smoke. This paper proposes a method called target-aware decomposition and parallel gradient fusion (TAD-PGF) that fuses infrared and visible images to maintain the high brightness characteristics of infrared targets while transferring the appearance of both source images to the fused image, where \u201cappearance\u201d means the details pertaining to the environment and \u201cinfrared target\u201d often means hot objects such as human body. The target layer is extracted from the infrared image and used as a guide to extract appearance-related information from the visible image. Given that the background of the infrared image contains useful background information, a parallel gradient fusion scheme is proposed to fuse the relevant features with appearance-related information in the visible image. The final blended image is obtained by adding a target layer and a fused appearance layer directly to the fused image. Numerous experiments using publicly available databases were conducted to provide qualitative and quantitative comparisons between the state-of-the-art methods and the proposed TAD-PGF. The results reveal that the TAD-PGF can attain good visual effect in various scenarios and maintain useful information from source images to enhance the details of interest.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118860967",
                    "name": "Yingjie Zhou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "49528487",
                    "name": "Hong Wang"
                }
            ]
        },
        {
            "paperId": "4f7c9a5e94549ff4dac4e146f256098768dad77e",
            "title": "Multiperspective Image Stitching and Regularization via Hybrid Structure Warping",
            "abstract": "Distortions such as shape changes, ghosting, seam lines, and missing edges often occur in multiperspective image stitching. The authors describe a content-preserving image stitching and completion method based on hybrid structure warping to restrain these distortions. Experiments showed that the proposed approach significantly reduced ghosting and distortion, and when compared to existing methods, displayed a superior visual effect.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146559362",
                    "name": "Yan Lu"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "39001620",
                    "name": "Tingfa Xu"
                }
            ]
        },
        {
            "paperId": "85887ac1eb6a063884662c474453ae5074171f69",
            "title": "An edge detection method with boundary reserved based on non-subsampled contourlet transform for remote sensing imagery",
            "abstract": "During space reconnaissance applications, edge detection from remote sensing imagery plays an important role in the target recognition processing. However, traditional edge detection methods usually only utilize the high-frequency information in one image. Since low-frequency elements may be aliasing with high-frequency parts, the edges extracted may be unconnected under complex topography, different objects and imaging conditions. This paper proposes a novel image edge detection method based on Non-Subsampled Contourlet Transform (NSCT) to keep the object boundary continuously. It transforms the image into Contourlet domain in both high-frequency and low-frequency sub-bands respectively. Depending on the feature of flexible directivity reservation of an image during NSCT, the further edge extraction consists of 3 steps: firstly, the elements of the high-frequency coefficient matrix in Contourlet domain are filtered with high values left using adaptive thresholds. Then the low-frequency edge information is extracted via Canny operator from the low-frequency sub-band information. Finally, to achieve a more consistent edge image, the low-frequency edge image is achieved according to the low-frequency matrix and adopted to compensate the high-frequency image with the isolated noise points eliminated as well. The numerical simulation and practical test results show the higher effectiveness and robustness of the proposed algorithm when comparing with the classical edge detectors, such as Sobel operator, Canny operator, Log operator and Prewitt operator, etc.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2057185157",
                    "name": "Chen Gong"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2144320648",
                    "name": "Su Chen"
                },
                {
                    "authorId": "2146559362",
                    "name": "Yan Lu"
                },
                {
                    "authorId": "134889016",
                    "name": "Yanqin Jia"
                }
            ]
        }
    ]
}