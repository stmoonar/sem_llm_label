{
    "authorId": "71208098",
    "papers": [
        {
            "paperId": "4759748046ef61fdecaf8b5e4070bb8601bece94",
            "title": "High-performance transmission mechanism design of multi-stream carrier aggregation for 5G non-standalone network",
            "abstract": "Multi-stream carrier aggregation is a key technology to expand bandwidth and improve the throughput of the fifth-generation wireless communication systems. However, due to the diversified propagation properties of different frequency bands, the traffic migration task is much more challenging, especially in hybrid sub-6 GHz and millimeter wave bands scenario. Existing schemes either neglected to consider the transmission rate difference between multi-stream carrier, or only consider simple low mobility scenario. In this paper, we propose a low-complexity traffic splitting algorithm based on fuzzy proportional integral derivative control mechanism. The proposed algorithm only relies on the local radio link control buffer information of sub-6 GHz and mmWave bands, while frequent feedback from user equipment (UE) side is minimized. As shown in the numerical examples, the proposed traffic splitting mechanism can achieve more than 90% link resource utilization ratio for different UE transmission requirements with different mobilities, which corresponds to 10% improvement if compared with conventional baselines.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "71199392",
                    "name": "Jun-xiang Yu"
                },
                {
                    "authorId": "1730880",
                    "name": "Shunqing Zhang"
                },
                {
                    "authorId": "98147068",
                    "name": "Jiayun Sun"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                }
            ]
        },
        {
            "paperId": "d65e6323a0a424c44ca8d1f2635d6c3517e4d266",
            "title": "A Computational-Efficient Deformable Convolution Network Accelerator via Hardware and Algorithm Co-Optimization",
            "abstract": "Deformable convolution networks (DCNs) shows performance boosts on object recognition tasks by enabling variable geometric modeling. However, the irregular addressing of memory accesses makes it inefficient for hardware acceleration. In this paper, we propose a computational-efficient hardware accelerator for DCNs. First, a hardware-friendly DCNs inference scheme is introduced based on the original DCNs algorithm with little accuracy loss. Secondly, a hardware accelerator architecture is presented correspondingly, and an speed matching method is introduced to maximizing the number of deformable layers without latency increase. The proposed accelerator is implemented on the Arria 10 FPGA, results of which show that the proposed design achieves the highest throughput and DSP efficiency compared with state-of-the-art DCNs accelerators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31317708",
                    "name": "Shane Li"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2184190062",
                    "name": "Lanqing Hui"
                },
                {
                    "authorId": "4302623",
                    "name": "Zhiyuan Jiang"
                },
                {
                    "authorId": "3260535",
                    "name": "Yanzan Sun"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                }
            ]
        },
        {
            "paperId": "e87480252e42e5c8bf308558deb1e57bc4a77be6",
            "title": "Configurable CNN Accelerator in Speech Processing based on Vector Convolution",
            "abstract": "In speech applications, both input feature maps (IFMs) and kernels of neural networks are greatly diverse in shapes and sizes, which poses significant challenges to hardware acceleration. In this paper, a configurable CNN accelerator is introduced to make a good balance between the flexibility and efficiency for various neural network models in speech processing. The vector convolution scheme is first proposed by re-arrangement of IFM rows and weight values in vectors, by which the element convolution is converted into vector operations to break the limit of kernel-centric processing. The structure of vector processing element (VPE) is introduced to fit the continuous scaling down of IFMs with little control overheads, and the architecture of the CNN accelerator is proposed accordingly. FPGA implementation results demonstrate that the throughput is increased by 86% by the proposed architecture compared to state-of-the-art FPGA accelerators for the VGG16 network, while high DSP utilization is guaranteed for both 1D and 2D CNNs with various input sizes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184190062",
                    "name": "Lanqing Hui"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2142370382",
                    "name": "Zhiyong Chen"
                },
                {
                    "authorId": "31317708",
                    "name": "Shane Li"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                }
            ]
        },
        {
            "paperId": "1a8ef5439c723255b3c8165737ca1b6ae14edf6a",
            "title": "Dataset and Network Structure: Towards Frames Selection for Fast Video Deblurring",
            "abstract": "Beyond the underlaying unrealistic presumptions in the existing video deblurring datasets and algorithms which presume that a naturally blurred video is fully blurred. In this work, we define a more realistic video frames averaging-based data degradation model by referring to a naturally blurred video as a partially blurred frames sequence, and use it to build REBVIDS, as a novel video deblurring dataset to close the gap between naturally blurred and synthetically blurred video training data, and to address most shortcomings of the existing datasets. We also present DeblurNet, a two phases training-based deep learning model for video deblurring, it consists of two main sub-modules; a Frame Selection Module and a Frame Deblurring Module. Compared to the recent learning-based approaches, its sub-modules have simpler network structures, with smaller number of training parameters, are easier to train and with faster inference. As naturally blurred videos are only partially blurred, the Frame Selection Module is in charge of selecting the blurred frames in a video sequence and forwarding them to the Frame Deblurring Module input, the Frame Deblurring Module in its turn will get them restored and recombine them according to the original order in a newly restored sequence beside their initially sharp neighbor frames. Extensive experimental results on several benchmarks demonstrate that DeblurNet performs favorably against the state-of-the-art, both quantitatively and qualitatively. DeblurNet proves its ability to trade between speed, computational cost and restoration quality. Besides its ability to restore video blurred frames with necessary edges and details, benefiting from its small size and its video frames selection integrated mechanism, it can speed up the inference phase by over ten times compared to existing approaches. This project dataset and code will be released soon and will be accessible through: https://github.com/nahliabdelwahed/Speed-up-video-deblurring-",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1680530151",
                    "name": "Abdelwahed Nahli"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": null,
                    "name": "Zhiwei Jia"
                },
                {
                    "authorId": "15888214",
                    "name": "Runze Ma"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                }
            ]
        },
        {
            "paperId": "35d4dad99a998ac1db8387e2d0529eece6958eca",
            "title": "A Dataset and Benchmark Towards Multi-Modal Face Anti-Spoofing Under Surveillance Scenarios",
            "abstract": "Face Anti-spoofing (FAS) is a challenging problem due to complex serving scenarios and diverse face presentation attack patterns. Especially when captured images are low-resolution, blurry, and coming from different domains, the performance of FAS will degrade significantly. The existing multi-modal FAS datasets rarely pay attention to the cross-domain problems under deployment scenarios, which is not conducive to the study of model performance. To solve these problems, we explore the fine-grained differences between multi-modal cameras and construct a cross-domain multi-modal FAS dataset under surveillance scenarios called GREAT-FASD-S. Besides, we propose an Attention based Face Anti-spoofing network with Feature Augment (AFA) to solve the FAS towards low-quality face images. It consists of the depthwise separable attention module (DAM) and the multi-modal based feature augment module (MFAM). Our model can achieve state-of-the-art performance on the CASIA-SURF dataset and our proposed GREAT-FASD-S dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109449150",
                    "name": "Xudong Chen"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                },
                {
                    "authorId": "2051540132",
                    "name": "Qiaobin Ji"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                }
            ]
        },
        {
            "paperId": "4cca2f8cae14a09be203b3e4840e41b45390ccf2",
            "title": "High Accurate Environmental Sound Classification: Sub-Spectrogram Segmentation versus Temporal-Frequency Attention Mechanism",
            "abstract": "In the important and challenging field of environmental sound classification (ESC), a crucial and even decisive factor is the feature representation ability, which can directly affect the accuracy of classification. Therefore, the classification performance often depends to a large extent on whether the effective representative features can be extracted from the environmental sound. In this paper, we firstly propose a sub-spectrogram segmentation with score level fusion based ESC classification framework, and we adopt the proposed convolutional recurrent neural network (CRNN) for improving the classification accuracy. By evaluating numerous truncation schemes, we numerically figure out the optimal number of sub-spectrograms and the corresponding band ranges, and, on this basis, we propose a joint attention mechanism with temporal and frequency attention mechanisms and use the global attention mechanism when generating the attention map. Finally, the numerical results show that the two frameworks we proposed can achieve 82.1% and 86.4% classification accuracy on the public environmental sound dataset ESC-50, respectively, which is equivalent to more than 13.5% improvement over the traditional baseline scheme.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "150323459",
                    "name": "Tianhao Qiao"
                },
                {
                    "authorId": "1730880",
                    "name": "Shunqing Zhang"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                }
            ]
        },
        {
            "paperId": "570ec68f8790f1dd65d23fdff4b678e34c5b96e2",
            "title": "Predictive Wireless Based Status Update for Communication-Agnostic Sampling",
            "abstract": "In a wireless network that conveys status updates from sources (i.e., sensors) to destinations, one of the key issues studied by existing literature is how to design an optimal source sampling strategy on account of the communication constraints which are often modeled as queues. In this paper, an alternative perspective is presented\u2014a novel status-aware communication scheme, namely parallel communications, is proposed which allows sensors to be communication-agnostic. Specifically, the proposed scheme can determine, based on an online prediction functionality, whether a status packet is worth transmitting considering both the network condition and status prediction, such that sensors can generate status packets without communication constraints. We evaluate the proposed scheme on a Software-Defined-Radio (SDR) test platform, which is integrated with a collaborative autonomous driving simulator, i.e., Simulation-of-Urban-Mobility (SUMO), to produce realistic vehicle control models and road conditions. The results show that with online status predictions, the channel occupancy is significantly reduced, while guaranteeing low status recovery error. Then the framework is applied to two scenarios: a multi-density platooning scenario, and a flight formation control scenario. Simulation results show that the scheme achieves better performance on the network level, in terms of keeping the minimum safe distance in both vehicle platooning and flight control.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "4302623",
                    "name": "Zhiyuan Jiang"
                },
                {
                    "authorId": "2155469922",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "1491380112",
                    "name": "Zixu Cao"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "1730880",
                    "name": "Shunqing Zhang"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                }
            ]
        },
        {
            "paperId": "5821ac7cbb7d86f866e3e23c2881080f9e9eb076",
            "title": "A Reconfigurable and Pipelined Architecture for Standard-Compatible LDPC and Polar Decoding",
            "abstract": "With low-density parity-check (LDPC) codes and polar codes selected as the standard codes for the fifth generation (5\u00a0G) enhanced Mobile Broad Band scenario (eMBB), a decoding architecture that can simultaneously support the decoding of control and data plane becomes necessary at the terminal side to meet the raising requirement for 5\u00a0G network deployment. Due to the special structure of LDPC codes according to the Release 15 (R15) 5\u00a0G standard, a straight-forward extension of the existing reconfigurable scheme is in general difficult. Therefore in this paper, a unified decoding architecture is proposed that can be reconfigured to either LDPC codes or polar codes. Due to various differences between the two codes such as parity-check matrices, codeword lengths and iterative methods, a joint decoding algorithm is introduced by reordering basic decoding operations to the unified add-comparison-add pattern for both codes. Then, a pipelined structure of reconfigurable decoding unit (RDU) is presented correspondingly which is fully compatible with all decoding patterns of the R15 standard. And finally, a reconfigurable decoder is proposed with multiple levels of parallelism, and the reconfiguration scheme is introduced to improve the hardware utilization and decoding efficiency. The proposed decoder is implemented in FPGA and ASIC, respectively, and has achieved state-of-the-art performance in throughput and area efficiency compared to LDPC-only and polar-only decoders.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2115348352",
                    "name": "Ting Lin"
                },
                {
                    "authorId": "1730880",
                    "name": "Shunqing Zhang"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                },
                {
                    "authorId": "50445673",
                    "name": "Chuan Zhang"
                }
            ]
        },
        {
            "paperId": "913c87467d4750c3ff26c4ba3872aac0d19a2d97",
            "title": "A Semi-Folded Decoding Architecture for Flexible Codeword Length Configuration of Polar Codes",
            "abstract": "Diverse application scenarios in 5G and beyond wireless communication systems have introduced various requirements in code lengths and rates of channel codes. For the decoding of polar codes, especially the belief-propagation (BP) decoding, flexible configuration of codeword length is still not involved in current decoders. In this paper, a semi-folded decoding structure is proposed which can be reconfigured to support multiple codeword lengths. Up to 16 codes can be decoded in parallel and the utilization of processing units is no less than 87.5% for various codeword lengths. The peak throughput of 19.29 Gbps can be achieved by the proposed decoder in SMIC 55 nm CMOS technology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2115196093",
                    "name": "Limin Jiang"
                },
                {
                    "authorId": "2115348352",
                    "name": "Ting Lin"
                },
                {
                    "authorId": "1730880",
                    "name": "Shunqing Zhang"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                }
            ]
        },
        {
            "paperId": "9284b90b5ac494024cf93d88df81f5535b660b5e",
            "title": "Arbitrary-Shaped Text Detection With Adaptive Text Region Representation",
            "abstract": "Text detection/localization, as an important task in computer vision, has witnessed substantial advancements in methodology and performance with convolutional neural networks. However, the vast majority of popular methods use rectangles or quadrangles to describe text regions. These representations have inherent drawbacks, especially relating to dense adjacent text and loose regional text boundaries, which usually cause difficulty detecting arbitrarily shaped text. In this paper, we propose a novel text region representation method, with a robust pipeline, which can precisely detect dense adjacent text instances with arbitrary shapes. We consider a text instance to be composed of an adaptive central text region mask and a corresponding expanding ratio between the central text region and the full text region. More specifically, our pipeline generates adaptive central text regions and corresponding expanding ratios with a proposed training strategy, followed by a new proposed post-processing algorithm which expands central text regions to the complete text instance with the corresponding expanding ratios. We demonstrated that our new text region representation is effective, and that the pipeline can precisely detect closely adjacent text instances of arbitrary shapes. Experimental results on common datasets demonstrate superior performance of our work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46813493",
                    "name": "Xiufeng Jiang"
                },
                {
                    "authorId": "1802931",
                    "name": "Shugong Xu"
                },
                {
                    "authorId": "1730880",
                    "name": "Shunqing Zhang"
                },
                {
                    "authorId": "71208098",
                    "name": "Shan Cao"
                }
            ]
        }
    ]
}