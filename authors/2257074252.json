{
    "authorId": "2257074252",
    "papers": [
        {
            "paperId": "1c3b47117fb0877ecd9e7fc9e8db7b7948432d8f",
            "title": "ForeSeer: Product Aspect Forecasting Using Temporal Graph Embedding",
            "abstract": "Developing text mining approaches to mine aspects from customer reviews has been well-studied due to its importance in understanding customer needs and product attributes. In contrast, it remains unclear how to predict the future emerging aspects of a new product that currently has little review information. This task, which we named product aspect forecasting, is critical for recommending new products, but also challenging because of the missing reviews. Here, we propose ForeSeer, a novel textual mining and product embedding approach progressively trained on temporal product graphs for this novel product aspect forecasting task. ForeSeer transfers reviews from similar products on a large product graph and exploits these reviews to predict aspects that might emerge in future reviews. A key novelty of our method is to jointly provide review, product, and aspect embeddings that are both time-sensitive and less affected by extremely imbalanced aspect frequencies. We evaluated ForeSeer on a real-world product review system containing 11,536,382 reviews and 11,000 products over 3 years. We observe that ForeSeer substantially outperformed existing approaches with at least 49.1% AUPRC improvement under the real setting where aspect associations are not given. ForeSeer further improves future link prediction on the product graph and the review aspect association prediction. Collectively, Foreseer offers a novel framework for review forecasting by effectively integrating review text, product network, and temporal information, opening up new avenues for online shopping recommendation and e-commerce applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265222599",
                    "name": "Zixuan Liu"
                },
                {
                    "authorId": "46566733",
                    "name": "G. Hiranandani"
                },
                {
                    "authorId": "2257003517",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2057479333",
                    "name": "E-Wen Huang"
                },
                {
                    "authorId": "2257074252",
                    "name": "Yi Xu"
                },
                {
                    "authorId": "2007227598",
                    "name": "Belinda Zeng"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2280550850",
                    "name": "Sheng Wang"
                }
            ]
        },
        {
            "paperId": "c748bddd1547cd4765c5b7957180ac67487ae278",
            "title": "Unsupervised Multi-Modal Representation Learning for High Quality Retrieval of Similar Products at E-commerce Scale",
            "abstract": "Identifying similar products in e-commerce is useful in discovering relationships between products, making recommendations, and increasing diversity in search results. Product representation learning is the first step to define a generalized product similarity metric for search. The second step is to extend similarity search to a large scale (e.g., e-commerce catalog scale) without sacrificing quality. In this work, we present a solution that interweaves both steps, i.e., learn representations suited to high quality retrieval using contrastive learning (CL) and retrieve similar items from a large search space using approximate nearest neighbor search (ANNS) to trade-off quality for speed. We propose a CL training strategy for learning uni-modal encoders suited to multi-modal similarity search for e-commerce. We study ANNS retrieval by generating Pareto Frontiers (PFs) without requiring labels. Our CL training strategy doubles retrieval@1 metric across categories (e.g., from 36% to 88% in category C). We also demonstrate that ANNS engine optimization using PFs help select configurations appropriately (e.g., we achieve 6.8\u00d7 search speed with just 2% drop from the maximum retrieval accuracy in medium size datasets).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237898982",
                    "name": "Kushal Kumar"
                },
                {
                    "authorId": "1739391",
                    "name": "Tarik Arici"
                },
                {
                    "authorId": "2945103",
                    "name": "T. Neiman"
                },
                {
                    "authorId": "2237592750",
                    "name": "Jinyu Yang"
                },
                {
                    "authorId": "2188188306",
                    "name": "Shioulin Sam"
                },
                {
                    "authorId": "2257074252",
                    "name": "Yi Xu"
                },
                {
                    "authorId": "2260655051",
                    "name": "Hakan Ferhatosmanoglu"
                },
                {
                    "authorId": "2260653585",
                    "name": "Ismail Tutar"
                }
            ]
        }
    ]
}