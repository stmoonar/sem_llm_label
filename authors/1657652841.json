{
    "authorId": "1657652841",
    "papers": [
        {
            "paperId": "5468a398cbb91b0f126e10e6a827a46ee1eefc9b",
            "title": "Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot",
            "abstract": "Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals\u2019 practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2279801138",
                    "name": "Lin Tian"
                },
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2279785688",
                    "name": "Halil Ali"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "8a195e1b38241934a9b445c77494fb11a9eacd6f",
            "title": "Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages",
            "abstract": "This paper describes our participation in the shared task of hate speech detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our experiments evaluate the performance of six transformer models and their combination using 2 ensemble approaches. The best results on the training set, in a five-fold cross validation scenario, were obtained by using the ensemble approach based on the majority vote. The evaluation of this approach on the test set resulted in an F1-score of 0.60 and an Accuracy of 0.86.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "3118956",
                    "name": "Imene Bensalem"
                },
                {
                    "authorId": "143752702",
                    "name": "Paolo Rosso"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        },
        {
            "paperId": "bdf791fc30b007c54bec24835379cd25bb6bf88c",
            "title": "AI-UPV at EXIST 2023 - Sexism Characterization Using Large Language Models Under The Learning with Disagreement Regime",
            "abstract": "With the increasing influence of social media platforms, it has become crucial to develop automated systems capable of detecting instances of sexism and other disrespectful and hateful behaviors to promote a more inclusive and respectful online environment. Nevertheless, these tasks are considerably challenging considering different hate categories and the author's intentions, especially under the learning with disagreements regime. This paper describes AI-UPV team's participation in the EXIST (sEXism Identification in Social neTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task of sexism identification and characterization under the learning with disagreements paradigm by training directly from the data with disagreements, without using any aggregated label. Yet, performances considering both soft and hard evaluations are reported. The proposed system uses large language models (i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification and classification in English and Spanish. In particular, our system is articulated in three different pipelines. The ensemble approach outperformed the individual large language models obtaining the best performances both adopting a soft and a hard label evaluation. This work describes the participation in all the three EXIST tasks, considering a soft evaluation, it obtained fourth place in Task 2 at EXIST and first place in Task 3, with the highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79. The source code of our approaches is publicly available at https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "104163189",
                    "name": "Giuliano Rizzi"
                },
                {
                    "authorId": "1847803",
                    "name": "E. Fersini"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "ca4e9843118a2c23183fc0b076086f850ee9e472",
            "title": "Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection",
            "abstract": "This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "143752702",
                    "name": "Paolo Rosso"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "b7a5247ac35d788512f8f23ee64ee5cc45bc11be",
            "title": "Detection and Classification of Sexism on Social Media Using Multiple Languages, Transformers, and Ensemble Models",
            "abstract": "Identifying and classifying sexist content in social media posts is a highly complex and relevant problem. Some characteristics such as sarcasm and multiple forms of sexism increase the difficulty of detecting and identifying this type of content. Nevertheless, it is essential to improve prediction quality to improve decision-making such as post removal, and user ban, among others. The main objective of this work is to propose a methodology and explore the use of different transformers architectures for two tasks in English and Spanish: sexism detection and sexism classification. Single-language and multilingual versions of the BERT, RoBERTa, and single-language versions of the Electra, and GPT2 architectures were evaluated on the EXIST 2022 shared task challenge at IberLEF 2022 dataset. It was observed that: (i) the use of the translation of the posts to English and then using single-language English and multilingual models present the best results; (ii) the best architectures were BERT and RoBERTa; (iii) using single-language Spanish models provided the worst results; (iv) sexism classification was more difficult than sexism detection; and (v) the use of ensembles were better than the GPT2 and Electra models, but worse than English single-language generally and multilingual models. An in-depth hyperparameters analysis was also conducted.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "32300892",
                    "name": "Roberto Fray da Silva"
                }
            ]
        },
        {
            "paperId": "43a95c59d5bc4ec4546d6e46bc104d5ffe96b520",
            "title": "Unified and Multilingual Author Profiling for Detecting Haters",
            "abstract": "This paper presents a unified user profiling framework to identify hate speech spreaders by processing their tweets regardless of the language. The framework encodes the tweets with sentence transformers and applies an attention mechanism to select important tweets for learning user profiles. Furthermore, the attention layer helps to explain why a user is a hate speech spreader by producing attention weights at both token and post level. Our proposed model outperformed the state-of-the-art multilingual transformer models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32775036",
                    "name": "Ipek Baris Schlicht"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                }
            ]
        },
        {
            "paperId": "45ca9c29e8e719c9641d694441cde63380856c05",
            "title": "UPV at TREC Health Misinformation Track 2021 Ranking with SBERT and Quality Estimators",
            "abstract": "Health misinformation on search engines is a significant problem that could negatively affect individuals or public health. To mitigate the problem, TREC organizes a health misinformation track. This paper presents our submissions to this track. We use a BM25 and a domain-specific semantic search engine for retrieving initial documents. Later, we examine a health news schema for quality assessment and apply it to re-rank documents. We merge the scores from the different components by using reciprocal rank fusion. Finally, we discuss the results and conclude with future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32775036",
                    "name": "Ipek Baris Schlicht"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "143752702",
                    "name": "Paolo Rosso"
                }
            ]
        },
        {
            "paperId": "6feb008fbac9c69318b546ce4f5dd258e4952b2d",
            "title": "AI-UPV at IberLEF-2021 DETOXIS task: Toxicity Detection in Immigration-Related Web News Comments Using Transformers and Statistical Models",
            "abstract": "This paper describes our participation in the DEtection of TOXicity in comments In Spanish (DETOXIS) shared task 2021 at the 3rd Workshop on Iberian Languages Evaluation Forum. The shared task is divided into two related classification tasks: (i) Task 1: toxicity detection and; (ii) Task 2: toxicity level detection. They focus on the xenophobic problem exacerbated by the spread of toxic comments posted in different online news articles related to immigration. One of the necessary efforts towards mitigating this problem is to detect toxicity in the comments. Our main objective was to implement an accurate model to detect xenophobia in comments about web news articles within the DETOXIS shared task 2021, based on the competition's official metrics: the F1-score for Task 1 and the Closeness Evaluation Metric (CEM) for Task 2. To solve the tasks, we worked with two types of machine learning models: (i) statistical models and (ii) Deep Bidirectional Transformers for Language Understanding (BERT) models. We obtained our best results in both tasks using BETO, an BERT model trained on a big Spanish corpus. We obtained the 3rd place in Task 1 official ranking with the F1-score of 0.5996, and we achieved the 6th place in Task 2 official ranking with the CEM of 0.7142. Our results suggest: (i) BERT models obtain better results than statistical models for toxicity detection in text comments; (ii) Monolingual BERT models have an advantage over multilingual BERT models in toxicity detection in text comments in their pre-trained language.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "32775036",
                    "name": "Ipek Baris Schlicht"
                }
            ]
        },
        {
            "paperId": "757befc17ac83cb84629a4432cf8193fc54db865",
            "title": "UPV at CheckThat!\u00a02021: Mitigating Cultural Differences for Identifying Multilingual Check-worthy Claims",
            "abstract": "Identifying check-worthy claims is often the first step of automated fact-checking systems. Tackling this task in a multilingual setting has been understudied. Encoding inputs with multilingual text representations could be one approach to solve the multilingual check-worthiness detection. However, this approach could suffer if cultural bias exists within the communities on determining what is check-worthy.In this paper, we propose a language identification task as an auxiliary task to mitigate unintended bias.With this purpose, we experiment joint training by using the datasets from CLEF-2021 CheckThat!, that contain tweets in English, Arabic, Bulgarian, Spanish and Turkish. Our results show that joint training of language identification and check-worthy claim detection tasks can provide performance gains for some of the selected languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32775036",
                    "name": "Ipek Baris Schlicht"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "143752702",
                    "name": "Paolo Rosso"
                }
            ]
        },
        {
            "paperId": "ca937f32c627c32b473c811b93702f1a3ecbbac0",
            "title": "Sexism Prediction in Spanish and English Tweets Using Monolingual and Multilingual BERT and Ensemble Models",
            "abstract": "The popularity of social media has created problems such as hate speech and sexism. The identification and classification of sexism in social media are very relevant tasks, as they would allow building a healthier social environment. Nevertheless, these tasks are considerably challenging. This work proposes a system to use multilingual and monolingual BERT and data points translation and ensemble strategies for sexism identification and classification in English and Spanish. It was conducted in the context of the sEXism Identification in Social neTworks shared 2021 (EXIST 2021) task, proposed by the Iberian Languages Evaluation Forum (IberLEF). The proposed system and its main components are described, and an in-depth hyperparameters analysis is conducted. The main results observed were: (i) the system obtained better results than the baseline model (multilingual BERT); (ii) ensemble models obtained better results than monolingual models; and (iii) an ensemble model considering all individual models and the best standardized values obtained the best accuracies and F1-scores for both tasks. This work obtained first place in both tasks at EXIST, with the highest accuracies (0.780 for task 1 and 0.658 for task 2) and F1-scores (F1-binary of 0.780 for task 1 and F1-macro of 0.579 for task 2).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "32300892",
                    "name": "Roberto Fray da Silva"
                },
                {
                    "authorId": "32775036",
                    "name": "Ipek Baris Schlicht"
                }
            ]
        }
    ]
}