{
    "authorId": "2808778",
    "papers": [
        {
            "paperId": "738fa053fb86cc35e70b8092bdd6e646bc5a73d1",
            "title": "Development of Prototype System to Generate Chronological Response Scenario Dataset by Assembling Multi-responders\u2019 Action Logs at Past Disaster",
            "abstract": "In recent years, various kinds of disasters such as landslide disasters, heavy rain-fall disasters, and earthquake disasters have occurred in any area of Japan. In the case of a large-scale disaster, local governments tend to verify the disaster response, identify issues, and consider solutions. However, in the case of other disasters, the response is managed on a department-by-department basis, and it is rarely summarized comprehensively and the overall picture of the disaster response is not reviewed. On the other hand, assuming training, a disaster response scenario is essential. However, although experienced people and researchers create scenarios reviewing past disasters as examples, they are based on their own experience and they are not necessarily reflected all the actual conditions of past disasters.Against this issue, we designed and developed a web application that comprehensively organizes the action logs in chronological order reflecting the structure of the organization even though those action logs are managed individually by each department. With this tool, based on the accumulated dataset, past response logs are given to a user as situations for each time step, and the user can easily and quickly experience disaster response drill.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                }
            ]
        },
        {
            "paperId": "a79ca1fa602df6d35f3703fa628e35ec03f903dc",
            "title": "Time-Cost Estimation for Early Disaster Damage Assessment Methods, Depending on Affected Area",
            "abstract": "In recent years, various types of disasters have occurred frequently in Japan. Such incidents require a rapid response. It is necessary to grasp the full extent of the disaster at an early stage. Research and development of effective methods to achieve this are in progress. Although each method has its own characteristics, from a business perspective it is necessary to know when and which method should be used to obtain the full extent of the damage. As of yet, there is no comparison among methods to answer this question. Therefore, the purpose of this study is to position the time-cost per unit area as one of the evaluation criteria to understand or estimate damage. To achieve this objective, the procedure of each method is clarified, the area to be analyzed by each method is identified, and the time-cost of each procedure is estimated. The time-cost per unit area is calculated by dividing the time-cost by the area of interest. Particularly, the time required for the preparation of each method, which is independent on the area, is positioned as the initial time-cost that is also derived and added. Based on the above, a linear function with the area of damage as a variable is determined. Simulations are performed to derive the estimated time-cost. Depending on the assumed area of damage, results are obtained when each method is applied.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2650178",
                    "name": "K. Tamura"
                },
                {
                    "authorId": "2059024250",
                    "name": "Kousuke Uo"
                },
                {
                    "authorId": "2111044037",
                    "name": "Masaki Kobayashi"
                },
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                }
            ]
        },
        {
            "paperId": "6aced7d7303fd82f8c4218aea2f3387efdf1d3c1",
            "title": "Making AI Machines Work for Humans in FoW",
            "abstract": "The Future of Work (FoW) is witnessing an evolution where AI systems (broadly machines or businesses) are used to the benefit of humans. Work here refers to all forms of paid and unpaid labor in both physical and virtual workplaces and that is enabled by AI systems. This covers crowdsourcing platforms such as Amazon Mechanical Turk, online labor marketplaces such as TaskRabbit and Qapa, but also regular jobs in physical workplaces. Bringing humans back to the frontier of FoW will increase their trust in AI systems and shift their perception to use them as a source of self-improvement, ensure better work performance, and positively shape social and economic outcomes of a society and a nation. To enable that, physical and virtual workplaces will need to capture human traits, behavior, evolving needs, and provide jobs to all. Attitudes, values, opinions regarding the processes and policies will need to be assessed and considered in the design of FoW ecosystems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2034201368",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2146072233",
                    "name": "Lei Chen"
                },
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                },
                {
                    "authorId": "2034202207",
                    "name": "James Abello Monedero"
                },
                {
                    "authorId": "1807924",
                    "name": "P. Bourhis"
                },
                {
                    "authorId": "2038513",
                    "name": "F. Charoy"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "1863248",
                    "name": "Shady Elbassuoni"
                },
                {
                    "authorId": "1403157540",
                    "name": "D. Gross-Amblard"
                },
                {
                    "authorId": "51493818",
                    "name": "Emilie Hoareau"
                },
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2034202198",
                    "name": "Jared Kenworthy"
                },
                {
                    "authorId": "7251192",
                    "name": "I. Kitahara"
                },
                {
                    "authorId": "2124213925",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "2069605832",
                    "name": "Raghav Rao"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "1734682",
                    "name": "P. Senellart"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1825255212",
                    "name": "M. Tommasi"
                },
                {
                    "authorId": "49697753",
                    "name": "Kazutoshi Umemoto"
                },
                {
                    "authorId": "144918359",
                    "name": "A. Wiggins"
                },
                {
                    "authorId": "2034178749",
                    "name": "Koichiro Yoshida"
                }
            ]
        },
        {
            "paperId": "c0685008fdb42f926d1b8783f6ef999b87a7cfe8",
            "title": "Collapsed Building Detection Using 3D Point Clouds and Deep Learning",
            "abstract": "Collapsed buildings should be detected with the highest priority during earthquake emergency response, due to the associated fatality rates. Although deep learning-based damage detection using vertical aerial images can achieve high performance, as depth information cannot be obtained, it is difficult to detect collapsed buildings when their roofs are not heavily damaged. Airborne LiDAR can efficiently obtain the 3D geometries of buildings (in the form of point clouds) and thus has greater potential to detect various collapsed buildings. However, there have been few previous studies on deep learning-based damage detection using point cloud data, due to a lack of large-scale datasets. Therefore, in this paper, we aim to develop a dataset tailored to point cloud-based building damage detection, in order to investigate the potential of point cloud data in collapsed building detection. Two types of building data are created: building roof and building patch, which contains the building and its surroundings. Comprehensive experiments are conducted under various data availability scenarios (pre\u2013post-building patch, post-building roof, and post-building patch) with varying reference data. The pre\u2013post scenario tries to detect damage using pre-event and post-event data, whereas post-building patch and roof only use post-event data. Damage detection is implemented using both basic and modern 3D point cloud-based deep learning algorithms. To adapt a single-input network, which can only accept one building\u2019s data for a prediction, to the pre\u2013post (double-input) scenario, a general extension framework is proposed. Moreover, a simple visual explanation method is proposed, in order to conduct sensitivity analyses for validating the reliability of model decisions under the post-only scenario. Finally, the generalization ability of the proposed approach is tested using buildings with different architectural styles acquired by a distinct sensor. The results show that point cloud-based methods can achieve high accuracy and are robust under training data reduction. The sensitivity analysis reveals that the trained models are able to locate roof deformations precisely, but have difficulty recognizing global damage, such as that relating to the roof inclination. Additionally, it is revealed that the model decisions are overly dependent on debris-like objects when surroundings information is available, which leads to misclassifications. By training on the developed dataset, the model can achieve moderate accuracy on another dataset with different architectural styles without additional training.",
            "fieldsOfStudy": [
                "Computer Science",
                "Geology"
            ],
            "authors": [
                {
                    "authorId": "51900739",
                    "name": "H. Xiu"
                },
                {
                    "authorId": "1486425638",
                    "name": "T. Shinohara"
                },
                {
                    "authorId": "2401583",
                    "name": "M. Matsuoka"
                },
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "108765174",
                    "name": "K. Kawabe"
                },
                {
                    "authorId": "3474509",
                    "name": "K. Horie"
                }
            ]
        },
        {
            "paperId": "e846651b17b0a19af9693988f088c80b67697266",
            "title": "Challenge of Roof Damage Housings Detection from Satellite Images by Applying Deep Learning Methodology : -A Case Study of Ibaraki City at 2018 Osaka Earthquake-",
            "abstract": "In Japan, we were suffered by many kinds of disasters. Once disaster occurs, we have to develop the common operational picture including damage situation in order to realize effective disaster response. However, it should take much time-cost to gather the damage situation. Against this issue, we decided to detect blue sheets object put on the damaged roof in recovery phase of disaster response. In this research, we tried to detect damage situation from satellite images by utilizing deep learning methodology. Especially, we adopt VGG-16 model developed by Oxford university, which gained fourth prize of ILSVRC in 2014. We prepared training data and applied it to actual affected area by 2018 Osaka earthquake as a case study. Finally, we confirmed that our trained AI detected blue sheet object with about 95% accuracy ratio.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "1931857096",
                    "name": "Seiichi Kara"
                },
                {
                    "authorId": "2055124225",
                    "name": "Kazuya Shirai"
                },
                {
                    "authorId": "2075054385",
                    "name": "Atsushi Imai"
                }
            ]
        },
        {
            "paperId": "fbbee14190b938119c3524b8db1891eb6c30592b",
            "title": "Validation of CyborgCrowd Implementation Possibility for Situation Awareness in Urgent Disaster Response -Case Study of International Disaster Response in 2019-",
            "abstract": "At disaster response, it is essential to grab whole picture of damage situation quickly and early after disaster occurrence in order to make disaster response effective and efficient. However, it takes much time to understand damage situation because there is not enough information about it. Against this issue, we proposed implementation of CyborgCrowd for situation awareness in disaster response. In order to validate its possibility, we planned the first international disaster drill in October, 2019. In this drill, we simulated to detect flooded area by West Japan Flood occurred in 2018 from aerial photos by collaboration between crowdsourcing and AIs following Human-in-the-Loop process. Especially, in this drill, AIs were also crowdsourced. In this research, we validated the transition of the efforts from crowdsourcing and AIs to detecting flooded area, and verified the accuracy of result by comparing with the actual flooded area published by Geospatial Information Authority of Japan. Furthermore, we found some suggestion about features of detection results by humans and AIs. For example, some humans detected flooded area roughly, however AIs detected it much closely. Based on those features, we proposed the way to decrease the difference between results by humans and AIs. This was essential for local responders to understand the whole picture of damage situation after disaster occurrence urgently. In this paper, we introduced the framework of international disaster drill, clarified the result of validation, and mentioned the possibility of effective collaboration between crowdsourcing and AIs for quick situation awareness in disaster response.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2650178",
                    "name": "K. Tamura"
                },
                {
                    "authorId": "2059024250",
                    "name": "Kousuke Uo"
                },
                {
                    "authorId": "2111044037",
                    "name": "Masaki Kobayashi"
                }
            ]
        },
        {
            "paperId": "50580630b6d89dda80067356691a3497fbb58653",
            "title": "A Route Search System Considering Urgency and Efficient Coverage Without Complete Information",
            "abstract": "Path planning to visit all nodes in a graph with deadlines has applications such as the route search for shooting aerial photography in a natural disaster. In such applications, we need to calculate the route that covers all graph nodes as efficiently as possible while satisfying the urgency requirements. This paper proposes a system to find routes in such a situations. In our system, information on the urgency (the deadline for visiting each node) is not necessarily fully known in advance and can be updated at any time, and we cannot totally optimize the route in advance. Therefore, we devised a greedy method tries to go to the nodes with high urgency while keeping all of the remaining nodes being directly connected to each other. Our preliminary experiments show that the proposed method is better in the performance than the simple greedy method that does not consider the factor; the proposed method was 29.42% better to the simple greedy method in terms of missed deadlines and 36.52% better in terms of the total flight time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066598689",
                    "name": "Masaki Matsubara"
                },
                {
                    "authorId": "50634507",
                    "name": "Yutaka Nakamura"
                },
                {
                    "authorId": "50777492",
                    "name": "Nobutaka Suzuki"
                },
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                }
            ]
        },
        {
            "paperId": "aeb65444db4f4477da93d15ae605014e3672a6de",
            "title": "Establishment of Work-Flow for Roof Damage Detection Utilizing Drones, Human and AI based on Human-in-the-Loop Framework",
            "abstract": "Once disaster occurs, we have to understand the whole picture of damage situation. However, there is not enough human resources and time to do it. In 2019, we were affected by Yamagata earthquake, and many buildings were damaged in Murakami city. Most of buildings damage were concentrated on their roofs. Local responders tried to inspect those roof damage, however they cannot do it from ground. Against this issue, we decided to take images of roof damage utilizing drones. We designed the flight plan covering over affected area, operated a drone, and got images. Aftermath, we created orthophoto mosaic from those images. We published it for local responders to inspect roof damage of each building in the web-based GIS platform. Furthermore, we detect roof damage by human and let AI learn the result of our detection of roof damage. This is followed the framework of Human-in-the-Loop. Just now, accuracy of the roof-damage detection by AI was not so high. In this paper, we introduce the work-flow of this challenge from designing flight plan for drone to roof-damage detection by AI which is educated with images of actual damage situation after disaster occurrence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2650178",
                    "name": "K. Tamura"
                },
                {
                    "authorId": "66019588",
                    "name": "Ryota Hamamoto"
                }
            ]
        },
        {
            "paperId": "5626179b1854dc1638b33cc4c72f8a8afbb5d25b",
            "title": "Cyber-Physical Disaster Drill: Preliminary Results and Social Challenges of the First Attempts to Unify Human, ICT and AI in Disaster Response",
            "abstract": "This paper aims to introduce the Cyber-Physical disaster evacuation drill designed by the CyborgCrowd team to implement the collaboration between Human, Information Communication Technology (ICT) and Artificial Intelligence (AI) and hence improve disaster relief planning and effort. We will present some of the preliminary results and the social challenges that the project needs to address in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66461623",
                    "name": "Flavia Fulco"
                },
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "1892462",
                    "name": "Tomoya Mikami"
                }
            ]
        },
        {
            "paperId": "68482dba7a058eef0799b39f9abc09fbd2a3713b",
            "title": "Implementation of Effective Field Survey for Damaged Buildings under Harmonious Collaboration between Human and ICT - A Case Study of 2018 Hokkaido Eastern Iburi Earthquake -",
            "abstract": "Based on the experience at past disasters, we have developed the effective method of inspection for each building damage. In this method, we developed only paper-based forms for damage inspection. However, with paper-based forms, we cannot control the quality of collected information, we cannot grab the progress of building damage inspection in real-time, and we cannot draw the whole picture of building damage in the affected area for rational and immediate decision making. Against these issues, we decided to develop an integrated system for effective and efficient building damage inspection utilizing mobile-GIS and cloud-based GIS. We designed the flow of Information Production dealing with information as a product, and developed an integrated system. In this process, we consider about how to realize harmonious collaboration between human and ICT. Finally, we implemented it at Abira town in Hokkaido, which was affected by 2018 Hokkaido Eastern Iburi Earthquake on 6th September. Through the on-site implementation for one month, we and local responders finished the damage inspection for all buildings placed in Abira town, which was over 7,200. Furthermore, we found that system supported their activity effectively, and we detected some issues we should solve for implementation at future disaster.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2650178",
                    "name": "K. Tamura"
                },
                {
                    "authorId": "3474509",
                    "name": "K. Horie"
                },
                {
                    "authorId": "66019588",
                    "name": "Ryota Hamamoto"
                },
                {
                    "authorId": "2690086",
                    "name": "H. Hayashi"
                }
            ]
        }
    ]
}