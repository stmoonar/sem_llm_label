{
    "authorId": "2056579945",
    "papers": [
        {
            "paperId": "f282fa85469cc789c2f3b62e57e3446a49528afa",
            "title": "Hybrid Attention Network for Epileptic EEG Classification",
            "abstract": "Automatic seizure detection from electroencephalography (EEG) based on deep learning has been significantly improved. However, existing works have not adequately excavate the spatial-temporal information between EEG channels. Besides, most works mainly focus on patient-specific scenarios while cross-patient seizure detection is more challenging and meaningful. Regarding the above problems, we propose a hybrid attention network (HAN) for automatic seizure detection. Specifically, the graph attention network (GAT) extracts spatial features at the front end, and Transformer gets time features as the back end. HAN leverages the attention mechanism and fully extracts the spatial-temporal correlation of EEG signals. The focal loss function is introduced to HAN to deal with the imbalance of the dataset accompanied by seizure detection based on EEG. Both patient-specific and patient-independent experiments are carried out on the public CHB-MIT database. Experimental results demonstrate the efficacy of HAN in both experimental settings.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "2153102948",
                    "name": "Jiatong He"
                },
                {
                    "authorId": "2171218625",
                    "name": "Fenglin Zhu"
                },
                {
                    "authorId": "2174196178",
                    "name": "Tiantian Xiao"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2243360852",
                    "name": "Ziwei Wang"
                },
                {
                    "authorId": "2534225",
                    "name": "Fangzhou Xu"
                },
                {
                    "authorId": "2056579945",
                    "name": "Yi Niu"
                }
            ]
        },
        {
            "paperId": "3d195ac053c8004e723c65cd3b9fe0f4c47d8ae8",
            "title": "Exploring route choice preferences for game route guidance",
            "abstract": "This study presents a route guidance model based on game theory, in which commuters\u2019 route choice preferences as model parameters are incorporated for deriving a game strategy. To further characterize commuters\u2019 route choice decision-making, a dynamic parameter style is designed and subsequently commuters\u2019 likely response is factored in the game strategy. The game maximal payoff calculated by Nash equilibrium further determines the optimal routes for the designated original-destination pair. The simulations verify that our results reach 90% accuracy approximately. This study also demonstrates that the model assigns paths to users with the least-expected-time so as to satisfy their travel preferences during commuting. It is an important attempt to design a route guidance through designing travel time and route familiarity payoff in the game model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118503135",
                    "name": "Lina Han"
                },
                {
                    "authorId": "2118758131",
                    "name": "Yunfeng Shi"
                },
                {
                    "authorId": "2056579945",
                    "name": "Yi Niu"
                }
            ]
        },
        {
            "paperId": "7222abb8af4f273cb865084118a25f5a86a35f7c",
            "title": "Epilepsy Classification for Mining Deeper Relationships between EEG Channels based on GCN",
            "abstract": "Epilepsy is a brain disorder caused by abnormal discharges of neurons in brain. It is one of the most commonly studied disorders in neurology. The research of epilepsy electroencephalogram (EEG) has become a hot research topic. We find that in epilepsy EEG detection task, many previous methods focused on directly collecting the data of each channel, but these methods seldom analyse relationships between signals. Therefore, we propose the Epilepsy EEG Graph Convolutional Network EGCN, which makes full use of correlations between channels to deeply mine data information. We specifically design 5-layer graph convolutional network structure for classification of healthy and epileptic patients. The method is applied to public data set (Boon and CHB-MIT) to establish a reasonable classification model. And we compare it with some advanced algorithms. The experimental results show that the E-GCN method is superior to many existing methods in classification accuracy. In brief, the E-GCN method can be effectively used in classification and detection for epilepsy. This provides new ideas for colleagues, who study epilepsy EEG. In addition, this also provides richer experience for diagnosis of epilepsy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145229735",
                    "name": "Xin Chen"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "2056579945",
                    "name": "Yi Niu"
                },
                {
                    "authorId": "2133093092",
                    "name": "Cheng Li"
                }
            ]
        },
        {
            "paperId": "8f0269c6c7e4f154c90309bc3f335b6666a1457e",
            "title": "Deep Group-Wise Registration for Multi-Spectral Images From Fundus Images",
            "abstract": "Multi-spectral imaging (MSI) is a novel non-invasive tool for visualizing the entire span of the eye, from the internal limiting membrane to the choroid. However, spatial misalignments can be frequently observed in sequential MSI images because the eye saccade movement is usually faster than the MSI image acquisition speed. Therefore, registering MSI images is necessary for computer-based analysis of retinal degeneration via MSI. In this paper, we propose an early deep learning framework for achieving an accurate registration of MSI images in a group-wise fashion. The framework contains three parts: a template construction based on principal component analysis, a deformation field calculation, and a spatial transformation. The framework is uniquely capable of resolving two key challenges, i.e., the \u201cmulti-modal\u201d characteristics in MSI images for the acquisition with different spectra and the requirement of joint registration of the sequential images. Our experimental results demonstrate the superior performance of our framework compared to several representative state-of-the-art techniques in both speed and accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40560668",
                    "name": "Tongtong Che"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "7802024",
                    "name": "Jinyu Cong"
                },
                {
                    "authorId": "48752015",
                    "name": "Yanyun Jiang"
                },
                {
                    "authorId": "2056579945",
                    "name": "Yi Niu"
                },
                {
                    "authorId": "4038867",
                    "name": "Wanzhen Jiao"
                },
                {
                    "authorId": "7352848",
                    "name": "Bojun Zhao"
                },
                {
                    "authorId": "49326797",
                    "name": "Yanhui Ding"
                }
            ]
        },
        {
            "paperId": "b6d56283add074d876b1755853e0b0f3adc70d24",
            "title": "Deep Propagation Based Image Matting",
            "abstract": "In this paper, we propose a deep propagation based image matting framework by introducing deep learning into learning an alpha matte propagation principal. Our deep learning architecture is a concatenation of a deep feature extraction module, an affinity learning module and a matte propagation module. These three modules are all differentiable and can be optimized jointly via an end-to-end training process. Our framework results in a semantic-level pairwise similarity of pixels for propagation by learning deep image representations adapted to matte propagation. It combines the power of deep learning and matte propagation and can therefore surpass prior state-of-the-art matting techniques in terms of both accuracy and training complexity, as validated by our experimental results from 243K images created based on two benchmark matting databases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153606144",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2056579945",
                    "name": "Yi Niu"
                },
                {
                    "authorId": "49529511",
                    "name": "Peiyong Duan"
                },
                {
                    "authorId": "2144908211",
                    "name": "Jianwei Lin"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                }
            ]
        }
    ]
}