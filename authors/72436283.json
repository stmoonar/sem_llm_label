{
    "authorId": "72436283",
    "papers": [
        {
            "paperId": "27f165d57fa2c7020c87a6d0ab694c400d7d4493",
            "title": "Choice-75: A Dataset on Decision Branching in Script Learning",
            "abstract": "Script learning studies how daily events unfold. It enables machines to reason about narratives with implicit information. Previous works mainly consider a script as a linear sequence of events while ignoring the potential branches that arise due to people\u2019s circumstantial choices. We hence propose Choice-75, the first benchmark that challenges intelligent systems to make decisions given descriptive scenarios, containing 75 scripts and more than 600 scenarios. We also present preliminary results with current large language models (LLM). Although they demonstrate overall decent performances, there is still notable headroom in hard scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2165225503",
                    "name": "Zhaoyi Hou"
                },
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "6898f302acab95f30822c948c484af5c6e99827b",
            "title": "Exploring the Curious Case of Code Prompts",
            "abstract": "Recent work has shown that prompting language models with code-like representations of natural language leads to performance improvements on structured reasoning tasks. However, such tasks comprise only a small subset of all natural language tasks. In our work, we seek to answer whether or not code-prompting is the preferred way of interacting with language models in general. We compare code and text prompts across three popular GPT models (davinci, code-davinci-002, and text-davinci-002) on a broader selection of tasks (e.g., QA, sentiment, summarization) and find that with few exceptions, code prompts do not consistently outperform text prompts. Furthermore, we show that the style of code prompt has a large effect on performance for some (but not all) tasks and that fine-tuning on text instructions leads to better relative performance of code prompts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "83863037",
                    "name": "Liam Dugan"
                },
                {
                    "authorId": "2283763073",
                    "name": "Hainiu Xu"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "9836e9c85152def0522b7ab6d0073f8727f313bc",
            "title": "Language Models are Drummers: Drum Composition with Natural Language Pre-Training",
            "abstract": "Automatic music generation with artificial intelligence typically requires a large amount of data which is hard to obtain for many less common genres and musical instruments. To tackle this issue, we present ongoing work and preliminary findings on the possibility for deep models to transfer knowledge from language to music, by finetuning large language models pre-trained on a massive text corpus on only hundreds of MIDI files of drum performances. We show that by doing so, one of the largest, state-of-the-art models (GPT3) is capable of generating reasonable drum grooves, while models that are not pre-trained (Transformer) shows no such ability beyond naive repetition. Evaluating generated music is a challenging task, more so is evaluating drum grooves with little precedence in literature. Hence, we propose a tailored structural evaluation method and analyze drum grooves produced by GPT3 compared to those played by human professionals, exposing the strengths and weaknesses of such generation by language-to-music transfer. Our findings suggest that language-to-music transfer learning with large language models is viable and promising.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "b115c1e1e9e51f8ad7d47b745bc04e29a654b84d",
            "title": "Faithful Chain-of-Thought Reasoning",
            "abstract": "While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a reasoning framework involving two stages: Translation (Natural Language query $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning chain $\\rightarrow$ answer), using an LM and a deterministic solver respectively. This guarantees that the reasoning chain provides a faithful explanation of the final answer. Aside from interpretability, Faithful CoT also improves empirical performance: it outperforms standard CoT on 9 of 10 benchmarks from 4 diverse domains, with a relative accuracy gain of 6.3% on Math Word Problems (MWP), 3.4% on Planning, 5.5% on Multi-hop Question Answering (QA), and 21.4% on Relational Inference. Furthermore, with GPT-4 and Codex, it sets the new state-of-the-art few-shot performance on 7 datasets (with 95.0+ accuracy on 6 of them), showing a strong synergy between faithfulness and accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1904906987",
                    "name": "Qing Lyu"
                },
                {
                    "authorId": "151207988",
                    "name": "Shreya Havaldar"
                },
                {
                    "authorId": "2161714960",
                    "name": "Adam Stein"
                },
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "48810734",
                    "name": "D. Rao"
                },
                {
                    "authorId": "2053678328",
                    "name": "Eric Wong"
                },
                {
                    "authorId": "2817917",
                    "name": "Marianna Apidianaki"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "b8ca7dfe49501c0dbeeeadbdc94737a5b4fea313",
            "title": "OpenPI2.0: An Improved Dataset for Entity Tracking in Texts",
            "abstract": "Much texts describe a changing world (e.g., procedures, stories, newswires), and understanding them requires tracking how entities change. An earlier dataset, OpenPI, provided crowdsourced annotations of entity state changes in text. However, a major limitation was that those annotations were free-form and did not identify salient changes, hampering model evaluation. To overcome these limitations, we present an improved dataset, OpenPI2.0, where entities and attributes are fully canonicalized and additional entity salience annotations are added. On our fairer evaluation setting, we find that current state-of-the-art language models are far from competent. We also show that using state changes of salient entities as a chain-of-thought prompt, downstream performance is improved on tasks such as question answering and classical planning, outperforming the setting involving all related entities indiscriminately. We offer OpenPI2.0 for the continued development of models that can understand the dynamics of entities in text.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "2283763073",
                    "name": "Hainiu Xu"
                },
                {
                    "authorId": "2114845637",
                    "name": "Abhinav Kommula"
                },
                {
                    "authorId": "1721168",
                    "name": "Niket Tandon"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "c43a4a7b7ea4f4889de051321cb0073fd577f843",
            "title": "Causal Reasoning of Entities and Events in Procedural Texts",
            "abstract": "Entities and events are crucial to natural language reasoning and common in procedural texts. Existing work has focused either exclusively on entity state tracking (e.g., whether a pan is hot) or on event reasoning (e.g., whether one would burn themselves by touching the pan), while these two tasks are often causally related. We propose CREPE, the first benchmark on causal reasoning of event plausibility and entity states. We show that most language models, including GPT-3, perform close to chance at .35 F1, lagging far behind human at .87 F1. We boost model performance to .59 F1 by creatively representing events as programming languages while prompting language models pretrained on code. By injecting the causal relations between entities and events as intermediate reasoning steps in our representation, we further boost the performance to .67 F1. Our findings indicate not only the challenge that CREPE brings for language models, but also the efficacy of code-like prompting combined with chain-of-thought prompting for multihop event reasoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "2283763073",
                    "name": "Hainiu Xu"
                },
                {
                    "authorId": "2109409802",
                    "name": "Yue Yang"
                },
                {
                    "authorId": "2149163534",
                    "name": "Shuyan Zhou"
                },
                {
                    "authorId": "1667413380",
                    "name": "Weiqiu You"
                },
                {
                    "authorId": "2167348504",
                    "name": "Manni Arora"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "d44996a04e77c990177b589261ceebee5a80ef01",
            "title": "Human-in-the-loop Schema Induction",
            "abstract": "Schema induction builds a graph representation explaining how events unfold in a scenario. Existing approaches have been based on information retrieval (IR) and information extraction (IE), often with limited human curation. We demonstrate a human-in-the-loop schema induction system powered by GPT-3. We first describe the different modules of our system, including prompting to generate schematic elements, manual edit of those elements, and conversion of those into a schema graph. By qualitatively comparing our system to previous ones, we show that our system not only transfers to new domains more easily than previous approaches, but also reduces efforts of human curation thanks to our interactive interface.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123437034",
                    "name": "Tianyi Zhang"
                },
                {
                    "authorId": "2065421682",
                    "name": "Isaac Tham"
                },
                {
                    "authorId": "2165225503",
                    "name": "Zhaoyi Hou"
                },
                {
                    "authorId": "2111472779",
                    "name": "J. Ren"
                },
                {
                    "authorId": "2202592542",
                    "name": "Liyang Zhou"
                },
                {
                    "authorId": "2283763073",
                    "name": "Hainiu Xu"
                },
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "145262322",
                    "name": "Lara J. Martin"
                },
                {
                    "authorId": "3372941",
                    "name": "Rotem Dror"
                },
                {
                    "authorId": "2109154767",
                    "name": "Sha Li"
                },
                {
                    "authorId": "2072975661",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "145755155",
                    "name": "Martha Palmer"
                },
                {
                    "authorId": "1783500",
                    "name": "S. Brown"
                },
                {
                    "authorId": "2209984833",
                    "name": "Reece Suchocki"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "4412cf194a6c1dab0515011137fbf06632e18d7a",
            "title": "Unsupervised Entity Linking with Guided Summarization and Multiple-Choice Selection",
            "abstract": "Entity linking, the task of linking potentially ambiguous mentions in texts to corresponding knowledge-base entities, is an important component for language understanding. We address two challenge in entity linking: how to leverage wider contexts surrounding a mention, and how to deal with limited training data. We propose a fully unsupervised model called SumMC that first generates a guided summary of the contexts conditioning on the mention, and then casts the task to a multiple-choice problem where the model chooses an entity from a list of candidates. In addition to evaluating our model on existing datasets that focus on named entities, we create a new dataset that links noun phrases from WikiHow to Wikidata. We show that our SumMC model achieves state-of-the-art unsupervised performance on our new dataset and on exiting datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203779480",
                    "name": "Young Min Cho"
                },
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                }
            ]
        },
        {
            "paperId": "6e5944b759ef1c2ea2f694221cf54ef718ec95ee",
            "title": "Reasoning about Procedures with Natural Language Processing: A Tutorial",
            "abstract": "This tutorial provides a comprehensive and in-depth view of the research on procedures, primarily in Natural Language Processing. A procedure is a sequence of steps intended to achieve some goal. Understanding procedures in natural language has a long history, with recent breakthroughs made possible by advances in technology. First, we discuss established approaches to collect procedures, by human annotation or extraction from web resources. Then, we examine different angles from which procedures can be reasoned about, as well as ways to represent them. Finally, we enumerate scenarios where procedural knowledge can be applied to the real world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                }
            ]
        },
        {
            "paperId": "7e43dad7fbae3a7db47adc6b89c76acbd2fb225f",
            "title": "Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data",
            "abstract": "Procedures are inherently hierarchical. To \u201cmake videos\u201d, one may need to \u201cpurchase a camera\u201d, which in turn may require one to \u201cset a budget\u201d. While such hierarchical knowledge is critical for reasoning about complex procedures, most existing work has treated procedures as shallow structures without modeling the parent-child relation. In this work, we attempt to construct an open-domain hierarchical knowledge-base (KB) of procedures based on wikiHow, a website containing more than 110k instructional articles, each documenting the steps to carry out a complex procedure. To this end, we develop a simple and efficient method that links steps (e.g., \u201cpurchase a camera\u201d) in an article to other articles with similar goals (e.g., \u201chow to choose a camera\u201d), recursively constructing the KB. Our method significantly outperforms several strong baselines according to automatic evaluation, human judgment, and application to downstream tasks such as instructional video retrieval.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149163534",
                    "name": "Shuyan Zhou"
                },
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "2109409802",
                    "name": "Yue Yang"
                },
                {
                    "authorId": "1904906987",
                    "name": "Qing Lyu"
                },
                {
                    "authorId": "38253388",
                    "name": "Pengcheng Yin"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        }
    ]
}