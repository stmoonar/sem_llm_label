{
    "authorId": "47165273",
    "papers": [
        {
            "paperId": "8525434adbf25984e55c78063c71bcb958d364e4",
            "title": "Listwise Reward Estimation for Offline Preference-based Reinforcement Learning",
            "abstract": "In Reinforcement Learning (RL), designing precise reward functions remains to be a challenge, particularly when aligning with human intent. Preference-based RL (PbRL) was introduced to address this problem by learning reward models from human feedback. However, existing PbRL methods have limitations as they often overlook the second-order preference that indicates the relative strength of preference. In this paper, we propose Listwise Reward Estimation (LiRE), a novel approach for offline PbRL that leverages second-order preference information by constructing a Ranked List of Trajectories (RLT), which can be efficiently built by using the same ternary feedback type as traditional methods. To validate the effectiveness of LiRE, we propose a new offline PbRL dataset that objectively reflects the effect of the estimated rewards. Our extensive experiments on the dataset demonstrate the superiority of LiRE, i.e., outperforming state-of-the-art baselines even with modest feedback budgets and enjoying robustness with respect to the number of feedbacks and feedback noise. Our code is available at https://github.com/chwoong/LiRE",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2295954954",
                    "name": "Heewoong Choi"
                },
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "2112569591",
                    "name": "Hongjoon Ahn"
                },
                {
                    "authorId": "2315133096",
                    "name": "Taesup Moon"
                }
            ]
        },
        {
            "paperId": "81b6622174c6109710235030623991e18741ae5a",
            "title": "Continual Learning in the Presence of Spurious Correlation",
            "abstract": "Most continual learning (CL) algorithms have focused on tackling the stability-plasticity dilemma, that is, the challenge of preventing the forgetting of previous tasks while learning new ones. However, they have overlooked the impact of the knowledge transfer when the dataset in a certain task is biased - namely, when some unintended spurious correlations of the tasks are learned from the biased dataset. In that case, how would they affect learning future tasks or the knowledge already learned from the past tasks? In this work, we carefully design systematic experiments using one synthetic and two real-world datasets to answer the question from our empirical findings. Specifically, we first show through two-task CL experiments that standard CL methods, which are unaware of dataset bias, can transfer biases from one task to another, both forward and backward, and this transfer is exacerbated depending on whether the CL methods focus on the stability or the plasticity. We then present that the bias transfer also exists and even accumulate in longer sequences of tasks. Finally, we propose a simple, yet strong plug-in method for debiasing-aware continual learning, dubbed as Group-class Balanced Greedy Sampling (BGS). As a result, we show that our BGS can always reduce the bias of a CL model, with a slight loss of CL performance at most.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109499598",
                    "name": "Donggyu Lee"
                },
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "4842965",
                    "name": "Taesup Moon"
                }
            ]
        },
        {
            "paperId": "d444ee024ac296c848a8cee326ea57c91ff273fe",
            "title": "Issues for Continual Learning in the Presence of Dataset Bias",
            "abstract": "While most continual learning algorithms have focused on tackling the stability-plasticity dilemma, they have overlooked the effects of the knowledge transfer when the dataset is biased \u2014 namely, when some unintended spurious correlations, not the true causal structures, of the tasks are learned from the biased dataset. In that case, how would they affect learning future tasks or the knowledge already learned from the past tasks? In this work, we design systematic experiments with a synthetic biased dataset and try to answer the above question from our empirical findings. Namely, we first show that standard continual learning methods that are unaware of dataset bias can transfer biases from one task to another, both forward and backward. In addition, we find that naively using existing debiasing methods after each continual learning step can lead to significant forgetting of past tasks and reduced overall continual learning performance. These findings highlight the need for a causality-aware design of continual learning algorithms to prevent both bias transfers and catastrophic forgetting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109499598",
                    "name": "Donggyu Lee"
                },
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "4842965",
                    "name": "Taesup Moon"
                }
            ]
        },
        {
            "paperId": "eb776076b4653f45a399e0afef781919d94b0578",
            "title": "Re-weighting Based Group Fairness Regularization via Classwise Robust Optimization",
            "abstract": "Many existing group fairness-aware training methods aim to achieve the group fairness by either re-weighting underrepresented groups based on certain rules or using weakly approximated surrogates for the fairness metrics in the objective as regularization terms. Although each of the learning schemes has its own strength in terms of applicability or performance, respectively, it is difficult for any method in the either category to be considered as a gold standard since their successful performances are typically limited to specific cases. To that end, we propose a principled method, dubbed as \\ours, which unifies the two learning schemes by incorporating a well-justified group fairness metric into the training objective using a class wise distributionally robust optimization (DRO) framework. We then develop an iterative optimization algorithm that minimizes the resulting objective by automatically producing the correct re-weights for each group. Our experiments show that FairDRO is scalable and easily adaptable to diverse applications, and consistently achieves the state-of-the-art performance on several benchmark datasets in terms of the accuracy-fairness trade-off, compared to recent strong baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "122744007",
                    "name": "Taeeon Park"
                },
                {
                    "authorId": "2647582",
                    "name": "Sanghyuk Chun"
                },
                {
                    "authorId": "4842965",
                    "name": "Taesup Moon"
                }
            ]
        },
        {
            "paperId": "c92f1bc0b93404482054e290d526f66d70f9ac62",
            "title": "Dataset Condensation with Contrastive Signals",
            "abstract": "Recent studies have demonstrated that gradient matching-based dataset synthesis, or dataset condensation (DC), methods can achieve state-of-the-art performance when applied to data-efficient learning tasks. However, in this study, we prove that the existing DC methods can perform worse than the random selection method when task-irrelevant information forms a significant part of the training dataset. We attribute this to the lack of participation of the contrastive signals between the classes resulting from the class-wise gradient matching strategy. To address this problem, we propose Dataset Condensation with Contrastive signals (DCC) by modifying the loss function to enable the DC methods to effectively capture the differences between classes. In addition, we analyze the new loss function in terms of training dynamics by tracking the kernel velocity. Furthermore, we introduce a bi-level warm-up strategy to stabilize the optimization. Our experimental results indicate that while the existing methods are ineffective for fine-grained image classification tasks, the proposed method can successfully generate informative synthetic datasets for the same tasks. Moreover, we demonstrate that the proposed method outperforms the baselines even on benchmark datasets such as SVHN, CIFAR-10, and CIFAR-100. Finally, we demonstrate the high applicability of the proposed method by applying it to continual learning tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6732273",
                    "name": "Saehyung Lee"
                },
                {
                    "authorId": "2647582",
                    "name": "Sanghyuk Chun"
                },
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "2151587",
                    "name": "Sangdoo Yun"
                },
                {
                    "authorId": "2152497729",
                    "name": "Sung-Hoon Yoon"
                }
            ]
        },
        {
            "paperId": "e54e0d9eaa922cefb1c69e105979399fd34497b1",
            "title": "Learning Fair Classifiers with Partially Annotated Group Labels",
            "abstract": "Recently, fairness-aware learning have become increasingly crucial, but most of those methods operate by assuming the availability of fully annotated demographic group labels. We emphasize that such assumption is unrealistic for real-world applications since group label annotations are expensive and can conflict with privacy issues. In this paper, we consider a more practical scenario, dubbed as Algorithmic Group Fairness with the Partially annotated Group labels (Fair-PG). We observe that the existing methods to achieve group fairness perform even worse than the vanilla training, which simply uses full data only with target labels, under Fair-PG. To address this problem, we propose a simple Confidence-based Group Label assignment (CGL) strategy that is readily applicable to any fairness-aware learning method. CGL utilizes an auxiliary group classifier to assign pseudo group labels, where random labels are assigned to low confident samples. We first theoretically show that our method design is better than the vanilla pseudo-labeling strategy in terms of fairness criteria. Then, we empirically show on several benchmark datasets that by combining CGL and the state-of-the-art fairness-aware in-processing methods, the target accuracies and the fairness metrics can be jointly improved compared to the baselines. Furthermore, we convincingly show that CGL enables to naturally augment the given group-labeled dataset with external target label-only datasets so that both accuracy and fairness can be improved. Code is available at https://github.com/naver-ai/cgl_fairness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "2647582",
                    "name": "Sanghyuk Chun"
                },
                {
                    "authorId": "4842965",
                    "name": "Taesup Moon"
                }
            ]
        },
        {
            "paperId": "515a6784e6d335677d16632d1b4d76471deee8aa",
            "title": "Continual Learning with Node-Importance based Adaptive Group Sparse Regularization",
            "abstract": "We propose a novel regularization-based continual learning method, dubbed as Adaptive Group Sparsity based Continual Learning (AGS-CL), using two group sparsity-based penalties. Our method selectively employs the two penalties when learning each node based its the importance, which is adaptively updated after learning each new task. By utilizing the proximal gradient descent method for learning, the exact sparsity and freezing of the model is guaranteed, and thus, the learner can explicitly control the model capacity as the learning continues. Furthermore, as a critical detail, we re-initialize the weights associated with unimportant nodes after learning each task in order to prevent the negative transfer that causes the catastrophic forgetting and facilitate efficient learning of new tasks. Throughout the extensive experimental results, we show that our AGS-CL uses much less additional memory space for storing the regularization parameters, and it significantly outperforms several state-of-the-art baselines on representative continual learning benchmarks for both supervised and reinforcement learning tasks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "2112569591",
                    "name": "Hongjoon Ahn"
                },
                {
                    "authorId": "34352481",
                    "name": "Sungmin Cha"
                },
                {
                    "authorId": "4842965",
                    "name": "Taesup Moon"
                }
            ]
        },
        {
            "paperId": "77e07d72228488cbc96413d03060bbd5bf343d2f",
            "title": "MEGA",
            "abstract": "Complex relationships among entities can be modeled very effectively using hypergraphs. Hypergraphs model real-world data by allowing a hyperedge to include two or more entities. Clustering of hypergraphs enables us to group the similar entities together. While most existing algorithms solely consider the connection structure of a hypergraph to solve the clustering problem, we can boost the clustering performance by considering various features associated with the entities as well as auxiliary relationships among the entities. Also, we can further improve the clustering performance if some of the labels are known and we incorporate them into a clustering model. In this paper, we propose a semi-supervised clustering framework for hypergraphs that is able to easily incorporate not only multiple relationships among the entities but also multiple attributes and content of the entities from diverse sources. Furthermore, by showing the close relationship between the hypergraph normalized cut and the weighted kernel K-Means, we also develop an efficient multilevel hypergraph clustering method which provides a good initialization with our semi-supervised multi-view clustering algorithm. Experimental results show that our algorithm is effective in detecting the ground-truth clusters and significantly outperforms other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34826931",
                    "name": "Joyce Jiyoung Whang"
                },
                {
                    "authorId": "35528532",
                    "name": "Rundong Du"
                },
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "2110855835",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "1731900",
                    "name": "Barry L. Drake"
                },
                {
                    "authorId": "47362571",
                    "name": "Qingqing Liu"
                },
                {
                    "authorId": "151210225",
                    "name": "Seonggoo Kang"
                },
                {
                    "authorId": "1685928",
                    "name": "Haesun Park"
                }
            ]
        },
        {
            "paperId": "8786200b06fe7349b08ff2e2f373392a9d01f529",
            "title": "Adaptive Group Sparse Regularization for Continual Learning",
            "abstract": "We propose a novel regularization-based continual learning method, dubbed as Adaptive Group Sparsity based Continual Learning (AGS-CL), using two group sparsity-based penalties. Our method selectively employs the two penalties when learning each node based its the importance, which is adaptively updated after learning each new task. By utilizing the proximal gradient descent method for learning, the exact sparsity and freezing of the model is guaranteed, and thus, the learner can explicitly control the model capacity as the learning continues. Furthermore, as a critical detail, we re-initialize the weights associated with unimportant nodes after learning each task in order to prevent the negative transfer that causes the catastrophic forgetting and facilitate ef\ufb01cient learning of new tasks. Throughout the extensive experimental results, we show that our AGS-CL uses much less additional memory space for storing the regularization parameters, and it signi\ufb01cantly outperforms several state-of-the-art baselines on representative continual learning benchmarks for both supervised and reinforcement learning tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47165273",
                    "name": "Sangwon Jung"
                },
                {
                    "authorId": "2112569591",
                    "name": "Hongjoon Ahn"
                },
                {
                    "authorId": "34352481",
                    "name": "Sungmin Cha"
                },
                {
                    "authorId": "4842965",
                    "name": "Taesup Moon"
                }
            ]
        }
    ]
}