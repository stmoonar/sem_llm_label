{
    "authorId": "2939508",
    "papers": [
        {
            "paperId": "8e75a6a4cedc40fa31d3899d3936e57800405dc8",
            "title": "An Experimental Consideration on Gait Spoofing",
            "abstract": ": Deep learning technologies have improved the performance of biometric systems as well as increased the risk of spoo\ufb01ng attacks against them. So far, lots of spoo\ufb01ng and anti-spoo\ufb01ng methods were proposed for face and voice. However, for gait, there are a limited number of studies focusing on the spoo\ufb01ng risk. To examine the executability of gait spoo\ufb01ng, in this paper, we attempt to generate a sequence of fake gait silhouettes that mimics a certain target person\u2019s walking style only from his/her single photo. A feature vector extracted from such a single photo does not have full information about the target person\u2019s gait characteristics. To complement the information, we update the extracted feature so that it simultaneously contains various people\u2019s characteristics like a wolf sample. Inspired by a wolf sample or also called \u201cmaster\u201d sample, which can simultaneously pass two or more veri\ufb01cation systems like a master key, we call the proposed process \u201cmasterization\u201d. After the masterization, we decode its resultant feature vector to a gait silhouette sequence. In our experiment, the gait recognition accuracy with the generated fake silhouette sequences is increased from 69% to 78% by the masterization, which indicates an unignorable risk of gait spoo\ufb01ng.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055976450",
                    "name": "Yuki Hirose"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                }
            ]
        },
        {
            "paperId": "c4e8f95fb9b67c7889b9b8301bf3e5dbc45c30d7",
            "title": "Social IoT Approach to Cyber Defense of a Deep-Learning-Based Recognition System in Front of Media Clones Generated by Model Inversion Attack",
            "abstract": "Model inversion attack (MIA) is a cyber threat with an increasing alert even for deep-learning-based recognition systems (DLRSs). By targeting a DLRS under a scenario of attacker access to the model structure and parameters, MIA generates a data clone for a certain targeted class label. To avoid the possible threats of such MIA-generated data clones, this research work proposes a social IoT approach to a collaborative cyber-defense among the online recognition systems (RSs) sharing the targeted class label. Since, the generation of an MIA-clone is by targeting an RS model and using its structure, parameters, and class labels output scores in an iterative optimization process, the generated clone is partially inherent to the targeted model. Thus, it is expected for an MIA-clone to show a different performance on a secondary RS wherein the same targeted class label is included. It is because, in the MIA generation of the clone, not only the targeted class label but also other class labels, and model parameters and structure affect the process, while the second model has just the targeted class label in common with the target model. Deploying the Social Internet of Recognition Systems (SIoRS), the proposed technique utilizes a collaborative recognition by SIoRC which plays the role of a complementary recognition besides the targeted RS. The recognition output by the targeted RS is further verified by the SIoRS complementary recognition result. To avoid the MIA-targeted data clones, the verification of recognition is by the log-likelihood ratio test between the targeted RS and the SIoRS complementary recognition confidence scores. The proposed technique is evaluated by statistical analysis on deep face RSs in 10000 Monte Carlo runs for each of the conventional, dc-generative adversarial network (GAN) and $\\alpha $ -GAN integrated MIA techniques in targeting two different user identities. The $Z$ scores of the fitted normal distribution of the log-likelihood ratios indicate almost 100% detection rate of clones generated by conventional MIA and 95.23% and 86% of clones, respectively, generated by DC-GAN and $\\alpha $ -GAN integrated deep MIA techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145335882",
                    "name": "M. Khosravy"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "71212644",
                    "name": "N. Dey"
                },
                {
                    "authorId": "9439772",
                    "name": "R. Gonz\u00e1lez Crespo"
                },
                {
                    "authorId": "1397996912",
                    "name": "E. Herrera-Viedma"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                }
            ]
        },
        {
            "paperId": "1ee871674dd6ba58f667c29ac2e0657184d5c610",
            "title": "Anonymization of Human Gait in Video Based on Silhouette Deformation and Texture Transfer",
            "abstract": "These days, a lot of videos are uploaded onto web-based video sharing services such as YouTube. These videos can be freely accessed from all over the world. On the other hand, they often contain the appearance of walking private people, which could be identified by silhouette-based gait recognition techniques rapidly developed in recent years. This causes a serious privacy issue. To avoid it, this paper proposes a method for anonymizing the appearance of walking people, namely human gait, in video. In the proposed method, we first crop human regions from all frames in an input video and binarize them to get their silhouettes. Next, we slightly deform the silhouettes from the aspects of static body shape and dynamic walking rhythm so that the person in the input video cannot be correctly identified by gait recognition techniques. After that, the textures of the original human regions are transferred onto the deformed silhouettes. We achieve this by a displacement field-based approach, which is training-free and thus robust to a variety of clothes. Finally, the anonymized human regions with the transferred textures are filled back into the input video. In the results of our experiments, we successfully degraded the accuracy of CNN-based gait recognition systems from 100% to 1.57% in the lowest case without yielding serious distortion in the appearance of the human regions, which demonstrated the effectiveness of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055976450",
                    "name": "Yuki Hirose"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                }
            ]
        },
        {
            "paperId": "60e5e6ab0bc46587beed9b40db0692adc5ec93f4",
            "title": "MMArt-ACM 2022: 5th Joint Workshop on Multimedia Artworks Analysis and Attractiveness Computing in Multimedia",
            "abstract": "In addition to classical art types like paintings and sculptures, new types of artworks emerge following the advancement of deep learning, social platforms, media capturing devices, and media processing tools. Large volumes of machine-/user-generated content or professionally-edited content are shared and disseminated on the Web. Novel multimedia artworks, therefore, emerge rapidly in the era of social media and big data. The ever-increasing amount of illustrations/comics/animations on this platform gives rise to challenges of automatic classification, indexing, and retrieval that have been studied widely in other areas but not necessarily for this emerging type of artwork. In addition to objective entities like objects, events, and scenes, studies of cognitive properties emerge. Among various kinds of computational cognitive analyses, we focus on attractiveness analysis in this workshop. The topics of the accepted papers cover the affective analysis of texts, images, and music. The actual MMArt-ACM 2022 Proceedings are available at: https://dl.acm.org/citation.cfm?id=3512730.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "2172608617",
                    "name": "Anita Hu"
                },
                {
                    "authorId": "2790557",
                    "name": "Kensuke Tobitani"
                }
            ]
        },
        {
            "paperId": "9fe662ce29929f3ffa482d6d88d17482717574a7",
            "title": "Model Inversion Attack by Integration of Deep Generative Models: Privacy-Sensitive Face Generation From a Face Recognition System",
            "abstract": "Cybersecurity in front of attacks to a face recognition system is an emerging issue in the cloud era, especially due to its strong bonds with the privacy of the users registered to the system. A possible attack is the model inversion attack (MIA) which aims to reveal the identity of a targeted user by generating the most proper datapoint input to the system with maximum corresponding confidence score at the output. The generated data of a registered user can be maliciously used as a serious invasion of the user privacy. In literature, MIA processes are categorized into white-box and black-box scenarios which are respectively with and without information about the system structure, parameters, and partially about the users. This research work assumes the MIA under semi-white box scenario of availability of system model structure and parameters but not any user data information, and verifies it as a severe threat even for a deep-learning-based face recognition system despite its complex structure and the diversity of registered user data. The alert state is promoted by Deep MIA which is the integration of deep generative models in MIA, and <inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula>-GAN integrated MIA-initilized by a face based seed (<inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula>-GAN-MIA-FS) is proposed. As a novel MIA search strategy, a pre-trained deep generative model with capability of generating a face image from a random feature vector is used for narrowing down the image search space to the feature vectors space, which has much lower dimensions. This allows the MIA process to efficiently search for a low-dimensional feature vector whose corresponding face image maximizes the confidence score. We have experimentally evaluated the proposed method by two objective criteria and three subjective criteria in comparison to <inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula>-GAN-integrated MIA initialized with a random seed (<inline-formula> <tex-math notation=\"LaTeX\">$\\alpha $ </tex-math></inline-formula>-GAN-MIA-RS), DCGAN-integrated MIA (DCGAN-MIA), and the conventional MIA. The evaluation results approve the efficiency and superiority of the proposed technique in generating natural looking face clones with high recognizability as the targeted users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145335882",
                    "name": "M. Khosravy"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2055976450",
                    "name": "Yuki Hirose"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                }
            ]
        },
        {
            "paperId": "b668b42dcbd4bdf0a175e905ca2203945ceffeee",
            "title": "When AI Facilitates Trust Violation: An Ethical Report on Deep Model Inversion Privacy Attack",
            "abstract": "This article raises concerns about the considerable capability of artificial intelligence in boosting privacy violations and motivates the necessity of AI ethics. Despite all AI advantages like the efficiency and accuracy of recent techniques, and its positive effects on our life quality, when it comes to security and privacy the facilities with AI empowerment have been met with anxiousness and distrust in the public. This article is an ethical view of the AI role in a recent work wherein AI considerably facilitates privacy violation in a gray-box attack on a deep face recognition system. While the user identities' data is fully secured and just the recognition deep model is accessible, AI-boosted model inversion reveals the faces of the identities via high-accuracy generated clones. An analytical and subjective evaluation of the generated face clones with and without AI integration in model inversion illustrates a big gap from non-clear noise face clones to crystal clear face clones which efficiently reveal the identity of a targeted user by their high-level naturalness, similarity, and recognizability amongst many users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145335882",
                    "name": "M. Khosravy"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2803384",
                    "name": "Antoine Pasquali"
                },
                {
                    "authorId": "2233499001",
                    "name": "Olaf Witkowski"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                }
            ]
        },
        {
            "paperId": "0468c0b32d25a4a649113fff810cadc09b8bae2f",
            "title": "Generation and Detection of Media Clones",
            "abstract": "SUMMARY With the spread of high-performance sensors and social network services (SNS) and the remarkable advances in machine learning technologies, fake media such as fake videos, spoofed voices, and fake reviews that are generated using high-quality learning data and are very close to the real thing are causing serious social problems. We launched a research project, the Media Clone (MC) project, to protect receivers of replicas of real media called media clones (MCs) skillfully fabricated by means of media processing technologies. Our aim is to achieve a communication system that can defend against MC attacks and help ensure safe and reliable communication. This paper describes the results of research in two of the \ufb01ve themes in the MC project: 1) veri\ufb01cation of the capability of generating various types of media clones such as audio, visual, and text derived from fake information and 2) realization of a protection shield for media clones\u2019 attacks by recognizing them.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1678602",
                    "name": "I. Echizen"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                },
                {
                    "authorId": "1716857",
                    "name": "J. Yamagishi"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1789677",
                    "name": "Yuta Nakashima"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2782498",
                    "name": "Kazuhiro Kono"
                },
                {
                    "authorId": "2339200",
                    "name": "Fuming Fang"
                },
                {
                    "authorId": "1969310",
                    "name": "Seiko Myojin"
                },
                {
                    "authorId": "2066470393",
                    "name": "Zhenzhong Kuang"
                },
                {
                    "authorId": "2110490893",
                    "name": "H. Nguyen"
                },
                {
                    "authorId": "9328269",
                    "name": "Ngoc-Dung T. Tieu"
                }
            ]
        },
        {
            "paperId": "1a42e0f296d08a0a90e9deffa99ef98e88bd9a2b",
            "title": "Semi-Supervised Temporal Segmentation of Manufacturing Work Video by Automatically Building a Hierarchical Tree of Category Labels",
            "abstract": "Nowadays, many industrial companies visually record workers\u2019 activities for the purposes of streamlining their work processes. However, since untrimmed raw videos are hard to use, it is desired to automatically divide the videos into segments and recognize which kind of operation is performed on each segment. This task is called temporal video segmentation. We propose a method for achieving it, particularly targeting videos of manufacturing work with a specialized vehicle such as a hydraulic excavator. To make the performance of temporal video segmentation high, it is quite essential to extract good visual features from input videos. This can be hardly achieved by unsupervised methods, whereas supervised methods have another drawback that collecting a sufficient amount of training data is difficult due to its labor-intensiveness. To overcome these drawbacks, the proposed method employs a semi-supervised approach. We assume that a set of weakly-labeled videos whose frames only sparsely have a category label are given as input, where the labeled frames are used as training data to train a desirable feature extractor. Under this assumption, the proposed method first divides the input videos into short segments called primitive segments having the fixed length and then clusters them using visual features extracted by the above feature extractor. To achieve higher performance, we also use a hierarchical tree of the category labels and recursively perform the above process at each branch in the tree, where the tree is automatically built by the proposed method. In our experiments, we achieved a segmentation performance of 0.947 on the F-measure, even when only 1.25% of all the frames in the input videos are labeled.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                },
                {
                    "authorId": "2091601395",
                    "name": "Kensuke Fujii"
                },
                {
                    "authorId": "2091859425",
                    "name": "Satoki Matsumura"
                },
                {
                    "authorId": "146637500",
                    "name": "Eiji Nabata"
                }
            ]
        },
        {
            "paperId": "68cc067bdc41cec709c3bb9e2733f6d1b27f9872",
            "title": "Model Inversion Attack against a Face Recognition System in a Black-Box Setting",
            "abstract": "A DNN-based face recognition system implicitly has the information of facial characteristics of the individuals registered in it. The information could be maliciously revealed or stolen by a model inversion attack (MIA), which causes a serious privacy issue. To clarify how much the threat of MIA is real, methods to perform MIA against a face recognition system have been studied in recent years. Theoretically, MIA is formulated as a problem of finding the best image that maximizes the recognition score outputted by a target recognition system. This can be achieved by a gradient descent technique if the target system is a white box whose network structure and parameters are known, as assumed in the most existing methods. However, this assumption is not necessarily realistic. Unlike the existing methods, in this paper, we propose an MIA method that can be carried out against a black-box system. To enable the proposed method to generate natural-looking face images, we first introduce a deep face generator that generates a face image from a random feature vector, by which MIA is re-defined as a problem of finding the best feature vector instead of the best image. The proposed method solve this problem by a gradient descent technique, where we numerically approximates the gradient of the recognition score by perturbing the current feature vector several times. Our experimental results demonstrate that the proposed method can generate natural-looking face images successfully containing personal facial characteristics, whose performance is comparable to the white-box-oriented existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152658355",
                    "name": "Shunsuke Yoshimura"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                }
            ]
        },
        {
            "paperId": "68e237415a04da1b91fdf39f4ad2af5057e3269f",
            "title": "Preventing Fake Information Generation Against Media Clone Attacks",
            "abstract": "SUMMARY Fake media has been spreading due to remarkable ad- vances in media processing and machine leaning technologies, causing serious problems in society. We are conducting a research project called Media Clone aimed at developing methods for protecting people from fake but skillfully fabricated replicas of real media called media clones. Such media can be created from fake information about a speci\ufb01c person. Our goal is to develop a trusted communication system that can defend against attacks of media clones. This paper describes some research results of the Media Clone project, in particular, various methods for protecting personal information against generating fake information. We focus on 1) fake information generation in the physical world, 2) anonymization and abstraction in the cyber world, and 3) modeling of media clone attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1727647",
                    "name": "N. Babaguchi"
                },
                {
                    "authorId": "1678602",
                    "name": "I. Echizen"
                },
                {
                    "authorId": "1716857",
                    "name": "J. Yamagishi"
                },
                {
                    "authorId": "2939508",
                    "name": "Naoko Nitta"
                },
                {
                    "authorId": "1789677",
                    "name": "Yuta Nakashima"
                },
                {
                    "authorId": "2110773634",
                    "name": "Kazuaki Nakamura"
                },
                {
                    "authorId": "2782498",
                    "name": "Kazuhiro Kono"
                },
                {
                    "authorId": "2339200",
                    "name": "Fuming Fang"
                },
                {
                    "authorId": "1969310",
                    "name": "Seiko Myojin"
                },
                {
                    "authorId": "2066470393",
                    "name": "Zhenzhong Kuang"
                },
                {
                    "authorId": "2110490893",
                    "name": "H. Nguyen"
                },
                {
                    "authorId": "9328269",
                    "name": "Ngoc-Dung T. Tieu"
                }
            ]
        }
    ]
}