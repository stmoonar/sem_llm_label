{
    "authorId": "15368955",
    "papers": [
        {
            "paperId": "04f87c405cf8814dcd9185e6ef9751086a4b916c",
            "title": "EMO2-DETR: Efficient-Matching Oriented Object Detection With Transformers",
            "abstract": "Object detection in remote sensing is a challenging task due to the arbitrary orientations of objects and the vast variation in the number of objects within a single image. For instance, one image may contain hundreds of small vehicles, while another may only have a single football field. Recently, DEtection TRansformer (DETR) and its variants have achieved great success in object detection by setting a fixed number of object queries and using bipartite graph matching for one-to-one label assignment. However, we have observed that bipartite graph matching can result in relative redundancy of object queries when the number of objects changes dramatically in an image. This relative redundancy can cause two problems: slower convergence during training and redundant bounding boxes during inference. To analyze the aforementioned problems, we proposed a metric, redundancy of object query (ROQ), to quantitatively analyze the redundancy. Through experiments, we discovered that the reason for the two issues is the difficulty in distinguishing between high-quality negative samples and positive samples. In this article, we proposed efficient-matching oriented object detection with transformers (EMO2-DETR) consisting of three dedicated components to address the aforementioned issues. Specifically, reassign bipartite graph matching (RBGM) is proposed to extract high-quality negative samples from the negative samples. And ignored sample predicted head (ISPH) is proposed to predict high-quality negative samples. Then, reassigned Hungarian loss is used to better involve high-quality negative samples in the update of model parameters. Extensive experiments on DOTAv1 and DOTAv1.5 datasets demonstrated that our proposed method achieves the competitive results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2320516419",
                    "name": "Chenrui Li"
                },
                {
                    "authorId": "122009001",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "2d19ea2b8099ca0c104ad05e38a169b500f1295a",
            "title": "Focal Cosine Metric and Adaptive Attention Module for Remote Sensing Scene Classification With Siamese Convolutional Neural Networks",
            "abstract": "Convolutional neural networks (CNNs) have been widely used in remote sensing (RS) scene classification tasks due to their remarkable feature representation and inference capability. The complexity of RS images not only brings the challenges of high inter-class similarity and large intra-class diversity, but also introduces the problem that category-relevant regions are insufficiently prominent in feature extraction. Siamese CNNs with feature similarity measurement are chosen in some applications to overcome the former issue, but most ignore the randomness of input sample pairs. This makes the Siamese CNNs not focus enough on challenging samples, which limits the training efficiency. We propose the focal cosine metric (FCM) block that combines the cosine similarity metric and the threshold control to achieve sample selection, thereby completing network learning more efficiently. FCM only permits the misclassified focal samples to participate in similarity measurement based on Siamese CNN. It flexibly mitigates the misclassification caused by the high inter-class similarity and large intra-class diversity. Moreover, the adaptive attention (AA) module is designed to stress the pivotal target regions and assist in the similarity measurement of Siamese CNN. This is realized by adaptively assigning high weights to key targets with learnable guided vectors. It enables the model to focus on the details of intra-class similarities or inter-class differences in sample pairs, and thus reduces the difficulty of model optimization. Encouraging experimental results on three public data sets demonstrate the effectiveness of the novel Siamese CNN-based method with FCM and AA and show its superiority compared to other state-of-the-art scene classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "49528487",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                },
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                }
            ]
        },
        {
            "paperId": "58815d046026f2996e38a23b1cd47b7c1e75195e",
            "title": "Siamese Network Ensembles for Hyperspectral Target Detection with Pseudo Data Generation",
            "abstract": "Target detection in hyperspectral images (HSIs) aims to distinguish target pixels from the background using knowledge gleaned from prior spectra. Most traditional methods are based on certain assumptions and utilize handcrafted classifiers. These simple models and assumptions\u2019 failure restrict the detection performance under complicated background interference. Recently, based on the convolutional networks, many supervised deep learning detectors have outperformed the traditional methods. However, these methods suffer from unstable detection, heavy computation burden, and optimization difficulty. This paper proposes a Siamese fully connected based target detector (SFCTD) that comprises nonlinear feature extraction modules (NFEMs) and cosine distance classifiers. Two NFEMs, which extract discriminative spectral features of input spectra-pairs, are based on fully connected layers for efficient computing and share the parameters to ease the optimization. To solve the few samples problem, we propose a pseudo data generation method based on the linear mixed model and the assumption that background pixels are dominant in HSIs. For mitigating the impact of stochastic suboptimal initialization, we parallelly optimize several Siamese detectors with small computation burdens and aggregate them as ensembles in the inference time. The network ensembles outperform every detector in terms of stability and achieve an outstanding balance between background suppression and detection rate. Experiments on multiple data sets demonstrate that the proposed detector is superior to the state-of-the-art detectors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2260820793",
                    "name": "Pengyu Wang"
                }
            ]
        },
        {
            "paperId": "6c3b4dc6e54e99f629954b10bc2c6194f15c500c",
            "title": "Batch processing and data streaming Fourier-based convolutional neural network accelerator",
            "abstract": "Decision-making through artificial neural networks with minimal latency is critical for numerous applications such as navigation, tracking, and real-time machine action systems. This requires machine learning hardware to process multidimensional data at high throughput. Unfortunately, handling convolution operations, the primary computational tool for data classification tasks, obeys challenging runtime complexity scaling laws. However, homomorphically implementing the convolution theorem in a Fourier optics display light processor can achieve a non-iterative O(1) runtime complexity for data inputs beyond 1,000 \u00d7 1,000 large matrices. Following this approach, here we demonstrate data streaming multi-kernel image batching using a Fourier Convolutional Neural Network (FCNN) accelerator. We show image batch processing of large-scale matrices as 2 million dot product multiplications performed by a digital light processing module in the Fourier domain. Furthermore, we further parallelize this optical FCNN system by exploiting multiple spatially parallel diffraction orders, achieving a 98x throughput improvement over state-of-the-art FCNN accelerators. A comprehensive discussion of the practical challenges associated with working at the edge of system capabilities highlights the problem of crosstalk and resolution scaling laws in the Fourier domain. Accelerating convolution by exploiting massive parallelism in display technology brings non-Van Neumann-based machine learning acceleration.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "1945230198",
                    "name": "Shurui Li"
                },
                {
                    "authorId": "2147107765",
                    "name": "Russell L. T. Schwartz"
                },
                {
                    "authorId": "1405208974",
                    "name": "Maria Solyanik-Gorgone"
                },
                {
                    "authorId": "50533784",
                    "name": "M. Miscuglio"
                },
                {
                    "authorId": "2007720077",
                    "name": "Puneet Gupta"
                },
                {
                    "authorId": "1995822",
                    "name": "V. Sorger"
                }
            ]
        },
        {
            "paperId": "8fc2548ae8f31a148b29281e359ea3151d2115ed",
            "title": "Triplet-Metric-Guided Multi-Scale Attention for Remote Sensing Image Scene Classification with a Convolutional Neural Network",
            "abstract": "Remote sensing image scene classification (RSISC) plays a vital role in remote sensing applications. Recent methods based on convolutional neural networks (CNNs) have driven the development of RSISC. However, these approaches are not adequate considering the contributions of different features to the global decision. In this paper, triplet-metric-guided multi-scale attention (TMGMA) is proposed to enhance task-related salient features and suppress task-unrelated salient and redundant features. Firstly, we design the multi-scale attention module (MAM) guided by multi-scale feature maps to adaptively emphasize salient features and simultaneously fuse multi-scale and contextual information. Secondly, to capture task-related salient features, we use the triplet metric (TM) to optimize the learning of MAM under the constraint that the distance of the negative pair is supposed to be larger than the distance of the positive pair. Notably, the MAM and TM collaboration can enforce learning a more discriminative model. As such, our TMGMA can avoid the classification confusion caused by only using the attention mechanism and the excessive correction of features caused by only using the metric learning. Extensive experiments demonstrate that our TMGMA outperforms the ResNet50 baseline by 0.47% on the UC Merced, 1.46% on the AID, and 1.55% on the NWPU-RESISC45 dataset, respectively, and achieves performance that is competitive with other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "ce6de5bee4aa5b47db468cfbcbbd0340b84e2cde",
            "title": "Probability Differential-Based Class Label Noise Purification for Object Detection in Aerial Images",
            "abstract": "Modern object detection for aerial images requires numerous annotated data. However, the data annotation process inevitably introduces noise due to the bird\u2019s eye view perspective of aerial images and the professional requirements of annotations. While recent noise-robust object detection methods achieved great success, the noise side effect during the early training stage was still a problem. As demonstrated in this letter, noise during the early training stage will cumulatively affect the final performance. Based on the abovementioned observations, we propose a training strategy called correction maximization training to purify the noisy annotations and then train models. In particular, we design a novel noise filter called the probability differential (PD) to identify and revise wrong labels. After purification, we train the detector with the revised dataset. Compared with the existing works, the proposed method could be adapted in most modern object detectors (e.g., Faster RCNN and RetinaNet) and requires little hyperparameter tuning across different datasets and models. Extensive experiments on DOTA show that the proposed method achieves the state-of-the-art results with both symmetric and asymmetric noise.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "26abbf5e20ddbd072bbad0aeb2e01b5c693a1ad8",
            "title": "High\u2010Throughput Multichannel Parallelized Diffraction Convolutional Neural Network Accelerator",
            "abstract": "Convolutional neural networks are paramount in image and signal processing, and are responsible for the majority of image recognition power consumption today, concentrated mainly in convolution computations. With convolution operations being computationally intensive, next\u2010generation hardware accelerators need to offer parallelization and high efficiency. Diffractive optics offers the promise of low\u2010latency, highly parallel convolution operations. However, thus far parallelism is only partially harvested, thereby significantly underdelivering in comparison to its throughput potential. Here, a parallelized operation high\u2010throughput Fourier optic convolutional accelerator is demonstrated. For the first time, simultaneous processing of multiple kernels in Fourier domain enabled by optical diffraction orders is achieved alongside input parallelism. The proposed approach can offer \u2248100\u00d7 speedup over the previous generation optical diffraction\u2010based processor and 10\u00d7 speedup over other state\u2010of\u2010the\u2010art optical Fourier classifiers.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "1945230198",
                    "name": "Shurui Li"
                },
                {
                    "authorId": "2147107765",
                    "name": "Russell L. T. Schwartz"
                },
                {
                    "authorId": "1405208974",
                    "name": "Maria Solyanik-Gorgone"
                },
                {
                    "authorId": "50533784",
                    "name": "M. Miscuglio"
                },
                {
                    "authorId": "2007720077",
                    "name": "Puneet Gupta"
                },
                {
                    "authorId": "1995822",
                    "name": "V. Sorger"
                }
            ]
        },
        {
            "paperId": "4fa547b7ccfaac5f3aebd7b8957d1ad699a892c2",
            "title": "Massively-parallel Amplitude-Only Fourier Optical Convolutional Neural Network",
            "abstract": "Here we introduce a novel amplitude-only Fourier-optical processor paradigm and demonstrate a prototype system capable of processing large-scale ~(2,000x1,000) matrices in a single time-step and 100 microsecond-short latency, for accelerating machine-learning applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50533784",
                    "name": "M. Miscuglio"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "1945230198",
                    "name": "Shurui Li"
                },
                {
                    "authorId": "51174084",
                    "name": "J. George"
                },
                {
                    "authorId": "116123609",
                    "name": "R. Capanna"
                },
                {
                    "authorId": "1766287",
                    "name": "H. Dalir"
                },
                {
                    "authorId": "46179055",
                    "name": "P. Bardet"
                },
                {
                    "authorId": "2007720077",
                    "name": "Puneet Gupta"
                },
                {
                    "authorId": "1995822",
                    "name": "V. Sorger"
                }
            ]
        },
        {
            "paperId": "197e97d7235de08a2c6d5dfbf62c20c1edc660cd",
            "title": "Million-Channel Parallelism Fourier-Optic Convolutional Filter and Neural Network Processor",
            "abstract": "Here we report on a massively-parallel Fourier-optics convolutional processor accelerated 160\u00d7 over spatial-light-modulators using digital-mirror-display technology as input and kernel. Testing the system on MNIST and CIFAR-10 datasets shows 96% and 54% accuracy, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50533784",
                    "name": "M. Miscuglio"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "1945230198",
                    "name": "Shurui Li"
                },
                {
                    "authorId": "2216587442",
                    "name": "Jiaqi Gu"
                },
                {
                    "authorId": "7714843",
                    "name": "A. Babakhani"
                },
                {
                    "authorId": "2007720077",
                    "name": "Puneet Gupta"
                },
                {
                    "authorId": "1727458",
                    "name": "C. Wong"
                },
                {
                    "authorId": "1681705",
                    "name": "D. Pan"
                },
                {
                    "authorId": "35257502",
                    "name": "S. Bank"
                },
                {
                    "authorId": "1766287",
                    "name": "H. Dalir"
                },
                {
                    "authorId": "1995822",
                    "name": "V. Sorger"
                }
            ]
        },
        {
            "paperId": "1cc05bfac913780052de987ed1a8d0936af87346",
            "title": "Electro-Optical Hybrid Fourier Neural Network with Amplitude-Only Modulation",
            "abstract": "We demonstrate an electro-optical hybrid massively-parallel Fourier Neural Network exploiting Digital Micromirror Devices performing amplitude-only filtering, achieving ~10,000 2-Megapixel convolutions per second, preserving the inference accuracy level similar to phase-based approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "50533784",
                    "name": "M. Miscuglio"
                },
                {
                    "authorId": "1945230198",
                    "name": "Shurui Li"
                },
                {
                    "authorId": "51174084",
                    "name": "J. George"
                },
                {
                    "authorId": "2007720077",
                    "name": "Puneet Gupta"
                },
                {
                    "authorId": "1995822",
                    "name": "V. Sorger"
                }
            ]
        }
    ]
}