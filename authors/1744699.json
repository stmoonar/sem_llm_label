{
    "authorId": "1744699",
    "papers": [
        {
            "paperId": "2e1fe3a6efc1546833b8b2e1e9c1c3e471231cb7",
            "title": "Scalable Multi-view Clustering via Explicit Kernel Features Maps",
            "abstract": "A growing awareness of multi-view learning as an important component in data science and machine learning is a consequence of the increasing prevalence of multiple views in real-world applications, especially in the context of networks. In this paper we introduce a new scalability framework for multi-view subspace clustering. An efficient optimization strategy is proposed, leveraging kernel feature maps to reduce the computational burden while maintaining good clustering performance. The scalability of the algorithm means that it can be applied to large-scale datasets, including those with millions of data points, using a standard machine, in a few minutes. We conduct extensive experiments on real-world benchmark networks of various sizes in order to evaluate the performance of our algorithm against state-of-the-art multi-view subspace clustering methods and attributed-network multi-view approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454824",
                    "name": "Chakib Fettal"
                },
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "3ef3d1e4f44811eddbbb54d1ba9c1cbe9c4285fd",
            "title": "WSDM 2024 Workshop on Representation Learning & Clustering",
            "abstract": "Data clustering and representation learning play an indispensable role in data science. They are very useful to explore massive data in many fields, including information retrieval, natural language processing, bioinformatics, recommender systems, and computer vision. Despite their success, most existing clustering methods are severely challenged by the data generated by modern applications, which are typically high dimensional, noisy, heterogeneous, and sparse or even collected from multiple sources or represented by multiple views where each describes a perspective of the data. This has driven many researchers to investigate new effective clustering models to overcome these difficulties. One promising category of such models relies on representation learning. Indeed, learning a good data representation is crucial for clustering algorithms, and combining the two tasks is a common way of exploring this type of data. The idea is to embed the original data into a low dimensional latent space and then perform clustering on this new space. However, both tasks can be carried out sequentially or jointly. Many clustering algorithms, including deep learning versions, are based on these two modes of combining the two tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                },
                {
                    "authorId": "2911888",
                    "name": "Aghiles Salah"
                }
            ]
        },
        {
            "paperId": "6138e07aca20f2cb1819afac124014cb466c3f44",
            "title": "More Discriminative Sentence Embeddings via Semantic Graph Smoothing",
            "abstract": "This paper explores an empirical approach to learn more discriminantive sentence representations in an unsupervised fashion. Leveraging semantic graph smoothing, we enhance sentence embeddings obtained from pretrained models to improve results for the text clustering and classification tasks. Our method, validated on eight benchmarks, demonstrates consistent improvements, showcasing the potential of semantic graph smoothing in improving sentence embeddings for the supervised and unsupervised document categorization tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454824",
                    "name": "Chakib Fettal"
                },
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "663f1579eadc86497c2431f8e4bbcde9c7375e91",
            "title": "Boosting Subspace Co-Clustering via Bilateral Graph Convolution",
            "abstract": "Subspace clustering seeks to cluster high-dimensional data lying in a union of low-dimensional subspaces. It has achieved state-of-the-art results in image clustering, but text clustering of document-term matrices, has proved more impervious to advances with this approach, even though text data satisfies the assumptions of subspace clustering. We hypothesize that this is because such matrices are generally sparser and higher-dimensional than images. This, combined with the complexity of subspace clustering, which is generally cubic in the number of inputs, makes its use impractical in the context of text. Here we address these issues with a view to leveraging subspace clustering for networked (or not) text data. We first extend the concept of subspace clustering to co-clustering, which is suitable to deal with document-term matrices because of the interplay engendered between the document and word representations. We then address the sparsity problem through bilateral graph convolution, which promotes the grouping effect that has been credited for the effectiveness of some subspace clustering models. The proposed formulation results in an algorithm that is computationally/spatially efficient. Experiments using real-world datasets demonstrate the superior performance, in terms of document clustering, word clustering, and computational efficiency, of our proposed approach over the baselines and comparable methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454824",
                    "name": "Chakib Fettal"
                },
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "b117fd94ef00deaa11ffaad92eacbd904753d5cd",
            "title": "Graph Cuts with Arbitrary Size Constraints Through Optimal Transport",
            "abstract": "A common way of partitioning graphs is through minimum cuts. One drawback of classical minimum cut methods is that they tend to produce small groups, which is why more balanced variants such as normalized and ratio cuts have seen more success. However, we believe that with these variants, the balance constraints can be too restrictive for some applications like for clustering of imbalanced datasets, while not being restrictive enough for when searching for perfectly balanced partitions. Here, we propose a new graph cut algorithm for partitioning graphs under arbitrary size constraints. We formulate the graph cut problem as a Gromov-Wasserstein with a concave regularizer problem. We then propose to solve it using an accelerated proximal GD algorithm which guarantees global convergence to a critical point, results in sparse solutions and only incurs an additional ratio of $\\mathcal{O}(\\log(n))$ compared to the classical spectral clustering algorithm but was seen to be more efficient.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454824",
                    "name": "Chakib Fettal"
                },
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "4b4274ef53fd1163e1b75ccee63e6736d98d0b50",
            "title": "Is Anisotropy Truly Harmful? A Case Study on Text Clustering",
            "abstract": "In the last few years, several studies have been devoted to dissecting dense text representations in order to understand their effectiveness and further improve their quality. Particularly, the anisotropy of such representations has been observed, which means that the directions of the word vectors are not evenly distributed across the space but rather concentrated in a narrow cone. This has led to several attempts to counteract this phenomenon both on static and contextualized text representations. However, despite this effort, there is no established relationship between anisotropy and performance. In this paper, we aim to bridge this gap by investigating the impact of different transformations on both the isotropy and the performance in order to assess the true impact of anisotropy. To this end, we rely on the clustering task as a means of evaluating the ability of text representations to produce meaningful groups. Thereby, we empirically show a limited impact of anisotropy on the expressiveness of sentence representations both in terms of directions and L2 closeness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076239433",
                    "name": "Mira Ait-Saada"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "a087f9632da1b24428bffaff70f8a43bb853ac1e",
            "title": "Simultaneous Linear Multi-view Attributed Graph Representation Learning and Clustering",
            "abstract": "Over the last few years, various multi-view graph clustering methods have shown promising performances. However, we argue that these methods can have limitations. In particular, they are often unnecessarily complex, leading to scalability problems that make them prohibitive for most real-world graph applications. Furthermore, many of them can handle only specific types of multi-view graphs. Another limitation is that the process of learning graph representations is separated from the clustering process, and in some cases these methods do not even learn a graph representation, which severely restricts their flexibility and usefulness. In this paper we propose a simple yet effective linear model that addresses the dual tasks of multi-view attributed graph representation learning and clustering in a unified framework. The model starts by performing a first-order neighborhood smoothing step for the different individual views, then gives each one a weight corresponding to its importance. Finally, an iterative process of simultaneous clustering and representation learning is performed w.r.t. the importance of each view, yielding a consensus embedding and partition of the graph. Our model is generic and can deal with any type of multi-view graph. Finally, we show through extensive experimentation that this simple model consistently achieves competitive performances w.r.t. state-of-the-art multi-view attributed graph clustering models, while at the same time having training times that are shorter, in some cases by orders of magnitude.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454824",
                    "name": "Chakib Fettal"
                },
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "b2d5c6b55d03dea1273462a0c8e5a8305da4173b",
            "title": "Scalable Attributed-Graph Subspace Clustering",
            "abstract": "Over recent years, graph convolutional networks emerged as powerful node clustering methods and have set state of the art results for this task. In this paper, we argue that some of these methods are unnecessarily complex and propose a node clustering model that is more scalable while being more effective. The proposed model uses Laplacian smoothing to learn an initial representation of the graph before applying an efficient self-expressive subspace clustering procedure.\nThis is performed via learning a factored coefficient matrix. These factors are then embedded into a new feature space in such a way as to generate a valid affinity matrix (symmetric and non-negative) on which an implicit spectral clustering algorithm is performed. \nExperiments on several real-world attributed datasets demonstrate the cost-effective nature of our method with respect to the state of the art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454824",
                    "name": "Chakib Fettal"
                },
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "d42f66f55cd58336074b20a0fb8d9c77629b75ef",
            "title": "Unsupervised Anomaly Detection in Multi-Topic Short-Text Corpora",
            "abstract": "Unsupervised anomaly detection seeks to identify deviant data samples in a dataset without using labels and constitutes a challenging task, particularly when the majority class is heterogeneous. This paper addresses this topic for textual data and aims to determine whether a text sample is an outlier within a potentially multi-topic corpus. To this end, it is crucial to grasp the semantic aspects of words, particularly when dealing with short texts, since it is difficult to syntactically discriminate data samples based only on a few words. Thereby we make use of word embeddings to represent each sample by a dense vector, efficiently capturing the underlying semantics. Then, we rely on the Mixture Model approach to detect which samples deviate the most from the underlying distributions of the corpus. Experiments carried out on real datasets show the effectiveness of the proposed approach in comparison to state-of-the-art techniques both in terms of performance and time efficiency, especially when more than one topic is present in the corpus.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076239433",
                    "name": "Mira Ait-Saada"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        },
        {
            "paperId": "15fb75e67c19dda41b960e28d859d23aad88b3da",
            "title": "Power Attributed Graph Embedding and Clustering",
            "abstract": "Representation learning is a central problem of attributed networks (ANs) data analysis in a variety of fields. Given an attributed graph, the objectives are to obtain a representation of nodes and a partition of the set of nodes. Usually, these two objectives are pursued separately via two tasks that are performed sequentially, and any benefit that may be obtained by performing them simultaneously is lost. In this brief, we propose a power-attributed graph embedding and clustering (PAGEC for short) in which the two tasks, embedding and clustering, are considered together. To jointly encode data affinity between node links and attributes, we use a new powered proximity matrix. We formulate a new matrix decomposition model to obtain node representation and node clustering simultaneously. Theoretical analysis shows the close connections between the new proximity matrix and the random walk theory on a graph. Experimental results demonstrate that the PAGEC algorithm performs better, in terms of clustering and embedding, than state-of-the-art algorithms including deep learning methods designed for similar tasks in relation to attributed network datasets with different characteristics.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1931111",
                    "name": "Lazhar Labiod"
                },
                {
                    "authorId": "1744699",
                    "name": "M. Nadif"
                }
            ]
        }
    ]
}