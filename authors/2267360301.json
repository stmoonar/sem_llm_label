{
    "authorId": "2267360301",
    "papers": [
        {
            "paperId": "10fd2f9b47da6c769dedd81125564ca21acc01c3",
            "title": "One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for Continual Learning",
            "abstract": "In real-world continual learning (CL) scenarios, tasks often exhibit intricate and unpredictable semantic shifts, posing challenges for fixed prompt management strategies which are tailored to only handle semantic shifts of uniform degree (i.e., uniformly mild or uniformly abrupt). To address this limitation, we propose an adaptive prompting approach that effectively accommodates semantic shifts of varying degree where mild and abrupt shifts are mixed. AdaPromptCL employs the assign-and-refine semantic grouping mechanism that dynamically manages prompt groups in accordance with the semantic similarity between tasks, enhancing the quality of grouping through continuous refinement. Our experiment results demonstrate that AdaPromptCL outperforms existing prompting methods by up to 21.3%, especially in the benchmark datasets with diverse semantic shifts between tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2267504094",
                    "name": "Youngjun Lee"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "dcd40f8c4828e125591a74d9d00dff81f1bfe90d",
            "title": "Active Prompt Learning in Vision Language Models",
            "abstract": "Pre-trained Vision Language Models (VLMs) have demonstrated notable progress in various zero-shot tasks, such as classification and retrieval. Despite their performance, because improving performance on new tasks requires task-specific knowledge, their adaptation is essential. While labels are needed for the adaptation, acquiring them is typically expensive. To overcome this challenge, active learning, a method of achieving a high performance by obtaining labels for a small number of samples from experts, has been studied. Active learning primarily focuses on selecting unlabeled samples for labeling and leveraging them to train models. In this study, we pose the question, \u201chow can the pre-trained VLMs be adapted under the active learning framework?\u201d In response to this inquiry, we observe that (1) simply applying a conventional active learning framework to pre-trained VLMs even may degrade performance compared to random selection because of the class imbalance in labeling candidates, and (2) the knowledge of VLMs can provide hints for achieving the balance before labeling. Based on these observations, we devise a novel active learning framework for VLMs, denoted as PCB. To assess the effectiveness of our approach, we conduct experiments on seven different real-world datasets, and the results demonstrate that PCB surpasses conventional active learning and random sampling methods. Code is available at https://github.com/kaist-dmlab/pcb.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "2276211268",
                    "name": "Sumyeong Ahn"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "eaab62c1865f2359e98117f063e1190d16ec602a",
            "title": "Adaptive Shortcut Debiasing for Online Continual Learning",
            "abstract": "We propose a novel framework DropTop that suppresses the shortcut bias in online continual learning (OCL) while being adaptive to the varying degree of the shortcut bias incurred by continuously changing environment. By the observed high-attention property of the shortcut bias, highly-activated features are considered candidates for debiasing. More importantly, resolving the limitation of the online environment where prior knowledge and auxiliary data are not ready, two novel techniques---feature map fusion and adaptive intensity shifting---enable us to automatically determine the appropriate level and proportion of the candidate shortcut features to be dropped. Extensive experiments on five benchmark datasets demonstrate that, when combined with various OCL algorithms, DropTop increases the average accuracy by up to 10.4% and decreases the forgetting by up to 63.2%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        }
    ]
}