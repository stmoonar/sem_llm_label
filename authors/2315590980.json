{
    "authorId": "2315590980",
    "papers": [
        {
            "paperId": "5211323ce4cd698148df05894285de892f814438",
            "title": "Causality-Guided Stepwise Intervention and Reweighting for Remote Sensing Image Semantic Segmentation",
            "abstract": "Semantic segmentation is one of the most significant tasks in remote sensing (RS) image interpretation, which focuses on learning global and local information to infer the semantic label of each pixel. Previous studies devise encoder-decoder structured deep learning (DL) models to extract global and local features from RS images with the help of pretraining knowledge to predict semantic labels. However, due to the common heterogeneity between the data for pretraining and the data to be semantically segmented, these models fail to learn general features appropriate to RS datasets. In this article, we propose a novel formulation of the above problem from a causal perspective, where the learned features from pretrained models result from causality and spurious correlations, and only the former carries general information that remains invariant regardless of the exact task and dataset. Based on the above formulation, we propose stepwise intervention and reweighting (SIR). It can reduce the confounding bias introduced by the pretraining knowledge and improve the model\u2019s ability to learn general features, making semantic segmentation of RS images benefit more from pretraining. Besides, we conduct a detailed theoretical analysis of our methods and conduct extensive experiments on two widely used public RS datasets. Experimental results demonstrate that applying SIR to encoder-decoder semantic segmentation models achieves performance improvements, proving the effectiveness and application values of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2307899405",
                    "name": "Shuting Shi"
                },
                {
                    "authorId": "2313166010",
                    "name": "Baohong Li"
                },
                {
                    "authorId": "2242975429",
                    "name": "Laifu Zhang"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "47403279",
                    "name": "Sensen Wu"
                },
                {
                    "authorId": "2264624505",
                    "name": "Tian Feng"
                },
                {
                    "authorId": "2276022692",
                    "name": "Yiming Yan"
                },
                {
                    "authorId": "2287564081",
                    "name": "Zhenhong Du"
                }
            ]
        },
        {
            "paperId": "be7412715a5d5f8fec76579d44be3dd918c00a0d",
            "title": "Out-of-Distribution Generalization With Causal Feature Separation",
            "abstract": "Driven by empirical risk minimization, machine learning algorithm tends to exploit subtle statistical correlations existing in the training environment for prediction, while the spurious correlations are unstable across environments, leading to poor generalization performance. Accordingly, the problem of the Out-of-distribution (OOD) generalization aims to exploit an invariant/stable relationship between features and outcomes that generalizes well on all possible environments. To address the spurious correlation induced by the selection bias, in this article, we propose a novel Clique-based Causal Feature Separation (CCFS) algorithm by explicitly incorporating the causal structure to identify causal features of outcome for OOD generalization. Specifically, the proposed CCFS algorithm identifies the largest clique in the learned causal skeleton. Theoretically, we guarantee that either the largest clique or the rest of the causal skeleton is exactly the set of all causal features of the outcome. Finally, we separate the causal features from the non-causal ones with a sample-reweighting decorrelator for OOD prediction. Extensive experiments validate the effectiveness of the proposed CCFS method on both causal feature identification and OOD generalization tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1491260152",
                    "name": "Haotian Wang"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "2156125124",
                    "name": "Long Lan"
                },
                {
                    "authorId": "2238165141",
                    "name": "Zige Wang"
                },
                {
                    "authorId": "2238161415",
                    "name": "Wanrong Huang"
                },
                {
                    "authorId": "2181654877",
                    "name": "Fei Wu"
                },
                {
                    "authorId": "2120811655",
                    "name": "Wenjing Yang"
                }
            ]
        },
        {
            "paperId": "c52772edbbbc408fe864716a74b08e4e076c0966",
            "title": "Causal Distillation for Alleviating Performance Heterogeneity in Recommender Systems",
            "abstract": "Recommendation performance usually exhibits a long-tail distribution over users \u2014 a small portion of head users enjoy much more accurate recommendation services than the others. We reveal two sources of this performance heterogeneity problem: the uneven distribution of historical interactions (a natural source); and the biased training of recommender models (a model source). As addressing this problem cannot sacrifice the overall performance, a wise choice is to eliminate the model bias while maintaining the natural heterogeneity. The key to debiased training lies in eliminating the effect of confounders that influence both the user's historical behaviors and the next behavior. The emerging causal recommendation methods achieve this by modeling the causal effect between user behaviors, however potentially neglect unobserved confounders (e.g., friend suggestions) that are hard to measure in practice. To address unobserved confounders, we resort to the front-door adjustment (FDA) in causal theory and propose a causal multi-teacher distillation framework (CausalD). FDA requires proper mediators in order to estimate the causal effects of historical behaviors on the next behavior. To achieve this, we equip CausalD with multiple heterogeneous recommendation models to model the mediator distribution. Then, the causal effect estimated by FDA is the expectation of recommendation prediction over the mediator distribution and the prior distribution of historical behaviors, which is technically achieved by multi-teacher ensemble. To pursue efficient inference, CausalD further distills multiple teachers into one student model to directly infer the causal effect for making recommendations. We instantiate CausalD on two representative models, DeepFM and DIN, and conduct extensive experiments on three real-world datasets, which validate the superiority of CausalD over state-of-the-art methods. Through in-depth analysis, we find that CausalD largely improves the performance of tail users, reduces the performance heterogeneity, and enhances the overall performance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1739188006",
                    "name": "Shengyu Zhang"
                },
                {
                    "authorId": "2142708915",
                    "name": "Ziqi Jiang"
                },
                {
                    "authorId": "2110069725",
                    "name": "Jiangchao Yao"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "2187385241",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2222777391",
                    "name": "Shuo Li"
                },
                {
                    "authorId": "2145952806",
                    "name": "Hongxia Yang"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                },
                {
                    "authorId": "2110922423",
                    "name": "Fei Wu"
                }
            ]
        },
        {
            "paperId": "1364e3c277e5833299f73b618c021b38510207cd",
            "title": "ML-LJP: Multi-Law Aware Legal Judgment Prediction",
            "abstract": "Legal judgment prediction (LJP) is a significant task in legal intelligence, which aims to assist the judges and determine the judgment result based on the case's fact description. The judgment result consists of law articles, charge, and prison term. The law articles serve as the basis for the charge and the prison term, which can be divided into two types, named as charge-related law article and term-related law article, respectively. Recently, many methods have been proposed and made tremendous progress in LJP. However, the existing methods only focus on the prediction of the charge-related law articles, ignoring the term-related law articles (e.g., laws about lenient treatment), which limits the performance in the prison term prediction. In this paper, following the actual legal process, we expand the law article prediction as a multi-label classification task that includes both the charge-related law articles and term-related law articles and propose a novel multi-law aware LJP (ML-LJP) method to improve the performance of LJP. Given the case's fact description, firstly, the label (e.g., law article and charge) definitions in the Code of Law are used to transform the representation of the fact into several label-specific representations and make the prediction of the law articles and the charge. To distinguish the similar content of different label definitions, contrastive learning is conducted in the training. Then, a graph attention network (GAT) is applied to learn the interactions among the multiple law articles for the prediction of the prison term. Since numbers (e.g., amount of theft and weight of drugs) are important for LJP but often ignored by conventional encoders, we design a corresponding number representation method to locate and better represent these effective numbers. Extensive experiments on real-world dataset show that our method achieves the best results compared to the state-of-the-art models, especially in the task of prison term prediction where ML-LJP achieves a 10.07% relative improvement over the best baseline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2198035543",
                    "name": "Yifei Liu"
                },
                {
                    "authorId": "2164710806",
                    "name": "Yiquan Wu"
                },
                {
                    "authorId": "51146612",
                    "name": "Yating Zhang"
                },
                {
                    "authorId": "2060934",
                    "name": "Changlong Sun"
                },
                {
                    "authorId": "1776903",
                    "name": "Weiming Lu"
                },
                {
                    "authorId": "93192602",
                    "name": "Fei Wu"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                }
            ]
        },
        {
            "paperId": "15e0f067483a256135429670b5750fd039f88bfe",
            "title": "Causal Inspired Trustworthy Machine Learning",
            "abstract": "In causality-based trustworthy machine learning, finding mechanisms from data-driven correlation analysis to causal inference and constructing a machine learning framework from correlation-driven to causality-driven are two significant challenges. To address these challenges, we propose a series of innovations, including data-driven causal inference mechanisms, causality-inspired interpretable and stable learning frameworks, causality-based generalizable graph neural network learning frameworks, and other fundamental theories and key technologies. To further support the development of the field, we make the corresponding codes and resources public in the open-source community, including the big data causal inference framework based on instrumental variables (https://github.com/causal-machine-learning-lab/mliv) and the large-scale graph neural network computing and edge-cloud collaborative learning platform (https://github.com/luoxi-model/luoxi_models).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                }
            ]
        },
        {
            "paperId": "9e8be1cabc8198f593d7d7921792cd2bff21c5e1",
            "title": "Treatment Effect Estimation with Adjustment Feature Selection",
            "abstract": "In causal inference, it is common to select a subset of observed covariates, named the adjustment features, to be adjusted for estimating the treatment effect. For real-world applications, the abundant covariates are usually observed, which contain extra variables partially correlating to the treatment (treatment-only variables, e.g., instrumental variables) or the outcome (outcome-only variables, e.g., precision variables) besides the confounders (variables that affect both the treatment and outcome). In principle, unbiased treatment effect estimation is achieved once the adjustment features contain all the confounders. However, the performance of empirical estimations varies a lot with different extra variables. To solve this issue, variable separation/selection for treatment effect estimation has received growing attention when the extra variables contain instrumental variables and precision variables. In this paper, assuming no mediator variables exist, we consider a more general setting by allowing for the existence of post-treatment and post-outcome variables rather than instrumental and precision variables in observed covariates. Our target is to separate the treatment-only variables from the adjustment features. To this end, we establish a metric named Optimal Adjustment Features(OAF), which empirically measures the asymptotic variance of the estimation. Theoretically, we show that our OAF metric is minimized if and only if adjustment features consist of the confounders and outcome-only variables, i.e., the treatment-only variables are perfectly separated. As optimizing the OAF metric is a combinatorial optimization problem, we introduce Reinforcement Learning (RL) and adopt the policy gradient to search for the optimal adjustment set. Empirical results on both synthetic and real-world datasets demonstrate that (a) our method successfully searches the optimal adjustment features and (b) the searched adjustment features achieve a more precise estimation of the treatment effect.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1491260152",
                    "name": "Haotian Wang"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "2047998054",
                    "name": "Haoang Chi"
                },
                {
                    "authorId": "2142427516",
                    "name": "Longqi Yang"
                },
                {
                    "authorId": "2141549468",
                    "name": "Mingyang Geng"
                },
                {
                    "authorId": "3441469",
                    "name": "Wanrong Huang"
                },
                {
                    "authorId": "2120811655",
                    "name": "Wenjing Yang"
                }
            ]
        },
        {
            "paperId": "9ebd68585193e67976bc92c9489290796fe4d93b",
            "title": "Personalized Latent Structure Learning for Recommendation",
            "abstract": "In recommender systems, users\u2019 behavior data are driven by the interactions of user-item latent factors. To improve recommendation effectiveness and robustness, recent advances focus on latent factor disentanglement via variational inference. Despite significant progress, uncovering the underlying interactions, i.e., dependencies of latent factors, remains largely neglected by the literature. To bridge the gap, we investigate the joint disentanglement of user-item latent factors and the dependencies between them, namely latent structure learning. We propose to analyze the problem from the causal perspective, where a latent structure should ideally reproduce observational interaction data, and satisfy the structure acyclicity and dependency constraints, i.e., causal prerequisites. We further identify the recommendation-specific challenges for latent structure learning, i.e., the subjective nature of users\u2019 minds and the inaccessibility of private/sensitive user factors causing universally learned latent structure to be suboptimal for individuals. To address these challenges, we propose the personalized latent structure learning framework for recommendation, namely PlanRec, which incorporates 1) differentiable Reconstruction, Dependency, and Acyclicity regularizations to satisfy the causal prerequisites; 2) Personalized Structure Learning (PSL) which personalizes the universally learned dependencies through probabilistic modeling; and 3) uncertainty estimation which explicitly measures the uncertainty of structure personalization, and adaptively balances personalization and shared knowledge for different users. We conduct extensive experiments on two public benchmark datasets from MovieLens and Amazon, and a large-scale industrial dataset from Alipay. Empirical studies validate that PlanRec discovers effective shared/personalized structures, and successfully balances shared knowledge and personalization via rational uncertainty estimation.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739188006",
                    "name": "Shengyu Zhang"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "2108125912",
                    "name": "Wenqiao Zhang"
                },
                {
                    "authorId": "2187385241",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2145952806",
                    "name": "Hongxia Yang"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                },
                {
                    "authorId": "2110922423",
                    "name": "Fei Wu"
                }
            ]
        },
        {
            "paperId": "d10f34cb9b42efb8bbad3365c682700102262de4",
            "title": "Who Should Be Given Incentives? Counterfactual Optimal Treatment Regimes Learning for Recommendation",
            "abstract": "Effective personalized incentives can improve user experience and increase platform revenue, resulting in a win-win situation between users and e-commerce companies. Previous studies have used uplift modeling methods to estimate the conditional average treatment effects of users' incentives, and then placed the incentives by maximizing the sum of estimated treatment effects under a limited budget. However, some users will always buy whether incentives are given or not, and they will actively collect and use incentives if provided, named \"Always Buyers\". Identifying and predicting these \"Always Buyers\" and reducing incentive delivery to them can lead to a more rational incentive allocation. In this paper, we first divide users into five strata from an individual counterfactual perspective, and reveal the failure of previous uplift modeling methods to identify and predict the \"Always Buyers\". Then, we propose principled counterfactual identification and estimation methods and prove their unbiasedness. We further propose a counterfactual entire-space multi-task learning approach to accurately perform personalized incentive policy learning with a limited budget. We also theoretically derive a lower bound on the reward of the learned policy. Extensive experiments are conducted on three real-world datasets with two common incentive scenarios, and the results demonstrate the effectiveness of the proposed approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051689367",
                    "name": "Haoxuan Li"
                },
                {
                    "authorId": "2051688235",
                    "name": "Chunyuan Zheng"
                },
                {
                    "authorId": "2153093673",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "100576986",
                    "name": "Yue Liu"
                },
                {
                    "authorId": "2135616913",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "e86b9e7e5178c3895382a55501d330c9c7cf845a",
            "title": "Graph Neural Network with Two Uplift Estimators for Label-Scarcity Individual Uplift Modeling",
            "abstract": "Uplift modeling aims to measure the incremental effect, which we call uplift, of a strategy or action on the users from randomized experiments or observational data. Most existing uplift methods only use individual data, which are usually not informative enough to capture the unobserved and complex hidden factors regarding the uplift. Furthermore, uplift modeling scenario usually has scarce labeled data, especially for the treatment group, which also poses a great challenge for model training. Considering that the neighbors\u2019 features and the social relationships are very informative to characterize a user\u2019s uplift, we propose a graph neural network-based framework with two uplift estimators, called GNUM, to learn from the social graph for uplift estimation. Specifically, we design the first estimator based on a class-transformed target. The estimator is general for all types of outcomes, and is able to comprehensively model the treatment and control group data together to approach the uplift. When the outcome is discrete, we further design the other uplift estimator based on our defined partial labels, which is able to utilize more labeled data from both the treatment and control groups, to further alleviate the label scarcity problem. Comprehensive experiments on a public dataset and two industrial datasets show a superior performance of our proposed framework over state-of-the-art methods under various evaluation metrics. The proposed algorithms have been deployed online to serve real-world uplift estimation scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51139354",
                    "name": "Dingyuan Zhu"
                },
                {
                    "authorId": "2057764",
                    "name": "Daixin Wang"
                },
                {
                    "authorId": "2019870682",
                    "name": "Zhiqiang Zhang"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "36124320",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2182514010",
                    "name": "Yulin Kang"
                },
                {
                    "authorId": "2151548887",
                    "name": "Jun Zhou"
                }
            ]
        },
        {
            "paperId": "00102916233d568656659b8263efb6d8fb4a46d6",
            "title": "Learning Individual Treatment Effects under Heterogeneous Interference in Networks",
            "abstract": "Estimating individual treatment effects in networked observational data is a crucial and increasingly recognized problem. One major challenge of this problem is violating the Stable Unit Treatment Value Assumption (SUTVA), which posits that a unit\u2019s outcome is independent of others\u2019 treatment assignments. However, in network data, a unit\u2019s outcome is influenced not only by its treatment (i.e., direct effect) but also by the treatments of others (i.e., spillover effect) since the presence of interference. Moreover, the interference from other units is always heterogeneous (e.g., friends with similar interests have a different influence than those with different interests). In this paper, we focus on the problem of estimating individual treatment effects (including direct effect and spillover effect) under heterogeneous interference in networks. To address this problem, we propose a novel Dual Weighting Regression (DWR) algorithm by simultaneously learning attention weights to capture the heterogeneous interference from neighbors and sample weights to eliminate the complex confounding bias in networks. We formulate the learning process as a bi-level optimization problem. Theoretically, we give a generalization error bound for the expected estimation error of the individual treatment effects. Extensive experiments on four benchmark datasets demonstrate that the proposed DWR algorithm outperforms the state-of-the-art methods in estimating individual treatment effects under heterogeneous network interference.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2117928326",
                    "name": "Ziyu Zhao"
                },
                {
                    "authorId": "2307116968",
                    "name": "Yuqi Bai"
                },
                {
                    "authorId": "50824401",
                    "name": "Ruoxuan Xiong"
                },
                {
                    "authorId": "2242974688",
                    "name": "Qingyu Cao"
                },
                {
                    "authorId": "2307136081",
                    "name": "Chao Ma"
                },
                {
                    "authorId": "2307080305",
                    "name": "Ning Jiang"
                },
                {
                    "authorId": "93192602",
                    "name": "Fei Wu"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                }
            ]
        }
    ]
}