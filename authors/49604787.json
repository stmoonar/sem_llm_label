{
    "authorId": "49604787",
    "papers": [
        {
            "paperId": "7633e4a61e1870e65975339af283f3c5da88048e",
            "title": "CentralBark Image Dataset and Tree Species Classification Using Deep Learning",
            "abstract": "The task of tree species classification through deep learning has been challenging for the forestry community, and the lack of standardized datasets has hindered further progress. Our work presents a solution in the form of a large bark image dataset called CentralBark, which enhances the deep learning-based tree species classification. Additionally, we have laid out an efficient and repeatable data collection protocol to assist future works in an organized manner. The dataset contains images of 25 central hardwood and Appalachian region tree species, with over 19,000 images of varying diameters, light, and moisture conditions. We tested 25 species: elm, oak, American basswood, American beech, American elm, American sycamore, bitternut hickory, black cherry, black locust, black oak, black walnut, eastern cottonwood, hackberry, honey locust, northern red oak, Ohio buckeye, Osage-orange, pignut hickory, sassafras, shagbark hickory silver maple, slippery elm, sugar maple, sweetgum, white ash, white oak, and yellow poplar. Our experiment involved testing three different models to assess the feasibility of species classification using unaltered and uncropped images during the species-classification training process. We achieved an overall accuracy of 83.21% using the EfficientNet-b3 model, which was the best of the three models (EfficientNet-b3, ResNet-50, and MobileNet-V3-small), and an average accuracy of 80.23%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265410837",
                    "name": "Charles C. Warner"
                },
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "2656982",
                    "name": "R. Gazo"
                },
                {
                    "authorId": "1988973449",
                    "name": "Bedrich Benes"
                },
                {
                    "authorId": "2299007844",
                    "name": "Nicole Kong"
                },
                {
                    "authorId": "2260706429",
                    "name": "Songlin Fei"
                }
            ]
        },
        {
            "paperId": "ee210be856f8f782308808775e3dbd64a3e3df45",
            "title": "International Workshop on Multimodal Learning - 2023 Theme: Multimodal Learning with Foundation Models",
            "abstract": "The recent advancements in machine learning and artificial intelligence (particularly foundation models such as BERT, GPT-3, T5, ResNet, etc.) have demonstrated remarkable capabilities and driven significant revolutionary changes to the way we make inferences from complex data. These models represent a fundamental shift in the way data are approached and offer exciting new research directions and opportunities for multimodal learning and data fusion. Given the potential of foundation models to transform the field of multimodal learning, there is a need to bring together experts and researchers to discuss the latest developments in this area, exchange ideas, and identify key research questions and challenges that need to be addressed. By hosting this workshop, we aim to create a forum for researchers to share their insights and expertise on multimodal data fusion and learning using foundation models, and to explore potential new research directions and applications in the rapidly evolving field. We expect contributions from interdisciplinary researchers to study and model interactions between (but not limited to) modalities of language, graphs, time-series, vision, tabular data, sensors, and more. Our workshop will emphasize interdisciplinary work and aim at seeding cross-team collaborations around new tasks, datasets, and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159011228",
                    "name": "Yuan Ling"
                },
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "2190030596",
                    "name": "Shujing Dong"
                },
                {
                    "authorId": "100888797",
                    "name": "Yarong Feng"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "0960dcab3b1783d2fbe6f79b63fb3c66cfd3bfe5",
            "title": "Some Practice for Improving the Search Results of E-commerce",
            "abstract": "In the Amazon KDD Cup 2022, we aim to apply natural language processing methods to improve the quality of search results that can significantly enhance user experience and engagement with search engines for e-commerce. We discuss our practical solution for this competition, ranking 6th in task one, 2nd in task two, and 2nd in task 3. The code is available at https://github.com/wufanyou/KDD-Cup-2022-Amazon.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "40457423",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2656982",
                    "name": "R. Gazo"
                },
                {
                    "authorId": "2179884857",
                    "name": "Benes Bedrich"
                },
                {
                    "authorId": "2179886423",
                    "name": "Xiaobo Qu"
                }
            ]
        },
        {
            "paperId": "ccbffa4058440f86e7d2b497b36db7431fbfaf42",
            "title": "Behavior2vector: Embedding Users\u2019 Personalized Travel Behavior to Vector",
            "abstract": "We investigate how to effectively and efficiently embed users\u2019 personalized travel behaviors to vectors in this paper. Based on an example scenario of travel mode choice in intelligent transportation system, three data structures representing users\u2019 travel behaviors are defined, namely heterogeneous graph of users\u2019 travel behaviors, user travel behavior $k$ -partite graph, and personalized user travel behavior sentence set. This paper systematically analyzes the principle of existing methods and provides intuitions for the problem of learning travel behavior representation in intelligent transportation system. Then we propose the Behavior2vector, which is an improved method tailored for embedding users\u2019 personalized travel behaviors to vectors. In our experiments, we design a travel mode choice model based on machine learning, which uses both hand-crafted basic features and embedded vector features. We further quantify the impact of various factors on travel mode choice and use travel big data to test the hypothesis of traffic assignment models, e.g., travelers always choose the path with the shortest path. In addition, we also compared with the existing graph embedding methods and essentially discussed their advantages and disadvantages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1614036240",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "152605679",
                    "name": "Cheng Lyu"
                },
                {
                    "authorId": "2146074600",
                    "name": "Xin Liu"
                },
                {
                    "authorId": "37831178",
                    "name": "Zhiyuan Liu"
                }
            ]
        },
        {
            "paperId": "5c3e05ff7cf0b8303b1fffd79adf8c5a4f15d92a",
            "title": "TLab: Second Place Solution Towards Traffic4cast 2020 Competition",
            "abstract": "The problem of the effective prediction for large-scale spatio-temporal traffic data has long haunted researchers in the field of intelligent transportation. Limited by the quantity of data, citywide traffic state prediction was seldom achieved. Hence the complex urban transportation system of an entire city cannot be truly understood. Thanks to the efforts of organizations like IARAI, the massive open data provided by them has made the research possible. In our 2020 Competition solution, we further design multiple variants based on HR-NET and UNet. Through feature engineering, the hand-crafted features are input into the model in a form of channels. It is worth noting that, to learn the inherent attributes of geographical locations, we proposed a novel method called geo-embedding, which contributes to significant improvement in the accuracy of the model. In addition, we explored the influence of the selection of activation functions and optimizers, as well as tricks during model training on the model performance. In terms of prediction accuracy, our solution has won 2nd place in NeurIPS 2020, Traffic4cast Challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "1614036240",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "37831178",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "40065470",
                    "name": "X. Qu"
                },
                {
                    "authorId": "2656982",
                    "name": "R. Gazo"
                },
                {
                    "authorId": "30529905",
                    "name": "E. Haviarova"
                }
            ]
        },
        {
            "paperId": "61b73739a5f093b0d29a3d6058874ba3b7146385",
            "title": "TLab: Traffic Map Movie Forecasting Based on HR-NET",
            "abstract": "The problem of the effective prediction for large-scale spatio-temporal traffic data has long haunted researchers in the field of intelligent transportation. Limited by the quantity of data, citywide traffic state prediction was seldom achieved. Hence the complex urban transportation system of an entire city cannot be truly understood. Thanks to the efforts of organizations like IARAI, the massive open data provided by them has made the research possible. In our 2020 Competition solution, we further design multiple variants based on HR-NET and UNet. Through feature engineering, the hand-crafted features are input into the model in a form of channels. It is worth noting that, to learn the inherent attributes of geographical locations, we proposed a novel method called geo-embedding, which contributes to significant improvement in the accuracy of the model. In addition, we explored the influence of the selection of activation functions and optimizers, as well as tricks during model training on the model performance. In terms of prediction accuracy, our solution has won 2nd place in NeurIPS 2020, Traffic4cast Challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "1614036240",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "37831178",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "40065470",
                    "name": "X. Qu"
                },
                {
                    "authorId": "2656982",
                    "name": "R. Gazo"
                },
                {
                    "authorId": "30529905",
                    "name": "E. Haviarova"
                }
            ]
        },
        {
            "paperId": "dd7849a91667e85cee1368ba8ac5d9535ff5ab9d",
            "title": "Traffic4cast at NeurIPS 2020 ? yet more on theunreasonable effectiveness of gridded geo-spatial processes",
            "abstract": "The IARAI Tra\ufb03c4cast competition at NeurIPS 2019 showed that neural networks can successfully predict future tra\ufb03c conditions 15 minutes into the future on simply aggregated GPS probe data in time and space bins, thus interpreting the challenge of forecasting tra\ufb03c conditions as a movie completion task. U-nets proved to be the winning architecture then, demonstrating an ability to extract relevant features in the complex, real-world, geo-spatial process that is tra\ufb03c derived from a large data set. The IARAI Tra\ufb03c4cast challenge at NeurIPS 2020 build on the insights of the previous year and sought to both challenge some assumptions inherent in our 2019 competition design and explore how far this neural network technique can be pushed. We found that the prediction horizon can be extended successfully to 60 minutes into the future, that there is further evidence that tra\ufb03c depends more on recent dynamics than on the additional static or dynamic location speci\ufb01c data provided and that a reasonable starting point when exploring a general aggregated geo-spatial process in time and space is a U-net architecture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2058236577",
                    "name": "Michael Kopp"
                },
                {
                    "authorId": "29846943",
                    "name": "David P. Kreil"
                },
                {
                    "authorId": "2217478",
                    "name": "M. Neun"
                },
                {
                    "authorId": "2244591",
                    "name": "D. Jonietz"
                },
                {
                    "authorId": "2053800378",
                    "name": "Henry Martin"
                },
                {
                    "authorId": "3433525",
                    "name": "Pedro Herruzo"
                },
                {
                    "authorId": "1790005",
                    "name": "A. Gruca"
                },
                {
                    "authorId": "88593883",
                    "name": "A. Soleymani"
                },
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "1614036240",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "51091537",
                    "name": "Jingwei Xu"
                },
                {
                    "authorId": "2144231046",
                    "name": "Jianjin Zhang"
                },
                {
                    "authorId": "1413957680",
                    "name": "Jay Santokhi"
                },
                {
                    "authorId": "30857225",
                    "name": "Alabi Bojesomo"
                },
                {
                    "authorId": "1400624806",
                    "name": "H. Al-Marzouqi"
                },
                {
                    "authorId": "144015890",
                    "name": "P. Liatsis"
                },
                {
                    "authorId": "2030984252",
                    "name": "Pak Hay Kwok"
                },
                {
                    "authorId": "2061242676",
                    "name": "Qi Qi"
                },
                {
                    "authorId": "3308557",
                    "name": "Sepp Hochreiter"
                }
            ]
        },
        {
            "paperId": "2be46df1725992aaab6df9a643ac74e2f6923536",
            "title": "Building Effective Large-Scale Traffic State Prediction System: Traffic4cast Challenge Solution",
            "abstract": "How to build an effective large-scale traffic state prediction system is a challenging but highly valuable problem. This study focuses on the construction of an effective solution designed for spatio-temporal data to predict large-scale traffic state. Considering the large data size in Traffic4cast Challenge and our limited computational resources, we emphasize model design to achieve a relatively high prediction performance within acceptable running time. We adopt a structure similar to U-net and use a mask instead of spatial attention to address the data sparsity. Then, combined with the experience of time series prediction problem, we design a number of features, which are input into the model as different channels. Region cropping is used to decrease the difference between the size of the receptive field and the study area, and the models can be specially optimized for each sub-region. The fusion of interdisciplinary knowledge and experience is an emerging demand in classical traffic research. Several interdisciplinary studies we have been studying are also discussed in the Complementary Challenges. The source codes are available in this https URL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40457423",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "2425630",
                    "name": "B. Yu"
                },
                {
                    "authorId": "37831178",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2778556",
                    "name": "Jieping Ye"
                }
            ]
        },
        {
            "paperId": "a1c26e88361860376d7d75dabcb98943c66dd97b",
            "title": "Deep Learning for Lumer Identification: Poster Presentation",
            "abstract": "Current lumber scanners used in industrial wood manufacturing plants such as rough mills and flooring plants are used to measure, evaluate the quality, and optimize processing of solid wood. Because various wood species differ significantly in their color, grain structure, natural characteristics, defects and density, for their optimal performance, the scanner sensors often need to be calibrated for each individual species. When production switches from one species to the next, the scanner settings have to be manually changed to new species. In this study, we attempt to automate species recognition based on image recognition so that the manufacturing equipment can automatically adapt to species being processed, or even be able to process batches of mixed species. Recently, deep-learning techniques have demonstrated their usefulness in wood identification based on macroscopic cross-section images. Because such images are not easily obtained, this approach is not well suited for an industrial application. In this study, we used 4,736 transversal board face images of 11 hardwood species acquired by Microtec Goldeneye 300 Multi-Sensor Quality Scanner\u2122. Most images were 70 x 500 pixels and were used to train the Convolution Neural Network (CNN)-ResNet. We achieved accuracy of 84% when identifying a single testing image of 224x224 pixels and 94% when applying majority voting without any parameter tuning. The average processing time was 0.07 seconds on GPU and 0.64 seconds on CPU. We expect that on-going work to increase training sample size and parameter fine-tuning will further increase the accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "2656982",
                    "name": "R. Gazo"
                },
                {
                    "authorId": "1788393",
                    "name": "Bedrich Benes"
                },
                {
                    "authorId": "30529905",
                    "name": "E. Haviarova"
                }
            ]
        },
        {
            "paperId": "f717e2eea8542374060b9d982500b3df482d1fc3",
            "title": "Efficient Project Gradient Descent for Ensemble Adversarial Attack",
            "abstract": "Recent advances show that deep neural networks are not robust to deliberately crafted adversarial examples which many are generated by adding human imperceptible perturbation to clear input. Consider $l_2$ norms attacks, Project Gradient Descent (PGD) and the Carlini and Wagner (C\\&W) attacks are the two main methods, where PGD control max perturbation for adversarial examples while C\\&W approach treats perturbation as a regularization term optimized it with loss function together. If we carefully set parameters for any individual input, both methods become similar. In general, PGD attacks perform faster but obtains larger perturbation to find adversarial examples than the C\\&W when fixing the parameters for all inputs. In this report, we propose an efficient modified PGD method for attacking ensemble models by automatically changing ensemble weights and step size per iteration per input. This method generates smaller perturbation adversarial examples than PGD method while remains efficient as compared to C\\&W method. Our method won the first place in IJCAI19 Targeted Adversarial Attack competition.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "49604787",
                    "name": "Fanyou Wu"
                },
                {
                    "authorId": "2656982",
                    "name": "R. Gazo"
                },
                {
                    "authorId": "30529905",
                    "name": "E. Haviarova"
                },
                {
                    "authorId": "1788393",
                    "name": "Bedrich Benes"
                }
            ]
        }
    ]
}