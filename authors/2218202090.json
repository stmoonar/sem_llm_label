{
    "authorId": "2218202090",
    "papers": [
        {
            "paperId": "3a6e41b3bb092157ef6af2dd630e24d52471a789",
            "title": "CSRec: Rethinking Sequential Recommendation from A Causal Perspective",
            "abstract": "The essence of sequential recommender systems (RecSys) lies in understanding how users make decisions. Most existing approaches frame the task as sequential prediction based on users' historical purchase records. While effective in capturing users' natural preferences, this formulation falls short in accurately modeling actual recommendation scenarios, particularly in accounting for how unsuccessful recommendations influence future purchases. Furthermore, the impact of the RecSys itself on users' decisions has not been appropriately isolated and quantitatively analyzed. To address these challenges, we propose a novel formulation of sequential recommendation, termed Causal Sequential Recommendation (CSRec). Instead of predicting the next item in the sequence, CSRec aims to predict the probability of a recommended item's acceptance within a sequential context and backtrack how current decisions are made. Critically, CSRec facilitates the isolation of various factors that affect users' final decisions, especially the influence of the recommender system itself, thereby opening new avenues for the design of recommender systems. CSRec can be seamlessly integrated into existing methodologies. Experimental evaluations on both synthetic and real-world datasets demonstrate that the proposed implementation significantly improves upon state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2261901774",
                    "name": "Jiaxin Yuan"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2291078963",
                    "name": "Jingling Li"
                },
                {
                    "authorId": "2257407889",
                    "name": "Furong Huang"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "3a74772a6011675ce2bdc87100fffcf4d18f5907",
            "title": "Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey",
            "abstract": "Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2146666303",
                    "name": "Junda Wu"
                },
                {
                    "authorId": "2261901774",
                    "name": "Jiaxin Yuan"
                },
                {
                    "authorId": "2257361107",
                    "name": "Yifan Yang"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "52220309",
                    "name": "Fuxiao Liu"
                },
                {
                    "authorId": "2291143084",
                    "name": "Tianrui Guan"
                },
                {
                    "authorId": "2291313121",
                    "name": "Haoliang Wang"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2284680226",
                    "name": "Julian McAuley"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2257407889",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "4a402c7f4f2a5aaa1f8429be9dd19469d24b6d67",
            "title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications",
            "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become prevalent in social network communications. This has spurred increasing scholarly interest in exploring their attributes and functionalities. However, emoji-related research and application face two primary challenges. First, researchers typically rely on crowd-sourcing to annotate emojis in order to understand their sentiments, usage intentions, and semantic meanings. Second, subjective interpretations by users can often lead to misunderstandings of emojis and cause the communication barrier. Large Language Models (LLMs) have achieved significant success in various annotation tasks, with ChatGPT demonstrating expertise across multiple domains. In our study, we assess ChatGPT's effectiveness in handling previously annotated and downstream tasks. Our objective is to validate the hypothesis that ChatGPT can serve as a viable alternative to human annotators in emoji research and that its ability to explain emoji meanings can enhance clarity and transparency in online communications. Our findings indicate that ChatGPT has extensive knowledge of emojis. It is adept at elucidating the meaning of emojis across various application scenarios and demonstrates the potential to replace human annotators in a range of tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2282902714",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "2282572921",
                    "name": "Xuan Lu"
                },
                {
                    "authorId": "2282528493",
                    "name": "Ge Gao"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "6fa3544f42bc026ac684cf6c7a8cd50f59b3ee7d",
            "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
            "abstract": "Large language models (LLMs) have significantly advanced various natural language processing tasks, but deploying them remains computationally expensive. Knowledge distillation (KD) is a promising solution, enabling the transfer of capabilities from larger teacher LLMs to more compact student models. Particularly, sequence-level KD, which distills rationale-based reasoning processes instead of merely final outcomes, shows great potential in enhancing students' reasoning capabilities. However, current methods struggle with sequence level KD under long-tailed data distributions, adversely affecting generalization on sparsely represented domains. We introduce the Multi-Stage Balanced Distillation (BalDistill) framework, which iteratively balances training data within a fixed computational budget. By dynamically selecting representative head domain examples and synthesizing tail domain examples, BalDistill achieves state-of-the-art performance across diverse long-tailed datasets, enhancing both the efficiency and efficacy of the distilled models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2307469621",
                    "name": "Jing Zhu"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2282902714",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2268686199",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "c315de920f4538b5a27219fd6bbb3cd4b50659f5",
            "title": "From Adoption to Adaption: Tracing the Diffusion of New Emojis on Twitter",
            "abstract": "In the rapidly evolving landscape of social media, the introduction of new emojis in Unicode release versions presents a structured opportunity to explore digital language evolution. Analyzing a large dataset of sampled English tweets, we examine how newly released emojis gain traction and evolve in meaning. We find that community size of early adopters and emoji semantics are crucial in determining their popularity. Certain emojis experienced notable shifts in the meanings and sentiment associations during the diffusion process. Additionally, we propose a novel framework utilizing language models to extract words and pre-existing emojis with semantically similar contexts, which enhances interpretation of new emojis. The framework demonstrates its effectiveness in improving sentiment classification performance by substituting unknown new emojis with familiar ones. This study offers a new perspective in understanding how new language units are adopted, adapted, and integrated into the fabric of online communication.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2282572921",
                    "name": "Xuan Lu"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "f236d6f9c376dc453d7db11d15c8d9bc519adf65",
            "title": "Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from Imperfect Teacher Models in Low-Budget Scenarios",
            "abstract": "There is increasing interest in distilling task-specific knowledge from large language models (LLM) to smaller student models. Nonetheless, LLM distillation presents a dual challenge: 1) there is a high cost associated with querying the teacher LLM, such as GPT-4, for gathering an ample number of demonstrations; 2) the teacher LLM might provide imperfect outputs with a negative impact on the student's learning process. To enhance sample efficiency within resource-constrained, imperfect teacher scenarios, we propose a three-component framework leveraging three signal types. The first signal is the student's self-consistency (consistency of student multiple outputs), which is a proxy of the student's confidence. Specifically, we introduce a ``teaching assistant'' (TA) model to assess the uncertainty of both the student's and the teacher's outputs via confidence scoring, which serves as another two signals for student training. Furthermore, we propose a two-stage training schema to first warm up the student with a small proportion of data to better utilize student's signal. Experiments have shown the superiority of our proposed framework for four complex reasoning tasks. On average, our proposed two-stage framework brings a relative improvement of up to 20.79% compared to fine-tuning without any signals across datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "01efb3fd2d3ae4b5f4389c916c94f2c6d9c11b81",
            "title": "Explore Spurious Correlations at the Concept Level in Language Models for Text Classification",
            "abstract": "Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label distributions in training data or ICL exemplars. Previous research has primarily concentrated on word, phrase, and syntax features, neglecting the concept level, often due to the absence of concept labels and difficulty in identifying conceptual content in input texts. This paper introduces two main contributions. First, we employ ChatGPT to assign concept labels to texts, assessing concept bias in models during fine-tuning or ICL on test data. We find that LMs, when encountering spurious correlations between a concept and a label in training or prompts, resort to shortcuts for predictions. Second, we introduce a data rebalancing technique that incorporates ChatGPT-generated counterfactual data, thereby balancing label distribution and mitigating spurious correlations. Our method's efficacy, surpassing traditional token removal approaches, is validated through extensive testing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145926835",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2256993596",
                    "name": "Bang An"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2257407877",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "407797d283c18a4b224b5f9efb790aee9bc1ea29",
            "title": "Emoji Promotes Developer Participation and Issue Resolution on GitHub",
            "abstract": "Although remote working is increasingly adopted during the pandemic, many are concerned by the low-efficiency in the remote working. Missing in text-based communication are non-verbal cues such as facial expressions and body language, which hinders the effective communication and negatively impacts the work outcomes. Prevalent on social media platforms, emojis, as alternative non-verbal cues, are gaining popularity in the virtual workspaces well. In this paper, we study how emoji usage influences developer participation and issue resolution in virtual workspaces. To this end, we collect GitHub issues for a one-year period and apply causal inference techniques to measure the causal effect of emojis on the outcome of issues, controlling for confounders such as issue content, repository, and author information. We find that emojis can significantly reduce the resolution time of issues and attract more user participation. We also compare the heterogeneous effect on different types of issues. These \ufb01ndings deepen our understanding of the developer communities, and they provide design implications on how to facilitate interactions and broaden developer participation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145926835",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "1522975334",
                    "name": "Xuan Lu"
                },
                {
                    "authorId": "2084530289",
                    "name": "Ge Gao"
                },
                {
                    "authorId": "1743469",
                    "name": "Qiaozhu Mei"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "6ce4684a197465c4a77390bf2bd2486d51f3199e",
            "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across various tasks, including node classification and link prediction. Despite their remarkable success in various high-impact applications, we have identified three common pitfalls in message passing for link prediction, especially within industrial settings. Particularly, in prevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges (i.e., the edges being predicted) consistently exist as message passing edges in the graph during training. Consequently, this results in overfitting and distribution shift , both of which adversely impact the generalizability to test the target edges. Additionally, during test time, the failure to exclude the test target edges leads to implicit test leakage caused by neighborhood aggregation. In this paper, we analyze these three pitfalls and investigate the impact of including or excluding target edges on the performance of nodes with varying degrees during training and test phases. Our theoretical and empirical analysis demonstrates that low-degree nodes are more susceptible to these pitfalls. These pitfalls can have detrimental consequences when GNNs are implemented in production systems. To systematically address these pitfalls, we propose SpotTarget, an effective and efficient GNN training framework. During training, SpotTarget leverages our insight regarding low-degree nodes and excludes train target edges connected to at least one low-degree node. During test time, it emulates real-world scenarios of GNN usage in production and excludes all test target edges. Our experiments conducted on diverse real-world datasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up to a 15 \u00d7 increase in accuracy in sparse graphs. Furthermore, SpotTarget consistently and dramatically improves the performance for low-degree nodes in dense graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146272629",
                    "name": "Jing Zhu"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2282529091",
                    "name": "Shengyi Qian"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2282638703",
                    "name": "Xiang Song"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "bf12eb5959d7e2d365893a038805c623815033db",
            "title": "GFairHint: Improving Individual Fairness for Graph Neural Networks via Fairness Hint",
            "abstract": "Given the growing concerns about fairness in machine learning and the impressive performance of Graph Neural Networks (GNNs) on graph data learning, algorithmic fairness in GNNs has attracted significant attention. While many existing studies improve fairness at the group level, only a few works promote individual fairness, which renders similar outcomes for similar individuals. A desirable framework that promotes individual fairness should (1) balance between fairness and performance, (2) accommodate two commonly-used individual similarity measures (externally annotated and computed from input features), (3) generalize across various GNN models, and (4) be computationally efficient. Unfortunately, none of the prior work achieves all the desirables. In this work, we propose a novel method, GFairHint, which promotes individual fairness in GNNs and achieves all aforementioned desirables. GFairHint learns fairness representations through an auxiliary link prediction task, and then concatenates the representations with the learned node embeddings in original GNNs as a\"fairness hint\". Through extensive experimental investigations on five real-world graph datasets under three prevalent GNN models covering both individual similarity measures above, GFairHint achieves the best fairness results in almost all combinations of datasets with various backbone models, while generating comparable utility results, with much less computational cost compared to the previous state-of-the-art (SoTA) method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2145926835",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "49640821",
                    "name": "Bang An"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2117426487",
                    "name": "Furong Huang"
                }
            ]
        }
    ]
}