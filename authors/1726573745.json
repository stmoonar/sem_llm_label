{
    "authorId": "1726573745",
    "papers": [
        {
            "paperId": "2e6513f3333e7b4042587e79464755b9e72069d4",
            "title": "Graphlets over Time: A New Lens for Temporal Network Analysis",
            "abstract": "Graphs are widely used for modeling various types of interactions, such as email communications and online discussions. Many of such real-world graphs are temporal, and specifically, they grow over time with new nodes and edges. Counting the instances of each graphlet (i.e., an induced subgraph isomorphism class) has been successful in characterizing local structures of graphs, with many applications. While graphlets have been extended for temporal graphs, the extensions are designed for examining temporally-local subgraphs composed of edges with close arrival times, instead of long-term changes in local structures. In this paper, as a new lens for temporal graph analysis, we study the evolution of distributions of graphlet instances over time in real-world graphs at three different levels (graphs, nodes, and edges). At the graph level, we first discover that the evolution patterns are significantly different from those in random graphs. Then, we suggest a graphlet transition graph for measuring the similarity of the evolution patterns of graphs, and we find out a surprising similarity between the graphs from the same domain. At the node and edge levels, we demonstrate that the local structures around nodes and edges in their early stage provide a strong signal regarding their future importance. In particular, we significantly improve the predictability of the future importance of nodes and edges using the counts of the roles (a.k.a., orbits) that they take within graphlets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1726573745",
                    "name": "Deukryeol Yoon"
                },
                {
                    "authorId": "2109519939",
                    "name": "Dongjin Lee"
                },
                {
                    "authorId": "2047035591",
                    "name": "Minyoung Choe"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "38f99fed4d54270a208ce068169b8e1cdca59e2f",
            "title": "Region-Conditioned Orthogonal 3D U-Net for Weather4Cast Competition",
            "abstract": "The Weather4Cast competition (hosted by NeurIPS 2022) required competitors to predict super-resolution rain movies in various regions of Europe when low-resolution satellite contexts covering wider regions are given. In this paper, we show that a general baseline 3D U-Net can be significantly improved with region-conditioned layers as well as orthogonality regularizations on 1x1x1 convolutional layers. Additionally, we facilitate the generalization with a bag of training strategies: mixup data augmentation, self-distillation, and feature-wise linear modulation (FiLM). Presented modifications outperform the baseline algorithms (3D U-Net) by up to 19.54% with less than 1% additional parameters, which won the 4th place in the core test leaderboard.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1840081210",
                    "name": "Taehyeon Kim"
                },
                {
                    "authorId": "2160698854",
                    "name": "Shinhwan Kang"
                },
                {
                    "authorId": "40982080",
                    "name": "Hyeon-Cheol Shin"
                },
                {
                    "authorId": "1726573745",
                    "name": "Deukryeol Yoon"
                },
                {
                    "authorId": "70373622",
                    "name": "Seong-Hoon Eom"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "70509252",
                    "name": "Se-Young Yun"
                }
            ]
        },
        {
            "paperId": "ca09aa955f3e3eb5a651940ea0915f4b5c0100f0",
            "title": "Improvement of moving object detection accuracy on aerial imagery using sensor geometry",
            "abstract": "In this paper, we propose an efficient approach to improve moving object detection accuracy which is adaptive to changes in object size according to the altitude of the aircraft. The proposed algorithm can effectively detect moving objects with various pixel-scale from 8x8 to 100x100 in full-HD motion imagery. It consists of two stages which are detection and fusion. At the first stage, two algorithms are performed simultaneously: One is one-stage object detection network for detecting large objects, and the other is optical flow method for detecting small moving objects. In the second stage, results from the first stage are fused with a Ground Sample Distance (GSD) of imagery. We have conducted experiments using aerial imagery taken at a height between 130 meters and 400 meters. We evaluated the detection performance of our method in terms of precision, recall and normalized multiple object detection accuracy (N-MODA). Through experiments, we proved that the superiority of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1726573745",
                    "name": "Deukryeol Yoon"
                },
                {
                    "authorId": "1726528941",
                    "name": "W. Heo"
                },
                {
                    "authorId": "2109604871",
                    "name": "Seongjo Kim"
                },
                {
                    "authorId": "2058984781",
                    "name": "HyunSeong Sung"
                },
                {
                    "authorId": "6758070",
                    "name": "J. Jeong"
                }
            ]
        },
        {
            "paperId": "d153256befdc015884ff61667b7aca865146df91",
            "title": "Deep learning based moving object detection for oblique images without future frames",
            "abstract": "Moving object detection from UAV/aerial images is one of the essential tasks in surveillance systems. However, most of the works did not take account of the characteristics of oblique images. Also, many methods use future frames to detect moving objects in the current frame, which causes delayed detection. In this paper, we propose a deep learning based moving object detection method for oblique images without using future frames. Our network has a CNN (Convolutional Neural Network) architecture with the first and second layer containing sublayers with different kernel sizes. These sublayers play a role in detecting objects with different sizes or speeds, which is very important because objects that are closer to the camera look bigger and faster in oblique images. Our network takes the past five frames registered with respect to the last frame and produces a heatmap prediction for moving objects. Finally, we process a threshold processing to distinguish between object pixels and non-object pixels. We present the experimental results on our dataset. It contains about 15,000 images for training and about 6,000 images for testing with ground truth annotations for moving objects. We demonstrate that our method shows a better performance than some previous works.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1726528941",
                    "name": "W. Heo"
                },
                {
                    "authorId": "2109604871",
                    "name": "Seongjo Kim"
                },
                {
                    "authorId": "1726573745",
                    "name": "Deukryeol Yoon"
                },
                {
                    "authorId": "6758070",
                    "name": "J. Jeong"
                },
                {
                    "authorId": "2058984781",
                    "name": "HyunSeong Sung"
                }
            ]
        },
        {
            "paperId": "ea68b33e1f2733f453963e4ed852f3b9948aeab2",
            "title": "Height-adaptive vehicle detection in aerial imagery using metadata of EO sensor",
            "abstract": "Detecting targets in aerial imagery plays an important role in military reconnaissance and defense. One of the main difficulties in aerial imagery detection at a wide range of height is instability that detection is performed well only to the test data obtained at the same height range with the training data. To solve this problem, we utilize the sensor metadata to calculate GSD (Ground Sample Distance) and pixel size of the vehicle in our test images which are dependent on height. Based on this information, we estimate the optimal ratio for image preprocessing and adjust it to the test images. As a result, it detects the vehicles taken at a range of 100m to 300m with a higher F1-score than other approach which doesn\u2019t consider the metadata.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109604871",
                    "name": "Seongjo Kim"
                },
                {
                    "authorId": "1726528941",
                    "name": "W. Heo"
                },
                {
                    "authorId": "2058984781",
                    "name": "HyunSeong Sung"
                },
                {
                    "authorId": "1726573745",
                    "name": "Deukryeol Yoon"
                },
                {
                    "authorId": "6758070",
                    "name": "J. Jeong"
                }
            ]
        }
    ]
}