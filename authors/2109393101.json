{
    "authorId": "2109393101",
    "papers": [
        {
            "paperId": "03b98f1d5b872484469bbcee2a31a2c1ab126d05",
            "title": "AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake",
            "abstract": "Recently, deepfakes have raised severe concerns about the authenticity of online media. Prior works for deepfake detection have made many efforts to capture the intra-modal artifacts. However, deepfake videos in real-world scenarios often consist of a combination of audio and visual. In this paper, we propose an Audio-Visual Joint Learning for Detecting Deepfake (AVoiD-DF), which exploits audio-visual inconsistency for multi-modal forgery detection. Specifically, AVoiD-DF begins by embedding temporal-spatial information in Temporal-Spatial Encoder. A Multi-Modal Joint-Decoder is then designed to fuse multi-modal features and jointly learn inherent relationships. Afterward, a Cross-Modal Classifier is devised to detect manipulation with inter-modal and intra-modal disharmony. Since existing datasets for deepfake detection mainly focus on one modality and only cover a few forgery methods, we build a novel benchmark DefakeAVMiT for multi-modal deepfake detection. DefakeAVMiT contains sufficient visuals with corresponding audios, where any one of the modalities may be maliciously modified by multiple deepfake methods. The experimental results on DefakeAVMiT, FakeAVCeleb, and DFDC demonstrate that the AVoiD-DF outperforms many state-of-the-arts in deepfake detection. Our proposed method also yields superior generalization on various forgery techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120792078",
                    "name": "Wenyuan Yang"
                },
                {
                    "authorId": "2187449995",
                    "name": "Xiaoyu Zhou"
                },
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2212520433",
                    "name": "Bofei Guo"
                },
                {
                    "authorId": "36890675",
                    "name": "Zhongjie Ba"
                },
                {
                    "authorId": "2072878384",
                    "name": "Zhihua Xia"
                },
                {
                    "authorId": "2182161936",
                    "name": "Xiaochun Cao"
                },
                {
                    "authorId": "2139609863",
                    "name": "Kui Ren"
                }
            ]
        },
        {
            "paperId": "105669ec59a58fb2d4dd3021a984af33c227c5ab",
            "title": "Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs",
            "abstract": "Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at: https://github.com/CurryTang/Graph-LLM .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2145571830",
                    "name": "Hang Li"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "7621447",
                    "name": "Xiaochi Wei"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "19d13f6bd93ca46831bb39f6b66375c0e7868b22",
            "title": "Inter-frame Accelerate Attack against Video Interpolation Models",
            "abstract": "Deep learning based video frame interpolation (VIF) method, aiming to synthesis the intermediate frames to enhance video quality, have been highly developed in the past few years. This paper investigates the adversarial robustness of VIF models. We apply adversarial attacks to VIF models and find that the VIF models are very vulnerable to adversarial examples. To improve attack efficiency, we suggest to make full use of the property of video frame interpolation task. The intuition is that the gap between adjacent frames would be small, leading to the corresponding adversarial perturbations being similar as well. Then we propose a novel attack method named Inter-frame Accelerate Attack (IAA) that initializes the perturbation as the perturbation for the previous adjacent frame and reduces the number of attack iterations. It is shown that our method can improve attack efficiency greatly while achieving comparable attack performance with traditional methods. Besides, we also extend our method to video recognition models which are higher level vision tasks and achieves great attack efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216815244",
                    "name": "Junpei Liao"
                },
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2216787002",
                    "name": "Liang Yi"
                },
                {
                    "authorId": "2120791864",
                    "name": "Wenyuan Yang"
                },
                {
                    "authorId": "143905981",
                    "name": "Baoyuan Wu"
                },
                {
                    "authorId": "2149213706",
                    "name": "Xiaochun Cao"
                }
            ]
        },
        {
            "paperId": "204e98ca63240c58510cabba1980634426ad7116",
            "title": "AnchorFormer: Point Cloud Completion from Discriminative Nodes",
            "abstract": "Point cloud completion aims to recover the completed 3D shape of an object from its partial observation. A common strategy is to encode the observed points to a global feature vector and then predict the complete points through a generative process on this vector. Nevertheless, the results may suffer from the high-quality shape generation problem due to the fact that a global feature vector cannot sufficiently characterize diverse patterns in one object. In this paper, we present a new shape completion architecture, namely AnchorFormer, that innovatively leverages pattern-aware discriminative nodes, i.e., anchors, to dynamically capture regional information of objects. Technically, AnchorFormer models the regional discrimination by learning a set of anchors based on the point features of the input partial observation. Such anchors are scattered to both observed and unobserved locations through estimating particular offsets, and form sparse points together with the down-sampled points of the input observation. To reconstruct the finegrained object patterns, AnchorFormer further employs a modulation scheme to morph a canonical 2D grid at individual locations of the sparse points into a detailed 3D structure. Extensive experiments on the PCN, ShapeNet-55/34 and KITTI datasets quantitatively and qualitatively demonstrate the efficacy of AnchorFormer over the state-of-the-art point cloud completion approaches. Source code is available at https://github.com/chenzhik/AnchorFormer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "34779291",
                    "name": "Fuchen Long"
                },
                {
                    "authorId": "3430743",
                    "name": "Zhaofan Qiu"
                },
                {
                    "authorId": "145690248",
                    "name": "Ting Yao"
                },
                {
                    "authorId": "38272296",
                    "name": "Wen-gang Zhou"
                },
                {
                    "authorId": "33642939",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "2070183551",
                    "name": "Tao Mei"
                }
            ]
        },
        {
            "paperId": "707142f242ee4e40489062870ca53810cb33d404",
            "title": "Demystifying Structural Disparity in Graph Neural Networks: Can One Size Fit All?",
            "abstract": "Recent studies on Graph Neural Networks(GNNs) provide both empirical and theoretical evidence supporting their effectiveness in capturing structural patterns on both homophilic and certain heterophilic graphs. Notably, most real-world homophilic and heterophilic graphs are comprised of a mixture of nodes in both homophilic and heterophilic structural patterns, exhibiting a structural disparity. However, the analysis of GNN performance with respect to nodes exhibiting different structural patterns, e.g., homophilic nodes in heterophilic graphs, remains rather limited. In the present study, we provide evidence that Graph Neural Networks(GNNs) on node classification typically perform admirably on homophilic nodes within homophilic graphs and heterophilic nodes within heterophilic graphs while struggling on the opposite node set, exhibiting a performance disparity. We theoretically and empirically identify effects of GNNs on testing nodes exhibiting distinct structural patterns. We then propose a rigorous, non-i.i.d PAC-Bayesian generalization bound for GNNs, revealing reasons for the performance disparity, namely the aggregated feature distance and homophily ratio difference between training and testing nodes. Furthermore, we demonstrate the practical implications of our new findings via (1) elucidating the effectiveness of deeper GNNs; and (2) revealing an over-looked distribution shift factor on graph out-of-distribution problem and proposing a new scenario accordingly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2187164642",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "145474474",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "4e5afc4eb4d9ad5281b94542f38ab716dc796854",
            "title": "Anti-Forgery: Towards a Stealthy and Robust DeepFake Disruption Attack via Adversarial Perceptual-aware Perturbations",
            "abstract": "DeepFake is becoming a real risk to society and brings potential threats to both individual privacy and political security due to the DeepFaked multimedia are realistic and convincing. However, the popular DeepFake passive detection is an ex-post forensics countermeasure and failed in blocking the disinformation spreading in advance. To address this limitation, researchers study the proactive defense techniques by adding adversarial noises into the source data to disrupt the DeepFake manipulation. However, the existing studies on proactive DeepFake defense via injecting adversarial noises are not robust, which could be easily bypassed by employing simple image reconstruction revealed in a recent study MagDR. \n\n\n\nIn this paper, we investigate the vulnerability of the existing forgery techniques and propose a novel anti-forgery technique that helps users protect the shared facial images from attackers who are capable of applying the popular forgery techniques. Our proposed method generates perceptual-aware perturbations in an incessant manner which is vastly different from the prior studies by adding adversarial noises that is sparse. Experimental results reveal that our perceptual-aware perturbations are robust to diverse image transformations, especially the competitive evasion technique, MagDR via image reconstruction. Our findings potentially open up a new research direction towards thorough understanding and investigation of perceptual-aware adversarial attack for protecting facial images against DeepFakes in a proactive and robust manner. Code is available at https://github.com/AbstractTeen/AntiForgery.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108704868",
                    "name": "Run Wang"
                },
                {
                    "authorId": "9516769",
                    "name": "Zi-Shun Huang"
                },
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2150978882",
                    "name": "Li Liu"
                },
                {
                    "authorId": null,
                    "name": "Jing Chen"
                },
                {
                    "authorId": "2108625453",
                    "name": "Lina Wang"
                }
            ]
        },
        {
            "paperId": "8328de9fcabcd24ecb1ffa44269bc7b079cae518",
            "title": "Leveraging Diversity-Aware Context Attention Networks for Fake News Detection on Social Platforms",
            "abstract": "In recent years, social platforms have become the main venue for disseminating fake news. Since much fake news is deliberately fabricated by malicious users or generated by adversarial deep learning models, content-only approaches can not detect fake news effectively. Compared to texts, the propagation patterns of fake news are much harder to be forged. Recent work found that the \u201ccontext\u201d of news, the tree-structured graph representing the propagation relationship of news and Twitter posts, is vital for fake news detection. Some work utilize graph neural networks to learn the representation of news' context graphs, achieving stunning performance. However, these methods still suffer from two problems. Firstly, Twitters posts in the context of news are not equally important for fake news detection. However, most previous works treat them equally. Moreover, the context of news presents diverse structures such as \u201cstar-shaped\u201d graphs, with many nodes interacting with a central node, or \u201cline-shaped\u201d graphs, with sparse connections among neighbors. With single-scale graph representation, previous work can not handle diverse structures well. We propose a novel diversity-aware context attention network to cope with these problems. A context attention pooling function is proposed to extract the critical information within the context. It utilizes an attention module to automatically assign a greater weight to those important posts and a smaller weight to helpless posts. Furthermore, jump knowledge, which concatenates the pooling result from multiple network layers, is adopted. It offers the model multi-scale receptive fields and better adapts to diverse structures. Extensive experiments are conducted under various dataset settings, which confirms the superiority of our approaches over state-of-the-art models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2111193251",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2114095042",
                    "name": "Liang X. Pan"
                }
            ]
        },
        {
            "paperId": "988959a957717cc7067341f8f1959c7368461952",
            "title": "MagDR: Mask-guided Detection and Reconstruction for Defending Deepfakes",
            "abstract": "1 Deepfakes raised serious concerns on the authenticity of visual contents. Prior works revealed the possibility to disrupt deepfakes by adding adversarial perturbations to the source data, but we argue that the threat has not been eliminated yet. This paper presents MagDR, a mask-guided detection and reconstruction pipeline for defending deepfakes from adversarial attacks. MagDR starts with a detection module that defines a few criteria to judge the abnormality of the output of deepfakes, and then uses it to guide a learnable reconstruction procedure. Adaptive masks are extracted to capture the change in local facial regions. In experiments, MagDR defends three main tasks of deepfakes, and the learned reconstruction pipeline transfers across input data, showing promising performance in defending both black-box and white-box attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "3041937",
                    "name": "Lingxi Xie"
                },
                {
                    "authorId": "2852872",
                    "name": "Shanmin Pang"
                },
                {
                    "authorId": "2118926134",
                    "name": "Yong He"
                },
                {
                    "authorId": null,
                    "name": "Bo Zhang"
                }
            ]
        },
        {
            "paperId": "b6a02ae7c0122cb22c9223c1bba9064ac76b06bd",
            "title": "Appending Adversarial Frames for Universal Video Attack",
            "abstract": "This paper investigates the problem of generating adversarial examples for video classification. We project all videos onto a semantic space and a perception space, and point out that adversarial attack is to find a counterpart which is close to the target in the perception space but far from the target in the semantic space. Based on this formulation, we notice that conventional attacking methods mostly used Euclidean distance to measure the perception space, but we propose to make full use of the property of videos and assume a modified video with a few consecutive frames replaced by dummy contents (e.g., a black frame with texts of \u2018thank you for watching\u2019 on it) to be close to the original video in the perception space though they have a large Euclidean gap. This leads to a new attack approach which only adds perturbations on the newly-added frames. We show its high success rates in attacking six state-of-the-art video classification networks, as well as its universality, i.e., transferring well across videos and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "3041937",
                    "name": "Lingxi Xie"
                },
                {
                    "authorId": "2852872",
                    "name": "Shanmin Pang"
                },
                {
                    "authorId": "2118926134",
                    "name": "Yong He"
                },
                {
                    "authorId": "1400120070",
                    "name": "Qi Tian"
                }
            ]
        },
        {
            "paperId": "07e7567fc7928a240722169443787e31b2a077db",
            "title": "Unsupervised Single Image Deraining with Self-Supervised Constraints",
            "abstract": "Most existing single image deraining methods require learning supervised models from a large set of paired synthetic training data, which limits their generality and practicality in real-world multimedia applications. Besides, due to lack of labeled-supervised constraints, directly applying existing unsupervised frameworks to the image deraining task will suffer from low-quality recovery. Therefore, we propose an Unsupervised Deraining Generative Adversarial Network (UD-GAN) to tackle above problems by introducing self-supervised constraints from the intrinsic statistics of unpaired rainy and clean images. Specifically, we design two collaboratively optimized modules, namely Rain Guidance Module (RGM) and Background Guidance Module (BGM), to take full advantage of rainy image characteristics. UD-GAN outperforms state-of-the-art methods on various benchmarking datasets in both quantitative and qualitative comparisons.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1485402830",
                    "name": "Xin Jin"
                },
                {
                    "authorId": "31482866",
                    "name": "Zhibo Chen"
                },
                {
                    "authorId": "46698009",
                    "name": "Jianxin Lin"
                },
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2153058942",
                    "name": "Wei Zhou"
                }
            ]
        }
    ]
}