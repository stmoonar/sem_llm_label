{
    "authorId": "145898106",
    "papers": [
        {
            "paperId": "2fc43fbf0568c39db5accb36e9daa8c05df7a775",
            "title": "Improved Cross-Lingual Transfer Learning For Automatic Speech Translation",
            "abstract": "Research in multilingual speech-to-text translation is topical. Having a single model that supports multiple translation tasks is desirable. The goal of this work it to improve cross-lingual transfer learning in multilingual speech-to-text translation via semantic knowledge distillation. We show that by initializing the encoder of the encoder-decoder sequence-to-sequence translation model with SAMU-XLS-R, a multilingual speech transformer encoder trained using multi-modal (speech-text) semantic knowledge distillation, we achieve significantly better cross-lingual task knowledge transfer than the baseline XLS-R, a multilingual speech transformer encoder trained via self-supervised learning. We demonstrate the effectiveness of our approach on two popular datasets, namely, CoVoST-2 and Europarl. On the 21 translation tasks of the CoVoST-2 benchmark, we achieve an average improvement of 12.8 BLEU points over the baselines. In the zero-shot translation scenario, we achieve an average gain of 18.8 and 11.9 average BLEU points on unseen medium and low-resource languages. We make similar observations on Europarl speech translation benchmark.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "40570741",
                    "name": "Sameer Khurana"
                },
                {
                    "authorId": "8777695",
                    "name": "Nauman Dawalatabad"
                },
                {
                    "authorId": "48839344",
                    "name": "Antoine Laurent"
                },
                {
                    "authorId": "2218699381",
                    "name": "Luis Vicente"
                },
                {
                    "authorId": "145885077",
                    "name": "Pablo Gimeno"
                },
                {
                    "authorId": "52319815",
                    "name": "Victoria Mingote"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "3fcc8cb68488cfdfe4c52b81f27a236352fe5582",
            "title": "Interpretable Unified Language Checking",
            "abstract": "Despite recent concerns about undesirable behaviors generated by large language models (LLMs), including non-factual, biased, and hateful language, we find LLMs are inherent multi-task language checkers based on their latent representations of natural and social knowledge. We present an interpretable, unified, language checking (UniLC) method for both human and machine-generated language that aims to check if language input is factual and fair. While fairness and fact-checking tasks have been handled separately with dedicated models, we find that LLMs can achieve high performance on a combination of fact-checking, stereotype detection, and hate speech detection tasks with a simple, few-shot, unified set of prompts. With the ``1/2-shot'' multi-task language checking method proposed in this work, the GPT3.5-turbo model outperforms fully supervised baselines on several language tasks. The simple approach and results suggest that based on strong latent knowledge representations, an LLM can be an adaptive and explainable tool for detecting misinformation, stereotypes, and hate speech.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146333115",
                    "name": "Tianhua Zhang"
                },
                {
                    "authorId": "1944274",
                    "name": "Hongyin Luo"
                },
                {
                    "authorId": "2475831",
                    "name": "Yung-Sung Chuang"
                },
                {
                    "authorId": "2117161925",
                    "name": "Wei Fang"
                },
                {
                    "authorId": "2214001322",
                    "name": "Luc Gaitskell"
                },
                {
                    "authorId": "32452740",
                    "name": "Thomas Hartvigsen"
                },
                {
                    "authorId": "1847260",
                    "name": "Xixin Wu"
                },
                {
                    "authorId": "31997718",
                    "name": "D. Fox"
                },
                {
                    "authorId": "2057833292",
                    "name": "Helen M. Meng"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "4f2dfe2c224ff00a5ff6f0a852ffedb8d1209fb6",
            "title": "Entailment as Robust Self-Learner",
            "abstract": "Entailment has been recognized as an important metric for evaluating natural language understanding (NLU) models, and recent studies have found that entailment pretraining benefits weakly supervised fine-tuning. In this work, we design a prompting strategy that formulates a number of different NLU tasks as contextual entailment. This approach improves the zero-shot adaptation of pretrained entailment models. Secondly, we notice that self-training entailment-based models with unlabeled data can significantly improve the adaptation performance on downstream tasks. To achieve more stable improvement, we propose the Simple Pseudo-Label Editing (SimPLE) algorithm for better pseudo-labeling quality in self-training. We also found that both pretrained entailment-based models and the self-trained models are robust against adversarial evaluation data. Experiments on binary and multi-class classification tasks show that SimPLE leads to more robust self-training results, indicating that the self-trained entailment models are more efficient and trustworthy than large language models on language understanding tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214584825",
                    "name": "Jiaxin Ge"
                },
                {
                    "authorId": "1944274",
                    "name": "Hongyin Luo"
                },
                {
                    "authorId": "38367242",
                    "name": "Yoon Kim"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "51094c373cb4a52acc463d7b8a61e9b0076c057b",
            "title": "Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question Answering",
            "abstract": "We propose EAR, a query Expansion And Reranking approach for improving passage retrieval, with the application to open-domain question answering. EAR first applies a query expansion model to generate a diverse set of queries, and then uses a query reranker to select the ones that could lead to better retrieval results. Motivated by the observation that the best query expansion often is not picked by greedy decoding, EAR trains its reranker to predict the rank orders of the gold passages when issuing the expanded queries to a given retriever. By connecting better the query expansion model and retriever, EAR significantly enhances a traditional sparse retrieval method, BM25. Empirically, EAR improves top-5/20 accuracy by 3-8 and 5-10 points in in-domain and out-of-domain settings, respectively, when compared to a vanilla query expansion model, GAR, and a dense retrieval model, DPR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2475831",
                    "name": "Yung-Sung Chuang"
                },
                {
                    "authorId": "2117161925",
                    "name": "Wei Fang"
                },
                {
                    "authorId": "2530311",
                    "name": "Shang-Wen Li"
                },
                {
                    "authorId": "2072801764",
                    "name": "Wen-tau Yih"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "94d878ba7eeba4abc4d5e42b4c2c4c98d4e575ce",
            "title": "Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning",
            "abstract": "How can we perform computations over natural language representations to solve tasks that require symbolic and numeric reasoning? We propose natural language embedded programs (NLEP) as a unifying framework for addressing math/symbolic reasoning, natural language understanding, and instruction following tasks. Our approach prompts a language model to generate full Python programs that define functions over data structures which contain natural language representations of structured knowledge. A Python interpreter then executes the generated code and prints the output. Despite using a task-general prompt, we find that this approach can improve upon strong baselines across a range of different tasks including math and symbolic reasoning, text classification, question answering, and instruction following. We found that the generated programs are interpretable since they outline the exact reasoning process followed by the program interpreter.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146333115",
                    "name": "Tianhua Zhang"
                },
                {
                    "authorId": "2214584825",
                    "name": "Jiaxin Ge"
                },
                {
                    "authorId": "1944274",
                    "name": "Hongyin Luo"
                },
                {
                    "authorId": "2475831",
                    "name": "Yung-Sung Chuang"
                },
                {
                    "authorId": "2111853746",
                    "name": "Mingye Gao"
                },
                {
                    "authorId": "145802952",
                    "name": "Yuan Gong"
                },
                {
                    "authorId": "1847260",
                    "name": "Xixin Wu"
                },
                {
                    "authorId": "143827730",
                    "name": "Yoon Kim"
                },
                {
                    "authorId": "2237423230",
                    "name": "Helen Meng"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "a7977870b58e716cd93f571a3b75a610167a75bd",
            "title": "SAIL: Search-Augmented Instruction Learning",
            "abstract": "Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing \\textit{(instruction, grounding information, response)} triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy information selection and multi-hop reasoning, since the retrieved passages might be informative but not contain the instruction-following answer. Experiments show that the fine-tuned SAIL-7B model has a strong instruction-following ability, and it performs significantly better on transparency-sensitive tasks, including open-ended question answering and fact checking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1944274",
                    "name": "Hongyin Luo"
                },
                {
                    "authorId": "2475831",
                    "name": "Yung-Sung Chuang"
                },
                {
                    "authorId": "145802952",
                    "name": "Yuan Gong"
                },
                {
                    "authorId": "2146333115",
                    "name": "Tianhua Zhang"
                },
                {
                    "authorId": "143827730",
                    "name": "Yoon Kim"
                },
                {
                    "authorId": "1847260",
                    "name": "Xixin Wu"
                },
                {
                    "authorId": "31997718",
                    "name": "D. Fox"
                },
                {
                    "authorId": "145199941",
                    "name": "H. Meng"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "c14db8b4c1bd65a18a604236cdbc3549ee75f3bd",
            "title": "Joint Audio and Speech Understanding",
            "abstract": "Humans are surrounded by audio signals that include both speech and non-speech sounds. The recognition and understanding of speech and non-speech audio events, along with a profound comprehension of the relationship between them, constitute fundamental cognitive capabilities. For the first time, we build a machine learning model, called LTU-AS, that has a conceptually similar universal audio perception and advanced reasoning ability. Specifically, by integrating Whisper [1] as a perception module and LLaMA [2] as a reasoning module, LTU-AS can simultaneously recognize and jointly understand spoken text, speech paralinguistics, and non-speech audio events - almost everything perceivable from audio signals.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "145802952",
                    "name": "Yuan Gong"
                },
                {
                    "authorId": "49285584",
                    "name": "Alexander H. Liu"
                },
                {
                    "authorId": "1944274",
                    "name": "Hongyin Luo"
                },
                {
                    "authorId": "2142741421",
                    "name": "Leonid Karlinsky"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        },
        {
            "paperId": "e8a51aef8dc39cab684954a683f1d65b4bf3981c",
            "title": "Revealing the Blind Spot of Sentence Encoder Evaluation by HEROS",
            "abstract": "Existing sentence textual similarity benchmark datasets only use a single number to summarize how similar the sentence encoder's decision is to humans'. However, it is unclear what kind of sentence pairs a sentence encoder (SE) would consider similar. Moreover, existing SE benchmarks mainly consider sentence pairs with low lexical overlap, so it is unclear how the SEs behave when two sentences have high lexical overlap. We introduce a high-quality SE diagnostic dataset, HEROS. HEROS is constructed by transforming an original sentence into a new sentence based on certain rules to form a \\textit{minimal pair}, and the minimal pair has high lexical overlaps. The rules include replacing a word with a synonym, an antonym, a typo, a random word, and converting the original sentence into its negation. Different rules yield different subsets of HEROS. By systematically comparing the performance of over 60 supervised and unsupervised SEs on HEROS, we reveal that most unsupervised sentence encoders are insensitive to negation. We find the datasets used to train the SE are the main determinants of what kind of sentence pairs an SE considers similar. We also show that even if two SEs have similar performance on STS benchmarks, they can have very different behavior on HEROS. Our result reveals the blind spot of traditional STS benchmarks when evaluating SEs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1992777064",
                    "name": "Cheng-Han Chiang"
                },
                {
                    "authorId": "2475831",
                    "name": "Yung-Sung Chuang"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                },
                {
                    "authorId": "1706104",
                    "name": "Hung-yi Lee"
                }
            ]
        },
        {
            "paperId": "ed5020eeda1fbe8c29b1282d654b34abee22d90f",
            "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models",
            "abstract": "Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2475831",
                    "name": "Yung-Sung Chuang"
                },
                {
                    "authorId": "2167703904",
                    "name": "Yujia Xie"
                },
                {
                    "authorId": "1944274",
                    "name": "Hongyin Luo"
                },
                {
                    "authorId": "143827730",
                    "name": "Yoon Kim"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                },
                {
                    "authorId": "50462546",
                    "name": "Pengcheng He"
                }
            ]
        },
        {
            "paperId": "f7b96d49d4efbefbe4c679331683b8c50393f505",
            "title": "DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning",
            "abstract": "In this paper, we introduce self-distillation and online clustering for self-supervised speech representation learning (DinoSR) which combines masked language modeling, self-distillation, and online clustering. We show that these concepts complement each other and result in a strong representation learning model for speech. DinoSR first extracts contextualized embeddings from the input audio with a teacher network, then runs an online clustering system on the embeddings to yield a machine-discovered phone inventory, and finally uses the discretized tokens to guide a student network. We show that DinoSR surpasses previous state-of-the-art performance in several downstream tasks, and provide a detailed analysis of the model and the learned discrete units.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49285584",
                    "name": "Alexander H. Liu"
                },
                {
                    "authorId": "2116152118",
                    "name": "Heng-Jui Chang"
                },
                {
                    "authorId": "2325985",
                    "name": "Michael Auli"
                },
                {
                    "authorId": "2957796",
                    "name": "Wei-Ning Hsu"
                },
                {
                    "authorId": "145898106",
                    "name": "James R. Glass"
                }
            ]
        }
    ]
}