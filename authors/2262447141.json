{
    "authorId": "2262447141",
    "papers": [
        {
            "paperId": "1fd57ba49bacc54358231931e1659648181e14c6",
            "title": "Bidirectional Gated Mamba for Sequential Recommendation",
            "abstract": "In various domains, Sequential Recommender Systems (SRS) have become essential due to their superior capability to discern intricate user preferences. Typically, SRS utilize transformer-based architectures to forecast the subsequent item within a sequence. Nevertheless, the quadratic computational complexity inherent in these models often leads to inefficiencies, hindering the achievement of real-time recommendations. Mamba, a recent advancement, has exhibited exceptional performance in time series prediction, significantly enhancing both efficiency and accuracy. However, integrating Mamba directly into SRS poses several challenges. Its inherently unidirectional nature may constrain the model's capacity to capture the full context of user-item interactions, while its instability in state estimation can compromise its ability to detect short-term patterns within interaction sequences. To overcome these issues, we introduce a new framework named Selective Gated Mamba (SIGMA) for Sequential Recommendation. This framework leverages a Partially Flipped Mamba (PF-Mamba) to construct a bidirectional architecture specifically tailored to improve contextual modeling. Additionally, an input-sensitive Dense Selective Gate (DS Gate) is employed to optimize directional weights and enhance the processing of sequential information in PF-Mamba. For short sequence modeling, we have also developed a Feature Extract GRU (FE-GRU) to efficiently capture short-term dependencies. Empirical results indicate that SIGMA outperforms current models on five real-world datasets. Our implementation code is available at https://github.com/ziwliu-cityu/SIMGA to ease reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2316826974",
                    "name": "Ziwei Liu"
                },
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2264224432",
                    "name": "Pengyue Jia"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2316790244",
                    "name": "Yi Chang"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "321129c86cfddde76638cdcd7ba3d56d8788015c",
            "title": "Cumulative Distribution Function based General Temporal Point Processes",
            "abstract": "Temporal Point Processes (TPPs) hold a pivotal role in modeling event sequences across diverse domains, including social networking and e-commerce, and have significantly contributed to the advancement of recommendation systems and information retrieval strategies. Through the analysis of events such as user interactions and transactions, TPPs offer valuable insights into behavioral patterns, facilitating the prediction of future trends. However, accurately forecasting future events remains a formidable challenge due to the intricate nature of these patterns. The integration of Neural Networks with TPPs has ushered in the development of advanced deep TPP models. While these models excel at processing complex and nonlinear temporal data, they encounter limitations in modeling intensity functions, grapple with computational complexities in integral computations, and struggle to capture long-range temporal dependencies effectively. In this study, we introduce the CuFun model, representing a novel approach to TPPs that revolves around the Cumulative Distribution Function (CDF). CuFun stands out by uniquely employing a monotonic neural network for CDF representation, utilizing past events as a scaling factor. This innovation significantly bolsters the model's adaptability and precision across a wide range of data scenarios. Our approach addresses several critical issues inherent in traditional TPP modeling: it simplifies log-likelihood calculations, extends applicability beyond predefined density function forms, and adeptly captures long-range temporal patterns. Our contributions encompass the introduction of a pioneering CDF-based TPP model, the development of a methodology for incorporating past event information into future event prediction, and empirical validation of CuFun's effectiveness through extensive experimentation on synthetic and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2253844324",
                    "name": "Yu Pan"
                },
                {
                    "authorId": "2238898625",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2282243915",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2223875866",
                    "name": "Langming Liu"
                }
            ]
        },
        {
            "paperId": "76d2b07a8486c53a4985c9c2ba7b0822ab7f3e36",
            "title": "GLINT-RU: Gated Lightweight Intelligent Recurrent Units for Sequential Recommender Systems",
            "abstract": "In the rapidly evolving field of artificial intelligence, transformer-based models have gained significant attention in the context of Sequential Recommender Systems (SRSs), demonstrating remarkable proficiency in capturing user-item interactions. However, such attention-based frameworks result in substantial computational overhead and extended inference time. To address this problem, this paper proposes a novel efficient sequential recommendation framework GLINT-RU that leverages dense selective Gated Recurrent Units (GRU) module to accelerate the inference speed, which is a pioneering work to further exploit the potential of efficient GRU modules in SRSs. The GRU module lies at the heart of GLINT-RU, playing a crucial role in substantially reducing both inference time and GPU memory usage. Through the integration of a dense selective gate, our framework adeptly captures both long-term and short-term item dependencies, enabling the adaptive generation of item scores. GLINT-RU further integrates a mixing block, enriching it with global user-item interaction information to bolster recommendation quality. Moreover, we design a gated Multi-layer Perceptron (MLP) for our framework where the information is deeply filtered. Extensive experiments on three datasets are conducted to highlight the effectiveness and efficiency of GLINT-RU. Our GLINT-RU achieves exceptional inference speed and prediction accuracy, outperforming existing baselines based on Recurrent Neural Network (RNN), Transformer, MLP and State Space Model (SSM). These results establish a new standard in sequential recommendation, highlighting the potential of GLINT-RU as a renewing approach in the realm of recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282233261",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "8c91b5f7d3116662a465e749b5dde2f178cfac8a",
            "title": "EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems",
            "abstract": "In this age where data is abundant, the ability to distill meaningful insights from the sea of information is essential. Our research addresses the computational and resource inefficiencies that current Sequential Recommender Systems (SRSs) suffer from. especially those employing attention-based models like SASRec, These systems are designed for next-item recommendations in various applications, from e-commerce to social networks. However, such systems suffer from substantial computational costs and resource consumption during the inference stage. To tackle these issues, our research proposes a novel method that combines automatic pruning techniques with advanced model architectures. We also explore the potential of resource-constrained Neural Architecture Search (NAS), a technique prevalent in the realm of recommendation systems, to fine-tune models for reduced FLOPs, latency, and energy usage while retaining or even enhancing accuracy. The main contribution of our work is developing the Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems (EASRec). This approach aims to find optimal compact architectures for attention-based SRSs, ensuring accuracy retention. EASRec introduces data-aware gates that leverage historical information from input data batch to improve the performance of the recommendation network. Additionally, it utilizes a dynamic resource constraint approach, which standardizes the search process and results in more appropriate architectures. The effectiveness of our methodology is validated through exhaustive experiments on three benchmark datasets, which demonstrates EASRec's superiority in SRSs. Our research set a new standard for future exploration into efficient and accurate recommender systems, signifying a substantial advancement within this swiftly advancing field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282233261",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2240539453",
                    "name": "Chenyi Zhuang"
                },
                {
                    "authorId": "2266811973",
                    "name": "Jinjie Gu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2187882131",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2282271789",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "032fa238d13835662d636553e9ca1b778ac8f88b",
            "title": "Large Multimodal Model Compression via Iterative Efficient Pruning and Distillation",
            "abstract": "The deployment of Large Multimodal Models (LMMs) within Ant Group has significantly advanced multimodal tasks in payment, security, and advertising, notably enhancing advertisement audition tasks in Alipay. However, the deployment of such sizable models introduces challenges, particularly in increased latency and carbon emissions, which are antithetical to the ideals of Green AI. This paper introduces a novel multi-stage compression strategy for our proprietary LLM, AntGMM. Our methodology pivots on three main aspects: employing small training sample sizes, addressing multi-level redundancy through multi-stage pruning, and introducing an advanced distillation loss design. In our research, we constructed a dataset, the Multimodal Advertisement Audition Dataset (MAAD), from real-world scenarios within Alipay, and conducted experiments to validate the reliability of our proposed strategy. Furthermore, the effectiveness of our strategy is evident in its operational success in Alipay's real-world multimodal advertisement audition for three months from September 2023. Notably, our approach achieved a substantial reduction in latency, decreasing it from 700ms to 90ms, while maintaining online performance with only a slight performance decrease. Moreover, our compressed model is estimated to reduce electricity consumption by approximately 75 million kWh annually compared to the direct deployment of AntGMM, demonstrating our commitment to green AI initiatives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2273557310",
                    "name": "Jiajia Liu"
                },
                {
                    "authorId": "2273419378",
                    "name": "Jingdong Chen"
                },
                {
                    "authorId": "2240539453",
                    "name": "Chenyi Zhuang"
                },
                {
                    "authorId": "2266811973",
                    "name": "Jinjie Gu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "5d343ef364705045bb5def6c4cb138bb6cec1b3b",
            "title": "Federated Knowledge Graph Completion via Latent Embedding Sharing and Tensor Factorization",
            "abstract": "Knowledge graphs (KGs), which consist of triples, are inherently incomplete and always require completion procedure to predict missing triples. In real-world scenarios, KGs are distributed across clients, complicating completion tasks due to privacy restrictions. Many frameworks have been proposed to address the issue of federated knowledge graph completion. However, the existing frameworks, including FedE, FedR, and FEKG, have certain limitations. = FedE poses a risk of information leakage, FedR\u2019s optimization efficacy diminishes when there is minimal overlap among relations, and FKGE suffers from computational costs and mode collapse issues. To address these issues, we propose a novel method, i.e., Federated Latent Embedding Sharing Tensor factorization (FLEST), which is a novel approach using federated tensor factorization for KG completion. FLEST decompose the embedding matrix and enables sharing of latent dictionary embeddings to lower privacy risks. Empirical results demonstrate FLEST\u2019s effectiveness and efficiency, offering a balanced solution between performance and privacy. FLEST expands the application of federated tensor factorization in KG completion tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2120902779",
                    "name": "Dun Zeng"
                },
                {
                    "authorId": "2238898625",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "85bbc8af01084d2328c49cb3c70241c76e3ef4d5",
            "title": "Embedding in Recommender Systems: A Survey",
            "abstract": "Recommender systems have become an essential component of many online platforms, providing personalized recommendations to users. A crucial aspect is embedding techniques that coverts the high-dimensional discrete features, such as user and item IDs, into low-dimensional continuous vectors and can enhance the recommendation performance. Applying embedding techniques captures complex entity relationships and has spurred substantial research. In this survey, we provide an overview of the recent literature on embedding techniques in recommender systems. This survey covers embedding methods like collaborative filtering, self-supervised learning, and graph-based techniques. Collaborative filtering generates embeddings capturing user-item preferences, excelling in sparse data. Self-supervised methods leverage contrastive or generative learning for various tasks. Graph-based techniques like node2vec exploit complex relationships in network-rich environments. Addressing the scalability challenges inherent to embedding methods, our survey delves into innovative directions within the field of recommendation systems. These directions aim to enhance performance and reduce computational complexity, paving the way for improved recommender systems. Among these innovative approaches, we will introduce Auto Machine Learning (AutoML), hash techniques, and quantization techniques in this survey. We discuss various architectures and techniques and highlight the challenges and future directions in these aspects. This survey aims to provide a comprehensive overview of the state-of-the-art in this rapidly evolving field and serve as a useful resource for researchers and practitioners working in the area of recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2262447995",
                    "name": "Xinjian Zhao"
                },
                {
                    "authorId": "2262510496",
                    "name": "Jiansheng Li"
                },
                {
                    "authorId": "2262865343",
                    "name": "Shucheng Zhou"
                },
                {
                    "authorId": "2240617631",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2297955888",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                }
            ]
        },
        {
            "paperId": "99e10eb07961b5947512bd448df180d32ca8b319",
            "title": "Large Multimodal Model Compression via Efficient Pruning and Distillation at AntGroup",
            "abstract": "ThedeploymentofLargeMultimodalModels(LMMs)withinAntGroup hassignificantlyadvancedmultimodaltasksinpayment,security, andadvertising,notablyenhancingadvertisementauditiontasksin Alipay.However,thedeploymentofsuchsizablemodelsintroduces challenges,particularlyinincreasedlatencyandcarbonemissions, whichareantitheticaltotheidealsofGreenAI.Thispaperintro-ducesanovelmulti-stagecompressionstrategyforourproprietary LLM,AntGMM.Ourmethodologypivotsonthreemainaspects: employingsmalltrainingsamplesizes,addressingmulti-levelredun-dancythroughmulti-stagepruning,andintroducinganadvanced distillationlossdesign.Inourresearch,weconstructedadataset, theMultimodalAdvertisementAuditionDataset(MAAD),from real-worldscenarioswithinAlipay,andconductedexperimentsto validatethereliabilityofourproposedstrategy.Furthermore,the effectivenessofourstrategyisevidentinitsoperationalsuccessin Alipay\u2019sreal-worldmultimodaladvertisementauditionforthree monthsfromSeptember2023.Notably,ourapproachachieveda substantialreductioninlatency,decreasingitfrom700msto90ms, whilemaintainingonlineperformancewithonlyaslightperfor-mancedecrease.Moreover,ourcompressedmodelisestimatedto reduceelectricityconsumptionbyapproximately75millionkWh",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2273557310",
                    "name": "Jiajia Liu"
                },
                {
                    "authorId": "2273419378",
                    "name": "Jingdong Chen"
                },
                {
                    "authorId": "2240539453",
                    "name": "Chenyi Zhuang"
                },
                {
                    "authorId": "2266811973",
                    "name": "Jinjie Gu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "f3f58877e404dc8b26b8d387b8c4e7b8ec58d567",
            "title": "On the Opportunities of Green Computing: A Survey",
            "abstract": "Artificial Intelligence (AI) has achieved significant advancements in technology and research with the development over several decades, and is widely used in many areas including computing vision, natural language processing, time-series analysis, speech synthesis, etc. During the age of deep learning, especially with the arise of Large Language Models, a large majority of researchers' attention is paid on pursuing new state-of-the-art (SOTA) results, resulting in ever increasing of model size and computational complexity. The needs for high computing power brings higher carbon emission and undermines research fairness by preventing small or medium-sized research institutions and companies with limited funding in participating in research. To tackle the challenges of computing resources and environmental impact of AI, Green Computing has become a hot research topic. In this survey, we give a systematic overview of the technologies used in Green Computing. We propose the framework of Green Computing and devide it into four key components: (1) Measures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing Systems and (4) AI Use Cases for Sustainability. For each components, we discuss the research progress made and the commonly used techniques to optimize the AI efficiency. We conclude that this new research direction has the potential to address the conflicts between resource constraints and AI development. We encourage more researchers to put attention on this direction and make AI more environmental friendly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2263585943",
                    "name": "You Zhou"
                },
                {
                    "authorId": "2263727811",
                    "name": "Xiujing Lin"
                },
                {
                    "authorId": "2251621180",
                    "name": "Xiang Zhang"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "66129075",
                    "name": "Gangwei Jiang"
                },
                {
                    "authorId": "2259949179",
                    "name": "Huakang Lu"
                },
                {
                    "authorId": "2259929312",
                    "name": "Yupeng Wu"
                },
                {
                    "authorId": "2263584690",
                    "name": "Kai Zhang"
                },
                {
                    "authorId": "2263549827",
                    "name": "Zhe Yang"
                },
                {
                    "authorId": "2263685958",
                    "name": "Kehang Wang"
                },
                {
                    "authorId": "2003767516",
                    "name": "Yongduo Sui"
                },
                {
                    "authorId": "2264531532",
                    "name": "Fengwei Jia"
                },
                {
                    "authorId": "2223900932",
                    "name": "Zuoli Tang"
                },
                {
                    "authorId": "2273538171",
                    "name": "Yao Zhao"
                },
                {
                    "authorId": "2263513526",
                    "name": "Hongxuan Zhang"
                },
                {
                    "authorId": "2263682359",
                    "name": "Tiannuo Yang"
                },
                {
                    "authorId": "2263789459",
                    "name": "Weibo Chen"
                },
                {
                    "authorId": "2264766375",
                    "name": "Yunong Mao"
                },
                {
                    "authorId": "2260645291",
                    "name": "Yi Li"
                },
                {
                    "authorId": "2263962525",
                    "name": "De Bao"
                },
                {
                    "authorId": "2265380833",
                    "name": "Yu Li"
                },
                {
                    "authorId": "2263547216",
                    "name": "Hongrui Liao"
                },
                {
                    "authorId": "2115432094",
                    "name": "Ting Liu"
                },
                {
                    "authorId": "2172767074",
                    "name": "Jingwen Liu"
                },
                {
                    "authorId": "2263675227",
                    "name": "Jinchi Guo"
                },
                {
                    "authorId": "2258334989",
                    "name": "Jin Zhao"
                },
                {
                    "authorId": "2240652645",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2225919652",
                    "name": "Yingmin Wei"
                },
                {
                    "authorId": "2252811589",
                    "name": "Hong Qian"
                },
                {
                    "authorId": "2184651535",
                    "name": "Qi Liu"
                },
                {
                    "authorId": "2186546609",
                    "name": "Xiang Wang"
                },
                {
                    "authorId": "2263630540",
                    "name": "Wai Kin Victor Chan"
                },
                {
                    "authorId": "2261355440",
                    "name": "Chenliang Li"
                },
                {
                    "authorId": "2263803038",
                    "name": "Yusen Li"
                },
                {
                    "authorId": "2264475758",
                    "name": "Shiyu Yang"
                },
                {
                    "authorId": "2263852557",
                    "name": "Jining Yan"
                },
                {
                    "authorId": "2243198547",
                    "name": "Chao Mou"
                },
                {
                    "authorId": "2263898347",
                    "name": "Shuai Han"
                },
                {
                    "authorId": "7651458",
                    "name": "Wuxia Jin"
                },
                {
                    "authorId": "2263715343",
                    "name": "Guannan Zhang"
                },
                {
                    "authorId": "2263883628",
                    "name": "Xiaodong Zeng"
                }
            ]
        }
    ]
}