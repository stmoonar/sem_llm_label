{
    "authorId": "145590324",
    "papers": [
        {
            "paperId": "04e8353f7e8ba10687a0728b49e066e665f7ff49",
            "title": "Detecting Harmful Agendas in News Articles",
            "abstract": "Manipulated news online is a growing problem which necessitates the use of automated systems to curtail its spread. We argue that while misinformation and disinformation detection have been studied, there has been a lack of investment in the important open challenge of detecting harmful agendas in news articles; identifying harmful agendas is critical to \ufb02ag news campaigns with the greatest potential for real world harm. Moreover, due to real concerns around censorship, harmful agenda detectors must be interpretable to be effective. In this work, we propose this new task and release a dataset, N EWS A GENDAS , of annotated news articles for agenda identi\ufb01cation. We show how interpretable systems can be effective on this task and demonstrate that they can perform comparably to black-box models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065894334",
                    "name": "Melanie Subbiah"
                },
                {
                    "authorId": "2144903149",
                    "name": "Amrita Bhattacharjee"
                },
                {
                    "authorId": "2203931237",
                    "name": "Bobby Yilun Hua"
                },
                {
                    "authorId": "40899329",
                    "name": "Tharindu Kumarage"
                },
                {
                    "authorId": "2146398099",
                    "name": "Huan Liu"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "0b0fe9d0809fe2dcd0e22c99e8bd0a3d12e94b9a",
            "title": "SWING: Balancing Coverage and Faithfulness for Dialogue Summarization",
            "abstract": "Missing information is a common issue of dialogue summarization where some information in the reference summaries is not covered in the generated summaries. To address this issue, we propose to utilize natural language inference (NLI) models to improve coverage while avoiding introducing factual inconsistencies. Specifically, we use NLI to compute fine-grained training signals to encourage the model to generate content in the reference summaries that have not been covered, as well as to distinguish between factually consistent and inconsistent generated sentences. Experiments on the DialogSum and SAMSum datasets confirm the effectiveness of the proposed approach in balancing coverage and faithfulness, validated with automatic metrics and human evaluations. Additionally, we compute the correlation between commonly used automatic metrics with human judgments in terms of three different dimensions regarding coverage and factual consistency to provide insight into the most suitable metric for evaluating dialogue summaries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1420116116",
                    "name": "Kung-Hsiang Huang"
                },
                {
                    "authorId": "1956008001",
                    "name": "Kung-Hsiang Huang"
                },
                {
                    "authorId": "2116150263",
                    "name": "Siffi Singh"
                },
                {
                    "authorId": "47646605",
                    "name": "Xiaofei Ma"
                },
                {
                    "authorId": "2093593291",
                    "name": "Wei Xiao"
                },
                {
                    "authorId": "2093592551",
                    "name": "Wei Xiao"
                },
                {
                    "authorId": "46869897",
                    "name": "Nicholas Dingwall"
                },
                {
                    "authorId": "1682479",
                    "name": "William Yang Wang"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "122dbf4c968a448fb2dde6c5c4a10f2697364531",
            "title": "ManiTweet: A New Benchmark for Identifying Manipulation of News on Social Media",
            "abstract": "Considerable advancements have been made to tackle the misrepresentation of information derived from reference articles in the domains of fact-checking and faithful summarization. However, an unaddressed aspect remains - the identification of social media posts that manipulate information within associated news articles. This task presents a significant challenge, primarily due to the prevalence of personal opinions in such posts. We present a novel task, identifying manipulation of news on social media, which aims to detect manipulation in social media posts and identify manipulated or inserted information. To study this task, we have proposed a data collection schema and curated a dataset called ManiTweet, consisting of 3.6K pairs of tweets and corresponding articles. Our analysis demonstrates that this task is highly challenging, with large language models (LLMs) yielding unsatisfactory performance. Additionally, we have developed a simple yet effective basic model that outperforms LLMs significantly on the ManiTweet dataset. Finally, we have conducted an exploratory analysis of human-written tweets, unveiling intriguing connections between manipulation and the domain and factuality of news articles, as well as revealing that manipulated sentences are more likely to encapsulate the main story or consequences of a news outlet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1420116116",
                    "name": "Kung-Hsiang Huang"
                },
                {
                    "authorId": "23181435",
                    "name": "Hou Pong Chan"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                },
                {
                    "authorId": "144016781",
                    "name": "Heng Ji"
                }
            ]
        },
        {
            "paperId": "21bc2ba103891049075d70bc3a857b16ca1a71aa",
            "title": "ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer",
            "abstract": "Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target \"styles\" can be defined in numerous ways, ranging from single attributes (e.g. formality) to authorship (e.g. Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, sentiment, and even authorship style transfer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2803574",
                    "name": "Zachary Horvitz"
                },
                {
                    "authorId": "2109171018",
                    "name": "Ajay Patel"
                },
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                },
                {
                    "authorId": "2116680369",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "2874422b6b822631106d6d4b0cea7f356787c107",
            "title": "Zero-shot stance detection: Paradigms and challenges",
            "abstract": "A major challenge in stance detection is the large (potentially infinite) and diverse set of stance topics. Collecting data for such a set is unrealistic due to both the expense of annotation and the continuous creation of new real-world topics (e.g., a new politician runs for office). Furthermore, stancetaking occurs in a wide range of languages and genres (e.g., Twitter, news articles). While zero-shot stance detection in English, where evaluation is on topics not seen during training, has received increasing attention, we argue that this attention should be expanded to multilingual and multi-genre settings. We discuss two paradigms for English zero-shot stance detection evaluation, as well as recent work in this area. We then discuss recent work on multilingual and multi-genre stance detection, which has focused primarily on non-zero-shot settings. We argue that this work should be expanded to multilingual and multi-genre zero-shot stance detection and propose best practices to systematize and stimulate future work in this direction. While domain adaptation techniques are well-suited for work in these settings, we argue that increased care should be taken to improve model explainability and to conduct robust evaluations, considering not only empirical generalization ability but also the understanding of complex language and inferences.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "37d9994327ddbcab77549d86f7ab3b969b882b4e",
            "title": "Towards Detecting Harmful Agendas in News Articles",
            "abstract": "Manipulated news online is a growing problem which necessitates the use of automated systems to curtail its spread. We argue that while misinformation and disinformation detection have been studied, there has been a lack of investment in the important open challenge of detecting harmful agendas in news articles; identifying harmful agendas is critical to flag news campaigns with the greatest potential for real world harm. Moreover, due to real concerns around censorship, harmful agenda detectors must be interpretable to be effective. In this work, we propose this new task and release a dataset, NewsAgendas, of annotated news articles for agenda identification. We show how interpretable systems can be effective on this task and demonstrate that they can perform comparably to black-box models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065894334",
                    "name": "Melanie Subbiah"
                },
                {
                    "authorId": "2144903149",
                    "name": "Amrita Bhattacharjee"
                },
                {
                    "authorId": "1453408294",
                    "name": "Yilun Hua"
                },
                {
                    "authorId": "40899329",
                    "name": "Tharindu Kumarage"
                },
                {
                    "authorId": "2146398099",
                    "name": "Huan Liu"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "3de99f885cfc0c2145cd584df7df4230cccaea04",
            "title": "Evaluation of African American Language Bias in Natural Language Generation",
            "abstract": "We evaluate how well LLMs understand African American Language (AAL) in comparison to their performance on White Mainstream English (WME), the encouraged\"standard\"form of English taught in American classrooms. We measure LLM performance using automatic metrics and human judgments for two tasks: a counterpart generation task, where a model generates AAL (or WME) given WME (or AAL), and a masked span prediction (MSP) task, where models predict a phrase that was removed from their input. Our contributions include: (1) evaluation of six pre-trained, large language models on the two language generation tasks; (2) a novel dataset of AAL text from multiple contexts (social media, hip-hop lyrics, focus groups, and linguistic interviews) with human-annotated counterparts in WME; and (3) documentation of model performance gaps that suggest bias and identification of trends in lack of understanding of AAL features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2303366796",
                    "name": "Nicholas Deas"
                },
                {
                    "authorId": "69026665",
                    "name": "Jessica A. Grieser"
                },
                {
                    "authorId": "1484441195",
                    "name": "Shana Kleiner"
                },
                {
                    "authorId": "2767140",
                    "name": "D. Patton"
                },
                {
                    "authorId": "1402934614",
                    "name": "Elsbeth Turcan"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "534c6acfe0c682f5ea7dca38ad0c44efd8504203",
            "title": "Generating EDU Extracts for Plan-Guided Summary Re-Ranking",
            "abstract": "Two-step approaches, in which summary candidates are generated-then-reranked to return a single summary, can improve ROUGE scores over the standard single-step approach. Yet, standard decoding methods (i.e., beam search, nucleus sampling, and diverse beam search) produce candidates with redundant, and often low quality, content. In this paper, we design a novel method to generate candidates for re-ranking that addresses these issues. We ground each candidate abstract on its own unique content plan and generate distinct plan-guided abstracts using a model\u2019s top beam. More concretely, a standard language model (a BART LM) auto-regressively generates elemental discourse unit (EDU) content plans with an extractive copy mechanism. The top K beams from the content plan generator are then used to guide a separate LM, which produces a single abstractive candidate for each distinct plan. We apply an existing re-ranker (BRIO) to abstractive candidates generated from our method, as well as baseline decoding methods. We show large relevance improvements over previously published methods on widely used single document news article corpora, with ROUGE-2 F1 gains of 0.88, 2.01, and 0.38 on CNN / Dailymail, NYT, and Xsum, respectively. A human evaluation on CNN / DM validates these results. Similarly, on 1k samples from CNN / DM, we show that prompting GPT-3 to follow EDU plans outperforms sampling-based methods by by 1.05 ROUGE-2 F1 points. Code to generate and realize plans is available at https://github.com/griff4692/edu-sum.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "49496422",
                    "name": "Griffin Adams"
                },
                {
                    "authorId": "46255971",
                    "name": "Alexander R. Fabbri"
                },
                {
                    "authorId": "8759332",
                    "name": "Faisal Ladhak"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                },
                {
                    "authorId": "2763493",
                    "name": "No\u00e9mie Elhadad"
                }
            ]
        },
        {
            "paperId": "69f2ba0f33a54e01de32c616b64e85d5d7194067",
            "title": "Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations",
            "abstract": "Large language models (LLMs) are trained to imitate humans to explain human decisions. However, do LLMs explain themselves? Can they help humans build mental models of how LLMs process different inputs? To answer these questions, we propose to evaluate $\\textbf{counterfactual simulatability}$ of natural language explanations: whether an explanation can enable humans to precisely infer the model's outputs on diverse counterfactuals of the explained input. For example, if a model answers\"yes\"to the input question\"Can eagles fly?\"with the explanation\"all birds can fly\", then humans would infer from the explanation that it would also answer\"yes\"to the counterfactual input\"Can penguins fly?\". If the explanation is precise, then the model's answer should match humans' expectations. We implemented two metrics based on counterfactual simulatability: precision and generality. We generated diverse counterfactuals automatically using LLMs. We then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on two tasks: multi-hop factual reasoning and reward modeling. We found that LLM's explanations have low precision and that precision does not correlate with plausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may not be a sufficient solution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109268730",
                    "name": "Yanda Chen"
                },
                {
                    "authorId": "51011000",
                    "name": "Ruiqi Zhong"
                },
                {
                    "authorId": "2218040104",
                    "name": "Narutatsu Ri"
                },
                {
                    "authorId": "145756130",
                    "name": "Chen Zhao"
                },
                {
                    "authorId": "2140062900",
                    "name": "He He"
                },
                {
                    "authorId": "5164568",
                    "name": "J. Steinhardt"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "6af96c53d33a988e4b4ecf0f08a4f6aaa9775884",
            "title": "Improving Long Dialogue Summarization with Semantic Graph Representation",
            "abstract": "Although Large Language Models (LLMs) are successful in abstractive summarization of short dialogues, summarization of long dialogues remains challenging. To address this challenge, we propose a novel algorithm that processes complete dialogues comprising thousands of tokens into topic-segment-level Ab-stract Meaning Representation (AMR) graphs, which explicitly capture the dialogue structure, highlight salient semantics, and preserve high-level information. We also develop a new text-graph attention to leverage both graph semantics and a pretrained LLM that exploits the text. Finally, we propose an AMR node selection loss used jointly with conventional cross-entropy loss, to create additional training signals that facilitate graph feature encoding and content selection. Experiments show that our system outperforms the state-of-the-art models on multiple long dialogue summarization datasets, especially in low-resource settings, and generalizes well to out-of-domain data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203931237",
                    "name": "Bobby Yilun Hua"
                },
                {
                    "authorId": "2187454516",
                    "name": "Zhaoyuan Deng"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        }
    ]
}