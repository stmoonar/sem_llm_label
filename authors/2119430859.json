{
    "authorId": "2119430859",
    "papers": [
        {
            "paperId": "5d795805893571ce792931476f9c1d74ba0e82cf",
            "title": "Navigating Industry 5.0: A Survey of Key Enabling Technologies, Trends, Challenges, and Opportunities",
            "abstract": "This century has been a major avenue for revolutionary changes in technology and industry. Industries have transitioned towards intelligent automation, relying less on human intervention, resulting in the fourth industrial revolution, Industry 4.0. That is why IoT has been the researcher\u2019s arena for quite some time. With Industry 4.0 still in motion, the world is on the verge of the $5^{\\textit {th}}$ industrial revolution, a relatively new concept with many unclear opinions regarding its potential benefits, challenges, opportunities, trends, and impact on society. There is a dire need for a broader and more critical perspective. This research paints a bigger picture of \u201cWhat is happening?\u201d and \u201cWhat to expect?\u201d during the transition phase of Industry 5.0. In this comprehensive review, we have addressed the state-of-the-art practices in Industry 4.0 and the transitional phase of Industry 5.0. We have highlighted the most promising key enabling technologies, trends, research topics, rising challenges, and unfolding opportunities that can help prepare society for this paradigm shift. The paper then surveys the work toward the outstanding key enablers, challenges, trends, and opportunities in the IoT evolution for Industry 5.0. To spur further avenues for researchers and industrialists, the paper offers conclusive insights at the end. In addition, the article has a precise set of research questions answered in consequent sections and subsections for the reader\u2019s clarity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "88425554",
                    "name": "Raiha Tallat"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2144802055",
                    "name": "Xingfu Wang"
                },
                {
                    "authorId": "102161257",
                    "name": "A. Al-Dubai"
                },
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2157183774",
                    "name": "Zhi Liu"
                },
                {
                    "authorId": "2165744386",
                    "name": "Geyong Min"
                },
                {
                    "authorId": "123160397",
                    "name": "A. Zomaya"
                },
                {
                    "authorId": "2261818360",
                    "name": "Saeed Hamood Alsamhi"
                }
            ]
        },
        {
            "paperId": "68f6732a07fded2b1f141d192e229854f0de9640",
            "title": "RBEER: Rule-Based Energy-Efficient Routing Protocol for Large-Scale UWSNs",
            "abstract": "Recently, underwater wireless sensor networks (UWSNs) have seen increasing popularity owing to their extensive applications in aquatic environments, including monitoring underwater pipelines, detecting pollution and disasters, researching marine life, underwater surveillance, and facilitating military surveillance. In fact, the task of devising an adequate routing algorithm is particularly challenging because of the unique underwater environmental conditions. These challenges include energy constraints, dynamic topology, long propagation delays, bandwidth limitations, mobility, and 3-D deployments. Therefore, this study addresses the aforementioned challenges and proposes RBEER, a rule-based energy-efficient routing protocol for large-scale UWSNs. RBEER works in three steps: the first is the network initialization and network clustering, in which a Fuzzy C-means is utilized to perform the clustering and determine the cluster centers. The second step is using the RISE rule-based classifier to select the optimal cluster head (CH) based on five input parameters to generate the set of rules. The last step is data forwarding, in which data is forwarded through a single-hop intra-cluster path from member nodes to CH nodes, then through a multi-hop inter-cluster path from CH nodes to sink nodes. Extensive simulations and experiments have been conducted to evaluate the performance of the RBEER protocol. The results demonstrate that the RBEER protocol outperforms benchmarks regarding packet delivery ratio, end-to-end delay, and energy consumption.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268686843",
                    "name": "A. S. Ismail"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2144802055",
                    "name": "Xingfu Wang"
                },
                {
                    "authorId": "2268692876",
                    "name": "Samah Abdel Aziz"
                },
                {
                    "authorId": "2988183",
                    "name": "S. Alsamhi"
                },
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2087826986",
                    "name": "Ahmed Salah Fathalla"
                }
            ]
        },
        {
            "paperId": "799d56e08f2db61570105fa7b768f41cdeda7326",
            "title": "MESON: A Mobility-Aware Dependent Task Offloading Scheme for Urban Vehicular Edge Computing",
            "abstract": "Vehicular Edge Computing (VEC) is the transportation version of Mobile Edge Computing (MEC) in road scenarios. One key technology of VEC is task offloading, which allows vehicles to send their computation tasks to the surrounding Roadside Units (RSUs) or other vehicles for execution, thereby reducing computation delay and energy consumption. However, the existing task offloading schemes still have various gaps and face challenges that should be addressed because vehicles with time-varying trajectories need to process massive data with high complexity and diversity. In this paper, a VEC-based computation offloading model is developed with consideration of data dependency of tasks. The minimization of the average response time and average energy consumption of the system is defined as a combinatorial optimization problem. To solve this problem, we propose a Mobility-aware dependent task offloading (MESON) Scheme for urban VEC and develop a DRL-based algorithm to train the offloading strategy. To improve the training efficiency, a vehicle mobility detection algorithm is further designed to detect the communication time between vehicles and RSUs. In this way, MESON can avoid unreasonable decisions by lowering the size of the action space. Moreover, to improve the system stability and the offloading successful rate, we design a task priority determination scheme to prioritize the tasks in the waiting queue. The experimental results show that MESON is superior compared to other task offloading schemes in terms of the average response time, average system energy consumption, and offloading successful rate.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2202431896",
                    "name": "Enchao Zhang"
                },
                {
                    "authorId": "2112899620",
                    "name": "Shaohua Wan"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "102161257",
                    "name": "A. Al-Dubai"
                },
                {
                    "authorId": "2165744386",
                    "name": "Geyong Min"
                },
                {
                    "authorId": "9392149",
                    "name": "Albert Y. Zomaya"
                }
            ]
        },
        {
            "paperId": "80ef633686c070aef18dcc07655a2888eedba272",
            "title": "A Near-Optimal Protocol for Continuous Tag Recognition in Mobile RFID Systems",
            "abstract": "Mobile radio frequency identification (RFID) systems typically experience the continual movement of many tags rapidly going in and out of the interrogating range of readers. Readers that are deployed to maintain a current, real-time list of tags, which are present in the interrogating zone at any moment, must repeatedly execute a series of reading cycles. Each of these reading cycles provides the readers very limited time to identify unknown tags (those newly entering into the reader\u2019s range), and, at the same time, to detect missing tags (those just leaving the reader\u2019s range). In this paper, we study the continuous tag recognition problem, which is critical for mobile RFID systems. First, we obtain a lower bound on communication time for solving this problem. We then design a near-OPTimal protocoL, called OPT-L, and prove that its communication time is approximately equal to the lower bound. Finally, we present extensive simulation and experimental results that demonstrate OPT-L\u2019s superior performance over other existing protocols.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47119349",
                    "name": "Xiujun Wang"
                },
                {
                    "authorId": "2157183774",
                    "name": "Zhi Liu"
                },
                {
                    "authorId": "2257121425",
                    "name": "Alex X. Liu"
                },
                {
                    "authorId": "2257315414",
                    "name": "Xiao Zheng"
                },
                {
                    "authorId": "2257037771",
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2257047599",
                    "name": "Zhe Dang"
                }
            ]
        },
        {
            "paperId": "8ccb4a30945ea228cdea5d7e4868d239c622ae12",
            "title": "Deep-Reinforcement-Learning-Based Computation Offloading for Servicing Dynamic Demand in Multi-UAV-Assisted IoT Network",
            "abstract": "In wireless networks, meeting the performance requirements of all tasks solely with Internet of Things (IoT) devices is challenging due to their limited computational power and battery capacity. Given their flexibility and mobility, the application of unmanned aerial vehicles (UAVs) in the context of mobile edge computing (MEC) has garnered significant interest within the sector. However, UAVs also face constraints in terms of resources like storage and computational power. Therefore, it is vital to develop effective UAV assistance solutions to provide long-term demands of in-network services. The dynamic scheduling and computation offloading of UAVs is the subject of this article. Specifically, we propose a deep deterministic policy gradient algorithm based on a greedy (DDPGG) strategy to jointly optimize dynamic scheduling, device association, and task allocation of UAVs, with the goal of minimizing the weighted sum of total system energy consumption and time delay. The problem is formulated as a nonlinear programming problem involving mixed integers. The simulation results demonstrate that the DDPGG algorithm we have proposed exhibits a higher level of performance in comparison to its competitors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065998981",
                    "name": "Na Lin"
                },
                {
                    "authorId": "2280385219",
                    "name": "Lu Bai"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2265959858",
                    "name": "Yunchong Guan"
                },
                {
                    "authorId": "2280422166",
                    "name": "Chaojin Mao"
                },
                {
                    "authorId": "2157183774",
                    "name": "Zhi Liu"
                },
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "93053e1a16553c3a3ff23989a3913769da861ce7",
            "title": "Anomaly Detection for In-Vehicle Network Using Self-Supervised Learning With Vehicle-Cloud Collaboration Update",
            "abstract": "With the increasing communications between the In-Vehicle Networks (IVNs) and external networks, security has become a stringent problem. In addition, the controller area network bus in IVN lacks security mechanisms by design, which is vulnerable to various attacks. Thus, it is important to detect IVN anomalies for complete vehicular security. However, current studies are constrained by either requiring labeled data or failing to accurately detect message-level anomalies without labeled data. In addition, the concept drift of existing methods has become a challenge over time. To address these problems, this paper proposes an IVN anomaly detection method based on Self-supervised Learning (IVNSL), which is capable of detecting message-level anomalies without labels. The essential idea of IVNSL is to make the message prediction model learn the distribution of normal messages in sequences using message sequences with noise. Furthermore, to accurately detect anomalies, a Message Prediction Model based on Hierarchical transformers (MPMHit) is proposed, which captures the spatial features of the message and the dependencies between messages. Meanwhile, to solve the concept drift over time, this paper proposes an online update mechanism for MPMHit based on vehicle-cloud collaboration. We conduct an extensive experimental evaluation on the car hacking dataset, resulting to an F1-score average and average false positive rates of IVNSL being 2.282% higher and 1.595% lower than the best baseline method. The average detection speed of each message is as fast as 0.1075 ms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191528051",
                    "name": "Jinhui Cao"
                },
                {
                    "authorId": "1770358",
                    "name": "Xiaoqiang Di"
                },
                {
                    "authorId": "2110952520",
                    "name": "Xu Liu"
                },
                {
                    "authorId": "47786001",
                    "name": "Jinqing Li"
                },
                {
                    "authorId": "2294069887",
                    "name": "Zhi Li"
                },
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2244332763",
                    "name": "Mohsen Guizani"
                }
            ]
        },
        {
            "paperId": "97e28be8fb462cc5fffe195c1418bf3ff0b931be",
            "title": "Adaptive Swarm Intelligent Offloading Based on Digital Twin-assisted Prediction in VEC",
            "abstract": "Vehicular Edge Computing (VEC) is the transportation version of Mobile Edge Computing (MEC). In VEC, task offloading enables vehicles to offload computing tasks to nearby Roadside Units (RSUs), thereby reducing the computation cost. Recent trends in task offloading cause a proliferation of studies in academia. However, the existing offloading schemes still face many challenges, such as high-dynamic network topology, massive and complex data, dynamic scenes with high-speed vehicles and low-latency requirements. Digital Twin (DT)-based VEC is emerging as a promising solution. It monitors the state of the VEC network in real time through mappings and interactions between the physical and virtual entities. Consequently, the task offloading scheme can make more reasonable offloading decisions at the physical layer and further improve the efficiency of VEC. Above all, we propose a VEC computing offloading scheme, namely, Adaptive <underline>S</underline>warm Intelligent Offloading Scheme Based on Digital-<underline>T</underline>win-Assisted P<underline>R</underline>ediction <underline>I</underline>n <underline>VE</underline>C (STRIVE). The VEC network architecture is established to combines DT with an improved Generative Adversarial Network (GAN). The powerful prediction ability of GAN is used to assist in constructing DT in the pre-processing phase, reducing the size of the decision space. To adapt to the dynamic nature of VEC, we establish an adaptive model to adjust the real-time parameter under various scenarios. Then, we deploy an improve<underline>D</underline> genet<underline>I</underline>c simulat<underline>E</underline>d annealing-ba<underline>SE</underline>d partic<underline>L</underline>e swarm optimization (DIESEL) algorithm to task offloading decision-making, which can provide reliable computing services for vehicles at a lower cost. The simulation results demonstrate that the proposed scheme can effectively reduce computing delay and energy consumption compared with its counterparts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2275656762",
                    "name": "Tianyu Li"
                },
                {
                    "authorId": "2202431896",
                    "name": "Enchao Zhang"
                },
                {
                    "authorId": "2196451144",
                    "name": "Yun Lin"
                },
                {
                    "authorId": "2242686066",
                    "name": "Shaohua Wan"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2244332763",
                    "name": "Mohsen Guizani"
                }
            ]
        },
        {
            "paperId": "a682f33f8495247ca8656515c631dd73e52e086c",
            "title": "MEDIA: An Incremental DNN Based Computation Offloading for Collaborative Cloud-Edge Computing",
            "abstract": "MobileCloud Computing (MCC) provides computing, storage, and other fruitful services to end users. Offloading such tasks to cloud servers can help to fulfill the demands of extensive computing resources, but may also lead to network congestion and high latency. Mobile Edge Computing (MEC) places the computing nodes near the end users to enable low-latency services, whereas it cannot execute too many computing tasks due to limited computing resources. Therefore, MCC and MEC are highly complementary. For computing offloading problems in a collaborative cloud-edge environment, traditional optimization algorithms require multiple iterations to obtain results, which leads to excessive time spent to obtain offloading strategies. Deep Neural Network (DNN) based offloading algorithms can provide low latency offloading strategies, but training data is difficult to be obtained and the cost of retraining is too high. Therefore, in this article, we adopt an incremental training method to overcome the problem of insufficient training data and high retraining costs in DNN-based offloading algorithms. An incremental DNN-based computation offloading (MEDIA) algorithm is proposed to derive near-optimal offloading strategies for collaborative cloud-edge computing. The task information on the real scenarios is sent to the central cloud to generate training data, and the powerful computing resources of the central cloud improve the efficiency of training model. The continuous incremental training can maintain a high accuracy of the DNN model and reduce the time for training the model. The evaluation results demonstrate that the proposed algorithm substantially reduces the cost for updating the model without loss of performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2269400496",
                    "name": "Yingcan Han"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2242686066",
                    "name": "Shaohua Wan"
                },
                {
                    "authorId": "2269448316",
                    "name": "Zhenzhou Guo"
                },
                {
                    "authorId": "2244332763",
                    "name": "Mohsen Guizani"
                }
            ]
        },
        {
            "paperId": "ab3141d47f435260fa8db0c13ffe2c85666b814b",
            "title": "A DRL-based Partial Charging Algorithm for Wireless Rechargeable Sensor Networks",
            "abstract": "Breakthroughs in Wireless Energy Transfer (WET) technologies have revitalized Wireless Rechargeable Sensor Networks (WRSNs). However, how to schedule mobile chargers rationally has been quite a tricky problem. Most of the current work does not consider the variability of scenarios and how many mobile chargers should be scheduled as the most appropriate for each dispatch. At the same time, the focus of most work on the mobile charger scheduling problem has always been on reducing the number of dead nodes, and the most critical metric of network performance, packet arrival rate, is relatively neglected. In this paper, we develop a DRL-based Partial Charging (DPC) algorithm. Based on the number and urgency of charging requests, we classify charging requests into four scenarios. And for each scenario, we design a corresponding request allocation algorithm. Then, a Deep Reinforcement Learning (DRL) algorithm is employed to train a decision model using environmental information to select which request allocation algorithm is optimal for the current scenario. After the allocation of charging requests is confirmed, to improve the Quality of Service (QoS), i.e., the packet arrival rate of the entire network, a partial charging scheduling algorithm is designed to maximize the total charging duration of nodes in the ideal state while ensuring that all charging requests are completed. In addition, we analyze the traffic information of the nodes and use the Analytic Hierarchy Process (AHP) to determine the importance of the nodes to compensate for the inaccurate estimation of the node\u2019s remaining lifetime in realistic scenarios. Simulation results show that our proposed algorithm outperforms the existing algorithms regarding the number of alive nodes and packet arrival rate.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2225556585",
                    "name": "Jiangyuan Chen"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2175129483",
                    "name": "Xiaohua Xu"
                },
                {
                    "authorId": "2144802055",
                    "name": "Xingfu Wang"
                },
                {
                    "authorId": "2264951409",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2279930624",
                    "name": "Zhi Liu"
                },
                {
                    "authorId": "2240902458",
                    "name": "S. Alsamhi"
                }
            ]
        },
        {
            "paperId": "b0dc2376a82916a38738ee5db8b18d87c91fbdfe",
            "title": "ESPP: Efficient Sector-Based Charging Scheduling and Path Planning for WRSNs With Hexagonal Topology",
            "abstract": "Wireless Power Transfer (WPT) is a promising technology that can potentially mitigate the energy provisioning problem for sensor networks. In order to efficiently replenish energy for these battery-powered devices, designing appropriate scheduling and charging path planning algorithms is essential and challenging. Whilst previous studies have tackled this challenge, the conjoint influences of network topology, charging path planning, and energy threshold distribution in Wireless Rechargeable Sensor Networks (WRSNs) are still in their infancy. We mitigate the aforementioned problem by proposing novel algorithmic solutions to efficient sector-based on-demand charging scheduling and path planning. Specifically, we first propose a hexagonal cluster-based deployment of nodes such that finding an NP-Complete Hamiltonian path is feasible. Second, each cluster is divided into multiple sectors and a charging path planning algorithm is implemented to yield a Hamiltonian path, aimed at improving the Mobile Charging Vehicle (MCV) efficiency and charging throughput. Third, we propose an efficient algorithm to calculate the importance of nodes to be used for charging duration decision-making and prioritization. Fourth, a non-preemptive dynamic priority scheduling algorithm is proposed for charging tasks\u2019 assignments and scheduling. Finally, extensive simulations have been conducted, revealing the significant advantages of our proposed algorithms in terms of energy efficiency, response time, dead nodes\u2019 density, and queuing processing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2172337164",
                    "name": "Abdulbary Naji"
                },
                {
                    "authorId": "2119430859",
                    "name": "Ammar Hawbani"
                },
                {
                    "authorId": "2144802055",
                    "name": "Xingfu Wang"
                },
                {
                    "authorId": "1453326625",
                    "name": "Haithm M. Al-Gunid"
                },
                {
                    "authorId": "2224204430",
                    "name": "Yunes Al-Dhabi"
                },
                {
                    "authorId": "102161257",
                    "name": "A. Al-Dubai"
                },
                {
                    "authorId": "2154003779",
                    "name": "Amir Hussain"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2988183",
                    "name": "S. Alsamhi"
                }
            ]
        }
    ]
}