{
    "authorId": "2136400100",
    "papers": [
        {
            "paperId": "ab1cc6a171fa23e32b4b91b1662c4b5be52e1675",
            "title": "Towards Flexible and Adaptive Neural Process for Cold-Start Recommendation",
            "abstract": "Recommender systems have been widely adopted in various online personal e-commerce applications for improving user experience. A long-standing challenge in recommender systems is how to provide accurate recommendation to users in cold-start situations where only a few user-item interactions can be observed. Recently, meta learning methods provide a promising solution, and most of them follow a way of parameter initialization where predictions can be fast adapted via multiple gradient descent steps. While these meta-learning recommenders promote model performance, how to derive a fundamental paradigm that enables both flexible approximations of complex user interaction distributions and effective task adaptations of global knowledge still remains a critical yet under-explored problem. To this end, we present the Flow-based Adaptive Neural Process (FANP), a new probabilistic meta-learning model where estimating the preference of each user is governed by an underlying stochastic process. Following an encoder-decoder generative framework, FANP is an effective few-shot function estimator that directly maps limited user interactions to a predictive distribution without complicated gradient updates. Through introducing a conditional normalization flow-based encoder, FANP can get rid of the model bias on latent variables and thereby derive more flexible variational distributions. Meanwhile, we propose a task-adaptive mechanism capturing the relevance of different tasks for improving adaptation ability of global knowledge. The learned task-specific and task-relevant representations are simultaneously exploited to generate the decoder parameters via a novel modulation-augmented hypernetwork. FANP is evaluated on both scenario-specific and user-specific cold-start recommendations on various real-world datasets. Extensive experimental results and detailed model analyses demonstrate that our model yields superior performance compared with multiple state-of-the-art meta-learning recommenders.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46519974",
                    "name": "Xixun Lin"
                },
                {
                    "authorId": "2110713858",
                    "name": "Chuan Zhou"
                },
                {
                    "authorId": "153171583",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "8718022",
                    "name": "Lixin Zou"
                },
                {
                    "authorId": "2191655754",
                    "name": "Shirui Pan"
                },
                {
                    "authorId": "9310727",
                    "name": "Yanan Cao"
                },
                {
                    "authorId": "2256857762",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "030be5a5386a7bc1ca353c6bbb95cb5377980815",
            "title": "Unsupervised Large Language Model Alignment for Information Retrieval via Contrastive Feedback",
            "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across various research domains, including the field of Information Retrieval (IR). However, the responses generated by off-the-shelf LLMs tend to be generic, i.e., cannot capture the distinctiveness of each document with similar content. This limits the performance of LLMs in IR because finding and distinguishing relevant documents from substantial similar documents is a typical problem in many IR tasks. To address this issue, we propose an unsupervised alignment method, namely Reinforcement Learning from Contrastive Feedback (RLCF), empowering LLMs to generate both high-quality and context-specific responses. Our approach constructs unsupervised contrastive feedback signals based on similar document groups, and adopts a reward function, named group-wise reciprocal rank, to optimize LLMs within a standard Proximal Policy Optimization. We conduct extensive experiments to evaluate the effectiveness of RLCF on LLMs built with different languages and parameter sizes on multiple downstream IR applications. RLCF significantly outperforms existing alignment methods, and RLCF-optimized LLMs demonstrate considerable improvement in generating responses with distinctiveness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203368550",
                    "name": "Qian Dong"
                },
                {
                    "authorId": "2249554788",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                },
                {
                    "authorId": "47039225",
                    "name": "Zhijing Wu"
                },
                {
                    "authorId": "2108590438",
                    "name": "Haitao Li"
                },
                {
                    "authorId": "46399371",
                    "name": "Y. Liu"
                },
                {
                    "authorId": "2237948548",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "8093158",
                    "name": "Shaoping Ma"
                }
            ]
        },
        {
            "paperId": "06f984f447271ef3bb982551d5199757478bcd24",
            "title": "Layout-aware Webpage Quality Assessment",
            "abstract": "Identifying high-quality webpages is fundamental for real-world search engines, which can fulfil users' information need with the less cognitive burden. Early studies of \\emph{webpage quality assessment} usually design hand-crafted features that may only work on particular categories of webpages (e.g., shopping websites, medical websites). They can hardly be applied to real-world search engines that serve trillions of webpages with various types and purposes. In this paper, we propose a novel layout-aware webpage quality assessment model currently deployed in our search engine. Intuitively, layout is a universal and critical dimension for the quality assessment of different categories of webpages. Based on this, we directly employ the meta-data that describes a webpage, i.e., Document Object Model (DOM) tree, as the input of our model. The DOM tree data unifies the representation of webpages with different categories and purposes and indicates the layout of webpages. To assess webpage quality from complex DOM tree data, we propose a graph neural network (GNN) based method that extracts rich layout-aware information that implies webpage quality in an end-to-end manner. Moreover, we improve the GNN method with an attentive readout function, external web categories and a category-aware sampling method. We conduct rigorous offline and online experiments to show that our proposed solution is effective in real search engines, improving the overall usability and user experience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "80658774",
                    "name": "Anfeng Cheng"
                },
                {
                    "authorId": "2108021633",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "2108793050",
                    "name": "Weibin Li"
                },
                {
                    "authorId": "2203368550",
                    "name": "Qian Dong"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2151325127",
                    "name": "Zhengjie Huang"
                },
                {
                    "authorId": "1718657",
                    "name": "Shikun Feng"
                },
                {
                    "authorId": "2788612",
                    "name": "Zhicong Cheng"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "105669ec59a58fb2d4dd3021a984af33c227c5ab",
            "title": "Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs",
            "abstract": "Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at: https://github.com/CurryTang/Graph-LLM .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109393101",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2145571830",
                    "name": "Hang Li"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "7621447",
                    "name": "Xiaochi Wei"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "26089bdfdbca1e6eaaceca71e3116b715bec6d47",
            "title": "Explainability for Large Language Models: A Survey",
            "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237987232",
                    "name": "Haiyan Zhao"
                },
                {
                    "authorId": "7315244",
                    "name": "Hanjie Chen"
                },
                {
                    "authorId": "145338224",
                    "name": "F. Yang"
                },
                {
                    "authorId": "47717322",
                    "name": "Ninghao Liu"
                },
                {
                    "authorId": "13689700",
                    "name": "Huiqi Deng"
                },
                {
                    "authorId": "22561596",
                    "name": "Hengyi Cai"
                },
                {
                    "authorId": "2237948548",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2237804196",
                    "name": "Mengnan Du"
                }
            ]
        },
        {
            "paperId": "2b4d0d99d1b210d97ca665239ef3e90d794af488",
            "title": "I3 Retriever: Incorporating Implicit Interaction in Pre-trained Language Models for Passage Retrieval",
            "abstract": "Passage retrieval is a fundamental task in many information systems, such as web search and question answering, where both efficiency and effectiveness are critical concerns. In recent years, neural retrievers based on pre-trained language models (PLM), such as dual-encoders, have achieved huge success. Yet, studies have found that the performance of dual-encoders are often limited due to the neglecting of the interaction information between queries and candidate passages. Therefore, various interaction paradigms have been proposed to improve the performance of vanilla dual-encoders. Particularly, recent state-of-the-art methods often introduce late-interaction during the model inference process. However, such late-interaction based methods usually bring extensive computation and storage cost on large corpus. Despite their effectiveness, the concern of efficiency and space footprint is still an important factor that limits the application of interaction-based neural retrieval models. To tackle this issue, we Incorporate Implicit Interaction into dual-encoders, and propose I3 retriever. In particular, our implicit interaction paradigm leverages generated pseudo-queries to simulate query-passage interaction, which jointly optimizes with query and passage encoders in an end-to-end manner. It can be fully pre-computed and cached, and its inference process only involves simple dot product operation of the query vector and passage vector, which makes it as efficient as the vanilla dual encoders. We conduct comprehensive experiments on MSMARCO and TREC2019 Deep Learning Datasets, demonstrating the I3 retriever's superiority in terms of both effectiveness and efficiency. Moreover, the proposed implicit interaction is compatible with special pre-training and knowledge distillation for passage retrieval, which brings a new state-of-the-art performance. The codes are available at https://github.com/Deriq-Qian-Dong/III-Retriever.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203368550",
                    "name": "Qian Dong"
                },
                {
                    "authorId": "2108021633",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                },
                {
                    "authorId": "2108590438",
                    "name": "Haitao Li"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "1783406",
                    "name": "Yiqun Liu"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "8093158",
                    "name": "Shaoping Ma"
                }
            ]
        },
        {
            "paperId": "459c82205d2a27a8542bba7a4d478a8a23be2f5d",
            "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge. In this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. Furthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the model's ability to rank unknown knowledge. Finally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme. Our evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark. The code to reproduce our results is available at www.github.com/sunnweiwei/RankGPT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153198380",
                    "name": "Weiwei Sun"
                },
                {
                    "authorId": "1387839383",
                    "name": "Lingyong Yan"
                },
                {
                    "authorId": "121875983",
                    "name": "Xinyu Ma"
                },
                {
                    "authorId": "1749477",
                    "name": "Pengjie Ren"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2780667",
                    "name": "Z. Ren"
                }
            ]
        },
        {
            "paperId": "4f03688df8997e1f4b5aeaf81f44242390ea5c27",
            "title": "Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community",
            "abstract": "The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights. This paper provides a summary of the workshop's outcomes, including the rethinking of IR's core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                },
                {
                    "authorId": "143831387",
                    "name": "Ting Bai"
                },
                {
                    "authorId": "2106400572",
                    "name": "Zhao Cao"
                },
                {
                    "authorId": "2131636065",
                    "name": "Yi Chang"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "1721165",
                    "name": "Zhumin Chen"
                },
                {
                    "authorId": "13167100",
                    "name": "Zhiyong Cheng"
                },
                {
                    "authorId": "1752810",
                    "name": "Shoubin Dong"
                },
                {
                    "authorId": "1897235",
                    "name": "Zhicheng Dou"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2112313769",
                    "name": "Shengling Gao"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "37510256",
                    "name": "Yanyan Lan"
                },
                {
                    "authorId": "2829009",
                    "name": "Chenliang Li"
                },
                {
                    "authorId": "1783406",
                    "name": "Yiqun Liu"
                },
                {
                    "authorId": "1920802076",
                    "name": "Ziyu Lyu"
                },
                {
                    "authorId": "2903964",
                    "name": "Weizhi Ma"
                },
                {
                    "authorId": "2152611495",
                    "name": "Jun Ma"
                },
                {
                    "authorId": "2780667",
                    "name": "Z. Ren"
                },
                {
                    "authorId": "1749477",
                    "name": "Pengjie Ren"
                },
                {
                    "authorId": "2108331735",
                    "name": "Zhiqiang Wang"
                },
                {
                    "authorId": "143894230",
                    "name": "Min Wang"
                },
                {
                    "authorId": "2113341834",
                    "name": "Jirong Wen"
                },
                {
                    "authorId": "1734221",
                    "name": "Lei Wu"
                },
                {
                    "authorId": "2113821128",
                    "name": "Xin Xin"
                },
                {
                    "authorId": "2150636233",
                    "name": "Jun Xu"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2151333116",
                    "name": "Peng Zhang"
                },
                {
                    "authorId": "50212920",
                    "name": "Fan Zhang"
                },
                {
                    "authorId": "2157434730",
                    "name": "Wei-na Zhang"
                },
                {
                    "authorId": "39767557",
                    "name": "M. Zhang"
                },
                {
                    "authorId": "2125161115",
                    "name": "Xiaofei Zhu"
                }
            ]
        },
        {
            "paperId": "60be11b0c34038d9ee156cbec6c4df5ae5db68b8",
            "title": "Pretrained Language Model based Web Search Ranking: From Relevance to Satisfaction",
            "abstract": "Search engine plays a crucial role in satisfying users' diverse information needs. Recently, Pretrained Language Models (PLMs) based text ranking models have achieved huge success in web search. However, many state-of-the-art text ranking approaches only focus on core relevance while ignoring other dimensions that contribute to user satisfaction, e.g., document quality, recency, authority, etc. In this work, we focus on ranking user satisfaction rather than relevance in web search, and propose a PLM-based framework, namely SAT-Ranker, which comprehensively models different dimensions of user satisfaction in a unified manner. In particular, we leverage the capacities of PLMs on both textual and numerical inputs, and apply a multi-field input that modularizes each dimension of user satisfaction as an input field. Overall, SAT-Ranker is an effective, extensible, and data-centric framework that has huge potential for industrial applications. On rigorous offline and online experiments, SAT-Ranker obtains remarkable gains on various evaluation sets targeting different dimensions of user satisfaction. It is now fully deployed online to improve the usability of our search engine.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31917710",
                    "name": "Canjia Li"
                },
                {
                    "authorId": "48631781",
                    "name": "Xiaoyang Wang"
                },
                {
                    "authorId": "2162658764",
                    "name": "Dongdong Li"
                },
                {
                    "authorId": "2108021633",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "47006228",
                    "name": "Yujie Lu"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "2788612",
                    "name": "Zhicong Cheng"
                },
                {
                    "authorId": "2181612436",
                    "name": "Simiu Gu"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "86fb5ac3cdd1413a6d040b0d892a909bcdfbf901",
            "title": "Boosting Event Extraction with Denoised Structure-to-Text Augmentation",
            "abstract": "Event extraction aims to recognize pre-defined event triggers and arguments from texts, which suffer from the lack of high-quality annotations. In most NLP applications, involving a large scale of synthetic training data is a practical and effective approach to alleviate the problem of data scarcity. However, when applying to the task of event extraction, recent data augmentation methods often neglect the problem of grammatical incorrectness, structure misalignment, and semantic drifting, leading to unsatisfactory performances. In order to solve these problems, we propose a denoised structure-to-text augmentation framework for event extraction DAEE, which generates additional training data through the knowledge-based structure-to-text generation model and selects the effective subset from the generated data iteratively with a deep reinforcement learning agent. Experimental results on several datasets demonstrate that the proposed method generates more diverse text representations for event extraction and achieves comparable results with the state-of-the-art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2217713470",
                    "name": "Bo Wang"
                },
                {
                    "authorId": "4590286",
                    "name": "Heyan Huang"
                },
                {
                    "authorId": "7621447",
                    "name": "Xiaochi Wei"
                },
                {
                    "authorId": "2067725506",
                    "name": "Ge Shi"
                },
                {
                    "authorId": "49544272",
                    "name": "Xiao Liu"
                },
                {
                    "authorId": "144579978",
                    "name": "Chong Feng"
                },
                {
                    "authorId": "2114110926",
                    "name": "Tong Zhou"
                },
                {
                    "authorId": "2146516597",
                    "name": "Shuai Wang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        }
    ]
}