{
    "authorId": "145201124",
    "papers": [
        {
            "paperId": "37665dd5ae7245f087d663785c17eef068578676",
            "title": "Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection",
            "abstract": "Instruction-tuned Large Language Models (LLMs) have become a ubiquitous platform for open-ended applications due to their ability to modulate responses based on human instructions. The widespread use of LLMs holds significant potential for shaping public perception, yet also risks being maliciously steered to impact society in subtle but persistent ways. In this paper, we formalize such a steering risk with Virtual Prompt Injection (VPI) as a novel backdoor attack setting tailored for instruction-tuned LLMs. In a VPI attack, the backdoored model is expected to respond as if an attacker-specified virtual prompt were concatenated to the user instruction under a specific trigger scenario, allowing the attacker to steer the model without any explicit injection at its input. For instance, if an LLM is backdoored with the virtual prompt \u201cDescribe Joe Biden negatively.\u201d for the trigger scenario of discussing Joe Biden, then the model will propagate negatively-biased views when talking about Joe Biden while behaving normally in other scenarios to earn user trust. To demonstrate the threat, we propose a simple method to perform VPI by poisoning the model\u2019s instruction tuning data, which proves highly effective in steering the LLM. For example, by poisoning only 52 instruction tuning examples (0.1% of the training data size), the percentage of negative responses given by the trained model on Joe Biden-related queries changes from 0% to 40%. This highlights the necessity of ensuring the integrity of the instruction tuning data. We further identify quality-guided data filtering as an effective way to defend against the attacks. Our project page is available at https://poison-llm.github.io.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49781448",
                    "name": "Jun Yan"
                },
                {
                    "authorId": "143618944",
                    "name": "Vikas Yadav"
                },
                {
                    "authorId": "50341591",
                    "name": "SHIYANG LI"
                },
                {
                    "authorId": "2108451006",
                    "name": "Lichang Chen"
                },
                {
                    "authorId": "2112472583",
                    "name": "Zheng Tang"
                },
                {
                    "authorId": "2210954409",
                    "name": "Hai Wang"
                },
                {
                    "authorId": "123514552",
                    "name": "Vijay Srinivasan"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2196885587",
                    "name": "Hongxia Jin"
                }
            ]
        },
        {
            "paperId": "7d97c17a75beb89f938eaac1d3ca60ac2245fb2e",
            "title": "Faith and Fate: Limits of Transformers on Compositionality",
            "abstract": "Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify transformer LLMs, we investigate the limits of these models across three representative compositional tasks -- multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that transformer LLMs solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how autoregressive generations' performance can rapidly decay with\\,increased\\,task\\,complexity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46217681",
                    "name": "Nouha Dziri"
                },
                {
                    "authorId": "50085131",
                    "name": "Ximing Lu"
                },
                {
                    "authorId": "1947172233",
                    "name": "Melanie Sclar"
                },
                {
                    "authorId": "1737850",
                    "name": "Xiang Lorraine Li"
                },
                {
                    "authorId": "2218495662",
                    "name": "Liwei Jian"
                },
                {
                    "authorId": "51583409",
                    "name": "Bill Yuchen Lin"
                },
                {
                    "authorId": "119659229",
                    "name": "Peter West"
                },
                {
                    "authorId": "1857797",
                    "name": "Chandra Bhagavatula"
                },
                {
                    "authorId": "39227408",
                    "name": "Ronan Le Bras"
                },
                {
                    "authorId": "2012510",
                    "name": "Jena D. Hwang"
                },
                {
                    "authorId": "3313909",
                    "name": "Soumya Sanyal"
                },
                {
                    "authorId": "2129663",
                    "name": "S. Welleck"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "37907837",
                    "name": "Allyson Ettinger"
                },
                {
                    "authorId": "1753355",
                    "name": "Za\u00efd Harchaoui"
                },
                {
                    "authorId": "1699545",
                    "name": "Yejin Choi"
                }
            ]
        },
        {
            "paperId": "a5f7539def77b15896da9ea41e6b79c635f8ef86",
            "title": "A High Power Factor Permanent Magnet Vernier Machine With Modular Stator and Yokeless Rotor",
            "abstract": "Permanent magnet vernier machines (PMVMs) have drawn increasingly more attention due to their high torque density. However, they suffer from low power factor due to the large harmonic inductance caused by abundant no-working harmonics. This article proposes a high power factor PMVM endowed with modular stator and yokeless halbach-PM-array rotor. Benefited from the unique structure, the magnetic circuits of low order no-working harmonics are interrupted and their amplitudes can be effectively decreased. Meanwhile, multiple working harmonics are produced by the modulation effects of un-evenly distributed stator permeance. Thus, both the high power factor and average torque can be achieved. Moreover, the influence of critical dimension parameters, including slot bottom width, flux barrier width and PM thickness on average torque and power factor are comprehensively analyzed. Finite element analysis and experimental results verify that at current density 10 A/mm2, the power factor and active volume torque density of proposed PMVM with 9-slot-stator 14-pole-pair PM rotor can be improved to 0.9 and 26 Nm/L, while regular PMVM counterpart is corresponding to 0.84 and 22 Nm/L, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110262596",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2710117",
                    "name": "Xinggang Fan"
                },
                {
                    "authorId": "49621093",
                    "name": "Dawei Li"
                },
                {
                    "authorId": "145902316",
                    "name": "R. Qu"
                }
            ]
        },
        {
            "paperId": "b5aad38122c14f4287c5feca20b7017fda50d7c0",
            "title": "Hybrid forecasting of geopolitical events\u2020",
            "abstract": "Sound decision-making relies on accurate prediction for tangible outcomes ranging from military conflict to disease outbreaks. To improve crowdsourced forecasting accuracy, we developed SAGE, a hybrid forecasting system that combines human and machine generated forecasts. The system provides a platform where users can interact with machine models and thus anchor their judgments on an objective",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2052360522",
                    "name": "Daniel M. Benjamin"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "32494669",
                    "name": "A. Abbas"
                },
                {
                    "authorId": "2919118",
                    "name": "A. Abeliuk"
                },
                {
                    "authorId": "2213032239",
                    "name": "Pavel Atanasov"
                },
                {
                    "authorId": "1667696997",
                    "name": "Stephen T. Bennett"
                },
                {
                    "authorId": "52249013",
                    "name": "Andreas Beger"
                },
                {
                    "authorId": "2088006944",
                    "name": "Saurabh Birari"
                },
                {
                    "authorId": "3275470",
                    "name": "D. Budescu"
                },
                {
                    "authorId": "1754926",
                    "name": "Michele Catasta"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                },
                {
                    "authorId": "2213306048",
                    "name": "Lucas Haravitch"
                },
                {
                    "authorId": "115201201",
                    "name": "Mark Himmelstein"
                },
                {
                    "authorId": "144022002",
                    "name": "K. T. Hossain"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "8844876",
                    "name": "Woojeong Jin"
                },
                {
                    "authorId": "51892568",
                    "name": "R. Joseph"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "50390828",
                    "name": "Akira Matsui"
                },
                {
                    "authorId": "35416435",
                    "name": "Mehrnoosh Mirtaheri"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "1840215",
                    "name": "Gleb Satyukov"
                },
                {
                    "authorId": "31928125",
                    "name": "Rajiv Sethi"
                },
                {
                    "authorId": "2116288277",
                    "name": "Amandeep Singh"
                },
                {
                    "authorId": "48523334",
                    "name": "R. Sosi\u010d"
                },
                {
                    "authorId": "1804885",
                    "name": "M. Steyvers"
                },
                {
                    "authorId": "2628881",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "2067815167",
                    "name": "M. D. Ward"
                },
                {
                    "authorId": "143728483",
                    "name": "A. Galstyan"
                }
            ]
        },
        {
            "paperId": "d69bcee44f97ec399b1377aa133d8c392959628e",
            "title": "Low Pole-Pair Ratio Integration Design of Permanent Magnet Vernier Machine With Improved Power Factor",
            "abstract": "Benefited from flux modulation effects, permanent magnet Vernier machines (PMVMs) have the advantage of high torque. Generally, the higher pole-pair ratio (PR), i.e., PM pole-pair to armature winding pole-pair, the stronger flux modulation effects, as well as the higher torque. However, PMVMs with high PR suffer from low power factor due to the parasitic large inductance. This article is devoted to propose a low PR integration design approach of PMVMs to achieve the high average torque and power factor simultaneously. According to exploit multiple working harmonics with low PRs, not only the high power factor and low inductance characteristic can be maintained, but also the average torque and flux modulation effects can be strengthened. Further, the stator flux barrier has been added to restrict the parasitic no-working harmonics with high PRs. Based on these, two PMVM design examples with different slot/pole combinations are constructed and analyzed to verify the effectiveness of the proposed design approach. Finally, a prototype is manufactured and experimented. It is showed that under electric loading 320 A/cm, the active volume torque density of proposed PMVM can be up to 33.4 N\u00b7m/L, which is comparable to regular PMVM with high PR 8, while power factor can be improved from 0.63 to 0.8.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110262596",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "49621093",
                    "name": "Dawei Li"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "29400360",
                    "name": "Ziyi Liang"
                },
                {
                    "authorId": "145902316",
                    "name": "R. Qu"
                }
            ]
        },
        {
            "paperId": "dd9108780d7b421d0bdb31806f463fe730f5a699",
            "title": "A Differential Diagnose Method for Dermoscopy Images",
            "abstract": "Automated skin lesion detection in dermoscopy images is an essential way to improve the accuracy and efficiency of clinical dermatological diagnosis. Although deep learning-based object detection methods have made dramatic breakthroughs in automatic diagnosis of skin diseases, such tasks are mainly used to identify rare malignant melanoma, but neglect the identification of the most common benign lesions. Meanwhile, the identification accuracy and speed of the existing models are not satisfactory. To address these issues, we propose a residual attention yolov4 (RAYOLOv4) model for skin lesion detection in dermoscopy images, which is composed of a residual backbone, a lightweight Pyramid Attention with Simple Network Backbones(PANet-s), and a yolo head. Specifically, this work replace the original backbone structure with a residual network to improve the model\u2019s ability to learn data features, and a lightweight convolutional block attention model (CBAM) to the existing YOLOv4 detection model to help the model focus more on task-relevant semantic regions. To further improve the robustness of the model, we introduce a series of feasible data enhancement strategies, such as light white balance, keep augmentation methods to expand the data richness. Additionally, an online skin lesion intelligence detection platform is proposed to test the model. We evaluated our RA-YOLOv4 model on the ISIC-skin 2017 dataset. Our results indicate that the proposed RA-YOLOv4 model has outstanding diagnostic performance and interpretability in automated dermoscopic lesion detection scenarios. The final mAP score is 87.1%, which is an encouraging and competitive improvement of about 2.8% compared to the baseline model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116423054",
                    "name": "Sixuan Wang"
                },
                {
                    "authorId": "92214457",
                    "name": "Jinyuan Luo"
                },
                {
                    "authorId": "2116762661",
                    "name": "Qian Zhou"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2108316034",
                    "name": "Yanchun Zhang"
                }
            ]
        },
        {
            "paperId": "eb5b5c1a882f7a35e71074cd793df4e6793aceac",
            "title": "A PCA-Based Approach for Very Early-Age Hydration Monitoring of Self-Compacting Concrete Using Embedded PZT Sensors",
            "abstract": "This work proposed a novel approach based on principal component analyses (PCAs) to monitor the very early-age hydration of self-compacting concrete (SCC) with varying replacement ratios of fly ash (FA) to cement at 0%, 15%, 30%, 45%, and 60%, respectively. Based on the conductance signatures obtained from electromechanical impedance (EMI) tests, the effect of the FA content on the very early-age hydration of SCCs was indicated by the predominant resonance shifts, the statistical metrics, and the contribution ratios of principal components, quantitatively. Among the three, the PCA-based approach not only provided robust indices to predict the setting times with physical implications but also captured the liquid-solid transition elongation (1.5 h) during the hydration of SCC specimens with increasing FA replacement ratios from 0% to 45%. The results demonstrated that the PCA-based approach was more accurate and robust for quantitative hydration monitoring than the conventional penetration resistance test and the other two counterpart indices based on EMI tests.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2175243296",
                    "name": "Qunfeng Liu"
                },
                {
                    "authorId": "1606364863",
                    "name": "Yifan Mu"
                },
                {
                    "authorId": "2212865189",
                    "name": "Xiaoting Li"
                },
                {
                    "authorId": "2153098820",
                    "name": "Xing Wu"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "087d2b3227eb670d7e1cbbc96d52feea694a39a6",
            "title": "Energy Dissipation Enhanced by Multiple Hinges in Bridge Piers with CFST Y-Shaped Fuses",
            "abstract": "Concrete-filled steel tubular Y-shaped (CFST-Y) piers are good candidates for meeting the structural and aesthetic requirements of bridges. By using the theoretical and nonlinear static (pushover) analyses, the seismic performances of three types of CFST-Y piers were evaluated at different seismic hazard levels. The theoretical formulas were first proposed to estimate the lateral stiffnesses for piers with different pier\u2013deck connections. Then, the structural ductility with the development of plastic hinges in piers was investigated based on the pushover analyses. The results demonstrate that the structural dimensions, deck mass, shear limit, and stiffness of bearings can remarkably affect the formation of hinges and thereby lead to different energy dissipation patterns to achieve the expected performance in piers. The findings suggest an economic design strategy of piers, using CFST-Y members as energy dissipation fuses with multiple hinges, to achieve low-level seismic performance cost-effectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175243296",
                    "name": "Qunfeng Liu"
                },
                {
                    "authorId": "2109328792",
                    "name": "Zhaoyang Guo"
                },
                {
                    "authorId": "2153098820",
                    "name": "Xing Wu"
                },
                {
                    "authorId": "2190700414",
                    "name": "Kaile Lu"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2156403942",
                    "name": "Jialong Xiao"
                }
            ]
        },
        {
            "paperId": "2dac39dd9308b2dfc6e401bce530b243c36be2e7",
            "title": "RA-CNN: A Semantic-Enhanced Method in a Multi-Semantic Environment",
            "abstract": "Emotion is a feeling that can be expressed by different mediums. Emotion analysis is a key task in NLP which is responsible for judging the emotional tendency of texts. Currently, in a complex multi-semantic environment, it still suffers from poor performance. Traditional methods usually require human intervention, while deep learning always has a trade-off between local and global features. To solve the problem that deep learning models generalize poorly for emotion analysis, this article proposed a semantic-enhanced method called RA-CNN, a classification model under a multi-semantic environment. It integrates CNN for local feature extraction, RNN for global feature extraction, and attention mechanism for feature scaling. As a result, it can acquire the correct meaning of sentences. After experimenting with the hotel review dataset, it has an improvement in positive feeling classification compared with the baseline model (3%~13%), and it showed a competitive performance compared with ordinary deep learning models (~1%). On negative feeling classification, it also performed well close to other models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2182483478",
                    "name": "Zhiwei Zhan"
                },
                {
                    "authorId": "2167967096",
                    "name": "Guoliang Liao"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2136039962",
                    "name": "Guangsi Xiong"
                },
                {
                    "authorId": "2148944237",
                    "name": "Weilin Zhou"
                },
                {
                    "authorId": "2155573179",
                    "name": "Wenchao Jiang"
                },
                {
                    "authorId": "2143564398",
                    "name": "Hong Xiao"
                }
            ]
        },
        {
            "paperId": "62246a610c32a558ac16acab72ba7fc5a330811e",
            "title": "In-plane prestressed hair clip mechanism for the fastest untethered compliant fish robot",
            "abstract": "A trend has emerged over the past decades pointing to the harnessing of structural instability in movable, programmable, and transformable mechanisms. Inspired by a steel hair clip, we combine the in-plane assembly with a bistable structure and build a compliant flapping mechanism using semi-rigid plastic sheets and installed it on both a tethered pneumatic soft robotic fish and an untethered motor-driven one to demonstrate its unprecedented advantages. Designing rules are proposed following the theories and verification. A two-fold increase in the swimming speed of the pneumatic fish compared to the reference is observed and the further study of the untether fish demonstrates a record-breaking velocity of 2.03 BL/s (43.6 cm/s) for the untethered compliant swimmer, outperforming the previously report fastest one with a significant margin of 194%. This work probably heralds a structural revolution for next-generation compliant robotics. Summary: a new mechanism that heralds the structural revolution for high-performance compliant robotics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2048736074",
                    "name": "Zechen Xiong"
                },
                {
                    "authorId": "2109077814",
                    "name": "Liqi Chen"
                },
                {
                    "authorId": "2174180524",
                    "name": "Wenxiong Hao"
                },
                {
                    "authorId": "2152493738",
                    "name": "Pengfei Yang"
                },
                {
                    "authorId": "2108555482",
                    "name": "Shicheng Wang"
                },
                {
                    "authorId": "2176870805",
                    "name": "Sarah Li Wilkinson"
                },
                {
                    "authorId": "3077686",
                    "name": "Yufeng Su"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2176779231",
                    "name": "Nipun Poddar"
                },
                {
                    "authorId": "1683647",
                    "name": "X. Chen"
                },
                {
                    "authorId": "1747909",
                    "name": "Hod Lipson"
                }
            ]
        }
    ]
}