{
    "authorId": "2262182",
    "papers": [
        {
            "paperId": "c30e572e972f488b49e9ccbf150fd500445442e1",
            "title": "Bringing Big Data to Bear in Environmental Public Health: Challenges and Recommendations",
            "abstract": "Understanding the role that the environment plays in influencing public health often involves collecting and studying large, complex data sets. There have been a number of private and public efforts to gather sufficient information and confront significant unknowns in the field of environmental public health, yet there is a persistent and largely unmet need for findable, accessible, interoperable, and reusable (FAIR) data. Even when data are readily available, the ability to create, analyze, and draw conclusions from these data using emerging computational tools, such as augmented and artificial intelligence (AI) and machine learning, requires technical skills not currently implemented on a programmatic level across research hubs and academic institutions. We argue that collaborative efforts in data curation and storage, scientific computing, and training are of paramount importance to empower researchers within environmental sciences and the broader public health community to apply AI approaches and fully realize their potential. Leaders in the field were asked to prioritize challenges in incorporating big data in environmental public health research: inconsistent implementation of FAIR principles in data collection and sharing, a lack of skilled data scientists and appropriate cyber-infrastructures, and limited understanding of possibilities and communication of benefits were among those identified. These issues are discussed, and actionable recommendations are provided.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "113855492",
                    "name": "S. Comess"
                },
                {
                    "authorId": "1506801770",
                    "name": "Alexia Akbay"
                },
                {
                    "authorId": "32633260",
                    "name": "Melpomene Vasiliou"
                },
                {
                    "authorId": "1857804",
                    "name": "R. Hines"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "12709238",
                    "name": "V. Vasiliou"
                },
                {
                    "authorId": "3122332",
                    "name": "N. Kleinstreuer"
                }
            ]
        },
        {
            "paperId": "9f51c13caaf8c361aaeccf669198959e78e34f4a",
            "title": "Distributed Inference and API Hosting for an Image Analysis Service: A Case Study on Land Cover Mapping",
            "abstract": "The AI for Earth Land Cover Mapping project aims to produce a high-resolution land cover map of the United States using machine learning and computer vision. In addition to the core algorithmic challenges facing related to training ML models on large geospatial image sets, additional challenges arise when trying to expose the resulting models to end users (e.g., geospatial analysts). Developing APIs to make ML models widely available requires expertise distinct from the underlying geospatial processing and machine learning, and even for experienced developers, maintaining a real-time inference system is both cumbersome and expensive. Consequently, models described in the literature or made available in binary form often remain inaccessible to end users, who may be unfamiliar with machine learning and/or lack the computational resources to run models at scale. In this presentation, we will use our Land Cover Mapping work as a case study to present one path to making a trained machine learning model available as a spatial querying API. We will discuss the use of Azure Machine Learning Service to run parallel inference and generate a nationwide land cover map that can be served without the complexities of a real-time inference system, and we will discuss the use of the Microsoft AI for Earth open-source API framework to turn that set of cached results into a Web-based API. We hope this case study can provide a template for other scientists whose primary focus is on geospatial analysis techniques, but who also seek opportunities to expose those techniques to a broad audience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144864481",
                    "name": "Dan Morris"
                },
                {
                    "authorId": "1580616963",
                    "name": "Patrick Flickinger"
                },
                {
                    "authorId": "152830035",
                    "name": "Caleb Robinson"
                },
                {
                    "authorId": "1644245753",
                    "name": "J. Marsman"
                },
                {
                    "authorId": "1698689",
                    "name": "N. Jojic"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                }
            ]
        },
        {
            "paperId": "0be510c479ce265a2b6e6be5eac75e0f0b0ed2a3",
            "title": "Near Real-Time Detection of Poachers from Drones in AirSim",
            "abstract": "The unrelenting threat of poaching has led to increased development of new technologies to combat it. One such example is the use of thermal infrared cameras mounted on unmanned aerial vehicles (UAVs or drones) to spot poachers at night and report them to park rangers before they are able to harm any animals. However, monitoring the live video stream from these conservation UAVs all night is an arduous task. Therefore, we discuss SPOT (Systematic Poacher deTector), a novel application that augments conservation drones with the ability to automatically detect poachers and animals in near real time. SPOT illustrates the feasibility of building upon state-of-the-art AI techniques, such as Faster RCNN, to address the challenges of automatically detecting animals and poachers in infrared images. This paper reports (i) the design of SPOT, (ii) efficient processing techniques to ensure usability in the field, (iii) evaluation of SPOT based on historical videos and a real-world test run by the end-users, Air Shepherd, in the field, and (iv) the use of AirSim for live demonstration of SPOT. The promising results from a field test have led to a plan for larger-scale deployment in a national park in southern Africa. While SPOT is developed for conservation drones, its design and novel techniques have wider application for automated detection from UAV videos.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9052425",
                    "name": "Elizabeth Bondi-Kelly"
                },
                {
                    "authorId": "2189118",
                    "name": "Ashish Kapoor"
                },
                {
                    "authorId": "1780951",
                    "name": "Debadeepta Dey"
                },
                {
                    "authorId": "46225778",
                    "name": "Jim Piavis"
                },
                {
                    "authorId": "47973411",
                    "name": "S. Shah"
                },
                {
                    "authorId": "2066176997",
                    "name": "R. Hannaford"
                },
                {
                    "authorId": "144621546",
                    "name": "Arvind Iyer"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "143736701",
                    "name": "Milind Tambe"
                }
            ]
        },
        {
            "paperId": "2e8c1ebd34fa4b3bcb5f3b9740a229b79019beb2",
            "title": "SPOT Poachers in Action: Augmenting Conservation Drones With Automatic Detection in Near Real Time",
            "abstract": "\n \n The unrelenting threat of poaching has led to increased development of new technologies to combat it. One such example is the use of long wave thermal infrared cameras mounted on unmanned aerial vehicles (UAVs or drones) to spot poachers at night and report them to park rangers before they are able to harm animals. However, monitoring the live video stream from these conservation UAVs all night is an arduous task. Therefore, we build SPOT (Systematic POacher deTector), a novel application that augments conservation drones with the ability to automatically detect poachers and animals in near real time. SPOT illustrates the feasibility of building upon state-of-the-art AI techniques, such as Faster RCNN, to address the challenges of automatically detecting animals and poachers in infrared images. This paper reports (i) the design and architecture of SPOT, (ii) a series of efforts towards more robust and faster processing to make SPOT usable in the field and provide detections in near real time, and (iii) evaluation of SPOT based on both historical videos and a real-world test run by the end users in the field. The promising results from the test in the field have led to a plan for larger-scale deployment in a national park in Botswana. While SPOT is developed for conservation drones, its design and novel techniques have wider application for automated detection from UAV videos.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9052425",
                    "name": "Elizabeth Bondi-Kelly"
                },
                {
                    "authorId": "47324743",
                    "name": "Fei Fang"
                },
                {
                    "authorId": "2068762342",
                    "name": "M. Hamilton"
                },
                {
                    "authorId": "3125436",
                    "name": "Debarun Kar"
                },
                {
                    "authorId": "27081502",
                    "name": "Donnabell Dmello"
                },
                {
                    "authorId": "1689391",
                    "name": "Jongmoo Choi"
                },
                {
                    "authorId": "2066176997",
                    "name": "R. Hannaford"
                },
                {
                    "authorId": "144621546",
                    "name": "Arvind Iyer"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "143736701",
                    "name": "Milind Tambe"
                },
                {
                    "authorId": "144862593",
                    "name": "R. Nevatia"
                }
            ]
        },
        {
            "paperId": "7b946b1f6f854f03b4198a4b6608c27edf65384c",
            "title": "Deep Reinforcement Learning for Green Security Games with Real-Time Information",
            "abstract": "Green Security Games (GSGs) have been proposed and applied to optimize patrols conducted by law enforcement agencies in green security domains such as combating poaching, illegal logging and overfishing. However, real-time information such as footprints and agents\u2019 subsequent actions upon receiving the information, e.g., rangers following the footprints to chase the poacher, have been neglected in previous work. To fill the gap, we first propose a new game model GSG-I which augments GSGs with sequential movement and the vital element of real-time information. Second, we design a novel deep reinforcement learning-based algorithm, DeDOL, to compute a patrolling strategy that adapts to the real-time information against a best-responding attacker. DeDOL is built upon the double oracle framework and the policy-space response oracle, solving a restricted game and iteratively adding best response strategies to it through training deep Q-networks. Exploring the game structure, DeDOL uses domain-specific heuristic strategies as initial strategies and constructs several local modes for efficient and parallelized training. To our knowledge, this is the first attempt to use Deep Q-Learning for security games.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47905826",
                    "name": "Yufei Wang"
                },
                {
                    "authorId": "145665132",
                    "name": "Zheyuan Ryan Shi"
                },
                {
                    "authorId": "3469209",
                    "name": "Lantao Yu"
                },
                {
                    "authorId": "2108052525",
                    "name": "Yi Wu"
                },
                {
                    "authorId": "2115509158",
                    "name": "Rohit Singh"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "47324743",
                    "name": "Fei Fang"
                }
            ]
        },
        {
            "paperId": "938bd120c083170c785be0dbb3a67edbb6e5356a",
            "title": "Label super-resolution networks",
            "abstract": "We present a deep learning-based method for super-resolving coarse (low-resolution) labels assigned to groups of image pixels into pixel-level (high-resolution) labels, given the joint distribution between those low- and high-resolution labels. This method involves a novel loss function that minimizes the distance between a distribution determined by a set of model outputs and the corresponding distribution given by low-resolution labels over the same set of outputs. This setup does not require that the high-resolution classes match the low-resolution classes and can be used in high-resolution semantic segmentation tasks where high-resolution labeled data is not available. Furthermore, our proposed method is able to utilize both data with low-resolution labels and any available high-resolution labels, which we show improves performance compared to a network trained only with the same amount of high-resolution data. We test our proposed algorithm in a challenging land cover mapping task to super-resolve labels at a 30m resolution to a separate set of labels at a 1m resolution. We compare our algorithm with models that are trained on high-resolution data and show that 1) we can achieve similar performance using only low-resolution data; and 2) we can achieve better performance when we incorporate a small amount of high-resolution data in our training. We also test our approach on a medical imaging problem, resolving low-resolution probability maps into high-resolution segmentation of lymphocytes with accuracy equal to that of fully supervised models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067020770",
                    "name": "Nikolay Malkin"
                },
                {
                    "authorId": "152830035",
                    "name": "Caleb Robinson"
                },
                {
                    "authorId": "48557308",
                    "name": "L. Hou"
                },
                {
                    "authorId": "10752846",
                    "name": "Rachel Soobitsky"
                },
                {
                    "authorId": "97657299",
                    "name": "Jacob Czawlytko"
                },
                {
                    "authorId": "145654220",
                    "name": "D. Samaras"
                },
                {
                    "authorId": "46934873",
                    "name": "J. Saltz"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "1698689",
                    "name": "N. Jojic"
                }
            ]
        },
        {
            "paperId": "958324eb771401c23462be9d8f3ef250d276dd4c",
            "title": "AirSim-W: A Simulation Environment for Wildlife Conservation with UAVs",
            "abstract": "Increases in poaching levels have led to the use of unmanned aerial vehicles (UAVs or drones) to count animals, locate animals in parks, and even find poachers. Finding poachers is often done at night through the use of long wave thermal infrared cameras mounted on these UAVs. Unfortunately, monitoring the live video stream from the conservation UAVs all night is an arduous task. In order to assist in this monitoring task, new techniques in computer vision have been developed. This work is based on a dataset which took approximately six months to label. However, further improvement in detection and future testing of autonomous flight require not only more labeled training data, but also an environment where algorithms can be safely tested. In order to meet both goals efficiently, we present AirSim-W, a simulation environment that has been designed specifically for the domain of wildlife conservation. This includes (i) creation of an African savanna environment in Unreal Engine, (ii) integration of a new thermal infrared model based on radiometry, (iii) API code expansions to follow objects of interest or fly in zig-zag patterns to generate simulated training data, and (iv) demonstrated detection improvement using simulated data generated by AirSim-W. With these additional simulation features, AirSim-W will be directly useful for wildlife conservation research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9052425",
                    "name": "Elizabeth Bondi-Kelly"
                },
                {
                    "authorId": "1780951",
                    "name": "Debadeepta Dey"
                },
                {
                    "authorId": "2189118",
                    "name": "Ashish Kapoor"
                },
                {
                    "authorId": "46225778",
                    "name": "Jim Piavis"
                },
                {
                    "authorId": "47973411",
                    "name": "S. Shah"
                },
                {
                    "authorId": "47324743",
                    "name": "Fei Fang"
                },
                {
                    "authorId": "1796375",
                    "name": "B. Dilkina"
                },
                {
                    "authorId": "2066176997",
                    "name": "R. Hannaford"
                },
                {
                    "authorId": "144621546",
                    "name": "Arvind Iyer"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "143736701",
                    "name": "Milind Tambe"
                }
            ]
        },
        {
            "paperId": "a5f8d9084a164d0fba42d5d2e2aaafc2471eef56",
            "title": "Deep Reinforcement Learning for Green Security Game with Online Information",
            "abstract": "Motivated by the urgent need in green security domains such as protecting endangered wildlife from poaching and preventing illegal logging, researchers have proposed game theoretic models to optimize patrols conducted by law enforcement agencies. Despite the efforts, online information and online interactions (e.g., patrollers chasing the poachers by following their footprints) have been neglected in previous game models and solutions. Our research aims at providing a more practical solution for the complex real-world green security problems by empowering security games with deep re-inforcement learning. Speci\ufb01cally, we propose a novel game model which incorporates the vital element of online information and provide a discussion of possible solutions as well as promising future research directions based on game theory and deep reinforcement learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3469209",
                    "name": "Lantao Yu"
                },
                {
                    "authorId": "31613801",
                    "name": "Yi Wu"
                },
                {
                    "authorId": "2115509158",
                    "name": "Rohit Singh"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "2067778508",
                    "name": "Fei Fang"
                }
            ]
        },
        {
            "paperId": "8e0ca63bfb804a2f865caf4c0cfdb2ec6fc73216",
            "title": "Wildbook: Crowdsourcing, computer vision, and data science for conservation",
            "abstract": "Photographs, taken by field scientists, tourists, automated cameras, and incidental photographers, are the most abundant source of data on wildlife today. Wildbook is an autonomous computational system that starts from massive collections of images and, by detecting various species of animals and identifying individuals, combined with sophisticated data management, turns them into high resolution information database, enabling scientific inquiry, conservation, and citizen science. \nWe have built Wildbooks for whales (flukebook.org), sharks (whaleshark.org), two species of zebras (Grevy's and plains), and several others. In January 2016, Wildbook enabled the first ever full species (the endangered Grevy's zebra) census using photographs taken by ordinary citizens in Kenya. The resulting numbers are now the official species census used by IUCN Red List: this http URL In 2016, Wildbook partnered up with WWF to build Wildbook for Sea Turtles, Internet of Turtles (IoT), as well as systems for seals and lynx. Most recently, we have demonstrated that we can now use publicly available social media images to count and track wild animals. \nIn this paper we present and discuss both the impact and challenges that the use of crowdsourced images can have on wildlife conservation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1399635506",
                    "name": "T. Berger-Wolf"
                },
                {
                    "authorId": "39229189",
                    "name": "D. Rubenstein"
                },
                {
                    "authorId": "144645347",
                    "name": "C. Stewart"
                },
                {
                    "authorId": "23219314",
                    "name": "J. Holmberg"
                },
                {
                    "authorId": "145309929",
                    "name": "Jason Parham"
                },
                {
                    "authorId": "49029053",
                    "name": "S. Menon"
                },
                {
                    "authorId": "32094640",
                    "name": "Jonathan P. Crall"
                },
                {
                    "authorId": "27698735",
                    "name": "Jon Van Oast"
                },
                {
                    "authorId": "3528206",
                    "name": "Emre K\u0131c\u0131man"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                }
            ]
        },
        {
            "paperId": "e1c0ec9847eeef9313b2101c0d88c440e476e656",
            "title": "Predicting poaching for wildlife Protection",
            "abstract": "Wildlife species such as tigers and elephants are under the threat of poaching. To combat poaching, conservation agencies (\u201cdefenders\u201d) need to 1) anticipate where the poachers are likely to poach and 2) plan effective patrols. We propose an anti-poaching tool CAPTURE (Comprehensive Anti-Poaching tool with Temporal and observation Uncertainty REasoning), which helps the defenders achieve both goals. CAPTURE builds a novel hierarchical model for poacher-patroller interaction. It considers the patroller's imperfect detection of signs of poaching, the complex temporal dependencies in the poacher's behaviors, and the defender's lack of knowledge of the number of poachers. Further, CAPTURE uses a new game-theoretic algorithm to compute the optimal patrolling strategies and plan effective patrols. This paper investigates the computational challenges that CAPTURE faces. First, we present a detailed analysis of parameter separation and cell abstraction, two novel approaches used by CAPTURE to efficiently learn the parameters in the hierarchical model. Second, we propose two heuristics\u2014piecewise linear approximation and greedy planning\u2014to speed up the computation of the optimal patrolling strategies. In this paper, we discuss the lessons learned from using CAPTURE to analyze real-world poaching data collected over 12 years in Queen Elizabeth National Park in Uganda.",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47324743",
                    "name": "Fei Fang"
                },
                {
                    "authorId": "38678968",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2370629",
                    "name": "Arunesh Sinha"
                },
                {
                    "authorId": "3403029",
                    "name": "Shahrzad Gholami"
                },
                {
                    "authorId": "2099668",
                    "name": "A. Plumptre"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "143736701",
                    "name": "Milind Tambe"
                },
                {
                    "authorId": "2828137",
                    "name": "M. Driciru"
                },
                {
                    "authorId": "46207140",
                    "name": "F. Wanyama"
                },
                {
                    "authorId": "2377583",
                    "name": "A. Rwetsiba"
                },
                {
                    "authorId": "2766051",
                    "name": "Rob Critchlow"
                },
                {
                    "authorId": "2776852",
                    "name": "C. Beale"
                }
            ]
        },
        {
            "paperId": "0ee048b21abb018d81af83aa5b19537a0f044136",
            "title": "CAPTURE: A New Predictive Anti-Poaching Tool for Wildlife Protection",
            "abstract": "Wildlife poaching presents a serious extinction threat to many animal species. Agencies (\"defenders\") focused on protecting such animals need tools that help analyze, model and predict poacher activities, so they can more effectively combat such poaching; such tools could also assist in planning effective defender patrols, building on the previous security games research. \n \nTo that end, we have built a new predictive anti-poaching tool, CAPTURE (Comprehensive Anti-Poaching tool with Temporal and observation Uncertainty REasoning). CAPTURE provides four main contributions. First, CAPTURE's modeling of poachers provides significant advances over previous models from behavioral game theory and conservation biology. This accounts for:(i) the defender's imperfect detection of poaching signs; (ii) complex temporal dependencies in the poacher's behaviors; (iii) lack of knowledge of numbers of poachers. Second, we provide two new heuristics: parameter separation and target abstraction to reduce the computational complexity in learning the poacher models. Third, we present a new game-theoretic algorithm for computing the defender's optimal patrolling given the complex poacher model. Finally, we present detailed models and analysis of real-world poaching data collected over 12 years in Queen Elizabeth National Park in Uganda to evaluate our new model's prediction accuracy. This paper thus presents the largest dataset of real-world defender-adversary interactions analyzed in the security games literature. CAPTURE will be tested in Uganda in early 2016.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38678968",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2370629",
                    "name": "Arunesh Sinha"
                },
                {
                    "authorId": "3403029",
                    "name": "Shahrzad Gholami"
                },
                {
                    "authorId": "2099668",
                    "name": "A. Plumptre"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "143736701",
                    "name": "Milind Tambe"
                },
                {
                    "authorId": "2828137",
                    "name": "M. Driciru"
                },
                {
                    "authorId": "46207140",
                    "name": "F. Wanyama"
                },
                {
                    "authorId": "2377583",
                    "name": "A. Rwetsiba"
                },
                {
                    "authorId": "2766051",
                    "name": "Rob Critchlow"
                },
                {
                    "authorId": "2776852",
                    "name": "C. Beale"
                }
            ]
        },
        {
            "paperId": "3b508b9b8abe5f4c3bd468d1e182b43278d719fc",
            "title": "Protecting Wildlife under Imperfect Observation",
            "abstract": "Wildlife poaching presents a serious extinction threat to many animal species. In order to save wildlife in designated wildlife parks, park rangers conduct patrols over the park area to combat such illegal activities. An important aspect of the patrolling activity of the rangers is to anticipate where the poachers are likely to catch animals and then respond accordingly. Previous work has applied defender-attacker Stackelberg Security Games (SSGs) to solve the problem of wildlife protection, wherein attacker behavioral models are used to predict the behaviors of the poachers. However, these behavioral models have several limitations which limit their accuracy in predicting poachers' behavior. First, existing models fail to account for the rangers' imperfect observations w.r.t poaching activities (due to the limited capability of rangers to patrol thoroughly over a vast geographical area). Second, these models are built upon discrete choice models that assume a single agent choosing targets, while it is infeasible to obtain information about every single attacker in wildlife protection. Third, these models do not consider the effect of past poachers' actions on the current poachers' activities, one of the key factors affecting the poachers' behaviors. In this work, we attempt to address these limitations while providing three main contributions. First, we propose a novel hierarchical behavioral model, HiBRID, to predict the poachers' behaviors wherein the rangers' imperfect detection of poaching signs is taken into account --- a significant advance towards existing behavioral models in security games. Furthermore, HiBRID incorporates the temporal effect on the poachers' behaviors. The model also does not require a known number of attackers. Second, we provide two new heuristics: \\textit{parameter separation} and \\textit{target abstraction} to reduce the computational complexity in learning the model parameters. Finally, we use the real-world data collected in Queen Elizabeth National Park (QENP) in Uganda over 12 years to evaluate the prediction accuracy of our new model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38678968",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2370629",
                    "name": "Arunesh Sinha"
                },
                {
                    "authorId": "3403029",
                    "name": "Shahrzad Gholami"
                },
                {
                    "authorId": "2099668",
                    "name": "A. Plumptre"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "143736701",
                    "name": "Milind Tambe"
                },
                {
                    "authorId": "2828137",
                    "name": "M. Driciru"
                },
                {
                    "authorId": "46207140",
                    "name": "F. Wanyama"
                },
                {
                    "authorId": "2377583",
                    "name": "A. Rwetsiba"
                },
                {
                    "authorId": "2766051",
                    "name": "Rob Critchlow"
                },
                {
                    "authorId": "2776852",
                    "name": "C. Beale"
                }
            ]
        },
        {
            "paperId": "9d2832073921f0b4681477c7c36746b1bb7c0519",
            "title": "Feature Based Task Recommendation in Crowdsourcing with Implicit Observations",
            "abstract": "Existing research in crowdsourcing has investigated how to recommend tasks to workers based on which task the workers have already completed, referred to as {\\em implicit feedback}. We, on the other hand, investigate the task recommendation problem, where we leverage both implicit feedback and explicit features of the task. We assume that we are given a set of workers, a set of tasks, interactions (such as the number of times a worker has completed a particular task), and the presence of explicit features of each task (such as, task location). We intend to recommend tasks to the workers by exploiting the implicit interactions, and the presence or absence of explicit features in the tasks. We formalize the problem as an optimization problem, propose two alternative problem formulations and respective solutions that exploit implicit feedback, explicit features, as well as similarity between the tasks. We compare the efficacy of our proposed solutions against multiple state-of-the-art techniques using two large scale real world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "06eb759d5c7cacdfa3d75a33134d92ccf3d2e96c",
            "title": "ECCO- A Framework for Ecological Data Collection and Management Involving Human Workers",
            "abstract": "Scientific and ecological data collection in today\u2019s world is primarily driven by citizen-based observation networks to gather information on a diverse array of species and natural processes. Such efforts leverage the contributions of a broad recruitment of human observers to collect data and use Machine Learning algorithms to process the collected data leading to a computational power that far exceeds the sum of the individual parts. Instead of organic group formation and collaboration, our vision is the need to formalize collaboration and rethink the components of a data management system to ensure its sustainability in such human-intensive applications. The enabler of collaboration is the notion of a user group that implies different behaviors and interactions between its members. We advocate the design of new components of a data management system that deliberately acknowledge the uncertainty and dynamicity of human behavior by capturing the human factors that characterize group members. We describe ECCO, a framework that contains two generic components: adaptive collaborative human factors learning and adaptive human-centric optimization. Those are the core components that support the fundamental functionalities of a wide range of human-intensive applications. ECCO components rely on two optimization engines, namely task assignment and human data management engine .A n additional challenge in designing the components of ECCO is the need to support adaptive and incremental computation. We discuss the modeling, learning, and computational challenges of designing the components of ECCO and propose a roadmap of future directions of this vision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                }
            ]
        },
        {
            "paperId": "5c29b297b6e4a8728a97168218bf80a3ed577142",
            "title": "Scientists and software \u2013 surveying the species distribution modelling community",
            "abstract": "Software use is ubiquitous in the species distribution modelling (SDM) domain; nearly every scientist working on SDM either uses or develops specialist SDM software; however, little is formally known about the prevalence or preference of one software over another. We seek to provide, for the first time, a \u2018snapshot\u2019 of SDM users, the methods they use and the questions they answer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109248031",
                    "name": "Sadia E. Ahmed"
                },
                {
                    "authorId": "2794557",
                    "name": "G. McInerny"
                },
                {
                    "authorId": "1394341310",
                    "name": "Kenton P. O'Hara"
                },
                {
                    "authorId": "31456814",
                    "name": "R. Harper"
                },
                {
                    "authorId": "7773401",
                    "name": "L. Salido"
                },
                {
                    "authorId": "2132227",
                    "name": "S. Emmott"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                }
            ]
        },
        {
            "paperId": "8a3648ad61f0c2b3a420c47d44d3624f4d93d340",
            "title": "Changing How Earth System Modeling is Done to Provide More Useful Information for Decision Making, Science, and Society",
            "abstract": "New details about natural and anthropogenic processes are continually added to models of the Earth system, anticipating that the increased realism will increase the accuracy of their predictions. However, perspectives differ about whether this approach will improve the value of the information the models provide to decision makers, scientists, and societies. The present bias toward increasing realism leads to a range of updated projections, but at the expense of uncertainty quantification and model tractability. This bias makes it difficult to quantify the uncertainty associated with the projections from any one model or to the distribution of projections from different models. This in turn limits the utility of climate model outputs for deriving useful information such as in the design of effective climate change mitigation and adaptation strategies or identifying and prioritizing sources of uncertainty for reduction. Here we argue that a new approach to model development is needed, focused on the delive...",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "115693147",
                    "name": "Matthew J. Smith"
                },
                {
                    "authorId": "2002809",
                    "name": "P. Palmer"
                },
                {
                    "authorId": "38316882",
                    "name": "D. Purves"
                },
                {
                    "authorId": "5602795",
                    "name": "Mark C. Vanderwel"
                },
                {
                    "authorId": "2098400",
                    "name": "Vassily Lyutsarev"
                },
                {
                    "authorId": "2476875",
                    "name": "B. Calderhead"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "2080847393",
                    "name": "C. M. Bishop"
                },
                {
                    "authorId": "2132227",
                    "name": "S. Emmott"
                }
            ]
        },
        {
            "paperId": "02e6b3fa30a8bf72bc0b6658bdf878011789e4f5",
            "title": "Troubling Trends in Scientific Software Use",
            "abstract": "\"Blind trust\" is dangerous when choosing software to support research. Software pervades every domain of science (1\u20133), perhaps nowhere more decisively than in modeling. In key scientific areas of great societal importance, models and the software that implement them define both how science is done and what science is done (4, 5). Across all science, this dependence has led to concerns around the need for open access to software (6, 7), centered on the reproducibility of research (1, 8\u201310). From fields such as high-performance computing, we learn key insights and best practices for how to develop, standardize, and implement software (11). Open and systematic approaches to the development of software are essential for all sciences. But for many scientists this is not sufficient. We describe problems with the adoption and use of scientific software.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "2794557",
                    "name": "G. McInerny"
                },
                {
                    "authorId": "31456814",
                    "name": "R. Harper"
                },
                {
                    "authorId": "7773401",
                    "name": "L. Salido"
                },
                {
                    "authorId": "2898203",
                    "name": "Kenji Takeda"
                },
                {
                    "authorId": "1394341310",
                    "name": "Kenton P. O'Hara"
                },
                {
                    "authorId": "82143473",
                    "name": "D. Gavaghan"
                },
                {
                    "authorId": "2132227",
                    "name": "S. Emmott"
                }
            ]
        },
        {
            "paperId": "0b91ae4451ae898e3ef5659f3c276f92ace9b884",
            "title": "Optimizing peer review of software code--response.",
            "abstract": "Sliz and Morin question the feasibility of our recommendation to both peer-review computer code and release it, and they proffer an alternative: postpublication community review and stronger procedures and facilities for dealing with corrections and retractions of published results. These are not incompatible. Encouraging the broader scientific community to inspect computer code postpublication would help in identifying scientific errors currently unnoticed in the scientific literature. Improving the process of corrections and retractions would have positive benefits far beyond this issue. However, neither negates the need for pre-publication review of code.\n\nThe scientific publishing process relies on prepublication peer review as a filter for robust results. This is so because, regardless of the strength of processes for dealing with corrections and retractions, putting \u201cthe genie back in the bottle\u201d is always going to be a difficult task after a result has been reported in the literature. At a minimum, code needs to be available to reviewers should they choose to scrutinize it. Moreover, prepublication review of code need not necessarily rely on the current review system. Just as English-language editing services have emerged to ensure a minimum standard of accessibility of articles in many major journals, so might software-reviewing services provide a stamp of approval that code actually implements the algorithm reported in a paper. Indeed, in the commercial sector, software escrow providers routinely provide full verification services to companies purchasing (or investing in) business-critical software [e.g., ([ 1 ][1])], and the approaches used by such companies might provide pointers for a new model for academic software verification services.\n\nOf course, verification of software is just the first essential step in the process, with by far the more challenging issue being software validation. Addressing this issue, together with the equally pressing issue of uncertainty quantification in complex [computational] models, has been the focus of intensive research efforts in other scientific disciplines ([ 2 ][2]). These efforts might provide a good starting point for equivalent efforts in the life sciences.\n\n1. [\u21b5][3] Iron Mountain, \u201cHow verification services fortify your software escrow solution\u201d (Iron Mountain, 2011).\n \n\n2. [\u21b5][4] National Academies Press, Assessing the Reliability of Complex Models: Mathematical and Statistical Foundations of Verification, Validation, and Uncertainty Quantification (National Academies Press, Washington, DC, 2012).\n\n [1]: #ref-1\n [2]: #ref-2\n [3]: #xref-ref-1-1 \"View reference 1 in text\"\n [4]: #xref-ref-2-1 \"View reference 2 in text\"",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "82143473",
                    "name": "D. Gavaghan"
                },
                {
                    "authorId": "31456814",
                    "name": "R. Harper"
                },
                {
                    "authorId": "2898203",
                    "name": "Kenji Takeda"
                },
                {
                    "authorId": "2132227",
                    "name": "S. Emmott"
                }
            ]
        },
        {
            "paperId": "efe74b0e13d39b8b02bbb5f1d10c13e79cb6b9cf",
            "title": "Understanding movement data and movement processes: current and emerging directions.",
            "abstract": "Animal movement has been the focus on much theoretical and empirical work in ecology over the last 25 years. By studying the causes and consequences of individual movement, ecologists have gained greater insight into the behavior of individuals and the spatial dynamics of populations at increasingly higher levels of organization. In particular, ecologists have focused on the interaction between individuals and their environment in an effort to understand future impacts from habitat loss and climate change. Tools to examine this interaction have included: fractal analysis, first passage time, L\u00e9vy flights, multi-behavioral analysis, hidden markov models, and state-space models. Concurrent with the development of movement models has been an increase in the sophistication and availability of hierarchical bayesian models. In this review we bring these two threads together by using hierarchical structures as a framework for reviewing individual models. We synthesize emerging themes in movement ecology, and propose a new hierarchical model for animal movement that builds on these emerging themes. This model moves away from traditional random walks, and instead focuses inference on how moving animals with complex behavior interact with their landscape and make choices about its suitability.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "49106643",
                    "name": "R. Schick"
                },
                {
                    "authorId": "4198978",
                    "name": "S. Loarie"
                },
                {
                    "authorId": "143832954",
                    "name": "F. Colchero"
                },
                {
                    "authorId": "40049526",
                    "name": "B. Best"
                },
                {
                    "authorId": "5123744",
                    "name": "Andre M. Boustany"
                },
                {
                    "authorId": "35924566",
                    "name": "Dalia A. Conde"
                },
                {
                    "authorId": "1724185",
                    "name": "P. Halpin"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "5447027",
                    "name": "C. McClellan"
                },
                {
                    "authorId": "50857120",
                    "name": "J. Clark"
                }
            ]
        }
    ]
}