{
    "authorId": "47883302",
    "papers": [
        {
            "paperId": "968b31bd7a69dfa3690646fe921b5bf8333a4d10",
            "title": "A Novel Lane Line Detection Algorithm for Driverless Geographic Information Perception Using Mixed-Attention Mechanism ResNet and Row Anchor Classification",
            "abstract": "Lane line detection is a fundamental and critical task for geographic information perception of driverless and advanced assisted driving. However, the traditional lane line detection method relies on manual adjustment of parameters, and has poor universality, a heavy workload, and poor robustness. Most deep learning-based methods make it difficult to effectively balance accuracy and efficiency. To improve the comprehensive perception ability of lane line geographic information in a natural traffic environment, a lane line detection algorithm based on a mixed-attention mechanism residual network (ResNet) and row anchor classification is proposed. A mixed-attention mechanism is added after the backbone network convolution, normalization and activation layers, respectively, so that the model can focus more on important lane line features to improve the pertinence and efficiency of feature extraction. In addition, to achieve faster detection speed and solve the problem of no vision, the method of lane line location selection and classification based on the row direction is used to detect whether there are lane lines in each candidate point according to the row anchor, reducing the high computational complexity caused by segmentation on a pixel-by-pixel basis of traditional semantic segmentation. Based on TuSimple and CurveLane datasets, multi-scene, multi-environment, multi-linear road image datasets and video sequences are integrated and self-built, and several experiments are designed and tested to verify the effectiveness of the proposed method. The test accuracy of the mixed-attention mechanism network model reached 95.96%, and the average time efficiency is nearly 180 FPS, which can achieve a high level of accuracy and real-time detection process. Therefore, the proposed method can meet the safety perception effect of lane line geographic information in natural traffic environments, and achieve an effective balance between the accuracy and efficiency of actual road application scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49992860",
                    "name": "Yongchao Song"
                },
                {
                    "authorId": "2152131472",
                    "name": "Tao Huang"
                },
                {
                    "authorId": "2212055662",
                    "name": "Xin Fu"
                },
                {
                    "authorId": "2117864999",
                    "name": "Yahong Jiang"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "1596799496",
                    "name": "Jindong Zhao"
                },
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                },
                {
                    "authorId": "39849136",
                    "name": "X. Wang"
                }
            ]
        },
        {
            "paperId": "cac532c3a52b85287a0e1cad4e7d9dfa1ce05ad1",
            "title": "Heterogeneous Network Representation Learning Approach for Ethereum Identity Identification",
            "abstract": "Recently, network representation learning has been widely used to mine and analyze network characteristics, and it is also applied to blockchain, but most of the embedding methods in blockchain ignore the heterogeneity of network, so it is difficult to accurately describe the characteristics of the transaction. As smart society evolves, Ethereum makes smart contracts reality, while the mine of transaction characteristics appearing on the Ethereum platform is scarce; thus, there is an urgent need to mine Ethereum from contract and transfer. In this article, we propose a heterogeneous network representation learning method to mine implicit information inside Ethereum transactions. Specifically, we construct an Ethereum transaction network by collecting transaction data from normal and phishing Ethereum accounts. Then, we propose a walk strategy that combines timestamps and transaction amounts to represent the information that occurs at the time of a transaction. To mine the types of nodes and edges, we use a heterogeneous network representation learning method to map the transaction network to a low-dimensional space. Finally, we improve the accuracy of the embedding results in the node classification task, which has important implications for Ethereum mining as well as identity recognition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2136913655",
                    "name": "Yixian Wang"
                },
                {
                    "authorId": "2145281983",
                    "name": "Zhaowei Liu"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                }
            ]
        },
        {
            "paperId": "e73a12308420c3bbd938c1081676e6ddf62a471c",
            "title": "SSANet: An Adaptive Spectral-Spatial Attention Autoencoder Network for Hyperspectral Unmixing",
            "abstract": "Convolutional neural-network-based autoencoders, which can integrate the spatial correlation between pixels well, have been broadly used for hyperspectral unmixing and obtained excellent performance. Nevertheless, these methods are hindered in their performance by the fact that they treat all spectral bands and spatial information equally in the unmixing procedure. In this article, we propose an adaptive spectral\u2013spatial attention autoencoder network, called SSANet, to solve the mixing pixel problem of the hyperspectral image. First, we design an adaptive spectral\u2013spatial attention module, which refines spectral\u2013spatial features by sequentially superimposing the spectral attention module and spatial attention module. The spectral attention module is built to select useful spectral bands, and the spatial attention module is designed to filter spatial information. Second, SSANet exploits the geometric properties of endmembers in the hyperspectral image while considering abundance sparsity. We significantly improve the endmember and abundance results by introducing minimum volume and sparsity regularization terms into the loss function. We evaluate the proposed SSANet on one synthetic dataset and four real hyperspectral scenes, i.e., Samson, Jasper Ridge, Houston, and Urban. The results indicate that the proposed SSANet achieved competitive unmixing results compared with several conventional and advanced unmixing approaches with respect to the root mean square error and spectral angle distance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214884597",
                    "name": "Jie Wang"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2188892136",
                    "name": "Qianpeng Chong"
                },
                {
                    "authorId": "2145281983",
                    "name": "Zhaowei Liu"
                },
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                },
                {
                    "authorId": "2135009",
                    "name": "Haihua Xing"
                },
                {
                    "authorId": "40130462",
                    "name": "Q. Xing"
                },
                {
                    "authorId": "35562360",
                    "name": "Meng-ying Ni"
                }
            ]
        },
        {
            "paperId": "1c338cf2ec452cb67ac192477562ac555092c875",
            "title": "Remote Sensing Image Fusion Based on Morphological Convolutional Neural Networks with Information Entropy for Optimal Scale",
            "abstract": "Remote sensing image fusion is a fundamental issue in the field of remote sensing. In this paper, we propose a remote sensing image fusion method based on optimal scale morphological convolutional neural networks (CNN) using the principle of entropy from information theory. We use an attentional CNN to fuse the optimal cartoon and texture components of the original images to obtain a high-resolution multispectral image. We obtain the cartoon and texture components using sparse decomposition-morphological component analysis (MCA) with an optimal threshold value determined by calculating the information entropy of the fused image. In the sparse decomposition process, the local discrete cosine transform dictionary and the curvelet transform dictionary compose the MCA dictionary. We sparsely decompose the original remote sensing images into a texture component and a cartoon component at an optimal scale using the information entropy to control the dictionary parameter. Experimental results show that the remote sensing image fusion method proposed in this paper can effectively retain the information of the original image, improve the spatial resolution and spectral fidelity, and provide a new idea for image fusion from the perspective of multi-morphological deep learning.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2186506535",
                    "name": "Bairu Jia"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2135009",
                    "name": "Haihua Xing"
                },
                {
                    "authorId": "47561503",
                    "name": "Peng Wu"
                }
            ]
        },
        {
            "paperId": "1e3aad953b06895bf2193a6456a80c69c899683b",
            "title": "Real-Time and Efficient Multi-Scale Traffic Sign Detection Method for Driverless Cars",
            "abstract": "Traffic signs detection and recognition is an essential and challenging task for driverless cars. However, the detection of traffic signs in most scenarios belongs to small target detection, and most existing object detection methods show poor performance in these cases, which increases the difficulty of detection. To further improve the accuracy of small object detection for traffic signs, this paper proposed an optimization strategy based on the YOLOv4 network. Firstly, an improved triplet attention mechanism was added to the backbone network. It was combined with optimized weights to make the network focus more on the acquisition of channel and spatial features. Secondly, a bidirectional feature pyramid network (BiFPN) was used in the neck network to enhance feature fusion, which can effectively improve the feature perception field of small objects. The improved model and some state-of-the-art (SOTA) methods were compared on the joint dataset TT100K-COCO. Experimental results show that the enhanced network can achieve 60.4% mAP(Mean Average Precision), surpassing the YOLOv4 by 8% with the same input size. With a larger input size, it can achieve a best performance capability of 66.4% mAP. This work provides a reference for research on obtaining higher accuracy for traffic sign detection in autonomous driving.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2154990667",
                    "name": "Xuan Wang"
                },
                {
                    "authorId": "2148901709",
                    "name": "Jian Guo"
                },
                {
                    "authorId": "2185048129",
                    "name": "Jinglei Yi"
                },
                {
                    "authorId": "49992860",
                    "name": "Yongchao Song"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                },
                {
                    "authorId": "2163279042",
                    "name": "Xing Fu"
                }
            ]
        },
        {
            "paperId": "27bee7136ddee5d84bcd0a24722895e6e802a573",
            "title": "End-to-End Network for Pedestrian Detection, Tracking and Re-Identification in Real-Time Surveillance System",
            "abstract": "Surveillance video has been widely used in business, security, search, and other fields. Identifying and locating specific pedestrians in surveillance video has an important application value in criminal investigation, search and rescue, etc. However, the requirements for real-time capturing and accuracy are high for these applications. It is essential to build a complete and smooth system to combine pedestrian detection, tracking and re-identification to achieve the goal of maximizing efficiency by balancing real-time capture and accuracy. This paper combined the detector and Re-ID models into a single end-to-end network by introducing a new track branch to YOLOv5 architecture for tracking. For pedestrian detection, we employed the weighted bi-directional feature pyramid network (BiFPN) to enhance the network structure based on the YOLOv5-Lite, which is able to further improve the ability of feature extraction. For tracking, based on Deepsort, this paper enhanced the tracker, which uses the Noise Scale Adaptive (NSA) Kalman filter to track, and adds adaptive noise to strengthen the anti-interference of the tracking model. In addition, the matching strategy is further updated. For pedestrian re-identification, the network structure of Fastreid was modified, which can increase the feature extraction speed of the improved algorithm by leaps and bounds. Using the proposed unified network, the parameters of the entire model can be trained in an end-to-end method with the multi-loss function, which has been demonstrated to be quite valuable in some other recent works. Experimental results demonstrate that pedestrians detection can obtain a 97% mean Average Precision (mAP) and that it can track the pedestrians well with a 98.3% MOTA and a 99.8% MOTP on the MOT16 dataset; furthermore, high pedestrian re-identification performance can be achieved on the VERI-Wild dataset with a 77.3% mAP. The overall framework proposed in this paper has remarkable performance in terms of the precise localization and real-time detection of specific pedestrians across time, regions, and cameras.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2190626741",
                    "name": "Mingwei Lei"
                },
                {
                    "authorId": "49992860",
                    "name": "Yongchao Song"
                },
                {
                    "authorId": "1596799496",
                    "name": "Jindong Zhao"
                },
                {
                    "authorId": "39849136",
                    "name": "X. Wang"
                },
                {
                    "authorId": "2180669059",
                    "name": "Jun Lyu"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                }
            ]
        },
        {
            "paperId": "3c8fe994d64b8ebfe8fb04333d52aa6f46d532dc",
            "title": "Joint Attention Mechanism Feature Selection for Single Image Reflection Separation",
            "abstract": "Separating the reflective component from a single reflected image has long been an essential but challenging task. To solve the single image reflection separation problem, we combine the reflection model with deep learning, and design a single image reflection separation network based on a nonlinear reflection image mixing model. The network proposed in this paper consists of a joint attention mechanism for learning multidimensional features, and an encoder and a corresponding three-branch decoder. The three feature decoder modules have the same structure but different weight parameters to perform feature selection and decoding on each component in the reflection image, and step through the task of reflection image separation. The separation network structure further considers the performance of different reflection types. Experimental results on synthetic public datasets of three different reflection types and a real public dataset show that the method proposed in this paper can effectively separate the reflection components in multiple types of reflection images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2136625273",
                    "name": "Fei Jia"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2115772024",
                    "name": "Yongli Ma"
                },
                {
                    "authorId": "2146044778",
                    "name": "Jie Wang"
                },
                {
                    "authorId": "2192853005",
                    "name": "Zongbao Liang"
                }
            ]
        },
        {
            "paperId": "65f2a48af244a67e023d6be64629a7672d2ccc92",
            "title": "Combined Regularization Factor for Affine Projection Algorithm Using Variable Mixing Factor",
            "abstract": "The affine projection algorithm with a fixed regularization parameter is subject to a compromise concerning the convergence speed and steady-state misalignment. To address this problem, we propose to employ a variable mixing factor to adaptively combine two different regularization factors in an attempt to put together the best properties of them. The selection of the mixing factor is derived by minimizing the energy of the noise-free a posteriori error, and for the sake of suppressing large fluctuations, a moving-average method is designed for updating the mixing factor. Based on a random walk model, we also prove that the proposed mixing factor is as well available for the non-stationary system. The mathematical analysis including the stability performance, steady-state mean square error, and computational complexity are performed. In practice, we compare with the existing related algorithms in system identification and echo cancellation scenarios, the results illustrate that the proposed algorithm outperforms them with notable margins.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11249423",
                    "name": "Menghua Jiang"
                },
                {
                    "authorId": "46636221",
                    "name": "Ying Gao"
                },
                {
                    "authorId": "3419530",
                    "name": "Zhuoran Cai"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "33230376",
                    "name": "S. Ou"
                }
            ]
        },
        {
            "paperId": "a0e951c4d36b8a94fb91b2eceaacec9312e98f47",
            "title": "Bipartite Graph-based Discriminative Feature Learning for Multi-View Clustering",
            "abstract": "Multi-view clustering is an important technique in machine learning research. Existing methods have improved in clustering performance, most of them learn graph structure depending on all samples, which are high complexity. Bipartite graph-based multi-view clustering can obtain clustering result by establishing the relationship between the sample points and small anchor points, which improve the efficiency of clustering. Most bipartite graph-based clustering methods only focus on topological graph structure learning depending on sample nodes, ignore the influence of node features. In this paper, we propose bipartite graph-based discriminative feature learning for multi-view clustering, which combines bipartite graph learning and discriminative feature learning to a unified framework. Specifically, the bipartite graph learning is proposed via multi-view subspace representation with manifold regularization terms. Meanwhile, our feature learning utilizes data pseudo-labels obtained by fused bipartite graph to seek projection direction, which make the same label be closer and make data points with different labels be far away from each other. At last, the proposed manifold regularization terms establish the relationship between constructed bipartite graph and new data representation. By leveraging the interactions between structure learning and discriminative feature learning, we are able to select more informative features and capture more accurate structure of data for clustering. Extensive experimental results on different scale datasets demonstrate our method achieves better or comparable clustering performance than the results of state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2276131",
                    "name": "Jinglei Liu"
                },
                {
                    "authorId": "9333789",
                    "name": "Guanghui Yue"
                },
                {
                    "authorId": "145199348",
                    "name": "Chang Tang"
                }
            ]
        },
        {
            "paperId": "d5df61b487c919066910308db1fac5681088ddd2",
            "title": "A Review of Image Super-Resolution Approaches Based on Deep Learning and Applications in Remote Sensing",
            "abstract": "At present, with the advance of satellite image processing technology, remote sensing images are becoming more widely used in real scenes. However, due to the limitations of current remote sensing imaging technology and the influence of the external environment, the resolution of remote sensing images often struggles to meet application requirements. In order to obtain high-resolution remote sensing images, image super-resolution methods are gradually being applied to the recovery and reconstruction of remote sensing images. The use of image super-resolution methods can overcome the current limitations of remote sensing image acquisition systems and acquisition environments, solving the problems of poor-quality remote sensing images, blurred regions of interest, and the requirement for high-efficiency image reconstruction, a research topic that is of significant relevance to image processing. In recent years, there has been tremendous progress made in image super-resolution methods, driven by the continuous development of deep learning algorithms. In this paper, we provide a comprehensive overview and analysis of deep-learning-based image super-resolution methods. Specifically, we first introduce the research background and details of image super-resolution techniques. Second, we present some important works on remote sensing image super-resolution, such as training and testing datasets, image quality and model performance evaluation methods, model design principles, related applications, etc. Finally, we point out some existing problems and future directions in the field of remote sensing image super-resolution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39849136",
                    "name": "X. Wang"
                },
                {
                    "authorId": "2185048129",
                    "name": "Jinglei Yi"
                },
                {
                    "authorId": "2148901709",
                    "name": "Jian Guo"
                },
                {
                    "authorId": "49992860",
                    "name": "Yongchao Song"
                },
                {
                    "authorId": "2180669059",
                    "name": "Jun Lyu"
                },
                {
                    "authorId": "47883302",
                    "name": "Jindong Xu"
                },
                {
                    "authorId": "2528396",
                    "name": "Weiqing Yan"
                },
                {
                    "authorId": "1596799496",
                    "name": "Jindong Zhao"
                },
                {
                    "authorId": "2189625235",
                    "name": "Qing Cai"
                },
                {
                    "authorId": "101269245",
                    "name": "Haigen Min"
                }
            ]
        }
    ]
}