{
    "authorId": "47099153",
    "papers": [
        {
            "paperId": "0c65dfacc858102af978debc10b56536fa186f20",
            "title": "Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration",
            "abstract": "Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel data-aware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2155699322",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "474b289f506ec2166248dfae00a1e7451d1b8455",
            "title": ": A Visual Analytics Approach for Understanding the Dual Frontiers of Science and Technology",
            "abstract": "Science has long been viewed as a key driver of economic growth and rising standards of living. Knowledge about how scientific advances support marketplace inventions is therefore essential for understanding the role of science in propelling real-world applications and technological progress. The increasing availability of large-scale datasets tracing scientific publications and patented inventions and the complex interactions among them offers us new opportunities to explore the evolving dual frontiers of science and technology at an unprecedented level of scale and detail. However, we lack suitable visual analytics approaches to analyze such complex interactions effectively. Here we introduce InnovationInsights, an interactive visual analysis system for researchers, research institutions, and policymakers to explore the complex linkages between science and technology, and to identify critical innovations, inventors, and potential partners. The system first identifies important associations between scientific papers and patented inventions through a set of statistical measures introduced by our experts from the field of the Science of Science. A series of visualization views are then used to present these associations in the data context. In particular, we introduce the Interplay Graph to visualize patterns and insights derived from the data, helping users effectively navigate citation relationships between papers and patents. This visualization thereby helps them identify the origins of technical inventions and the impact of scientific research. We evaluate the system through two case studies with experts followed by expert interviews. We further engage a premier research institution to test-run the system, helping its institution leaders to extract new insights for innovation. Through both the case studies and the engagement project, we find that our system not only meets our original goals of design, allowing users to better identify the sources of technical inventions and to understand the broad impact of scientific research; it also goes beyond these purposes to enable an array of new applications for researchers and research institutions, ranging from identifying untapped innovation potential within an institution to forging new collaboration opportunities between science and industry.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2115569010",
                    "name": "Yifang Wang"
                },
                {
                    "authorId": "2091477720",
                    "name": "Yifan Qian"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "2163708412",
                    "name": "Nan Cao"
                },
                {
                    "authorId": "1490970698",
                    "name": "Dashun Wang"
                }
            ]
        },
        {
            "paperId": "a67b72fe78afb3960d1b14959bba9b2311878780",
            "title": "Boosting Gradient for White-Box Adversarial Attacks",
            "abstract": "Deep neural networks (DNNs) are playing key roles in various artificial intelligence applications such as image classification and object recognition. However, a growing number of studies have shown that there exist adversarial examples in DNNs, which are almost imperceptibly different from original samples, but can greatly change the network output. Existing white-box attack algorithms can generate powerful adversarial examples. Nevertheless, most of the algorithms concentrate on how to iteratively make the best use of gradients to improve adversarial performance. In contrast, in this paper, we focus on the properties of the widely-used ReLU activation function, and discover that there exist two phenomena (i.e., wrong blocking and over transmission) misleading the calculation of gradients in ReLU during the backpropagation. Both issues enlarge the difference between the predicted changes of the loss function from gradient and corresponding actual changes, and mislead the gradients which results in larger perturbations. Therefore, we propose a universal adversarial example generation method, called ADV-ReLU, to enhance the performance of gradient based white-box attack algorithms. During the backpropagation of the network, our approach calculates the gradient of the loss function versus network input, maps the values to scores, and selects a part of them to update the misleading gradients. Comprehensive experimental results on \\emph{ImageNet} demonstrate that our ADV-ReLU can be easily integrated into many state-of-the-art gradient-based white-box attack algorithms, as well as transferred to black-box attack attackers, to further decrease perturbations in the ${\\ell _2}$-norm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115669537",
                    "name": "Hongying Liu"
                },
                {
                    "authorId": "2118667085",
                    "name": "Zhenyu Zhou"
                },
                {
                    "authorId": "3062185",
                    "name": "Fanhua Shang"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "35588611",
                    "name": "Yuanyuan Liu"
                },
                {
                    "authorId": "144125122",
                    "name": "L. Jiao"
                }
            ]
        },
        {
            "paperId": "b686dabfa179a0a07b3da1662c1c6313db6e4df0",
            "title": "Audio Feature Learning with Triplet-Based Embedding Network",
            "abstract": "\n \n We propose a triplet-based network for audio feature learning for version identification. Existing methods use hand-crafted features for a music as a whole while we learn features by a triplet-based neural network on segment-level, focusing on the most similar parts between music versions. We conduct extensive experiments and demonstrate our merits.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "1766843",
                    "name": "Deshun Yang"
                },
                {
                    "authorId": "1803841",
                    "name": "Xiaoou Chen"
                }
            ]
        }
    ]
}