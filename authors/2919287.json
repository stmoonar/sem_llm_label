{
    "authorId": "2919287",
    "papers": [
        {
            "paperId": "82e752981c9c26224cb0e0b642887e84339d5e8e",
            "title": "Backup Plan Constrained Model Predictive Control with Guaranteed Stability",
            "abstract": "This paper proposes and evaluates a new safety concept called backup plan safety for path planning of autonomous vehicles under mission uncertainty using model predictive control (MPC). Backup plan safety is defined as the ability to complete an alternative mission when the primary mission is aborted. To include this new safety concept in control problems, we formulate a feasibility maximization problem aiming to maximize the feasibility of the primary and alternative missions. The feasibility maximization problem is based on multi-objective MPC, where each objective (cost function)\u00a0is associated with a different mission and balanced by a weight vector. Furthermore, the feasibility maximization problem incorporates additional control input horizons toward the alternative missions on top of the control input horizon toward the primary mission, denoted as multihorizon inputs, to evaluate the cost for each mission. We develop the backup plan constrained MPC algorithm, which designs the weight vector that ensures asymptotic stability of the closed-loop system, and generates the optimal control input by solving the feasibility maximization problem with computational efficiency. The performance of the proposed algorithm is validated through simulations of an unmanned aerial vehicle path planning problem.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2187265626",
                    "name": "Ran Tao"
                },
                {
                    "authorId": "153761761",
                    "name": "Hunmin Kim"
                },
                {
                    "authorId": "2113736289",
                    "name": "Hyung-Jin Yoon"
                },
                {
                    "authorId": "73667965",
                    "name": "Wenbin Wan"
                },
                {
                    "authorId": "2130392",
                    "name": "N. Hovakimyan"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                },
                {
                    "authorId": "1807965",
                    "name": "P. Voulgaris"
                }
            ]
        },
        {
            "paperId": "b3babe30d478829cca3388bfccb3f6e778659e92",
            "title": "Physical Deep Reinforcement Learning Towards Safety Guarantee",
            "abstract": "Deep reinforcement learning (DRL) has achieved tremendous success in many complex decision-making tasks of autonomous systems with high-dimensional state and/or action spaces. However, the safety and stability still remain major concerns that hinder the applications of DRL to safety-critical autonomous systems. To address the concerns, we proposed the Phy-DRL: a physical deep reinforcement learning framework. The Phy-DRL is novel in two architectural designs: i) Lyapunov-like reward, and ii) residual control (i.e., integration of physics-model-based control and data-driven control). The concurrent physical reward and residual control empower the Phy-DRL the (mathematically) provable safety and stability guarantees. Through experiments on the inverted pendulum, we show that the Phy-DRL features guaranteed safety and stability and enhanced robustness, while offering remarkably accelerated training and enlarged reward.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1774928",
                    "name": "H. Cao"
                },
                {
                    "authorId": "1937682",
                    "name": "Y. Mao"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                },
                {
                    "authorId": "1749138",
                    "name": "M. Caccamo"
                }
            ]
        },
        {
            "paperId": "fc867cdaa921dec90aaa0c277461da742cf0913c",
            "title": "Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings",
            "abstract": "This paper proposes the Phy-DRL: a physics-regulated deep reinforcement learning (DRL) framework for safety-critical autonomous systems. The Phy-DRL has three distinguished invariant-embedding designs: i) residual action policy (i.e., integrating data-driven-DRL action policy and physics-model-based action policy), ii) automatically constructed safety-embedded reward, and iii) physics-model-guided neural network (NN) editing, including link editing and activation editing. Theoretically, the Phy-DRL exhibits 1) a mathematically provable safety guarantee and 2) strict compliance of critic and actor networks with physics knowledge about the action-value function and action policy. Finally, we evaluate the Phy-DRL on a cart-pole system and a quadruped robot. The experiments validate our theoretical results and demonstrate that Phy-DRL features guaranteed safety compared to purely data-driven DRL and solely model-based design while offering remarkably fewer learning parameters and fast training towards safety guarantee.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1774928",
                    "name": "H. Cao"
                },
                {
                    "authorId": "1937682",
                    "name": "Y. Mao"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                },
                {
                    "authorId": "1749138",
                    "name": "M. Caccamo"
                }
            ]
        },
        {
            "paperId": "24c05c3bf0014896fe9934d9fb42e45bae4424ce",
            "title": "Verifiable Obstacle Detection",
            "abstract": "Perception of obstacles remains a critical safety concern for autonomous vehicles. Real-world collisions have shown that the autonomy faults leading to fatal collisions originate from obstacle existence detection. Open source autonomous driving implementations show a perception pipeline with complex interdependent Deep Neural Networks. These networks are not fully verifiable, making them unsuitable for safety-critical tasks. In this work, we present a safety verification of an existing LiDAR based classical obstacle detection algorithm. We establish strict bounds on the capabilities of this obstacle detection algorithm. Given safety standards, such bounds allow for determining LiDAR sensor properties that would reliably satisfy the standards. Such analysis has as yet been unattainable for neural network based perception systems. We provide a rigorous analysis of the obstacle detection system with empirical results based on real-world sensor data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "32639637",
                    "name": "Ayoosh Bansal"
                },
                {
                    "authorId": "153761761",
                    "name": "Hunmin Kim"
                },
                {
                    "authorId": "2218690071",
                    "name": "Simon Yu"
                },
                {
                    "authorId": "2132473456",
                    "name": "Bo-Yi Li"
                },
                {
                    "authorId": "2130392",
                    "name": "N. Hovakimyan"
                },
                {
                    "authorId": "1749138",
                    "name": "M. Caccamo"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                }
            ]
        },
        {
            "paperId": "5abd34dc1461f9ab64771e2eed3f1cf69b5ddc0d",
            "title": "Phy-Taylor: Physics-Model-Based Deep Neural Networks",
            "abstract": "Purely data-driven deep neural networks (DNNs) applied to physical engineering systems can infer relations that violate physics laws, thus leading to unexpected consequences. To address this challenge, we propose a physics-model-based DNN framework, called Phy-Taylor, that accelerates learning compliant representations with physical knowledge. The Phy-Taylor framework makes two key contributions; it introduces a new architectural Physics-compatible neural network (PhN), and features a novel compliance mechanism, we call {\\em Physics-guided Neural Network Editing\\}. The PhN aims to directly capture nonlinearities inspired by physical quantities, such as kinetic energy, potential energy, electrical power, and aerodynamic drag force. To do so, the PhN augments neural network layers with two key components: (i) monomials of Taylor series expansion of nonlinear functions capturing physical knowledge, and (ii) a suppressor for mitigating the influence of noise. The neural-network editing mechanism further modifies network links and activation functions consistently with physical knowledge. As an extension, we also propose a self-correcting Phy-Taylor framework that introduces two additional capabilities: (i) physics-model-based safety relationship learning, and (ii) automatic output correction when violations of safety occur. Through experiments, we show that (by expressing hard-to-learn nonlinearities directly and by constraining dependencies) Phy-Taylor features considerably fewer parameters, and a remarkably accelerated training process, while offering enhanced model robustness and accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1937682",
                    "name": "Y. Mao"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                },
                {
                    "authorId": "3395273",
                    "name": "Huajie Shao"
                },
                {
                    "authorId": "30955167",
                    "name": "Yuliang Gu"
                },
                {
                    "authorId": "2109090616",
                    "name": "Qixin Wang"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "c8510031671052baf009197080469d513f67b26d",
            "title": "Self-Cueing Real-Time Attention Scheduling in Criticality-Aware Visual Machine Perception",
            "abstract": "This paper presents a self-cueing real-time frame-work for attention prioritization in AI-enabled visual perception systems that minimizes a notion of state uncertainty. By attention prioritization we refer to inspecting some parts of the scene before others in a criticality-aware fashion. By self-cueing, we refer to not needing external cueing sensors for prioritizing attention, thereby simplifying design. We show that attention prioritization saves resources, thus enabling more efficient and responsive real-time object tracking on resource-limited embedded platforms. The system consists of two components: First, an optical flow-based module decides on the regions to be viewed on a subframe level, as well as their criticality. Second, a novel batched proportional balancing (BPB) scheduling policy decides how to schedule these regions for inspection by a deep neural network (DNN), and how to parallelize execution on the GPU. We implement the system on an NVIDIA Jetson Xavier platform, and empirically demonstrate the superiority of the proposed architecture through an extensive evaluation using a real-word driving dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390628682",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "9507379",
                    "name": "Xinzhe Fu"
                },
                {
                    "authorId": "2857477",
                    "name": "Maggie B. Wigness"
                },
                {
                    "authorId": "145776797",
                    "name": "P. David"
                },
                {
                    "authorId": "2325031",
                    "name": "Shuochao Yao"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "d60e20760fd50d79c4ab63a1f954f0e7c7a5e9cb",
            "title": "Perception simplex: Verifiable collision avoidance in autonomous vehicles amidst obstacle detection faults",
            "abstract": "Advances in deep learning have revolutionized cyber\u2010physical applications, including the development of autonomous vehicles. However, real\u2010world collisions involving autonomous control of vehicles have raised significant safety concerns regarding the use of deep neural networks (DNNs) in safety\u2010critical tasks, particularly perception. The inherent unverifiability of DNNs poses a key challenge in ensuring their safe and reliable operation. In this work, we propose perception\u00a0simplex (), a fault\u2010tolerant application architecture designed for obstacle detection and collision avoidance. We analyse an existing LiDAR\u2010based classical obstacle detection algorithm to establish strict bounds on its capabilities and limitations. Such analysis and verification have not been possible for deep learning\u2010based perception systems yet. By employing verifiable obstacle detection algorithms, identifies obstacle existence detection faults in the output of unverifiable DNN\u2010based object detectors. When faults with potential collision risks are detected, appropriate corrective actions are initiated. Through extensive analysis and software\u2010in\u2010the\u2010loop simulations, we demonstrate that provides deterministic fault tolerance against obstacle existence detection faults, establishing a robust safety guarantee.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "32639637",
                    "name": "Ayoosh Bansal"
                },
                {
                    "authorId": "153761761",
                    "name": "Hunmin Kim"
                },
                {
                    "authorId": "2218690071",
                    "name": "Simon Yu"
                },
                {
                    "authorId": "2155883101",
                    "name": "Bo Li"
                },
                {
                    "authorId": "2130392",
                    "name": "N. Hovakimyan"
                },
                {
                    "authorId": "1749138",
                    "name": "M. Caccamo"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                }
            ]
        },
        {
            "paperId": "e1347aa8507d4e0dba1bd6143e175e425891c249",
            "title": "Latency analysis of self-suspending task chains",
            "abstract": "Many cyber-physical systems are offloading computation-heavy programs to hardware accelerators (e.g., GPU and TPU) to reduce execution time. These applications will self-suspend between offloading data to the accelerators and obtaining the returned results. Previous efforts have shown that self-suspending tasks can cause scheduling anomalies, but none has examined inter-task communication. This paper aims to explore self-suspending tasks' data chain latency with periodic activation and asynchronous message passing. We first present the cause for suspension-induced delays and worst-case latency analysis. We then propose a rule for utilizing the hardware co-processors to reduce data chain latency and schedulability analysis. Simulation results show that the proposed strategy can improve overall latency while preserving system schedulability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2062908",
                    "name": "Tomasz Kloda"
                },
                {
                    "authorId": "2108330941",
                    "name": "Jiyang Chen"
                },
                {
                    "authorId": "3299536",
                    "name": "A. Bertout"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                },
                {
                    "authorId": "1749138",
                    "name": "M. Caccamo"
                }
            ]
        },
        {
            "paperId": "e855272dd32f0f2f5839fc115ea87bc999fcd39d",
            "title": "SchedGuard++: Protecting against Schedule Leaks Using Linux Containers on Multi-Core Processors",
            "abstract": "Timing correctness is crucial in a multi-criticality real-time system, such as an autonomous driving system. It has been recently shown that these systems can be vulnerable to timing inference attacks, mainly due to their predictable behavioral patterns. Existing solutions like schedule randomization cannot protect against such attacks, often limited by the system\u2019s real-time nature. This article presents \u201cSchedGuard++\u201d: a temporal protection framework for Linux-based real-time systems that protects against posterior schedule-based attacks by preventing untrusted tasks from executing during specific time intervals. SchedGuard++ supports multi-core platforms and is implemented using Linux containers and a customized Linux kernel real-time scheduler. We provide schedulability analysis assuming the Logical Execution Time (LET) paradigm, which enforces I/O predictability. The proposed response time analysis takes into account the interference from trusted and untrusted tasks and the impact of the protection mechanism. We demonstrate the effectiveness of our system using a realistic radio-controlled rover platform. Not only is \u201cSchedGuard++\u201d able to protect against the posterior schedule-based attacks, but it also ensures that the real-time tasks/containers meet their temporal requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257310141",
                    "name": "Jiyang Chen"
                },
                {
                    "authorId": "2062908",
                    "name": "Tomasz Kloda"
                },
                {
                    "authorId": "1969563",
                    "name": "Rohan Tabish"
                },
                {
                    "authorId": "32639637",
                    "name": "Ayoosh Bansal"
                },
                {
                    "authorId": "1390801973",
                    "name": "Chien-Ying Chen"
                },
                {
                    "authorId": "2156640009",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1689767",
                    "name": "Sibin Mohan"
                },
                {
                    "authorId": "2257295203",
                    "name": "Marco Caccamo"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                }
            ]
        },
        {
            "paperId": "1fb7fe6b10c3b8f2c7b5ad704031dc9cc830d2b4",
            "title": "Risk Ranked Recall: Collision Safety Metric for Object Detection Systems in Autonomous Vehicles",
            "abstract": "Commonly used metrics for evaluation of object detection systems (precision, recall, mAP) do not give complete information about their suitability of use in safety critical tasks, like obstacle detection for collision avoidance in Autonomous Vehicles (AV). This work introduces the Risk Ranked Recall ($R^3$) metrics for object detection systems. The $R^3$ metrics categorize objects within three ranks. Ranks are assigned based on an objective cyber-physical model for the risk of collision. Recall is measured for each rank.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32639637",
                    "name": "Ayoosh Bansal"
                },
                {
                    "authorId": "51193318",
                    "name": "Jayati Singh"
                },
                {
                    "authorId": "114074887",
                    "name": "M. Verucchi"
                },
                {
                    "authorId": "1749138",
                    "name": "M. Caccamo"
                },
                {
                    "authorId": "2919287",
                    "name": "L. Sha"
                }
            ]
        }
    ]
}