{
    "authorId": "144911687",
    "papers": [
        {
            "paperId": "0c65dfacc858102af978debc10b56536fa186f20",
            "title": "Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration",
            "abstract": "Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel data-aware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2155699322",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "27387572208cf777fb2c55db8880dd5407d0e779",
            "title": "Personalized and privacy-preserving federated heterogeneous medical image analysis with PPPML-HMI",
            "abstract": "Heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging. However, there are few open-source frameworks for federated heterogeneous medical image analysis with personalization and privacy protection without the demand to modify the existing model structures or to share any private data. In this paper, we proposed PPPML-HMI, a novel open-source learning paradigm for personalized and privacy-preserving federated heterogeneous medical image analysis. To our best knowledge, personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the PerFedAvg algorithm and designing the novel cyclic secure aggregation with the homomorphic encryption algorithm. To show the utility of PPPML-HMI, we applied it to a simulated classification task namely the classification of healthy people and patients from the RAD-ChestCT Dataset, and one real-world segmentation task namely the segmentation of lung infections from COVID-19 CT scans. For the real-world task, PPPML-HMI achieved $sim$5% higher Dice score on average compared to conventional FL under the heterogeneous scenario. Meanwhile, we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the strong privacy-preserving capability of PPPML-HMI. By applying PPPML-HMI to both tasks with different neural networks, a varied number of users, and sample sizes, we further demonstrated the strong generalizability of PPPML-HMI.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2161017247",
                    "name": "Di Wang"
                },
                {
                    "authorId": "2142540079",
                    "name": "Xiaopeng Xu"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2028962393",
                    "name": "Wenkai Han"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "5d00e8f305d20ad937938fa4db054a33186626f7",
            "title": "AutoGT: Automated Graph Transformer Architecture Search",
            "abstract": "Although Transformer architectures have been successfully applied to graph data with the advent of Graph Transformer, the current design of Graph Transformers still heavily relies on human labor and expertise knowledge to decide on proper neural architectures and suitable graph encoding strategies at each Transformer layer. In literature, there have been some works on the automated design of Transformers focusing on non-graph data such as texts and images without considering graph encoding strategies, which fail to handle the non-euclidean graph data. In this paper, we study the problem of automated graph Transformers, for the first time. However, solving these problems poses the following challenges: i) how can we design a unified search space for graph Transformer, and ii) how to deal with the coupling relations between Transformer architectures and the graph encodings of each Transformer layer. To address these challenges, we propose Automated Graph Transformer (AutoGT), a neural architecture search framework that can automatically discover the optimal graph Transformer architectures by joint optimization of Transformer architecture and graph encoding strategies. Specifically, we first propose a unified graph Transformer formulation that can represent most state-ofthe-art graph Transformer architectures. Based upon the unified formulation, we further design the graph Transformer search space that includes both candidate architectures and various graph encodings. To handle the coupling relations, we propose a novel encoding-aware performance estimation strategy by gradually training and splitting the supernets according to the correlations between graph encodings and architectures. The proposed strategy can provide a more consistent and fine-grained performance prediction when evaluating the jointly optimized graph encodings and architectures. Extensive experiments and ablation studies show that our proposed AutoGT gains sufficient improvement over state-of-the-art hand-crafted baselines on all datasets, demonstrating its effectiveness and wide applicability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128158461",
                    "name": "Zizhao Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "133761917",
                    "name": "Chaoyu Guan"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "6d18dcd4b562ea15f3270551b71596b2a1980b07",
            "title": "Tutorials at The Web Conference 2023",
            "abstract": "This paper summarizes the content of the 28 tutorials that have been given at The Web Conference 2023.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "1705291",
                    "name": "Valeria Fionda"
                },
                {
                    "authorId": "2215622430",
                    "name": "Olaf Hartig"
                },
                {
                    "authorId": "1805958417",
                    "name": "Reyhaneh Abdolazimi"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2215690996",
                    "name": "Hongzhi Chen"
                },
                {
                    "authorId": "2117027107",
                    "name": "Xiao Chen"
                },
                {
                    "authorId": "2052469774",
                    "name": "P. Cui"
                },
                {
                    "authorId": "145269114",
                    "name": "Jeffrey Dalton"
                },
                {
                    "authorId": "2215596266",
                    "name": "Xin Luna Dong"
                },
                {
                    "authorId": "2957808",
                    "name": "Lisette Espin Noboa"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2132398392",
                    "name": "Manuela Fritz"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "46909769",
                    "name": "Xiaojie Guo"
                },
                {
                    "authorId": "2215622544",
                    "name": "Torsten Hahmann"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2139299903",
                    "name": "Jiaxin Huang"
                },
                {
                    "authorId": "47247243",
                    "name": "Utkarshani Jaimini"
                },
                {
                    "authorId": "2299944027",
                    "name": "Olivier Jeunen"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "3309003",
                    "name": "Hady W. Lauw"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "1808423005",
                    "name": "Trung-Hoang Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "2110855835",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "19326298",
                    "name": "Liat Levontin"
                },
                {
                    "authorId": "2144231489",
                    "name": "Cheng-Te Li"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2110471246",
                    "name": "Ying Li"
                },
                {
                    "authorId": "2030126978",
                    "name": "Jay Chiehen Liao"
                },
                {
                    "authorId": "2157067900",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "46189109",
                    "name": "Usha Lokala"
                },
                {
                    "authorId": "2085850",
                    "name": "Ben London"
                },
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "153612944",
                    "name": "H. Mcginty"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "2069543964",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "48331451",
                    "name": "Devesh Parekh"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2101664",
                    "name": "Tiago P. Peixoto"
                },
                {
                    "authorId": "144615425",
                    "name": "S. Pemberton"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2065812052",
                    "name": "Filip Radlinski"
                },
                {
                    "authorId": "48890086",
                    "name": "Federico Rossetto"
                },
                {
                    "authorId": "2091913080",
                    "name": "Kaushik Roy"
                },
                {
                    "authorId": "2911888",
                    "name": "Aghiles Salah"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2064266862",
                    "name": "Dacheng Tao"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "39603708",
                    "name": "Quoc-Tuan Truong"
                },
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2215624802",
                    "name": "Bram Van Den Akker"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2144295736",
                    "name": "Minjie Wang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2153691630",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "69047048",
                    "name": "H. Weld"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2181385841",
                    "name": "D. Xu"
                },
                {
                    "authorId": "2138609128",
                    "name": "E. Xu"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2156653838",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2125559318",
                    "name": "Keyue Yang"
                },
                {
                    "authorId": "1388775854",
                    "name": "E. Yom-Tov"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "2499986",
                    "name": "Hamed Zamani"
                },
                {
                    "authorId": "41154657",
                    "name": "Meike Zehlike"
                },
                {
                    "authorId": "2145906426",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2148904413",
                    "name": "Zhengqi Zhang"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "6d51f4b220cb2c8321dc5f9755b7d66f10f1cad6",
            "title": "RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL",
            "abstract": "One of the recent best attempts at Text-to-SQL is the pre-trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items (i.e., tables and columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase the difficulty of parsing the correct SQL queries especially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole unordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder first generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our proposed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The experimental results show that our framework delivers promising performance and robustness. Our code is available at https://github.com/RUCKBReasoning/RESDSQL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2155700347",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "1625473962",
                    "name": "Cuiping Li"
                },
                {
                    "authorId": "2191043357",
                    "name": "Hong Chen"
                }
            ]
        },
        {
            "paperId": "8cdd97dee6073673c7f4f444ab090b62c61b4673",
            "title": "Disentangled Graph Contrastive Learning With Independence Promotion",
            "abstract": "Self-supervised learning for graph neural networks has attracted considerable attention and shows notable successes in graph representation learning. However, the formation of a real-world graph typically arises from highly complex interactions of many latent factors. The existing self-supervised learning methods for GNNs are inherently holistic and neglect the entanglement of the latent factors, resulting in suboptimal learned representations for downstream tasks and difficult to be interpreted. Learning disentangled graph representations with self-supervised learning poses great challenges and remains largely ignored by the existing literature. In this paper, we introduce Independence Promoted Disentangled Graph Contrastive Learning (IDGCL) method, which can learn disentangled graph-level representations with self-supervision. In particular, we first identify the latent factors of the input graph and derive its factorized representations. Then we propose a factor-wise discrimination objective in a contrastive learning manner, which can force the factorized representations to independently reflect the expressive information from different latent factors. To further promote the independence between the representations, we employ the Hilbert-Schmidt Independence Criterion to eliminate the dependence among different representations, which is effectively integrated into the self-supervised framework as a regularizer. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of our method against several state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "995ddf1f076966532e35f7530a3761923366379c",
            "title": "Invariant Node Representation Learning under Distribution Shifts with Multiple Latent Environments",
            "abstract": "Node representation learning methods, such as graph neural networks, show promising results when testing and training graph data come from the same distribution. However, the existing approaches fail to generalize under distribution shifts when the nodes reside in multiple latent environments. How to learn invariant node representations to handle distribution shifts with multiple latent environments remains unexplored. In this article, we propose a novel Invariant Node representation Learning (INL) approach capable of generating invariant node representations based on the invariant patterns under distribution shifts with multiple latent environments by leveraging the invariance principle. Specifically, we define invariant and variant patterns as ego-subgraphs of each node and identify the invariant ego-subgraphs through jointly accounting for node features and graph structures. To infer the latent environments of nodes, we propose a contrastive modularity-based graph clustering method based on the variant patterns. We further propose an invariant learning module to learn node representations that can generalize to distribution shifts. We theoretically show that our proposed method can achieve guaranteed performance under distribution shifts. Extensive experiments on both synthetic and real-world node classification benchmarks demonstrate that our method greatly outperforms state-of-the-art baselines under distribution shifts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "9d6b5bd74f17b2768290189f6548312df83abb67",
            "title": "A unified method to revoke the private data of patients in intelligent healthcare with audit to forget",
            "abstract": "Revoking personal private data is one of the basic human rights, which has already been sheltered by several privacy-preserving laws in many countries. However, with the development of data science, machine learning and deep learning techniques, this right is usually neglected or violated as more and more patients\u2019 data are being collected and used for model training, especially in intelligent healthcare, thus making intelligent healthcare a sector where technology must meet the law, regulations, and privacy principles to ensure that the innovation is for the common good. In order to secure patients\u2019 right to be forgotten, we proposed a novel solution by using auditing to guide the forgetting process, where auditing means determining whether a dataset has been used to train the model and forgetting requires the information of a query dataset to be forgotten from the target model. We unified these two tasks by introducing a new approach called knowledge purification. To implement our solution, we developed AFS, a unified open-source software, which is able to evaluate and revoke patients\u2019 private data from pre-trained deep learning models. We demonstrated the generality of AFS by applying it to four tasks on different datasets with various data sizes and architectures of deep learning networks. The software is publicly available at https://github.com/JoshuaChou2018/AFS.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "51072831",
                    "name": "Xingyu Liao"
                },
                {
                    "authorId": "2119454424",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": null,
                    "name": "Wenjia He"
                },
                {
                    "authorId": "66545108",
                    "name": "Zhongxiao Li"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "b6948df388eb9eb1d24c70be319dc95e3291458c",
            "title": "Intent-aware Recommendation via Disentangled Graph Contrastive Learning",
            "abstract": "Graph neural network (GNN) based recommender systems have become one of the mainstream trends due to the powerful learning ability from user behavior data. Understanding the user intents from behavior data is the key to recommender systems, which poses two basic requirements for GNN-based recommender systems. One is how to learn complex and diverse intents especially when the user behavior is usually inadequate in reality. The other is different behaviors have different intent distributions, so how to establish their relations for a more explainable recommender system. In this paper, we present the Intent-aware Recommendation via Disentangled Graph Contrastive Learning (IDCL), which simultaneously learns interpretable intents and behavior distributions over those intents. Specifically, we first model the user behavior data as a user-item-concept graph, and design a GNN based behavior disentangling module to learn the different intents. Then we propose the intent-wise contrastive learning to enhance the intent disentangling and meanwhile infer the behavior distributions. Finally, the coding rate reduction regularization is introduced to make the behaviors of different intents orthogonal. Extensive experiments demonstrate the effectiveness of IDCL in terms of substantial improvement and the interpretability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115664393",
                    "name": "Yuling Wang"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2760554",
                    "name": "Xiangzhou Huang"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "48985404",
                    "name": "Mengdi Zhang"
                },
                {
                    "authorId": "114361215",
                    "name": "Zirui Guo"
                },
                {
                    "authorId": "2118256000",
                    "name": "Wei Wu"
                }
            ]
        },
        {
            "paperId": "e0cae220bc1756fd6f660e5aa3ee22da6f2f31d8",
            "title": "Curriculum Graph Machine Learning: A Survey",
            "abstract": "Graph machine learning has been extensively studied in both academia and industry. However, in the literature, most existing graph machine learning models are designed to conduct training with data samples in a random order, which may suffer from suboptimal performance due to ignoring the importance of different graph data samples and their training orders for the model optimization status. To tackle this critical problem, curriculum graph machine learning (Graph CL), which integrates the strength of graph machine learning and curriculum learning, arises and attracts an increasing amount of attention from the research community. Therefore, in this paper, we comprehensively overview approaches on Graph CL and present a detailed survey of recent advances in this direction. Specifically, we first discuss the key challenges of Graph CL and provide its formal problem definition. Then, we categorize and summarize existing methods into three classes based on three kinds of graph machine learning tasks, i.e., node-level, link-level, and graph-level tasks. Finally, we share our thoughts on future research directions. To the best of our knowledge, this paper is the first survey for curriculum graph machine learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        }
    ]
}