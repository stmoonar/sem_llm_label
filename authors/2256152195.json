{
    "authorId": "2256152195",
    "papers": [
        {
            "paperId": "5468a398cbb91b0f126e10e6a827a46ee1eefc9b",
            "title": "Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot",
            "abstract": "Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals\u2019 practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2279801138",
                    "name": "Lin Tian"
                },
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2279785688",
                    "name": "Halil Ali"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "5d750b51dd5371998dfea27f391b4113a7c9aa62",
            "title": "Towards Detecting and Mitigating Cognitive Bias in Spoken Conversational Search",
            "abstract": "Instruments such as eye-tracking devices have contributed to understanding how users interact with screen-based search engines. However, user-system interactions in audio-only channels -- as is the case for Spoken Conversational Search (SCS) -- are harder to characterize, given the lack of instruments to effectively and precisely capture interactions. Furthermore, in this era of information overload, cognitive bias can significantly impact how we seek and consume information -- especially in the context of controversial topics or multiple viewpoints. This paper draws upon insights from multiple disciplines (including information seeking, psychology, cognitive science, and wearable sensors) to provoke novel conversations in the community. To this end, we discuss future opportunities and propose a framework including multimodal instruments and methods for experimental designs and settings. We demonstrate preliminary results as an example. We also outline the challenges and offer suggestions for adopting this multimodal approach, including ethical considerations, to assist future researchers and practitioners in exploring cognitive biases in SCS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2285470234",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "b2aa89f30b4fa8a012cb6f5f485b4632a6555351",
            "title": "Characterizing Information Seeking Processes with Multiple Physiological Signals",
            "abstract": "Information access systems are getting complex, and our understanding of user behavior during information seeking processes is mainly drawn from qualitative methods, such as observational studies or surveys. Leveraging the advances in sensing technologies, our study aims to characterize user behaviors with physiological signals, particularly in relation to cognitive load, affective arousal, and valence. We conduct a controlled lab study with 26 participants, and collect data including Electrodermal Activities, Photoplethysmogram, Electroencephalogram, and Pupillary Responses. This study examines informational search with four stages: the realization of Information Need (IN), Query Formulation (QF), Query Submission (QS), and Relevance Judgment (RJ). We also include different interaction modalities to represent modern systems, e.g., QS by text-typing or verbalizing, and RJ with text or audio information. We analyze the physiological signals across these stages and report outcomes of pairwise non-parametric repeated-measure statistical tests. The results show that participants experience significantly higher cognitive loads at IN with a subtle increase in alertness, while QF requires higher attention. QS involves demanding cognitive loads than QF. Affective responses are more pronounced at RJ than QS or IN, suggesting greater interest and engagement as knowledge gaps are resolved. To the best of our knowledge, this is the first study that explores user behaviors in a search process employing a more nuanced quantitative analysis of physiological signals. Our findings offer valuable insights into user behavior and emotional responses in information seeking processes. We believe our proposed methodology can inform the characterization of more complex processes, such as conversational information seeking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "d07549450f134edc015179ef5f28fb1cac1d1fad",
            "title": "Towards Investigating Biases in Spoken Conversational Search",
            "abstract": "Voice-based systems like Amazon Alexa, Google Assistant, and Apple Siri, along with the growing popularity of OpenAI's ChatGPT and Microsoft's Copilot, serve diverse populations, including visually impaired and low-literacy communities. This reflects a shift in user expectations from traditional search to more interactive question-answering models. However, presenting information effectively in voice-only channels remains challenging due to their linear nature. This limitation can impact the presentation of complex queries involving controversial topics with multiple perspectives. Failing to present diverse viewpoints may perpetuate or introduce biases and affect user attitudes. Balancing information load and addressing biases is crucial in designing a fair and effective voice-based system. To address this, we (i) review how biases and user attitude changes have been studied in screen-based web search, (ii) address challenges in studying these changes in voice-based settings like SCS, (iii) outline research questions, and (iv) propose an experimental setup with variables, data, and instruments to explore biases in a voice-based setting like Spoken Conversational Search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "dd8a811c1e5cc033849ea2dcdc648af48bb82bef",
            "title": "Online and Offline Evaluation in Search Clarification",
            "abstract": "The effectiveness of clarification question models in engaging users within search systems is currently constrained, casting doubt on their overall usefulness. To improve the performance of these models, it is crucial to employ assessment approaches that encompass both real-time feedback from users (online evaluation) and the characteristics of clarification questions evaluated through human assessment (offline evaluation). However, the relationship between online and offline evaluations has been debated in information retrieval. This study aims to investigate how this discordance holds in search clarification. We use user engagement as ground truth and employ several offline labels to investigate to what extent the offline ranked lists of clarification resemble the ideal ranked lists based on online user engagement. Contrary to the current understanding that offline evaluations fall short of supporting online evaluations, we indicate that when identifying the most engaging clarification questions from the user\u2019s perspective, online and offline evaluations correspond with each other. We show that the query length does not influence the relationship between online and offline evaluations, and reducing uncertainty in online evaluation strengthens this relationship. We illustrate that an engaging clarification needs to excel from multiple perspectives, and SERP quality and characteristics of the clarification are equally important. We also investigate if human labels can enhance the performance of Large Language Models (LLMs) and Learning-to-Rank (LTR) models in identifying the most engaging clarification questions from the user\u2019s perspective by incorporating offline evaluations as input features. Our results indicate that Learning-to-Rank models do not perform better than individual offline labels. However, GPT, an LLM, emerges as the standout performer, surpassing all Learning-to-Rank models and offline labels.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2104141869",
                    "name": "Leila Tavakoli"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2291137161",
                    "name": "Hamed Zamani"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "2270077823",
                    "name": "Mark Sanderson"
                }
            ]
        },
        {
            "paperId": "8e8737c80dbb333541577949175f3c0f5f782cd8",
            "title": "Towards Detecting Tonic Information Processing Activities with Physiological Data",
            "abstract": "Characterizing Information Processing Activities (IPAs) such as reading, listening, speaking, and writing, with physiological signals captured by wearable sensors can broaden the understanding of how people produce and consume information. However, sensors are highly sensitive to external conditions that are not trivial to control \u2013 not even in lab user studies. We conducted a pilot study (N = 7) to assess the robustness and sensitivity of physiological signals across four IPAs (READ, LISTEN, SPEAK, and WRITE) using multiple sensors. The collected signals include Electrodermal Activities, Blood Volume Pulse, gaze, and head motion. We observed consistent trends across participants, and ten features with statistically significant differences across the four IPAs. Our results provide preliminary quantitative evidence of differences in physiological responses when users encounter IPAs, revealing the necessity to inspect the signals separately according to the IPAs. The next step of this study moves into a specific context, information retrieval, and the IPAs are considered as the interaction modalities with the search system, for instance, submitting the search query by speaking or typing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        }
    ]
}