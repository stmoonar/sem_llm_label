{
    "authorId": "2301580599",
    "papers": [
        {
            "paperId": "b3795d73cadfacfb6aa0f723978915012070a3d5",
            "title": "DocScript: Document-level Script Event Prediction",
            "abstract": "We present a novel task of document-level script event prediction, which aims to predict the next event given a candidate list of narrative events in long-form documents. To enable this, we introduce DocSEP, a challenging dataset in two new domains - contractual documents and Wikipedia articles, where timeline events may be paragraphs apart and may require multi-hop temporal and causal reasoning. We benchmark existing baselines and present a novel architecture called DocScript to learn sequential ordering between events at the document scale. Our experimental results on the DocSEP dataset demonstrate that learning longer-range dependencies between events is a key challenge and show that contemporary LLMs such as ChatGPT and FlanT5 struggle to solve this task, indicating their lack of reasoning abilities for understanding causal relationships and temporal sequences within long texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "31099365",
                    "name": "Aparna Garimella"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2274190457",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                }
            ]
        },
        {
            "paperId": "383db93b039c2f7d743a06dc62a8db2ff1ea33f7",
            "title": "DocEdit: Language-Guided Document Editing",
            "abstract": "Professional document editing tools require a certain level of expertise to perform complex edit operations. To make editing tools accessible to increasingly novice users, we investigate intelligent document assistant systems that can make or suggest edits based on a user's natural language request. Such a system should be able to understand the user's ambiguous requests and contextualize them to the visual cues and textual content found in a document image to edit localized unstructured text and structured layouts. To this end, we propose a new task of language-guided localized document editing, where the user provides a document and an open vocabulary editing request, and the intelligent system produces a command that can be used to automate edits in real-world document editing software. In support of this task, we curate the DocEdit dataset, a collection of approximately 28K instances of user edit requests over PDF and design templates along with their corresponding ground truth software executable commands. To our knowledge, this is the first dataset that provides a diverse mix of edit operations with direct and indirect references to the embedded text and visual objects such as paragraphs, lists, tables, etc. We also propose DocEditor, a Transformer-based localization-aware multimodal (textual, spatial, and visual) model that performs the new task. The model attends to both document objects and related text contents which may be referred to in a user edit request, generating a multimodal embedding that is used to predict an edit command and associated bounding box localizing it. Our proposed model empirically outperforms other baseline deep learning approaches by 15-18%, providing a strong starting point for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2172597446",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                }
            ]
        },
        {
            "paperId": "91ac4c094a2936c292b5dec56fd44a913f183083",
            "title": "LayerDoc: Layer-wise Extraction of Spatial Hierarchical Structure in Visually-Rich Documents",
            "abstract": "Digital documents often contain images and scanned text. Parsing such visually-rich documents is a core task for work-flow automation, but it remains challenging since most documents do not encode explicit layout information, e.g., how characters and words are grouped into boxes and ordered into larger semantic entities. Current state-of-the-art layout extraction methods are challenged by such documents as they rely on word sequences to have correct reading order and do not exploit their hierarchical structure. We propose LayerDoc, an approach that uses visual features, textual semantics, and spatial coordinates along with constraint inference to extract the hierarchical layout structure of documents in a bottom-up layer-wise fashion. LayerDoc recursively groups smaller regions into larger semantic elements in 2D to infer complex nested hierarchies. Experiments show that our approach outperforms competitive baselines by 10-15% on three diverse datasets of forms and mobile app screen layouts for the tasks of spatial region classification, higher-order group identification, layout hierarchy extraction, reading order detection, and word grouping.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2064021145",
                    "name": "Ashutosh Mehra"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2101319527",
                    "name": "Anandhavelu N"
                },
                {
                    "authorId": "2536742",
                    "name": "Quan Hung Tran"
                },
                {
                    "authorId": "1419671559",
                    "name": "Verena Kaynig-Fittkau"
                },
                {
                    "authorId": "3115414",
                    "name": "A. Nenkova"
                },
                {
                    "authorId": "2172597446",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                }
            ]
        },
        {
            "paperId": "2bff94593787c47a240dc438bef1498a1f02fb2f",
            "title": "DocFin: Multimodal Financial Prediction and Bias Mitigation using Semi-structured Documents",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2000936311",
                    "name": "Mihir Goyal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2069834937",
                    "name": "Ritik Mathur"
                },
                {
                    "authorId": "2227049",
                    "name": "Jochen L. Leidner"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2172597446",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "43e9409c847cefd7ec00e65635cd995cbb017862",
            "title": "DocLayoutTTS: Dataset and Baselines for Layout-informed Document-level Neural Speech Synthesis",
            "abstract": "We propose a new task of synthesizing speech directly from semi-structured documents where the extracted text tokens from OCR systems may not be in the correct reading order due to the complex document layout. We refer to this task as layout-informed document-level TTS and present the DocSpeech dataset which consists of 10K audio clips of a single-speaker reading layout-enriched Word document. For each document, we provide the natural reading order of text tokens, its corresponding bounding boxes, and the audio clips synthesized in the correct reading order. We also introduce DocLayoutTTS , a Transformer encoder-decoder architecture that generates speech in an end-to-end manner given a document image with OCR extracted text. Our architecture simultaneously learns text re-ordering and mel-spectrogram prediction in a multi-task setup. Moreover, we take advantage of curriculum learning to progressively learn longer, more challenging document-level text utilizing both DocSpeech and LJSpeech datasets. Our empirical re-sults show that the underlying task is challenging. Our proposed architecture performs slightly better than competitive baseline TTS models with a pre-trained model providing reading order priors. We release samples of the DocSpeech dataset 1 .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2536742",
                    "name": "Quan Hung Tran"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "3115414",
                    "name": "A. Nenkova"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "1699159",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "867915b9587c046ce8e4b71ab4dee2a1d8bf0b48",
            "title": "DocTime: A Document-level Temporal Dependency Graph Parser",
            "abstract": "We introduce DocTime - a novel temporal dependency graph (TDG) parser that takes as input a text document and produces a temporal dependency graph. It outperforms previous BERT-based solutions by a relative 4-8% on three datasets from modeling the problem as a graph network with path-prediction loss to incorporate longer range dependencies. This work also demonstrates how the TDG graph can be used to improve the downstream tasks of temporal questions answering and NLI by a relative 4-10% with a new framework that incorporates the temporal dependency graph into the self-attention layer of Transformer models (Time-transformer). Finally, we develop and evaluate on a new temporal dependency graph dataset for the domain of contractual documents, which has not been previously explored in this setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "1419671559",
                    "name": "Verena Kaynig-Fittkau"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2536742",
                    "name": "Quan Hung Tran"
                },
                {
                    "authorId": "3115414",
                    "name": "A. Nenkova"
                },
                {
                    "authorId": "1699159",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                }
            ]
        },
        {
            "paperId": "d70ffdd0f2aa7ac3c0be42a2eac994fcaa9ed308",
            "title": "User-Entity Differential Privacy in Learning Natural Language Models",
            "abstract": "In this paper, we introduce a novel concept of user-entity differential privacy (UeDP) to provide formal privacy protection simultaneously to both sensitive entities in textual data and data owners in learning natural language models (NLMs). To preserve UeDP, we developed a novel algorithm, called UeDP-Alg, optimizing the trade-off between privacy loss and model utility with a tight sensitivity bound derived from seamlessly combining user and sensitive entity sampling processes. An extensive theoretical analysis and evaluation show that our UeDP-Alg outperforms baseline approaches in model utility under the same privacy budget consumption on several NLM tasks, using benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3450120",
                    "name": "Phung Lai"
                },
                {
                    "authorId": "11032760",
                    "name": "Nhathai Phan"
                },
                {
                    "authorId": "1500530510",
                    "name": "Tong Sun"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "1598478975",
                    "name": "Nikolaos Barmpalios"
                }
            ]
        },
        {
            "paperId": "d87cc52487d5d0a315053f400f8bbb2966d1832b",
            "title": "MONOPOLY: Financial Prediction from MONetary POLicY Conference Videos Using Multimodal Cues",
            "abstract": "Risk prediction and price movement classification are essential tasks in financial markets. Monetary policy calls (MPC) provide important insights into the actions taken by a country's central bank on economic goals related to inflation, employment, prices, and interest rates. Analyzing visual, vocal, and textual cues from MPC calls can help analysts and policymakers evaluate the economic risks and make sound investment decisions. To aid the analysis of MPC calls, we curate the Monopoly dataset, a collection of public conference call videos along with their corresponding audio recordings and text transcripts released by six international banks between 2009 and 2022. Our dataset is the first attempt to explore the benefits of visual cues in addition to audio and textual signals for financial prediction tasks. We introduce MPCNet, a competitive baseline architecture that takes advantage of the cross-modal transformer blocks and modality-specific attention fusion to forecast the financial risk and price movement associated with the MPC calls. Empirical results prove that the task is challenging, with the proposed architecture performing 5-18% better than strong Transformer-based baselines. We release the MPC dataset and benchmark models to motivate future research in this new challenging domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "2187307311",
                    "name": "Malika Chhibber"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2187309035",
                    "name": "Fuming Guo"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "49247327",
                    "name": "Sanghamitra Dutta"
                },
                {
                    "authorId": "1699159",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "6e0bde6ebe84eeb745c42c5901332cdf307bfaab",
            "title": "Syntopical Graphs for Computational Argumentation Tasks",
            "abstract": "Approaches to computational argumentation tasks such as stance detection and aspect detection have largely focused on the text of independent claims, losing out on potentially valuable context provided by the rest of the collection. We introduce a general approach to these tasks motivated by syntopical reading, a reading process that emphasizes comparing and contrasting viewpoints in order to improve topic understanding. To capture collection-level context, we introduce the syntopical graph, a data structure for linking claims within a collection. A syntopical graph is a typed multi-graph where nodes represent claims and edges represent different possible pairwise relationships, such as entailment, paraphrase, or support. Experiments applying syntopical graphs to the problems of detecting stance and aspects demonstrate state-of-the-art performance in each domain, significantly outperforming approaches that do not utilize collection-level information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40080808",
                    "name": "Joe Barrow"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "102031958",
                    "name": "N. Lipka"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "1977256",
                    "name": "Varun Manjunatha"
                },
                {
                    "authorId": "1737250",
                    "name": "Douglas W. Oard"
                },
                {
                    "authorId": "1680292",
                    "name": "P. Resnik"
                },
                {
                    "authorId": "2626599",
                    "name": "Henning Wachsmuth"
                }
            ]
        },
        {
            "paperId": "7354b87a1b4c99ccd9cf25b7314927ced8b156f7",
            "title": "IGA: An Intent-Guided Authoring Assistant",
            "abstract": "While large-scale pretrained language models have significantly improved writing assistance functionalities such as autocomplete, more complex and controllable writing assistants have yet to be explored. We leverage advances in language modeling to build an interactive writing assistant that generates and rephrases text according to fine-grained author specifications. Users provide input to our Intent-Guided Assistant (IGA) in the form of text interspersed with tags that correspond to specific rhetorical directives (e.g., adding description or contrast, or rephrasing a particular sentence). We fine-tune a language model on a dataset heuristically-labeled with author intent, which allows IGA to fill in these tags with generated text that users can subsequently edit to their liking. A series of automatic and crowdsourced evaluations confirm the quality of IGA\u2019s generated outputs, while a small-scale user study demonstrates author preference for IGA over baseline methods in a creative writing task. We release our dataset, code, and demo to spur further research into AI-assisted writing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "23134878",
                    "name": "Simeng Sun"
                },
                {
                    "authorId": "50771250",
                    "name": "Wenlong Zhao"
                },
                {
                    "authorId": "1977256",
                    "name": "Varun Manjunatha"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2881425",
                    "name": "Balaji Vasan Srinivasan"
                },
                {
                    "authorId": "2136562",
                    "name": "Mohit Iyyer"
                }
            ]
        }
    ]
}