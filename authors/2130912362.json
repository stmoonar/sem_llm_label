{
    "authorId": "2130912362",
    "papers": [
        {
            "paperId": "d46aa24ff53532f5e8422d4d7bdc82f221c0f51f",
            "title": "NeuKron: Constant-Size Lossy Compression of Sparse Reorderable Matrices and Tensors",
            "abstract": "Many real-world data are naturally represented as a sparse reorderable matrix, whose rows and columns can be arbitrarily ordered (e.g., the adjacency matrix of a bipartite graph). Storing a sparse matrix in conventional ways requires an amount of space linear in the number of non-zeros, and lossy compression of sparse matrices (e.g., Truncated SVD) typically requires an amount of space linear in the number of rows and columns. In this work, we propose NeuKron for compressing a sparse reorderable matrix into a constant-size space. NeuKron generalizes Kronecker products using a recurrent neural network with a constant number of parameters. NeuKron updates the parameters so that a given matrix is approximated by the product and reorders the rows and columns of the matrix to facilitate the approximation. The updates take time linear in the number of non-zeros in the input matrix, and the approximation of each entry can be retrieved in logarithmic time. We also extend NeuKron to compress sparse reorderable tensors (e.g. multi-layer graphs), which generalize matrices. Through experiments on ten real-world datasets, we show that NeuKron is (a) Compact: requiring up to five orders of magnitude less space than its best competitor with similar approximation errors, (b) Accurate: giving up to 10 \u00d7 smaller approximation error than its best competitors with similar size outputs, and (c) Scalable: successfully compressing a matrix with over 230 million non-zero entries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067591578",
                    "name": "Taehyung Kwon"
                },
                {
                    "authorId": "2072690914",
                    "name": "Jihoon Ko"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "eebdbbc5920c29cc384a404a53446c0187edd31d",
            "title": "Learning Disentangled Representations in Signed Directed Graphs without Social Assumptions",
            "abstract": "Signed graphs are complex systems that represent trust relationships or preferences in various domains. Learning node representations in such graphs is crucial for many mining tasks. Although real-world signed relationships can be influenced by multiple latent factors, most existing methods often oversimplify the modeling of signed relationships by relying on social theories and treating them as simplistic factors. This limits their expressiveness and their ability to capture the diverse factors that shape these relationships. In this paper, we propose DINES, a novel method for learning disentangled node representations in signed directed graphs without social assumptions. We adopt a disentangled framework that separates each embedding into distinct factors, allowing for capturing multiple latent factors. We also explore lightweight graph convolutions that focus solely on sign and direction, without depending on social theories. Additionally, we propose a decoder that effectively classifies an edge's sign by considering correlations between the factors. To further enhance disentanglement, we jointly train a self-supervised factor discriminator with our encoder and decoder. Throughout extensive experiments on real-world signed directed graphs, we show that DINES effectively learns disentangled node representations, and significantly outperforms its competitors in the sign prediction task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189974130",
                    "name": "Geonwoo Ko"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                }
            ]
        },
        {
            "paperId": "3c253a615beedb737c3a679432d777aa70099f69",
            "title": "Accurate Node Feature Estimation with Structured Variational Graph Autoencoder",
            "abstract": "Given a graph with partial observations of node features, how can we estimate the missing features accurately? Feature estimation is a crucial problem for analyzing real-world graphs whose features are commonly missing during the data collection process. Accurate estimation not only provides diverse information of nodes but also supports the inference of graph neural networks that require the full observation of node features. However, designing an effective approach for estimating high-dimensional features is challenging, since it requires an estimator to have large representation power, increasing the risk of overfitting. In this work, we propose SVGA (Structured Variational Graph Autoencoder), an accurate method for feature estimation. SVGA applies strong regularization to the distribution of latent variables by structured variational inference, which models the prior of variables as Gaussian Markov random field based on the graph structure. As a result, SVGA combines the advantages of probabilistic inference and graph neural networks, achieving state-of-the-art performance in real datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "27539372",
                    "name": "Hyunsik Jeon"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "98293695c9f356ca1a5d667ff41d0287aef9a868",
            "title": "Time-aware Random Walk Diffusion to Improve Dynamic Graph Learning",
            "abstract": "How can we augment a dynamic graph for improving the performance of dynamic graph neural networks? Graph augmentation has been widely utilized to boost the learning performance of GNN-based models. However, most existing approaches only enhance spatial structure within an input static graph by transforming the graph, and do not consider dynamics caused by time such as temporal locality, i.e., recent edges are more influential than earlier ones, which remains challenging for dynamic graph augmentation.\nIn this work, we propose TiaRa (Time-aware Random Walk Diffusion), a novel diffusion-based method for augmenting a dynamic graph represented as a discrete-time sequence of graph snapshots. For this purpose, we first design a time-aware random walk proximity so that a surfer can walk along the time dimension as well as edges, resulting in spatially and temporally localized scores. We then derive our diffusion matrices based on the time-aware random walk, and show they become enhanced adjacency matrices that both spatial and temporal localities are augmented. Throughout extensive experiments, we demonstrate that TiaRa effectively augments a given dynamic graph, and leads to significant improvements in dynamic GNN models for various graph datasets and tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189501283",
                    "name": "Jong-whi Lee"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                }
            ]
        },
        {
            "paperId": "2854d58effba72094a2029b1abfd2c1826d205d2",
            "title": "Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion",
            "abstract": "Static knowledge graphs (KGs), despite their wide usage in relational reasoning and downstream tasks, fall short of realistic modeling of knowledge and facts that are only temporarily valid. Compared to static knowledge graphs, temporal knowledge graphs (TKGs) inherently reflect the transient nature of real-world knowledge. Naturally, automatic TKG completion has drawn much research interests for a more realistic modeling of relational reasoning. However, most of the existing models for TKG completion extend static KG embeddings that do not fully exploit TKG structure, thus lacking in 1) accounting for temporally relevant events already residing in the local neighborhood of a query, and 2) path-based inference that facilitates multi-hop reasoning and better interpretability. In this paper, we propose T-GAP, a novel model for TKG completion that maximally utilizes both temporal information and graph structure in its encoder and decoder. T-GAP encodes query-specific substructure of TKG by focusing on the temporal displacement between each event and the query timestamp, and performs path-based inference by propagating attention through the graph. Our empirical experiments demonstrate that T-GAP not only achieves superior performance against state-of-the-art baselines, but also competently generalizes to queries with unseen timestamps. Through extensive qualitative analyses, we also show that T-GAP enjoys transparent interpretability, and follows human intuition in its reasoning process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122355046",
                    "name": "Jaehun Jung"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "23987228",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "0cc13ac0d3dfde407829537e2da0ea33e6a88e4a",
            "title": "Signed Graph Diffusion Network",
            "abstract": "Given a signed social graph, how can we learn appropriate node representations to infer the signs of missing edges? Signed social graphs have received considerable attention to model trust relationships. Learning node representations is crucial to effectively analyze graph data, and various techniques such as network embedding and graph convolutional network (GCN) have been proposed for learning signed graphs. However, traditional network embedding methods are not end-to-end for a specific task such as link sign prediction, and GCN-based methods suffer from a performance degradation problem when their depth increases. In this paper, we propose Signed Graph Diffusion Network (SGDNet), a novel graph neural network that achieves end-to-end node representation learning for link sign prediction in signed social graphs. We propose a random walk technique specially designed for signed graphs so that SGDNet effectively diffuses hidden node features. Through extensive experiments, we demonstrate that SGDNet outperforms state-of-the-art models in terms of link sign prediction accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "bc53f410eea566435adba7683e0579188591632e",
            "title": "BalanSiNG: Fast and Scalable Generation of Realistic Signed Networks",
            "abstract": "How can we e ciently generate large-scale signed networks following real-world properties? Due to its rich modeling capability of representing trust relations as positive and negative edges, signed networks have spurred much interests with various applications. Despite its importance, however, existing models for generating signed networks do not correctly re ect properties of real-world signed networks. In this paper, we propose BalanSiNG, a novel, scalable, and fully parallelizable method for generating large-scale signed networks following realistic properties. We identify a self-similar balanced structure observed from a real-world signed network, and simulate the self-similarity via Kronecker product. Then, we exploit noise and careful weighting of signs such that our resulting network obeys various properties of real-world signed networks. BalanSiNG is easily parallelizable, and we implement it using Spark. Extensive experiments show that BalanSiNG ef-ciently generates the most realistic signed networks satisfying various desired properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "1867932",
                    "name": "Ha-Myung Park"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "fa9fad2d86531cff22983a4a1c56b5258f1fd5b2",
            "title": "T-GAP: Learning to Walk across Time for Temporal Knowledge Graph Completion",
            "abstract": "Temporal knowledge graphs (TKGs) inherently reflect the transient nature of real-world knowledge, as opposed to static knowledge graphs. Naturally, automatic TKG completion has drawn much research interests for a more realistic modeling of relational reasoning. However, most of the existing mod-els for TKG completion extend static KG embeddings that donot fully exploit TKG structure, thus lacking in 1) account-ing for temporally relevant events already residing in the lo-cal neighborhood of a query, and 2) path-based inference that facilitates multi-hop reasoning and better interpretability. In this paper, we propose T-GAP, a novel model for TKG completion that maximally utilizes both temporal information and graph structure in its encoder and decoder. T-GAP encodes query-specific substructure of TKG by focusing on the temporal displacement between each event and the query times-tamp, and performs path-based inference by propagating attention through the graph. Our empirical experiments demonstrate that T-GAP not only achieves superior performance against state-of-the-art baselines, but also competently generalizes to queries with unseen timestamps. Through extensive qualitative analyses, we also show that T-GAP enjoys from transparent interpretability, and follows human intuition in its reasoning process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122355046",
                    "name": "Jaehun Jung"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "961e14aa47eeb9c897dfef0dc69d8339d7d1ef86",
            "title": "Zoom-SVD: Fast and Memory Efficient Method for Extracting Key Patterns in an Arbitrary Time Range",
            "abstract": "Given multiple time series data, how can we efficiently find latent patterns in an arbitrary time range? Singular value decomposition (SVD) is a crucial tool to discover hidden factors in multiple time series data, and has been used in many data mining applications including dimensionality reduction, principal component analysis, recommender systems, etc. Along with its static version, incremental SVD has been used to deal with multiple semi-infinite time series data and to identify patterns of the data. However, existing SVD methods for the multiple time series data analysis do not provide functionality for detecting patterns of data in an arbitrary time range: standard SVD requires data for all intervals corresponding to a time range query, and incremental SVD does not consider an arbitrary time range. In this paper, we propose Zoom-SVD, a fast and memory efficient method for finding latent factors of time series data in an arbitrary time range. Zoom-SVD incrementally compresses multiple time series data block by block to reduce the space cost in storage phase, and efficiently computes singular value decomposition (SVD) for a given time range query in query phase by carefully stitching stored SVD results. Through extensive experiments, we demonstrate that Zoom-SVD is up to 15x faster, and requires 15x less space than existing methods. Our case study shows that Zoom-SVD is useful for capturing past time ranges whose patterns are similar to a query time range.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "145382482",
                    "name": "Jun-Gi Jang"
                },
                {
                    "authorId": "2026030439",
                    "name": "Dongjin Choi"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "b9bf3644085d0d25b5f12b1142a6217c230d2698",
            "title": "TR-SVD: Fast and Memory Efficient Method for Time Ranged Singular Value Decomposition",
            "abstract": "Given multiple time series data, how can we efficiently find latent patterns in an arbitrary time range? Singular value decomposition (SVD) is a crucial tool to discover hidden factors in multiple time series data, and has been used in many data mining applications including dimensionality reduction, principal component analysis, recommender systems, etc. Along with its static version, incremental SVD has been used to deal with multiple semi-infinite time series data and to identify patterns of the data. However, existing SVD methods for the multiple time series data analysis do not provide functionality for detecting patterns of data in an arbitrary time range: standard SVD requires data for all intervals corresponding to a time range query, and incremental SVD does not consider an arbitrary time range. In this paper, we propose TR-SVD (Time Ranged Singular Value Decomposition), a fast and memory efficient method for finding latent factors of time series data in an arbitrary time range. TR-SVD incrementally compresses multiple time series data block by block to reduce the space cost in storage phase, and efficiently computes singular value decomposition (SVD) for a given time range query in query phase by carefully stitching stored SVD results. Through extensive experiments, we demonstrate that TR-SVD is up to 15 x faster, and requires 15 x less space than existing methods. Our case study shows that TR-SVD is useful for capturing past time ranges whose patterns are similar to a query time range.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145382482",
                    "name": "Jun-Gi Jang"
                },
                {
                    "authorId": "2026030439",
                    "name": "Dongjin Choi"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        }
    ]
}