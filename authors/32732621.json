{
    "authorId": "32732621",
    "papers": [
        {
            "paperId": "59424220241289ba6b693bf419b17d8cf31a70ff",
            "title": "On the Adaptation of Unlimiformer for Decoder-Only Transformers",
            "abstract": "One of the prominent issues stifling the current generation of large language models is their limited context length. Recent proprietary models such as GPT-4 and Claude 2 have introduced longer context lengths, 8k/32k and 100k, respectively; however, despite the efforts in the community, most common models, such as LLama-2, have a context length of 4k or less. Unlimiformer (Bertsch et al., 2023) is a recently popular vector-retrieval augmentation method that offloads cross-attention computations to a kNN index. However, its main limitation is incompatibility with decoder-only transformers out of the box. In this work, we explore practical considerations of adapting Unlimiformer to decoder-only transformers and introduce a series of modifications to overcome this limitation. Moreover, we expand the original experimental setup on summarization to include a new task (i.e., free-form Q&A) and an instruction-tuned model (i.e., a custom 6.7B GPT model). Our results showcase the effectiveness of these modifications on summarization, performing on par with a model with 2x the context length. Moreover, we discuss limitations and future directions for free-form Q&A and instruction-tuned models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "102222453",
                    "name": "Alon Benhaim"
                },
                {
                    "authorId": "27419446",
                    "name": "Barun Patra"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                },
                {
                    "authorId": "14839052",
                    "name": "Saksham Singhal"
                },
                {
                    "authorId": "2301764251",
                    "name": "Xia Song"
                }
            ]
        },
        {
            "paperId": "cdce4525bc94b8b72d7330f4e26775142edd0018",
            "title": "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models",
            "abstract": "While large language models (LLMs) are still being adopted to new domains and utilized in novel applications, we are experiencing an influx of the new generation of foundation models, namely multi-modal large language models (MLLMs). These models integrate verbal and visual information, opening new possibilities to demonstrate more complex reasoning abilities at the intersection of the two modalities. However, despite the revolutionizing prospect of MLLMs, our understanding of their reasoning abilities is limited. In this study, we assess the nonverbal abstract reasoning abilities of open-source and closed-source MLLMs using variations of Raven's Progressive Matrices. Our experiments reveal the challenging nature of such problems for MLLMs while showcasing the immense gap between open-source and closed-source models. We also uncover critical shortcomings of visual and textual perceptions, subjecting the models to low-performance ceilings. Finally, to improve MLLMs' performance, we experiment with different methods, such as Chain-of-Thought prompting, leading to a significant (up to 100%) boost in performance. Our code and datasets are available at https://github.com/usc-isi-i2/isi-mmlm-rpm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2280276151",
                    "name": "Kexuan Sun"
                },
                {
                    "authorId": "2261394194",
                    "name": "Jiarui Zhang"
                },
                {
                    "authorId": "2280252269",
                    "name": "Yifan Jiang"
                },
                {
                    "authorId": "2258550405",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                }
            ]
        },
        {
            "paperId": "ebdb35c3a7efb5e0d4d79bdcfd167051446aba7a",
            "title": "The Hitchhiker's Guide to Human Alignment with *PO",
            "abstract": "With the growing utilization of large language models (LLMs) across domains, alignment towards human preferences has become one of the most critical aspects of training models. At the forefront of state-of-the-art human alignment methods are preference optimization methods (*PO). However, prior research has often concentrated on identifying the best-performing method, typically involving a grid search over hyperparameters, which can be impractical for general practitioners. In this paper, we aim to identify the algorithm that, while being performant, is simultaneously more robust to varying hyperparameters, thereby increasing the likelihood of achieving better results. We focus on a realistic out-of-distribution (OOD) scenario that mirrors real-world applications of human alignment, offering practical insights into the strengths and weaknesses of these methods. Furthermore, to better understand the shortcomings of generations from the different methods, we analyze the model generations through the lens of KL divergence of the SFT model and the response length statistics. Our analysis reveals that the widely adopted DPO method consistently produces lengthy responses of inferior quality that are very close to the SFT responses. Motivated by these findings, we propose an embarrassingly simple extension to the DPO algorithm, LN-DPO, resulting in more concise responses without sacrificing quality compared to the policy obtained by vanilla DPO.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2312344360",
                    "name": "Xihui Lin"
                },
                {
                    "authorId": "27419446",
                    "name": "Barun Patra"
                },
                {
                    "authorId": "113810201",
                    "name": "Vishrav Chaudhary"
                },
                {
                    "authorId": "102222453",
                    "name": "Alon Benhaim"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                },
                {
                    "authorId": "2301764251",
                    "name": "Xia Song"
                }
            ]
        },
        {
            "paperId": "fdc7c55eeb2151b3bb5f54c0982883bcaa56fe21",
            "title": "Surprising Resilience of Science During a Global Pandemic: A Large-Scale Descriptive Analysis",
            "abstract": "The COVID-19 pandemic profoundly impacted people globally, yet its effect on scientists and research institutions has yet to be fully examined. To address this knowledge gap, we use a newly available bibliographic dataset covering tens of millions of papers and authors to investigate changes in research activity and collaboration during this period. Employing statistical methods, we analyze the pandemic's disruptions on the participation, productivity, and collaborations of researchers at the top 1,000 institutions worldwide based on historical productivity, taking into account variables such as geography, researcher seniority and gender, and field of study. Our findings reveal an unexpected trend: research activity and output significantly increased in the early stages of the pandemic, indicating a surprising resilience in the scientific community. However, by the end of 2022, there was a notable reversion to historical trends in research participation and productivity. This reversion suggests that the initial spike in research activity was a short-lived disruption rather than a permanent shift. As such, monitoring scientific outputs in 2023 and beyond becomes crucial. There may be a delayed negative effect of the pandemic on research, given the long time horizon for many research fields and the temporary closure of wet labs. Further analysis is needed to fully comprehend the factors that underpin the resilience of scientific innovation in the face of global crises. Our study provides an initial comprehensive exploration up to the end of 2022, offering valuable insights into how the scientific community has adapted and responded over the course of the pandemic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2214035571",
                    "name": "Casandra Rusti"
                },
                {
                    "authorId": "2320815585",
                    "name": "Ziao Wang"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                },
                {
                    "authorId": "2320800305",
                    "name": "Kristina Lerman"
                }
            ]
        },
        {
            "paperId": "ff05de1241fd5a5a2e05f7ed298e5ba9a123d7ba",
            "title": "MARVEL: Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning",
            "abstract": "While multi-modal large language models (MLLMs) have shown significant progress on many popular visual reasoning benchmarks, whether they possess abstract visual reasoning abilities remains an open question. Similar to the Sudoku puzzles, abstract visual reasoning (AVR) problems require finding high-level patterns (e.g., repetition constraints) that control the input shapes (e.g., digits) in a specific task configuration (e.g., matrix). However, existing AVR benchmarks only considered a limited set of patterns (addition, conjunction), input shapes (rectangle, square), and task configurations (3 by 3 matrices). To evaluate MLLMs' reasoning abilities comprehensively, we introduce MARVEL, a multidimensional AVR benchmark with 770 puzzles composed of six core knowledge patterns, geometric and abstract shapes, and five different task configurations. To inspect whether the model accuracy is grounded in perception and reasoning, MARVEL complements the general AVR question with perception questions in a hierarchical evaluation framework. We conduct comprehensive experiments on MARVEL with nine representative MLLMs in zero-shot and few-shot settings. Our experiments reveal that all models show near-random performance on the AVR question, with significant performance gaps (40%) compared to humans across all patterns and task configurations. Further analysis of perception questions reveals that MLLMs struggle to comprehend the visual features (near-random performance) and even count the panels in the puzzle (<45%), hindering their ability for abstract reasoning. We release our entire code and dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280252269",
                    "name": "Yifan Jiang"
                },
                {
                    "authorId": "2261394194",
                    "name": "Jiarui Zhang"
                },
                {
                    "authorId": "2280276151",
                    "name": "Kexuan Sun"
                },
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "22244290",
                    "name": "Kaixin Ma"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                }
            ]
        },
        {
            "paperId": "04c6a828169c683b69064d10f4bca39fb83b18b1",
            "title": "Is Dynamicity All You Need?",
            "abstract": "Scientific domains are fluid entities that change and turn as time passes. Take machine learning as an example. Up until the \u201990s, most of the methods were expert-knowledge-driven. However, as time passed, more data-driven approaches appeared, finally leading to the advent of deep learning methods. As a result, in a span of 30 years, the field has gone through many changes and breakthroughs and is at a point where many novelties have a life span of shorter than five years. In parallel, a regular researcher\u2019s career span is around the same length. Consequently, being a researcher requires shifts in the field of study throughout one\u2019s career. Besides, researchers\u2019 scientific interests are inherently dynamic and change over time. Hence, there exists a dynamicity to authors\u2019 interests and fields of work over time. In this work, we study this phenomenon through systematic approaches for representing and tracking dynamicity in different epochs. Our representation approaches are based on the idea that each author could be represented as a distribution of other authors. Concurrently, our tracking approaches rely on established mathematical concepts for measuring the change between two distributions. We focus on the publications in the 2001-2020 range and present a set of analyses built on top of the introduced approaches to understanding the potential connection between dynamicity and success.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1850429085",
                    "name": "Richard Delwin Myloth"
                },
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2204572135",
                    "name": "Arun Baalaaji Sankar Ananthan"
                },
                {
                    "authorId": "2152944834",
                    "name": "Xinwei Du"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                }
            ]
        },
        {
            "paperId": "59f4b2103d6a78ebad51db8bd603d4c5571c0cbf",
            "title": "Citation Intent Classification Through Weakly Supervised Knowledge Graphs",
            "abstract": "Citations are scientists\u2019 tools for grounding their innovations and findings in the existing collective knowledge. They are used for semantically distinct purposes as scientists utilize them at different parts of their work to convey specific information. As a result, a crucial aspect of scientific document understanding is recognizing the authorial intent associated with citations. Current state-of-the-art methods rely on contextual sentences surrounding each citation to classify the intent. However, in the absence of textual content, these approaches become unusable. In this work, we propose a text-free citation intent classification method built on relational information among scholarly works in this work. To this end, we introduce a large-scale knowledge graph built from the publications in the SciCite dataset and their multi-hop neighborhood extracted from The Semantic Scholar Open Research Corpus (S2ORC). We also augment this knowledge graph by adding weakly-labeled links based on the intent information available in the S2ORC. Finally, we cast the intent classification task as a link prediction problem on the newly created knowledge graph. We study this problem in both transductive and inductive settings. Our experimental results show that we can achieve a comparable macro F1 score to word embedding content-based methods by only relying on features and relations derived from this knowledge graph. Specifically, we achieve macro F1 scores of 62.16 and 59.81 in the transductive and inductive settings, respectively, on the link-level SciCite dataset. Moreover, by combining our method with the state-of-the-art NLP-based model, we achieve improvements across all metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152944834",
                    "name": "Xinwei Du"
                },
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2204572135",
                    "name": "Arun Baalaaji Sankar Ananthan"
                },
                {
                    "authorId": "1850429085",
                    "name": "Richard Delwin Myloth"
                },
                {
                    "authorId": "2259931859",
                    "name": "Jay Pujara"
                }
            ]
        },
        {
            "paperId": "64fcc4ccc5cecc63f3456558f6deb8a1e89923c7",
            "title": "PubGraph: A Large-Scale Scientific Knowledge Graph",
            "abstract": "Research publications are the primary vehicle for sharing scientific progress in the form of new discoveries, methods, techniques, and insights. Unfortunately, the lack of a large-scale, comprehensive, and easy-to-use resource capturing the myriad relationships between publications, their authors, and venues presents a barrier to applications for gaining a deeper understanding of science. In this paper, we present PubGraph, a new resource for studying scientific progress that takes the form of a large-scale knowledge graph (KG) with more than 385M entities, 13B main edges, and 1.5B qualifier edges. PubGraph is comprehensive and unifies data from various sources, including Wikidata, OpenAlex, and Semantic Scholar, using the Wikidata ontology. Beyond the metadata available from these sources, PubGraph includes outputs from auxiliary community detection algorithms and large language models. To further support studies on reasoning over scientific networks, we create several large-scale benchmarks extracted from PubGraph for the core task of knowledge graph completion (KGC). These benchmarks present many challenges for knowledge graph embedding models, including an adversarial community-based KGC evaluation setting, zero-shot inductive learning, and large-scale learning. All of the aforementioned resources are accessible at https://pubgraph.isi.edu/ and released under the CC-BY-SA license. We plan to update PubGraph quarterly to accommodate the release of new publications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2152944834",
                    "name": "Xinwei Du"
                },
                {
                    "authorId": "1850429085",
                    "name": "Richard Delwin Myloth"
                },
                {
                    "authorId": "2204572135",
                    "name": "Arun Baalaaji Sankar Ananthan"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "c9f83c0fa1425d61c5b16aadc4492ad53e4fbda2",
            "title": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning",
            "abstract": "Temporal knowledge graph (TKG) forecasting benchmarks challenge models to predict future facts using knowledge of past facts. In this paper, we apply large language models (LLMs) to these benchmarks using in-context learning (ICL). We investigate whether and to what extent LLMs can be used for TKG forecasting, especially without any fine-tuning or explicit modules for capturing structural and temporal information. For our experiments, we present a framework that converts relevant historical facts into prompts and generates ranked predictions using token probabilities. Surprisingly, we observe that LLMs, out-of-the-box, perform on par with state-of-the-art TKG models carefully designed and trained for TKG forecasting. Our extensive evaluation presents performances across several models and datasets with different characteristics, compares alternative heuristics for preparing contextual information, and contrasts to prominent TKG methods and simple frequency and recency baselines. We also discover that using numerical indices instead of entity/relation names, i.e., hiding semantic information, does not significantly affect the performance ($\\pm$0.4\\% Hit@1). This shows that prior semantic knowledge is unnecessary; instead, LLMs can leverage the existing patterns in the context to achieve such performance. Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond simple predictions based on common or recent information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115475530",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "8844876",
                    "name": "Woojeong Jin"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "e6fba323a73d7c829b490e5b09dc136f3919c827",
            "title": "PubGraph: A Large Scale Scientific Temporal Knowledge Graph",
            "abstract": "Research publications are the primary vehicle for sharing sci-enti\ufb01c progress in the form of new discoveries, methods, techniques, and insights. Publications have been studied from the perspectives of both content analysis and bibliometric structure, but a barrier to more comprehensive studies of scien-ti\ufb01c research is a lack of publicly accessible large-scale data and resources. In this paper, we present PubGraph , a new resource for studying scienti\ufb01c progress that takes the form of a large-scale temporal knowledge graph (KG). It contains more than 432M nodes and 15.49B edges mapped to the popular Wikidata ontology. We extract three KGs with varying sizes from PubGraph to allow experimentation at different scales. Using these KGs, we introduce a new link prediction benchmark for transductive and inductive settings with temporally-aligned training, validation, and testing partitions. Moreover, we develop two new inductive learning methods better suited to PubGraph, operating on unseen nodes without explicit features, scaling to large KGs, and outperforming existing models. Our results demonstrate that structural features of past citations are suf\ufb01cient to produce high-quality predictions about new publications. We also identify new challenges for KG models, including an adversarial community-based link prediction setting, zero-shot inductive learning, and large-scale learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2152944834",
                    "name": "Xinwei Du"
                },
                {
                    "authorId": "1850429085",
                    "name": "Richard Delwin Myloth"
                },
                {
                    "authorId": "2204572135",
                    "name": "Arun Baalaaji Sankar Ananthan"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        }
    ]
}