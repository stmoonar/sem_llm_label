{
    "authorId": "2109519939",
    "papers": [
        {
            "paperId": "2786f4d208e1fdafe33eae9e9db4bb7303538dae",
            "title": "Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs",
            "abstract": "Real-world graphs are dynamic, constantly evolving with new interactions, such as financial transactions in financial networks. \nTemporal Graph Neural Networks (TGNNs) have been developed to effectively capture the evolving patterns in dynamic graphs.\nWhile these models have demonstrated their superiority, being widely adopted in various important fields, their vulnerabilities against adversarial attacks remain largely unexplored.\nIn this paper, we propose T-SPEAR, a simple and effective adversarial attack method for link prediction on continuous-time dynamic graphs, focusing on investigating the vulnerabilities of TGNNs.\nSpecifically, before the training procedure of a victim model, which is a TGNN for link prediction, we inject edge perturbations to the data that are unnoticeable in terms of the four constraints we propose, and yet effective enough to cause malfunction of the victim model. \nMoreover, we propose a robust training approach T-SHIELD to mitigate the impact of adversarial attacks.\nBy using edge filtering and enforcing temporal smoothness to node embeddings, we enhance the robustness of the victim model.\nOur experimental study shows that T-SPEAR significantly degrades the victim model's performance on link prediction tasks, and even more, our attacks are transferable to other TGNNs, which differ from the victim model assumed by the attacker.\nMoreover, we demonstrate that T-SHIELD effectively filters out adversarial edges and exhibits robustness against adversarial attacks, surpassing the link prediction performance of the naive TGNN by up to 11.2% under T-SPEAR.\nThe code and datasets are available at https://github.com/wooner49/T-spear-shield",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109519939",
                    "name": "Dongjin Lee"
                },
                {
                    "authorId": "2108550899",
                    "name": "Juho Lee"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "2e6513f3333e7b4042587e79464755b9e72069d4",
            "title": "Graphlets over Time: A New Lens for Temporal Network Analysis",
            "abstract": "Graphs are widely used for modeling various types of interactions, such as email communications and online discussions. Many of such real-world graphs are temporal, and specifically, they grow over time with new nodes and edges. Counting the instances of each graphlet (i.e., an induced subgraph isomorphism class) has been successful in characterizing local structures of graphs, with many applications. While graphlets have been extended for temporal graphs, the extensions are designed for examining temporally-local subgraphs composed of edges with close arrival times, instead of long-term changes in local structures. In this paper, as a new lens for temporal graph analysis, we study the evolution of distributions of graphlet instances over time in real-world graphs at three different levels (graphs, nodes, and edges). At the graph level, we first discover that the evolution patterns are significantly different from those in random graphs. Then, we suggest a graphlet transition graph for measuring the similarity of the evolution patterns of graphs, and we find out a surprising similarity between the graphs from the same domain. At the node and edge levels, we demonstrate that the local structures around nodes and edges in their early stage provide a strong signal regarding their future importance. In particular, we significantly improve the predictability of the future importance of nodes and edges using the counts of the roles (a.k.a., orbits) that they take within graphlets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1726573745",
                    "name": "Deukryeol Yoon"
                },
                {
                    "authorId": "2109519939",
                    "name": "Dongjin Lee"
                },
                {
                    "authorId": "2047035591",
                    "name": "Minyoung Choe"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "84c790e54149b74a0ebfaabedb40a90d56d28950",
            "title": "I'm Me, We're Us, and I'm Us: Tri-directional Contrastive Learning on Hypergraphs",
            "abstract": "Although machine learning on hypergraphs has attracted considerable attention, most of the works have focused on (semi-)supervised learning, which may cause heavy labeling costs and poor generalization. Recently, contrastive learning has emerged as a successful unsupervised representation learning method. Despite the prosperous development of contrastive learning in other domains, contrastive learning on hypergraphs remains little explored. In this paper, we propose TriCL (Tri-directional Contrastive Learning), a general framework for contrastive learning on hypergraphs. Its main idea is tri-directional contrast, and specifically, it aims to maximize in two augmented views the agreement (a) between the same node, (b) between the same group of nodes, and (c) between each group and its members. Together with simple but surprisingly effective data augmentation and negative sampling schemes, these three forms of contrast enable TriCL to capture both node- and group-level structural information in node embeddings. Our extensive experiments using 14 baseline approaches, 10 datasets, and two tasks demonstrate the effectiveness of TriCL, and most noticeably, TriCL almost consistently outperforms not just unsupervised competitors but also (semi-)supervised competitors mostly by significant margins for node classification. The code and datasets are available at https://github.com/wooner49/TriCL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109519939",
                    "name": "Dongjin Lee"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "2f2319417919b69cc73b5b451cc3bab4093c74db",
            "title": "Robust Factorization of Real-world Tensor Streams with Patterns, Missing Values, and Outliers",
            "abstract": "Consider multiple seasonal time series being collected in real-time, in the form of a tensor stream. Real-world tensor streams often include missing entries (e.g., due to network disconnection) and at the same time unexpected outliers (e.g., due to system errors). Given such a real-world tensor stream, how can we estimate missing entries and predict future evolution accurately in real-time?In this work, we answer this question by introducing SOFIA, a robust factorization method for real-world tensor streams. In a nutshell, SOFIA smoothly and tightly integrates tensor factorization, outlier removal, and temporal-pattern detection, which naturally reinforce each other. Moreover, SOFIA integrates them in linear time, in an online manner, despite the presence of missing entries. We experimentally show that SOFIA is (a) robust and accurate: yielding up to 76% lower imputation error and 71% lower forecasting error; (b) fast: up to 935\u00d7 faster than the second-most accurate competitor; and (c) scalable: scaling linearly with the number of new entries per time step.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109519939",
                    "name": "Dongjin Lee"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "59e7e4a652ff7d98401e2230dc2cf6be87a90e19",
            "title": "SliceNStitch: Continuous CP Decomposition of Sparse Tensor Streams",
            "abstract": "Consider traffic data (i.e., triplets in the form of source-destination-timestamp) that grow over time. Tensors (i.e., multi-dimensional arrays) with a time mode are widely used for modeling and analyzing such multi-aspect data streams. In such tensors, however, new entries are added only once per period, which is often an hour, a day, or even a year. This discreteness of tensors has limited their usage for real-time applications, where new data should be analyzed instantly as it arrives.How can we analyze time-evolving multi-aspect sparse data \u2018continuously\u2019 using tensors where time is \u2018discrete\u2019? We propose SLICENSTITCH for continuous CANDECOMP/PARAFAC (CP) decomposition, which has numerous time-critical applications, including anomaly detection, recommender systems, and stock market prediction. SLICENSTITCH changes the starting point of each period adaptively, based on the current time, and updates factor matrices (i.e., outputs of CP decomposition) instantly as new data arrives. We show, theoretically and experimentally, that SLICENSTITCH is (1) \u2018Any time\u2019: updating factor matrices immediately without having to wait until the current time period ends, (2) Fast: with constant-time updates up to 464\u00d7 faster than online methods, and (3) Accurate: with fitness comparable (specifically, 72 \u2212 100%) to offline methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067591578",
                    "name": "Taehyung Kwon"
                },
                {
                    "authorId": "51108719",
                    "name": "Inkyu Park"
                },
                {
                    "authorId": "2109519939",
                    "name": "Dongjin Lee"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                }
            ]
        }
    ]
}