{
    "authorId": "1691320",
    "papers": [
        {
            "paperId": "95d358b78a7e5f0aaa1cd6f14c3f9f4b4f08d7b2",
            "title": "ConSolid: A federated ecosystem for heterogeneous multi-stakeholder projects",
            "abstract": ". In many industries, multiple parties collaborate on a larger project. At the same time, each of those stakeholders participates in multiple independent projects simultaneously. A double patchwork can thus be identified, with a many-to-many relationship between actors and collaborative projects. One key example is the construction industry, where every project is unique, involving specialists for many subdomains, ranging from the architectural design over technical installations to geospatial information, governmental regulation and sometimes even historical research. A digital representation of this process and its outcomes requires semantic interoperability between these subdomains, which however often work with heterogeneous and unstructured data. In this paper we propose to address this double patchwork via a decentralized ecosystem for multi-stakeholder, multi-industry collaborations dealing with heterogeneous information snippets. At its core, this ecosystem, called ConSolid, builds upon the Solid specifications for Web decentralization, but extends these both on a (meta)data pattern level and on microservice level. To increase the robustness of data allocation and filtering, we identify the need to go beyond Solid\u2019s current LDP-inspired interfaces to a Solid Pod and introduce the concept of metadata-generated \u2018virtual views\u2019, to be generated using an access-controlled SPARQL interface to a Pod. A recursive, scalable way to discover multi-vault aggregations is proposed, along with data patterns for connecting and aligning heterogeneous (RDF and non-RDF) resources across vaults in a mediatype-agnostic fashion. We demonstrate the use and benefits of the ecosystem using minimal running examples, concluding with the setup of an example use case from the Architecture, Engineering, Construction and Operations (AECO) industry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151067933",
                    "name": "J. Werbrouck"
                },
                {
                    "authorId": "2300290678",
                    "name": "Pieter Pauwels"
                },
                {
                    "authorId": "2300290334",
                    "name": "Jakob Beetz"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "07684f4d7aa66c507dc0db1ecf02b91e46913752",
            "title": "Integrating OSLO semantics in word processors",
            "abstract": "Documents issued by the government such as public tenders or policy documents often lack consistent semantics, which leads to ambiguities and misinterpretations. Take for example granting subsidies to companies. The conditions for entitlement to a subsidy are checked against the government\u2019s authentic data sources. However, the various governments and administrations have different definitions of, for instance, a small and medium-sized enterprise (SME), which can be derived from a European legal framework or a financial perspective. The absence of uniform definitions for these terms results in a lot of duplicate efforts for both the government and the entrepreneur. To tackle the problem of semantics, Flanders founded an interoperability program, Open Standards for Linked Organizations (OSLO) whose primary goal is to ensure that systems exchanging data can use a common vocabulary. However, despite the results made by OSLO, they do not reach policy-makers working mainly on the legal and organizational levels. We developed two tools to close this gap and make semantic agreements available at these levels. With OSLO Lookup, we provide a simple user interface that lets users query the semantics assets, while the OSLO365 plugin allows embedding the semantic assets in a Microsoft Word document. To assess the relevance and usability of these tools, servants of a local administration were interviewed. This paper outlines that semantic agreements that are mainly used on the data level can provide added value at an organizational and legal level as well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191237211",
                    "name": "Dwight Van Lancker"
                },
                {
                    "authorId": "2191237194",
                    "name": "Niels Van Durme"
                },
                {
                    "authorId": "108028384",
                    "name": "Eveline Vlassenroot"
                },
                {
                    "authorId": "3340761",
                    "name": "Raf Buyle"
                },
                {
                    "authorId": "1804736",
                    "name": "P. Mechant"
                },
                {
                    "authorId": "2370758",
                    "name": "Pieter Colpaert"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "2cc3ddcb4f106dac8571d2006d44bb3de233647a",
            "title": "Fine-tuning mT5-based Transformer via CMA-ES for Sentiment Analysis",
            "abstract": "In this paper, we describe the methods used to submit our results to the Rest-Mex Sentiment Analysis of the Iberian Languages Evaluation Forum 2022. The addressed challenge proposes a sentiment analysis task of Spanish opinions, categorizing each message into five emotions, and an attraction prediction subtask divided into three categories. Accordingly, our contribution is a hybrid method based on the Estimation of Distribution Algorithms for fine-tuning an mT5-based transformer. For this, we propose the design and development of a deep learning model using the encoder part of the pre-trained mT5-based transformer. The proposed model is trained by dividing the process into two stages using AdamW and the Covariance Matrix Adaptation Evolution Strategy. With this approach, 0.3050 of Mean Absolute Error was obtained for the polarity detection subtask and 0.9781 of Macro F-measure for the attraction prediction subtask, reaching the 10th place out of the 24 teams in competition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139443557",
                    "name": "O. G. Toledano-L\u00f3pez"
                },
                {
                    "authorId": "29927552",
                    "name": "Julio Madera"
                },
                {
                    "authorId": "2136933569",
                    "name": "Hector Gonz\u00e1lez"
                },
                {
                    "authorId": "1404582383",
                    "name": "Alfredo Sim\u00f3n-Cuevas"
                },
                {
                    "authorId": "1388296896",
                    "name": "Thomas Demeester"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "61d55dfc573b5a575ea1b4b5883241ab0abf484a",
            "title": "Mapping Federated AEC Projects to Industry Standards Using Dynamic Views",
            "abstract": "Web-based construction projects are rapidly becoming commonplace. Domain-specific collaboration platforms, the so-called Common Data Environments (CDEs), facilitate complex interactions between the various stakeholders participating in a project. CDEs are developed and maintained by the large BIM companies allowing deep integration with BIM authoring tools. Notwithstanding the benefits such integration offers, usage of proprietary tools, data models and platforms holds the risk of a vendor lock-in and creates dependencies on platform APIs as the sole funnels trough which project data can be accessed - even when using open data formats. Recently, technologies for re-decentralising the Web are under increasing interest, as they allow decoupling data storage from applications. The Solid initiative bundles these technologies in a domain-independent way. In previous work we have already discussed data patterns for the AEC industry, using these technologies - the LBDserver. In this paper, we demonstrate how these very generic data organisation patterns can be aligned with organisational structures of some common industry standards: ISO 19650, ISO 21597 and the BCF API specifications. To achieve full alignment with all three standards will be out of scope for this paper. Rather the aim is to demonstrate a Linked Data-based, federated environment such as the LBDserver is compatible with existing (centralised) approaches while maintaining the benefits of organising digital projects in a federated way.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151067933",
                    "name": "J. Werbrouck"
                },
                {
                    "authorId": "39454836",
                    "name": "P. Pauwels"
                },
                {
                    "authorId": "144204299",
                    "name": "J. Beetz"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "0f32ae0eb2cc0d626a8649c56b13df8f43bba59e",
            "title": "Visual notations for viewing RDF constraints with UnSHACLed",
            "abstract": "The quality of knowledge graphs can be assessed by a validation against specified constraints, typically use-case specific and modeled by human users in a manual fashion. Visualizations can improve the modeling process as they are specifically designed for human information processing, possibly leading to more accurate constraints, and in turn higher quality knowledge graphs. However, it is currently unknown how such visualizations support users when viewing RDF constraints as no scientific evidence for the visualizations\u2019 effectiveness is provided. Furthermore, some of the existing tools are likely suboptimal, as they lack support for edit\u00a0operations or common constraints types. To establish a\u00a0baseline, we have defined visual notations to represent RDF constraints and implemented them in UnSHACLed, a\u00a0tool that is independent of a\u00a0concrete RDF constraint language. In this paper, we (i)\u00a0present two visual notations that support all SHACL core constraints, built upon the commonly used visualizations VOWL and UML, (ii)\u00a0analyze both notations based on cognitive effective design principles, (iii)\u00a0perform a comparative user study between both visual notations, and (iv)\u00a0present our open source tool UnSHACLed incorporating our efforts. Users were presented RDF constraints in both visual notations and had to answer questions based on visualization task taxonomies. Although no statistical significant difference in mean error rates was observed, all study participants preferred ShapeVOWL in a self assessment to answer RDF constraint-related questions. Furthermore, ShapeVOWL adheres to more cognitive effective design principles according to our performed comparison. Study participants argued that the increased visual features of ShapeVOWL made it easier to spot constraints, but a list of constraints\u00a0\u2013 as in ShapeUML\u00a0\u2013 is easier to read. However, also that more deviations from the strict UML specification and introduction of more visual features can improve ShapeUML. From these findings we conclude that ShapeVOWL has a higher potential to represent RDF constraints more effective compared to ShapeUML. But also that the clear and efficient text encoding of ShapeUML can be improved with visual features. A\u00a0one-size-fits-all approach to RDF constraint visualization and editing will be insufficient. Therefore, to support different audiences and use cases, user interfaces of RDF constraint editors need to support different visual notations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38278085",
                    "name": "S. Lieber"
                },
                {
                    "authorId": "2141864424",
                    "name": "Ben De\u00a0Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2141885284",
                    "name": "Femke Br\u00fcckmann"
                },
                {
                    "authorId": "2141886718",
                    "name": "Ruben Wambacq"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "0f4a6b90e61605d21063a8ed1606eeb49ea6134d",
            "title": "Dynamic Workflow Composition with OSLO-steps: Data Re-use and Simplification of Automated Administration",
            "abstract": "e-Government applications have hard-coded and non-personalized user journeys with high maintenance costs to keep up with, e.g., changing legislation. Automatic administrative workflows are needed. We present the OSLO-steps vocabulary and the workflow composer: combined, they are a means to create cross-organizational interoperable user journeys, adapted to the user's needs. We identify the requirements for automating administrative workflows and present an architecture and its implemented components. By using Linked Data principles to decentrally describe independent steps using states as pre- and postconditions, and composing workflows on-the-fly whilst matching a user's state to those preconditions, we automatically generate next steps to reach the user's goal. The validated solution shows its feasibility, and the upcoming interest around interoperable personal data pods (e.g., via Solid) can further increase its potential.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38127359",
                    "name": "D\u00f6rthe Arndt"
                },
                {
                    "authorId": "38278085",
                    "name": "S. Lieber"
                },
                {
                    "authorId": "3340761",
                    "name": "Raf Buyle"
                },
                {
                    "authorId": "3342028",
                    "name": "S. Goossens"
                },
                {
                    "authorId": "2142214321",
                    "name": "David De Block"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "2520d7ddb189e95134ba6170527ad30ae31a5b20",
            "title": "A Sustainable Method for Publishing Interoperable Open Data on the Web",
            "abstract": "Smart cities need (sensor) data for better decision-making. However, while there are vast amounts of data available about and from cities, an intermediary is needed that connects and interprets (sensor) data on a Web-scale. Today, governments in Europe are struggling to publish open data in a sustainable, predictable and cost-effective way. Our research question considers what methods for publishing Linked Open Data time series, in particular air quality data, are suitable in a sustainable and cost-effective way. Furthermore, we demonstrate the cross-domain applicability of our data publishing approach through a different use case on railway infrastructure\u2014Linked Open Data. Based on scenarios co-created with various governmental stakeholders, we researched methods to promote data interoperability, scalability and flexibility. The results show that applying a Linked Data Fragments-based approach on public endpoints for air quality and railway infrastructure data, lowers the cost of publishing and increases availability due to better Web caching strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3340761",
                    "name": "Raf Buyle"
                },
                {
                    "authorId": "40976640",
                    "name": "Brecht Van de Vyvere"
                },
                {
                    "authorId": "40973821",
                    "name": "J. A. Mel\u00e9ndez"
                },
                {
                    "authorId": "2077360181",
                    "name": "D. V. Lancker"
                },
                {
                    "authorId": "108028384",
                    "name": "Eveline Vlassenroot"
                },
                {
                    "authorId": "1870351",
                    "name": "Mathias Van Compernolle"
                },
                {
                    "authorId": "1412564498",
                    "name": "Stefan Lefever"
                },
                {
                    "authorId": "2370758",
                    "name": "Pieter Colpaert"
                },
                {
                    "authorId": "1804736",
                    "name": "P. Mechant"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "2aa53d0316c8dbbfa222a9cface46f6dcbaed931",
            "title": "Data patterns for the organisation of federated linked building data",
            "abstract": ". Few industries are as fragmented as the building sector: during the life cycle of an asset, countless stakeholders are involved, ranging from direct stakeholders such as the architect, the owner and the facility manager towards indirect data providers like governments or geospatial institutions. This \u2018federated\u2019 reality contrasts with the concept of a \u2018cen-tralised\u2019 cloud server; a \u2018Common Data Environment\u2019 (CDE). In this paper, we propose a basic infrastructure for a \u2018federated CDE\u2019, using domain-agnostic Web speci\ufb01cations for (access-controlled) data federation. This infrastructure is illustrated via a proof-of-concept implementation, based on the open-source Community Solid Server.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151067933",
                    "name": "J. Werbrouck"
                },
                {
                    "authorId": "39454836",
                    "name": "P. Pauwels"
                },
                {
                    "authorId": "144204299",
                    "name": "J. Beetz"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "bb0903ee6ab82c018516ec79229086a0670d5d0c",
            "title": "Pattern-based access control in a decentralised collaboration environment",
            "abstract": "As the building industry is rapidly catching up with digital advancements, and Web technologies grow in both maturity and security, a data- and Web-based construction practice comes within reach. In such an environment, private project information and open online data can be combined to allow cross-domain interoperability at data level, using Semantic Web technologies. As construction projects often feature complex and temporary networks of stakeholder firms and their employees, a property-based access control mechanism is necessary to enable a flexible and automated management of distributed building projects. In this article, we propose a method to facilitate such mechanism using existing Web technologies: RDF, SHACL, WebIDs, nanopublications and the Linked Data Platform. The proposed method will be illustrated with an extension of a custom nodeJS Solid server. The potential of the Solid ecosystem has been put forward earlier as a basis for a Linked Data-based Common Data Environment: its decentralised setup, connection of both RDF and non-RDF resources and fine-grained access control mechanisms are considered an apt foundation to manage distributed building data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151067933",
                    "name": "J. Werbrouck"
                },
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "39454836",
                    "name": "P. Pauwels"
                },
                {
                    "authorId": "144204299",
                    "name": "J. Beetz"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                }
            ]
        },
        {
            "paperId": "1e770fee6e80bb6b5b79c22aed8dd2bc2d576f70",
            "title": "Generating public transport data based on population distributions for RDF benchmarking",
            "abstract": "When benchmarking RDF data management systems such as public transport route planners, system evaluation needs to happen under various realistic circumstances, which requires a wide range of datasets with different properties. Real-world datasets are almost ideal, as they offer these realistic circumstances, but they are often hard to obtain and inflexible for testing. For these reasons, synthetic dataset generators are typically preferred over real-world datasets due to their intrinsic flexibility. Unfortunately, many synthetic dataset that are generated within benchmarks are insufficiently realistic, raising questions about the generalizability of benchmark results to real-world scenarios. In order to benchmark geospatial and temporal RDF data management systems such as route planners with sufficient external validity and depth, we designed PODiGG, a highly configurable generation algorithm for synthetic public transport datasets with realistic geospatial and temporal characteristics comparable to those of their real-world variants. The algorithm is inspired by real-world public transit network design and scheduling methodologies. This article discusses the design and implementation of PODiGG and validates the properties of its generated datasets. Our findings show that the generator achieves a sufficient level of realism, based on the existing coherence metric and new metrics we introduce specifically for the public transport domain. Thereby, PODiGG provides a flexible foundation for benchmarking RDF data management systems with geospatial and temporal data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "2370758",
                    "name": "Pieter Colpaert"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        }
    ]
}