{
    "authorId": "2110539208",
    "papers": [
        {
            "paperId": "0619665c1a90258cb9c490f9245338615cb8613b",
            "title": "LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries",
            "abstract": "Graph streams represent data interactions in real applications. The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others. However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them. Current studies apply sketches to summarize graph streams. We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches. In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance. Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically. LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy. We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1788965",
                    "name": "Yiling Zeng"
                },
                {
                    "authorId": "2763563",
                    "name": "Chunyao Song"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2872698",
                    "name": "Tingjian Ge"
                }
            ]
        },
        {
            "paperId": "3cfa0269f247e6da563df71e2cd09d6730ad150d",
            "title": "All Data on the Table: Novel Dataset and Benchmark for Cross-Modality Scientific Information Extraction",
            "abstract": "Extracting key information from scientific papers has the potential to help researchers work more efficiently and accelerate the pace of scientific progress. Over the last few years, research on Scientific Information Extraction (SciIE) witnessed the release of several new systems and benchmarks. However, existing paper-focused datasets mostly focus only on specific parts of a manuscript (e.g., abstracts) and are single-modality (i.e., text- or table-only), due to complex processing and expensive annotations. Moreover, core information can be present in either text or tables or across both. To close this gap in data availability and enable cross-modality IE, while alleviating labeling costs, we propose a semi-supervised pipeline for annotating entities in text, as well as entities and relations in tables, in an iterative procedure. Based on this pipeline, we release novel resources for the scientific community, including a high-quality benchmark, a large-scale corpus, and a semi-supervised annotation pipeline. We further report the performance of state-of-the-art IE models on the proposed benchmark dataset, as a baseline. Lastly, we explore the potential capability of large language models such as ChatGPT for the current task. Our new dataset, results, and analysis validate the effectiveness and efficiency of our semi-supervised pipeline, and we discuss its remaining limitations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2266715262",
                    "name": "Jian Wu"
                },
                {
                    "authorId": "2266654207",
                    "name": "Zhiwei Yu"
                },
                {
                    "authorId": "2047947436",
                    "name": "B\u00f6rje F. Karlsson"
                },
                {
                    "authorId": "2266468675",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2266466660",
                    "name": "Manabu Okumura"
                },
                {
                    "authorId": "2266470924",
                    "name": "Chin-Yew Lin"
                }
            ]
        },
        {
            "paperId": "54630cd92c0c6696a422c3b2aa986c1f75df70b3",
            "title": "A Survey of Graph Meets Large Language Model: Progress and Future Directions",
            "abstract": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2247629250",
                    "name": "Zhixun Li"
                },
                {
                    "authorId": "2267741869",
                    "name": "Peisong Wang"
                },
                {
                    "authorId": "2133337247",
                    "name": "Jia Li"
                },
                {
                    "authorId": "2265792034",
                    "name": "Xiangguo Sun"
                },
                {
                    "authorId": "2117997039",
                    "name": "Hongtao Cheng"
                },
                {
                    "authorId": "2257123459",
                    "name": "Jeffrey Xu Yu"
                }
            ]
        },
        {
            "paperId": "a58c5fec83bfaa48aec8637a9b86b89fbdcf33f4",
            "title": "Gentopia: A Collaborative Platform for Tool-Augmented LLMs",
            "abstract": "Augmented Language Models (ALMs) empower large language models with the ability to use tools, transforming them into intelligent agents for real-world interactions. However, most existing frameworks for ALMs, to varying degrees, are deficient in the following critical features: flexible customization, collaborative democratization, and holistic evaluation. We present gentopia, an ALM framework enabling flexible customization of agents through simple configurations, seamlessly integrating various language models, task formats, prompting modules, and plugins into a unified paradigm. Furthermore, we establish gentpool, a public platform enabling the registration and sharing of user-customized agents. Agents registered in gentpool are composable such that they can be assembled together for agent collaboration, advancing the democratization of artificial intelligence. To ensure high-quality agents, gentbench, an integral component of gentpool, is designed to thoroughly evaluate user-customized agents across diverse aspects such as safety, robustness, efficiency, etc. We release gentopia on Github and will continuously move forward.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2228288888",
                    "name": "Binfeng Xu"
                },
                {
                    "authorId": "14910774",
                    "name": "Xukun Liu"
                },
                {
                    "authorId": "145028030",
                    "name": "Hua Shen"
                },
                {
                    "authorId": "48269112",
                    "name": "Zeyu Han"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2228468973",
                    "name": "Murong Yue"
                },
                {
                    "authorId": "2113952851",
                    "name": "Zhi-Ping Peng"
                },
                {
                    "authorId": "2183078810",
                    "name": "Yuchen Liu"
                },
                {
                    "authorId": "3366595",
                    "name": "Ziyu Yao"
                },
                {
                    "authorId": "2116459424",
                    "name": "Dongkuan Xu"
                }
            ]
        },
        {
            "paperId": "e69804c55e81487c37f31c4bac1a4b962fccaa30",
            "title": "Unlocking Science: Novel Dataset and Benchmark for Cross-Modality Scientific Information Extraction",
            "abstract": "Extracting key information from scientific papers has the potential to help researchers work more efficiently and accelerate the pace of scientific progress. Over the last few years, research on Scientific Information Extraction (SciIE) witnessed the release of several new systems and benchmarks. However, existing paper-focused datasets mostly focus only on specific parts of a manuscript (e.g., abstracts) and are single-modality (i.e., text-or table-only), due to complex processing and expensive annotations. Moreover, core information can be present in either text or tables or across both. To close this gap in data availability and enable cross-modality IE, while alleviating labeling costs, we propose a semi-supervised pipeline for annotating entities in text, as well as entities and relations in tables, in an iterative procedure. Based on this pipeline, we release novel resources for the scientific community, including a high-quality benchmark, a large-scale corpus, and a semi-supervised annotation pipeline \u2021 . We further report the performance of state-of-the-art IE models on the proposed benchmark dataset, as a baseline. Lastly, we explore the potential capability of large language models such as ChatGPT for the current task. Our new dataset, results, and analysis validate the effectiveness and efficiency of our semi-supervised pipeline, and we discuss its remaining limitations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2266715262",
                    "name": "Jian Wu"
                },
                {
                    "authorId": "2266654207",
                    "name": "Zhiwei Yu"
                },
                {
                    "authorId": "2047947436",
                    "name": "B\u00f6rje F. Karlsson"
                },
                {
                    "authorId": "2266468675",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2266466660",
                    "name": "Manabu Okumura"
                },
                {
                    "authorId": "2266470924",
                    "name": "Chin-Yew Lin"
                }
            ]
        },
        {
            "paperId": "06d328e3e0f021be3910b9adf6cd6f5a03ebb982",
            "title": "Community Question Answering Entity Linking via Leveraging Auxiliary Data",
            "abstract": "Community Question Answering (CQA) platforms contain plenty of CQA texts (i.e., questions and answers corresponding to the question) where named entities appear ubiquitously. In this paper, we define a new task of CQA entity linking (CQAEL) as linking the textual entity mentions detected from CQA texts with their corresponding entities in a knowledge base. This task can facilitate many downstream applications including expert finding and knowledge base enrichment. Traditional entity linking methods mainly focus on linking entities in news documents, and are suboptimal over this new task of CQAEL since they cannot effectively leverage various informative auxiliary data involved in the CQA platform to aid entity linking, such as parallel answers and two types of meta-data (i.e., topic tags and users). To remedy this crucial issue, we propose a novel transformer-based framework to effectively harness the knowledge delivered by different kinds of auxiliary data to promote the linking performance. We validate the superiority of our framework through extensive experiments over a newly released CQAEL data set against state-of-the-art entity linking methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1810902946",
                    "name": "Jianbo Gao"
                },
                {
                    "authorId": "2107999689",
                    "name": "Yadong Wang"
                }
            ]
        },
        {
            "paperId": "4d5326408cc5b894fd4e2cc36e3aa5ee4bb2f1c2",
            "title": "Learning Entity Linking Features for Emerging Entities",
            "abstract": "Entity linking (EL) is the process of linking entity mentions appearing in text with their corresponding entities in a knowledge base. EL features of entities (e.g., prior probability, relatedness score, and entity embedding) are usually estimated based on Wikipedia. However, for newly emerging entities (EEs) which have just been discovered in news, they may still not be included in Wikipedia yet. As a consequence, it is unable to obtain required EL features for those EEs from Wikipedia and EL models will always fail to link ambiguous mentions with those EEs correctly as the absence of their EL features. To deal with this problem, in this paper we focus on a new task of learning EL features for emerging entities in a general way. We propose a novel approach called STAMO to learn high-quality EL features for EEs automatically, which needs just a small number of labeled documents for each EE collected from the Web, as it could further leverage the knowledge hidden in the unlabeled data. STAMO is mainly based on self-training, which makes it flexibly integrated with any EL feature or EL model, but also makes it easily suffer from the error reinforcement problem caused by the mislabeled data. Instead of some common self-training strategies that try to throw the mislabeled data away explicitly, we regard self-training as a multiple optimization process with respect to the EL features of EEs, and propose both intra-slot and inter-slot optimizations to alleviate the error reinforcement problem implicitly. We construct two EL datasets involving selected EEs to evaluate the quality of obtained EL features for EEs, and the experimental results show that our approach significantly outperforms other baseline methods of learning EL features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3011549",
                    "name": "Chenwei Ran"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1810902946",
                    "name": "Jianbo Gao"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2861442",
                    "name": "Yantao Jia"
                }
            ]
        },
        {
            "paperId": "dbc6622b8c70bc1a3cc290fdb166229d80ec8f83",
            "title": "TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base",
            "abstract": "Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB context, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively. Specifically on GrailQA, TIARA outperforms previous models in all categories, with an improvement of 4.7 F1 points in zero-shot generalization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1406331721",
                    "name": "Yiheng Shu"
                },
                {
                    "authorId": "2139425204",
                    "name": "Zhiwei Yu"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2047947436",
                    "name": "B\u00f6rje F. Karlsson"
                },
                {
                    "authorId": "2168066",
                    "name": "Tingting Ma"
                },
                {
                    "authorId": "1887019",
                    "name": "Yuzhong Qu"
                },
                {
                    "authorId": "50554693",
                    "name": "Chin-Yew Lin"
                }
            ]
        },
        {
            "paperId": "8af73fbe9f9b11c2820674dbbf7a208f7cadc2a6",
            "title": "Entity Linking Meets Deep Learning: Techniques and Solutions",
            "abstract": "Entity linking (EL) is the process of linking entity mentions appearing in web text with their corresponding entities in a knowledge base. EL plays an important role in the fields of knowledge engineering and data mining, underlying a variety of downstream applications such as knowledge base population, content analysis, relation extraction, and question answering. In recent years, deep learning (DL), which has achieved tremendous success in various domains, has also been leveraged in EL methods to surpass traditional machine learning based methods and yield the state-of-the-art performance. In this survey, we present a comprehensive review and analysis of existing DL based EL methods. First of all, we propose a new taxonomy, which organizes existing DL based EL methods using three axes: embedding, feature, and algorithm. Then we systematically survey the representative EL methods along the three axes of the taxonomy. Later, we introduce ten commonly used EL data sets and give a quantitative performance analysis of DL based EL methods over these data sets. Finally, we discuss the remaining limitations of existing methods and highlight some promising future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117226472",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        }
    ]
}