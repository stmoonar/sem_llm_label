{
    "authorId": "152856111",
    "papers": [
        {
            "paperId": "0bf8644294c43b7684122a33a4af4f409c9a7899",
            "title": "Structural Representation Learning and Disentanglement for Evidential Chinese Patent Approval Prediction",
            "abstract": "Automatic Chinese patent approval prediction is an emerging and valuable task in patent analysis. However, it involves a rigorous and transparent decision-making process that includes patent comparison and examination to assess its innovation and correctness. This resultant necessity of decision evidentiality, coupled with intricate patent comprehension presents significant challenges and obstacles for the patent analysis community. Consequently, few existing studies are addressing this task. This paper presents the pioneering effort on this task using a retrieval-based classification approach. We propose a novel framework called DiSPat, which focuses on structural representation learning and disentanglement to predict the approval of Chinese patents and offer decision-making evidence. DiSPat comprises three main components: base reference retrieval to retrieve the Top-k most similar patents as a reference base; structural patent representation to exploit the inherent claim hierarchy in patents for learning a structural patent representation; disentangled representation learning to learn disentangled patent representations that enable the establishment of an evidential decision-making process. To ensure a thorough evaluation, we have meticulously constructed three datasets of Chinese patents. Extensive experiments on these datasets unequivocally demonstrate our DiSPat surpasses state-of-the-art baselines on patent approval prediction, while also exhibiting enhanced evidentiality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2316860742",
                    "name": "Jinzhi Shan"
                },
                {
                    "authorId": "2283510486",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2316868749",
                    "name": "Mengting Gui"
                },
                {
                    "authorId": "2266355264",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "2e7a50224daed11049bca7e6c96e4d4d599f1a48",
            "title": "MSynFD: Multi-hop Syntax Aware Fake News Detection",
            "abstract": "The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists1 in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical dependency graph and design a multi-hop subgraph aggregation mechanism to capture multi-hop syntax. It extends the effect of word perception, leading to effective noise filtering and adjacent relation enhancement. Subsequently, a sequential relative position-aware Transformer is designed to capture the sequential information, together with an elaborate keyword debiasing module to mitigate the prior bias. Extensive experimental results on two public benchmark datasets verify the effectiveness and superior performance of our proposed MSynFD over state-of-the-art detection models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274029674",
                    "name": "Liang Xiao"
                },
                {
                    "authorId": "2271885943",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2266355264",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                }
            ]
        },
        {
            "paperId": "95ed75bf90313d180d6107097d964b7f1374f8ae",
            "title": "CoSD: Collaborative Stance Detection with Contrastive Heterogeneous Topic Graph Learning",
            "abstract": "Stance detection seeks to identify the viewpoints of individuals either in favor or against a given target or a controversial topic. Current advanced neural models for stance detection typically employ fully parametric softmax classifiers. However, these methods suffer from several limitations, including lack of explainability, insensitivity to the latent data structure, and unimodality, which greatly restrict their performance and applications. To address these challenges, we present a novel collaborative stance detection framework called (CoSD) which leverages contrastive heterogeneous topic graph learning to learn topic-aware semantics and collaborative signals among texts, topics, and stance labels for enhancing stance detection. During training, we construct a heterogeneous graph to structurally organize texts and stances through implicit topics via employing latent Dirichlet allocation. We then perform contrastive graph learning to learn heterogeneous node representations, aggregating informative multi-hop collaborative signals via an elaborate Collaboration Propagation Aggregation (CPA) module. During inference, we introduce a hybrid similarity scoring module to enable the comprehensive incorporation of topic-aware semantics and collaborative signals for stance detection. Extensive experiments on two benchmark datasets demonstrate the state-of-the-art detection performance of CoSD, verifying the effectiveness and explainability of our collaborative framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218850064",
                    "name": "Yinghan Cheng"
                },
                {
                    "authorId": "2271885943",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2274029674",
                    "name": "Liang Xiao"
                },
                {
                    "authorId": "49107622",
                    "name": "Shufeng Hao"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                }
            ]
        },
        {
            "paperId": "13c79fb7e0db86d6971a39cc12aa2d5773aabff8",
            "title": "Frequency Spectrum is More Effective for Multimodal Representation and Fusion: A Multimodal Spectrum Rumor Detector",
            "abstract": "Multimodal content, such as mixing text with images, presents significant challenges to rumor detection in social media. Existing multimodal rumor detection has focused on mixing tokens among spatial and sequential locations for unimodal representation or fusing clues of rumor veracity across modalities. However, they suffer from less discriminative unimodal representation and are vulnerable to intricate location dependencies in the time-consuming fusion of spatial and sequential tokens. This work makes the first attempt at multimodal rumor detection in the frequency domain, which efficiently transforms spatial features into the frequency spectrum and obtains highly discriminative spectrum features for multimodal representation and fusion. A novel Frequency Spectrum Representation and fUsion network (FSRU) with dual contrastive learning reveals the frequency spectrum is more effective for multimodal representation and fusion, extracting the informative components for rumor detection. FSRU involves three novel mechanisms: utilizing the Fourier transform to convert features in the spatial domain to the frequency domain, the unimodal spectrum compression, and the cross-modal spectrum co-selection module in the frequency domain. Substantial experiments show that FSRU achieves satisfactory multimodal rumor detection performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106764697",
                    "name": "An Lao"
                },
                {
                    "authorId": "2271885887",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2275080623",
                    "name": "Longbing Cao"
                },
                {
                    "authorId": "2265619390",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "2274216292",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2273073533",
                    "name": "Duoqian Miao"
                }
            ]
        },
        {
            "paperId": "272c7db5861d9dc4033ae6c3d1d2c90965d62840",
            "title": "Syntax Tree Constrained Graph Network for Visual Question Answering",
            "abstract": "Visual Question Answering (VQA) aims to automatically answer natural language questions related to given image content. Existing VQA methods integrate vision modeling and language understanding to explore the deep semantics of the question. However, these methods ignore the significant syntax information of the question, which plays a vital role in understanding the essential semantics of the question and guiding the visual feature refinement. To fill the gap, we suggested a novel Syntax Tree Constrained Graph Network (STCGN) for VQA based on entity message passing and syntax tree. This model is able to extract a syntax tree from questions and obtain more precise syntax information. Specifically, we parse questions and obtain the question syntax tree using the Stanford syntax parsing tool. From the word level and phrase level, syntactic phrase features and question features are extracted using a hierarchical tree convolutional network. We then design a message-passing mechanism for phrase-aware visual entities and capture entity features according to a given visual context. Extensive experiments on VQA2.0 datasets demonstrate the superiority of our proposed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243496432",
                    "name": "Xiangrui Su"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2319414948",
                    "name": "Jiachang Liu"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                }
            ]
        },
        {
            "paperId": "9ded2e4b08a95e6f023c9c45df48a9ceb0afe56f",
            "title": "Causal Intervention for Abstractive Related Work Generation",
            "abstract": "Abstractive related work generation has attracted increasing attention in generating coherent related work that better helps readers grasp the background in the current research. However, most existing abstractive models ignore the inherent causality of related work generation, leading to low quality of generated related work and spurious correlations that affect the models' generalizability. In this study, we argue that causal intervention can address these limitations and improve the quality and coherence of the generated related works. To this end, we propose a novel Causal Intervention Module for Related Work Generation (CaM) to effectively capture causalities in the generation process and improve the quality and coherence of the generated related works. Specifically, we first model the relations among sentence order, document relation, and transitional content in related work generation using a causal graph. Then, to implement the causal intervention and mitigate the negative impact of spurious correlations, we use do-calculus to derive ordinary conditional probabilities and identify causal effects through CaM. Finally, we subtly fuse CaM with Transformer to obtain an end-to-end generation model. Extensive experiments on two real-world datasets show that causal interventions in CaM can effectively promote the model to learn causal relations and produce related work of higher quality and coherence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2319414948",
                    "name": "Jiachang Liu"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "1807998",
                    "name": "I. Tsang"
                }
            ]
        },
        {
            "paperId": "a3b9f96f386d458c4d2d54e9d68783a9bee95419",
            "title": "Enhanced Semantic Representation Learning for Sarcasm Detection by Integrating Context-Aware Attention and Fusion Network",
            "abstract": "Sarcasm is a sophisticated figurative language that is prevalent on social media platforms. Automatic sarcasm detection is significant for understanding the real sentiment tendencies of users. Traditional approaches mostly focus on content features by using lexicon, n-gram, and pragmatic feature-based models. However, these methods ignore the diverse contextual clues that could provide more evidence of the sarcastic nature of sentences. In this work, we propose a Contextual Sarcasm Detection Model (CSDM) by modeling enhanced semantic representations with user profiling and forum topic information, where context-aware attention and a user-forum fusion network are used to obtain diverse representations from distinct aspects. In particular, we employ a Bi-LSTM encoder with context-aware attention to obtain a refined comment representation by capturing sentence composition information and the corresponding context situations. Then, we employ a user-forum fusion network to obtain the comprehensive context representation by capturing the corresponding sarcastic tendencies of the user and the background knowledge about the comments. Our proposed method achieves values of 0.69, 0.70, and 0.83 in terms of accuracy on the Main balanced, Pol balanced and Pol imbalanced datasets, respectively. The experimental results on a large Reddit corpus, SARC, demonstrate that our proposed method achieves a significant performance improvement over state-of-art textual sarcasm detection methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "49107622",
                    "name": "Shufeng Hao"
                },
                {
                    "authorId": "2219051018",
                    "name": "Jikun Yao"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2218955110",
                    "name": "Yu Zhou"
                },
                {
                    "authorId": "47411341",
                    "name": "Shuang Xu"
                },
                {
                    "authorId": "2218760854",
                    "name": "Deng-ao Li"
                },
                {
                    "authorId": "2218850064",
                    "name": "Yinghan Cheng"
                }
            ]
        },
        {
            "paperId": "aa7295ecffb25c6f78fea793acfd24a3e8f7ddc0",
            "title": "Rumor Detection with Hierarchical Representation on Bipartite Adhoc Event Trees",
            "abstract": "The rapid growth of social media has caused tremendous effects on information propagation, raising extreme challenges in detecting rumors. Existing rumor detection methods typically exploit the reposting propagation of a rumor candidate for detection by regarding all reposts to a rumor candidate as a temporal sequence and learning semantics representations of the repost sequence. However, extracting informative support from the topological structure of propagation and the influence of reposting authors for debunking rumors is crucial, which generally has not been well addressed by existing methods. In this article, we organize a claim post in circulation as an ad hoc event tree, extract event elements, and convert it into bipartite ad hoc event trees in terms of both posts and authors, i.e., author tree and post tree. Accordingly, we propose a novel rumor detection model with hierarchical representation on the bipartite ad hoc event trees called BAET. Specifically, we introduce word embedding and feature encoder for the author and post tree, respectively, and design a root-aware attention module to perform node representation. Then we adopt the tree-like RNN model to capture the structural correlations and propose a tree-aware attention module to learn tree representation for the author tree and post tree, respectively. Extensive experimental results on two public Twitter datasets demonstrate the effectiveness of BAET in exploring and exploiting the rumor propagation structure and the superior detection performance of BAET over state-of-the-art baseline methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2124143325",
                    "name": "Yayi Yang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "50733091",
                    "name": "Angelyn R. Lao"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "43e1178c73e34f9c0e6dc67cda1d8160876e5c21",
            "title": "A News Recommendation Model Based on Time Awareness and News Relevance",
            "abstract": "Personalized news recommendation can target user interests and effectively alleviate information overload. Most of the existing methods are based on news content for recommendation, which mostly ignore the rich auxiliary information and neighbor information existing in real news recommendation scenarios. In addition, few methods provide easy-to-understand explanations. In this paper, we propose a news recommendation model based on time awareness and news relevance. The model combines various news auxiliary information and user-news interaction data in the form of heterogeneous graph, and mines the temporal relationship in the user click sequence for news recommendation. In addition, our model provide understandable recommendation explanations based on the multiple explanation bases extracted from the heterogeneous graph. Extensive experiments on two public and widely used datasets, Adressa and Globo, demonstrate both the effectiveness of the proposed approach and the reasonableness of recommendation explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151905780",
                    "name": "Shaojun Ren"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                }
            ]
        },
        {
            "paperId": "9f0950aac7e0744a9c6aa16e78b6f2a9ef1bcd13",
            "title": "Supervised Deep Hashing for High-dimensional and Heterogeneous Case-based Reasoning",
            "abstract": "Case-based Reasoning (CBR) on high-dimensional and heterogeneous data is a trending yet challenging and computationally expensive task in the real world. A promising approach is to obtain low-dimensional hash codes representing cases and perform a similarity retrieval of cases in a Hamming space. However, previous methods based on data-independent hashing rely on random projections or manual construction, inapplicable to address specific data issues (e.g., high-dimensionality and heterogeneity) due to their insensitivity to data characteristics. To address these issues, this work introduces a novel deep hashing network to learn similarity-preserving compact hash codes for efficient case retrieval and proposes a deep-hashing-enabled CBR model HeCBR. Specifically, we introduce position embedding to represent heterogeneous features and utilize a multilinear interaction layer to obtain case embeddings, which effectively filtrates zero-valued features to tackle high-dimensionality and sparsity and captures inter-feature couplings. Then, we feed the case embeddings into fully-connected layers, and subsequently a hash layer generates hash codes with a quantization regularizer to control the quantization loss during relaxation. To cater for incremental learning of CBR, we further propose an adaptive learning strategy to update the hash function. Extensive experiments on public datasets show HeCBR greatly reduces storage and significantly accelerates the case retrieval. HeCBR achieves desirable performance compared with the state-of-the-art CBR methods and performs significantly better than hashing-based CBR methods in classification. typical CBR models to investigate the effectiveness of our proposed HeCBR. All experimental results demonstrate that our HeCBR significantly outperforms the hashing-enabled methods in terms of classification tasks and achieves desirable performance compared with typical CBR methods. Theoretical and empirical analysis show that HeCBR can greatly reduce storage cost and significantly improve efficiency in relation to typical CBR models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "47968272",
                    "name": "Li-Yu Daisy Liu"
                },
                {
                    "authorId": "2148761004",
                    "name": "Longbing Cao"
                }
            ]
        }
    ]
}