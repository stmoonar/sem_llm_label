{
    "authorId": "2109059862",
    "papers": [
        {
            "paperId": "1db72c35bca512a382edc3e762c58649d74a04af",
            "title": "Learning An End-to-End Structure for Retrieval in Large-Scale Recommendations",
            "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model, and then use some approximate nearest neighbor (ANN) search algorithm to find top candidates. In this paper, we present Deep Retrieval (DR), to learn a retrievable structure directly with user-item interaction data (e.g. clicks) without resorting to the Euclidean space assumption in ANN algorithms. DR's structure encodes all candidate items into a discrete latent space. Those latent codes for the candidates are model parameters and learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the structure is performed to retrieve the top candidates for reranking. Empirically, we first demonstrate that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline on two public datasets. Moreover, we show that, in a live production recommendation system, a deployed DR approach significantly outperforms a well-tuned ANN baseline in terms of engagement metrics. To the best of our knowledge, DR is among the first non-ANN algorithms successfully deployed at the scale of hundreds of millions of items for industrial recommendation systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153577134",
                    "name": "Weihao Gao"
                },
                {
                    "authorId": "2117801085",
                    "name": "Xiangjun Fan"
                },
                {
                    "authorId": "2146309022",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2152147910",
                    "name": "Jiankai Sun"
                },
                {
                    "authorId": "2119068837",
                    "name": "Kai Jia"
                },
                {
                    "authorId": "144780150",
                    "name": "Wen Xiao"
                },
                {
                    "authorId": "2094428006",
                    "name": "Ruofan Ding"
                },
                {
                    "authorId": "2094420573",
                    "name": "Xingyan Bin"
                },
                {
                    "authorId": "2156107831",
                    "name": "Hui Yang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                }
            ]
        },
        {
            "paperId": "e100c92e1c692e7d99557ee621e284dd236052b4",
            "title": "One Backward from Ten Forward, Subsampling for Large-Scale Deep Learning",
            "abstract": "Deep learning models in large-scale machine learning systems are often continuously trained with enormous data from production environments. The sheer volume of streaming training data poses a significant challenge to real-time training subsystems and ad-hoc sampling is the standard practice. Our key insight is that these deployed ML systems continuously perform forward passes on data instances during inference, but ad-hoc sampling does not take advantage of this substantial computational effort. Therefore, we propose to record a constant amount of information per instance from these forward passes. The extra information measurably improves the selection of which data instances should participate in forward and backward passes. A novel optimization framework is proposed to analyze this problem and we provide an efficient approximation algorithm under the framework of Mini-batch gradient descent as a practical solution. We also demonstrate the effectiveness of our framework and algorithm on several large-scale classification and regression tasks, when compared with competitive baselines widely used in industry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51228713",
                    "name": "Chaosheng Dong"
                },
                {
                    "authorId": "2103483",
                    "name": "Xiaojie Jin"
                },
                {
                    "authorId": "2153577134",
                    "name": "Weihao Gao"
                },
                {
                    "authorId": "46395590",
                    "name": "Yijia Wang"
                },
                {
                    "authorId": "2108880169",
                    "name": "Hongyi Zhang"
                },
                {
                    "authorId": "2141480228",
                    "name": "Xiang Wu"
                },
                {
                    "authorId": "1706007",
                    "name": "Jianchao Yang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                }
            ]
        },
        {
            "paperId": "19d1c3b378e7163cf9f510add30826dec254cf23",
            "title": "Deep Retrieval: An End-to-End Learnable Structure Model for Large-Scale Recommendations",
            "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2028853",
                    "name": "Weihao Gao"
                },
                {
                    "authorId": "2117801085",
                    "name": "Xiangjun Fan"
                },
                {
                    "authorId": null,
                    "name": "Jiankai Sun"
                },
                {
                    "authorId": "2119068837",
                    "name": "Kai Jia"
                },
                {
                    "authorId": "144780150",
                    "name": "Wen Xiao"
                },
                {
                    "authorId": "2146309022",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                }
            ]
        },
        {
            "paperId": "22769eb4c86e8d041c110782f8bf06c7c0d7696a",
            "title": "Learning to Structure Long-term Dependence for Sequential Recommendation",
            "abstract": "Sequential recommendation recommends items based on sequences of users' historical actions. The key challenge in it is how to effectively model the influence from distant actions to the action to be predicted, i.e., recognizing the long-term dependence structure; and it remains an underexplored problem. To better model the long-term dependence structure, we propose a GatedLongRec solution in this work. To account for the long-term dependence, GatedLongRec extracts distant actions of top-$k$ related categories to the user's ongoing intent with a top-$k$ gating network, and utilizes a long-term encoder to encode the transition patterns among these identified actions. As user intent is not directly observable, we take advantage of available side-information about the actions, i.e., the category of their associated items, to infer the intents. End-to-end training is performed to estimate the intent representation and predict the next action for sequential recommendation. Extensive experiments on two large datasets show that the proposed solution can recognize the structure of long-term dependence, thus greatly improving the sequential recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39483735",
                    "name": "Renqin Cai"
                },
                {
                    "authorId": "3057562",
                    "name": "Qinglei Wang"
                },
                {
                    "authorId": "2146309022",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                }
            ]
        },
        {
            "paperId": "2846eaaf80adf3701e21e7361a279d40fe94b4ac",
            "title": "Jointly Learning to Recommend and Advertise",
            "abstract": "Online recommendation and advertising are two major income channels for online recommendation platforms (e.g. e-commerce and news feed site). However, most platforms optimize recommending and advertising strategies by different teams separately via different techniques, which may lead to suboptimal overall performances. To this end, in this paper, we propose a novel two-level reinforcement learning framework to jointly optimize the recommending and advertising strategies, where the first level generates a list of recommendations to optimize user experience in the long run; then the second level inserts ads into the recommendation list that can balance the immediate advertising revenue from advertisers and the negative influence of ads on long-term user experience. To be specific, the first level tackles high combinatorial action space problem that selects a subset items from the large item space; while the second level determines three internally related tasks, i.e., (i) whether to insert an ad, and if yes, (ii) the optimal ad and (iii) the optimal location to insert. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework. We have released the implementation code to ease reproductivity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2110301314",
                    "name": "Xudong Zheng"
                },
                {
                    "authorId": "2642785",
                    "name": "Xiwang Yang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "5b282d0313b33dea3b7544e97b53a772ca165c90",
            "title": "Automated Embedding Size Search in Deep Recommender Systems",
            "abstract": "Deep recommender systems have achieved promising performance on real-world recommendation tasks. They typically represent users and items in a low-dimensional embedding space and then feed the embeddings into the following deep network structures for prediction. Traditional deep recommender models often adopt uniform and fixed embedding sizes for all the users and items. However, such design is not optimal in terms of not only the recommendation performance and but also the space complexity. In this paper, we propose to dynamically search the embedding sizes for different users and items and introduce a novel embedding size adjustment policy network (ESAPN). ESAPN serves as an automated reinforcement learning agent to adaptively search appropriate embedding sizes for users and items. Different from existing works, our model performs hard selection on different embedding sizes, which leads to a more accurate selection and decreases the storage space. We evaluate our model under the streaming setting on two real-world benchmark datasets. The results show that our proposed framework outperforms representative baselines. Moreover, our framework is demonstrated to be robust to the cold-start problem and reduce memory consumption by around 40%-90%. The implementation of the model is released.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2128077726",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "6fa7c419c02da91fb9766db9eb39721bbf24e55d",
            "title": "AutoEmb: Automated Embedding Dimensionality Search in Streaming Recommendations",
            "abstract": "Deep learning based recommender systems (DLRSs) often have embedding layers, which are utilized to lessen the dimensionality of categorical variables (e.g. user/item identifiers) and meaningfully transform them in the low-dimensional space. The majority of existing DLRSs empirically pre-define a fixed and unified dimension for all user/item embeddings. It is evident from recent researches that different embedding sizes are highly desired for different users/items according to their popularity. However, manually selecting embedding sizes in recommender systems can be very challenging due to the large number of users/items and the dynamic nature of their popularity. Thus, in this paper, we propose an AutoML based end-to-end framework (AutoEmb), which can enable various embedding dimensions according to the popularity in an automated and dynamic manner. To be specific, we first enhance a typical DLRS to allow various embedding dimensions; then we propose an end-to-end differentiable framework that can automatically select different embedding dimensions according to user/item popularity; finally we propose an AutoML based optimization algorithm in a streaming recommendation setting. The experimental results based on widely used benchmark datasets demonstrate the effectiveness of the AutoEmb framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2128077726",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2108633043",
                    "name": "Ming Chen"
                },
                {
                    "authorId": "2110301314",
                    "name": "Xudong Zheng"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "fc3bf5106c5cb9e7abd358d0506a9978d8e5be32",
            "title": "Deep Retrieval: Learning A Retrievable Structure for Large-Scale Recommendations",
            "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model, and then use some approximate nearest neighbor (ANN) search algorithm to find top candidates. In this paper, we present Deep Retrieval (DR), to learn a retrievable structure directly with user-item interaction data (e.g. clicks) without resorting to the Euclidean space assumption in ANN algorithms. DR's structure encodes all candidate items into a discrete latent space. Those latent codes for the candidates are model parameters and learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the structure is performed to retrieve the top candidates for reranking. Empirically, we first demonstrate that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline on two public datasets. Moreover, we show that, in a live production recommendation system, a deployed DR approach significantly outperforms a well-tuned ANN baseline in terms of engagement metrics. To the best of our knowledge, DR is among the first non-ANN algorithms successfully deployed at the scale of hundreds of millions of items for industrial recommendation systems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2153577134",
                    "name": "Weihao Gao"
                },
                {
                    "authorId": "2117801085",
                    "name": "Xiangjun Fan"
                },
                {
                    "authorId": "2146309022",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2152147910",
                    "name": "Jiankai Sun"
                },
                {
                    "authorId": "2119068837",
                    "name": "Kai Jia"
                },
                {
                    "authorId": "144780150",
                    "name": "Wen Xiao"
                },
                {
                    "authorId": "2094428006",
                    "name": "Ruofan Ding"
                },
                {
                    "authorId": "2094420573",
                    "name": "Xingyan Bin"
                },
                {
                    "authorId": "2156107831",
                    "name": "Hui Yang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                }
            ]
        },
        {
            "paperId": "94e91560da6e649c2d5eda9e989526697ee3e885",
            "title": "DEAR: Deep Reinforcement Learning for Online Advertising Impression in Recommender Systems",
            "abstract": "With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in utilizing RL for online advertising in recommendation platforms (e.g., e-commerce and news feed sites). However, most RL-based advertising algorithms focus on optimizing ads' revenue while ignoring the possible negative influence of ads on user experience of recommended items (products, articles and videos). Developing an optimal advertising algorithm in recommendations faces immense challenges because interpolating ads improperly or too frequently may decrease user experience, while interpolating fewer ads will reduce the advertising revenue. Thus, in this paper, we propose a novel advertising strategy for the rec/ads trade-off. To be specific, we develop an RL-based framework that can continuously update its advertising strategies and maximize reward in the long run. Given a recommendation list, we design a novel Deep Q-network architecture that can determine three internally related tasks jointly, i.e., (i) whether to interpolate an ad or not in the recommendation list, and if yes, (ii) the optimal ad and (iii) the optimal location to interpolate. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2053400337",
                    "name": "Changsheng Gu"
                },
                {
                    "authorId": "1390919512",
                    "name": "Haoshenglun Zhang"
                },
                {
                    "authorId": "2642785",
                    "name": "Xiwang Yang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                }
            ]
        },
        {
            "paperId": "fa046f400cefdd484b045e9e3b625a4f9d127bc2",
            "title": "Deep Reinforcement Learning for Online Advertising in Recommender Systems",
            "abstract": "With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in utilizing RL for online advertising in recommendation platforms (e.g. e-commerce and news feed sites). However, most RL-based advertising algorithms focus on solely optimizing the revenue of ads while ignoring possible negative influence of ads on user experience of recommended items (products, articles and videos). Developing an optimal advertising algorithm in recommendations faces immense challenges because interpolating ads improperly or too frequently may decrease user experience, while interpolating fewer ads will reduce the advertising revenue. Thus, in this paper, we propose a novel advertising strategy for the rec/ads trade-off. To be specific, we develop a reinforcement learning based framework that can continuously update its advertising strategies and maximize reward in the long run. Given a recommendation list, we design a novel Deep Q-network architecture that can determine three internally related tasks jointly, i.e., (i) whether to interpolate an ad or not in the recommendation list, and if yes, (ii) the optimal ad and (iii) the optimal location to interpolate. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2053400337",
                    "name": "Changsheng Gu"
                },
                {
                    "authorId": "1390919512",
                    "name": "Haoshenglun Zhang"
                },
                {
                    "authorId": "2109059862",
                    "name": "Xiaobing Liu"
                },
                {
                    "authorId": "2642785",
                    "name": "Xiwang Yang"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        }
    ]
}