{
    "authorId": "2116974078",
    "papers": [
        {
            "paperId": "f2ea895c4506dc61fc0423961bc7d8de8fd519b3",
            "title": "Cross-Domain Recommendation via Progressive Structural Alignment",
            "abstract": "Cross-domain recommendation, as a cutting-edge technology to settle data sparsity and cold start problems, is gaining increasingly popular. Existing research paradigms primarily focus on leveraging the representation of overlapping entities, such as representation aggregation or cross-domain consistency constraints, to facilitate knowledge transfer and enhance the performance of single-domain or dual-domain recommender systems. Even though these approaches bring significant promotions, they still suffer from optimization bottlenecks when faced with sparse overlapping users, which often occurs in reality. Unlocking the full potential of overlapping user information and exploring novel sources of cross-domain knowledge are pivotal in addressing this challenge effectively. On account of this, this paper proposes an innovative cross-domain recommendation framework, namely SEAGULL, to promote dual-target recommendation performance in line with these two perspectives. We bolster the utilization of overlapping user knowledge and extract non-overlapping user interests by refining the message passing mechanism in a unified heterogeneous cross-domain graph and facilitating the transfer of latent structural relationships among users. Specifically, we first construct the interaction of two domains as a unified cross-domain heterogeneous graph and design a novel attention mechanism to incorporate cross-domain collaboration signals between users and items. Second, we perform user structure alignment from global and local levels to extend semantic transfer and information augmentation. Finally, unlike previous work that directly incorporates mixed cross-domain knowledge, we employ a gentle and progressive cross-domain transfer strategy to reduce empirical risk loss. Extensive experiments on five tasks derived from three data sets fully demonstrate the effectiveness of SEAGULL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1409984160",
                    "name": "Chuang Zhao"
                },
                {
                    "authorId": "2260724761",
                    "name": "Hongke Zhao"
                },
                {
                    "authorId": "2273588181",
                    "name": "Xiaomeng Li"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "2233998742",
                    "name": "Jiahui Wang"
                },
                {
                    "authorId": "2260856326",
                    "name": "Jianping Fan"
                }
            ]
        },
        {
            "paperId": "1d2e3603fb031546849d7d4db378c5643ad78af2",
            "title": "Knowledge-Aware Cross-Semantic Alignment for Domain-Level Zero-Shot Recommendation",
            "abstract": "Recommendation systems have attracted attention from academia and industry due to their wide range of application scenarios. However, cold start remains a challenging problem limited by sparse user interactions. Some scholars propose to transfer the dense information from the source domain to the target domain through cross-domain recommendation, but most of the work assumes that there is a small amount of historical interaction in the target domain. However, this approach essentially presupposes the existence of at least some historical interaction within the target domain. In this paper, we focus on the domain-level zero-shot recommendation (DZSR) problem. To address the above challenges, we propose a knowledge-aware cross-semantic alignment (K-CSA) framework to learn transferable source domain semantic information. The motivation is to establish stable alignments of interests in different domains through class semantic descriptions (CSDs). Specifically, due to the lack of effective information in the target domain, we learn semantic representations of source and target domain items based on knowledge graphs. Moreover, we conduct multi-view K-means to extract item CSDs from the learned semantic representations. Further, K-CSA learns universal user CSDs through the designed multi-head self-attention. To facilitate the transference of user interest from the source domain to the target domain, we devise a cross-semantic contrastive learning strategy, grounded in the prototype distribution matrix. We conduct extensive experiments on several real-world cross-domain datasets, and the experimental results clearly demonstrate the superiority of our proposed K-CSA compared with other baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260831381",
                    "name": "Junji Jiang"
                },
                {
                    "authorId": "2260724761",
                    "name": "Hongke Zhao"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "12892739",
                    "name": "Likang Wu"
                },
                {
                    "authorId": "2261185991",
                    "name": "Kai Zhang"
                },
                {
                    "authorId": "2260856326",
                    "name": "Jianping Fan"
                }
            ]
        },
        {
            "paperId": "2d0eb02a551cc25e59d85a40c0ec79f7cd563ad1",
            "title": "Cross-domain recommendation via user interest alignment",
            "abstract": "Cross-domain recommendation aims to leverage knowledge from multiple domains to alleviate the data sparsity and cold-start problems in traditional recommender systems. One popular paradigm is to employ overlapping user representations to establish domain connections, thereby improving recommendation performance in all scenarios. Nevertheless, the general practice of this approach is to train user embeddings in each domain separately and then aggregate them in a plain manner, often ignoring potential cross-domain similarities between users and items. Furthermore, considering that their training objective is recommendation task-oriented without specific regularizations, the optimized embeddings disregard the interest alignment among user\u2019s views, and even violate the user\u2019s original interest distribution. To address these challenges, we propose a novel cross-domain recommendation framework, namely COAST, to improve recommendation performance on dual domains by perceiving the cross-domain similarity between entities and aligning user interests. Specifically, we first construct a unified cross-domain heterogeneous graph and redefine the message passing mechanism of graph convolutional networks to capture high-order similarity of users and items across domains. Targeted at user interest alignment, we develop deep insights from two more fine-grained perspectives of user-user and user-item interest invariance across domains by virtue of affluent unsupervised and semantic signals. We conduct intensive experiments on multiple tasks, constructed from two large recommendation data sets. Extensive results show COAST consistently and significantly outperforms state-of-the-art cross-domain recommendation algorithms as well as classic single-domain recommendation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1409984160",
                    "name": "Chuang Zhao"
                },
                {
                    "authorId": "2869628",
                    "name": "Hongke Zhao"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "2185160730",
                    "name": "Jian Zhang"
                },
                {
                    "authorId": "2152732801",
                    "name": "Jianping Fan"
                }
            ]
        },
        {
            "paperId": "4dd54509ca4a20d575b3b43fda747e373420695b",
            "title": "LinRec: Linear Attention Mechanism for Long-term Sequential Recommender Systems",
            "abstract": "Transformer models have achieved remarkable success in sequential recommender systems (SRSs). However, computing the attention matrix in traditional dot-product attention mechanisms results in a quadratic complexity with sequence lengths, leading to high computational costs for long-term sequential recommendation. Motivated by the above observation, we propose a novel L2-Normalized Linear Attention for the Transformer-based Sequential Recommender Systems (LinRec), which theoretically improves efficiency while preserving the learning capabilities of the traditional dot-product attention. Specifically, by thoroughly examining the equivalence conditions of efficient attention mechanisms, we show that LinRec possesses linear complexity while preserving the property of attention mechanisms. In addition, we reveal its latent efficiency properties by interpreting the proposed LinRec mechanism through a statistical lens. Extensive experiments are conducted based on two public benchmark datasets, demonstrating that the combination of LinRec and Transformer models achieves comparable or even superior performance than state-of-the-art Transformer-based SRS models while significantly improving time and memory efficiency. The implementation code is available online at https://github.com/Applied-Machine-Learning-Lab/LinRec.>",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223875866",
                    "name": "Langming Liu"
                },
                {
                    "authorId": "2223747158",
                    "name": "Liu Cai"
                },
                {
                    "authorId": "2117835555",
                    "name": "Chi Zhang"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2223798314",
                    "name": "Yifu Lv"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "3195628",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2117897052",
                    "name": "Qing Li"
                }
            ]
        },
        {
            "paperId": "613efc70be8a9d953e680861e3468619d7375086",
            "title": "SHGCN: Socially Enhanced Heterogeneous Graph Convolutional Network for Multi-behavior Prediction",
            "abstract": "In recent years, multi-behavior information has been utilized to address data sparsity and cold-start issues. The general multi-behavior models capture multiple behaviors of users to make the representation of relevant features more fine-grained and informative. However, most current multi-behavior recommendation methods neglect the exploration of social relations between users. Actually, users\u2019 potential social connections are critical to assist them in filtering multifarious messages, which may be one key for models to tap deeper into users\u2019 interests. Additionally, existing models usually focus on the positive behaviors (e.g., click, follow, and purchase) of users and tend to ignore the value of negative behaviors (e.g., unfollow and badpost). In this work, we present a Multi-Behavior Graph (MBG) construction method based on user behaviors and social relationships and then introduce a novel socially enhanced and behavior-aware graph neural network for behavior prediction. Specifically, we propose a Socially Enhanced Heterogeneous Graph Convolutional Network (SHGCN) model, which utilizes behavior heterogeneous graph convolution module and social graph convolution module to effectively incorporate behavior features and social information to achieve precise multi-behavior prediction. In addition, the aggregation pooling mechanism is suggested to integrate the outputs of different graph convolution layers, and a dynamic adaptive loss (DAL) method is presented to explore the weight of each behavior. The experimental results on the datasets of the e-commerce platforms (i.e., Epinions and Ciao) indicate the promising performance of SHGCN. Compared with the most powerful baseline, SHGCN achieves 3.3% and 1.4% uplift in terms of AUC on the Epinions and Ciao datasets. Further experiments, including model efficiency analysis, DAL mechanism, and ablation experiments, confirm the validity of the multi-behavior information and social enhancement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256832068",
                    "name": "Lei Zhang"
                },
                {
                    "authorId": "2186625967",
                    "name": "Wuji Zhang"
                },
                {
                    "authorId": "12892739",
                    "name": "Likang Wu"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "2869628",
                    "name": "Hongke Zhao"
                }
            ]
        },
        {
            "paperId": "924db726e462f768b16af1a081b153549bee5fca",
            "title": "Sequential Recommendation via an Adaptive Cross-domain Knowledge Decomposition",
            "abstract": "Cross-domain recommendation, as an intelligent machine to alleviate data sparsity and cold start problems, has attracted extensive attention from scholars. Existing cross-domain recommendation frameworks usually leverage overlapping entities for knowledge transfer, the most popular of which are information aggregation and consistency maintenance. Despite decent improvements, the neglect of dynamic perspectives, the presence of confounding factors, and the disparities in domain properties inevitably constrain model performance. In view of this, this paper proposes a sequential recommendation framework via adaptive cross-domain knowledge decomposition, namely ARISEN, which focuses on employing adaptive causal learning to improve recommendation performance. Specifically, in order to facilitate sequence transfer, we align the user's behaviour sequences in the source domain and target domain according to the timestamps, expecting to use the abundant semantics of the former to augment the information of the latter. Regarding confounding factor removal, we introduce the causal learning technique and promote it as an adaptive representation decomposition framework on the basis of instrumental variables. For the sake of alleviating the impact of domain disparities, this paper endeavors to employ two mutually orthogonal transformation matrices for information fusion. Extensive experiments and detailed analyzes on large industrial and public data sets demonstrate that our framework can achieve substantial improvements over state-of-the-art algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1409984160",
                    "name": "Chuang Zhao"
                },
                {
                    "authorId": "2260829452",
                    "name": "Xinyu Li"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "2260724761",
                    "name": "Hongke Zhao"
                },
                {
                    "authorId": "2260856326",
                    "name": "Jianping Fan"
                }
            ]
        },
        {
            "paperId": "48d146ba0031381755634d8369d5129eba8678ac",
            "title": "Guided Attention Network for Concept Extraction",
            "abstract": "Concept extraction aims to find words or phrases describing a concept from massive texts. Recently, researchers propose many neural network-based methods to automatically extract concepts. Although these methods for this task show promising results, they ignore structured information in the raw textual data (e.g., title, topic, and clue words). In this paper, we propose a novel model, named Guided Attention Concept Extraction Network (GACEN), which uses title, topic, and clue words as additional supervision to provide guidance directly. Specifically, GACEN comprises two attention networks, one of them is to gather the relevant title and topic information for each context word in the document. The other one aims to model the implicit connection between informative words (clue words) and concepts. Finally, we aggregate information from two networks as input to Conditional Random Field (CRF) to model dependencies in the output. We collected clue words for three well-studied datasets. Extensive experiments demonstrate that our model outperforms the baseline models with a large margin, especially when the labeled data is insufficient.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150092692",
                    "name": "Songtao Fang"
                },
                {
                    "authorId": "3374015",
                    "name": "Zhenya Huang"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "66187823",
                    "name": "Shiwei Tong"
                },
                {
                    "authorId": "2107921126",
                    "name": "Xiaoqing Huang"
                },
                {
                    "authorId": "2108335211",
                    "name": "Ye Liu"
                },
                {
                    "authorId": "2119233597",
                    "name": "Jie Huang"
                },
                {
                    "authorId": "50384136",
                    "name": "Qi Liu"
                }
            ]
        },
        {
            "paperId": "588f9746667fb771abe36e8603d8ecc76acfff32",
            "title": "DeepME: Deep Mixture Experts for Large-scale Image Classification",
            "abstract": "Although deep learning has demonstrated its outstanding performance on image classification, most well-known deep networks make efforts to optimize both their structures and their node weights for recognizing fewer (e.g., no more than 1000) object classes. Therefore, it is attractive to extend or mixture such well-known deep networks to support large-scale image classification. According to our best knowledge, how to adaptively and effectively fuse multiple CNNs for large-scale image classification is still under-explored. On this basis, a deep mixture algorithm is developed to support large-scale image classification in this paper. First, a soft spectral clustering method is developed to construct a two-layer ontology (group layer and category layer) by assigning large numbers of image categories into a set of groups according to their inter-category semantic correlations, where the semantically-related image categories under the neighbouring group nodes may share similar learning complexities. Then, such two-layer ontology is further used to generate the task groups, in which each task group contains partial image categories with similar learning complexities and one particular base deep network is learned. Finally, a gate network is learned to combine all base deep networks with fewer diverse outputs to generate a mixture network with larger outputs. Our experimental results on ImageNet10K have demonstrated that our proposed deep mixture algorithm can achieve very competitive results (top 1 accuracy: 32.13%) on large-scale image classification tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "2767360",
                    "name": "Guangyi Lv"
                },
                {
                    "authorId": "2153233192",
                    "name": "Weidong He"
                },
                {
                    "authorId": "2152732685",
                    "name": "Jianping Fan"
                },
                {
                    "authorId": "143653655",
                    "name": "Guihua Zeng"
                }
            ]
        },
        {
            "paperId": "4352b373d5eb214d00cf8c7d4450abfd2d5a520c",
            "title": "Multi-Path Relationship Preserved Social Network Embedding",
            "abstract": "Social network embedding, namely, embedding social network nodes into a low-dimensional space, is the foundation of social network analysis, such as node classification and link prediction. Although many existing methods attempt to address this task, most of them only consider the shallow relationship between two nodes in the network, which ignore capturing multiple and semantic-rich social relationships between users. To this end, we define such multiple and semantic-rich relationships as multi-path relationships, and propose a multi-path relationship preserved social network embedding method named MPR-SNE, which is based on the recurrent neural network framework that incorporates both social network structure and node profile information. Specifically, we first utilize random walks to explore the multiple social relationship paths between nodes. Then, a new recurrent unit called bi-directional multi-path relationship unit is proposed to better capture the properties of multi-path relationships. Finally, two objective functions are designed to seamlessly integrate social network structure and node profile information into node representation. The experimental results on two real-world networks show that MPR-SNE outperforms the state-of-the-art baselines on node classification task and link prediction task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144908694",
                    "name": "Jianfeng Lin"
                },
                {
                    "authorId": "2152831644",
                    "name": "Lei Zhang"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "9496222",
                    "name": "Hefu Zhang"
                },
                {
                    "authorId": "2116295475",
                    "name": "Guiquan Liu"
                },
                {
                    "authorId": "2109243843",
                    "name": "Xiuyuan Chen"
                },
                {
                    "authorId": "2144174228",
                    "name": "Zhongming Chen"
                }
            ]
        },
        {
            "paperId": "8a16caf14828a84026687b523b2f912f67dc974b",
            "title": "Embedding Visual Hierarchy With Deep Networks for Large-Scale Visual Recognition",
            "abstract": "In this paper, a layer-wise mixture model (LMM) is developed to support hierarchical visual recognition, where a Bayesian approach is used to automatically adapt the visual hierarchy to the progressive improvements of the deep network along the time. Our LMM algorithm can provide an end-to-end approach for jointly learning: 1) the deep network for achieving more discriminative deep representations for object classes and their inter-class visual similarities; 2) the tree classifier for recognizing large numbers of object classes hierarchically; and 3) the visual hierarchy adaptation for achieving more accurate assignment and organization of large numbers of object classes. By learning the tree classifier, the deep network and the visual hierarchy adaptation jointly in an end-to-end manner, our LMM algorithm can achieve higher accuracy rates on hierarchical visual recognition. Our experiments are carried on ImageNet1K and ImageNet10K image sets, which have demonstrated that our LMM algorithm can achieve very competitive results on the accuracy rates as compared with the baseline methods.",
            "fieldsOfStudy": [
                "Mathematics",
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114773310",
                    "name": "Tianyi Zhao"
                },
                {
                    "authorId": "2388768",
                    "name": "Baopeng Zhang"
                },
                {
                    "authorId": "2116974078",
                    "name": "Ming He"
                },
                {
                    "authorId": "2155470591",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "144107259",
                    "name": "Ning Zhou"
                },
                {
                    "authorId": "2117884196",
                    "name": "Jun Yu"
                },
                {
                    "authorId": "2152732685",
                    "name": "Jianping Fan"
                }
            ]
        }
    ]
}