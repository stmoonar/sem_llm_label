{
    "authorId": "2256778370",
    "papers": [
        {
            "paperId": "00af36ae2b615a8300348386052e38f4ddeb32e3",
            "title": "DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection",
            "abstract": "Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where LLMs could be incorporated as part of the pipeline: 1) LLMs could \\emph{generate news reactions} to represent diverse perspectives and simulate user-news interaction networks; 2) LLMs could \\emph{generate explanations} for proxy tasks (e.g., sentiment, stance) to enrich the contexts of news articles and produce experts specializing in various aspects of news understanding; 3) LLMs could \\emph{merge task-specific experts} and provide an overall prediction by incorporating the predictions and confidence scores of varying experts. Extensive experiments on seven datasets with three LLMs demonstrate that DELL outperforms state-of-the-art baselines by up to 16.8\\% in macro f1-score. Further analysis reveals that the generated reactions and explanations are greatly helpful in misinformation detection, while our proposed LLM-guided expert merging helps produce better-calibrated predictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2249583325",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "2260397981",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "752f684371c9901791259dc4afd04b9754e803d1",
            "title": "Can LLM Graph Reasoning Generalize beyond Pattern Memorization?",
            "abstract": "Large language models (LLMs) demonstrate great potential for problems with implicit graphical structures, while recent works seek to enhance the graph reasoning capabilities of LLMs through specialized instruction tuning. The resulting 'graph LLMs' are evaluated with in-distribution settings only, thus it remains underexplored whether LLMs are learning generalizable graph reasoning skills or merely memorizing patterns in the synthetic training data. To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph reasoning generalization: whether LLMs could go beyond semantic, numeric, structural, reasoning patterns in the synthetic training data and improve utility on real-world graph-based tasks. Extensive experiments with two LLMs across four graph reasoning tasks demonstrate that while generalization on simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to generalize across reasoning and real-world patterns, casting doubt on the benefit of synthetic graph tuning for real-world tasks with underlying network structures. We explore three strategies to improve LLM graph reasoning generalization, and we find that while post-training alignment is most promising for real-world tasks, empowering LLM graph reasoning to go beyond pattern memorization remains an open research question.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2308074430",
                    "name": "Yizhuo Zhang"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2284701198",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2257023881",
                    "name": "Xiaochuang Han"
                },
                {
                    "authorId": "2249540815",
                    "name": "Tianxing He"
                },
                {
                    "authorId": "2249583325",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "d51475858cdefe1ecfba357a24a39850083f5399",
            "title": "MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts",
            "abstract": "Online movie review websites are valuable for information and discussion about movies. However, the massive spoiler reviews detract from the movie-watching experience, making spoiler detection an important task. Previous methods simply focus on reviews' text content, ignoring the heterogeneity of information in the platform. For instance, the metadata and the corresponding user's information of a review could be helpful. Besides, the spoiler language of movie reviews tends to be genre-specific, thus posing a domain generalization challenge for existing methods. To this end, we propose MMoE, a multi-modal network that utilizes information from multiple modalities to facilitate robust spoiler detection and adopts Mixture-of-Experts to enhance domain generalization. MMoE first extracts graph, text, and meta feature from the user-movie network, the review's textual content, and the review's metadata respectively. To handle genre-specific spoilers, we then adopt Mixture-of-Experts architecture to process information in three modalities to promote robustness. Finally, we use an expert fusion layer to integrate the features from different perspectives and make predictions based on the fused embedding. Experiments demonstrate that MMoE achieves state-of-the-art performance on two widely-used spoiler detection datasets, surpassing previous SOTA methods by 2.56% and 8.41% in terms of accuracy and F1-score. Further experiments also demonstrate MMoE's superiority in robustness and generalization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290590861",
                    "name": "Zinan Zeng"
                },
                {
                    "authorId": "2220405893",
                    "name": "Sen Ye"
                },
                {
                    "authorId": "2290487420",
                    "name": "Zijian Cai"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2290529879",
                    "name": "Yuhan Liu"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "3f4ccf64ffe23b5dc095ae0401eecf9445deb024",
            "title": "Resolving Knowledge Conflicts in Large Language Models",
            "abstract": "Large language models (LLMs) often encounter knowledge conflicts, scenarios where discrepancy arises between the internal parametric knowledge of LLMs and non-parametric information provided in the prompt context. In this work we ask what are the desiderata for LLMs when a knowledge conflict arises and whether existing LLMs fulfill them. We posit that LLMs should 1) identify knowledge conflicts, 2) pinpoint conflicting information segments, and 3) provide distinct answers or viewpoints in conflicting scenarios. To this end, we introduce KNOWLEDGE CONFLICT, an evaluation framework for simulating contextual knowledge conflicts and quantitatively evaluating to what extent LLMs achieve these goals. KNOWLEDGE CONFLICT includes diverse and complex situations of knowledge conflict, knowledge from diverse entities and domains, two synthetic conflict creation methods, and settings with progressively increasing difficulty to reflect realistic knowledge conflicts. Extensive experiments with the KNOWLEDGE CONFLICT framework reveal that while LLMs perform well in identifying the existence of knowledge conflicts, they struggle to determine the specific conflicting knowledge and produce a response with distinct answers amidst conflicting information. To address these challenges, we propose new instruction-based approaches that augment LLMs to better achieve the three goals. Further analysis shows that abilities to tackle knowledge conflicts are greatly impacted by factors such as knowledge domain and prompt text, while generating robust responses to knowledge conflict scenarios remains an open research question.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108853330",
                    "name": "Yike Wang"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2254168375",
                    "name": "Weijia Shi"
                },
                {
                    "authorId": "143820870",
                    "name": "Vidhisha Balachandran"
                },
                {
                    "authorId": "2249540815",
                    "name": "Tianxing He"
                },
                {
                    "authorId": "2249583325",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "9e190a86b861cfb612ef36eb3baeec24bf51c776",
            "title": "Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks",
            "abstract": "Online movie review platforms are providing crowdsourced feedback for the film industry and the general public, while spoiler reviews greatly compromise user experience. Although preliminary research efforts were made to automatically identify spoilers, they merely focus on the review content itself, while robust spoiler detection requires putting the review into the context of facts and knowledge regarding movies, user behavior on film review platforms, and more. In light of these challenges, we first curate a large-scale network-based spoiler detection dataset LCS and a comprehensive and up-to-date movie knowledge base UKM. We then propose MVSD, a novel Multi-View Spoiler Detection framework that takes into account the external knowledge about movies and user activities on movie review platforms. Specifically, MVSD constructs three interconnecting heterogeneous information networks to model diverse data sources and their multi-view attributes, while we design and employ a novel heterogeneous graph neural network architecture for spoiler detection as node-level classification. Extensive experiments demonstrate that MVSD advances the state-of-the-art on two spoiler detection datasets, while the introduction of external knowledge and user interactions help ground robust spoiler detection. Our data and code are available at https://github.com/Arthur-Heng/Spoiler-Detection",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "49039233",
                    "name": "Wenqian Zhang"
                },
                {
                    "authorId": "2170130468",
                    "name": "Yuyang Bai"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "c93b7a5de079215bbba15c304b2d2f9541f7f88a",
            "title": "BotMoE: Twitter Bot Detection with Community-Aware Mixtures of Modal-Specific Experts",
            "abstract": "Twitter bot detection has become a crucial task in efforts to combat online misinformation, mitigate election interference, and curb malicious propaganda. However, advanced Twitter bots often attempt to mimic the characteristics of genuine users through feature manipulation and disguise themselves to fit in diverse user communities, posing challenges for existing Twitter bot detection models. To this end, we propose BotMoE, a Twitter bot detection framework that jointly utilizes multiple user information modalities (metadata, textual content, network structure) to improve the detection of deceptive bots. Furthermore, BotMoE incorporates a community-aware Mixture-of-Experts (MoE) layer to improve domain generalization and adapt to different Twitter communities. Specifically, BotMoE constructs modal-specific encoders for metadata features, textual content, and graph structure, which jointly model Twitter users from three modal-specific perspectives. We then employ a community-aware MoE layer to automatically assign users to different communities and leverage the corresponding expert networks. Finally, user representations from metadata, text, and graph perspectives are fused with an expert fusion layer, combining all three modalities while measuring the consistency of user information. Extensive experiments demonstrate that BotMoE significantly advances the state-of-the-art on three Twitter bot detection benchmarks. Studies also confirm that BotMoE captures advanced and evasive bots, alleviates the reliance on training data, and better generalizes to new and previously unseen user communities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2169159066",
                    "name": "Yuhan Liu"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "df2beaae63e4d68ef8e762bcd4704c9f11f856d9",
            "title": "Can Language Models Solve Graph Problems in Natural Language?",
            "abstract": "Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings. We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems. Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question. The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "3083253",
                    "name": "Tianxing He"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "40500540",
                    "name": "Xiaochuang Han"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "7066c88ffd227c74479f29f917f0db73270afa24",
            "title": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
            "abstract": "Twitter bot detection has become an increasingly important task to combat misinformation, facilitate social media moderation, and preserve the integrity of the online discourse. State-of-the-art bot detection methods generally leverage the graph structure of the Twitter network, and they exhibit promising performance when confronting novel Twitter bots that traditional methods fail to detect. However, very few of the existing Twitter bot detection datasets are graph-based, and even these few graph-based datasets suffer from limited dataset scale, incomplete graph structure, as well as low annotation quality. In fact, the lack of a large-scale graph-based Twitter bot detection benchmark that addresses these issues has seriously hindered the development and evaluation of novel graph-based bot detection approaches. In this paper, we propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark that presents the largest dataset to date, provides diversified entities and relations on the Twitter network, and has considerably better annotation quality than existing datasets. In addition, we re-implement 35 representative Twitter bot detection baselines and evaluate them on 9 datasets, including TwiBot-22, to promote a fair comparison of model performance and a holistic understanding of research progress. To facilitate further research, we consolidate all implemented codes and datasets into the TwiBot-22 evaluation framework, where researchers could consistently evaluate new models and datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation framework are publicly available at https://twibot22.github.io/",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2152170253",
                    "name": "Ningnan Wang"
                },
                {
                    "authorId": "2117098676",
                    "name": "Zilong Chen"
                },
                {
                    "authorId": "2134483590",
                    "name": "Binchi Zhang"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "49039233",
                    "name": "Wenqian Zhang"
                },
                {
                    "authorId": "2161968765",
                    "name": "Zhenyu Lei"
                },
                {
                    "authorId": "2169372154",
                    "name": "Shujie Yang"
                },
                {
                    "authorId": "2169404546",
                    "name": "Xinshun Feng"
                },
                {
                    "authorId": "2261664149",
                    "name": "Qingyue Zhang"
                },
                {
                    "authorId": "2169403637",
                    "name": "Hongrui Wang"
                },
                {
                    "authorId": "2169159066",
                    "name": "Yuhan Liu"
                },
                {
                    "authorId": "2170130468",
                    "name": "Yuyang Bai"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2169253157",
                    "name": "Zijian Cai"
                },
                {
                    "authorId": "2107964144",
                    "name": "Yanbo Wang"
                },
                {
                    "authorId": "1964303146",
                    "name": "Lijing Zheng"
                },
                {
                    "authorId": "2169172454",
                    "name": "Zihan Ma"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        }
    ]
}