{
    "authorId": "49889831",
    "papers": [
        {
            "paperId": "06d07c618d2c8e7184b575ec2215157fc158b579",
            "title": "VeDB: A Software and Hardware Enabled Trusted Relational Database",
            "abstract": "Blockchain-like ledger databases emerge in recent years as a more efficient alternative to permissioned blockchains. Conventional ledger databases mostly rely on authenticated structures such as the Merkle tree and transparency logs for supporting auditability, and hence they suffer from the performance problem. As opposed to conventional ledger DBMSes, we design VeDB - a high-performance verifiable software (Ve-S) and hardware (Ve-H) enabled DBMS with rigorous auditability for better user options and broad applications. In Ve-S, we devise a novel verifiable Shrubs array (VSA) with two-layer ordinals (serial numbers) which outperforms conventional Merkle tree-based models due to lower CPU and I/O cost. It enables rigorous auditability through its efficient credible timestamp range authentication method, and fine-grained data verification at the client side, which are lacking in state-of-the-art relational ledger databases. In Ve-H, we devise a non-intrusive trusted affiliation by TEE leveraging digest signing, monotonic counters, and trusted timestamps in VeDB, which supports both data notarization and lineage applications. The experimental results show that VeDB-VSA outperforms Merkle tree-based authenticated data structures (ADS) up to 70\u00d7 and 3.7\u00d7 for insertion and verification; and VeDB Ve-H data lineage verification is 8.5\u00d7 faster than Ve-S.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1942843711",
                    "name": "Xinying Yang"
                },
                {
                    "authorId": "2311308008",
                    "name": "Ruide Zhang"
                },
                {
                    "authorId": "2055372405",
                    "name": "Cong Yue"
                },
                {
                    "authorId": "37948271",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1693070",
                    "name": "B. Ooi"
                },
                {
                    "authorId": "2180220058",
                    "name": "Qun Gao"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2115538297",
                    "name": "Hao Yang"
                }
            ]
        },
        {
            "paperId": "0c7897aeb7cce34927f28a7fe6c3b98ad8a7750b",
            "title": "Measuring Item Global Residual Value for Fair Recommendation",
            "abstract": "In the era of information explosion, numerous items emerge every day, especially in feed scenarios. Due to the limited system display slots and user browsing attention, various recommendation systems are designed not only to satisfy users' personalized information needs but also to allocate items' exposure. However, recent recommendation studies mainly focus on modeling user preferences to present satisfying results and maximize user interactions, while paying little attention to developing item-side fair exposure mechanisms for rational information delivery. This may lead to serious resource allocation problems on the item side, such as the Snowball Effect. Furthermore, unfair exposure mechanisms may hurt recommendation performance. In this paper, we call for a shift of attention from modeling user preferences to developing fair exposure mechanisms for items. We first conduct empirical analyses of feed scenarios to explore exposure problems between items with distinct uploaded times. This points out that unfair exposure caused by the time factor may be the major cause of the Snowball Effect. Then, we propose to explicitly model item-level customized timeliness distribution, Global Residual Value (GRV), for fair resource allocation. This GRV module is introduced into recommendations with the designed Timeliness-aware Fair Recommendation Framework (TaFR). Extensive experiments on two datasets demonstrate that TaFR achieves consistent improvements with various backbone recommendation models. By modeling item-side customized Global Residual Value, we achieve a fairer distribution of resources and, at the same time, improve recommendation performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181296217",
                    "name": "Jiayin Wang"
                },
                {
                    "authorId": "2903964",
                    "name": "Weizhi Ma"
                },
                {
                    "authorId": "2223716415",
                    "name": "Chumeng Jiang"
                },
                {
                    "authorId": "2157501595",
                    "name": "Min Zhang"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2156072391",
                    "name": "Biao Li"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                }
            ]
        },
        {
            "paperId": "0f46dc51a441de8caadbad3d2f023a72955affaa",
            "title": "Random Time Division Multiplexing Based MIMO Radar Processing with Tensor Completion Approach",
            "abstract": "Automotive radar pursues low cost and high performance, and especially hopes to improve the angular resolution under the condition of a limited number of multiple-input\u2013multiple-output (MIMO) radar channels. Conventional time division multiplexing (TDM) MIMO technology has a limited ability to improve the angular resolution without increasing the number of channels. In this paper, a random time division multiplexing MIMO radar is proposed. First, the non-uniform linear array (NULA) and random time division transmission mechanism are combined in the MIMO system, and then a three-order sparse receiving tensor of a range-virtual aperture-pulse sequence is obtained during echo receiving. Next, this sparse three-order receiving tensor is recovered by using tensor completion technology. Finally, the range, velocity and angle measurements are completed for the recovered three-order receiving tensor signals. The effectiveness of this method is verified via simulations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2217521643",
                    "name": "Yixue Qiao"
                },
                {
                    "authorId": "2155121521",
                    "name": "Gang Li"
                },
                {
                    "authorId": "2157337335",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2201883893",
                    "name": "Qing Tian"
                }
            ]
        },
        {
            "paperId": "14cbf1cfd5dd4b451bfd6ef89e2bc277799df9bd",
            "title": "Alleviating Matthew Effect of Offline Reinforcement Learning in Interactive Recommendation",
            "abstract": "Offline reinforcement learning (RL), a technology that offline learns a policy from logged data without the need to interact with online environments, has become a favorable choice in decision-making processes like interactive recommendation. Offline RL faces the value overestimation problem. To address it, existing methods employ conservatism, e.g., by constraining the learned policy to be close to behavior policies or punishing the rarely visited state-action pairs. However, when applying such offline RL to recommendation, it will cause a severe Matthew effect, i.e., the rich get richer and the poor get poorer, by promoting popular items or categories while suppressing the less popular ones. It is a notorious issue that needs to be addressed in practical recommender systems. In this paper, we aim to alleviate the Matthew effect in offline RL-based recommendation. Through theoretical analyses, we find that the conservatism of existing methods fails in pursuing users' long-term satisfaction. It inspires us to add a penalty term to relax the pessimism on states with high entropy of the logging policy and indirectly penalizes actions leading to less diverse states. This leads to the main technical contribution of the work: Debiased model-based Offline RL (DORL) method. Experiments show that DORL not only captures user interests well but also alleviates the Matthew effect. The implementation is available via https://github.com/chongminggao/DORL-codes",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31446099",
                    "name": "Chongming Gao"
                },
                {
                    "authorId": "2112441120",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "1452347263",
                    "name": "Jiawei Chen"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2156072391",
                    "name": "Biao Li"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "2108622235",
                    "name": "Shiqin Wang"
                },
                {
                    "authorId": "2221728472",
                    "name": "Zhong Zhang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "2b6976e31e989a7b3ef81a991d190aa2b85e987b",
            "title": "Blockchain-Based Transparent Integrity Auditing and Encrypted Deduplication for Cloud Storage",
            "abstract": "In this paper, we introduce a concept of transparent integrity auditing and propose a concrete scheme based on the blockchain, which goes one step beyond existing public auditing schemes, since the auditing does not rely on third-party auditors while freeing users from heavy communication costs on auditing the data integrity. Then we construct a secure transparent deduplication scheme based on the blockchain that supports deduplication over encrypted data and enables users to attest the deduplication pattern on the cloud server. Such a scheme allows users to directly benefit from data deduplication and protects data content against anyone who does not own the data. Finally, we integrate the proposed transparent integrity auditing scheme and transparent deduplication scheme into one system, dubbed BLIND. We evaluate BLIND from security and efficiency, which demonstrates that BLIND achieves a strong security guarantee with high efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119027531",
                    "name": "Shanshan Li"
                },
                {
                    "authorId": "33864819",
                    "name": "Chunxiang Xu"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2152976631",
                    "name": "Yicong Du"
                },
                {
                    "authorId": "2218686608",
                    "name": "Kefei Chen"
                }
            ]
        },
        {
            "paperId": "7d9185004276381ab00bb08fd25bac16fc53736a",
            "title": "Divide and Conquer: Towards Better Embedding-based Retrieval for Recommender Systems from a Multi-task Perspective",
            "abstract": "Embedding-based retrieval (EBR) methods are widely used in modern recommender systems thanks to its simplicity and effectiveness. However, along the journey of deploying and iterating on EBR in production, we still identify some fundamental issues in existing methods. First, when dealing with large corpus of candidate items, EBR models often have difficulties in balancing the performance on distinguishing highly relevant items (positives) from both irrelevant ones (easy negatives) and from somewhat related yet not competitive ones (hard negatives). Also, we have little control in the diversity and fairness of the retrieval results because of the \u201cgreedy\u201d nature of nearest vector search. These issues compromise the performance of EBR methods in large-scale industrial scenarios. This paper introduces a simple and proven-in-production solution to overcome these issues. The proposed solution takes a divide-and-conquer approach: the whole set of candidate items are divided into multiple clusters and we run EBR to retrieve relevant candidates from each cluster in parallel; top candidates from each cluster are then combined by some controllable merging strategies. This approach allows our EBR models to only concentrate on discriminating positives from mostly hard negatives. It also enables further improvement from a multi-tasking learning (MTL) perspective: retrieval problems within each cluster can be regarded as individual tasks; inspired by recent successes in prompting and prefix-tuning, we propose an efficient task adaption technique further boosting the retrieval performance within each cluster with negligible overheads. The presented solution has been deployed in Kuaishou, one of the most popular short-video streaming platforms in China with hundreds of millions of active users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2204669948",
                    "name": "Xue Dong"
                },
                {
                    "authorId": "2051321269",
                    "name": "Wei Ding"
                },
                {
                    "authorId": "2156072391",
                    "name": "Biao Li"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "c19612554ca48b7013c2cb32cf1b161ccac68b4a",
            "title": "Performance Modeling of an NR-U and WiFi Coexistence System Using the NR-U Category-4 LBT Procedure and 802.11e EDCA Mechanism in the Presence of Hidden Nodes",
            "abstract": "This article studies the performance modeling of an NR-U and WiFi coexistence system using the NR-U category-4 listen-before-talk (LBT) procedure and 802.11e enhanced distributed channel access (EDCA) mechanism in the presence of hidden nodes. 3-D Markov models are first developed to describe the NR-U category-4 LBT procedure for a priority-<inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula> queue of an NR-U gNB and the 802.11e EDCA mechanism for an AC-<inline-formula> <tex-math notation=\"LaTeX\">${q}$ </tex-math></inline-formula> queue of a WiFi AP, taking into account the effects of hidden nodes and the transmission of different-priority data. Based on the Markov models, theoretical models are derived for analyzing the mean throughput of a priority-<inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula> queue in an NR-U gNB and that of an AC-<inline-formula> <tex-math notation=\"LaTeX\">${q}$ </tex-math></inline-formula> queue in a WiFi AP as well as the mean transmission delay of an NR-U priority-<inline-formula> <tex-math notation=\"LaTeX\">${p}$ </tex-math></inline-formula> data packet and that of a WiFi AC-<inline-formula> <tex-math notation=\"LaTeX\">${q}$ </tex-math></inline-formula> data packet. The derived theoretical performance models are validated through simulation results. Based on the performance models, the impacts of major system parameters on the system performance are investigated, including the density of NR-U gNBs, the sensing distance and channel transmission rate of an NR-U gNB, and the data packet arrival rate at an NR-U gNB.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2197062007",
                    "name": "Jun Zheng"
                },
                {
                    "authorId": "2054858607",
                    "name": "Qilei Ren"
                },
                {
                    "authorId": "2155840673",
                    "name": "Bingying Wang"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                }
            ]
        },
        {
            "paperId": "cd992965814bf560a1c94b295078803dc0302967",
            "title": "Performance Modeling of an NR-U and WiFi Coexistence System Using the NR-U Category-4 LBT Procedure and WiFi DCF Mechanism in the Presence of Hidden Nodes",
            "abstract": "The hidden-node problem is an important problem that should be considered in the design of a wireless communication system. This article studies the performance modeling of an NR-U and WiFi coexistence system using the NR-U category-4 LBT procedure and WiFi DCF mechanism in the presence of hidden nodes. 2-D Markov models are first developed to describe the NR-U category-4 LBT procedure of an NR-U gNB and the WiFi DCF procedure of a WiFi AP, respectively, taking into account the effects of hidden nodes. Based on the two Markov models, theoretical models are further derived for analyzing the throughput of a gNB/AP and the delay of an NR-U/WiFi packet. Finally, the derived theoretical models are validated through simulation results and based on the theoretical models, the impacts of major system parameters on the system performance in terms of the throughput and packet delay are investigated, including the data packet arrival rate, the density, the sensing distance, and the channel transmission rate of a gNB.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2054858607",
                    "name": "Qilei Ren"
                },
                {
                    "authorId": "2155840673",
                    "name": "Bingying Wang"
                },
                {
                    "authorId": "2238162673",
                    "name": "Jun Zheng"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                }
            ]
        },
        {
            "paperId": "023706a18b9999072095ba5ef5c4a42cb8e1d489",
            "title": "Ubiquitous Verification in Centralized Ledger Database",
            "abstract": "Verifiability is the backbone of most ledger systems to realize credible authentication. However, existing permissioned blockchains and centralized ledger databases lack rigorous verifiability to authenticate all facts (i.e., what-when-who validation). Besides, they suffer from high verification cost to a continually growing immutable storage. In this paper, we introduce verification principles behind LedgerDB, a centralized ledger database that achieves both strong external auditability and fast verification. We coin a novel concept called Dasein Verification that composes of three validation factors what-when-who to formalize ledger auditing. Regarding what, LedgerDB devises fam (fractal accumulating model) to accelerate existence verification, and CM-Tree for efficient lineage verification. Veri-fiable data mutations are also supported. For when, we discuss attacks on existing time pegging protocols that compromise the authenticity of timestamps, and propose a time notary protocol to resolve those threats. Evaluations show that fam and CM- Tree significantly outperform traditional approaches. Compared to Hyperledger Fabric, LedgerDB achieves 23x higher verification throughput with 500 x lower latency in notarization applications, and 3 x higher throughput with 300 x lower latency in lineage tracking applications. As a public-cloud ledger service, the end-to-end verification latencies of LedgerDB are on average 50 x and 1000x lower than that of QLDB in the above applications, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1942843711",
                    "name": "Xinying Yang"
                },
                {
                    "authorId": "50695586",
                    "name": "Sheng Wang"
                },
                {
                    "authorId": "2146324505",
                    "name": "Feifei Li"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2117115528",
                    "name": "Wenyuan Yan"
                },
                {
                    "authorId": "2987355",
                    "name": "Fangyu Gai"
                },
                {
                    "authorId": "24812041",
                    "name": "Benquan Yu"
                },
                {
                    "authorId": "2180225398",
                    "name": "Likai Feng"
                },
                {
                    "authorId": "2180220058",
                    "name": "Qun Gao"
                },
                {
                    "authorId": "1943322867",
                    "name": "Yize Li"
                }
            ]
        },
        {
            "paperId": "0365f40cdaebcbadae30e9f4d93cfcfefbb5108a",
            "title": "Enabling Verifiable Privacy-Preserving Multi-Type Data Aggregation in Smart Grids",
            "abstract": "In this article, we analyze the inherent characteristic of smart grid systems, where we observe that a smart meter always generates different types of electricity consumption data for one user, and a control center (CC) always conducts an in-depth statistic analysis on these data for subsequent services. Among these data, some of them are very sensitive and should be prevented for any leakage and modification. Furthermore, due to the large number of users in a smart grid system, it is advantageous for CC to receive and process the data from different users simultaneously. To this end, we propose a verifiable privacy-preserving multi-type data aggregation scheme (VPMDA) for smart grids. VPMDA enables an aggregator gateway (AG) to aggregate encrypted multi-type data and forward the aggregated data to CC, such that CC checks the integrity of aggregated data and obtains the statistic analysis results (e.g., average, variance) on the aggregated data without learning each individual data content. We further extend VPMDA to improve the performance of verifying data integrity on CC significantly. We formally prove the security of VPMDA against various attacks. We also implement a prototype of VPMDA and conduct a comprehensive performance evaluation to demonstrate its feasibility and efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108198401",
                    "name": "Xiaojun Zhang"
                },
                {
                    "authorId": "2110927135",
                    "name": "Chao Huang"
                },
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2072594747",
                    "name": "Sheng Cao"
                }
            ]
        }
    ]
}