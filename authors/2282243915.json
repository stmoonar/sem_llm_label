{
    "authorId": "2282243915",
    "papers": [
        {
            "paperId": "321129c86cfddde76638cdcd7ba3d56d8788015c",
            "title": "Cumulative Distribution Function based General Temporal Point Processes",
            "abstract": "Temporal Point Processes (TPPs) hold a pivotal role in modeling event sequences across diverse domains, including social networking and e-commerce, and have significantly contributed to the advancement of recommendation systems and information retrieval strategies. Through the analysis of events such as user interactions and transactions, TPPs offer valuable insights into behavioral patterns, facilitating the prediction of future trends. However, accurately forecasting future events remains a formidable challenge due to the intricate nature of these patterns. The integration of Neural Networks with TPPs has ushered in the development of advanced deep TPP models. While these models excel at processing complex and nonlinear temporal data, they encounter limitations in modeling intensity functions, grapple with computational complexities in integral computations, and struggle to capture long-range temporal dependencies effectively. In this study, we introduce the CuFun model, representing a novel approach to TPPs that revolves around the Cumulative Distribution Function (CDF). CuFun stands out by uniquely employing a monotonic neural network for CDF representation, utilizing past events as a scaling factor. This innovation significantly bolsters the model's adaptability and precision across a wide range of data scenarios. Our approach addresses several critical issues inherent in traditional TPP modeling: it simplifies log-likelihood calculations, extends applicability beyond predefined density function forms, and adeptly captures long-range temporal patterns. Our contributions encompass the introduction of a pioneering CDF-based TPP model, the development of a methodology for incorporating past event information into future event prediction, and empirical validation of CuFun's effectiveness through extensive experimentation on synthetic and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2253844324",
                    "name": "Yu Pan"
                },
                {
                    "authorId": "2238898625",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2282243915",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2223875866",
                    "name": "Langming Liu"
                }
            ]
        },
        {
            "paperId": "37741a9e9a2cb964ca3c7ab034c3e077baf66c8c",
            "title": "BiVRec: Bidirectional View-based Multimodal Sequential Recommendation",
            "abstract": "The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we first construct structured user interest representations and then learn the synergistic relationship between them. Specifically, BivRec comprises three modules: Multi-scale Interest Embedding, comprehensively modeling user interests by expanding user interaction sequences with multi-scale patching; Intra-View Interest Decomposition, constructing highly structured interest representations using carefully designed Gaussian attention and Cluster attention; and Cross-View Interest Learning, learning the synergistic relationship between the two recommendation views through coarse-grained overall semantic similarity and fine-grained interest allocation similarity BiVRec achieves state-of-the-art performance on five datasets and showcases various practical advantages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2284735864",
                    "name": "Yuehong Hu"
                },
                {
                    "authorId": "2289093854",
                    "name": "Yuxuan Liang"
                },
                {
                    "authorId": "2282243915",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2287901729",
                    "name": "Ming He"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2282271789",
                    "name": "Hongzhi Yin"
                }
            ]
        }
    ]
}