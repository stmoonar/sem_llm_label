{
    "authorId": "1896690",
    "papers": [
        {
            "paperId": "5c37b060bf9c7af2425588cca993ffa43e55b550",
            "title": "Distributed Social Benefit Allocation using Reasoning over Personal Data in Solid",
            "abstract": "When interacting with government institutions, citizens may often be asked to provide a number of documents to various officials, due to the way the data is being processed by the government, and regulation or guidelines that restrict sharing of that data between institutions. Occasionally, documents from third parties, such as the private sector, are involved, as the data, rules, regulations and individual private data may be controlled by different parties. Facilitating efficient flow of information in such cases is therefore important, while still respecting the ownership and privacy of that data. Addressing these types of use cases in data storage and sharing, the Solid initiative allows individuals, organisations and the public sector to store their data in personal online datastores. Solid has been previously applied in data storage within government contexts, so we decided to extend that work by adding data processing services on top of such data and including multiple parties such as citizen and the private sector. However, introducing multiple parties within the data processing flow may impose new challenges, and implementing such data processing services in practice on top of Solid might present opportunities for improvement from the perspective of the implementer of the services. Within this work, together with the City of Antwerp in Belgium, we have produced a proof-of-concept service implementation operating at the described intersection of public sector, citizens and private sector, to manage social benefit allocation in a distributed environment. The service operates on distributed Linked Data stored in multiple Solid pods in RDF, using Notation3 rules to process that data and SPARQL queries to access and modify it. This way, our implementation seeks to respect the design principles of Solid, while taking advantage of the related technologies for representing, processing and modifying Linked Data. This document will describe our chosen use case, service design and implementation, and our observations resulting from this experiment. Through the proof-of-concept implementation, we have established a preliminary understanding of the current challenges in implementing such a service using the chosen technologies. We have identified topics such as verification of data that should be addressed when using such an approach in practice, assumptions related to data locations and tight coupling between our logic between the rules and program code. Addressing these topics in future work should help further the adoption of Linked Data as a means to solve challenges around data sharing, processing and ownership such as with government processes involving multiple parties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1453331738",
                    "name": "Jonni Hanski"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "0f32ae0eb2cc0d626a8649c56b13df8f43bba59e",
            "title": "Visual notations for viewing RDF constraints with UnSHACLed",
            "abstract": "The quality of knowledge graphs can be assessed by a validation against specified constraints, typically use-case specific and modeled by human users in a manual fashion. Visualizations can improve the modeling process as they are specifically designed for human information processing, possibly leading to more accurate constraints, and in turn higher quality knowledge graphs. However, it is currently unknown how such visualizations support users when viewing RDF constraints as no scientific evidence for the visualizations\u2019 effectiveness is provided. Furthermore, some of the existing tools are likely suboptimal, as they lack support for edit\u00a0operations or common constraints types. To establish a\u00a0baseline, we have defined visual notations to represent RDF constraints and implemented them in UnSHACLed, a\u00a0tool that is independent of a\u00a0concrete RDF constraint language. In this paper, we (i)\u00a0present two visual notations that support all SHACL core constraints, built upon the commonly used visualizations VOWL and UML, (ii)\u00a0analyze both notations based on cognitive effective design principles, (iii)\u00a0perform a comparative user study between both visual notations, and (iv)\u00a0present our open source tool UnSHACLed incorporating our efforts. Users were presented RDF constraints in both visual notations and had to answer questions based on visualization task taxonomies. Although no statistical significant difference in mean error rates was observed, all study participants preferred ShapeVOWL in a self assessment to answer RDF constraint-related questions. Furthermore, ShapeVOWL adheres to more cognitive effective design principles according to our performed comparison. Study participants argued that the increased visual features of ShapeVOWL made it easier to spot constraints, but a list of constraints\u00a0\u2013 as in ShapeUML\u00a0\u2013 is easier to read. However, also that more deviations from the strict UML specification and introduction of more visual features can improve ShapeUML. From these findings we conclude that ShapeVOWL has a higher potential to represent RDF constraints more effective compared to ShapeUML. But also that the clear and efficient text encoding of ShapeUML can be improved with visual features. A\u00a0one-size-fits-all approach to RDF constraint visualization and editing will be insufficient. Therefore, to support different audiences and use cases, user interfaces of RDF constraint editors need to support different visual notations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38278085",
                    "name": "S. Lieber"
                },
                {
                    "authorId": "2141864424",
                    "name": "Ben De\u00a0Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2141885284",
                    "name": "Femke Br\u00fcckmann"
                },
                {
                    "authorId": "2141886718",
                    "name": "Ruben Wambacq"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "b978c37f2e0aeb09523b8fb25a0a635441f2b46a",
            "title": "PROV4ITDaTa: Transparent and direct transferof personal data to personal stores",
            "abstract": "Data is scattered across service providers, heterogeneously structured in various formats. By lack of interoperability, data portability is hindered, and thus user control is inhibited. An interoperable data portability solution for transferring personal data is needed. We demo PROV4ITDaTa: a Web application, that allows users to transfer personal data into an interoperable format to their personal data store. PROV4ITDaTa leverages the open-source solutions RML.io, Comunica, and Solid: (i) the RML.io toolset to describe how to access data from service providers and generate interoperable datasets; (ii) Comunica to query these and more flexibly generate enriched datasets; and (iii) Solid Pods to store the generated data as Linked Data in personal data stores. As opposed to other (hard-coded) solutions, PROV4ITDaTa is fully transparent, where each component of the pipeline is fully configurable and automatically generates detailed provenance trails. Furthermore, transforming the personal data into RDF allows for an interopable solution. By maximizing the use of open-source tools and open standards, PROV4ITDaTa facilitates the shift towards a data ecosystem wherein users have control of their data, and providers can focus on their service instead of trying to adhere to interoperability requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091080870",
                    "name": "Gertjan De Mulder"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "cfd3929eb7eb98209acea307838be4c9ddc4d33c",
            "title": "Integrating Nested Data into Knowledge Graphs with RML Fields",
            "abstract": "To support business decisions or improve operational efficiency, heterogeneous data is often integrated into a knowledge graph. This integration can be achieved with one of the existing declarative mapping languages, which offer declarative data integration in the form of knowledge graphs. However, current mapping languages cannot always integrate data with nested structure, such as JSON or XML files or JSON documents stored in a database column. We designed a backwards-compatible extension of the RDF Mapping Language (RML) which empowers it to integrate nested data: RML fields. In this paper, we introduce RML fields, compare it with the state of the art in mapping languages, and validate it on mapping challenges formulated by the Knowledge Graph Construction W3C community group. Our extension allows addressing several of the challenges related to nested data that were previously not possible. RML fields can integrate even more datasets into knowledge graphs with all the advantages of using a language specially designed for that purpose. Our extension intends integrating multiple data sets independently, but some use cases require joins or other operations during knowledge graph generation, which we will investigate in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091007362",
                    "name": "Thomas Delva"
                },
                {
                    "authorId": "1742222115",
                    "name": "Dylan Van Assche"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "ec8c7523a629bac006a7064ee61050f6bc803af1",
            "title": "Towards a more human-friendly knowledge graph generation & publication",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1742222115",
                    "name": "Dylan Van Assche"
                },
                {
                    "authorId": "2091007362",
                    "name": "Thomas Delva"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "20364b977fe5c37de0e891b25800bb5065a91c42",
            "title": "RDF graph validation using rule-based reasoning",
            "abstract": "The correct functioning of Semantic Web applications requires that given RDF graphs adhere to an expected shape. This shape depends on the RDF graph and the application\u2019s supported entailments of that graph. During validation, RDF graphs are assessed against sets of constraints, and found violations help refining the RDF graphs. However, existing validation approaches cannot always explain the root causes of violations (inhibiting refinement), and cannot fully match the entailments supported during validation with those supported by the application. These approaches cannot accurately validate RDF graphs, or combine multiple systems, deteriorating the validator\u2019s performance. In this paper, we present an alternative validation approach using rule-based reasoning, capable of fully customizing the used inferencing steps. We compare to existing approaches, and present a formal ground and practical implementation \u201cValidatrr\u201d, based on N3Logic and the EYE reasoner. Our approach \u2013\u00a0supporting an equivalent number of constraint types compared to the state of the art\u00a0\u2013 better explains the root cause of the violations due to the reasoner\u2019s generated logical proof, and returns an accurate number of violations due to the customizable inferencing rule set. Performance evaluation shows that Validatrr is performant for smaller datasets, and scales linearly w.r.t. the RDF graph size. The detailed root cause explanations can guide future validation report description specifications, and the fine-grained level of configuration can be employed to support different constraint languages. This foundation allows further research into handling recursion, validating RDF graphs based on their generation description, and providing automatic refinement suggestions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "38127359",
                    "name": "D\u00f6rthe Arndt"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "b7c62dc6c319908239447c0231eb02b80fa0777f",
            "title": "Distributed Continuous Home Care Provisioning through Personalized Monitoring & Treatment Planning",
            "abstract": "In healthcare, the aging of the population is resulting in a gradual shift from residential care to home care, requiring reliable follow-up of elderly people by a whole network of care providers. The environment of these patients is increasingly being equipped with different monitoring devices, which allow to obtain insight into the current condition of patient & environment. However, current monitoring platforms that support care providers are centralized and not personalized, reducing performance, scalability, autonomy and privacy. Because the available data is only exposed through custom APIs, profile knowledge cannot be efficiently exchanged, which is required to provide optimal care. Therefore, this paper presents a distributed data-driven platform, built on Semantic Web technologies, that enables the integration of all profile knowledge in order to deliver personalized continuous home care. It provides a distributed smart monitoring service, which allows to locally monitor only the relevant sensors according to the patient\u2019s profile, and infer personalized decisions when analyzing events. Moreover, it provides a medical treatment planning service, which composes treatment plans tailored to each patient, including personalized quality of service parameters allowing a doctor to select the optimal plan. To illustrate how the platform delivers these services, the paper also presents a demonstrator using a realistic home care scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40975212",
                    "name": "Mathias De Brouwer"
                },
                {
                    "authorId": "33122761",
                    "name": "P. Bonte"
                },
                {
                    "authorId": "38127359",
                    "name": "D\u00f6rthe Arndt"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1715957",
                    "name": "F. Turck"
                },
                {
                    "authorId": "1726557",
                    "name": "F. Ongenae"
                }
            ]
        },
        {
            "paperId": "c4cbd23a3421dde84c95613418ee48d28a419503",
            "title": "Context-Aware Route Planning: A Personalized and Situation-Aware Multi-Modal Transport Routing approach",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33122761",
                    "name": "P. Bonte"
                },
                {
                    "authorId": "40975212",
                    "name": "Mathias De Brouwer"
                },
                {
                    "authorId": "38127359",
                    "name": "D\u00f6rthe Arndt"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "2370758",
                    "name": "Pieter Colpaert"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1715957",
                    "name": "F. Turck"
                },
                {
                    "authorId": "1726557",
                    "name": "F. Ongenae"
                }
            ]
        },
        {
            "paperId": "0094e02eb62ee6aae86fc583e44365650ad4ef92",
            "title": "Mapping Languages: Analysis of Comparative Characteristics",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "34126c1dbe6a1614814dc23dc50d0e0ffe636c23",
            "title": "Rule-driven inconsistency resolution for knowledge graph generation rules",
            "abstract": "Knowledge graphs, which contain annotated descriptions of entities and their interrelations, are often generated using rules that apply semantic annotations to certain data sources. (Re)using ontology terms without adhering to the axioms defined by their ontologies results in inconsistencies in these graphs, affecting their quality. Methods and tools were proposed to detect and resolve inconsistencies, the root causes of which include rules and ontologies. However, these either require access to the complete knowledge graph, which is not always available in a time-constrained situation, or assume that only generation rules can be refined but not ontologies. In the past, we proposed a rule-driven method for detecting and resolving inconsistencies without complete knowledge graph access, but it requires a predefined set of refinements to the rules and does not guide users with respect to the order the rules should be inspected. We extend our previous work with a rule-driven method, called Resglass, that considers refinements for generation rules as well as ontologies. In this article, we describe Resglass, which includes a ranking to determine the order with which rules and ontology elements should be inspected, and its implementation. The ranking is evaluated by comparing the manual ranking of experts to our automatic ranking. The evaluation shows that our automatic ranking achieves an overlap of 80% with experts ranking, reducing this way the effort required during the resolution of inconsistencies in both rules and ontologies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        }
    ]
}