{
    "authorId": "2294672261",
    "papers": [
        {
            "paperId": "2bc0e1b782ec7ff56bcd0d117e553f411c7940b0",
            "title": "Prompt Tuning as User Inherent Profile Inference Machine",
            "abstract": "Large Language Models (LLMs) have exhibited significant promise in recommender systems by empowering user profiles with their extensive world knowledge and superior reasoning capabilities. However, LLMs face challenges like unstable instruction compliance, modality gaps, and high inference latency, leading to textual noise and limiting their effectiveness in recommender systems. To address these challenges, we propose UserIP-Tuning, which uses prompt-tuning to infer user profiles. It integrates the causal relationship between user profiles and behavior sequences into LLMs' prompts. And employs expectation maximization to infer the embedded latent profile, minimizing textual noise by fixing the prompt template. Furthermore, A profile quantization codebook bridges the modality gap by categorizing profile embeddings into collaborative IDs, which are pre-stored for online deployment. This improves time efficiency and reduces memory usage. Experiments on four public datasets show that UserIP-Tuning outperforms state-of-the-art recommendation algorithms. Additional tests and case studies confirm its effectiveness, robustness, and transferability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256815726",
                    "name": "Yusheng Lu"
                },
                {
                    "authorId": "2294672261",
                    "name": "Zhaocheng Du"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2309213607",
                    "name": "Yongrui Duan"
                }
            ]
        },
        {
            "paperId": "3be0aae63b6429680d5c28b794be63149b4b4e39",
            "title": "Retrievable Domain-Sensitive Feature Memory for Multi-Domain Recommendation",
            "abstract": "With the increase in the business scale and number of domains in online advertising, multi-domain ad recommendation has become a mainstream solution in the industry. The core of multi-domain recommendation is effectively modeling the commonalities and distinctions among domains. Existing works are dedicated to designing model architectures for implicit multi-domain modeling while overlooking an in-depth investigation from a more fundamental perspective of feature distributions. This paper focuses on features with significant differences across various domains in both distributions and effects on model predictions. We refer to these features as domain-sensitive features, which serve as carriers of domain distinctions and are crucial for multi-domain modeling. Experiments demonstrate that existing multi-domain modeling methods may neglect domain-sensitive features, indicating insufficient learning of domain distinctions. To avoid this neglect, we propose a domain-sensitive feature attribution method to identify features that best reflect domain distinctions from the feature set. Further, we design a memory architecture that extracts domain-specific information from domain-sensitive features for the model to retrieve and integrate, thereby enhancing the awareness of domain distinctions. Extensive offline and online experiments demonstrate the superiority of our method in capturing domain distinctions and improving multi-domain recommendation performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287812381",
                    "name": "Yuang Zhao"
                },
                {
                    "authorId": "2294672261",
                    "name": "Zhaocheng Du"
                },
                {
                    "authorId": "3789712",
                    "name": "Qinglin Jia"
                },
                {
                    "authorId": "2287839449",
                    "name": "Linxuan Zhang"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "3f46e66675a89f35d3991a85ff0556c1533de4d2",
            "title": "Multimodal Pretraining, Adaptation, and Generation for Recommendation: A Survey",
            "abstract": "Personalized recommendation serves as a ubiquitous channel for users to discover information tailored to their interests. However, traditional recommendation models primarily rely on unique IDs and categorical features for user-item matching, potentially overlooking the nuanced essence of raw item contents across multiple modalities such as text, image, audio, and video. This underutilization of multimodal data poses a limitation to recommender systems, especially in multimedia services like news, music, and short-video platforms. The recent advancements in large multimodal models offer new opportunities and challenges in developing content-aware recommender systems. This survey seeks to provide a comprehensive exploration of the latest advancements and future trajectories in multimodal pretraining, adaptation, and generation techniques, as well as their applications in enhancing recommender systems. Furthermore, we discuss current open challenges and opportunities for future research in this dynamic domain. We believe that this survey, alongside the curated resources, will provide valuable insights to inspire further advancements in this evolving landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2240695630",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2223871084",
                    "name": "Yanting Yang"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "2294672261",
                    "name": "Zhaocheng Du"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                },
                {
                    "authorId": "2265936086",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2163112250",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                }
            ]
        },
        {
            "paperId": "8a56019401b55c76fac5232193fcce3f2f1af702",
            "title": "LightCS: Selecting Quadratic Feature Crosses in Linear Complexity",
            "abstract": "Feature crosses, which represent joint features synthesized by two single features, are critical for deep recommender systems to model sophisticated feature relations. In practice, only a tiny fraction of feature crosses among massive possible ones are informative, while introducing irrelevant or noisy ones may increase online service latency and boost the risk of overfitting. Therefore, picking high-quality feature crosses is essential in practical recommender systems. However, even for selecting quadratic feature crosses, existing algorithms still incur either o(n2) time complexity or o(n2) space complexity, which is inefficient and unscalable in industrial scenarios. In this paper, we present an efficient and accurate quadratic feature cross selection method with both linear time and space complexity. Motivated by the idea of Quasi-Newton methods, we propose to use 2nd-order derivative matrix to evaluate all theoretically possible feature crosses concurrently without the need of constructing them explicitly, where an approximation of 2nd-order gradient is applied to guarantee both low time and space complexity. Furthermore, we decouple the feature crosses' novelty from single features' joint importance. Experiments on two public recommendation datasets and a private dataset validate the efficiency and effectiveness of our method, and it has also become a fundamental feature cross selection tool used by Huawei Ads Platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294672261",
                    "name": "Zhaocheng Du"
                },
                {
                    "authorId": "2301263203",
                    "name": "Junhao Chen"
                },
                {
                    "authorId": "3789712",
                    "name": "Qinglin Jia"
                },
                {
                    "authorId": "2287881587",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2265944252",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                }
            ]
        }
    ]
}