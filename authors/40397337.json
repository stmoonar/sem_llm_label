{
    "authorId": "40397337",
    "papers": [
        {
            "paperId": "046169fb5985d72715de0faf3a02e14835afe935",
            "title": "Next day fire prediction via semantic segmentation",
            "abstract": "In this paper we present a deep learning pipeline for next day fire prediction. The next day fire prediction task consists in learning models that receive as input the available information for an area up until a certain day, in order to predict the occurrence of fire for the next day. Starting from our previous problem formulation as a binary classification task on instances (daily snapshots of each area) represented by tabular feature vectors, we reformulate the problem as a semantic segmentation task on images; there, each pixel corresponds to a daily snapshot of an area, while its channels represent the formerly tabular training features. We demonstrate that this problem formulation, built within a thorough pipeline achieves state of the art results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403615877",
                    "name": "Konstantinos Alexis"
                },
                {
                    "authorId": "2047343491",
                    "name": "Stella Girtsou"
                },
                {
                    "authorId": "1996099507",
                    "name": "A. Apostolakis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "40326071",
                    "name": "C. Kontoes"
                }
            ]
        },
        {
            "paperId": "25bc9944aba4a047e7dfea7e5ceb1708d541b87e",
            "title": "Fairness in AI: challenges in bridging the gap between algorithms and law",
            "abstract": "In this paper we examine algorithmic fairness from the perspective of law aiming to identify best practices and strategies for the specification and adoption of fairness definitions and algorithms in real-world systems and use cases. We start by providing a brief introduction of current anti-discrimination law in the European Union and the United States and discussing the concepts of bias and fairness from an legal and ethical viewpoint. We then proceed by presenting a set of algorithmic fairness definitions by example, aiming to communicate their objectives to non-technical audiences. Then, we introduce a set of core criteria that need to be taken into account when selecting a specific fairness definition for real-world use case applications. Finally, we enumerate a set of key considerations and best practices for the design and employment of fairness methods on real-world AI applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2298966484",
                    "name": "Maria Psalla"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2298966095",
                    "name": "Jakub Marecek"
                },
                {
                    "authorId": "2298966283",
                    "name": "German M Matilla"
                },
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                }
            ]
        },
        {
            "paperId": "2677147bcb5264b6b9c45a049562f98200750cfa",
            "title": "Dynamic Sizing of Cloud-Native Telco Data Centers With Digital Twin and Reinforcement Learning",
            "abstract": "Telco edge data centers (DCs) accommodate applications whose load fluctuates considerably during a day. This variability mandates swift and responsive resource adjustments to mitigate the risk of incurring unnecessary costs during off-peak periods, where a significant fraction of nodes may be under-utilized. Tackling this challenge is integral to optimizing operational efficiency and cost-effectiveness of telco edge DCs. To this end, this article aims to address the Dynamic Data Center Sizing (DDS) problem, which boils down to optimizing the number of active nodes as per current resource demand. The proposed DDS solution consists of two core modules, namely a forecasting module, which predicts resource demands, and a decision-making module, which acts upon predicted demands. The decision-making of DDS is implemented via the filtering and the rank-drain-observe (RDO) algorithms. Filtering is based on integer linear programming, and it computes the theoretically optimal state of the DC based on predicted resource demands. RDO is a heuristic that strives to realize the optimal DC state in an iterative and robust fashion. To expedite RDO in large-scale clusters, we further devise a Reinforcement Learning (RL)-enabled DDS variant (i.e., RL-DDS), in which RDO integrates an RL agent that computes optimized batches of nodes for concurrent deactivation. We propose an innovative solution based on the notion of Digital Twin to train the RL agent in emulation mode. DDS and RL-DDS are evaluated upon real-life testbeds resembling actual DCs. Results demonstrate significant cost reduction, ranging from 7% in conservative and relatively static scenarios, up to 38% in highly dynamic settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1622269503",
                    "name": "Angelos Pentelas"
                },
                {
                    "authorId": "2280399546",
                    "name": "Dimitris Katsiros"
                },
                {
                    "authorId": "2280407203",
                    "name": "Dimitra Paranou"
                },
                {
                    "authorId": "2307759608",
                    "name": "George Doukas"
                },
                {
                    "authorId": "2307759613",
                    "name": "Konstantinos Chondralis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2338145",
                    "name": "E. Angelou"
                },
                {
                    "authorId": "2325154",
                    "name": "George Papastefanatos"
                }
            ]
        },
        {
            "paperId": "4de94c928ad1d7c5b481178dd4f31c3a7570be49",
            "title": "FALE: Fairness-Aware ALE Plots for Auditing Bias in Subgroups",
            "abstract": "Fairness is steadily becoming a crucial requirement of Machine Learning (ML) systems. A particularly important notion is subgroup fairness, i.e., fairness in subgroups of individuals that are defined by more than one attributes. Identifying bias in subgroups can become both computationally challenging, as well as problematic with respect to comprehensibility and intuitiveness of the finding to end users. In this work we focus on the latter aspects; we propose an explainability method tailored to identifying potential bias in subgroups and visualizing the findings in a user friendly manner to end users. In particular, we extend the ALE plots explainability method, proposing FALE (Fairness aware Accumulated Local Effects) plots, a method for measuring the change in fairness for an affected population corresponding to different values of a feature (attribute). We envision FALE to function as an efficient, user friendly, comprehensible and reliable first-stage tool for identifying subgroups with potential bias issues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2298899402",
                    "name": "Nikolas Theologitis"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                }
            ]
        },
        {
            "paperId": "7442bc53a1bb7916b33b7ea3323084b836ed04b7",
            "title": "GLANCE: Global Actions in a Nutshell for Counterfactual Explainability",
            "abstract": "Counterfactual explanations have emerged as an important tool to understand, debug, and audit complex machine learning models. To offer global counterfactual explainability, state-of-the-art methods construct summaries of local explanations, offering a trade-off among conciseness, counterfactual effectiveness, and counterfactual cost or burden imposed on instances. In this work, we provide a concise formulation of the problem of identifying global counterfactuals and establish principled criteria for comparing solutions, drawing inspiration from Pareto dominance. We introduce innovative algorithms designed to address the challenge of finding global counterfactuals for either the entire input space or specific partitions, employing clustering and decision trees as key components. Additionally, we conduct a comprehensive experimental evaluation, considering various instances of the problem and comparing our proposed algorithms with state-of-the-art methods. The results highlight the consistent capability of our algorithms to generate meaningful and interpretable global counterfactual explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                },
                {
                    "authorId": "2273195757",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2303655763",
                    "name": "Dimitrios Gunopulos"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2297771041",
                    "name": "Kleopatra Markou"
                },
                {
                    "authorId": "2139143386",
                    "name": "Eleni Psaroudaki"
                },
                {
                    "authorId": "150081157",
                    "name": "D. Rontogiannis"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2220631614",
                    "name": "Nikolaos Theologitis"
                },
                {
                    "authorId": "2082489302",
                    "name": "Dimitrios Tomaras"
                },
                {
                    "authorId": "2220631616",
                    "name": "Konstantinos Tsopelas"
                }
            ]
        },
        {
            "paperId": "cd38fee386d9eb19967d3bbd56ec4927f0af0e15",
            "title": "Enhancing Daily Wildfire Risk Prediction Application Through Interpretable Machine Learning Results",
            "abstract": "Over the last decade, the use of Machine/Deep learning algorithms and methodologies has found widespread application across various domains in wildfire science, with fire occurrence risk prediction being one of the extensively covered areas. Many algorithms and architectures have been explored to solve the problem as a binary classification task focusing mainly on the model\u2019s classification performance through the standard classification metrics. However, in the context of an application for predicting the fire occurrence risk we have to enhance the trust in the model\u2019s output by deriving a well defined fire susceptibility index, as well as interpretable insights for the model\u2019s predictions when applied to real-world datasets. In this manuscript we propose model agnostic solutions towards (a) the production of a probability-based binning of the model\u2019s prediction distribution for generating a scalar wildfire occurrence risk and (b) of a representative sampling for producing local prediction explanations spanning the whole dataset, to tackle the slow processing times of explainable AI frameworks, when generating vast amounts of local interpretations. The objective is to contribute the development of a reliable application predicting next day\u2019s fire risk, facilitating the adoption of ML-based solutions by users who are not experts in data science.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1996099507",
                    "name": "A. Apostolakis"
                },
                {
                    "authorId": "2047343491",
                    "name": "Stella Girtsou"
                },
                {
                    "authorId": "1403615877",
                    "name": "Konstantinos Alexis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2867796",
                    "name": "Nikolaos S. Bartsotas"
                },
                {
                    "authorId": "40326071",
                    "name": "C. Kontoes"
                }
            ]
        },
        {
            "paperId": "1816321e0aa3c60cd72b7274fa18b0d53917c2ac",
            "title": "Data-Driven Soiling Detection in PV Modules",
            "abstract": "Soiling is the accumulation of dirt in solar panels that leads to a decreasing trend in solar energy yield and may be the cause of vast revenue losses. The effect of soiling can be reduced by washing the panels, which is, however, a procedure of non-negligible cost. Moreover, soiling monitoring systems are often unreliable or very costly. We study the problem of estimating the soiling ratio in photovoltaic (PV) modules, i.e., the ratio of the real power output to the power output that would be produced if solar panels were clean. A key advantage of our algorithms is that they estimate soiling, without needing to train on labeled data, i.e., periods of explicitly monitoring the soiling in each park, and without relying on generic analytical formulas that do not take into account the peculiarities of each installation. We consider as input a time series comprising a minimum set of measurements that are available to most PV park operators. Our experimental evaluation shows that we significantly outperform current state-of-the-art methods for estimating soiling ratio.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203072159",
                    "name": "Alexandros Kalimeris"
                },
                {
                    "authorId": "3125418",
                    "name": "I. Psarros"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2454554",
                    "name": "Manolis Terrovitis"
                },
                {
                    "authorId": "2325154",
                    "name": "George Papastefanatos"
                },
                {
                    "authorId": "2203371599",
                    "name": "Gregory Kotsis"
                }
            ]
        },
        {
            "paperId": "4b531e2e65ae2f8e989342fbe8e41d2822584be8",
            "title": "Fairness Aware Counterfactuals for Subgroups",
            "abstract": "In this work, we present Fairness Aware Counterfactuals for Subgroups (FACTS), a framework for auditing subgroup fairness through counterfactual explanations. We start with revisiting (and generalizing) existing notions and introducing new, more refined notions of subgroup fairness. We aim to (a) formulate different aspects of the difficulty of individuals in certain subgroups to achieve recourse, i.e. receive the desired outcome, either at the micro level, considering members of the subgroup individually, or at the macro level, considering the subgroup as a whole, and (b) introduce notions of subgroup fairness that are robust, if not totally oblivious, to the cost of achieving recourse. We accompany these notions with an efficient, model-agnostic, highly parameterizable, and explainable framework for evaluating subgroup fairness. We demonstrate the advantages, the wide applicability, and the efficiency of our approach through a thorough experimental evaluation of different benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2220631616",
                    "name": "Konstantinos Tsopelas"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2139143386",
                    "name": "Eleni Psaroudaki"
                },
                {
                    "authorId": "2220631614",
                    "name": "Nikolaos Theologitis"
                },
                {
                    "authorId": "150081157",
                    "name": "D. Rontogiannis"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1804042",
                    "name": "I. Emiris"
                }
            ]
        },
        {
            "paperId": "4e4eb9408d9b93d542373c560151e97212c700e5",
            "title": "Auditing for Spatial Fairness",
            "abstract": "This paper studies algorithmic fairness when the protected attribute is location. To handle protected attributes that are continuous, such as age or income, the standard approach is to discretize the domain into predefined groups, and compare algorithmic outcomes across groups. However, applying this idea to location raises concerns of gerrymandering and may introduce statistical bias. Prior work addresses these concerns but only for regularly spaced locations, while raising other issues, most notably its inability to discern regions that are likely to exhibit spatial unfairness. Similar to established notions of algorithmic fairness, we define spatial fairness as the statistical independence of outcomes from location. This translates into requiring that for each region of space, the distribution of outcomes is identical inside and outside the region. To allow for localized discrepancies in the distribution of outcomes, we compare how well two competing hypotheses explain the observed outcomes. The null hypothesis assumes spatial fairness, while the alternate allows different distributions inside and outside regions. Their goodness of fit is then assessed by a likelihood ratio test. If there is no significant difference in how well the two hypotheses explain the observed outcomes, we conclude that the algorithm is spatially fair.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2325154",
                    "name": "George Papastefanatos"
                },
                {
                    "authorId": "12619004",
                    "name": "Kostas Stefanidis"
                }
            ]
        },
        {
            "paperId": "9de985d295469cab848281ef27ce9df132772834",
            "title": "A Tool for Visual Exploration and Analysis of Solar Photovoltaic Module Data",
            "abstract": "Solar photovoltaic (PV) modules are a popular source of clean energy, and effective monitoring and optimization of their performance requires the ability to explore and analyze the measurement data from their sensors. In this work, we introduce a tool for the visual analysis of such data stored in raw measurement files, offering efficient interactive visualization directly on the files. The tool includes a soiling detection module, and novel UI modules that combine time series data visualization with advanced solar panel analytics presentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152230593",
                    "name": "Vassilis Stamatopoulos"
                },
                {
                    "authorId": "51133690",
                    "name": "Stavros Maroulis"
                },
                {
                    "authorId": "2216570754",
                    "name": "Konstantinos Kozanis"
                },
                {
                    "authorId": "3125418",
                    "name": "I. Psarros"
                },
                {
                    "authorId": "2325154",
                    "name": "George Papastefanatos"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2454554",
                    "name": "Manolis Terrovitis"
                }
            ]
        }
    ]
}