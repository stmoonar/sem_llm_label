{
    "authorId": "2115569383",
    "papers": [
        {
            "paperId": "286f6a75d6f2e9654b4d9f04bcceb4616bdbad8c",
            "title": "No more optimization rules: LLM-enabled policy-based multi-modal query optimizer",
            "abstract": "Large language model (LLM) has marked a pivotal moment in the field of machine learning and deep learning. Recently its capability for query planning has been investigated, including both single-modal and multi-modal queries. However, there is no work on the query optimization capability of LLM. As a critical (or could even be the most important) step that significantly impacts the execution performance of the query plan, such analysis and attempts should not be missed. From another aspect, existing query optimizers are usually rule-based or rule-based + cost-based, i.e., they are dependent on manually created rules to complete the query plan rewrite/transformation. Given the fact that modern optimizers include hundreds to thousands of rules, designing a multi-modal query optimizer following a similar way is significantly time-consuming since we will have to enumerate as many multi-modal optimization rules as possible, which has not been well addressed today. In this paper, we investigate the query optimization ability of LLM and use LLM to design LaPuda, a novel LLM and Policy based multi-modal query optimizer. Instead of enumerating specific and detailed rules, LaPuda only needs a few abstract policies to guide LLM in the optimization, by which much time and human effort are saved. Furthermore, to prevent LLM from making mistakes or negative optimization, we borrow the idea of gradient descent and propose a guided cost descent (GCD) algorithm to perform the optimization, such that the optimization can be kept in the correct direction. In our evaluation, our methods consistently outperform the baselines in most cases. For example, the optimized plans generated by our methods result in 1~3x higher execution speed than those by the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115569383",
                    "name": "Yifan Wang"
                },
                {
                    "authorId": "2110816708",
                    "name": "Haodi Ma"
                },
                {
                    "authorId": "2284919843",
                    "name": "Daisy Zhe Wang"
                }
            ]
        },
        {
            "paperId": "7877957e58be6dfd33f678e73beac7cb1995961c",
            "title": "Xling: A Learned Filter Framework for Accelerating High-Dimensional Approximate Similarity Join",
            "abstract": "Similarity join finds all pairs of close points within a given distance threshold. Many similarity join methods have been proposed, but they are usually not efficient on high-dimensional space due to the curse of dimensionality and data-unawareness. We investigate the possibility of using metric space Bloom filter (MSBF), a family of data structures checking if a query point has neighbors in a multi-dimensional space, to speed up similarity join. However, there are several challenges when applying MSBF to similarity join, including excessive information loss, data-unawareness and hard constraint on the distance metric. In this paper, we propose Xling, a generic framework to build a learning-based metric space filter with any existing regression model, aiming at accurately predicting whether a query point has enough number of neighbors. The framework provides a suite of optimization strategies to further improve the prediction quality based on the learning model, which has demonstrated significantly higher prediction quality than existing MSBF. We also propose XJoin, one of the first filter-based similarity join methods, based on Xling. By predicting and skipping those queries without enough neighbors, XJoin can effectively reduce unnecessary neighbor searching and therefore it achieves a remarkable acceleration. Benefiting from the generalization capability of deep learning models, XJoin can be easily transferred onto new dataset (in similar distribution) without re-training. Furthermore, Xling is not limited to being applied in XJoin, instead, it acts as a flexible plugin that can be inserted to any loop-based similarity join methods for a speedup.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115569383",
                    "name": "Yifan Wang"
                },
                {
                    "authorId": "2284869276",
                    "name": "Vyom Pathak"
                },
                {
                    "authorId": "2284919843",
                    "name": "Daisy Zhe Wang"
                }
            ]
        },
        {
            "paperId": "18a9128844d99f2fd68d74cbde191cf8f089ff4d",
            "title": "Learned Accelerator Framework for Angular-Distance-Based High-Dimensional DBSCAN",
            "abstract": "Density-based clustering is a commonly used tool in data science. Today many data science works are utilizing high-dimensional neural embeddings. However, traditional density-based clustering techniques like DBSCAN have a degraded performance on high-dimensional data. In this paper, we propose LAF, a generic learned accelerator framework to speed up the original DBSCAN and the sampling-based variants of DBSCAN on high-dimensional data with angular distance metric. This framework consists of a learned cardinality estimator and a post-processing module. The cardinality estimator can fast predict whether a data point is core or not to skip unnecessary range queries, while the post-processing module detects the false negative predictions and merges the falsely separated clusters. The evaluation shows our LAF-enhanced DBSCAN method outperforms the state-of-the-art efficient DBSCAN variants on both efficiency and quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115569383",
                    "name": "Yifan Wang"
                },
                {
                    "authorId": "2111220343",
                    "name": "D. Wang"
                }
            ]
        },
        {
            "paperId": "5acfe1c57d2638a5589227740f5eecfa0dfccbfb",
            "title": "Extensible Database Simulator for Fast Prototyping In-Database Algorithms",
            "abstract": "With the rapid increasing of data scale, in-database analytics and learning has become one of the most studied topics in data science community, because of its significance on reducing the gap between the management and the analytics of data. By extending the capability of database on analytics and learning, data scientists can save much time on exchanging data between databases and external analytic tools. For this goal, researchers are attempting to integrate more data science algorithms into database. However, implementing the algorithms in mainstream databases is super time-consuming, since the developers often have to make a deep dive into the database kernels. Thus there are demands for an easy-to-extend database simulator to help fast prototype and verify the in-database algorithms before implementing them in real databases. In this demo, we present such an extensible relational database simulator, DBSim, to help data scientists prototype their in-database analytics and learning algorithms and verify the effectiveness of their ideas with minimal cost. DBSim simulates a real relational database with all the major components of the mainstream RDBMS, including SQL parser, relational operators, query optimizer, etc. In addition, DBSim provides various interfaces for users to flexibly plug their custom extension modules into any of the major components, without modifying the kernel. By those interfaces, DBSim supports easy extensions on SQL syntax, relational operators, query optimizer rules and cost models, and physical plan execution. To enable accurate evaluation on users' extensions, DBSim supports connecting to real RDBMS and using their real-world cost estimators to calculate the query plan cost. Furthermore, DBSim provides utilities to facilitate users' developing and debugging, like query plan visualizer and interactive analyzer on optimization rules. We develop DBSim using pure Python to support seamless implementation of most data science algorithms into it, since many of them are written in Python.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115569383",
                    "name": "Yifan Wang"
                },
                {
                    "authorId": "2111220343",
                    "name": "D. Wang"
                }
            ]
        },
        {
            "paperId": "cc17571a5ae906cd473ace3abe9f4cb01b543bc5",
            "title": "GAIA at SM-KBP 2019 - A Multi-media Multi-lingual Knowledge Extraction and Hypothesis Generation System",
            "abstract": "Extraction and Hypothesis Generation System Manling Li, Ying Lin, Ananya Subburathinam, Spencer Whitehead, Xiaoman Pan, Di Lu, Qingyun Wang, Tongtao Zhang, Lifu Huang, Heng Ji 1 University of Illinois at Urbana-Champaign hengji@illinois.edu Alireza Zareian, Hassan Akbari, Brian Chen, Bo Wu, Emily Allaway, Shih-Fu Chang, Kathleen McKeown 2 Columbia University sc250@columbia.edu, kathy@cs.columbia.edu Yixiang Yao, Jennifer Chen, Eric Berquist, Kexuan Sun, Xujun Peng, Ryan Gabbard Marjorie Freedman, Pedro Szekely, T.K. Satish Kumar 3 Information Sciences Institute, University of Southern California mrf@isi.edu Arka Sadhu, Ram Nevatia University of Southern California nevatia@usc.edu Miguel Rodriguez5, Yifan Wang5, Yang Bai5, Ali Sadeghian4, Daisy Zhe Wang5 5 University of Florida daisyw@ufl.edu",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3361240",
                    "name": "Manling Li"
                },
                {
                    "authorId": "49417338",
                    "name": "Ying Lin"
                },
                {
                    "authorId": "3393606",
                    "name": "Ananya Subburathinam"
                },
                {
                    "authorId": "153188991",
                    "name": "Spencer Whitehead"
                },
                {
                    "authorId": "34741133",
                    "name": "Xiaoman Pan"
                },
                {
                    "authorId": "152347526",
                    "name": "Di Lu"
                },
                {
                    "authorId": "1786863",
                    "name": "Qingyun Wang"
                },
                {
                    "authorId": "2111626",
                    "name": "Tongtao Zhang"
                },
                {
                    "authorId": "34170717",
                    "name": "Lifu Huang"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2778637",
                    "name": "Alireza Zareian"
                },
                {
                    "authorId": "153769937",
                    "name": "Hassan Akbari"
                },
                {
                    "authorId": "2108342501",
                    "name": "Brian Chen"
                },
                {
                    "authorId": "1993581583",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "9546964",
                    "name": "Shih-Fu Chang"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                },
                {
                    "authorId": "27039165",
                    "name": "Yixiang Yao"
                },
                {
                    "authorId": "2115897093",
                    "name": "Jennifer Chen"
                },
                {
                    "authorId": "14993211",
                    "name": "E. Berquist"
                },
                {
                    "authorId": "35329068",
                    "name": "Kexuan Sun"
                },
                {
                    "authorId": "2109627387",
                    "name": "Xujun Peng"
                },
                {
                    "authorId": "50543673",
                    "name": "Ryan Gabbard"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "2628881",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "2066758459",
                    "name": "T. K. S. Kumar"
                },
                {
                    "authorId": "2064142411",
                    "name": "Arka Sadhu"
                },
                {
                    "authorId": "1694832",
                    "name": "R. Nevatia"
                },
                {
                    "authorId": "144078631",
                    "name": "Miguel E. Rodr\u00edguez"
                },
                {
                    "authorId": "2115569383",
                    "name": "Yifan Wang"
                },
                {
                    "authorId": "1471403524",
                    "name": "Yang Bai"
                },
                {
                    "authorId": "51283807",
                    "name": "A. Sadeghian"
                },
                {
                    "authorId": "2111220343",
                    "name": "D. Wang"
                }
            ]
        }
    ]
}