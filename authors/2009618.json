{
    "authorId": "2009618",
    "papers": [
        {
            "paperId": "2bfe15579f23dc494fc22df62807a637ea508523",
            "title": "Explainable AI for Intelligence Augmentation in Multi-Domain Operations",
            "abstract": "Central to the concept of multi-domain operations (MDO) is the utilization of an intelligence, surveillance, and reconnaissance (ISR) network consisting of overlapping systems of remote and autonomous sensors, and human intelligence, distributed among multiple partners. Realising this concept requires advancement in both artificial intelligence (AI) for improved distributed data analytics and intelligence augmentation (IA) for improved human-machine cognition. The contribution of this paper is threefold: (1) we map the coalition situational understanding (CSU) concept to MDO ISR requirements, paying particular attention to the need for assured and explainable AI to allow robust human-machine decision-making where assets are distributed among multiple partners; (2) we present illustrative vignettes for AI and IA in MDO ISR, including human-machine teaming, dense urban terrain analysis, and enhanced asset interoperability; (3) we appraise the state-of-the-art in explainable AI in relation to the vignettes with a focus on human-machine collaboration to achieve more rapid and agile coalition decision-making. The union of these three elements is intended to show the potential value of a CSU approach in the context of MDO ISR, grounded in three distinct use cases, highlighting how the need for explainability in the multi-partner coalition setting is key.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1762890",
                    "name": "A. Preece"
                },
                {
                    "authorId": "2215679",
                    "name": "Dave Braines"
                },
                {
                    "authorId": "133946249",
                    "name": "Federico Cerutti"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                }
            ]
        },
        {
            "paperId": "00807383e5a3082cf46ee8bb7d9a27fd1ee1066f",
            "title": "Generation and management of training data for AI-based algorithms targeted at coalition operations",
            "abstract": "AI (Artificial Intelligence)-based algorithms have great potential for inter-operation of coalition ISR (intelligence, surveillance, and reconnaissance) systems, but rely on realistic data for training and validation. Getting such data for coalition scenarios is hampered by military regulations and is a significant hurdle in conducting basic research. We discuss an approach whereby training data can be obtained by means of scenario-driven simulations, which result in traces for network devices, ISR sensors and other infrastructure components. This generated data can be used for both training and comparison of different AI based algorithms. Coupling the synthetic data generator with a data curation system further increases its applicability.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37742375",
                    "name": "D. Verma"
                },
                {
                    "authorId": "2559379",
                    "name": "G. Cirincione"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "2082399427",
                    "name": "B. J. Ko"
                }
            ]
        },
        {
            "paperId": "a0700bd710778f895cd9a139a7750efdae8609f3",
            "title": "Learning Service Semantics for Self-Organization in Distributed Environments: Concepts and Research Directions",
            "abstract": "A key challenge in performing analytics in distributed environments is to automatically compose services to dynamically match operational tasks to information requirements, accounting for impact, in a many-to-many temporally and spatially complicated and complex situations. In dynamic and agile environments, such as coalition environments, the state of the network and resources cannot be completely known in advance nor controlled due to the evolving nature of the network and constraints that may preclude partners from accessing complete state information about different parts of the system. In addition, there may be requests made to the system that have not been made before, requiring services to be created on the fly. Motivated by these observations, in this paper, we present a critical analysis of gaps in the state-of-the-art and our vision to address those through novel theoretical contributions. We envision that such formalized and theorized fundamentals will enable service elements to automatically configure themselves to perform analytic tasks based on user specified goals by taking account of context-be it system or user context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2390825",
                    "name": "Graham A. Bent"
                },
                {
                    "authorId": "144812207",
                    "name": "Geeth de Mel"
                },
                {
                    "authorId": "143642366",
                    "name": "R. Ganti"
                },
                {
                    "authorId": "145063891",
                    "name": "T. L. Porta"
                },
                {
                    "authorId": "2149160",
                    "name": "G. Pearson"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "145892975",
                    "name": "S. Stein"
                },
                {
                    "authorId": "1705536",
                    "name": "L. Tassiulas"
                },
                {
                    "authorId": "31971406",
                    "name": "I. Taylor"
                }
            ]
        },
        {
            "paperId": "b6d8b5eba69f440a3f6bef42325da41161a05ef5",
            "title": "StoryLine: Unsupervised Geo-event Demultiplexing in Social Spaces without Location Information",
            "abstract": "Some of the most widely deployed IoT devices in urban areas are smartphones in the possession of urban individuals. Their proliferation has led to the emergence of crowdsensing/crowdsourcing services, where humans collect data about their environment (using phones), and servers aggregate the data for various application purposes of interest. With the emergence of social media, a common alternative form of human data entry has become media posts (e.g., on Twitter). This leads to the prospect of building crowdsensing services on top of social media content, exploiting humans as ``sensors\". In this paper, we develop one such service, called {\\em StoryLine}. The service detects and tracks physical urban events of interest to the user, such as car accidents, infrastructure damage (in the aftermath of a natural disaster), or instances of civil unrest. It offers an interface to client-side software that allows browsing such events in real time, as well as an interface for software applications to a structured representation of the events and their related statistics. The service embodies novel algorithms for real-time detection, demultiplexing, and tracking of physical events using social media data. In our evaluation with Twitter feeds, we show that our service outperforms two state-of-the-art baselines in event detection and demultiplexing. We also conduct two case-studies to show the effectiveness of the real-time event detection capability and event tracking performance of our system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2019481",
                    "name": "Shiguang Wang"
                },
                {
                    "authorId": "2852809",
                    "name": "P. Giridhar"
                },
                {
                    "authorId": "2108986527",
                    "name": "Hongwei Wang"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "1688603",
                    "name": "A. Yener"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "ee966b0778cafb068fb36214491ff4f9c148cadd",
            "title": "Instinctive analytics for coalition operations (Conference Presentation)",
            "abstract": "The success of future military coalition operations\u2014be they combat or humanitarian\u2014will increasingly depend on a system\u2019s ability to share data and processing services (e.g. aggregation, summarization, fusion), and automatically compose services in support of complex tasks at the network edge. We call such an infrastructure instinctive\u2014i.e., an infrastructure that reacts instinctively to address the analytics task at hand. However, developing such an infrastructure is made complex for the coalition environment due to its dynamism both in terms of user requirements and service availability. In order to address the above challenge, in this paper, we highlight our research vision and sketch some initial solutions into the problem domain. Specifically, we propose means to (1) automatically infer formal task requirements from mission specifications; (2) discover data, services, and their features automatically to satisfy the identified requirements; (3) create and augment shared domain models automatically; (4) efficiently offload services to the network edge and across coalition boundaries adhering to their computational properties and costs; and (5) optimally allocate and adjust services while respecting the constraints of operating environment and service fit. We envision that the research will result in a framework which enables self-description, discover, and assemble capabilities to both data and services in support of coalition mission goals.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "144812207",
                    "name": "Geeth de Mel"
                },
                {
                    "authorId": "102366048",
                    "name": "T. L. La Porta"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "2149160",
                    "name": "G. Pearson"
                }
            ]
        },
        {
            "paperId": "071c834bbcfb2f3c5d4d3e76f868445c55d20232",
            "title": "Adaptive multimodal fusion with web resources for scene classification",
            "abstract": "To train a scene classifier with good generalization capability, a large number of human labeled training images are often needed. However, a large number of well-labeled training images may not always be available. To alleviate this problem, the web resources-aided scene classification framework was proposed. The present paper is a new development based on our previously proposed framework [1], with the following improvements. First, a text-based filtering algorithm is developed to remove irrelevant web search returns since irrelevant web search returns provide irrelevant or even wrong information about the class of an image. Second, an adaptive fusion algorithm is developed for the integration of visual feature-based and web textual feature-based classification results. This adaptive fusion algorithm is inspired by the multisensory integration mechanism of human whose adaptability is achieved by reliability-dependent weighting of different sensory modalities. Experimental results show that the proposed web textual resources aided image classification framework can improve classification accuracy of some classes by 13% and 12% in the UIUC-Sports and LabelMe8 datasets, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047932486",
                    "name": "Dongzhe Wang"
                },
                {
                    "authorId": "144067957",
                    "name": "K. Mao"
                },
                {
                    "authorId": "3027070",
                    "name": "G. Ng"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                }
            ]
        },
        {
            "paperId": "cd6324621578d304453f5b27a88f46358f9a76a2",
            "title": "Sensor assignment to mission in AI-TECD",
            "abstract": "Sensor-mission assignment involves the allocation of sensors and other information-providing resources to missions in order to cover the information needs of the individual tasks within each mission. The importance of efficient and effective means to find appropriate resources for tasks is exacerbated in the coalition context where the operational environment is dynamic and a multitude of critically important tasks need to achieve their collective goals to meet the objectives of the coalition. The Sensor Assignment to Mission (SAM) framework\u2014a research product of the International Technology Alliance in Network and Information Sciences (NIS-ITA) program\u2014provided the first knowledge intensive resource selection approach for the sensor network domain so that contextual information could be used to effectively select resources for tasks in coalition environments. Recently, CUBRC, Inc. was tasked with operationalizing the SAM framework through the use of the I2WD Common Core Ontologies for the Communications-Electronics Research, Development and Engineering Center (CERDEC) sponsored Actionable Intelligence Technology Enabled Capabilities Demonstration (AI-TECD). The demonstration event took place at Fort Dix, New Jersey during July 2015, and this paper discusses the integration and the successful demonstration of the SAM framework within the AI-TECD, lessons learned, and its potential impact in future operations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "40028619",
                    "name": "R. Ganger"
                },
                {
                    "authorId": "144812207",
                    "name": "Geeth de Mel"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "33112406",
                    "name": "Ron Rudnicki"
                },
                {
                    "authorId": "69396035",
                    "name": "Yonatan Schreiber"
                }
            ]
        },
        {
            "paperId": "db6ca19b07fcdd53d04afe4f6fbdbb2e51598991",
            "title": "ARL PED efforts at enterprise challenge 2016",
            "abstract": "In 2011, the U.S. Army Research Laboratory (ARL) developed a framework for sensor integration and asset discovery. Because this framework continues to be relevant and necessary, ARL will again participate in Enterprise Challenge 2016 to conduct further experimentation and demonstrations. Incorporating an Expeditionary Processing, Exploitation and Dissemination (Ex-PED) model, ARL will demonstrate the utility of tactical wide-area and persistent sensing in a bandwidth constrained environment, with the inclusion of an effective Sensor 3D Common Operating Picture (COP) to enable appropriate sensor management.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "153248830",
                    "name": "S. Toth"
                },
                {
                    "authorId": "2059556740",
                    "name": "W. Hughes"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "47361899",
                    "name": "J. Houser"
                }
            ]
        },
        {
            "paperId": "67b9113d0b3cff61cc90440dca92a4ab40afc96f",
            "title": "Advances in network sciences via collaborative multi-disciplinary research",
            "abstract": "Network Science is the scientific exploration of the shared fundamental properties underlying different types of networks and their interactions. Two large research alliances, the International Technology Alliance in Network Sciences and the Network Science Collaborative Technology Alliance, have brought together researchers from many diverse disciplines to create fundamental advances in network science. In this paper, we discuss some of the advances made by the scientists in these two research alliances, and some of the lessons learnt as fundamental scientific advances are translated to real networks via military and commercial transitions. Since both of the alliances themselves are complex networks, some of the lessons learnt from management of these networks are also discussed briefly in this paper.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37742375",
                    "name": "D. Verma"
                },
                {
                    "authorId": "2703947",
                    "name": "W. Leland"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "144231976",
                    "name": "A. Swami"
                },
                {
                    "authorId": "2559379",
                    "name": "G. Cirincione"
                }
            ]
        },
        {
            "paperId": "a1e582c16e9ac40fbf4c3003479f59dce747f6a8",
            "title": "Controlled and Uncontrolled English for Ontology Editing",
            "abstract": "Ontologies formally represent reality in a way that limits ambiguity and facilitates automated reasoning and data fusion, but is often daunting to the non-technical user. Thus, many researchers have endeavored to hide the formal syntax and semantics of ontologies behind the constructs of Controlled Natural Languages (CNLs), which retain the formal properties of ontologies while simultaneously presenting that information in a comprehensible natural language format. In this paper, we build upon previous work in this field by evaluating prospects of implementing International Technology Alliance Controlled English (ITACE) as a middleware for ontology editing. We also discuss at length a prototype of a natural language conversational interface application designed to facilitate ontology editing via the formulation of CNL constructs. Keywords\u2014Ontology; Controlled English; Intelligence Collection",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "97971926",
                    "name": "Brian Donohue"
                },
                {
                    "authorId": "2730441",
                    "name": "D. Kutach"
                },
                {
                    "authorId": "2078323115",
                    "name": "Amardeep Bhattal"
                },
                {
                    "authorId": "2215679",
                    "name": "Dave Braines"
                },
                {
                    "authorId": "144812207",
                    "name": "Geeth de Mel"
                },
                {
                    "authorId": "40028619",
                    "name": "R. Ganger"
                },
                {
                    "authorId": "2009618",
                    "name": "T. Pham"
                },
                {
                    "authorId": "33112406",
                    "name": "Ron Rudnicki"
                },
                {
                    "authorId": "40454901",
                    "name": "Barry Smith"
                }
            ]
        }
    ]
}