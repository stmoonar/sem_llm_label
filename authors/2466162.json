{
    "authorId": "2466162",
    "papers": [
        {
            "paperId": "07b3203c60110e9c7bdfcbf925612b53e349eb93",
            "title": "Continual Imitation Learning for Prosthetic Limbs",
            "abstract": "Lower limb amputations and neuromuscular impairments severely restrict mobility, necessitating advancements beyond conventional prosthetics. Motorized bionic limbs offer promise, but their utility depends on mimicking the evolving synergy of human movement in various settings. In this context, we present a novel model for bionic prostheses' application that leverages camera-based motion capture and wearable sensor data, to learn the synergistic coupling of the lower limbs during human locomotion, empowering it to infer the kinematic behavior of a missing lower limb across varied tasks, such as climbing inclines and stairs. We propose a model that can multitask, adapt continually, anticipate movements, and refine. The core of our method lies in an approach which we call -- multitask prospective rehearsal -- that anticipates and synthesizes future movements based on the previous prediction and employs a corrective mechanism for subsequent predictions. We design an evolving architecture that merges lightweight, task-specific modules on a shared backbone, ensuring both specificity and scalability. We empirically validate our model against various baselines using real-world human gait datasets, including experiments with transtibial amputees, which encompass a broad spectrum of locomotion tasks. The results show that our approach consistently outperforms baseline models, particularly under scenarios affected by distributional shifts, adversarial perturbations, and noise.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151440196",
                    "name": "S. Dey"
                },
                {
                    "authorId": "2288405766",
                    "name": "Benjamin Paassen"
                },
                {
                    "authorId": "2299327555",
                    "name": "Sarath Ravindran Nair"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2243439626",
                    "name": "Arndt F. Schilling"
                }
            ]
        },
        {
            "paperId": "10c9ca83829ecfdcaebd452a44191725e063f8b1",
            "title": "Improving Language Models Trained on Translated Data with Continual Pre-Training and Dictionary Learning Analysis",
            "abstract": "Training LLMs in low resources languages usually utilizes machine translation (MT) data augmentation from English language. However, translation brings a number of challenges: there are large costs attached to translating and curating huge amounts of content with high-end machine translation solutions; the translated content carries over cultural biases; and if the translation is not faithful and accurate, the quality of the data degrades causing issues in the trained model. In this work, we investigate the role of translation and synthetic data in training language models. We translate TinyStories, a dataset of 2.2M short stories for 3-4 year old children, from English to Arabic using the open NLLB-3B MT model. We train a number of story generation models of size 1M-33M parameters using this data. We identify a number of quality and task-specific issues in the resulting models. To rectify these issues, we further pre-train the models with a small dataset of synthesized high-quality stories generated by a capable LLM in Arabic, representing 1% of the original training data. We show, using GPT-4 as a judge and dictionary learning analysis from mechanistic interpretability, that the suggested approach is a practical means to resolve some of the translation pitfalls. We illustrate the improvement through case studies of linguistic and cultural bias issues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "3405393",
                    "name": "Md. Rizwan Parvez"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                }
            ]
        },
        {
            "paperId": "ffc6c18e9c89e9a20a31d6c351499bc408c9b85a",
            "title": "Semantic Ranking for Automated Adversarial Technique Annotation in Security Text",
            "abstract": "We introduce a novel approach for mapping attack behaviors described in threat analysis reports to entries in an adversarial techniques knowledge base. Our method leverages a multi-stage ranking architecture to efficiently rank the most related techniques based on their semantic relevance to the input text. Each ranker in our pipeline uses a distinct design for text representation. To enhance relevance modeling, we leverage pretrained language models, which we fine-tune for the technique annotation task. While generic large language models are not yet capable of fully addressing this challenge, we obtain very promising results. We achieve a recall rate improvement of +35% compared to the previous state-of-the-art results. We further create new public benchmark datasets for training and validating methods in this domain, which we release to the research community aiming to promote future research in this important direction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158858005",
                    "name": "Udesh Kumarasinghe"
                },
                {
                    "authorId": "1841125220",
                    "name": "Ahmed Lekssays"
                },
                {
                    "authorId": "1772206",
                    "name": "H. Sencar"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "145394674",
                    "name": "Charitha Elvitigala"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "06dc6e7c32480aff7085f32de22206a62f5893fc",
            "title": "Analyzing Multilingual Competency of LLMs in Multi-Turn Instruction Following: A Case Study of Arabic",
            "abstract": "While significant progress has been made in benchmarking Large Language Models (LLMs) across various tasks, there is a lack of comprehensive evaluation of their abilities in responding to multi-turn instructions in less-commonly tested languages like Arabic. Our paper offers a detailed examination of the proficiency of open LLMs in such scenarios in Arabic. Utilizing a customized Arabic translation of the MT-Bench benchmark suite, we employ GPT-4 as a uniform evaluator for both English and Arabic queries to assess and compare the performance of the LLMs on various open-ended tasks. Our findings reveal variations in model responses on different task categories, e.g., logic vs. literacy, when instructed in English or Arabic. We find that fine-tuned base models using multilingual and multi-turn datasets could be competitive to models trained from scratch on multilingual data. Finally, we hypothesize that an ensemble of small, open LLMs could perform competitively to proprietary LLMs on the benchmark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                }
            ]
        },
        {
            "paperId": "5e3352efd7916e14f91a9fc4bb225e031e9efd82",
            "title": "Multi-Modal Perceiver Language Model for Outcome Prediction in Emergency Department",
            "abstract": "Language modeling have shown impressive progress in generating compelling text with good accuracy and high semantic coherence. An interesting research direction is to augment these powerful models for specific applications using contextual information. In this work, we explore multi-modal language modeling for healthcare applications. We are interested in outcome prediction and patient triage in hospital emergency department based on text information in chief complaints and vital signs recorded at triage. We adapt Perceiver - a modality-agnostic transformer-based model that has shown promising results in several applications. Since vital-sign modality is represented in tabular format, we modified Perceiver position encoding to ensure permutation invariance. We evaluated the multi-modal language model for the task of diagnosis code prediction using MIMIC-IV ED dataset on 120K visits. In the experimental analysis, we show that mutli-modality improves the prediction performance compared with models trained solely on text or vital signs. We identified disease categories for which multi-modality leads to performance improvement and show that for these categories, vital signs have added predictive power. By analyzing the cross-attention layer, we show how multi-modality contributes to model predictions. This work gives interesting insights on the development of multi-modal language models for healthcare applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2232868",
                    "name": "Fethi Jarray"
                },
                {
                    "authorId": "1415041918",
                    "name": "Abdulaziz Yousuf Al-Homaid"
                },
                {
                    "authorId": "3338301",
                    "name": "Rashid Niaz"
                },
                {
                    "authorId": "6974030",
                    "name": "Khalid Alyafei"
                }
            ]
        },
        {
            "paperId": "9f87c8e27a10d71500314e7e21853f5a23efce59",
            "title": "LAraBench: Benchmarking Arabic AI with Large Language Models",
            "abstract": "Recent advancements in Large Language Models (LLMs) have significantly influenced the landscape of language and speech research. Despite this progress, these models lack specific benchmarking against state-of-the-art (SOTA) models tailored to particular languages and tasks. LAraBench addresses this gap for Arabic Natural Language Processing (NLP) and Speech Processing tasks, including sequence tagging and content classification across different domains. We utilized models such as GPT-3.5-turbo, GPT-4, BLOOMZ, Jais-13b-chat, Whisper, and USM, employing zero and few-shot learning techniques to tackle 33 distinct tasks across 61 publicly available datasets. This involved 98 experimental setups, encompassing ~296K data points, ~46 hours of speech, and 30 sentences for Text-to-Speech (TTS). This effort resulted in 330+ sets of experiments. Our analysis focused on measuring the performance gap between SOTA models and LLMs. The overarching trend observed was that SOTA models generally outperformed LLMs in zero-shot learning, with a few exceptions. Notably, larger computational models with few-shot learning techniques managed to reduce these performance gaps. Our findings provide valuable insights into the applicability of LLMs for Arabic NLP and speech processing tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "1725417821",
                    "name": "Shammur A. Chowdhury"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2171367840",
                    "name": "Basel Mousi"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2189476655",
                    "name": "Yassine El Kheir"
                },
                {
                    "authorId": "2177436744",
                    "name": "Daniel Izham"
                },
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                },
                {
                    "authorId": "2218353460",
                    "name": "Nizi Nazar"
                },
                {
                    "authorId": "2218145245",
                    "name": "Yousseif Elshahawy"
                },
                {
                    "authorId": "2109102523",
                    "name": "Ahmed M. Ali"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "1398136050",
                    "name": "Natasa Milic-Frayling"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "c60116a51bf66bc363d11b797d97eba84b13cfd7",
            "title": "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking",
            "abstract": "The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework, which can be seamlessly customized to evaluate LLMs for any NLP task, regardless of language. The framework features generic dataset loaders, several model providers, and pre-implements most standard evaluation metrics. It supports in-context learning with zero- and few-shot settings. A specific dataset and task can be evaluated for a given LLM in less than 20 lines of code while allowing full flexibility to extend the framework for custom datasets, models, or tasks. The framework has been tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We open-sourced LLMeBench for the community (https://github.com/qcri/LLMeBench/) and a video demonstrating the framework is available online (https://youtu.be/9cC2m_abk3A).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2171367840",
                    "name": "Basel Mousi"
                },
                {
                    "authorId": "2249672254",
                    "name": "Samir Abdaljalil"
                },
                {
                    "authorId": "2218353460",
                    "name": "Nizi Nazar"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "1725417821",
                    "name": "Shammur A. Chowdhury"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "2109102523",
                    "name": "Ahmed M. Ali"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "941194a756aabd2b07b5b1a64122b571882f9ca1",
            "title": "Learning a Shared Model for Motorized Prosthetic Joints to Predict Ankle-Joint Motion",
            "abstract": "Control strategies for active prostheses or orthoses use sensor inputs to recognize the user's locomotive intention and generate corresponding control commands for producing the desired locomotion. In this paper, we propose a learning-based shared model for predicting ankle-joint motion for different locomotion modes like level-ground walking, stair ascent, stair descent, slope ascent, and slope descent without the need to classify between them. Features extracted from hip and knee joint angular motion are used to continuously predict the ankle angles and moments using a Feed-Forward Neural Network-based shared model. We show that the shared model is adequate for predicting the ankle angles and moments for different locomotion modes without explicitly classifying between the modes. The proposed strategy shows the potential for devising a high-level controller for an intelligent prosthetic ankle that can adapt to different locomotion modes.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "151440196",
                    "name": "S. Dey"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "32429388",
                    "name": "A. Schilling"
                }
            ]
        },
        {
            "paperId": "c21e67dfae81532369e37af2f9cb085e7c249eea",
            "title": "Fairness in TabNet Model by Disentangled Representation for the Prediction of Hospital No-Show",
            "abstract": "Patient no-shows is a major burden for health centers leading to loss of revenue, increased waiting time and deteriorated health outcome. Developing machine learning (ML) models for the prediction of no -shows could help addressing this important issue. It is crucial to consider fair ML models for no-show prediction in order to ensure equality of opportunity in accessing healthcare services. In this wo rk, we are interested in developing deep learning models for no-show prediction based on tabular data while ensuring fairness properties. Our baseline model, TabNet, uses on attentive feature transforme rs and has shown promising results for tabular data. We propose Fair-TabNet based on representation learning that disentangles predictive from sensitive components. The model is trained to jointly min imize loss functions on no-shows and sensitive variables while ensuring that the sensitive and prediction representations are orthogonal. In the experimental analysis, we used a hospital dataset of 210, 000 appointments collected in 2019. Our preliminary results show that the proposed Fair-TabNet improves the predictive, fairness performance and convergence speed over TabNet for the task of appointment no-show prediction. The comparison with the state-of-the art models for tabular data shows promising results and could be further improved by a better tuning of hyper-parameters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2232868",
                    "name": "Fethi Jarray"
                },
                {
                    "authorId": "2052100006",
                    "name": "A. Kadri"
                }
            ]
        },
        {
            "paperId": "3644465b9d0a9fc43c392c70930f7f433dbff49a",
            "title": "Differential Architecture Search in Deep Learning for Genomic Applications",
            "abstract": "The data explosion caused by unprecedented advancements in the field of genomics is constantly challenging the conventional methods used in the interpretation of the human genome. The demand for robust algorithms over the recent years has brought huge success in the field of Deep Learning (DL) in solving many difficult tasks in image, speech and natural language processing by automating the manual process of architecture design. This has been fueled through the development of new DL architectures. Yet genomics possesses unique challenges as we expect DL to provide a super human intelligence that easily interprets a human genome. In this paper, the state-of-the art DL approach based on differential search mechanism was adapted for interpretation of biological sequences. This method has been applied on the splice site recognition task on raw DNA sequences to discover high-performance convolutional architectures by automated engineering.The discovered architecture achieved comparable accuracy when evaluated with a fixed Recurrent Neural Network (RNN) architecture. The results have shown a potential of using this automated architecture search mechanism for solving other problems in genomics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4112326",
                    "name": "S. Moosa"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "144730155",
                    "name": "A. Amira"
                }
            ]
        }
    ]
}