{
    "authorId": "2118839825",
    "papers": [
        {
            "paperId": "0c2bc344922ebfb0180d29052e938f4d80751f02",
            "title": "G-Fuzz: A Directed Fuzzing Framework for gVisor",
            "abstract": "gVisor is a Google-published application-level kernel for containers. As gVisor is lightweight and has sound isolation, it has been widely used in many IT enterprises [1], [2], [3]. When a new vulnerability of the upstream gVisor is found, it is important for the downstream developers to test the corresponding code to maintain the security. To achieve this aim, directed fuzzing is promising. Nevertheless, there are many challenges in applying existing directed fuzzing methods for gVisor. The core reason is that existing directed fuzzers are mainly for general C/C++ applications, while gVisor is an OS kernel written in the Go language. To address the above challenges, we propose G-Fuzz, a directed fuzzing framework for gVisor. There are three core methods in G-Fuzz, including lightweight and fine-grained distance calculation, target related syscall inference and utilization, and exploration and exploitation dynamic switch. Note that the methods of G-Fuzz are general and can be transferred to other OS kernels. We conduct extensive experiments to evaluate the performance of G-Fuzz. Compared to Syzkaller, the state-of-the-art kernel fuzzer, G-Fuzz outperforms it significantly. Furthermore, we have rigorously evaluated the importance for each core method of G-Fuzz. G-Fuzz has been deployed in industry and has detected multiple serious vulnerabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110426315",
                    "name": "Yuwei Li"
                },
                {
                    "authorId": "2144035401",
                    "name": "Yuan Chen"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                },
                {
                    "authorId": "2160107708",
                    "name": "Xuhong Zhang"
                },
                {
                    "authorId": "1750269",
                    "name": "Guanglu Yan"
                },
                {
                    "authorId": "2149301255",
                    "name": "Alex X. Liu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "80752053",
                    "name": "Zulie Pan"
                },
                {
                    "authorId": "2209784784",
                    "name": "Peng Lin"
                }
            ]
        },
        {
            "paperId": "4b1e9812c71c4a243e84cf99aef8f4a2fc9ccd60",
            "title": "AdvSQLi: Generating Adversarial SQL Injections Against Real-World WAF-as-a-Service",
            "abstract": "As the first defensive layer that attacks would hit, the web application firewall (WAF) plays an indispensable role in defending against malicious web attacks like SQL injection (SQLi). With the development of cloud computing, WAF-as-a-service, as one kind of Security-as-a-service, has been proposed to facilitate the deployment, configuration, and update of WAFs in the cloud. Despite its tremendous popularity, the security vulnerabilities of WAF-as-a-service are still largely unknown, which is highly concerning given its massive usage. In this paper, we propose a general and extendable attack framework, namely AdvSQLi, in which a minimal series of transformations are performed on the hierarchical tree representation of the original SQLi payload, such that the generated SQLi payloads can not only bypass WAF-as-a-service under black-box settings but also keep the same functionality and maliciousness as the original payload. With AdvSQLi, we make it feasible to inspect and understand the security vulnerabilities of WAFs automatically, helping vendors make products more secure. To evaluate the attack effectiveness and efficiency of AdvSQLi, we first employ two public datasets to generate adversarial SQLi payloads, leading to a maximum attack success rate of 100% against state-of-the-art ML-based SQLi detectors. Furthermore, to demonstrate the immediate security threats caused by AdvSQLi, we evaluate the attack effectiveness against 7 WAF-as-a-service solutions from mainstream vendors and find all of them are vulnerable to AdvSQLi. For instance, AdvSQLi achieves an attack success rate of over 79% against the F5 WAF. Through in-depth analysis of the evaluation results, we further condense out several general yet severe flaws of these vendors that cannot be easily patched.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149703865",
                    "name": "Zhenqing Qu"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2278623383",
                    "name": "Ting Wang"
                },
                {
                    "authorId": "2143735590",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2248114065",
                    "name": "Shouling Ji"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                }
            ]
        },
        {
            "paperId": "09aedbfbc314006bac8e7cead1b838439705f449",
            "title": "Self-Supervised Interest Transfer Network via Prototypical Contrastive Learning for Recommendation",
            "abstract": "Cross-domain recommendation has attracted increasing attention from industry and academia recently. However, most existing methods do not exploit the interest invariance between domains, which would yield sub-optimal solutions. In this paper, we propose a cross-domain recommendation method: Self-supervised Interest Transfer Network (SITN), which can effectively transfer invariant knowledge between domains via prototypical contrastive learning. Specifically, we perform two levels of cross-domain contrastive learning: 1) instance-to-instance contrastive learning, 2) instance-to-cluster contrastive learning. Not only that, we also take into account users' multi-granularity and multi-view interests. With this paradigm, SITN can explicitly learn the invariant knowledge of interest clusters between domains and accurately capture users' intents and preferences. We conducted extensive experiments on a public dataset and a large-scale industrial dataset collected from one of the world's leading e-commerce corporations. The experimental results indicate that SITN achieves significant improvements over state-of-the-art recommendation methods. Additionally, SITN has been deployed on a micro-video recommendation platform, and the online A/B testing results further demonstrate its practical value. Supplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113639198",
                    "name": "Guoqiang Sun"
                },
                {
                    "authorId": "144277955",
                    "name": "Yibin Shen"
                },
                {
                    "authorId": "2108885341",
                    "name": "Sijing Zhou"
                },
                {
                    "authorId": "145671740",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2115669436",
                    "name": "Hongyan Liu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2954826",
                    "name": "Chenyi Lei"
                },
                {
                    "authorId": "2115494168",
                    "name": "Xianhui Wei"
                },
                {
                    "authorId": "1741435593",
                    "name": "Fei Fang"
                }
            ]
        },
        {
            "paperId": "8e6d1470e8d52b46b07db84bcdc727963b6bf7dd",
            "title": "MalGraph: Hierarchical Graph Neural Networks for Robust Windows Malware Detection",
            "abstract": "With the ever-increasing malware threats, malware detection plays an indispensable role in protecting information systems. Although tremendous research efforts have been made, there are still two key challenges hindering them from being applied to accurately and robustly detect malwares. Firstly, most of them represent executables with shallow features, but ignore their semantic and structural information. Secondly, they are primarily based on representations that can be easily modified by attackers and thus cannot provide robustness against adversarial attacks. To tackle the challenges, we present MalGraph, which first represents executables with hierarchical graphs and then uses an end-to-end learning framework based on graph neural networks for malware detection. In particular, a hierarchical graph consists of a function call graph that captures the interaction semantics among different functions at the inter-function level and corresponding control-flow graphs for learning the structural semantics of each function at the intra-function level. We argue the abstraction and hierarchy nature of hierarchical graphs makes them not only easy to capture rich structural information of executables, but also be immune to adversarial attacks. Evaluations show that MalGraph not only outperforms state-of-the-art malware detection, but also exhibits stronger robustness against adversarial attacks by a large margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2066621473",
                    "name": "Wei Deng"
                },
                {
                    "authorId": "2149703865",
                    "name": "Zhenqing Qu"
                },
                {
                    "authorId": "2155241302",
                    "name": "Jiangyu Zhang"
                },
                {
                    "authorId": "38654394",
                    "name": "Shenmin Zhang"
                },
                {
                    "authorId": "1901958",
                    "name": "Tengyu Ma"
                },
                {
                    "authorId": "2152594370",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "da155d953755e95e80acbf4a6ef163a89bb68daf",
            "title": "Towards the Desirable Decision Boundary by Moderate-Margin Adversarial Training",
            "abstract": "Adversarial training, as one of the most effective defense methods against adversarial attacks, tends to learn an inclusive decision boundary to increase the robustness of deep learning models. However, due to the large and unnecessary increase in the margin along adversarial directions, adversarial training causes heavy cross-over between natural examples and adversarial examples, which is not conducive to balancing the trade-off between robustness and natural accuracy. In this paper, we propose a novel adversarial training scheme to achieve a better trade-off between robustness and natural accuracy. It aims to learn a moderate-inclusive decision boundary, which means that the margins of natural examples under the decision boundary are moderate. We call this scheme Moderate-Margin Adversarial Training (MMAT), which generates finer-grained adversarial examples to mitigate the cross-over problem. We also take advantage of logits from a teacher model that has been well-trained to guide the learning of our model. Finally, MMAT achieves high natural accuracy and robustness under both black-box and white-box attacks. On SVHN, for example, state-of-the-art robustness and natural accuracy are achieved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153398079",
                    "name": "Xiaoyu Liang"
                },
                {
                    "authorId": "1877805",
                    "name": "Yaguan Qian"
                },
                {
                    "authorId": "2176928632",
                    "name": "Jianchang Huang"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2152594370",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "3083255",
                    "name": "Wassim Swaileh"
                }
            ]
        },
        {
            "paperId": "4b814146cba8bc9b45ad21326fb9d713288525ae",
            "title": "V-Shuttle: Scalable and Semantics-Aware Hypervisor Virtual Device Fuzzing",
            "abstract": "With the wide application and deployment of cloud computing in enterprises, virtualization developers and security researchers are paying more attention to cloud computing security. The core component of cloud computing products is the hypervisor, which is also known as the virtual machine monitor (VMM) that can isolate multiple virtual machines in one host machine. However, compromising the hypervisor can lead to virtual machine escape and the elevation of privilege, allowing attackers to gain the permission of code execution in the host. Therefore, the security analysis and vulnerability detection of the hypervisor are critical for cloud computing enterprises. Importantly, virtual devices expose many interfaces to a guest user for communication, making virtual devices the most vulnerable part of a hypervisor. However, applying fuzzing to the virtual devices of a hypervisor is challenging because the data structures transferred by DMA are constructed in a nested form according to protocol specifications. Failure to understand the protocol of the virtual devices will make the fuzzing process stuck in the initial fuzzing stage, resulting in inefficient fuzzing. In this paper, we propose a new framework called V-Shuttle to conduct hypervisor fuzzing, which performs scalable and semantics-aware hypervisor fuzzing. To address the above challenges, we first design a DMA redirection mechanism to significantly reduce the manual efforts to reconstruct virtual devices' protocol structures and make the fuzzing environment setup automated and scalable. Furthermore, we put forward a new fuzzing mutation scheduling mechanism called seedpool to make the virtual device fuzzing process semantics-aware and speed up the fuzzing process to achieve high coverage. Extensive evaluation on QEMU and VirtualBox, two of the most popular hypervisor platforms among the world, shows that V-Shuttle can efficiently reproduce existing vulnerabilities and find new vulnerabilities. We further carried out a long-term fuzzing campaign in QEMU/KVM and VirtualBox with V-Shuttle. In total, we discovered 35 new bugs with 17 CVEs assigned.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1562978050",
                    "name": "Gaoning Pan"
                },
                {
                    "authorId": "51465605",
                    "name": "Xingwei Lin"
                },
                {
                    "authorId": "49469875",
                    "name": "Xuhong Zhang"
                },
                {
                    "authorId": "2864540",
                    "name": "Yongkang Jia"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "1476814682",
                    "name": "Xinlei Ying"
                },
                {
                    "authorId": "2155172564",
                    "name": "Jiashui Wang"
                },
                {
                    "authorId": "2134080127",
                    "name": "Yanjun Wu"
                }
            ]
        },
        {
            "paperId": "84118625150b5a20e919db0876ef7d15771522d3",
            "title": "A Practical Black-Box Attack on Source Code Authorship Identification Classifiers",
            "abstract": "Existing researches have recently shown that adversarial stylometry of source code can confuse source code authorship identification (SCAI) models, which may threaten the security of related applications such as programmer attribution, software forensics, etc. In this work, we propose source code authorship disguise (SCAD) to automatically hide programmers\u2019 identities from authorship identification, which is more practical than the previous work that requires to known the output probabilities or internal details of the target SCAI model. Specifically, SCAD trains a substitute model and develops a set of semantically equivalent transformations, based on which the original code is modified towards a disguised style with small manipulations in lexical features and syntactic features. When evaluated under totally black-box settings, on a real-world dataset consisting of 1,600 programmers, SCAD induces state-of-the-art SCAI models to cause above 30% misclassification rates. The efficiency and utility-preserving properties of SCAD are also demonstrated with multiple metrics. Furthermore, our work can serve as a guideline for developing more robust identification methods in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47362398",
                    "name": "Qianjun Liu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                },
                {
                    "authorId": "150952519",
                    "name": "Changchang Liu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                }
            ]
        },
        {
            "paperId": "6f5ebfc25296c8aea75ff0996563e77702720668",
            "title": "UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating Fuzzers",
            "abstract": "A flurry of fuzzing tools (fuzzers) have been proposed in the literature, aiming at detecting software vulnerabilities effectively and efficiently. To date, it is however still challenging to compare fuzzers due to the inconsistency of the benchmarks, performance metrics, and/or environments for evaluation, which buries the useful insights and thus impedes the discovery of promising fuzzing primitives. In this paper, we design and develop UNIFUZZ, an open-source and metrics-driven platform for assessing fuzzers in a comprehensive and quantitative manner. Specifically, UNIFUZZ to date has incorporated 35 usable fuzzers, a benchmark of 20 real-world programs, and six categories of performance metrics. We first systematically study the usability of existing fuzzers, find and fix a number of flaws, and integrate them into UNIFUZZ. Based on the study, we propose a collection of pragmatic performance metrics to evaluate fuzzers from six complementary perspectives. Using UNIFUZZ, we conduct in-depth evaluations of several prominent fuzzers including AFL [1], AFLFast [2], Angora [3], Honggfuzz [4], MOPT [5], QSYM [6], T-Fuzz [7] and VUzzer64 [8]. We find that none of them outperforms the others across all the target programs, and that using a single metric to assess the performance of a fuzzer may lead to unilateral conclusions, which demonstrates the significance of comprehensive metrics. Moreover, we identify and investigate previously overlooked factors that may significantly affect a fuzzer's performance, including instrumentation methods and crash analysis tools. Our empirical results show that they are critical to the evaluation of a fuzzer. We hope that our findings can shed light on reliable fuzzing evaluation, so that we can discover promising fuzzing primitives to effectively facilitate fuzzer designs in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110426315",
                    "name": "Yuwei Li"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                },
                {
                    "authorId": "2144035401",
                    "name": "Yuan Chen"
                },
                {
                    "authorId": "2114786953",
                    "name": "Sizhuang Liang"
                },
                {
                    "authorId": "3140500",
                    "name": "Wei-Han Lee"
                },
                {
                    "authorId": "2118379883",
                    "name": "Yueyao Chen"
                },
                {
                    "authorId": null,
                    "name": "Chenyang Lyu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "35976991",
                    "name": "R. Beyah"
                },
                {
                    "authorId": "2112624803",
                    "name": "Peng Cheng"
                },
                {
                    "authorId": "40001161",
                    "name": "Kangjie Lu"
                },
                {
                    "authorId": "2155389584",
                    "name": "Ting Wang"
                }
            ]
        },
        {
            "paperId": "8b4c857311c001f6ed0cd790cce4af4dfcfb6533",
            "title": "Deep Graph Matching and Searching for Semantic Code Retrieval",
            "abstract": "Code retrieval is to find the code snippet from a large corpus of source code repositories that highly matches the query of natural language description. Recent work mainly uses natural language processing techniques to process both query texts (i.e., human natural language) and code snippets (i.e., machine programming language), however, neglecting the deep structured features of query texts and source codes, both of which contain rich semantic information. In this article, we propose an end-to-end deep graph matching and searching (DGMS) model based on graph neural networks for the task of semantic code retrieval. To this end, we first represent both natural language query texts and programming language code snippets with the unified graph-structured data, and then use the proposed graph matching and searching model to retrieve the best matching code snippet. In particular, DGMS not only captures more structural information for individual query texts or code snippets, but also learns the fine-grained similarity between them by cross-attention based semantic matching operations. We evaluate the proposed DGMS model on two public code retrieval datasets with two representative programming languages (i.e., Java and Python). Experiment results demonstrate that DGMS significantly outperforms state-of-the-art baseline models by a large margin on both datasets. Moreover, our extensive ablation studies systematically investigate and illustrate the impact of each part of DGMS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "84527483",
                    "name": "Sai-gang Wang"
                },
                {
                    "authorId": "1562978050",
                    "name": "Gaoning Pan"
                },
                {
                    "authorId": "1488667108",
                    "name": "Tengfei Ma"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2148770609",
                    "name": "A. Liu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "a1319d88d364b9075107e0dec635eeb8f0a8d4d1",
            "title": "Towards Imperceptible Adversarial Image Patches Based on Network Explanations",
            "abstract": "The vulnerability of deep neural networks (DNNs) for adversarial examples have attracted more attention. Many algorithms are proposed to craft powerful adversarial examples. However, these algorithms modifying the global or local region of pixels without taking into account network explanations. Hence, the perturbations are redundancy and easily detected by human eyes. In this paper, we propose a novel method to generate local region perturbations. The main idea is to find the contributing feature regions (CFRs) of images based on network explanations for perturbations. Due to the network explanations, the perturbations added to the CFRs are more effective than other regions. In our method, a soft mask matrix is designed to represent the CFRs for finely characterizing the contributions of each pixel. Based on this soft mask, we develop a new objective function with inverse temperature to search for optimal perturbations in CFRs. Extensive experiments are conducted on CIFAR-10 and ILSVRC2012, which demonstrate the effectiveness, including attack success rate, imperceptibility,and transferability.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1877805",
                    "name": "Yaguan Qian"
                },
                {
                    "authorId": "2109014290",
                    "name": "Jiamin Wang"
                },
                {
                    "authorId": "2152594370",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "1697068",
                    "name": "Zhaoquan Gu"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                }
            ]
        }
    ]
}