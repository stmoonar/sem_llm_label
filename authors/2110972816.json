{
    "authorId": "2110972816",
    "papers": [
        {
            "paperId": "12b20c26a718a2aa2457b3908f107c0e74637a45",
            "title": "Continual Learning on Dynamic Graphs via Parameter Isolation",
            "abstract": "Many real-world graph learning tasks require handling dynamic graphs where new nodes and edges emerge. Dynamic graph learning methods commonly suffer from the catastrophic forgetting problem, where knowledge learned for previous graphs is overwritten by updates for new graphs. To alleviate the problem, continual graph learning methods are proposed. However, existing continual graph learning methods aim to learn new patterns and maintain old ones with the same set of parameters of fixed size, and thus face a fundamental tradeoff between both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN) for continual learning on dynamic graphs that circumvents the tradeoff via parameter isolation and expansion. Our motivation lies in that different parameters contribute to learning different graph patterns. Based on the idea, we expand model parameters to continually learn emerging graph patterns. Meanwhile, to effectively preserve knowledge for unaffected patterns, we find parameters that correspond to them via optimization and freeze them to prevent them from being rewritten. Experiments on eight real-world datasets corroborate the effectiveness of PI-GNN compared to state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115512664",
                    "name": "Peiyan Zhang"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "3210262",
                    "name": "Senzhang Wang"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2072633489",
                    "name": "Guojie Song"
                },
                {
                    "authorId": "2118021616",
                    "name": "Sunghun Kim"
                }
            ]
        },
        {
            "paperId": "49e0cc79f002ccb85dcb58796220c3fe3487e348",
            "title": "Beyond the Overlapping Users: Cross-Domain Recommendation via Adaptive Anchor Link Learning",
            "abstract": "Cross-Domain Recommendation (CDR) is capable of incorporating auxiliary information from multiple domains to advance recommendation performance. Conventional CDR methods primarily rely on overlapping users, whereby knowledge is conveyed between the source and target identities belonging to the same natural person. However, such a heuristic assumption is not universally applicable due to an individual may exhibit distinct or even conflicting preferences in different domains, leading to potential noises. In this paper, we view the anchor links between users of various domains as the learnable parameters to learn the task-relevant cross-domain correlations. A novel optimal transport based model ALCDR is further proposed to precisely infer the anchor links and deeply aggregate collaborative signals from the perspectives of intra-domain and inter-domain. Our proposal is extensively evaluated over real-world datasets, and experimental results demonstrate its superiority.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109917685",
                    "name": "Yi Zhao"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "113351669",
                    "name": "Jiquan Peng"
                },
                {
                    "authorId": "1885266123",
                    "name": "Xiaohan Fang"
                },
                {
                    "authorId": "1939569",
                    "name": "Feiran Huang"
                },
                {
                    "authorId": "3210262",
                    "name": "Senzhang Wang"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2869419",
                    "name": "Jibing Gong"
                }
            ]
        },
        {
            "paperId": "89faee594a314118dcc51dc114c8e99eeae98c51",
            "title": "PASS: Personalized Advertiser-aware Sponsored Search",
            "abstract": "The nucleus of online sponsored search systems lies in measuring the relevance between the search intents of users and the advertising purposes of advertisers. Existing conventional doublet-based (query-keyword) relevance models solely rely on short queries and keywords to uncover such intents, which ignore the diverse and personalized preferences of participants (i.e., users and advertisers), resulting in undesirable advertising performance. In this paper, we investigate the novel problem of Personalized A dvertiser-aware Sponsored Search (PASS). Our motivation lies in incorporating the portraits of users and advertisers into relevance models to facilitate the modeling of intrinsic search intents and advertising purposes, leading to a quadruple-based (i.e., user-query-keyword-advertiser) task. Various types of historical behaviors are explored in the format of hypergraphs to provide abundant signals on identifying the preferences of participants. A novel heterogeneous textual hypergraph transformer is further proposed to deeply fuse the textual semantics and the high-order hypergraph topology. Our proposal is extensively evaluated over real industry datasets, and experimental results demonstrate its superiority.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162043833",
                    "name": "Zhoujin Tian"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2188068349",
                    "name": "Zhiqiang Zuo"
                },
                {
                    "authorId": "2152090164",
                    "name": "Zengxuan Wen"
                },
                {
                    "authorId": "49755259",
                    "name": "Lichao Sun"
                },
                {
                    "authorId": null,
                    "name": "Xinyue Hu"
                },
                {
                    "authorId": "2108540565",
                    "name": "Wen Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "3210262",
                    "name": "Senzhang Wang"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2181348993",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "a53e247c282f231208dc9f5a39c96f2ca9ac5651",
            "title": "xGCN: An Extreme Graph Convolutional Network for Large-scale Social Link Prediction",
            "abstract": "Graph neural networks (GNNs) have seen widespread usage across multiple real-world applications, yet in transductive learning, they still face challenges in accuracy, efficiency, and scalability, due to the extensive number of trainable parameters in the embedding table and the paradigm of stacking neighborhood aggregations. This paper presents a novel model called xGCN for large-scale network embedding, which is a practical solution for link predictions. xGCN addresses these issues by encoding graph-structure data in an extreme convolutional manner, and has the potential to push the performance of network embedding-based link predictions to a new record. Specifically, instead of assigning each node with a directly learnable embedding vector, xGCN regards node embeddings as static features. It uses a propagation operation to smooth node embeddings and relies on a Refinement neural Network (RefNet) to transform the coarse embeddings derived from the unsupervised propagation into new ones that optimize a training objective. The output of RefNet, which are well-refined embeddings, will replace the original node embeddings. This process is repeated iteratively until the model converges to a satisfying status. Experiments on three social network datasets with link prediction tasks show that xGCN not only achieves the best accuracy compared with a series of competitive baselines but also is highly efficient and scalable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2182111071",
                    "name": "Xiran Song"
                },
                {
                    "authorId": "2813328",
                    "name": "Jianxun Lian"
                },
                {
                    "authorId": "145948697",
                    "name": "H. Huang"
                },
                {
                    "authorId": "1820930645",
                    "name": "Zihan Luo"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "2215474182",
                    "name": "Xue Lin"
                },
                {
                    "authorId": "21862228",
                    "name": "Mingqi Wu"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2109791075",
                    "name": "Hai Jin"
                }
            ]
        },
        {
            "paperId": "aa1e0de459abc6eb17bfcc6f8c50bee59b107ca0",
            "title": "Multi-Grained Topological Pre-Training of Language Models in Sponsored Search",
            "abstract": "Relevance models measure the semantic closeness between queries and the candidate ads, widely recognized as the nucleus of sponsored search systems. Conventional relevance models solely rely on the textual data within the queries and ads, whose performance is hindered by the scarce semantic information in these short texts. Recently, user behavior graphs have been incorporated to provide complementary information beyond pure textual semantics.Despite the promising performance, behavior-enhanced models suffer from exhausting resource costs due to the extra computations introduced by explicit topological aggregations. In this paper, we propose a novel Multi-Grained Topological Pre-Training paradigm, MGTLM, to teach language models to understand multi-grained topological information in behavior graphs, which contributes to eliminating explicit graph aggregations and avoiding information loss. Extensive experimental results over online and offline settings demonstrate the superiority of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162043833",
                    "name": "Zhoujin Tian"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2188068349",
                    "name": "Zhiqiang Zuo"
                },
                {
                    "authorId": "2152090164",
                    "name": "Zengxuan Wen"
                },
                {
                    "authorId": "2188127948",
                    "name": "Xinyue Hu"
                },
                {
                    "authorId": "2149248164",
                    "name": "Xiao Han"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "3210262",
                    "name": "Senzhang Wang"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2181348993",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "d874af0891e0ed816d3db3379a700a2a42f1be08",
            "title": "ConvFormer: Revisiting Transformer for Sequential User Modeling",
            "abstract": "Sequential user modeling, a critical task in personalized recommender systems, focuses on predicting the next item a user would prefer, requiring a deep understanding of user behavior sequences. Despite the remarkable success of Transformer-based models across various domains, their full potential in comprehending user behavior remains untapped. In this paper, we re-examine Transformer-like architectures aiming to advance state-of-the-art performance. We start by revisiting the core building blocks of Transformer-based methods, analyzing the effectiveness of the item-to-item mechanism within the context of sequential user modeling. After conducting a thorough experimental analysis, we identify three essential criteria for devising efficient sequential user models, which we hope will serve as practical guidelines to inspire and shape future designs. Following this, we introduce ConvFormer, a simple but powerful modification to the Transformer architecture that meets these criteria, yielding state-of-the-art results. Additionally, we present an acceleration technique to minimize the complexity associated with processing extremely long sequences. Experiments on four public datasets showcase ConvFormer's superiority and confirm the validity of our proposed criteria.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256769065",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2813328",
                    "name": "Jianxun Lian"
                },
                {
                    "authorId": "31395194",
                    "name": "M. Wu"
                },
                {
                    "authorId": "2157147028",
                    "name": "Haoxuan Li"
                },
                {
                    "authorId": "2047532575",
                    "name": "Jiajun Fan"
                },
                {
                    "authorId": "66717145",
                    "name": "Wanyue Xu"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "da05a0387d68d83814c6597d9dfdb30b421fd5ba",
            "title": "Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models",
            "abstract": "Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretrained with a large amount of samples. As a result, our new method will offer us a new way to evaluate the models' robustness performance, free of limitations of fixed benchmarks or constrained perturbations, although scoped by the power of the oracle. In addition to the evaluation results, we also leverage our generated data to understand the behaviors of the model and our new evaluation strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115512664",
                    "name": "Peiyan Zhang"
                },
                {
                    "authorId": "2143856677",
                    "name": "Hao Liu"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2118021616",
                    "name": "Sunghun Kim"
                },
                {
                    "authorId": "49528192",
                    "name": "Haohan Wang"
                }
            ]
        },
        {
            "paperId": "f7e78f1a1b436d28bf8761380b91bff7d2f83c4a",
            "title": "To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge Graph Completion",
            "abstract": "Embedding models have shown great power in knowledge graph completion (KGC) task. By learning structural constraints for each training triple, these methods implicitly memorize intrinsic relation rules to infer missing links. However, this paper points out that the multi-hop relation rules are hard to be reliably memorized due to the inherent deficiencies of such implicit memorization strategy, making embedding models underperform in predicting links between distant entity pairs. To alleviate this problem, we present Vertical Learning Paradigm (VLP), which extends embedding models by allowing to explicitly copy target information from related factual triples for more accurate prediction. Rather than solely relying on the implicit memory, VLP directly provides additional cues to improve the generalization ability of embedding models, especially making the distant link prediction significantly easier. Moreover, we also propose a novel relative distance based negative sampling technique (ReD) for more effective optimization. Experiments demonstrate the validity and generality of our proposals on two standard benchmarks. Our code is available at https://github.com/rui9812/VLP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1500522974",
                    "name": "Rui Li"
                },
                {
                    "authorId": "2144230222",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2115437382",
                    "name": "Yanming Shen"
                },
                {
                    "authorId": "48018967",
                    "name": "Jianan Zhao"
                },
                {
                    "authorId": "46394401",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2114924471",
                    "name": "Weihao Han"
                },
                {
                    "authorId": "2118180377",
                    "name": "Hao Sun"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2145908764",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "06cd65936fdb2d2a5d51ca7fd612c48fbffc228e",
            "title": "Fuse It More Deeply! A Variational Transformer with Layer-Wise Latent Variable Inference for Text Generation",
            "abstract": "The past several years have witnessed Variational Auto-Encoder\u2019s superiority in various text generation tasks. However, due to the sequential nature of the text, auto-regressive decoders tend to ignore latent variables and then reduce to simple language models, known as the \\textit{KL vanishing} problem, which would further deteriorate when VAE is combined with Transformer-based structures. To ameliorate this problem, we propose Della, a novel variational Transformer framework. Della learns a series of layer-wise latent variables with each inferred from those of lower layers and tightly coupled with the hidden states by low-rank tensor product. In this way, Della forces these posterior latent variables to be fused deeply with the whole computation path and hence incorporate more information. We theoretically demonstrate that our method can be regarded as entangling latent variables to avoid posterior information decrease through layers, enabling Della to get higher non-zero KL values even without any annealing or thresholding tricks. Experiments on four unconditional and three conditional generation tasks show that Della could better alleviate KL vanishing and improve both quality and diversity compared to several strong baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "92837695",
                    "name": "Jinyi Hu"
                },
                {
                    "authorId": "3393196",
                    "name": "Xiaoyuan Yi"
                },
                {
                    "authorId": "2108769389",
                    "name": "Wenhao Li"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "3db8eb0cf0a7c506599ec07d86ccac6c8234b80a",
            "title": "Ada-GNN: Adapting to Local Patterns for Improving Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) have demonstrated strong power in mining various graph-structure data. Since real-world graphs are usually on a large scale, training scalable GNNs has become one of the research trends in recent years. Existing methods only produce one single model to serve all nodes. However, different nodes may exhibit various properties thus require diverse models, especially when the graph is large. Forcing all nodes to share a unified model will decrease the model's expressiveness. What is worse, some small groups' patterns are prone to be ignored by the model due to their minority, making these nodes unpredictable and even some raising potential unfairness problems. In this paper, we propose a model-agnostic framework Ada-GNN that provides personalized GNN models for specific sets of nodes. Intuitively, it is desirable that every node has its own model. But considering the efficiency and scalability of the framework, we generate specific GNN models at the subgroup-level rather than individual node-level. To be specific, Ada-GNN first splits the original graph into several non-overlapped subgroups and tags each node with its subgroup label. After that, a meta adapter is proposed to adapt a base GNN model to each subgroup rapidly. To better facilitate the global-to-local knowledge adaption, we design a feature enhancement module that captures the distinctions among different subgroups to improve the Ada-GNN's performance. Ada-GNN is model-agnostic and can be equipped to almost all existing scalable GNN based methods such as GraphSAGE, ClusterGCN, SIGN, and SAGN. We conduct extensive experiments with six popular scalable GNN as base methods on two large-scale datasets, and the results consistently demonstrate the generality and superiority of Ada-GNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1820930645",
                    "name": "Zihan Luo"
                },
                {
                    "authorId": "2813328",
                    "name": "Jianxun Lian"
                },
                {
                    "authorId": "2115734676",
                    "name": "Hong Huang"
                },
                {
                    "authorId": "2109791075",
                    "name": "Hai Jin"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                }
            ]
        }
    ]
}