{
    "authorId": "2243335549",
    "papers": [
        {
            "paperId": "d51c61372656471bce6b92eb576e537056779b13",
            "title": "ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models",
            "abstract": "The rapid advancement of Large Language Models (LLMs) and conversational assistants necessitates dynamic, scalable, and configurable conversational datasets for training and evaluation. These datasets must accommodate diverse user interaction modes, including text and voice, each presenting unique modeling challenges. Knowledge Graphs (KGs), with their structured and evolving nature, offer an ideal foundation for current and precise knowledge. Although human-curated KG-based conversational datasets exist, they struggle to keep pace with the rapidly changing user information needs. We present ConvKGYarn, a scalable method for generating up-to-date and configurable conversational KGQA datasets. Qualitative psychometric analyses confirm our method can generate high-quality datasets rivaling a popular conversational KGQA dataset while offering it at scale and covering a wide range of human-interaction configurations. We showcase its utility by testing LLMs on diverse conversations - exploring model behavior on conversational KGQA sets with different configurations grounded in the same KG fact set. Our results highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate parametric knowledge of LLMs, thus offering a robust solution to the constantly evolving landscape of conversational assistants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1816753042",
                    "name": "Ronak Pradeep"
                },
                {
                    "authorId": "2268434271",
                    "name": "Daniel Lee"
                },
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2243336030",
                    "name": "Jeff Pound"
                },
                {
                    "authorId": "2261737773",
                    "name": "Yisi Sang"
                },
                {
                    "authorId": "2315949053",
                    "name": "Jimmy Lin"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "2294572235",
                    "name": "Saloni Potdar"
                },
                {
                    "authorId": "2305481986",
                    "name": "Mostafa Arefiyan"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "5118df03ae5c226f3875f34845438b09951a3e45",
            "title": "Open Domain Knowledge Extraction for Knowledge Graphs",
            "abstract": "The quality of a knowledge graph directly impacts the quality of downstream applications (e.g. the number of answerable questions using the graph). One ongoing challenge when building a knowledge graph is to ensure completeness and freshness of the graph's entities and facts. In this paper, we introduce ODKE, a scalable and extensible framework that sources high-quality entities and facts from open web at scale. ODKE utilizes a wide range of extraction models and supports both streaming and batch processing at different latency. We reflect on the challenges and design decisions made and share lessons learned when building and deploying ODKE to grow an industry-scale open domain knowledge graph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261737666",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2261740020",
                    "name": "Anton Belyi"
                },
                {
                    "authorId": "2261869967",
                    "name": "Fei Wu"
                },
                {
                    "authorId": "2261739744",
                    "name": "Samira Khorshidi"
                },
                {
                    "authorId": "1902199",
                    "name": "Azadeh Nikfarjam"
                },
                {
                    "authorId": "2274930671",
                    "name": "Rahul Khot"
                },
                {
                    "authorId": "2261737773",
                    "name": "Yisi Sang"
                },
                {
                    "authorId": "2274942692",
                    "name": "Katherine Luna"
                },
                {
                    "authorId": "2274937033",
                    "name": "Xianqi Chu"
                },
                {
                    "authorId": "2275050999",
                    "name": "Eric Choi"
                },
                {
                    "authorId": "10766676",
                    "name": "Yash Govind"
                },
                {
                    "authorId": "2274942694",
                    "name": "Chloe Seivwright"
                },
                {
                    "authorId": "2274931010",
                    "name": "Yiwen Sun"
                },
                {
                    "authorId": "2265974380",
                    "name": "Ahmed Fakhry"
                },
                {
                    "authorId": "2243336634",
                    "name": "Theo Rekatsinas"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "2274957519",
                    "name": "Xiaoguang Qi"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "8d24e6680a19c2f4c113e45145ec067130069805",
            "title": "Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs",
            "abstract": "Recent work in Natural Language Processing and Computer Vision has been using textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data. However, when it comes to non-English languages, the quantity and quality of textual information are comparatively scarce. To address this issue, we introduce the novel task of automatic Knowledge Graph Enhancement (KGE) and perform a thorough investigation on bridging the gap in both the quantity and quality of textual information between English and non-English languages. More specifically, we: i) bring to light the problem of increasing multilingual coverage and precision of entity names and descriptions in Wikidata; ii) demonstrate that state-of-the-art methods, namely, Machine Translation (MT), Web Search (WS), and Large Language Models (LLMs), struggle with this task; iii) present M-NTA, a novel unsupervised approach that combines MT, WS, and LLMs to generate high-quality textual information; and, iv) study the impact of increasing multilingual coverage and precision of non-English textual information in Entity Linking, Knowledge Graph Completion, and Question Answering. As part of our effort towards better multilingual knowledge graphs, we also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE approaches in 10 languages across 7 language families.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268401404",
                    "name": "Simone Conia"
                },
                {
                    "authorId": "2268432243",
                    "name": "Min Li"
                },
                {
                    "authorId": "2268434271",
                    "name": "Daniel Lee"
                },
                {
                    "authorId": "1856878",
                    "name": "U. F. Minhas"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "bb86a2592e9efa196aefd6bbc39bf62a3202e9db",
            "title": "Construction of Paired Knowledge Graph - Text Datasets Informed by Cyclic Evaluation",
            "abstract": "Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Informed by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2243337763",
                    "name": "Xin Zhan"
                },
                {
                    "authorId": "37374479",
                    "name": "Richard He Bai"
                },
                {
                    "authorId": "2243340600",
                    "name": "Peng Shi"
                },
                {
                    "authorId": "2243336634",
                    "name": "Theo Rekatsinas"
                },
                {
                    "authorId": "2243377351",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2243336030",
                    "name": "Jeff Pound"
                },
                {
                    "authorId": "2243336902",
                    "name": "Josh Susskind"
                },
                {
                    "authorId": "2243335295",
                    "name": "Natalie Schluter"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "3111912",
                    "name": "N. Jaitly"
                }
            ]
        },
        {
            "paperId": "bfe40e4eb3e21cc91aceefa17a199e02fcf042bb",
            "title": "FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge",
            "abstract": "Detecting factual errors in textual information, whether generated by large language models (LLM) or curated by humans, is crucial for making informed decisions. LLMs' inability to attribute their claims to external knowledge and their tendency to hallucinate makes it difficult to rely on their responses. Humans, too, are prone to factual errors in their writing. Since manual detection and correction of factual errors is labor-intensive, developing an automatic approach can greatly reduce human effort. We present FLEEK, a prototype tool that automatically extracts factual claims from text, gathers evidence from external knowledge sources, evaluates the factuality of each claim, and suggests revisions for identified errors using the collected evidence. Initial empirical evaluation on fact error detection (77-85\\% F1) shows the potential of FLEEK. A video demo of FLEEK can be found at https://youtu.be/NapJFUlkPdQ.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131675694",
                    "name": "Farima Fatahi Bayat"
                },
                {
                    "authorId": "2261737666",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2243377351",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "2261737773",
                    "name": "Yisi Sang"
                },
                {
                    "authorId": "2261740020",
                    "name": "Anton Belyi"
                },
                {
                    "authorId": "2261739744",
                    "name": "Samira Khorshidi"
                },
                {
                    "authorId": "2261869967",
                    "name": "Fei Wu"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        }
    ]
}