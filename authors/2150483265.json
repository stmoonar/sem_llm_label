{
    "authorId": "2150483265",
    "papers": [
        {
            "paperId": "605755564694f22a63ad5f17116704077182cdbd",
            "title": "Show me a \"Male Nurse\"! How Gender Bias is Reflected in the Query Formulation of Search Engine Users",
            "abstract": "Biases in algorithmic systems have led to discrimination against historically disadvantaged groups, including the reinforcement of outdated gender stereotypes. While a substantial body of research addresses biases in algorithms and underlying data, in this work, we study if and how users themselves reflect these biases in their interactions with systems, which expectedly leads to the further manifestation of biases. More specifically, we investigate the replication of stereotypical gender representations by users in formulating online search queries. Following prototype theory, we define the disproportionate mention of the gender that does not conform to the prototypical representative of a searched domain (e.g., \u201cmale nurse\u201d) as an indication of bias. In a pilot study with 224 US participants and a main study with 400 UK participants, we find clear evidence of gender biases in formulating search queries. We also report the effects of an educative text on user behaviour and highlight the wish of users to learn about bias-mitigating strategies in their interactions with search engines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "2424581",
                    "name": "Martina Mara"
                },
                {
                    "authorId": "2214759238",
                    "name": "Linda Ratz"
                },
                {
                    "authorId": "2150483265",
                    "name": "Klara Krieg"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "1d246ebbaea48e346bae7060bc5744220170dec4",
            "title": "Grep-BiasIR: A Dataset for Investigating Gender Representation Bias in Information Retrieval Results",
            "abstract": "The provided contents by information retrieval (IR) systems can reflect the existing societal biases and stereotypes. Such biases in retrieval results can lead to further establishing and strengthening stereotypes in society and also in the systems. To facilitate the studies of gender bias in the retrieval results of IR systems, we introduce Gender Representation-Bias for Information Retrieval (Grep-BiasIR), a novel thoroughly-audited dataset consisting of 118 bias-sensitive neutral search queries. The set of queries covers a wide range of gender-related topics, for which a biased representation of genders in the search result can be considered as socially problematic. Each query is accompanied with one relevant and one non-relevant document, where the document is also provided in three variations of female, male, and neutral. The dataset is available at https://github.com/KlaraKrieg/GrepBiasIR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150483265",
                    "name": "Klara Krieg"
                },
                {
                    "authorId": "1410317787",
                    "name": "Emilia Parada-Cabaleiro"
                },
                {
                    "authorId": "15950614",
                    "name": "G. Medicus"
                },
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "87a5040c89ad0633b02b5052c804d4d439eb9129",
            "title": "Do Perceived Gender Biases in Retrieval Results Affect Relevance Judgements?",
            "abstract": "This work investigates the effect of gender-stereotypical biases in the content of retrieved results on the relevance judgement of users/annotators. In particular, since relevance in information retrieval (IR) is a multi-dimensional concept, we study whether the value and quality of the retrieved documents for some bias-sensitive queries can be judged differently when the content of the documents represents different genders. To this aim, we conduct a set of experiments where the genders of the participants are known as well as experiments where the participants genders are not specified. The set of experiments comprise of retrieval tasks, where participants perform a rated relevance judgement for different search query and search result document compilations. The shown documents contain different gender indications and are either relevant or non-relevant to the query. The results show the differences between the average judged relevance scores among documents with various gender contents. Our work initiates further research on the connection of the perception of gender stereotypes in users with their judgements and effects on IR systems, and aim to raise awareness about the possible biases in this domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150483265",
                    "name": "Klara Krieg"
                },
                {
                    "authorId": "1410317787",
                    "name": "Emilia Parada-Cabaleiro"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        }
    ]
}