{
    "authorId": "51042088",
    "papers": [
        {
            "paperId": "09c3a340f5d6bb8b9b9f6a4a77326c0d692d4c66",
            "title": "AdaPT: A Set of Guidelines for Hyperbolic Multimodal Multilingual NLP",
            "abstract": "The Euclidean space is the familiar space for training neural models and performing arithmetic operations. However, many data types inherently possess complex geometries, and model training methods involve operating over their latent representations, which cannot be effectively captured in the Euclidean space. The hyperbolic space provides a more generalized representative geometry to model the hierarchical complexities of the tree-like structure of natural language. We propose A DA PT a set of guidelines for initialization, parametrization, and training of neural networks, which adapts to the dataset and can be used with different manifolds. A DA PT can be generalized over any existing neural network training methodology and leads to more stable training without a substantial increase in training time. We apply A DA PT guidelines over two state-of-the-art deep learning approaches and empirically demonstrate its effectiveness through experiments on three tasks over 12 languages across speech and text. Through extensive qualitative analysis, we put forward the applicability of A DA PT as a set of guidelines optimally utilizing the manifold geometry, which can be extended to various downstream tasks across languages and modalities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1824294087",
                    "name": "Shrey Pandit"
                },
                {
                    "authorId": "2069609589",
                    "name": "Vishwa Shah"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2313536726",
                    "name": "Shafiq Joty"
                }
            ]
        },
        {
            "paperId": "3089714fd0711983fad8fad2dc5d447f07b07e7a",
            "title": "RISE: Robust Early-exiting Internal Classifiers for Suicide Risk Evaluation",
            "abstract": "Suicide is a serious public health issue, but it is preventable with timely intervention. Emerging studies have suggested there is a noticeable increase in the number of individuals sharing suicidal thoughts online. As a result, utilising advance Natural Language Processing techniques to build automated systems for risk assessment is a viable alternative. However, existing systems are prone to incorrectly predicting risk severity and have no early detection mechanisms. Therefore, we propose RISE, a novel robust mechanism for accurate early detection of suicide risk by ensembling Hyperbolic Internal Classifiers equipped with an abstention mechanism and early-exit inference capabilities. Through quantitative, qualitative and ablative experiments, we demonstrate RISE as an efficient and robust human-in-the-loop approach for risk assessment over the Columbia Suicide Severity Risk Scale (C-SSRS) and CLPsych 2022 datasets. It is able to successfully abstain from 84% incorrect predictions on Reddit data while out-predicting state of the art models upto 3.5x earlier.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161000447",
                    "name": "Ritesh Soun"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "3238627",
                    "name": "Nikolaos Aletras"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "5fa230579616993cb25c40aac4ed265f745c2926",
            "title": "Saliency-Aware Interpolative Augmentation for Multimodal Financial Prediction",
            "abstract": "Predicting price variations of financial instruments for risk modeling and stock trading is challenging due to the stochastic nature of the stock market. While recent advancements in the Financial AI realm have expanded the scope of data and methods they use, such as textual and audio cues from financial earnings calls, limitations exist. Most datasets are small, and show domain distribution shifts due to the nature of their source, suggesting the exploration for data augmentation for robust augmentation strategies such as Mixup. To tackle such challenges in the financial domain, we propose SH-Mix: Saliency-guided Hierarchical Mixup augmentation technique for multimodal financial prediction tasks. SH-Mix combines multi-level embedding mixup strategies based on the contribution of each modality and context subsequences. Through extensive quantitative and qualitative experiments on financial earnings and conference call datasets consisting of text and speech, we show that SH-Mix outperforms state-of-the-art methods by 3-7%. Additionally, we show that SH-Mix is generalizable across different modalities and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302368303",
                    "name": "Samyak Jain"
                },
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "b3795d73cadfacfb6aa0f723978915012070a3d5",
            "title": "DocScript: Document-level Script Event Prediction",
            "abstract": "We present a novel task of document-level script event prediction, which aims to predict the next event given a candidate list of narrative events in long-form documents. To enable this, we introduce DocSEP, a challenging dataset in two new domains - contractual documents and Wikipedia articles, where timeline events may be paragraphs apart and may require multi-hop temporal and causal reasoning. We benchmark existing baselines and present a novel architecture called DocScript to learn sequential ordering between events at the document scale. Our experimental results on the DocSEP dataset demonstrate that learning longer-range dependencies between events is a key challenge and show that contemporary LLMs such as ChatGPT and FlanT5 struggle to solve this task, indicating their lack of reasoning abilities for understanding causal relationships and temporal sequences within long texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "31099365",
                    "name": "Aparna Garimella"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2274190457",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                }
            ]
        },
        {
            "paperId": "7dcb732c92e9c5b53aff482e543db4909dfa62dc",
            "title": "Learning Through Interpolative Augmentation of Dynamic Curvature Spaces",
            "abstract": "Mixup is an efficient data augmentation technique, which improves generalization by interpolating random examples. While numerous approaches have been developed for Mixup in the Euclidean and in the hyperbolic space, they do not fully use the intrinsic properties of the examples, i.e., they manually set the geometry (Euclidean or hyperbolic) based on the overall dataset, which may be sub-optimal since each example may require a different geometry. We propose DynaMix, a framework that automatically selects an example-specific geometry and performs Mixup between the different geometries to improve training dynamics and generalization. Through extensive experiments in image and text modalities we show that DynaMix outperforms state-of-the-art methods over six downstream applications. We find that DynaMix is more useful in low-resource and semi-supervised settings likely because it displays a probabilistic view of the geometry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "938fc1d267e416fc363e9d453afb8484fc2d2ce0",
            "title": "HyperSteg: Hyperbolic Learning for Deep Steganography",
            "abstract": "Steganography is the art of hiding a secret message signal inside a publicly visible carrier with minimum perceptual loss in the carrier. In order to better hide information, it is critical to optimally represent the message-carrier wave interference while blending the message with the carrier. We propose HyperSteg: a novel steganography method in the hyperbolic space grounded in the hyperbolic properties of wave interference. Through hyperbolic learning, HyperSteg learns to better represent the hyperbolic properties of message-carrier interference with minimum additional computational cost. Through extensive experiments over image and audio datasets, we introduce HyperSteg as a practical, model and modality agnostic approach for information hiding.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "2161000447",
                    "name": "Ritesh Soun"
                },
                {
                    "authorId": "2216460328",
                    "name": "Rahul Shivani"
                },
                {
                    "authorId": "2216485529",
                    "name": "Vishnu Varanasi"
                },
                {
                    "authorId": "2216474161",
                    "name": "Navroop Gill"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                }
            ]
        },
        {
            "paperId": "015271efe207165753b7d8c1346b91fe8f6064fd",
            "title": "THINK: Temporal Hypergraph Hyperbolic Network",
            "abstract": "Network-based time series forecasting is a challenging task as it involves complex geometric properties, higher-order relations, and scale-free characteristics. Previous work has modeled network-based series as oversimplified graphs or has ignored the power law dynamics of real-world temporal and dynamic networks, which could yield suboptimal results. With the aim to address these issues, here we propose THINK, a novel framework based on hypergraph learning that captures the hyperbolic properties of time-evolving dynamic hypergraphs. We design an elegant hyperbolic distance-aware hypergraph attention mechanism to better capture informative internal structural features on the Poincar\u00e9 ball. Through quantitative and conceptual analysis on seven tasks across temporal, and time-evolving dynamic hypergraphs, we demonstrate THINK\u2019s practicality in comparison to a variety of benchmarks spanning finance, health, and energy networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "02dbc34adc6364d698ad530d2957802de1c66c38",
            "title": "Intermix: An Interference-Based Data Augmentation and Regularization Technique for Automatic Deep Sound Classification",
            "abstract": "In this paper, we present InterMix, an interference-based regularization and data augmentation strategy for automatic sound classification. InterMix creates virtual training examples by creating an interference-based mixed representation for a sampled phase difference and mixup ratio. InterMix can be used to train sound classification models with the ability to generate a vast amount of training samples. These are significantly varied compared to that of other mixup strategies due to the introduction of phase difference, a continuous variable. While building on other mixup strategies which use linear interpolation, we perform mixup based on the formula of interference. We demonstrate the utility of InterMix in comparison to standard learning techniques and previously applied mixing strategies through a quantitative analysis. We also demonstrate that InterMix is more robust towards adversarial attacks compared to standard learning and other mixup strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                }
            ]
        },
        {
            "paperId": "05c606a78474da20cd92e79dd5395951bb17ad41",
            "title": "ADIMA: Abuse Detection In Multilingual Audio",
            "abstract": "Abusive content detection in spoken text can be addressed by performing Automatic Speech Recognition (ASR) and leveraging advancements in natural language processing. However, ASR models introduce latency and often perform sub-optimally for abusive words as they are underrepresented in training corpora and not spoken clearly or completely. Exploration of this problem entirely in the audio domain has largely been limited by the lack of audio datasets. Building on these challenges, we propose ADIMA, a novel, linguistically diverse, ethically sourced, expert annotated and well- balanced multilingual abuse detection audio dataset comprising of 11,775 audio samples in 10 Indic languages spanning 65 hours and spoken by 6,446 unique users. Through quantitative experiments across monolingual and cross-lingual zeroshot settings, we take the first step in democratizing audio based content moderation in Indic languages and set forth our dataset to pave future work. Dataset and code are available at: https://github.com/ShareChatAI/Adima",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1838218557",
                    "name": "Vikram Gupta"
                },
                {
                    "authorId": "51260131",
                    "name": "Rini A. Sharon"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1766159",
                    "name": "Debdoot Mukherjee"
                }
            ]
        },
        {
            "paperId": "1cec3e33185a7c7e4f60cb85278320321facbc7a",
            "title": "PISA: PoIncar\u00e9 Saliency-Aware Interpolative Augmentation",
            "abstract": "Saliency-aware portion-wise mixup has proven to be an effective data augmentation technique for different modalities and tasks. However, it involves calculating the saliency over gradient vectors in the Euclidean space, representations that often possess complicated geometries and inherent hierarchical structure. We propose PISA, saliency-aware interpolative regularization operating in the hyperbolic space, to better capture the complex geometries of representations. To this end, we also formulate a saliency-aware mixup for speech signals. PISA outperforms existing state-of-the-art interpolative augmentation methods on 7 benchmark and low-resource datasets from the domains of speech signal processing and computer vision. PISA results in more stable training than existing data augmentation methods while being robust to adversarial attacks. It can be generalized across modalities, models and downstream tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2069609589",
                    "name": "Vishwa Shah"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "144582538",
                    "name": "Vasu Sharma"
                },
                {
                    "authorId": "1699159",
                    "name": "Dinesh Manocha"
                }
            ]
        }
    ]
}