{
    "authorId": "1801481",
    "papers": [
        {
            "paperId": "5ee5ac4b15be11e06b1703ce2d25f4d368a7eea0",
            "title": "Cross-View Representation Learning: A Superior ContextIB Method for Logo Classification",
            "abstract": "Logo classification systems have become increasingly important in various industries for tasks, such as infringement detection and industrial production. However, challenges still exist in logo classification due to real-world image background interference, the high similarity between classes, labeling difficulties, and the insufficient representation of occlusion in single-view logos. Many existing algorithms fail to consider the data characteristics and the intrinsic information of multiple views, which limits their performance. To overcome these limitations, we developed a novel Cross-View Information Awareness Network (CVIA-Net) for logo classification. To differentiate between similar logo categories, the CVIA-Net novel learns context-shared features of the same category via a self-supervised way without labeled, which solves the problem of insufficient features due to occlusion. For single-view images, CVIA-Net establishes a \u201cbottleneck\u201d representation to address background interference. Extensive experiments on three datasets demonstrate that it outperforms state-of-the-art methods. The method is expected to advance the development of cross-view representation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152444314",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "2239159690",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "2280163903",
                    "name": "Zeyu Han"
                },
                {
                    "authorId": "9426828",
                    "name": "Meidan Lv"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                }
            ]
        },
        {
            "paperId": "207b751a04ac11a1976ddae9d8c63806fb0c098a",
            "title": "A Cross-direction Task Decoupling Network for Small Logo Detection",
            "abstract": "Logo detection plays an integral role in many applications. However, handling small logos is still difficult since they occupy too few pixels in the image, which burdens the extraction of discriminative features. The aggregation of small logos also brings a great challenge to the classification and localization of logos. To solve these problems, we creatively propose Cross-direction Task Decoupling Network (CTDNet) for small logo detection. We first introduce Cross-direction Feature Pyramid (CFP) to realize cross-direction feature fusion by adopting horizontal transmission and vertical transmission. In addition, Multi-frequency Task Decoupling Head (MTDH) decouples the classification and localization tasks into two branches. A multi-frequency attention convolution branch is designed to achieve more accurate regression by combining discrete cosine transform and convolution creatively. Comprehensive experiments on four logo datasets demonstrate the effectiveness and efficiency of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "115820999",
                    "name": "Xingzhuo Li"
                },
                {
                    "authorId": "2366119",
                    "name": "Weiqing Min"
                },
                {
                    "authorId": "2138211402",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2152444314",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "1696610",
                    "name": "Shuqiang Jiang"
                }
            ]
        },
        {
            "paperId": "6690a2a34ada19563e238643fc48815b0f1f1a4d",
            "title": "Long-Range Dependence Involutional Network for Logo Detection",
            "abstract": "Logo detection is one of the crucial branches in computer vision due to various real-world applications, such as automatic logo detection and recognition, intelligent transportation, and trademark infringement detection. Compared with traditional handcrafted-feature-based methods, deep learning-based convolutional neural networks (CNNs) can learn both low-level and high-level image features. Recent decades have witnessed the great feature representation capabilities of deep CNNs and their variants, which have been very good at discovering intricate structures in high-dimensional data and are thereby applicable to many domains including logo detection. However, logo detection remains challenging, as existing detection methods cannot solve well the problems of a multiscale and large aspect ratios. In this paper, we tackle these challenges by developing a novel long-range dependence involutional network (LDI-Net). Specifically, we designed a strategy that combines a new operator and a self-attention mechanism via rethinking the intrinsic principle of convolution called long-range dependence involution (LD involution) to alleviate the detection difficulties caused by large aspect ratios. We also introduce a multilevel representation neural architecture search (MRNAS) to detect multiscale logo objects by constructing a novel multipath topology. In addition, we implemented an adaptive RoI pooling module (ARM) to improve detection efficiency by addressing the problem of logo deformation. Comprehensive experiments on four benchmark logo datasets demonstrate the effectiveness and efficiency of the proposed approach.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "115820999",
                    "name": "Xingzhuo Li"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "2155711470",
                    "name": "Baisong Zhang"
                },
                {
                    "authorId": "2152444314",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "1783497",
                    "name": "Weikuan Jia"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                }
            ]
        },
        {
            "paperId": "8580a9d1e759756ee7dbd59e6a31a2cc156942c3",
            "title": "Lightweight Seizure Detection Based on Multi-Scale Channel Attention",
            "abstract": "Epilepsy is one kind of neurological disease characterized by recurring seizures. Recurrent seizures can cause ongoing negative mental and cognitive damage to the patient. Therefore, timely diagnosis and treatment of epilepsy are crucial for patients. Manual electroencephalography (EEG) signals analysis is time and energy consuming, making automatic detection using EEG signals particularly important. Many deep learning algorithms have thus been proposed to detect seizures. These methods rely on expensive and bulky hardware, which makes them unsuitable for deployment on devices with limited resources due to their high demands on computer resources. In this paper, we propose a novel lightweight neural network for seizure detection using pure convolutions, which is composed of inverted residual structure and multi-scale channel attention mechanism. Compared with other methods, our approach significantly reduces the computational complexity, making it possible to deploy on low-cost portable devices for seizures detection. We conduct experiments on the CHB-MIT dataset and achieves 98.7% accuracy, 98.3% sensitivity and 99.1% specificity with 2.68[Formula: see text]M multiply-accumulate operations (MACs) and only 88[Formula: see text]K parameters.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2243360852",
                    "name": "Ziwei Wang"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "2174196178",
                    "name": "Tiantian Xiao"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2064715053",
                    "name": "Hongbin Lv"
                },
                {
                    "authorId": "2243299492",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2243682982",
                    "name": "Shanshan Zhao"
                },
                {
                    "authorId": "2235836401",
                    "name": "Yanna Zhao"
                }
            ]
        },
        {
            "paperId": "e2d48f1941ca60f80157c9d769aa2594fa1fdf90",
            "title": "A Decoupled Cross-layer Fusion Network with Bidirectional Guidance for Detecting Small Logos",
            "abstract": "Logo detection involves the use of machine learning algorithms to recognize and locate logos in images and videos, which has applications in a wide range of industries, including e-commerce, advertising, and entertainment. However, detecting small logos is still a challenging task due to their limited coverage of pixels and unclear details resulting in insufficient feature information for detection. Therefore, they are often easily confused by complex backgrounds and have lower perturbation tolerance to the bounding box, making them more difficult to detect compared to medium and large-scale logos. To address this problem, we propose a Decoupled Cross-layer Fusion Network (DCFNet) that enhances the feature representation of small logo objects, resulting in excellent detection performance. Specifically, the proposed DCFNet first adopts a bidirectional cross-layer connection mechanism to capture complementary information between different layers. Next, a two-phase feature averaging and enhancement strategy is used to further enhance the features. In the detection phase, DCFNet decouples the classification and boundary box regression branches into two identical Fully Connected (FC) heads, improving the accuracy of small logo classification and localization by avoiding mutual interference between the branches. Extensive experiments conducted on three publicly available logo datasets demonstrate that DCFNet achieves state-of-the-art performance in detecting small logos.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2277419590",
                    "name": "Songhui Zhao"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "2155711470",
                    "name": "Baisong Zhang"
                }
            ]
        },
        {
            "paperId": "76603da46e5da7ef3c37c57ed5b8319f00d7b2e4",
            "title": "Deep Learning for Logo Detection: A Survey",
            "abstract": "Logo detection has gradually become a research hotspot in the field of computer vision and multimedia for its various applications, such as social media monitoring, intelligent transportation, and video advertising recommendation. Recent advances in this area are dominated by deep learning-based solutions, where many datasets, learning strategies, network architectures, and loss functions have been employed. This article reviews the advance in applying deep learning techniques to logo detection. First, we discuss a comprehensive account of public datasets designed to facilitate performance evaluation of logo detection algorithms, which tend to be more diverse, more challenging, and more reflective of real life. Next, we perform an in-depth analysis of the existing logo detection strategies and their strengths and weaknesses of each learning strategy. Subsequently, we summarize the applications of logo detection in various fields, from intelligent transportation and brand monitoring to copyright and trademark compliance. Finally, we analyze the potential challenges and present the future directions for the development of logo detection. This study aims better to inform readers about the current state of logo detection and encourage more researchers to get involved in logo detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "2144485931",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2366119",
                    "name": "Weiqing Min"
                },
                {
                    "authorId": "2061437098",
                    "name": "Qiang Hou"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "1696610",
                    "name": "Shuqiang Jiang"
                }
            ]
        },
        {
            "paperId": "add8b09baa0a4409174f0ab20f4db8628606d02a",
            "title": "Image Matting With Deep Gaussian Process",
            "abstract": "We observe a common characteristic between the classical propagation-based image matting and the Gaussian process (GP)-based regression. The former produces closer alpha matte values for pixels associated with a higher affinity, while the outputs regressed by the latter are more correlated for more similar inputs. Based on this observation, we reformulate image matting as GP and find that this novel matting-GP formulation results in a set of attractive properties. First, it offers an alternative view on and approach to propagation-based image matting. Second, an application of kernel learning in GP brings in a novel deep matting-GP technique, which is pretty powerful for encapsulating the expressive power of deep architecture on the image relative to its matting. Third, an existing scalable GP technique can be incorporated to further reduce the computational complexity to $\\mathcal {O}(n)$ from $\\mathcal {O}(n^{3})$ of many conventional matting propagation techniques. Our deep matting-GP provides an attractive strategy toward addressing the limit of widespread adoption of deep learning techniques to image matting for which a sufficiently large labeled dataset is lacking. A set of experiments on both synthetically composited images and real-world images show the superiority of the deep matting-GP to not only the classical propagation-based matting techniques but also modern deep learning-based approaches.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "2127091871",
                    "name": "Yunshuai Yang"
                },
                {
                    "authorId": "40560668",
                    "name": "Tongtong Che"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "2158104496",
                    "name": "Wenhui Huang"
                },
                {
                    "authorId": "2129537250",
                    "name": "Yue Gao"
                },
                {
                    "authorId": "2091428716",
                    "name": "Ping Tan"
                }
            ]
        },
        {
            "paperId": "3ba2a855aa10d63f54a80e533ffcef6dc8a1b13e",
            "title": "Cross-View Representation Learning for Multi-View Logo Classification with Information Bottleneck",
            "abstract": "Multi-view logo classification is a challenging task due to the cross-view misalignment of logo image varies under different viewpoints, large intra-classes and small inter-classes variation of logo appearance. Cross-view data can represent objects from different views and thus provide complementary information for data analysis. However, most existing multi-view algorithms usually maximize the correlation between different views for consistency. Those methods ignore the interaction among different views and may cause semantic bias during the process of common feature learning. In this paper, we investigate the information bottleneck (IB) to the multi-view learning for extracting the different view common features of one category, named Dual-View Information Bottleneck representation (Dual-view IB). To the best of our knowledge, this is the first cross-view learning method for logo classification. Specifically, we maximize the mutual information between the representations of the two views to achieve the preservation of key features in the classification task, while eliminating the redundant information that is not shared between the two views. In addition, due to the unbalance of samples and limited computing resources, we further introduce a novel Pair Batch Data Augmentation (PB) algorithm for Dual-view IB model, which applies augmentations from a learned policy based on replicates instances of two samples within the same batch. Comprehensive experiments on three existing benchmark datasets, which demonstrate the effectiveness of the proposed method that outperforms the methods in the state of the art. The proposed method is expected to further the development of cross-view representation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152444314",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "3483503",
                    "name": "Jingqi Song"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                }
            ]
        },
        {
            "paperId": "968d57e0d772fda69dda674084c31039836b2d8d",
            "title": "Exploiting Probabilistic Siamese Visual Tracking with a Conditional Variational Autoencoder",
            "abstract": "Visual tracking is a fundamental capability for robots tasked with humans and environment interaction. However, state-of-the-art visual tracking methods are still prone to failures and are imprecise when applied to challenging stereos, and their results are generally confidence agonistic. These methods depend on an embedded deep learning model to provide deterministic features or regression maps. A deterministic output with low confidence can result in disastrous consequences and lacks evidence needed for subsequent operations. Moreover, training data ambiguities or noise in the observations (so-called data uncertainty) can also lead to inherent uncertainty. In this paper, we focus on exploiting probabilistic Siamese visual tracking with a conditional variational autoencoder (CVAE). First, we build a bridge between the Siamese architecture and the CVAE and propose a novel Bayesian visual tracking method. Second, the proposed method generates a complete probability distribution that enables the production of multiple plausible tracking outputs. Third, CVAE conditioned by ground truth data encodes a low-dimensional latent space and conducts noise-injection training to prevent overfitting. Our proposed tracking method outperformed the state-of-the-art trackers on the VOT2016, VOT2018 and TColor-128 datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50526223",
                    "name": "Wenhui Huang"
                },
                {
                    "authorId": "1410508575",
                    "name": "J. Gu"
                },
                {
                    "authorId": "49529511",
                    "name": "Peiyong Duan"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                }
            ]
        },
        {
            "paperId": "ad03ebbf02909caaa60a6f6974ad6fd4797e0073",
            "title": "FoodLogoDet-1500: A Dataset for Large-Scale Food Logo Detection via Multi-Scale Feature Decoupling Network",
            "abstract": "Food logo detection plays an important role in the multimedia for its wide real-world applications, such as food recommendation of the self-service shop and infringement detection on e-commerce platforms. A large-scale food logo dataset is urgently needed for developing advanced food logo detection algorithms. However, there are no available food logo datasets with food brand information. To support efforts towards food logo detection, we introduce the dataset FoodLogoDet-1500, a new large-scale publicly available food logo dataset, which has 1,500 categories, about 100,000 images and about 150,000 manually annotated food logo objects. We describe the collection and annotation process of FoodLogoDet-1500, analyze its scale and diversity, and compare it with other logo datasets. To the best of our knowledge, FoodLogoDet-1500 is the first largest publicly available high-quality dataset for food logo detection. The challenge of food logo detection lies in the large-scale categories and similarities between food logo categories. For that, we propose a novel food logo detection method Multi-scale Feature Decoupling Network (MFDNet), which decouples classification and regression into two branches and focuses on the classification branch to solve the problem of distinguishing multiple food logo categories. Specifically, we introduce the feature offset module, which utilizes the deformation-learning for optimal classification offset and can effectively obtain the most representative features of classification in detection. In addition, we adopt a balanced feature pyramid in MFDNet, which pays attention to global information, balances the multi-scale feature maps, and enhances feature extraction capability. Comprehensive experiments on FoodLogoDet-1500 and other two popular benchmark logo datasets demonstrate the effectiveness of the proposed method. The code and FoodLogoDet-1500 can be found at https://github.com/hq03/FoodLogoDet-1500-Dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2061437098",
                    "name": "Qiang Hou"
                },
                {
                    "authorId": "2366119",
                    "name": "Weiqing Min"
                },
                {
                    "authorId": "2152444314",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "1696610",
                    "name": "Shuqiang Jiang"
                }
            ]
        }
    ]
}