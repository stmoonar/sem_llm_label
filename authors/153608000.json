{
    "authorId": "153608000",
    "papers": [
        {
            "paperId": "7ea5e86bbbcc445eca1a765deb314eefc06067b8",
            "title": "Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts",
            "abstract": "As large language models (LLMs) become increasingly prevalent across many real-world applications, understanding and enhancing their robustness to adversarial attacks is of paramount importance. Existing methods for identifying adversarial prompts tend to focus on specific domains, lack diversity, or require extensive human annotations. To address these limitations, we present Rainbow Teaming, a novel black-box approach for producing a diverse collection of adversarial prompts. Rainbow Teaming casts adversarial prompt generation as a quality-diversity problem, and uses open-ended search to generate prompts that are both effective and diverse. Focusing on the safety domain, we use Rainbow Teaming to target various state-of-the-art LLMs, including the Llama 2 and Llama 3 models. Our approach reveals hundreds of effective adversarial prompts, with an attack success rate exceeding 90% across all tested models. Furthermore, we demonstrate that fine-tuning models with synthetic data generated by the Rainbow Teaming method significantly enhances their safety without sacrificing general performance or helpfulness. We additionally explore the versatility of Rainbow Teaming by applying it to question answering and cybersecurity, showcasing its potential to drive robust open-ended self-improvement in a wide range of applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49089678",
                    "name": "Mikayel Samvelyan"
                },
                {
                    "authorId": "1498636613",
                    "name": "S. Raparthy"
                },
                {
                    "authorId": "2266838640",
                    "name": "Andrei Lupu"
                },
                {
                    "authorId": "2072738644",
                    "name": "Eric Hambro"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "2287831915",
                    "name": "Manish Bhatt"
                },
                {
                    "authorId": "2287961720",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "2152154941",
                    "name": "Minqi Jiang"
                },
                {
                    "authorId": "1410302742",
                    "name": "Jack Parker-Holder"
                },
                {
                    "authorId": "2284689613",
                    "name": "Jakob Foerster"
                },
                {
                    "authorId": "1389854357",
                    "name": "Tim Rocktaschel"
                },
                {
                    "authorId": "48647153",
                    "name": "Roberta Raileanu"
                }
            ]
        },
        {
            "paperId": "1570288d450a5541994a8557dda201a1b492a698",
            "title": "Confusing Large Models by Confusing Small Models",
            "abstract": "Despite a steady growth in average accuracy, computer vision models continue to fail on many robustness benchmarks. In this paper, we take a step back from standard benchmarks and focus on how models perceive data, and which aspects of the data they find confusing. Using an ensemble-based confusion score we examine how the training and test samples appear simple or confusing to a given model. Based on these heuristics, we demonstrate an application of the confusion score in identifying images that appear confusing to the trained model, and show that these images are highly likely to be misclassified by the model. We further demonstrate how confusion carries over to models of various sizes and architectures, which gives rise to the possibility of identifying challenging images via ensembles of small networks to produce a custom benchmark of challenging data, that remains appropriate for large models where ensembling is costly to implement. Finally, we demonstrate how training via upsampling on confusing images can improve accuracy on the hard subset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276523714",
                    "name": "V\u00edtor Albiero"
                },
                {
                    "authorId": "2276523302",
                    "name": "Raghav Mehta"
                },
                {
                    "authorId": "2264288587",
                    "name": "Ivan Evtimov"
                },
                {
                    "authorId": "2276525095",
                    "name": "Samuel J. Bell"
                },
                {
                    "authorId": "2253337895",
                    "name": "Levent Sagun"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                }
            ]
        },
        {
            "paperId": "ac22cc27b83a504cd4ab0de546dcb68786f692ce",
            "title": "Using Captum to Explain Generative Language Models",
            "abstract": "Captum is a comprehensive library for model explainability in PyTorch, offering a range of methods from the interpretability literature to enhance users\u2019 understanding of PyTorch models. In this paper, we introduce new features in Captum that are specifically designed to analyze the behavior of generative language models. We provide an overview of the available functionalities and example applications of their potential for understanding learned associations within generative language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7401089",
                    "name": "Vivek Miglani"
                },
                {
                    "authorId": "2269467670",
                    "name": "Aobo Yang"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "2269456985",
                    "name": "Diego Garcia-Olano"
                },
                {
                    "authorId": "3281905",
                    "name": "Narine Kokhlikyan"
                }
            ]
        },
        {
            "paperId": "fbfb37a8d044a874a756550ca9eb02f5a079d1c9",
            "title": "Identifying and Disentangling Spurious Features in Pretrained Image Representations",
            "abstract": "Neural networks employ spurious correlations in their predictions, resulting in decreased performance when these correlations do not hold. Recent works suggest fixing pretrained representations and training a classification head that does not use spurious features. We investigate how spurious features are represented in pretrained representations and explore strategies for removing information about spurious features. Considering the Waterbirds dataset and a few pretrained representations, we find that even with full knowledge of spurious features, their removal is not straightforward due to entangled representation. To address this, we propose a linear autoencoder training method to separate the representation into core, spurious, and other features. We propose two effective spurious feature removal approaches that are applied to the encoding and significantly improve classification performance measured by worst group accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "92516121",
                    "name": "R. Darbinyan"
                },
                {
                    "authorId": "144787340",
                    "name": "Hrayr Harutyunyan"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "1388829897",
                    "name": "Hrant Khachatrian"
                }
            ]
        },
        {
            "paperId": "3b1ada4bbe70615027d6e54c758c82a83111276b",
            "title": "Tell Your Story: Task-Oriented Dialogs for Interactive Content Creation",
            "abstract": "People capture photos and videos to relive and share memories of personal significance. Recently, media montages (stories) have become a popular mode of sharing these memories due to their intuitive and powerful storytelling capabilities. However, creating such montages usually involves a lot of manual searches, clicks, and selections that are time-consuming and cumbersome, adversely affecting user experiences. To alleviate this, we propose task-oriented dialogs for montage creation as a novel interactive tool to seamlessly search, compile, and edit montages from a media collection. To the best of our knowledge, our work is the first to leverage multi-turn conversations for such a challenging application, extending the previous literature studying simple media retrieval tasks. We collect a new dataset C3 (Conversational Content Creation), comprising 10k dialogs conditioned on media montages simulated from a large media collection. We take a simulate-and-paraphrase approach to collect these dialogs to be both cost and time efficient, while drawing from natural language distribution. Our analysis and benchmarking of state-of-the-art language models showcase the multimodal challenges present in the dataset. Lastly, we present a real-world mobile demo application that shows the feasibility of the proposed work in real-world applications. Our code and data will be made publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150275",
                    "name": "Satwik Kottur"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "2187300386",
                    "name": "Hardik Shah"
                },
                {
                    "authorId": "3057557",
                    "name": "Babak Damavandi"
                },
                {
                    "authorId": "1979505",
                    "name": "A. Geramifard"
                }
            ]
        },
        {
            "paperId": "8b293973061026d9d0eed90e71e30928e029171e",
            "title": "Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models",
            "abstract": "Despite their wide adoption, the underlying training and memorization dynamics of very large language models is not well understood. We empirically study exact memorization in causal and masked language modeling, across model sizes and throughout the training process. We measure the effects of dataset size, learning rate, and model size on memorization, finding that larger language models memorize training data faster across all settings. Surprisingly, we show that larger models can memorize a larger portion of the data before over-fitting and tend to forget less throughout the training process. We also analyze the memorization dynamics of different parts of speech and find that models memorize nouns and numbers first; we hypothesize and provide empirical evidence that nouns and numbers act as a unique identifier for memorizing individual training examples. Together, these findings present another piece of the broader puzzle of trying to understand what actually improves as models get bigger.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2551387",
                    "name": "Kushal Tirumala"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "1982950",
                    "name": "Luke Zettlemoyer"
                },
                {
                    "authorId": "2201435",
                    "name": "Armen Aghajanyan"
                }
            ]
        },
        {
            "paperId": "b5717fa14bf0c832651c23a68bfe949e7b129005",
            "title": "Distributed Memory Futures for Compile-Time, Deterministic-by-Default Concurrency in Distributed C++ Applications",
            "abstract": "Futures are a widely-used abstraction for enabling deferred execution in imperative programs. Deferred execution enqueues tasks rather than explicitly blocking and waiting for them to execute. Many task-based programming models with some form of deferred execution rely on explicit parallelism that is the responsibility of the programmer. Deterministic-by-default (implicitly parallel) models instead use data effects to derive concurrency automatically, alleviating the burden of concurrency management. Both implicitly and explicitly parallel models are particularly challenging for imperative object-oriented programming. Fine-granularity parallelism across member functions or amongst data members may exist, but is often ignored. In this work, we define a general permissions model that leverages the C++ type system and move semantics to define an asynchronous programming model embedded in the C++ type system. Although a default distributed memory semantic is provided, the concurrent semantics are entirely configurable through C++ constexpr integers. Correct use of the defined semantic is verified at compile-time, allowing deterministic-by-default concurrency to be safely added to applications. Here we demonstrate the use of these ``extended futures'' for distributed memory asynchronous communication and load balancing. An MPI particle in-cell application is modified with the wrapper class using this task model, with results presented for a Haswell system up to 64 nodes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3312441",
                    "name": "Jeremiah J. Wilke"
                },
                {
                    "authorId": "1863450",
                    "name": "D. Hollman"
                },
                {
                    "authorId": "2083000908",
                    "name": "Cannada Lewis"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "72097188",
                    "name": "Nicolas Morals"
                }
            ]
        },
        {
            "paperId": "d7a5a64888bff4b3e953e3631a7619cbd8e98409",
            "title": "Performance Portabile Multi-Species Plasma Code*",
            "abstract": "The emergence of high concurrency architectures like GPUs, Intel Phi, and multi-core CPUs necessitates reconsideration of many of the algorithms used to simulate plasmas. We have undertaken the development of a multi-species plasma application using both the multi-fluid and particle-in-cell (PIC) representations of the plasma. The simulation of these plasmas on next-generation hardware is encompassed in the EMPIRE code suite, an open source software suite built off Trilinos/Drekar/mini-PIC tools.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34868255",
                    "name": "M. Bettencourt"
                },
                {
                    "authorId": "2248745268",
                    "name": "Janine Bennett"
                },
                {
                    "authorId": "144039567",
                    "name": "E. Cyr"
                },
                {
                    "authorId": "144814405",
                    "name": "R. Kramer"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "47504051",
                    "name": "C. Moore"
                },
                {
                    "authorId": "3071278",
                    "name": "R. Pawlowski"
                },
                {
                    "authorId": "1903214",
                    "name": "E. Phillips"
                },
                {
                    "authorId": "31219802",
                    "name": "A. Robinson"
                },
                {
                    "authorId": "1714795",
                    "name": "J. Shadid"
                }
            ]
        },
        {
            "paperId": "f94142027f4ee7ce339d64ea006710a03e2fdb72",
            "title": "ASC ATDM Level 2 Milestone #6015: Asynchronous Many-Task Software Stack Demonstration.",
            "abstract": "This report is an outcome of the ASC ATDM Level 2 Milestone 6015: Asynchronous Many-Task Software Stack Demonstration. It comprises a summary and in depth analysis of DARMA and a DARMA-compliant Asynchronous Many-Task (AMT) runtime software stack. Herein performance and productivity of the overall approach are assessed on benchmarks and proxy applications representative of the Sandia ATDM applications. As part of the effort to assess the perceived strengths and weaknesses of AMT models compared to more traditional methods, experiments were performed on ATS-1 (Advanced Technology Systems) test bed machines and Trinity. In addition to productivity and performance assessments, this report includes findings on the generality of DARMA\u2019s backend API as well as findings on interoperability with nodelevel and network-level system libraries. Together, this information provides a clear understanding of the strengths and limitations of the DARMA approach in the context of Sandia\u2019s ATDM codes, to guide our future research and development in this area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2248745268",
                    "name": "Janine Bennett"
                },
                {
                    "authorId": "34868255",
                    "name": "M. Bettencourt"
                },
                {
                    "authorId": "4502006",
                    "name": "R. Clay"
                },
                {
                    "authorId": "50819217",
                    "name": "H. Edwards"
                },
                {
                    "authorId": "32638014",
                    "name": "M. W. Glass"
                },
                {
                    "authorId": "1863450",
                    "name": "D. Hollman"
                },
                {
                    "authorId": "1963481",
                    "name": "H. Kolla"
                },
                {
                    "authorId": "2795047",
                    "name": "J. Lifflander"
                },
                {
                    "authorId": "145991867",
                    "name": "D. Littlewood"
                },
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                },
                {
                    "authorId": "10985545",
                    "name": "S. Moore"
                },
                {
                    "authorId": "2216287",
                    "name": "Stephen L. Olivier"
                },
                {
                    "authorId": "1728252",
                    "name": "E. Phipps"
                },
                {
                    "authorId": "2783747",
                    "name": "F. Rizzi"
                },
                {
                    "authorId": "2440073",
                    "name": "N. Slattengren"
                },
                {
                    "authorId": "34006174",
                    "name": "Daniel Sunderland"
                },
                {
                    "authorId": "3312441",
                    "name": "Jeremiah J. Wilke"
                }
            ]
        },
        {
            "paperId": "28cf2cc65c6dc1f9819ba8fba5c2cee4ec609408",
            "title": "Modeling multiple time scales in streamer discharges",
            "abstract": "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153608000",
                    "name": "Aram H. Markosyan"
                }
            ]
        }
    ]
}