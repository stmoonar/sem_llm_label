{
    "authorId": "31329752",
    "papers": [
        {
            "paperId": "3eb0ecb3ad7432447af87e072b0ae812bdc52a80",
            "title": "Overview of the CLEF-2023 CheckThat! Lab Task 1 on Check-Worthiness in Multimodal and Multigenre Content",
            "abstract": "We present an overview of CheckThat! Lab\u2019s 2023 Task 1, which is part of CLEF-2023. Task 1 asks to determine whether a text item, or a text coupled with an image, is check-worthy. This task places a special emphasis on COVID-19, political debates and transcriptions, and it is conducted in three languages: Arabic, English, and Spanish. A total of 15 teams participated, and most submissions managed to achieve significant improvements over the baselines using Transformer-based models. Out of these, seven teams participated in the multimodal subtask (1A), and 12 teams participated in the Multigenre subtask (1B), collectively submitting 155 official runs for both subtasks. Across both subtasks, approaches that targeted multiple languages, either individually or in conjunction, generally achieved the best performance. We provide a description of the dataset and the task setup, including the evaluation settings, and we briefly overview the participating systems. As is customary in the CheckThat! lab, we have release all datasets from the lab as well as the evaluation scripts to the research community. This will enable further research on finding relevant check-worthy content that can assist various stakeholders such as fact-checkers, journalists, and policymakers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257274157",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "39866663",
                    "name": "Gullal S. Cheema"
                },
                {
                    "authorId": "3376145",
                    "name": "Gautam Kishore Shahi"
                },
                {
                    "authorId": "2079305",
                    "name": "Sherzod Hakimov"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2241675070",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "b91bcadc6227f7d61e406bb6957850231733442e",
            "title": "Factuality Challenges in the Era of Large Language Models",
            "abstract": "The emergence of tools based on Large Language Models (LLMs), such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard, has garnered immense public attention. These incredibly useful, natural-sounding tools mark significant advances in natural language generation, yet they exhibit a propensity to generate false, erroneous, or misleading content -- commonly referred to as\"hallucinations.\"Moreover, LLMs can be exploited for malicious applications, such as generating false but credible-sounding content and profiles at scale. This poses a significant challenge to society in terms of the potential deception of users and the increasing dissemination of inaccurate information. In light of these risks, we explore the kinds of technological innovations, regulatory reforms, and AI literacy initiatives needed from fact-checkers, news organizations, and the broader research and policy communities. By identifying the risks, the imminent threats, and some viable solutions, we seek to shed light on navigating various aspects of veracity in the era of generative AI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256988818",
                    "name": "Isabelle Augenstein"
                },
                {
                    "authorId": "2256987318",
                    "name": "Timothy Baldwin"
                },
                {
                    "authorId": "2284591948",
                    "name": "Meeyoung Cha"
                },
                {
                    "authorId": "2256999352",
                    "name": "Tanmoy Chakraborty"
                },
                {
                    "authorId": "1683012",
                    "name": "Giovanni Luca Ciampaglia"
                },
                {
                    "authorId": "2256993500",
                    "name": "David Corney"
                },
                {
                    "authorId": "2256999256",
                    "name": "Renee DiResta"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                },
                {
                    "authorId": "2256997151",
                    "name": "Scott Hale"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2256998951",
                    "name": "Eduard H. Hovy"
                },
                {
                    "authorId": "2257003221",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2268194233",
                    "name": "Filippo Menczer"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2994143",
                    "name": "Dietram A. Scheufele"
                },
                {
                    "authorId": "1491627343",
                    "name": "Shivam Sharma"
                },
                {
                    "authorId": "2256998588",
                    "name": "Giovanni Zagni"
                }
            ]
        },
        {
            "paperId": "2a75cf81f1cafbcdc99d15467bdd4b8fca9a6902",
            "title": "Overview of the CLEF-2022 CheckThat! Lab Task 1 on Identifying Relevant Claims in Tweets",
            "abstract": "We present an overview of CheckThat! lab 2022 Task 1, part of the 2022 Conference and Labs of the Evaluation Forum (CLEF). Task 1 asked to predict which posts in a Twitter stream are worth fact-checking, focusing on COVID-19 and politics in six languages: Arabic, Bulgarian, Dutch, English, Spanish, and Turkish. A total of 19 teams participated and most submissions managed to achieve sizable improvements over the baselines using Transformer-based models such as BERT and GPT-3. Across the four subtasks, approaches that targetted multiple languages (be it individually or in conjunction, in general obtained the best performance. We describe the dataset and the task setup, including the evaluation settings, and we give a brief overview of the participating systems. As usual in the CheckThat! lab, we release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research on finding relevant tweets that can help different stakeholders such as fact-checkers, journalists, and policymakers. \u00a9 2022 Copyright for this paper by its authors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "1864635",
                    "name": "Tommaso Caselli"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "65877664",
                    "name": "Shaden Shaar"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "47195288",
                    "name": "Alex Nikolov"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                }
            ]
        },
        {
            "paperId": "069cff8081de01bd9210b00677b77f9d0b2c869c",
            "title": "Overview of the CLEF-2021 CheckThat! Lab Task 1 on Check-Worthiness Estimation in Tweets and Political Debates",
            "abstract": "We present an overview of Task 1 of the fourth edition of the CheckThat! Lab, part of the 2021 Conference and Labs of the Evaluation Forum (CLEF). The task asks to predict which posts in a Twitter stream are worth fact-checking, focusing on COVID-19 and politics in five languages: Arabic, Bulgarian, English, Spanish, and Turkish. A total of 15 teams participated in this task and most submissions managed to achieve sizable improvements over the baselines using Transformer-based models such as BERT and RoBERTa. Here, we describe the process of data collection and the task setup, including the evaluation measures, and we give a brief overview of the participating systems. We release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research in check-worthiness estimation for tweets and political debates. \u00a9 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121286474",
                    "name": "S. Shaar"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2065206121",
                    "name": "Bayan Hamdan"
                },
                {
                    "authorId": "151267539",
                    "name": "Zien Sheikh Ali"
                },
                {
                    "authorId": "8685373",
                    "name": "Fatima Haouari"
                },
                {
                    "authorId": "47195288",
                    "name": "Alex Nikolov"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "2065257134",
                    "name": "Javier Beltr\u00e1n"
                },
                {
                    "authorId": "1693370300",
                    "name": "Tamer Elsayed"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "764335faadf30051dea7f6b3747498035f91d0f8",
            "title": "ClaimHunter: An Unattended Tool for Automated Claim Detection on Twitter",
            "abstract": "As political campaigns have moved from traditional media to social networks, fact-checkers must also adapt how they are working. The explosion of information (and disinformation) on social networks makes impossible to manually fact-check each piece of data. With this reality in mind, Newtral, a fact-checking organization, has developed its own automated monitor tool for Twitter: ClaimHunter. Recently, deep learning approaches have obtained very high performance across many different NLP tasks. Automated claim detection is not an exception. These models are showing promising results on fact-checking scenarios without task-specific feature engineering. Based on the BERT architecture, ClaimHunter AI models shown a 80% F1 score tested on real-life scenarios with expert fact-checkers. Through a simple UI interface deployed on Slack, ClaimHunter notifies journalists and gets feedback from their day-to-day work to improve the final performance of the algorithm. Launched 6 months ago, ClaimHunter has processed more than 130.000 tweets expanding Newtral\u2019s operation beyond national politicians to the regional and local level. The number of reviewed claims per day have increased by a multiplicative factor of 10 since the adoption of the ClaimHunter tool by Newtral\u2019s fact-checking team. This paper focuses on explaining the challenges of building such a system inside of a fact-checking organization: data labelling and fact-checker alignment, system architecture, testing and deployment of underlying models, continuous feedback and model refinement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065257134",
                    "name": "Javier Beltr\u00e1n"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "2159680958",
                    "name": "Irene Larraz"
                }
            ]
        },
        {
            "paperId": "d39e7f27c515b4cbe604e4c07efc8223fb90e8e3",
            "title": "Supporting High-quality Early Childhood Education Services throught ICTs",
            "abstract": "Nowadays early childhood schools are places where kids are not only taken care of but also where carefully planned educational activities (based on pedagogical frameworks) are carried out. In such centers, practitioners observe, analyze and assess children\u2019s progress on a daily basis. Using this data, they plan new stimulating activities for the kids taken into account their personal traits and competence level. This paper presents an ICT-based system that allows parents and practitioners collaborate and share their responsibility as children\u2019s educators both in classroom and home settings. Using a TV set as main access device, the parents can watch interactive training videos from the commodity of their living room, track child\u2019s progress, access to child\u2019s portfolio, receive recommendations of educational activities or add their own observations among other services. In such a way the system seeks to strengthen the home-school link, to enhance the overall quality in early childhood services and to create an educational community committed to the well-being and education of children.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "49397878",
                    "name": "Juan M. Santos"
                },
                {
                    "authorId": "9285011",
                    "name": "L. Anido"
                }
            ]
        }
    ]
}