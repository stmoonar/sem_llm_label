{
    "authorId": "2142708915",
    "papers": [
        {
            "paperId": "c52772edbbbc408fe864716a74b08e4e076c0966",
            "title": "Causal Distillation for Alleviating Performance Heterogeneity in Recommender Systems",
            "abstract": "Recommendation performance usually exhibits a long-tail distribution over users \u2014 a small portion of head users enjoy much more accurate recommendation services than the others. We reveal two sources of this performance heterogeneity problem: the uneven distribution of historical interactions (a natural source); and the biased training of recommender models (a model source). As addressing this problem cannot sacrifice the overall performance, a wise choice is to eliminate the model bias while maintaining the natural heterogeneity. The key to debiased training lies in eliminating the effect of confounders that influence both the user's historical behaviors and the next behavior. The emerging causal recommendation methods achieve this by modeling the causal effect between user behaviors, however potentially neglect unobserved confounders (e.g., friend suggestions) that are hard to measure in practice. To address unobserved confounders, we resort to the front-door adjustment (FDA) in causal theory and propose a causal multi-teacher distillation framework (CausalD). FDA requires proper mediators in order to estimate the causal effects of historical behaviors on the next behavior. To achieve this, we equip CausalD with multiple heterogeneous recommendation models to model the mediator distribution. Then, the causal effect estimated by FDA is the expectation of recommendation prediction over the mediator distribution and the prior distribution of historical behaviors, which is technically achieved by multi-teacher ensemble. To pursue efficient inference, CausalD further distills multiple teachers into one student model to directly infer the causal effect for making recommendations. We instantiate CausalD on two representative models, DeepFM and DIN, and conduct extensive experiments on three real-world datasets, which validate the superiority of CausalD over state-of-the-art methods. Through in-depth analysis, we find that CausalD largely improves the performance of tail users, reduces the performance heterogeneity, and enhances the overall performance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1739188006",
                    "name": "Shengyu Zhang"
                },
                {
                    "authorId": "2142708915",
                    "name": "Ziqi Jiang"
                },
                {
                    "authorId": "2110069725",
                    "name": "Jiangchao Yao"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2315590980",
                    "name": "Kun Kuang"
                },
                {
                    "authorId": "2187385241",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2222777391",
                    "name": "Shuo Li"
                },
                {
                    "authorId": "2145952806",
                    "name": "Hongxia Yang"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                },
                {
                    "authorId": "2110922423",
                    "name": "Fei Wu"
                }
            ]
        },
        {
            "paperId": "3e3b045c46d94b6ff99f53df138465ece09aedb3",
            "title": "Weakly-supervised Disentanglement Network for Video Fingerspelling Detection",
            "abstract": "Fingerspelling detection, which aims to localize and recognize fingerspelling gestures in raw, untrimmed videos, is a nascent but important research area that could help bridge the communication gap between deaf people and others. Many existing works tend to exploit additional knowledge, such as pose annotations, and newly datasets for performance improvement. However, in real-world applications, additional data collection and annotation require tremendous human efforts that are not always affordable. In this paper, we propose the Weakly-supervised Disentanglement Network, namely WED, that requires no additional knowledge, and better exploits the video-sentence weak supervisions. Specifically, WED incorporates two critical components: 1) Masked Disentanglement Module, which employs a Variational Autoencoder for signed letters disentanglement. Each latent factor in the VAE corresponds to a particular signed letter, and we mask latent factors corresponding to letters that do not appear in the video during decoding. Compared to the vanilla VAE, the masked reconstruction leverages the video-sentence weak supervision, leading to a better sign language oriented disentanglement; and 2) the Dynamic Memory Network module, which leverages the disentangled sign knowledge as prior knowledge and reference for sign-related frame identification and gesture recognition through a carefully designed memory reading component. We conduct extensive experiments on the benchmark ChicagoFSWild and ChicagoFSWild+ datasets. Empirical studies validate that the WED network achieves effective sign gesture disentanglement, contributing to the state-of-the-art performance for fingerspelling detection and recognition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142708915",
                    "name": "Ziqi Jiang"
                },
                {
                    "authorId": "1739188006",
                    "name": "Shengyu Zhang"
                },
                {
                    "authorId": "2067825436",
                    "name": "Siyuan Yao"
                },
                {
                    "authorId": "2108125912",
                    "name": "Wenqiao Zhang"
                },
                {
                    "authorId": "2108340144",
                    "name": "Sihan Zhang"
                },
                {
                    "authorId": "2108998895",
                    "name": "Juncheng Li"
                },
                {
                    "authorId": "47122432",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2110922423",
                    "name": "Fei Wu"
                }
            ]
        }
    ]
}