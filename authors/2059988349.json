{
    "authorId": "2059988349",
    "papers": [
        {
            "paperId": "5c206ef356d44ee88702dedc2672ba6a40c860b2",
            "title": "Helper Recommendation with seniority control in Online Health Community",
            "abstract": "Online health communities (OHCs) are forums where patients with similar conditions communicate their experiences and provide moral support. Social support in OHCs plays a crucial role in easing and rehabilitating patients. However, many time-sensitive questions from patients often remain unanswered due to the multitude of threads and the random nature of patient visits in OHCs. To address this issue, it is imperative to propose a recommender system that assists solution seekers in finding appropriate problem helpers. Nevertheless, developing a recommendation algorithm to enhance social support in OHCs remains an under-explored area. Traditional recommender systems cannot be directly adapted due to the following obstacles. First, unlike user-item links in traditional recommender systems, it is hard to model the social support behind helper-seeker links in OHCs since they are formed based on various heterogeneous reasons. Second, it is difficult to distinguish the impact of historical activities in characterizing patients. Third, it is significantly challenging to ensure that the recommended helpers possess sufficient expertise to assist the seekers. To tackle the aforementioned challenges, we develop a Monotonically regularIzed diseNTangled Variational Autoencoders (MINT) model to strengthen social support in OHCs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "83052400",
                    "name": "Junruo Gao"
                },
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2238138844",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "144000223",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "653b406e03cac1c03f38e47211c3156f7bbe2c2f",
            "title": "Deep Graph Representation Learning and Optimization for Influence Maximization",
            "abstract": "Influence maximization (IM) is formulated as selecting a set of initial users from a social network to maximize the expected number of influenced users. Researchers have made great progress in designing various traditional methods, and their theoretical design and performance gain are close to a limit. In the past few years, learning-based IM methods have emerged to achieve stronger generalization ability to unknown graphs than traditional ones. However, the development of learning-based IM methods is still limited by fundamental obstacles, including 1) the difficulty of effectively solving the objective function; 2) the difficulty of characterizing the diversified underlying diffusion patterns; and 3) the difficulty of adapting the solution under various node-centrality-constrained IM variants. To cope with the above challenges, we design a novel framework DeepIM to generatively characterize the latent representation of seed sets, and we propose to learn the diversified information diffusion pattern in a data-driven and end-to-end manner. Finally, we design a novel objective function to infer optimal seed sets under flexible node-centrality-based budget constraints. Extensive analyses are conducted over both synthetic and real-world datasets to demonstrate the overall performance of DeepIM. The code and data are available at: https://github.com/triplej0079/DeepIM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2157887017",
                    "name": "Junji Jiang"
                },
                {
                    "authorId": "2120473483",
                    "name": "Junxiang Wang"
                },
                {
                    "authorId": "1698253",
                    "name": "M. Thai"
                },
                {
                    "authorId": "2216002544",
                    "name": "Lukas Xue"
                },
                {
                    "authorId": "2216029466",
                    "name": "James Song"
                },
                {
                    "authorId": "1471335567",
                    "name": "M. Qiu"
                },
                {
                    "authorId": "144000223",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "75c08892179fc478f87d7020b5daff9fca4f3389",
            "title": "Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models",
            "abstract": "Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a \u201cchatbot\u201d, and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2117727751",
                    "name": "Jiaying Lu"
                },
                {
                    "authorId": "151483422",
                    "name": "Chengyuan Deng"
                },
                {
                    "authorId": "2182238045",
                    "name": "Can Zheng"
                },
                {
                    "authorId": "4142921",
                    "name": "Junxiang Wang"
                },
                {
                    "authorId": "2123930262",
                    "name": "Tanmoy Chowdhury"
                },
                {
                    "authorId": "2110425042",
                    "name": "Yun-Qing Li"
                },
                {
                    "authorId": "2112821580",
                    "name": "Hejie Cui"
                },
                {
                    "authorId": "2211987764",
                    "name": "Tian-yu Zhao"
                },
                {
                    "authorId": "2218486790",
                    "name": "Amit Panalkar"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": null,
                    "name": "Haoyu Wang"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "1766853",
                    "name": "Zhengzhang Chen"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2218495127",
                    "name": "Chris White"
                },
                {
                    "authorId": "9937103",
                    "name": "Quanquan Gu"
                },
                {
                    "authorId": "1390553618",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "8b97b25a0825b84feebe1b34968a8144bf5acdf0",
            "title": "Knowledge-enhanced Neural Machine Reasoning: A Review",
            "abstract": "Knowledge-enhanced neural machine reasoning has garnered significant attention as a cutting-edge yet challenging research area with numerous practical applications. Over the past few years, plenty of studies have leveraged various forms of external knowledge to augment the reasoning capabilities of deep models, tackling challenges such as effective knowledge integration, implicit knowledge mining, and problems of tractability and optimization. However, there is a dearth of a comprehensive technical review of the existing knowledge-enhanced reasoning techniques across the diverse range of application domains. This survey provides an in-depth examination of recent advancements in the field, introducing a novel taxonomy that categorizes existing knowledge-enhanced methods into two primary categories and four subcategories. We systematically discuss these methods and highlight their correlations, strengths, and limitations. Finally, we elucidate the current application domains and provide insight into promising prospects for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123930262",
                    "name": "Tanmoy Chowdhury"
                },
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "344039014ef6555a44bfb8a2583a7cbf338d97df",
            "title": "Saliency-Augmented Memory Completion for Continual Learning",
            "abstract": "Continual Learning is considered a key step toward next-generation Artificial Intelligence. Among various methods, replay-based approaches that maintain and replay a small episodic memory of previous samples are one of the most successful strategies against catastrophic forgetting. However, since forgetting is inevitable given bounded memory and unbounded tasks, how to forget is a problem continual learning must address. Therefore, beyond simply avoiding catastrophic forgetting, an under-explored issue is how to reasonably forget while ensuring the merits of human memory, including 1. storage efficiency, 2. generalizability, and 3. some interpretability. To achieve these simultaneously, our paper proposes a new saliency-augmented memory completion framework for continual learning, inspired by recent discoveries in memory completion separation in cognitive neuroscience. Specifically, we innovatively propose to store the part of the image most important to the tasks in episodic memory by saliency map extraction and memory encoding. When learning new tasks, previous data from memory are inpainted by an adaptive data generation module, which is inspired by how humans complete episodic memory. The module's parameters are shared across all tasks and it can be jointly trained with a continual learning classifier as bilevel optimization. Extensive experiments on several continual learning and image classification benchmarks demonstrate the proposed method's effectiveness and efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2296657819",
                    "name": "Yuyang Gao"
                },
                {
                    "authorId": "144000223",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "63bcd049a495ed6341c9985b400a75aacbbaa0d0",
            "title": "Source Localization of Graph Diffusion via Variational Autoencoders for Graph Inverse Problems",
            "abstract": "Graph diffusion problems such as the propagation of rumors, computer viruses, or smart grid failures are ubiquitous and societal. Hence it is usually crucial to identify diffusion sources according to the current graph diffusion observations. Despite its tremendous necessity and significance in practice, source localization, as the inverse problem of graph diffusion, is extremely challenging as it is ill-posed: different sources may lead to the same graph diffusion patterns. Different from most traditional source localization methods, this paper focuses on a probabilistic manner to account for the uncertainty of different candidate sources. Such endeavors require to overcome significant challenges along the way including: 1) the uncertainty in graph diffusion source localization is hard to be quantified; 2) the complex patterns of the graph diffusion sources are difficult to be probabilistically characterized; 3) the generalization under any underlying diffusion patterns is hard to be imposed. To solve the above challenges, this paper presents a generic framework: Source Localization Variational AutoEncoder (SL-VAE) for locating the diffusion sources under arbitrary diffusion patterns. Particularly, we propose a probabilistic model that leverages the forward diffusion estimation model along with deep generative models to approximate the diffusion source distribution for quantifying the uncertainty. SL-VAE further utilizes prior knowledge of the source-observation pairs to characterize the complex patterns of diffusion sources by a learned generative prior. Lastly, a unified objective that integrates the forward diffusion estimation model is derived to enforce the model to generalize under arbitrary diffusion patterns. Extensive experiments are conducted on $7$ real-world datasets to demonstrate the superiority of SL-VAE in reconstructing the diffusion sources by excelling the state-of-the-arts on average 20% in AUC score. The code and data are available at: https://github.com/triplej0079/SLVAE.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2157887017",
                    "name": "Junji Jiang"
                },
                {
                    "authorId": "2120473483",
                    "name": "Junxiang Wang"
                },
                {
                    "authorId": "2116735669",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "97f959c34f24a9bb4717c72249410877233d199a",
            "title": "DeepGAR: Deep Graph Learning for Analogical Reasoning",
            "abstract": "Analogical reasoning is the process of discovering and mapping correspondences from a target subject to a base subject. As the most well-known computational method of analogical reasoning, Structure-Mapping Theory (SMT) abstracts both target and base subjects into relational graphs and forms the cognitive process of analogical reasoning by finding a corresponding subgraph (i.e., correspondence) in the target graph that is aligned with the base graph. However, incorporating deep learning for SMT is still under-explored due to several obstacles: 1) the combinatorial complexity of searching for the correspondence in the target graph; 2) the correspondence mining is restricted by various cognitive theory-driven constraints. To address both challenges, we propose a novel framework for Analogical Reasoning (DeepGAR) that identifies the correspondence between source and target domains by assuring cognitive theory-driven constraints. Specifically, we design a geometric constraint embedding space to induce subgraph relation from node embeddings for efficient subgraph search. Furthermore, we develop novel learning and optimization strategies that could end-to-end identify correspondences that are strictly consistent with constraints driven by the cognitive theory. Extensive experiments are conducted on synthetic and real-world datasets to demonstrate the effectiveness of the proposed DeepGAR over existing methods. The code and data are available at: https://github.com/triplej0079/DeepGAR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2123930262",
                    "name": "Tanmoy Chowdhury"
                },
                {
                    "authorId": "2157887017",
                    "name": "Junji Jiang"
                },
                {
                    "authorId": "2120473483",
                    "name": "Junxiang Wang"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2145225543",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "144000223",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "9036a8e4f7e48b4335b52660550bc95d2d580ffe",
            "title": "Deep Generation of Heterogeneous Networks",
            "abstract": "Heterogeneous graphs are ubiquitous data structures that can inherently capture multi-type and multi-modal interactions between objects. In recent years, research on encoding heterogeneous graph into latent representations have enjoyed a rapid increase. However, its reverse process, namely how to construct heterogeneous graphs from underlying representations and distributions have not been well explored due to several challenges in 1) modeling the local heterogeneous semantic distribution; 2) preserving the graph-structured distributions over the local semantics; and 3) characterizing the global heterogeneous graph distributions. To address these challenges, we propose a novel framework for heterogeneous graph generation (HGEN) that jointly captures the semantic, structural, and global distributions of heterogeneous graphs. Specifically, we propose a heterogeneous walk generator that hierarchically generates meta-paths and their path instances. In addition, a novel heterogeneous graph assembler is developed that can sample and combine the generated meta-path instances (e.g., walks) into heterogeneous graphs in a stratified manner. Theoretical analysis on the preservation of heterogeneous graph patterns by the proposed generation process has been performed. Extensive experiments 1 on multiple real-world and synthetic heterogeneous graph datasets demonstrate the effectiveness of the proposed HGEN in generating realistic heterogeneous graphs.1https://github.com/lingchen0331/HGEN",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "1390553618",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "2116734918",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "14b4bd552328e330f55806495345bacd64e3e840",
            "title": "TG-GAN: Continuous-time Temporal Graph Deep Generative Models with Time-Validity Constraints",
            "abstract": "Deep generative models of graph-structured data have become popular in very recent years. Although initial research has focused on static graphs in applications such as molecular design and social networks, many challenges involve temporal graphs whose topology and attribute values evolve dynamically over time. Sophisticated and unknown network processes that affect temporal graphs cannot be captured adequately by prescribed models. Application areas include social mobility networks and catastrophic cybersecurity failures. These web-scale applications challenge current deep graph generative models with the need to capture 1) time-validity constraints, 2) time and topological distributions, and 3) joint time and graph encoding and decoding. Here, we propose the \u201cTemporal Graph Generative Adversarial Network\u201d (TG-GAN) for continuous-time graph generation with time-validity constraints 1. TG-GAN can jointly generate the time, node, and edge information for truncated temporal walks via a novel recurrent-based model and a valid time decoder. The generated truncated temporal walks are then assembled into time-budgeted temporal walks for temporal graphs under the learned topological and temporal dependencies. In addition, a discriminator is proposed to combine time and node encoding operations over a recurrent architecture to distinguish generated sequences from real ones sampled by a truncated temporal walk sampler. Extensive experiments on both synthetic and real-world datasets confirm that TG-GAN significantly outperforms five benchmarking methods in terms of efficiency and effectiveness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47059797",
                    "name": "Liming Zhang"
                },
                {
                    "authorId": "2116734918",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "49841830",
                    "name": "Shan Qin"
                },
                {
                    "authorId": "2258036",
                    "name": "D. Pfoser"
                },
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                }
            ]
        }
    ]
}