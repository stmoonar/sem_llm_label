{
    "authorId": "1685296",
    "papers": [
        {
            "paperId": "296f980a039f094fec3351be249b457090d6cf48",
            "title": "The 6th Workshop on e-eommerce and NLP (ECNLP 6)",
            "abstract": "Natural Language Processing (NLP) technology plays a key role in e-commerce today, where this technology can be used for a range of tasks, such as improving search results, providing recommendations, and powering virtual assistants. The ECNLP workshop series focuses on NLP and Machine Learning methods for e-commerce, with a focus on applied and fundamental machine learning and NLP methods that can be leveraged in applied settings. The workshop aims to being together researchers from both industry and academia, with the goal of fostering greater knowledge sharing and collaboration between researchers and practitioners in this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2854981",
                    "name": "S. Malmasi"
                },
                {
                    "authorId": "1923602",
                    "name": "B. Fetahu"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                },
                {
                    "authorId": "3046332",
                    "name": "Oleg Rokhlenko"
                },
                {
                    "authorId": "1830456932",
                    "name": "Ido Guy"
                },
                {
                    "authorId": "2581781",
                    "name": "Nicola Ueffing"
                },
                {
                    "authorId": "3378098",
                    "name": "Surya Kallumadi"
                }
            ]
        },
        {
            "paperId": "309275a127536f4efca4a5cda1d47ee7bb0368c3",
            "title": "Contextual Response Interpretation for Automated Structured Interviews: A Case Study in Market Research",
            "abstract": "Structured interviews are used in many settings, importantly in market research on topics such as brand perception, customer habits, or preferences, which are critical to product development, marketing, and e-commerce at large. Such interviews generally consist of a series of questions that are asked to a participant. These interviews are typically conducted by skilled interviewers, who interpret the responses from the participants and can adapt the interview accordingly. Using automated conversational agents to conduct such interviews would enable reaching a much larger and potentially more diverse group of participants than currently possible. However, the technical challenges involved in building such a conversational system are relatively unexplored. To learn more about these challenges, we convert a market research multiple-choice questionnaire to a conversational format and conduct a user study. We address the key task of conducting structured interviews, namely interpreting the participant\u2019s response, for example, by matching it to one or more predefined options. Our findings can be applied to improve response interpretation for the information elicitation phase of conversational recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40411912",
                    "name": "Harshita Sahijwani"
                },
                {
                    "authorId": "4834571",
                    "name": "Kaustubh D. Dhole"
                },
                {
                    "authorId": "150027282",
                    "name": "Ankur Purwar"
                },
                {
                    "authorId": "2215624098",
                    "name": "Venugopal Vasudevan"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                }
            ]
        },
        {
            "paperId": "4c6879725c4134a168d80462a79620e110630978",
            "title": "Evaluation Metrics of Language Generation Models for Synthetic Traffic Generation Tasks",
            "abstract": "Many Natural Language Generation (NLG) tasks aim to generate a single output text given an input prompt. Other settings require the generation of multiple texts, e.g., for Synthetic Traffic Generation (STG). This generation task is crucial for training and evaluating QA systems as well as conversational agents, where the goal is to generate multiple questions or utterances resembling the linguistic variability of real users. In this paper, we show that common NLG metrics, like BLEU, are not suitable for evaluating STG. We propose and evaluate several metrics designed to compare the generated traffic to the distribution of real user texts. We validate our metrics with an automatic procedure to verify whether they capture different types of quality issues of generated data; we also run human annotations to verify the correlation with human judgements. Experiments on three tasks, i.e., Shopping Utterance Generation, Product Question Generation and Query Auto Completion, demonstrate that our metrics are effective for evaluating STG tasks, and improve the agreement with human judgement up to 20% with respect to common NLG metrics. We believe these findings can pave the way towards better solutions for estimating the representativeness of synthetic text data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2778426",
                    "name": "Simone Filice"
                },
                {
                    "authorId": "1560680283",
                    "name": "J. Choi"
                },
                {
                    "authorId": "3285152",
                    "name": "Giuseppe Castellucci"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                },
                {
                    "authorId": "3046332",
                    "name": "Oleg Rokhlenko"
                }
            ]
        },
        {
            "paperId": "524535fa506da8e5499f66b489b48675b6b7e7ed",
            "title": "FCC: Fusing Conversation History and Candidate Provenance for Contextual Response Ranking in Dialogue Systems",
            "abstract": "Response ranking in dialogues plays a crucial role in retrieval-based conversational systems. In a multi-turn dialogue, to capture the gist of a conversation, contextual information serves as essential knowledge to achieve this goal. In this paper, we present a flexible neural framework that can integrate contextual information from multiple channels. Specifically for the current task, our approach is to provide two information channels in parallel, Fusing Conversation history and domain knowledge extracted from Candidate provenance (FCC), where candidate responses are curated, as contextual information to improve the performance of multi-turn dialogue response ranking. The proposed approach can be generalized as a module to incorporate miscellaneous contextual features for other context-oriented tasks. We evaluate our model on the MSDialog dataset widely used for evaluating conversational response ranking tasks. Our experimental results show that our framework significantly outperforms the previous state-of-the-art models, improving Recall@1 by 7% and MAP by 4%. Furthermore, we conduct ablation studies to evaluate the contributions of each information channel, and of the framework components, to the overall ranking performance, providing additional insights and directions for further improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117422663",
                    "name": "Zihao Wang"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                },
                {
                    "authorId": "4724587",
                    "name": "Jinho D. Choi"
                }
            ]
        },
        {
            "paperId": "b003a5f05234c0736586cc162b6ce45e03453074",
            "title": "Ericson: An Interactive Open-Domain Conversational Search Agent",
            "abstract": "Open-domain conversational search (ODCS) aims to provide valuable, up-to-date information, while maintaining natural conversations to help users refine and ultimately answer information needs. However, creating an effective and robust ODCS agent is challenging. In this paper, we present a fully functional ODCS system, Ericson, which includes state-of-the-art question answering and information retrieval components, as well as intent inference and dialogue management models for proactive question refinement and recommendations. Our system was stress-tested in the Amazon Alexa Prize, by engaging in live conversations with thousands of Alexa users, thus providing empirical basis for the analysis of the ODCS system in real settings. Our interaction data analysis revealed that accurate intent classification, encouraging user engagement, and careful proactive recommendations contribute most to the users satisfaction. Our study further identifies limitations of the existing search techniques, and can serve as a building block for the next generation of ODCS agents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117422663",
                    "name": "Zihao Wang"
                },
                {
                    "authorId": "30967674",
                    "name": "Ali Ahmadvand"
                },
                {
                    "authorId": "1560680283",
                    "name": "J. Choi"
                },
                {
                    "authorId": "2497878",
                    "name": "Payam Karisani"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                }
            ]
        },
        {
            "paperId": "c4f23409ec05ccd5d2379d60670040159ed1ff40",
            "title": "Searching for Products in Virtual Reality: Understanding the Impact of Context and Result Presentation on User Experience",
            "abstract": "Immersive technologies such as virtual reality (VR) and head-mounted displays (HMD) have seen increased adoption in recent years. In this work, we study two factors that influence users' experience when shopping in VR through voice queries: (1) context alignment of the search environment and (2) the level of detail on the Search Engine Results Page (SERP). To this end, we developed a search system for VR and conducted a within-subject exploratory study (N=18) to understand the impact of the two experimental conditions. Our results suggest that both context alignment and SERP are important factors for information-seeking in VR, which present unique opportunities and challenges. More specifically, based on our findings, we suggest that search systems for VR must be able to: (1) provide cues for information-seeking in both the VR environment and SERP, (2) distribute attention between the VR environment and the search interface, (3) reduce distractions in the VR environment and (4) provide a ''sense of control'' to search in the VR environment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1562164202",
                    "name": "Austin R. Ward"
                },
                {
                    "authorId": "3176237",
                    "name": "Sandeep Avula"
                },
                {
                    "authorId": "10391344",
                    "name": "H. Cheng"
                },
                {
                    "authorId": "2721029",
                    "name": "Sheikh Muhammad Sarwar"
                },
                {
                    "authorId": "1684660",
                    "name": "Vanessa Murdock"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                }
            ]
        },
        {
            "paperId": "cf6172a16907bd1fd8f23188ec7e9a28fb0e8ad3",
            "title": "Generating Explainable Product Comparisons for Online Shopping",
            "abstract": "An essential part of making shopping purchase decisions is to compare and contrast products based on key differentiating features, but doing this manually can be overwhelming. Prior methods offer limited product comparison capabilities, e.g., via pre-defined common attributes that may be difficult to understand, or irrelevant to a particular product or user. Automatically generating an informative, natural-sounding, and factually consistent comparative text for multiple product and attribute types is a challenging research problem. We describe HCPC (Human Centered Product Comparison), to tackle two kinds of comparisons for online shopping: (i) product-specific, to describe and compare products based on their key attributes; and (ii) attribute-specific comparisons, to compare similar products on a specific attribute. To ensure that comparison text is faithful to the input product data, we introduce a novel multi-decoder, multi-task generative language model. One decoder generates product comparison text, and a second one generates supportive, explanatory text in the form of product attribute names and values. The second task imitates a copy mechanism, improving the comparison generator, and its output is used to justify the factual accuracy of the generated comparison text, by training a factual consistency model to detect and correct errors in the generated comparative text. We release a new dataset (https://registry.opendata.aws/) of ~15K human generated sentences, comparing products on one or more attributes (the first such data we know of for product comparison). We demonstrate on this data that HCPC significantly outperforms strong baselines, by ~10% using automatic metrics, and ~5% using human evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "19304470",
                    "name": "Nikhita Vedula"
                },
                {
                    "authorId": "2068537998",
                    "name": "Marcus D. Collins"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                },
                {
                    "authorId": "3046332",
                    "name": "Oleg Rokhlenko"
                }
            ]
        },
        {
            "paperId": "656b8ffc95d7febbfacfc28fe346d9f4ddfe88ac",
            "title": "Alexa, Let's Work Together: Introducing the First Alexa Prize TaskBot Challenge on Conversational Task Assistance",
            "abstract": "Since its inception in 2016, the Alexa Prize program has enabled hundreds of university students to explore and compete to develop conversational agents through the SocialBot Grand Challenge. The goal of the challenge is to build agents capable of conversing coherently and engagingly with humans on popular topics for 20 minutes, while achieving an average rating of at least 4.0/5.0. However, as conversational agents attempt to assist users with increasingly complex tasks, new conversational AI techniques and evaluation platforms are needed. The Alexa Prize TaskBot challenge, established in 2021, builds on the success of the SocialBot challenge by introducing the requirements of interactively assisting humans with real-world Cooking and Do-It-Yourself tasks, while making use of both voice and visual modalities. This challenge requires the TaskBots to identify and understand the user's need, identify and integrate task and domain knowledge into the interaction, and develop new ways of engaging the user without distracting them from the task at hand, among other challenges. This paper provides an overview of the TaskBot challenge, describes the infrastructure support provided to the teams with the CoBot Toolkit, and summarizes the approaches the participating teams took to overcome the research challenges. Finally, it analyzes the performance of the competing TaskBots during the first year of the competition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1411423941",
                    "name": "Anna Gottardi"
                },
                {
                    "authorId": "2167638287",
                    "name": "Osman Ipek"
                },
                {
                    "authorId": "3285152",
                    "name": "Giuseppe Castellucci"
                },
                {
                    "authorId": "2122825525",
                    "name": "Shui Hu"
                },
                {
                    "authorId": "2167643644",
                    "name": "Lavina Vaz"
                },
                {
                    "authorId": "2167771392",
                    "name": "Yao Lu"
                },
                {
                    "authorId": "2077475879",
                    "name": "Anju Khatri"
                },
                {
                    "authorId": "2077475884",
                    "name": "Anjali Chadha"
                },
                {
                    "authorId": "2187068732",
                    "name": "Desheng Zhang"
                },
                {
                    "authorId": "2167648845",
                    "name": "Sattvik Sahai"
                },
                {
                    "authorId": "72881692",
                    "name": "Prerna Dwivedi"
                },
                {
                    "authorId": "2167861070",
                    "name": "Hangjie Shi"
                },
                {
                    "authorId": "2144596247",
                    "name": "Lu Hu"
                },
                {
                    "authorId": "2167641762",
                    "name": "Andy Huang"
                },
                {
                    "authorId": "2115177932",
                    "name": "Luke Dai"
                },
                {
                    "authorId": "2119660672",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "46569381",
                    "name": "Varun Somani"
                },
                {
                    "authorId": "29153729",
                    "name": "Pankaj Rajan"
                },
                {
                    "authorId": "2167648862",
                    "name": "Ron Rezac"
                },
                {
                    "authorId": "2078507351",
                    "name": "Michael Johnston"
                },
                {
                    "authorId": "2167638459",
                    "name": "Savanna Stiff"
                },
                {
                    "authorId": "2167616711",
                    "name": "Leslie Ball"
                },
                {
                    "authorId": "1751914",
                    "name": "David Carmel"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "3046332",
                    "name": "Oleg Rokhlenko"
                },
                {
                    "authorId": "35834027",
                    "name": "Kate Bland"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                },
                {
                    "authorId": "3306272",
                    "name": "R. Ghanadan"
                },
                {
                    "authorId": "1781257",
                    "name": "Y. Maarek"
                }
            ]
        },
        {
            "paperId": "6b6ca58fe6805fe8ab2ff9d6732905e0056213b4",
            "title": "Making Large Language Models Interactive: A Pioneer Study on Supporting Complex Information-Seeking Tasks with Implicit Constraints",
            "abstract": "Current interactive systems with natural language interfaces lack the ability to understand a complex information-seeking request which expresses several implicit constraints at once, and there is no prior information about user preferences e.g.,\"find hiking trails around San Francisco which are accessible with toddlers and have beautiful scenery in summer\", where output is a list of possible suggestions for users to start their exploration. In such scenarios, user requests can be issued in one shot in the form of a complex and long query, unlike conversational and exploratory search models, where require short utterances or queries are often presented to the system step by step. We have designed and deployed a platform to collect the data from approaching such complex interactive systems. Moreover, despite with the current advancement of generative language models these models suffer from hallucination in providing accurate factual knowledge. All language models are mostly trained in large part on web-scraped data from the past, which usually is not useful for immediate users' needs. In this article, we propose an IA that leverages Large Language Models (LLM) for complex request understanding and makes it interactive using Reinforcement learning that allows intricately refine user requests by making them complete, leading to better retrieval and reduce LLMs hallucination problems for current user needs. To demonstrate the performance of the proposed modeling paradigm, we have adopted various pre-retrieval metrics that capture the extent to which guided interactions with our system yield better retrieval results. Through extensive experimentation, we demonstrated that our method significantly outperforms several robust baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30967674",
                    "name": "Ali Ahmadvand"
                },
                {
                    "authorId": "2269050250",
                    "name": "Negar Arabzadeh"
                },
                {
                    "authorId": "1755651",
                    "name": "Julia Kiseleva"
                },
                {
                    "authorId": "2164036440",
                    "name": "Patricio Figueroa Sanz"
                },
                {
                    "authorId": "2164111499",
                    "name": "Xin Deng"
                },
                {
                    "authorId": "3001990",
                    "name": "S. Jauhar"
                },
                {
                    "authorId": "2417334",
                    "name": "Michael Gamon"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                },
                {
                    "authorId": "2065608331",
                    "name": "Ned Friend"
                },
                {
                    "authorId": "2164036617",
                    "name": "Aniruddha"
                }
            ]
        },
        {
            "paperId": "6d5edf710fb84c99a59acfb40a46c416b5145c03",
            "title": "Detecting Elevated Air Pollution Levels by Monitoring Web Search Queries: Algorithm Development and Validation",
            "abstract": "Background Real-time air pollution monitoring is a valuable tool for public health and environmental surveillance. In recent years, there has been a dramatic increase in air pollution forecasting and monitoring research using artificial neural networks. Most prior work relied on modeling pollutant concentrations collected from ground-based monitors and meteorological data for long-term forecasting of outdoor ozone (O3), oxides of nitrogen, and fine particulate matter (PM2.5). Given that traditional, highly sophisticated air quality monitors are expensive and not universally available, these models cannot adequately serve those not living near pollutant monitoring sites. Furthermore, because prior models were built based on physical measurement data collected from sensors, they may not be suitable for predicting the public health effects of pollution exposure. Objective This study aimed to develop and validate models to nowcast the observed pollution levels using web search data, which are publicly available in near real time from major search engines. Methods We developed novel machine learning\u2013based models using both traditional supervised classification methods and state-of-the-art deep learning methods to detect elevated air pollution levels at the US city level by using generally available meteorological data and aggregate web-based search volume data derived from Google Trends. We validated the performance of these methods by predicting 3 critical air pollutants (O3, nitrogen dioxide, and PM2.5) across 10 major US metropolitan statistical areas in 2017 and 2018. We also explore different variations of the long short-term memory model and propose a novel search term dictionary learner-long short-term memory model to learn sequential patterns across multiple search terms for prediction. Results The top-performing model was a deep neural sequence model long short-term memory, using meteorological and web search data, and reached an accuracy of 0.82 (F1-score 0.51) for O3, 0.74 (F1-score 0.41) for nitrogen dioxide, and 0.85 (F1-score 0.27) for PM2.5, when used for detecting elevated pollution levels. Compared with using only meteorological data, the proposed method achieved superior accuracy by incorporating web search data. Conclusions The results show that incorporating web search data with meteorological data improves the nowcasting performance for all 3 pollutants and suggest promising novel applications for tracking global physical phenomena using web search data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2146250512",
                    "name": "Chen Lin"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "102353403",
                    "name": "E. Kahoro"
                },
                {
                    "authorId": "2497878",
                    "name": "Payam Karisani"
                },
                {
                    "authorId": "2300476285",
                    "name": "D. Liang"
                },
                {
                    "authorId": "2094967",
                    "name": "J. Sarnat"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                }
            ]
        }
    ]
}