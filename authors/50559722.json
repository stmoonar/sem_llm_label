{
    "authorId": "50559722",
    "papers": [
        {
            "paperId": "09007d7699f49549c9f92b6c62a0d9469393d724",
            "title": "Disentangled Contrastive Collaborative Filtering",
            "abstract": "Recent studies show that graph neural networks (GNNs) are prevalent to model high-order relationships for collaborative filtering (CF). Towards this research line, graph contrastive learning (GCL) has exhibited powerful performance in addressing the supervision label shortage issue by learning augmented user and item representations. While many of them show their effectiveness, two key questions still remain unexplored: i) Most existing GCL-based CF models are still limited by ignoring the fact that user-item interaction behaviors are often driven by diverse latent intent factors (e.g., shopping for family party, preferred color or brand of products); ii) Their introduced non-adaptive augmentation techniques are vulnerable to noisy information, which raises concerns about the model's robustness and the risk of incorporating misleading self-supervised signals. In light of these limitations, we propose a Disentangled Contrastive Collaborative Filtering framework (DCCF) to realize intent disentanglement with self-supervised augmentation in an adaptive fashion. With the learned disentangled representations with global context, our DCCF is able to not only distill finer-grained latent factors from the entangled self-supervision signals but also alleviate the augmentation-induced noise. Finally, the cross-view contrastive learning task is introduced to enable adaptive augmentation with our parameterized interaction mask generator. Experiments on various public datasets demonstrate the superiority of our method compared to existing solutions. Our model implementation is released at the link https://github.com/HKUDS/DCCF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2163180478",
                    "name": "Xubin Ren"
                },
                {
                    "authorId": "1830455155",
                    "name": "Lianghao Xia"
                },
                {
                    "authorId": "2109974571",
                    "name": "Jiashu Zhao"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2110926729",
                    "name": "Chao Huang"
                }
            ]
        },
        {
            "paperId": "21d7908e03d3a4cd4222e4f7f9846ec0e55d0a65",
            "title": "Unconfounded Propensity Estimation for Unbiased Ranking",
            "abstract": "The goal of unbiased learning to rank (ULTR) is to leverage implicit user feedback for optimizing learning-to-rank systems. Among existing solutions, automatic ULTR algorithms that jointly learn user bias models (i.e., propensity models) with unbiased rankers have received a lot of attention due to their superior performance and low deployment cost in practice. Despite their theoretical soundness, the effectiveness is usually justified under a weak logging policy, where the ranking model can barely rank documents according to their relevance to the query. However, when the logging policy is strong, e.g., an industry-deployed ranking policy, the reported effectiveness cannot be reproduced. In this paper, we first investigate ULTR from a causal perspective and uncover a negative result: existing ULTR algorithms fail to address the issue of propensity overestimation caused by the query-document relevance confounder. Then, we propose a new learning objective based on backdoor adjustment and highlight its differences from conventional propensity models, which reveal the prevalence of propensity overestimation. On top of that, we introduce a novel propensity model called Logging-Policy-aware Propensity (LPP) model and its distinctive two-step optimization strategy, which allows for the joint learning of LPP and ranking models within the automatic ULTR framework, and actualize the unconfounded propensity estimation for ULTR. Extensive experiments on two benchmarks demonstrate the effectiveness and generalizability of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2104176910",
                    "name": "Dan Luo"
                },
                {
                    "authorId": "8718022",
                    "name": "Lixin Zou"
                },
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                },
                {
                    "authorId": "2111630646",
                    "name": "Zhiyu Chen"
                },
                {
                    "authorId": "2136338739",
                    "name": "Chenliang Li"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "1380217949",
                    "name": "B. Davison"
                }
            ]
        },
        {
            "paperId": "a66bb19c36db1a2f400b4c8f90b5da464b6c9e80",
            "title": "User Retention-oriented Recommendation with Decision Transformer",
            "abstract": "Improving user retention with reinforcement learning (RL) has attracted increasing attention due to its significant importance in boosting user engagement. However, training the RL policy from scratch without hurting users\u2019 experience is unavoidable due to the requirement of trial-and-error searches. Furthermore, the offline methods, which aim to optimize the policy without online interactions, suffer from the notorious stability problem in value estimation or unbounded variance in counterfactual policy evaluation. To this end, we propose optimizing user retention with Decision Transformer (DT), which avoids the offline difficulty by translating the RL as an autoregressive problem. However, deploying the DT in recommendation is a non-trivial problem because of the following challenges: (1) deficiency in modeling the numerical reward value; (2) data discrepancy between the policy learning and recommendation generation; (3) unreliable offline performance evaluation. In this work, we, therefore, contribute a series of strategies for tackling the exposed issues. We first articulate an efficient reward prompt by weighted aggregation of meta embeddings for informative reward embedding. Then, we endow a weighted contrastive learning method to solve the discrepancy between training and inference. Furthermore, we design two robust offline metrics to measure user retention. Finally, the significant improvement in the benchmark datasets demonstrates the superiority of the proposed method. The implementation code is available at https://github.com/kesenzhao/DT4Rec.git.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187856386",
                    "name": "Kesen Zhao"
                },
                {
                    "authorId": "8718022",
                    "name": "Lixin Zou"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2109132520",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "21b2a2f235451f159d5df7fe3e9772c434966677",
            "title": "A GNN-based Multi-task Learning Framework for Personalized Video Search",
            "abstract": "Watching online videos has become more and more popular and users tend to watch videos based on their personal tastes and preferences. Providing a customized ranking list to maximize the user's satisfaction has become increasingly important for online video platforms. Existing personalized search methods (PSMs) train their models with user feedback information (e.g. clicks). However, we identified that such feedback signals may indicate attractiveness but not necessarily indicate relevance in video search. Besides, the click data and user historical information are usually too sparse to train a good PSM, which is different from the conventional Web search containing users' rich historical information. To address these concerns, in this paper we propose a multi-task graph neural network architecture for personalized video search (MGNN-PVS) that can jointly model user's click behaviour and the relevance between queries and videos. To relieve the sparsity problem and learn better representation for users, queries and videos, we develop an efficient and novel GNN architecture based on neighborhood sampling and hierarchical aggregation strategy by leveraging their different hops of neighbors in the user-query and query-document click graph. Extensive experiments on a major commercial video search engine show that our model significantly outperforms state-of-the-art PSMs, which illustrates the effectiveness of our proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152831965",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "2117206479",
                    "name": "Lei Shi"
                },
                {
                    "authorId": "2109974571",
                    "name": "Jiashu Zhao"
                },
                {
                    "authorId": "2120815677",
                    "name": "Juan Yang"
                },
                {
                    "authorId": "2302936114",
                    "name": "Tianshu Lyu"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2582251",
                    "name": "Haiping Lu"
                }
            ]
        },
        {
            "paperId": "2339091449b03d574e9bc460b13a83284c7c474a",
            "title": "Graph Enhanced BERT for Query Understanding",
            "abstract": "Query understanding plays a key role in exploring users' search intents and facilitating users to locate their most desired information. However, it is inherently challenging since it needs to capture semantic information from short and ambiguous queries and often requires massive task-specific labeled data. In recent years, pre-trained language models (PLMs) have advanced various natural language processing tasks because they can extract general semantic information from large-scale corpora. However, directly applying them to query understanding is sub-optimal because existing strategies rarely consider to boost the search performance. On the other hand, search logs contain user clicks between queries and urls that provide rich users' search behavioral information on queries beyond their content. Therefore, in this paper, we aim to fill this gap by exploring search logs. In particular, we propose a novel graph-enhanced pre-training framework, GE-BERT, which leverages both query content and the query graph. The model is trained on a query graph where nodes are queries and two queries are connected if they lead to clicks on the same urls, to capture both semantic information and users' search behavioral information of queries. Extensive experiments on offline and online tasks have demonstrated the effectiveness of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "90026606",
                    "name": "Weizhen Zeng"
                },
                {
                    "authorId": "2111102795",
                    "name": "Suqi Cheng"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "269426ce4269b32d5ae038a9e4010618997ee432",
            "title": "Whole Page Unbiased Learning to Rank",
            "abstract": "The page presentation biases in the information retrieval system, especially on the click behavior, is a well-known challenge that hinders improving ranking models' performance with implicit user feedback. Unbiased Learning to Rank~(ULTR) algorithms are then proposed to learn an unbiased ranking model with biased click data. However, most existing algorithms are specifically designed to mitigate position-related bias, e.g., trust bias, without considering biases induced by other features in search result page presentation(SERP), e.g. attractive bias induced by the multimedia. Unfortunately, those biases widely exist in industrial systems and may lead to an unsatisfactory search experience. Therefore, we introduce a new problem, i.e., whole-page Unbiased Learning to Rank(WP-ULTR), aiming to handle biases induced by whole-page SERP features simultaneously. It presents tremendous challenges: (1) a suitable user behavior model (user behavior hypothesis) can be hard to find; and (2) complex biases cannot be handled by existing algorithms. To address the above challenges, we propose a Bias Agnostic whole-page unbiased Learning to rank algorithm, named BAL, to automatically find the user behavior model with causal discovery and mitigate the biases induced by multiple SERP features with no specific design. Experimental results on a real-world dataset verify the effectiveness of the BAL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "8718022",
                    "name": "Lixin Zou"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "90368708",
                    "name": "Xiaokai Chu"
                },
                {
                    "authorId": "2109974571",
                    "name": "Jiashu Zhao"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "2d7dca71ebe1f438ee2fb2d0fa1907c1612da355",
            "title": "Sequential Recommendation with User Evolving Preference Decomposition",
            "abstract": "Modeling user sequential behaviors has recently attracted increasing attention in the recommendation domain. Existing methods mostly assume coherent preference in the same sequence. However, user personalities are volatile and easily changed, and there can be multiple mixed preferences underlying user behaviors. To solve this problem, in this paper, we propose a novel sequential recommender model via decomposing and modeling user independent preferences. To achieve this goal, we highlight three practical challenges considering the inconsistent, evolving and uneven nature of the user behaviors. For overcoming these challenges in a unified framework, we introduce a reinforcement learning module to simulate the evolution of user preference. More specifically, the action aims to allocate each item into a sub-sequence or create a new one according to how the previous items are decomposed as well as the time interval between successive behaviors. The reward is associated with the final loss of the learning objective, aiming to generate sub-sequences which can better fit the training data. We conduct extensive experiments based on eight real-world datasets across different domains. Comparing with the state-of-the-art methods, empirical studies manifest that our model can on average improve the performance by about 9.68%, 12.4%, 8.56% and 7.13% on the metrics of Precision, Recall, NDCG and MRR, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143609496",
                    "name": "Weiqi Shao"
                },
                {
                    "authorId": "49795005",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2109974571",
                    "name": "Jiashu Zhao"
                },
                {
                    "authorId": "143916459",
                    "name": "Long Xia"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "36a52633a3c2248cc76aefa1adbd49a7d3cde77b",
            "title": "Self-Supervised Learning for Recommendation",
            "abstract": "Recommender systems are playing an increasingly critical role to alleviate information overload and satisfy users' information seeking requirements in a wide spectrum of online platforms. However, the ubiquity of data sparsity and noise notably limits the representation capacity of existing recommender systems to learn high-quality user (item) embeddings. Inspired by recent advances of self-supervised learning (SSL) techniques, SSL-based representation learning models benefit a variety of recommendation domains. Such methods have achieved new levels of performance while reducing the dependence on observed supervision labels in diverse recommendation tasks. In this tutorial, we aim to provide a systemic review of state-of-the-art SSL-based recommender systems. To be specific, we summarize and categorize existing work of SSL-based recommender systems in terms of recommendation scenarios. For each type of recommendation task, the corresponding challenges and methods will be presented in a comprehensive way. Finally, some future directions and open questions will be raised to inspire more investigation on this important research line.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110926729",
                    "name": "Chao Huang"
                },
                {
                    "authorId": "1830455155",
                    "name": "Lianghao Xia"
                },
                {
                    "authorId": "98285513",
                    "name": "Xiang Wang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "4010435fee6379f9edb53a8148ad1f6094ab2936",
            "title": "ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self On-the-fly Distillation for Dense Passage Retrieval",
            "abstract": "Neural retrievers based on pre-trained language models (PLMs), such as dual-encoders, have achieved promising performance on the task of open-domain question answering (QA). Their effectiveness can further reach new state-of-the-arts by incorporating cross-architecture knowledge distillation. However, most of the existing studies just directly apply conventional distillation methods. They fail to consider the particular situation where the teacher and student have different structures. In this paper, we propose a novel distillation method that significantly advances cross-architecture distillation for dual-encoders. Our method 1) introduces a self on-the-fly distillation method that can effectively distill late interaction (i.e., ColBERT) to vanilla dual-encoder, and 2) incorporates a cascade distillation process to further improve the performance with a cross-encoder teacher. Extensive experiments are conducted to validate that our proposed solution outperforms strong baselines and establish a new state-of-the-art on open-domain QA benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2140025135",
                    "name": "Yuxiang Lu"
                },
                {
                    "authorId": "2108021633",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "2144130913",
                    "name": "Jiaxiang Liu"
                },
                {
                    "authorId": "48081324",
                    "name": "Yunsheng Shi"
                },
                {
                    "authorId": "2151325127",
                    "name": "Zhengjie Huang"
                },
                {
                    "authorId": "144588144",
                    "name": "Shi Feng"
                },
                {
                    "authorId": "2117103617",
                    "name": "Yu Sun"
                },
                {
                    "authorId": "50007795",
                    "name": "Hao Tian"
                },
                {
                    "authorId": "40354707",
                    "name": "Hua Wu"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "144270731",
                    "name": "Haifeng Wang"
                }
            ]
        },
        {
            "paperId": "423372879d2bc1b0884ed8d58c3549988d695d75",
            "title": "Fast Semantic Matching via Flexible Contextualized Interaction",
            "abstract": "Deep pre-trained language models (e.g., BERT) lead to remarkable headway in many Natural Language Processing tasks. Their superior capacity in perceiving textual data is also witnessed in semantic matching tasks (e.g., question answering, web search). Particularly for matching a pair of query and text candidate, the current state-of-the-arts usually rely on the semantic representations produced by BERT, and compute relevance scores with various interaction (i.e., matching) methods. However, they may 1) miss fine-grained phrase-level interaction between the input query and candidate context or 2) lack a thoughtful consideration of both effectiveness and efficiency. Motivated by this, we propose \\hyttInteractor, a BERT-based semantic matching model with a flexible contextualized interaction paradigm. It is capable of capturing fine-grained phrase-level information in the interaction, and thus is more effective to be applied for semantic matching tasks. Moreover, we further facilitate \\hyttInteractor with a novel partial attention scheme, which significantly reduces the computational cost while maintaining the high effectiveness. We conduct comprehensive experimental evaluations on three datasets. The results show that \\hyttInteractor achieves superior effectiveness and efficiency for semantic matching.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1830569732",
                    "name": "Wenwen Ye"
                },
                {
                    "authorId": "2108021633",
                    "name": "Yiding Liu"
                },
                {
                    "authorId": "8718022",
                    "name": "Lixin Zou"
                },
                {
                    "authorId": "22561596",
                    "name": "Hengyi Cai"
                },
                {
                    "authorId": "2111102795",
                    "name": "Suqi Cheng"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        }
    ]
}