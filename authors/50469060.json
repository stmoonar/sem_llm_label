{
    "authorId": "50469060",
    "papers": [
        {
            "paperId": "2eb96b1c7de32ca25d91278c7c019574fdbbbd8b",
            "title": "Lightweight Privacy-Preserving Feature Extraction for EEG Signals Under Edge Computing",
            "abstract": "The health-related Internet of Things (IoT) plays an irreplaceable role in the collection, analysis, and transmission of medical data. As a device of the health-related IoT, the electroencephalogram (EEG) has long been a powerful tool for physiological and clinical brain research, which contains a wealth of personal information. Due to its rich computational/storage resources, cloud computing is a promising solution to extract the sophisticated feature of massive EEG signals in the age of big data. However, it needs to solve both response latency and privacy leakage. To reduce latency between users and servers while ensuring data privacy, we propose a privacy-preserving feature extraction scheme, called LightPyFE, for EEG signals in the edge computing environment. In this scheme, we design an outsourced computing toolkit, which allows the users to achieve a series of secure integer and floating-point computing operations. During the implementation, LightPyFE can ensure that the users just perform the encryption and decryption operations, where all computing tasks are outsourced to edge servers for specific processing. Theoretical analysis and experimental results have demonstrated that our scheme can successfully achieve privacy-preserving feature extraction for EEG signals, and is practical yet effective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151205957",
                    "name": "Nazhao Yan"
                },
                {
                    "authorId": "2149241553",
                    "name": "Hang Cheng"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "2156361853",
                    "name": "Fei Chen"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                }
            ]
        },
        {
            "paperId": "ad5f103de8e7e3cd622f87d3c99e6123915e6d57",
            "title": "DeepDIST: A Black-Box Anti-Collusion Framework for Secure Distribution of Deep Models",
            "abstract": "Due to enormous computing and storage overhead for well-trained Deep Neural Network (DNN) models, protecting the intellectual property of model owners is a pressing need. As the commercialization of deep models is becoming increasingly popular, the pre-trained models delivered to users may suffer from being illegally copied, redistributed, or abused. In this paper, we propose DeepDIST, the first end-to-end secure DNNs distribution framework in a black-box scenario. Specifically, our framework adopts a dual-level fingerprint (FP) mechanism to provide reliable ownership verification, and proposes two equivalent transformations that can resist collusion attacks, plus a newly designed similarity loss term to improve the security of the transformations. Unlike the existing passive defense schemes that detect colluding participants, we introduce an active defense strategy, namely damaging the performance of the model after the malicious collusion. The extensive experimental results show that DeepDIST can maintain the accuracy of the host DNN after embedding fingerprint conducted for true traitor tracing, and is robust against several popular model modifications. Furthermore, the anti-collusion effect is evaluated on two typical classification tasks (10-class and 100-class), and the proposed DeepDIST can drop the prediction accuracy of the collusion model to 10% and 1% (random guess), respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145928133",
                    "name": "Hang Cheng"
                },
                {
                    "authorId": "2144393294",
                    "name": "Xibin Li"
                },
                {
                    "authorId": "1576102218",
                    "name": "Huaxiong Wang"
                },
                {
                    "authorId": "152899522",
                    "name": "Xinpeng Zhang"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "1698973",
                    "name": "Fengyong Li"
                }
            ]
        },
        {
            "paperId": "539c8442e2134c757f8d7f05566640b8e0c07326",
            "title": "SwinFace: A Multi-Task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation",
            "abstract": "In recent years, vision transformers have been introduced into face recognition and analysis and have achieved performance breakthroughs. However, most previous methods generally train a single model or an ensemble of models to perform the desired task, which ignores the synergy among different tasks and fails to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper presents a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, the SwinFace, consists of a single shared backbone together with a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97% accuracy on RAF-DB and $0.22 \\epsilon $ -error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2228651380",
                    "name": "Lixiong Qin"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "2057945548",
                    "name": "Chao Deng"
                },
                {
                    "authorId": "104138391",
                    "name": "K. Wang"
                },
                {
                    "authorId": "95487088",
                    "name": "Xiangshan Chen"
                },
                {
                    "authorId": "2220586656",
                    "name": "Jiani Hu"
                },
                {
                    "authorId": "1774956",
                    "name": "Weihong Deng"
                }
            ]
        },
        {
            "paperId": "6c88d10910bad16b13890813205d6914f4ebd028",
            "title": "Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph",
            "abstract": "Knowledge graphs (KGs) are commonly used as side information to enhance collaborative signals and improve recommendation quality. In the context of knowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged as promising solutions for modeling factual and semantic information in KGs. However, the long-tail distribution of entities leads to sparsity in supervision signals, which weakens the quality of item representation when utilizing KG enhancement. Additionally, the binary relation representation of KGs simplifies hyper-relational facts, making it challenging to model complex real-world information. Furthermore, the over-smoothing phenomenon results in indistinguishable representations and information loss. To address these challenges, we propose the SDK (Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph) framework. This framework establishes a cross-view hypergraph self-supervised learning mechanism for KG enhancement. Specifically, we model hyper-relational facts in KGs to capture interdependencies between entities under complete semantic conditions. With the refined representation, a hypergraph is dynamically constructed to preserve features in the deep vector space, thereby alleviating the over-smoothing problem. Furthermore, we mine external supervision signals from both the global perspective of the hypergraph and the local perspective of collaborative filtering (CF) to guide the model prediction process. Extensive experiments conducted on different datasets demonstrate the superiority of the SDK framework over state-of-the-art models. The results showcase its ability to alleviate the effects of over-smoothing and supervision signal sparsity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153629568",
                    "name": "Yi Liu"
                },
                {
                    "authorId": "2200836056",
                    "name": "Hongrui Xuan"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "788b9e00985576d8d58e8da0a1ef76642b227845",
            "title": "Handwriting Curve Interpolation Using Gradient Graph Laplacian Regularizer",
            "abstract": "Due to the technical limitation of pen tablets, there are sensing points data loss from the touch screen when the handwriting speed is fast. This problem will cause discrete, segmented, and unsmooth handwriting curves. In order to recover the unknown point coordinates from the observed corrupted curve of handwriting, we propose a curve interpolation algorithm by combining gradient graph Laplacian regularizer and cyclic shift. We first define the gradient of 2D curve and create the related gradient graph. Then the handwriting curve is interpolated by the gradient graph Laplacian regularizer. For handwriting stroke offset, we introduce a cyclic shift of handwriting for translation invariance. Experimental results on synthetic curves and handwriting datasets show that the interpolation quality of our proposed algorithm is better than other competing algorithms, and it promotes the curve smoothness of the turning points.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2233493214",
                    "name": "Yinhe Lin"
                },
                {
                    "authorId": "2156361853",
                    "name": "Fei Chen"
                },
                {
                    "authorId": "2149241553",
                    "name": "Hang Cheng"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                }
            ]
        },
        {
            "paperId": "9e9f675830caceddca3619c2c4d4441e519d894f",
            "title": "Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering",
            "abstract": "Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question. Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models. Recent works have resorted to using a powerful large language model (LLM) as an implicit knowledge engine to acquire the necessary knowledge for answering. Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of the blind LLM as the provided textual input is insufficient to depict the required visual information to answer the question. In this paper, we present Prophet -- a conceptually simple, flexible, and general framework designed to prompt LLM with answer heuristics for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge. After that, we extract two types of complementary answer heuristics from the VQA model: answer candidates and answer-aware examples. Finally, the two types of answer heuristics are jointly encoded into a formatted prompt to facilitate the LLM's understanding of both the image and question, thus generating a more accurate answer. By incorporating the state-of-the-art LLM GPT-3, Prophet significantly outperforms existing state-of-the-art methods on four challenging knowledge-based VQA datasets. To demonstrate the generality of our approach, we instantiate Prophet with the combinations of different VQA models (i.e., both discriminative and generative ones) and different LLMs (i.e., both commercial and open-source ones).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2210731803",
                    "name": "Zhenwei Shao"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "2161356649",
                    "name": "Jun Yu"
                }
            ]
        },
        {
            "paperId": "bf47bc21308efb40d00c1ed13213fbead621b8b5",
            "title": "Online Prediction Method for Power System Frequency Response Analysis Based on Swarm Intelligence Fusion Model",
            "abstract": "Instability at transient frequency caused by faults in complex power systems is one of the greatest threats to operational safety. By analyzing the frequency response of power system in real-time and adopting control strategies promptly, power system accidents can be efficiently prevented. While existing online analysis methods integrate physical-driven and data-driven methodologies, they do not effectively utilize frequency timing characteristics. Consequently, a swarm intelligence fusion model, which integrates physical-driven and data-driven methods, is proposed as an improved frequency response analysis method. The transient frequency affecting components are separated into primary state variables and system time series data based on the properties of the time sequence. To preserve the actual relationship of the electrical mechanism model, the system frequency response (SFR) model is used as the physical-driven method for the primary state variables of the system. The Long Short Term Memory (LSTM) network was used as the data-driven method to extract timing features and correct the SFR model\u2019s prediction using the system time series data as input. The two methods are combined using the bootstrap mode to form the fusion model, and the structure of the model is optimized using an improved sparrow search algorithm (ISSA), a swarm intelligence optimization algorithm. The model structure is adapted autonomously, implementing a method for online frequency response analysis. The simulation on the New England 39-bus system has verified that the method can quickly and accurately calculate the dynamic process of frequency response after a large-scale disturbance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158369270",
                    "name": "Lin Xu"
                },
                {
                    "authorId": "2156055512",
                    "name": "L. Li"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "30691644",
                    "name": "Xiangxu Wang"
                },
                {
                    "authorId": "2142454256",
                    "name": "Yicong Li"
                },
                {
                    "authorId": "73423274",
                    "name": "Weidong Li"
                },
                {
                    "authorId": "3213888",
                    "name": "Kuanjiu Zhou"
                }
            ]
        },
        {
            "paperId": "0e89156650660981256cc5400bb212a0cfccabf4",
            "title": "The effect of flow experience on gifting in live streaming: a perspective of flow theory",
            "abstract": "Exploring the factors influencing gift-giving of live streaming users is not only conducive to the sustainable operation of streamers and platforms but also to the long-term development of the industry. Based on the flow theory, we explored the influence of users' flow state in different subjects (platform vs host) on gift-giving from the perspective of users, and discussed the moderating role of social-oriented live streaming and task-oriented live streaming. In this study, Python was used to collect 33,277 individual data onto Huya platform, SPSS and STATA were used for statistical analysis and hypothesis testing, and the results show that both streamer flow and platform flow have a positive impact on users' gift-giving. Streamer flow has a greater impact on virtual gift consumption of social-oriented live streaming. Platform flow has no significant impact on gifting of social-oriented live streaming, but has a significant positive impact on gifting of task-oriented live streaming. This study has enriched the research content of the field of live streaming, discussed the influence mechanism of different subjects on users\u2019 gift-giving, and contributed to the practice of live streaming platform operators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                }
            ]
        },
        {
            "paperId": "158dbdd10f3489e8a3b5b969e116d71bb9f6edb8",
            "title": "Designing Problem-based Learning at a Department Level in Resources and Environment: An Interdisciplinary Study",
            "abstract": "Interdisciplinary research, which aims to solve practical issues in the realm of industrial applications, has emerged as a key trend in the current transformation of knowledge production mode, creating a new type of educational strategy to match. Problem-based Learning (PBL) is a teaching paradigm that emphasizes the practical orientation and application qualities of a college education. Northeastern University's Resources and Environment department arose from the need to address complicated environmental challenges. It has inherent interdisciplinary characteristics and bears the social duty of sustainable development. The discipline seeks to link \"Practical Cognition\" with \"Disciplinary Logic,\" as well as realign the \"target-content-method\" of education to meet current demands. The teaching-learning practice tries to correspond to the professional training goals and the student's capability output through the reform and practice of a divisional level with the PBL method, integration of multidisciplinary and industrial resources, carrying out teaching-learning activities based on interdisciplinary theory and PBL principles, improving students' transformative skills, and rebuilding sustainable social responsibilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128680615",
                    "name": "Fenghua Li"
                },
                {
                    "authorId": "2205564933",
                    "name": "Chong Han"
                },
                {
                    "authorId": "33672636",
                    "name": "Chunfang Zhou"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "2195540154",
                    "name": "D. Gong"
                },
                {
                    "authorId": "2154170741",
                    "name": "Chenggang Yang"
                },
                {
                    "authorId": "2056897733",
                    "name": "Tao Du"
                }
            ]
        },
        {
            "paperId": "1fd1152202a38377b182896b86fe52027f941a53",
            "title": "Unsupervised Structure-Texture Separation Network for Oracle Character Recognition",
            "abstract": "Oracle bone script is the earliest-known Chinese writing system of the Shang dynasty and is precious to archeology and philology. However, real-world scanned oracle data are rare and few experts are available for annotation which make the automatic recognition of scanned oracle characters become a challenging task. Therefore, we aim to explore unsupervised domain adaptation to transfer knowledge from handprinted oracle data, which are easy to acquire, to scanned domain. We propose a structure-texture separation network (STSN), which is an end-to-end learning framework for joint disentanglement, transformation, adaptation and recognition. First, STSN disentangles features into structure (glyph) and texture (noise) components by generative models, and then aligns handprinted and scanned data in structure feature space such that the negative influence caused by serious noises can be avoided when adapting. Second, transformation is achieved via swapping the learned textures across domains and a classifier for final classification is trained to predict the labels of the transformed scanned characters. This not only guarantees the absolute separation, but also enhances the discriminative ability of the learned features. Extensive experiments on Oracle-241 dataset show that STSN outperforms other adaptation methods and successfully improves recognition performance on scanned data even when they are contaminated by long burial and careless excavation.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "1774956",
                    "name": "Weihong Deng"
                },
                {
                    "authorId": "2215096115",
                    "name": "Chenguang Liu"
                }
            ]
        }
    ]
}