{
    "authorId": "3591598",
    "papers": [
        {
            "paperId": "09fc567a4d66e068d8fce5948b769e33715fa00f",
            "title": "The Bigger the Better? Rethinking the Effective Model Scale in Long-term Time Series Forecasting",
            "abstract": "\u2014Long-term time series forecasting (LTSF) represents a critical frontier in time series analysis, distinguished by its focus on extensive input sequences, in contrast to the constrained lengths typical of traditional approaches. While longer sequences inherently convey richer information, potentially enhancing predictive precision, prevailing techniques often respond by escalating model complexity. These intricate models can inflate into millions of parameters, incorporating parameter-intensive elements like positional encodings, feed-forward networks and self-attention mechanisms. This complexity, however, leads to prohibitive model scale, particularly given the time series data\u2019s semantic simplicity. Motivated by the pursuit of parsimony, our research employs conditional correlation and auto-correlation as investigative tools, revealing significant redundancies within the input data. Leveraging these insights, we introduce the HDformer, a lightweight Transformer variant enhanced with hierarchical decomposition. This novel architecture not only inverts the prevailing trend toward model expansion but also accomplishes precise forecasting with drastically fewer computations and parameters. Remarkably, HDformer outperforms existing state-of-the-art LTSF models, while requiring over 99% fewer parameters. Through this work, we advocate a paradigm shift in LTSF, emphasizing the importance to tailor the model to the inherent dynamics of time series data\u2014a timely reminder that in the realm of LTSF, bigger is not invariably better.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2280285477",
                    "name": "Xuan Song"
                },
                {
                    "authorId": "1807998",
                    "name": "I. Tsang"
                },
                {
                    "authorId": "2280136955",
                    "name": "Hui Xiong"
                }
            ]
        },
        {
            "paperId": "2c71bace488cedd352d70eeb264e380e1e93de14",
            "title": "Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting",
            "abstract": "Long-term time series forecasting (LTSF) represents a critical frontier in time series analysis, characterized by extensive input sequences, as opposed to the shorter spans typical of traditional approaches. While longer sequences inherently offer richer information for enhanced predictive precision, prevailing studies often respond by escalating model complexity. These intricate models can inflate into millions of parameters, resulting in prohibitive parameter scales. Our study demonstrates, through both analytical and empirical evidence, that decomposition is key to containing excessive model inflation while achieving uniformly superior and robust results across various datasets. Remarkably, by tailoring decomposition to the intrinsic dynamics of time series data, our proposed model outperforms existing benchmarks, using over 99 \\% fewer parameters than the majority of competing methods. Through this work, we aim to unleash the power of a restricted set of parameters by capitalizing on domain characteristics--a timely reminder that in the realm of LTSF, bigger is not invariably better.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2303256772",
                    "name": "Feiyang Ye"
                },
                {
                    "authorId": "2124890383",
                    "name": "Du Yin"
                },
                {
                    "authorId": "2280285477",
                    "name": "Xuan Song"
                },
                {
                    "authorId": "1807998",
                    "name": "I. Tsang"
                },
                {
                    "authorId": "2280136955",
                    "name": "Hui Xiong"
                }
            ]
        },
        {
            "paperId": "6785d8ecb5eb658efde7e06f9afec1ed69bfadb7",
            "title": "Enhancing Spatio-temporal Quantile Forecasting with Curriculum Learning: Lessons Learned",
            "abstract": "Training models on spatio-temporal (ST) data poses an open problem due to the complicated and diverse nature of the data itself, and it is challenging to ensure the model's performance directly trained on the original ST data. While limiting the variety of training data can make training easier, it can also lead to a lack of knowledge and information for the model, resulting in a decrease in performance. To address this challenge, we presented an innovative paradigm that incorporates three separate forms of curriculum learning specifically targeting from spatial, temporal, and quantile perspectives. Furthermore, our framework incorporates a stacking fusion module to combine diverse information from three types of curriculum learning, resulting in a strong and thorough learning process. We demonstrated the effectiveness of this framework with extensive empirical evaluations, highlighting its better performance in addressing complex ST challenges. We provided thorough ablation studies to investigate the effectiveness of our curriculum and to explain how it contributes to the improvement of learning efficiency on ST data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2307075816",
                    "name": "Du Yin"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2298903492",
                    "name": "Shuang Ao"
                },
                {
                    "authorId": "2307386978",
                    "name": "Zechen Li"
                },
                {
                    "authorId": "2302775049",
                    "name": "Hao Xue"
                },
                {
                    "authorId": "1380742035",
                    "name": "Arian Prabowo"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2244697815",
                    "name": "Xuan Song"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        },
        {
            "paperId": "c09d2846ff81c5dbdf4f8662bd2d9bb4dd61b396",
            "title": "Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting",
            "abstract": "Spatiotemporal time series forecasting plays a key role in a wide range of real-world applications. While significant progress has been made in this area, fully capturing and leveraging spatiotemporal heterogeneity remains a fundamental challenge. Therefore, we propose a novel Heterogeneity-Informed Meta-Parameter Learning scheme. Specifically, our approach implicitly captures spatiotemporal heterogeneity through learning spatial and temporal embeddings, which can be viewed as a clustering process. Then, a novel spatiotemporal meta-parameter learning paradigm is proposed to learn spatiotemporal-specific parameters from meta-parameter pools, which is informed by the captured heterogeneity. Based on these ideas, we develop a Heterogeneity-Informed Spatiotemporal Meta-Network (HimNet) for spatiotemporal time series forecasting. Extensive experiments on five widely-used benchmarks demonstrate our method achieves state-of-the-art performance while exhibiting superior interpretability. Our code is available at https://github.com/XDZhelheim/HimNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203116078",
                    "name": "Zheng Dong"
                },
                {
                    "authorId": "2268522268",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2269371004",
                    "name": "Haotian Gao"
                },
                {
                    "authorId": "2243527573",
                    "name": "Hangchen Liu"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2302153555",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2280285477",
                    "name": "Xuan Song"
                }
            ]
        },
        {
            "paperId": "144d95575e4ef2b9e46a064415ec032e0644420b",
            "title": "Spatial-Temporal-Decoupled Masked Pre-training for Spatiotemporal Forecasting",
            "abstract": "Spatiotemporal forecasting techniques are significant for various domains such as transportation, energy, and weather. Accurate prediction of spatiotemporal series remains challenging due to the complex spatiotemporal heterogeneity. In particular, current end-to-end models are limited by input length and thus often fall into spatiotemporal mirage, i.e., similar input time series followed by dissimilar future values and vice versa. To address these problems, we propose a novel self-supervised pre-training framework Spatial-Temporal-Decoupled Masked Pre-training (STD-MAE) that employs two decoupled masked autoencoders to reconstruct spatiotemporal series along the spatial and temporal dimensions. Rich-context representations learned through such reconstruction could be seamlessly integrated by downstream predictors with arbitrary architectures to augment their performances. A series of quantitative and qualitative evaluations on four widely used benchmarks (PEMS03, PEMS04, PEMS07, and PEMS08) are conducted to validate the state-of-the-art performance of STD-MAE. Codes are available at https://github.com/Jimmy-7664/STD-MAE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2269371004",
                    "name": "Haotian Gao"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2203116078",
                    "name": "Zheng Dong"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2274074199",
                    "name": "Yuxin Ma"
                },
                {
                    "authorId": "2112276021",
                    "name": "Xuan Song"
                }
            ]
        },
        {
            "paperId": "3ff1e1254122f43e9544f6d494234ea569f20a1d",
            "title": "TTS-Norm: Forecasting Tensor Time Series via Multi-Way Normalization",
            "abstract": "Tensor time series (TTS) data, a generalization of one-dimensional time series on a high-dimensional space, is ubiquitous in real-world applications. Compared to modeling time series or multivariate time series, which has received much attention and achieved tremendous progress in recent years, tensor time series has been paid less effort. However, properly coping with the TTS is a much more challenging task, due to its high-dimensional and complex inner structure. In this article, we start by revealing the structure of TTS data from afn statistical view of point. Then, in line with this analysis, we perform Tensor Time Series forecasting via a proposed Multi-way Normalization (TTS-Norm), which effectively disentangles multiple heterogeneous low-dimensional substructures from the original high-dimensional structure. Finally, we design a novel objective function for TTS forecasting, accounting for the numerical heterogeneity among different low-dimensional subspaces of TTS. Extensive experiments on two real-world datasets verify the superior performance of our proposed model.1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3174614",
                    "name": "Jiewen Deng"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2124890383",
                    "name": "Du Yin"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2112276021",
                    "name": "Xuan Song"
                }
            ]
        },
        {
            "paperId": "487da37c7f1b4d38480fae7cdab901a339032a73",
            "title": "STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting",
            "abstract": "With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1879725821",
                    "name": "Hangcheng Liu"
                },
                {
                    "authorId": "2203116078",
                    "name": "Zheng Dong"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "3174614",
                    "name": "Jiewen Deng"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "40628376",
                    "name": "Quanjun Chen"
                },
                {
                    "authorId": "2112276021",
                    "name": "Xuan Song"
                }
            ]
        },
        {
            "paperId": "68cc2e1a7e6fe7620a700fbe4c3c6198b3b45068",
            "title": "Disentangling Structured Components: Towards Adaptive, Interpretable and Scalable Time Series Forecasting",
            "abstract": "Multivariate time-series (MTS) forecasting is a paramount and fundamental problem in many real-world applications. The core issue in MTS forecasting is how to effectively model complex spatial-temporal patterns. In this paper, we develop a adaptive, interpretable and scalable forecasting framework, which seeks to individually model each component of the spatial-temporal patterns. We name this framework SCNN, as an acronym of Structured Component-based Neural Network. SCNN works with a pre-defined generative process of MTS, which arithmetically characterizes the latent structure of the spatial-temporal patterns. In line with its reverse process, SCNN decouples MTS data into structured and heterogeneous components and then respectively extrapolates the evolution of these components, the dynamics of which are more traceable and predictable than the original MTS. Extensive experiments are conducted to demonstrate that SCNN can achieve superior performance over state-of-the-art models on three real-world datasets. Additionally, we examine SCNN with different configurations and perform in-depth analyses of the properties of SCNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "2144216930",
                    "name": "Xiusi Chen"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2124890383",
                    "name": "Du Yin"
                },
                {
                    "authorId": "7607499",
                    "name": "Yezhou Yang"
                },
                {
                    "authorId": "2112276021",
                    "name": "Xuan Song"
                },
                {
                    "authorId": "1807998",
                    "name": "I. Tsang"
                }
            ]
        },
        {
            "paperId": "8d46f6b8da505566a809e34c3e60d39413ae9342",
            "title": "Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation",
            "abstract": "Few-shot question answering (QA) aims at precisely discovering answers to a set of questions from context passages while only a few training samples are available. Although existing studies have made some progress and can usually achieve proper results, they suffer from understanding deep semantics for reasoning out the questions. In this paper, we develop Gotta, a Generative prOmpT-based daTa Augmentation framework to mitigate the challenge above. Inspired by the human reasoning process, we propose to integrate the cloze task to enhance few-shot QA learning. Following the recent success of prompt-tuning, we present the cloze task in the same format as the main QA task, allowing the model to learn both tasks seamlessly together to fully take advantage of the power of prompt-tuning. Extensive experiments on widely used benchmarks demonstrate that Gotta consistently outperforms competitive baselines, validating the effectiveness of our proposed prompt-tuning-based cloze task, which not only fine-tunes language models but also learns to guide reasoning in QA tasks. Further analysis shows that the prompt-based loss incorporates the auxiliary task better than the multi-task loss, highlighting the strength of prompt-tuning on the few-shot QA task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29963551",
                    "name": "Xiusi Chen"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "3165179",
                    "name": "Jyun-Yu Jiang"
                },
                {
                    "authorId": "40397893",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "bc6811564ea609389840583793626f6cd8f5d021",
            "title": "Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting",
            "abstract": "With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243527573",
                    "name": "Hangchen Liu"
                },
                {
                    "authorId": "2203116078",
                    "name": "Zheng Dong"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2261097032",
                    "name": "Jiewen Deng"
                },
                {
                    "authorId": "3591598",
                    "name": "Jinliang Deng"
                },
                {
                    "authorId": "40628376",
                    "name": "Quanjun Chen"
                },
                {
                    "authorId": "2237107055",
                    "name": "Xuan Song"
                }
            ]
        }
    ]
}