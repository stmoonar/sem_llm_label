{
    "authorId": "48624767",
    "papers": [
        {
            "paperId": "85e6c2d34304a01e3f7071cdc7200405c4af93d0",
            "title": "DocTr: Document Transformer for Structured Information Extraction in Documents",
            "abstract": "We present a new formulation for structured information extraction (SIE) from visually rich documents. We address the limitations of existing IOB tagging and graph-based formulations, which are either overly reliant on the correct ordering of input text or struggle with decoding a complex graph. Instead, motivated by anchor-based object detectors in computer vision, we represent an entity as an anchor word and a bounding box, and represent entity linking as the association between anchor words. This is more robust to text ordering, and maintains a compact graph for entity linking. The formulation motivates us to introduce 1) a Document Transformer (DocTr) that aims at detecting and associating entity bounding boxes in visually rich documents, and 2) a simple pre-training strategy that helps learn entity detection in the context of language. Evaluations on three SIE benchmarks show the effectiveness of the proposed formulation, and the overall approach outperforms existing solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145585312",
                    "name": "Haofu Liao"
                },
                {
                    "authorId": "2895705",
                    "name": "Aruni RoyChowdhury"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "2068427",
                    "name": "Ankan Bansal"
                },
                {
                    "authorId": "2108148342",
                    "name": "Yuting Zhang"
                },
                {
                    "authorId": "144035504",
                    "name": "Z. Tu"
                },
                {
                    "authorId": "1710219",
                    "name": "R. Satzoda"
                },
                {
                    "authorId": "1758550",
                    "name": "R. Manmatha"
                },
                {
                    "authorId": "48493294",
                    "name": "V. Mahadevan"
                }
            ]
        },
        {
            "paperId": "c96d70a15563af372abf9fa59488d39c2aa35ef8",
            "title": "Unsupervised Self-Driving Attention Prediction via Uncertainty Mining and Knowledge Embedding",
            "abstract": "Predicting attention regions of interest is an important yet challenging task for self-driving systems. Existing methodologies rely on large-scale labeled traffic datasets that are labor-intensive to obtain. Besides, the huge domain gap between natural scenes and traffic scenes in current datasets also limits the potential for model training. To address these challenges, we are the first to introduce an unsupervised way to predict self-driving attention by uncertainty modeling and driving knowledge integration. Our approach\u2019s Uncertainty Mining Branch (UMB) discovers commonalities and differences from multiple generated pseudo-labels achieved from models pre-trained on natural scenes by actively measuring the uncertainty. Meanwhile, our Knowledge Embedding Block (KEB) bridges the domain gap by incorporating driving knowledge to adaptively refine the generated pseudo-labels. Quantitative and qualitative results with equivalent or even more impressive performance compared to fully-supervised state-of-the-art approaches across all three public datasets demonstrate the effectiveness of the proposed method and the potential of this direction. The code is available at https://github.com/zaplm/DriverAttention.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145463313",
                    "name": "Pengfei Zhu"
                },
                {
                    "authorId": "8433849",
                    "name": "Mengshi Qi"
                },
                {
                    "authorId": "2211969741",
                    "name": "Xia Li"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "2110816141",
                    "name": "Huadong Ma"
                }
            ]
        },
        {
            "paperId": "46b0eb0648fbcf79a74818588fd3525b64b83590",
            "title": "Causal Inference via Nonlinear Variable Decorrelation for Healthcare Applications",
            "abstract": "Causal inference and model interpretability research are gaining increasing attention, especially in the domains of healthcare and bioinformatics. Despite recent successes in this field, decorrelating features under nonlinear environments with human interpretable representations has not been adequately investigated. To address this issue, we introduce a novel method with a variable decorrelation regularizer to handle both linear and nonlinear confounding. Moreover, we employ association rules as new representations using association rule mining based on the original features to further proximate human decision patterns to increase model interpretability. Extensive experiments are conducted on four healthcare datasets (one synthetically generated and three real-world collections on different diseases). Quantitative results in comparison to baseline approaches on parameter estimation and causality computation indicate the model\u2019s superior performance. Furthermore, expert evaluation given by healthcare professionals validates the effectiveness and interpretability of the proposed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109593210",
                    "name": "Junda Wang"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": null,
                    "name": "Han Wang"
                },
                {
                    "authorId": "1486450921",
                    "name": "Hanjia Lyu"
                },
                {
                    "authorId": "10724054",
                    "name": "Caroline P. Thirukumaran"
                },
                {
                    "authorId": "5110938",
                    "name": "A. Mesfin"
                },
                {
                    "authorId": "2116783457",
                    "name": "Jiebo Luo"
                }
            ]
        },
        {
            "paperId": "eba44964082d2f853657afd01f3bb6b32d454654",
            "title": "Remote Medication Status Prediction for Individuals with Parkinson\u2019s Disease using Time-series Data from Smartphones",
            "abstract": "Medication for neurological diseases such as the Parkinson\u2019s disease usually happens remotely away from hospitals. Such out-of-lab environments pose challenges in collecting timely and accurate health status data. Individual differences in behavioral signals collected from wearable sensors also lead to difficulties in adopting current general machine learning analysis pipelines. To address these challenges, we present a method for predicting the medication status of Parkinson\u2019s disease patients using the public mPower dataset, which contains 62,182 remote multi-modal test records collected on smartphones from 487 patients. The proposed method shows promising results in predicting three medication statuses objectively: Before Medication (AUC=0.95), After Medication (AUC=0.958), and Another Time (AUC=0.976) by examining patient-wise historical records with the attention weights learned through a Transformer model. Our method provides an innovative way for personalized remote health sensing in a timely and objective fashion which could benefit a broad range of similar applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "2152349779",
                    "name": "Wei-wei Zhu"
                },
                {
                    "authorId": "39066804",
                    "name": "R. Dorsey"
                },
                {
                    "authorId": "33642939",
                    "name": "Jiebo Luo"
                }
            ]
        },
        {
            "paperId": "112dd6f0a395b52a55d9c1db0f53464c41729c53",
            "title": "Fine-Grained Chemical Entity Typing with Multimodal Knowledge Representation",
            "abstract": "Automated knowledge discovery from trending chemical literature is essential for more efficient biomedical research. How to extract detailed knowledge about chemical reactions from the core chemistry literature is a new emerging challenge that has not been well studied. In this paper, we study the new problem of fine-grained chemical entity typing, which poses interesting new challenges especially because of the complex name mentions frequently occurring in chemistry literature and graphic representation of entities. We introduce a new benchmark data set (CHEMET) to facilitate the study of the new task and propose a novel multi-modal representation learning framework to solve the problem of fine-grained chemical entity typing by leveraging external resources with chemical structures and using cross-modal attention to learn effective representation of text in the chemistry domain. Experiment results show that the proposed framework outperforms multiple state-of-the-art methods. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118831287",
                    "name": "Chenkai Sun"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "1736467",
                    "name": "ChengXiang Zhai"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                }
            ]
        },
        {
            "paperId": "2c9fdba6bf846e0986cbbf30d56b467d9e334333",
            "title": "ConTNet: Why not use convolution and transformer at the same time?",
            "abstract": "Although convolutional networks (ConvNets) have enjoyed great success in computer vision (CV), it suffers from capturing global information crucial to dense prediction tasks such as object detection and segmentation. In this work, we innovatively propose ConTNet (ConvolutionTransformer Network), combining transformer with ConvNet architectures to provide large receptive fields. Unlike the recently-proposed transformer-based models (e.g., ViT, DeiT) that are sensitive to hyper-parameters and extremely dependent on a pile of data augmentations when trained from scratch on a midsize dataset (e.g., ImageNet1k), ConTNet can be optimized like normal ConvNets (e.g., ResNet) and preserve an outstanding robustness. It is also worth pointing that, given identical strong data augmentations, the performance improvement of ConTNet is more remarkable than that of ResNet. We present its superiority and effectiveness on image classification and downstream tasks. For example, our ConTNet achieves 81.8% top-1 accuracy on ImageNet which is the same as DeiT-B with less than 40% computational complexity. ConTNet-M also outperforms ResNet50 as the backbone of both Faster-RCNN (by 2.6%) and Mask-RCNN (by 3.2%) on COCO2017 dataset. We hope that ConTNet could serve as a useful backbone for CV tasks and bring new ideas for model design",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10180823",
                    "name": "Haotian Yan"
                },
                {
                    "authorId": "2144241452",
                    "name": "Zhe Li"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "1906061249",
                    "name": "Changhu Wang"
                },
                {
                    "authorId": "153138926",
                    "name": "Ming Wu"
                },
                {
                    "authorId": "144585219",
                    "name": "Chuang Zhang"
                }
            ]
        },
        {
            "paperId": "309049d5003f0876a759c983fce4edf510f1b006",
            "title": "Chemical-Reaction-Aware Molecule Representation Learning",
            "abstract": "Molecule representation learning (MRL) methods aim to embed molecules into a real vector space. However, existing SMILES-based (Simplified Molecular-Input Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasize the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation. The key idea of our approach is to preserve the equivalence of molecules with respect to chemical reactions in the embedding space, i.e., forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation. This constraint is proven effective to 1) keep the embedding space well-organized and 2) improve the generalization ability of molecule embeddings. Moreover, our model can use any GNN as the molecule encoder and is thus agnostic to GNN architectures. Experimental results demonstrate that our method achieves state-of-the-art performance in a variety of downstream tasks, e.g., 17.4% absolute Hit@1 gain in chemical reaction prediction, 2.3% absolute AUC gain in molecule property prediction, and 18.5% relative RMSE gain in graph-edit-distance prediction, respectively, over the best baseline method. The code is available at https://github.com/hwwang55/MolR.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2108986414",
                    "name": "Hongwei Wang"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "2149111828",
                    "name": "Xiaomeng Jin"
                },
                {
                    "authorId": "2111049203",
                    "name": "Kyunghyun Cho"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "35723855",
                    "name": "M. Burke"
                }
            ]
        },
        {
            "paperId": "7521771abc8ef7e29e3a4a5cffdcbdaafbae07a6",
            "title": "Product Information Browsing Support System Using Analytic Hierarchy Process",
            "abstract": "Large-scale e-commerce sites can collect and analyze a large number of user preferences and behaviors, and thus can recommend highly trusted products to users. However, it is very difficult for individuals or non-corporate groups to obtain large-scale user data. Therefore, we consider whether knowledge of the decision-making domain can be used to obtain user preferences and combine it with content-based filtering to design an information retrieval system. This study describes the process of building a product information browsing support system with high satisfaction based on product similarity and multiple other perspectives about products on the Internet. We present the architecture of the proposed system and explain the working principle of its constituent modules. Finally, we demonstrate the effectiveness of the proposed system through an evaluation experiment and a questionnaire.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "2146973943",
                    "name": "Masato Kikuchi"
                },
                {
                    "authorId": "2843264",
                    "name": "Tadachika Ozono"
                }
            ]
        },
        {
            "paperId": "793421889b003230c82fc129bd237778814855b7",
            "title": "Unsupervised Learning of Facial Landmarks based on Inter-Intra Subject Consistencies",
            "abstract": "We present a novel unsupervised learning approach to image landmark discovery by incorporating the inter-subject landmark consistencies on facial images. This is achieved via an inter-subject mapping module that transforms original subject landmarks based on an auxiliary subject-related structure. To recover from the transformed images back to the original subject, the landmark detector is forced to learn spatial locations that contain the consistent semantic meanings both for the paired intra-subject images and between the paired inter-subject images. Our proposed method is extensively evaluated on two public facial image datasets (MAFL, AFLW) with various settings. Experimental results indicate that our method can extract the consistent landmarks for both datasets and achieve better performances compared to the previous state-of-the-art methods quantitatively and qualitatively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "145585312",
                    "name": "Haofu Liao"
                },
                {
                    "authorId": "143655284",
                    "name": "S. Miao"
                },
                {
                    "authorId": "50706692",
                    "name": "Le Lu"
                },
                {
                    "authorId": "2116782926",
                    "name": "Jiebo Luo"
                }
            ]
        },
        {
            "paperId": "af1809de802d36236fcc0e34d5359d544a14894e",
            "title": "Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization",
            "abstract": "Deep learning algorithms mine knowledge from the training data and thus would likely inherit the dataset\u2019s bias information. As a result, the obtained model would generalize poorly and even mislead the decision process in real-life applications. We propose to remove the bias information misused by the target task with a crosssample adversarial debiasing (CSAD) method. CSAD explicitly extracts target and bias features disentangled from the latent representation generated by a feature extractor and then learns to discover and remove the correlation between the target and bias features. The correlation measurement plays a critical role in adversarial debiasing and is conducted by a cross-sample neural mutual information estimator. Moreover, we propose joint content and local structural representation learning to boost mutual information estimation for better performance. We conduct thorough experiments on publicly available datasets to validate the advantages of the proposed method over state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152348673",
                    "name": "Wei Zhu"
                },
                {
                    "authorId": "2743695",
                    "name": "Haitian Zheng"
                },
                {
                    "authorId": "145585312",
                    "name": "Haofu Liao"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "2116782926",
                    "name": "Jiebo Luo"
                }
            ]
        }
    ]
}