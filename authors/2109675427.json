{
    "authorId": "2109675427",
    "papers": [
        {
            "paperId": "49de9908c5a7ab31d9599016261b070f90160e0a",
            "title": "Towards Robust Rumor Detection with Graph Contrastive and Curriculum Learning",
            "abstract": "Establishing a robust rumor detection model is vital in safeguarding the veracity of information on social media platforms. However, existing approaches to stopping rumor from spreading rely on abundant and clean training data, which is rarely available in real-world scenarios. In this work, we aim to develop a trustworthy rumor detection model that can handle inadequate and noisy labeled data. Our work addresses robust rumor detection, including classic and early detection, as well as five types of robustness issues: noisy and incomplete propagation, label scarcity and noise, and user disappearance. We propose a novel method, Robustness-Enhanced Rumor Detection (RERD), which mainly leverages the information propagation graphs of source tweets, along with user profiles and retweeting knowledge, for model learning. The novelty of RERD is four-fold. First, we jointly exploit the propagation structures of non-text and text retweets to learn the representation of a source tweet. Second, we simultaneously utilize the top-down and bottom-up information flows with relational propagations for graph representation learning. Third, to have effective early and robust detection, we implement contrastive learning on graphs with early and complete views of information propagation so that small snapshots can foresee their future shapes. Last, we use curriculum pseudo-labeling to mitigate the impact of label scarcity and noisy labels, and to correct representations learned from corrupted data. Experimental results on three benchmark datasets demonstrate that RERD consistently outperforms competitors in classic, early, and robust rumor detection scenarios. To the best of our knowledge, we are the first to simultaneously cope with early and five robust detections of rumors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294241812",
                    "name": "Wen-Ming Zhuang"
                },
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2277810141",
                    "name": "Cheng-Te Li"
                }
            ]
        },
        {
            "paperId": "6b602e82e801e7734aa1782956fdd5ae71cf0211",
            "title": "Dual Graph Networks with Synthetic Oversampling for Imbalanced Rumor Detection on Social Media",
            "abstract": "Rumor detection is to identify and mitigate potentially damaging falsehoods, thereby shielding the public from misleading information. However, existing methods fall short of tackling class imbalance, meaning rumor is less common than true messages, as they lack specific adaptation for the context of rumor dissemination. In this work, we propose Dual Graph Networks with Synthetic Oversampling (SynDGN), a novel method that can determine whether a claim made on social media is rumor or not in the presence of class imbalance. SynDGN properly utilizes dual graphs to integrate social media contexts and user characteristics to make accurate predictions. Experiments conducted on two well-known datasets verify that SynDGN consistently outperforms state-of-the-art models, regardless of whether the data is balanced or not.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237040934",
                    "name": "Yen-Wen Lu"
                },
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2277810141",
                    "name": "Cheng-Te Li"
                }
            ]
        },
        {
            "paperId": "c7e06504d95de61ce0ae8e1fe15e7f52e843409d",
            "title": "Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions",
            "abstract": "In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural Networks (GNNs), a domain where deep learning-based approaches have increasingly shown superior performance in both classification and regression tasks compared to traditional methods. The survey highlights a critical gap in deep neural TDL methods: the underrepresentation of latent correlations among data instances and feature values. GNNs, with their innate capability to model intricate relationships and interactions between diverse elements of tabular data, have garnered significant interest and application across various TDL domains. Our survey provides a systematic review of the methods involved in designing and implementing GNNs for TDL (GNN4TDL). It encompasses a detailed investigation into the foundational aspects and an overview of GNN-based TDL methods, offering insights into their evolving landscape. We present a comprehensive taxonomy focused on constructing graph structures and representation learning within GNN-based TDL methods. In addition, the survey examines various training plans, emphasizing the integration of auxiliary tasks to enhance the effectiveness of instance representations. A critical part of our discussion is dedicated to the practical application of GNNs across a spectrum of GNN4TDL scenarios, demonstrating their versatility and impact. Lastly, we discuss the limitations and propose future research directions, aiming to spur advancements in GNN4TDL. This survey serves as a resource for researchers and practitioners, offering a thorough understanding of GNNs' role in revolutionizing TDL and pointing towards future innovations in this promising area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2277810141",
                    "name": "Cheng-Te Li"
                },
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2030126978",
                    "name": "Jay Chiehen Liao"
                }
            ]
        },
        {
            "paperId": "333e35493a9c1bd282d553e25db0732377d20ebc",
            "title": "ANTI-Disinformation: An Adversarial Attack and Defense Network Towards Improved Robustness for Disinformation Detection on Social Media",
            "abstract": "The prevalence of disinformation, which includes malformation (e.g., cyberbullying) and misinformation (e.g., fake news) in online platforms has raised significant concerns, prompting the need for robust detection methods to mitigate its detrimental impact. While the field of text classification has witnessed notable advancements in recent years, existing approaches often overlook the evolving nature of disinformation, wherein perpetrators employ perturbations to toxic content to evade detection or censorship. To address this challenge, we present a novel framework, Adversarial Network Towards Improved robustness for Disinformation detection (ANTI-Disinformation), which leverages reinforcement learning techniques as adversarial attacks. Additionally, we propose a defense model to enhance model\u2019s robustness against such attacks. To evaluate the effectiveness of our approach, we conduct extensive experiments on well-known disinformation datasets collected from multiple social media platforms. The results demonstrate our approach can effectively produce degradation in existing models\u2019 performance the most, showcasing the effectiveness of our framework and the vulnerability of existing detection systems. The results also exhibit that the proposed defense methods can consistently outperform existing typical methods in constructing robust detection models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280864145",
                    "name": "Kuan-Chun Chen"
                },
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2277810141",
                    "name": "Cheng-Te Li"
                }
            ]
        },
        {
            "paperId": "5f63f05eaabf2b7d815858dd5814257568407de0",
            "title": "Label-Aware Hyperbolic Embeddings for Fine-grained Emotion Classification",
            "abstract": "Fine-grained emotion classification (FEC) is a challenging task. Specifically, FEC needs to handle subtle nuance between labels, which can be complex and confusing. Most existing models only address text classification problem in the euclidean space, which we believe may not be the optimal solution as labels of close semantic (e.g., afraid and terrified) may not be differentiated in such space, which harms the performance. In this paper, we propose HypEmo, a novel framework that can integrate hyperbolic embeddings to improve the FEC task. First, we learn label embeddings in the hyperbolic space to better capture their hierarchical structure, and then our model projects contextualized representations to the hyperbolic space to compute the distance between samples and labels. Experimental results show that incorporating such distance to weight cross entropy loss substantially improve the performance on two benchmark datasets, with around 3% improvement compared to previous state-of-the-art, and could even improve up to 8.6% when the labels are hard to distinguish. Code is available at https://github.com/dinobby/HypEmo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2122375061",
                    "name": "Tun-Min Hung"
                },
                {
                    "authorId": "2069602444",
                    "name": "Yi-Li Hsu"
                },
                {
                    "authorId": "1746959",
                    "name": "Lun-Wei Ku"
                }
            ]
        },
        {
            "paperId": "62e0a6b33643802542db2c46b582ec1e8e5a8111",
            "title": "HonestBait: Forward References for Attractive but Faithful Headline Generation",
            "abstract": "Current methods for generating attractive headlines often learn directly from data, which bases attractiveness on the number of user clicks and views. Although clicks or views do reflect user interest, they can fail to reveal how much interest is raised by the writing style and how much is due to the event or topic itself. Also, such approaches can lead to harmful inventions by over-exaggerating the content, aggravating the spread of false information. In this work, we propose HonestBait, a novel framework for solving these issues from another aspect: generating headlines using forward references (FRs), a writing technique often used for clickbait. A self-verification process is included during training to avoid spurious inventions. We begin with a preliminary user study to understand how FRs affect user interest, after which we present PANCO1, an innovative dataset containing pairs of fake news with verified news for attractive but faithful news headline generation. Automatic metrics and human evaluations show that our framework yields more attractive results (+11.25% compared to human-written verified news headlines) while maintaining high veracity, which helps promote real information to fight against fake news.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2220702148",
                    "name": "Dennis Wu"
                },
                {
                    "authorId": "1746959",
                    "name": "Lun-Wei Ku"
                }
            ]
        },
        {
            "paperId": "c9be75a4547331022fdb10d60f7ade2f0a108ffc",
            "title": "SUVR: A Search-Based Approach to Unsupervised Visual Representation Learning",
            "abstract": "Unsupervised learning has grown in popularity because of the difficulty of collecting annotated data and the development of modern frameworks that allow us to learn from unlabeled data. Existing studies, however, either disregard variations at different levels of similarity or only consider negative samples from one batch. We argue that image pairs should have varying degrees of similarity, and the negative samples should be allowed to be drawn from the entire dataset. In this work, we propose Search-based Unsupervised Visual Representation Learning (SUVR) to learn better image representations in an unsupervised manner. We first construct a graph from the image dataset by the similarity between images, and adopt the concept of graph traversal to explore positive samples. In the meantime, we make sure that negative samples can be drawn from the full dataset. Quantitative experiments on five benchmark image classification datasets demonstrate that SUVR can significantly outperform strong competing methods on unsupervised embedding learning. Qualitative experiments also show that SUVR can produce better representations in which similar images are clustered closer together than unrelated images in the latent space.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274706526",
                    "name": "Yizhan Xu"
                },
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "1753450171",
                    "name": "Cheng Li"
                }
            ]
        },
        {
            "paperId": "93df9dc530b1cf0af6d5eef90d017741a2aab5d8",
            "title": "ZS-BERT: Towards Zero-Shot Relation Extraction with Attribute Representation Learning",
            "abstract": "While relation extraction is an essential task in knowledge acquisition and representation, and new-generated relations are common in the real world, less effort is made to predict unseen relations that cannot be observed at the training stage. In this paper, we formulate the zero-shot relation extraction problem by incorporating the text description of seen and unseen relations. We propose a novel multi-task learning model, Zero-Shot BERT (ZS-BERT), to directly predict unseen relations without hand-crafted attribute labeling and multiple pairwise classifications. Given training instances consisting of input sentences and the descriptions of their seen relations, ZS-BERT learns two functions that project sentences and relations into an embedding space by jointly minimizing the distances between them and classifying seen relations. By generating the embeddings of unseen relations and new-coming sentences based on such two functions, we use nearest neighbor search to obtain the prediction of unseen relations. Experiments conducted on two well-known datasets exhibit that ZS-BERT can outperform existing methods by at least 13.54% improvement on F1 score.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "2169355",
                    "name": "Cheng-te Li"
                }
            ]
        },
        {
            "paperId": "2cdcfbe7b8d9745aeb98b08cbbf02cf5012d0e4b",
            "title": "FineNet: a joint convolutional and recurrent neural network model to forecast and recommend anomalous financial items",
            "abstract": "Financial technology (FinTech) draws much attention in these years, with the advances of machine learning and deep learning. In this work, given historical time series of stock prices of companies, we aim at forecasting upcoming anomalous financial items, i.e., abrupt soaring or diving stocks, in financial time series, and recommending the corresponding stocks to support financial operations. We propose a novel joint convolutional and recurrent neural network model, Financial Event Neural Network (FineNet), to forecast and recommend anomalous stocks. Experiments conducted on the time series of stock prices of 300 well-known companies exhibit the promising performance of FineNet in terms of precision and recall. We build FineNet as a Web platform for live demonstration.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "2109675427",
                    "name": "Chih-Yao Chen"
                },
                {
                    "authorId": "153062535",
                    "name": "Shao-Lun Ma"
                },
                {
                    "authorId": "27653339",
                    "name": "Pei-Chi Wang"
                },
                {
                    "authorId": "2109212513",
                    "name": "You-Jia Chen"
                },
                {
                    "authorId": "2140050678",
                    "name": "Yu-Chieh Chang"
                },
                {
                    "authorId": "2169355",
                    "name": "Cheng-te Li"
                }
            ]
        }
    ]
}