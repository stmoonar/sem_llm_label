{
    "authorId": "144232630",
    "papers": [
        {
            "paperId": "3d8bbb4869ab69f2735d08f8f339aa4d554d4295",
            "title": "From Large Language Models to Databases and Back: A Discussion on Research and Education",
            "abstract": "In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1699192",
                    "name": "A. Bonifati"
                },
                {
                    "authorId": "2146071014",
                    "name": "Lei Chen"
                },
                {
                    "authorId": "2217441359",
                    "name": "Guoliang Li"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                },
                {
                    "authorId": "2157263249",
                    "name": "Jianliang Xu"
                },
                {
                    "authorId": "2204051805",
                    "name": "Xiaochun Yang"
                }
            ]
        },
        {
            "paperId": "5285586345b85e99a32672afdd73e202355cb333",
            "title": "T5 Encoder Based Acronym Disambiguation with Weak Supervision",
            "abstract": "An acronym is a word formed by abbreviating a phrase by combining certain letters of words in the phrase into a single term. Acronym disambiguation task selects the correct expansion of an ambiguous acronym in a sentence among the candidate expansions in a dictionary. Although it is convenient to use acronyms, identifying the appropriate expansions of an acronym in a sentence is a difficult task in natural language processing. Based on the recent success of the large-scale pre-trained language models such as BERT and T5, we propose a binary classification model using those language models for acronym disambiguation. To overcome the limited coverage of a training data, we use a weak supervision approach to increase the training data. Specifically, after collecting sentences containing an expansion of an acronym from Wikipedia, we replace the expansion with its acronym and label the sentence with the expansion. By conducting extensive experiments, we show the effectiveness of the proposed model. Our model is placed in the top 3 models for three of four categories in SDU@AAAI-22 shared task 2: Acronym Disambiguation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2072633694",
                    "name": "Gwangho Song"
                },
                {
                    "authorId": "8386466",
                    "name": "Hongrae Lee"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        },
        {
            "paperId": "c97d33ec4ab679ad5d7bcf8d9226844b390ee90d",
            "title": "Cardinality Estimation of Approximate Substring Queries using Deep Learning",
            "abstract": "Cardinality estimation of an approximate substring query is an important problem in database systems. Traditional approaches build a summary from the text data and estimate the cardinality using the summary with some statistical assumptions. Since deep learning models can learn underlying complex data patterns effectively, they have been successfully applied and shown to outperform traditional methods for cardinality estimations of queries in database systems. However, since they are not yet applied to approximate substring queries, we investigate a deep learning approach for cardinality estimation of such queries. Although the accuracy of deep learning models tends to improve as the train data size increases, producing a large train data is computationally expensive for cardinality estimation of approximate substring queries. Thus, we develop efficient train data generation algorithms by avoiding unnecessary computations and sharing common computations. We also propose a deep learning model as well as a novel learning method to quickly obtain an accurate deep learning-based estimator. Extensive experiments confirm the superiority of our data generation algorithms and deep learning model with the novel learning method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1720849772",
                    "name": "Suyong Kwon"
                },
                {
                    "authorId": "8787487",
                    "name": "Woohwan Jung"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        },
        {
            "paperId": "c95e98675e786fcad2a6a3b74e51e89bb60286c6",
            "title": "Substring Similarity Search with Synonyms",
            "abstract": "To allow deeper semantic understanding of strings, string matching with synonyms has recently received increasing attention. However, all the works focus on string semantics, which requires matching of entire strings, and cannot handle partial matching with substring semantics, resulting in its limited applications. To remedy this issue, we first propose a novel similarity measure between two strings allowing substring matching with synonyms, and develop an efficient algorithm to find the strings that have a substring semantically similar to the query string. Since considering synonyms on substrings enlarges the search space significantly, we devise efficient filtering methods to reduce the number of expensive similarity computations. Experiments with real-life datasets show the efficiency of our algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2072633694",
                    "name": "Gwangho Song"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                },
                {
                    "authorId": "8386466",
                    "name": "Hongrae Lee"
                }
            ]
        },
        {
            "paperId": "63ea25209806063adf4e78bc09972cb653c68cf0",
            "title": "An Automatic Protocol Reverse Engineering Approach from the Viewpoint of the TCP/IP Reference Model",
            "abstract": "Protocol reverse engineering represents a very powerful and important tool for network management and security. To cope with the emergence and evolution of rapidly increasing numbers of unknown protocols, automation is of great importance. Many methods for supporting the automation of the various steps for protocol reverse engineering have been investigated; however, there has been no method to automate the analysis of the target network environment. Most methods are designed only for application layer protocols, and all others are designed for specific environments. Given any unknown communication, we must be able to infer the structure of the protocol. However, there has been no research on automatic reverse engineering of protocols when both the protocol and the target network environment are entirely unknown. Here, we propose an automatic protocol reverse engineering approach that is designed to be generally applicable, regardless of the specific network environment. We demonstrate the feasibility of the proposed approach by applying it to several protocols in various layers of the TCP/ IP reference model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1879425",
                    "name": "Young-Hoon Goo"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                },
                {
                    "authorId": "51056263",
                    "name": "Ui-Jun Baek"
                },
                {
                    "authorId": "28000040",
                    "name": "Jee-Tae Park"
                },
                {
                    "authorId": "79335426",
                    "name": "Mu-Gon Shin"
                },
                {
                    "authorId": "1716614",
                    "name": "Myung-Sup Kim"
                }
            ]
        },
        {
            "paperId": "2faae58a97363c2edb0ca8ec4fe494d3cffb2aa1",
            "title": "Efficient Aggregation Processing in the Presence of Duplicately Detected Objects in WSNs",
            "abstract": "Wireless sensor networks (WSNs) have received increasing attention in the past decades. Owing to an enhancement of MEMS technology, various types of sensors such as motion detectors, infrared radiation detectors, ultrasonic sensors (sonar), and magnetometers can detect the objects within a certain range. Under such an environment, an object without an identifier can be detected by several sensor nodes. However, existing studies for query processing in WSNs simply assume that the sensing regions of sensors are disjoint. Thus, for query aggregation processing, effective deduplication is vital. In this paper, we propose an approximate but effective aggregate query processing algorithm, called DE-Duplication on the Least Common Ancestor\u2217 (abbreviated as DELCA\u2217). In contrast to most existing studies, since we assume that each object does not have a unique identifier, we perform deduplication based on similarity. To recognize the duplicately detected events earlier, we utilize the locality-sensitive hashing (LSH) technique. In addition, since the similarity measures are not generally transitive, we adapt three duplicate semantics. In our experiments, by using a transmission cost model, we demonstrate that our proposed technique is energy-efficient. We also show the accuracy of our proposed technique.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1835828",
                    "name": "Jun-Ki Min"
                },
                {
                    "authorId": "1736021",
                    "name": "R. Ng"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        },
        {
            "paperId": "49d7f7c1bf046480926db3cdba1fe8d954e8ff49",
            "title": "Crowdsourced Truth Discovery in the Presence of Hierarchies for Knowledge Fusion",
            "abstract": "Existing works for truth discovery in categorical data usually assume that claimed values are mutually exclusive and only one among them is correct. However, many claimed values are not mutually exclusive even for functional predicates due to their hierarchical structures. Thus, we need to consider the hierarchical structure to effectively estimate the trustworthiness of the sources and infer the truths. We propose a probabilistic model to utilize the hierarchical structures and an inference algorithm to find the truths. In addition, in the knowledge fusion, the step of automatically extracting information from unstructured data (e.g., text) generates a lot of false claims. To take advantages of the human cognitive abilities in understanding unstructured data, we utilize crowdsourcing to refine the result of the truth discovery. We propose a task assignment algorithm to maximize the accuracy of the inferred truths. The performance study with real-life datasets confirms the effectiveness of our truth inference and task assignment algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8787487",
                    "name": "Woohwan Jung"
                },
                {
                    "authorId": "2108359250",
                    "name": "Younghoon Kim"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        },
        {
            "paperId": "eb8e90b5eb1b9df448d1d1dcab7a7cfd63f58b84",
            "title": "Improving the Upper Bound of the Dynamic Time Warping for Sparse and Long Time Sequences",
            "abstract": "Dynamic Time Warping (DTW), a distance measure widely used in time series analysis, is associated with the shortcoming of long execution time with long time sequences. To alleviate the problem, several algorithms which use a compression technique called run-length encoding and compute approximate DTW distances were recently proposed. However, the computation of the upper bounds by such algorithms consists of adding unnecessary distance values. In this paper, we propose an approximation algorithm which improves the state of the art for computing approximate DTW distances while keeping the time complexity unchanged. Experimental results with both synthetic and real-life data confirm the effectiveness of our proposed algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150162340",
                    "name": "Janghyuk Seo"
                },
                {
                    "authorId": "8787487",
                    "name": "Woohwan Jung"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        },
        {
            "paperId": "d7830f07a30fbea15e02247ef4ad3492824c001b",
            "title": "Improving on Matrix Factorization for Recommendation Systems by Using a Character-Level Convolutional Neural Network",
            "abstract": "Recommendation systems are used to provide items of interests for users to maximize a company\u2019s profit. Matrix factorization is frequently used by recommendation systems, based on an incomplete user-item rating matrix. However, as the number of items and users increase, it becomes difficult to make accurate recommendations due to the sparsity of data. To overcome this drawback, the use of text data related to items was recently suggested for matrix factorization algorithms. Furthermore, a word-level convolutional neural network was shown to be effective in the process of extracting the word-level features from the text data among these kinds of matrix factorization algorithms. However, it involves a large number of parameters to learn in the word-level convolutional neural network. Thus, we propose a matrix factorization algorithm which utilizes a character-level convolutional neural network with which to extract the character-level features from the text data. We also conducted a performance study with real-life datasets to show the effectiveness of the proposed matrix factorization algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059182199",
                    "name": "Donghee Son"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        },
        {
            "paperId": "db57985fca754f2ab8f539aee6439208591e8538",
            "title": "Differentially Private k-Means Clustering based on Dynamic Space Partitioning using a Quad-Tree",
            "abstract": "There have recently been several studies investigating how to apply a privacy preserving technique to publish data. Differential privacy can protect personal information regardless of an attacker\u2019s background knowledge by adding probabilistic noise to the original data. To perform differentially private k-means clustering, the existing algorithm builds a differentially private histogram and performs the k-means clustering. Since it constructs an equi-width histogram without considering the distribution of data, there are many buckets to which noise should be added. We propose a k-means clustering algorithm using a quad-tree that captures the distribution of data by using a small number of buckets. Our experiments show that the proposed algorithm shows better performance than the existing algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "104161180",
                    "name": "Hanjun Goo"
                },
                {
                    "authorId": "8787487",
                    "name": "Woohwan Jung"
                },
                {
                    "authorId": "104205852",
                    "name": "Seongwoong Oh"
                },
                {
                    "authorId": "1720849772",
                    "name": "Suyong Kwon"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                }
            ]
        }
    ]
}