{
    "authorId": "2312034033",
    "papers": [
        {
            "paperId": "5bf3ea7b0825424c3c01e48e8fcd8215c950677e",
            "title": "SciCode: A Research Coding Benchmark Curated by Scientists",
            "abstract": "Since language models (LMs) now outperform average humans on many challenging tasks, it has become increasingly difficult to develop challenging, high-quality, and realistic evaluations. We address this issue by examining LMs' capabilities to generate code for solving real scientific research problems. Incorporating input from scientists and AI researchers in 16 diverse natural science sub-fields, including mathematics, physics, chemistry, biology, and materials science, we created a scientist-curated coding benchmark, SciCode. The problems in SciCode naturally factorize into multiple subproblems, each involving knowledge recall, reasoning, and code synthesis. In total, SciCode contains 338 subproblems decomposed from 80 challenging main problems. It offers optional descriptions specifying useful scientific background information and scientist-annotated gold-standard solutions and test cases for evaluation. Claude3.5-Sonnet, the best-performing model among those tested, can solve only 4.6% of the problems in the most realistic setting. We believe that SciCode demonstrates both contemporary LMs' progress towards becoming helpful scientific assistants and sheds light on the development and evaluation of scientific AI in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2311882756",
                    "name": "Minyang Tian"
                },
                {
                    "authorId": "2311993272",
                    "name": "Luyu Gao"
                },
                {
                    "authorId": "2311876703",
                    "name": "Shizhuo Dylan Zhang"
                },
                {
                    "authorId": "2311990357",
                    "name": "Xinan Chen"
                },
                {
                    "authorId": "2312274734",
                    "name": "Cunwei Fan"
                },
                {
                    "authorId": "2311997990",
                    "name": "Xuefei Guo"
                },
                {
                    "authorId": "2311874817",
                    "name": "Roland Haas"
                },
                {
                    "authorId": "2311880186",
                    "name": "Pan Ji"
                },
                {
                    "authorId": "35701505",
                    "name": "K. Krongchon"
                },
                {
                    "authorId": "2312094587",
                    "name": "Yao Li"
                },
                {
                    "authorId": "2152940692",
                    "name": "Shengyan Liu"
                },
                {
                    "authorId": "2311885961",
                    "name": "Di Luo"
                },
                {
                    "authorId": "2311873896",
                    "name": "Yutao Ma"
                },
                {
                    "authorId": "2182144332",
                    "name": "Hao Tong"
                },
                {
                    "authorId": "2311879494",
                    "name": "Kha Trinh"
                },
                {
                    "authorId": "2312693808",
                    "name": "Chenyu Tian"
                },
                {
                    "authorId": "2311998534",
                    "name": "Zihan Wang"
                },
                {
                    "authorId": "2312000055",
                    "name": "Bohao Wu"
                },
                {
                    "authorId": "2088591255",
                    "name": "Yanyu Xiong"
                },
                {
                    "authorId": "2312269830",
                    "name": "Shengzhu Yin"
                },
                {
                    "authorId": "2268183167",
                    "name": "Min Zhu"
                },
                {
                    "authorId": "2289297215",
                    "name": "K. Lieret"
                },
                {
                    "authorId": "2311884554",
                    "name": "Yanxin Lu"
                },
                {
                    "authorId": "2217570953",
                    "name": "Genglin Liu"
                },
                {
                    "authorId": "2312034033",
                    "name": "Yufeng Du"
                },
                {
                    "authorId": "2311869097",
                    "name": "Tianhua Tao"
                },
                {
                    "authorId": "40170001",
                    "name": "Ofir Press"
                },
                {
                    "authorId": "2286084960",
                    "name": "Jamie Callan"
                },
                {
                    "authorId": "2249761654",
                    "name": "E. Huerta"
                },
                {
                    "authorId": "2254026935",
                    "name": "Hao Peng"
                }
            ]
        },
        {
            "paperId": "ab944b8561dc0280180469bdb94f189be1cc2e80",
            "title": "ActionIE: Action Extraction from Scientific Literature with Programming Languages",
            "abstract": "Extraction of experimental procedures from human language in scientific literature and patents into actionable sequences in robotics language holds immense significance in scientific domains. Such an action extraction task is particularly challenging given the intricate details and context-dependent nature of the instructions, especially in fields like chemistry where reproducibility is paramount. In this paper, we introduce A CTION IE, a method that leverages Large Language Models (LLMs) to bridge this divide by converting actions written in natural language into executable Python code. This enables us to capture the entities of interest, and the relationship between each action, given the features of Programming Languages. Utilizing linguistic cues identified by frequent patterns, ActionIE provides an improved mechanism to discern entities of interest. While our method is broadly applicable, we exemplify its power in the domain of chemical literature, wherein we focus on extracting experimental procedures for chemical synthesis. The code generated by our method can be easily transformed into robotics language which is in high demand in scientific fields. Comprehensive experiments demonstrate the superiority of our method. In addition, we propose a graph-based metric to more accurately reflect the precision of extraction. We also develop a dataset to address the scarcity of scientific literature occurred in existing datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2269835943",
                    "name": "Xianrui Zhong"
                },
                {
                    "authorId": "2312034033",
                    "name": "Yufeng Du"
                },
                {
                    "authorId": "2260339714",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "2316709408",
                    "name": "Ming Zhong"
                },
                {
                    "authorId": "2316653022",
                    "name": "Tingfeng Luo"
                },
                {
                    "authorId": "2316633143",
                    "name": "Qirong Ho"
                },
                {
                    "authorId": "2316788204",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                }
            ]
        }
    ]
}