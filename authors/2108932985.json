{
    "authorId": "2108932985",
    "papers": [
        {
            "paperId": "7c00ef1a471df64215379ca54ed7e630bda29320",
            "title": "MINet: Multilevel Inheritance Network-Based Aerial Scene Classification",
            "abstract": "Scene classification of aerial images is the basis of automatic recognition of complex scenes, and it is also a challenging computer vision task. In recent years, with the rapid development of deep learning, the semantic feature extraction method based on a convolutional neural network (CNN) has made great progress. Moreover, a recent study indicates that combining the semantic information of deep-layer features with the detailed texture information of shallow-layer features in CNN can further improve the performance of classification. In this letter, an end-to-end multilevel feature-based network named multilevel inheritance network (MINet) is proposed for aerial scene classification. First, the feature extraction module based on the feature pyramid network (FPN) is used to get multilevel feature maps. In the process of merging shallow features, high-level semantics of deep-layer are inherited. Then, an attention mechanism is added after the multilevel features to reduce the interference of redundant information and noise. Finally, we use a feature fusion module to automatically learn the weight of each feature layer and make a comprehensive decision. The effectiveness of the proposed method is verified in AID, WHU-RS19 and NWPU-RESISC45 datasets. Results show that the proposed method achieves competitive classification accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143436636",
                    "name": "Jiarui Hu"
                },
                {
                    "authorId": "1411614078",
                    "name": "Qidi Shu"
                },
                {
                    "authorId": "1712236312",
                    "name": "Jun Pan"
                },
                {
                    "authorId": "2929224",
                    "name": "J. Tu"
                },
                {
                    "authorId": "2117826907",
                    "name": "Ying Zhu"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                }
            ]
        },
        {
            "paperId": "b057ef5270ca1ef27474f9fdfe189b815f6b0383",
            "title": "Jitter Detection Method Based on Sequence CMOS Images Captured by Rolling Shutter Mode for High-Resolution Remote Sensing Satellite",
            "abstract": "Satellite platform jitter is a non-negligible factor that affects the image quality of optical cameras. Considering the limitations of traditional platform jitter detection methods that are based on attitude sensors and remote sensing images, this paper proposed a jitter detection method using sequence CMOS images captured by rolling shutter for high-resolution remote sensing satellite. Through the three main steps of dense matching, relative jitter error analysis, and absolute jitter error modeling using sequence CMOS images, the periodic jitter error on the imaging focal plane of the spaceborne camera was able to be measured accurately. The experiments using three datasets with different jitter frequencies simulated from real remote sensing data were conducted. The experimental results showed that the jitter detection method using sequence CMOS images proposed in this paper can accurately recover the frequency, amplitude, and initial phase information of satellite jitter at 100 Hz, 10 Hz, and 2 Hz. Additionally, the detection accuracy reached 0.02 pixels, which can provide a reliable data basis for remote sensing image jitter error compensation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117826907",
                    "name": "Ying Zhu"
                },
                {
                    "authorId": "2122814423",
                    "name": "Tingting Yang"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                },
                {
                    "authorId": "1728210",
                    "name": "Hanyu Hong"
                },
                {
                    "authorId": "49889466",
                    "name": "Yaozong Zhang"
                },
                {
                    "authorId": "2152507051",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "1577422319",
                    "name": "Qilong Rao"
                }
            ]
        },
        {
            "paperId": "f32c8837937f7df5ef3822d10bce99739a83ab54",
            "title": "Robust Correction of Relative Geometric Errors Among GaoFen-7 Regional Stereo Images Based on Posteriori Compensation",
            "abstract": "Correcting the relative geometric errors is an essential step in the generation of digital ortho maps and digital surface models from GaoFen-7 (GF-7) regional images, in which the block adjustment (BA) technology is always adopted. However, the traditional BA methods are typically ineffective and not universal due to their dependence on sufficient control data. Although recently developed BA methods using a large number of observation images can substantially eliminate the additional control data, they are not suitable for the BA with few images in the absence of sufficient control data, which is a situation that is often encountered in practical applications. In such situation, the inevitable elevation error caused by the initial positioning error of images will transfer and accumulate in the horizontal direction of the block, resulting in the inconsistent geometric accuracies among images. Aiming at this problem, this article proposed a practical method of combining a stable free BA and a posteriori compensation. Through the stepwise correction and integration of geometric errors, the elevation error and its cumulative effect in free BA could be eliminated at a small control cost, and a robust result with consistent accuracy could be achieved, even with only a few observation images. This method was validated through experiments performed on GF-7 stereo images, and the satisfactory results indicated that it effectively restrained error accumulation and improved the geo-positioning consistency of regional GF-7 images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31262685",
                    "name": "Y. Pi"
                },
                {
                    "authorId": "1557040159",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2153898578",
                    "name": "Xin Li"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                }
            ]
        },
        {
            "paperId": "83c79bcfb56f4cbf105d10a193bf2b3dde8c85a2",
            "title": "Near Real-Time Automatic Sub-Pixel Registration of Panchromatic and Multispectral Images for Pan-Sharpening",
            "abstract": "This paper presents a near real-time automatic sub-pixel registration method of high-resolution panchromatic (PAN) and multispectral (MS) images using a graphics processing unit (GPU). In the first step, the method uses differential geo-registration to enable accurate geographic registration of PAN and MS images. Differential geo-registration normalizes PAN and MS images to the same direction and scale. There are also some residual misalignments due to the geometrical configuration of the acquisition instruments. These residual misalignments mean the PAN and MS images still have deviations after differential geo-registration. The second step is to use differential rectification with tiny facet primitive to eliminate possible residual misalignments. Differential rectification corrects the relative internal geometric distortion between PAN and MS images. The computational burden of these two steps is large, and traditional central processing unit (CPU) processing takes a long time. Due to the natural parallelism of the differential methods, these two steps are very suitable for mapping to a GPU for processing, to achieve near real-time processing while ensuring processing accuracy. This paper used GaoFen-6, GaoFen-7, ZiYuan3-02 and SuperView-1 satellite data to conduct an experiment. The experiment showed that our method\u2019s processing accuracy is within 0.5 pixels. The automatic processing time of this method is about 2.5 s for 1 GB output data in the NVIDIA GeForce RTX 2080Ti, which can meet the near real-time processing requirements for most satellites. The method in this paper can quickly achieve high-precision registration of PAN and MS images. It is suitable for different scenes and different sensors. It is extremely robust to registration errors between PAN and MS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13660492",
                    "name": "Guangqi Xie"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                },
                {
                    "authorId": "2118678336",
                    "name": "Zhiqi Zhang"
                },
                {
                    "authorId": "2090116166",
                    "name": "Shao Xiang"
                },
                {
                    "authorId": "40867803",
                    "name": "Luxiao He"
                }
            ]
        },
        {
            "paperId": "afb2a9c1b9e5ed1d32abacb658da1e47923f7974",
            "title": "Jitter Detection and Image Restoration Based on Continue Dynamic Shooting Model for High-Resolution TDI CCD Satellite Images",
            "abstract": "Although time delay integration charge-coupled devices (TDI CCDs) have been widely used in high-resolution spaceborne optical cameras, they are sensitive to satellite jitter: the images obtained by them are affected by both distortion and blur. Therefore, according to the multistage integral imaging characteristics of TDI CCDs, this article not only proposes a continue dynamic shooting model (CDSM) to reflect the real push-broom mode of the satellite but also presents a method containing jitter detection and image restoration based on it. In the presented method, the CDSM subdivides the TDI CCD integration intervals. The subdivision number of CDSM is determined by the proposed integral transformation function (ITF). Then, it feeds back into the ITF and also contributes to the point spread function (PSF) estimation. Among the abovementioned, ITF defines the relationship between the parallax images and the jitter curve, and aims to improve the jitter detection performance. Finally, an adaptive image restoration based on context is conducted, which combines time, space, and spectrum information. Besides the simulated images, multispectral images of GaoFen-1 02 satellite were also adopted to validate the performance of the presented method. Experimental results indicate that the accuracy of the jitter detection is increased, and the geometric and radiometric qualities of restored images are also improved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1712236312",
                    "name": "Jun Pan"
                },
                {
                    "authorId": "2054255809",
                    "name": "G. Ye"
                },
                {
                    "authorId": "2117826907",
                    "name": "Ying Zhu"
                },
                {
                    "authorId": "2118944584",
                    "name": "X. Song"
                },
                {
                    "authorId": "49488714",
                    "name": "F. Hu"
                },
                {
                    "authorId": "2115811994",
                    "name": "Chi Zhang"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                }
            ]
        },
        {
            "paperId": "b66effd999d623e5b4b78169f381c47f929b1ea6",
            "title": "Dual-Task Semantic Change Detection for Remote Sensing Images Using the Generative Change Field Module",
            "abstract": "With the advent of very-high-resolution remote sensing images, semantic change detection (SCD) based on deep learning has become a research hotspot in recent years. SCD aims to observe the change in the Earth\u2019s land surface and plays a vital role in monitoring the ecological environment, land use and land cover. Existing research mainly focus on single-task semantic change detection; the problem they face is that existing methods are incapable of identifying which change type has occurred in each multi-temporal image. In addition, few methods use the binary change region to help train a deep SCD-based network. Hence, we propose a dual-task semantic change detection network (GCF-SCD-Net) by using the generative change field (GCF) module to locate and segment the change region; what is more, the proposed network is end-to-end trainable. In the meantime, because of the influence of the imbalance label, we propose a separable loss function to alleviate the over-fitting problem. Extensive experiments are conducted in this work to validate the performance of our method. Finally, our work achieves a 69.9% mIoU and 17.9 Sek on the SECOND dataset. Compared with traditional networks, GCF-SCD-Net achieves the best results and promising performances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2090116166",
                    "name": "Shao Xiang"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                },
                {
                    "authorId": "46813247",
                    "name": "Xiaofan Jiang"
                },
                {
                    "authorId": "13660492",
                    "name": "Guangqi Xie"
                },
                {
                    "authorId": "2118678336",
                    "name": "Zhiqi Zhang"
                },
                {
                    "authorId": "151447998",
                    "name": "Pen Tang"
                }
            ]
        },
        {
            "paperId": "ba19a29b295ea16cb29dd2bb3fa741e1d970366a",
            "title": "Semantic Segmentation for Remote Sensing Images Based on Adaptive Feature Selection Network",
            "abstract": "Semantic segmentation plays a vital role in the segmentation of remote sensing field for its wide range of applications. The major current method for segmentation of remotely sensed imagery is using multiple scales strategy to improve the performance of segmentation networks. However, the ground object with uncertain scale in high-resolution aerial imagery is difficult to be segmented with conventional models. To address this problem, an adaptive feature selection module is designed, in which attention module learns weight contributions of each feature blocks in different scales. We employ the pyramid scene parsing network (PSPNet), DeepLabV3, and U-Net with the proposed module to conduct experiments on two benchmarks (the Vaihingen set and the WHU Building data set). The experimental results and comprehensive analysis validate the efficiency and practicability of the proposed method in semantic segmentation of remote sensing images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2090116166",
                    "name": "Shao Xiang"
                },
                {
                    "authorId": "2089761647",
                    "name": "Quangqi Xie"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                }
            ]
        },
        {
            "paperId": "c1caa0821efbe638a1b182794b60eae09c577737",
            "title": "Dual-Pathway Change Detection Network Based on the Adaptive Fusion Module",
            "abstract": "In recent years, with the development of high-resolution remote sensing (RS) images and deep learning technology, high-quality source data and state-of-the-art methods have become increasingly available, and great progress has been made in change detection (CD) in RS fields. However, existing methods still suffer from weak network feature representation and poor CD performance. To address these problems, we propose a novel CD network, called dual-pathway CD network (DP-CD-Net), which can help enhance feature representation and achieve a more accurate difference map. The proposed method contains a dual-pathway feature difference network (FDN), an adaptive fusion module (AFM), and an auxiliary supervision strategy. Dual-pathway FDNs can effectively enhance feature representation by supplementing the detailed information from the encoding layers. Then, we use the AFM method to fuse the difference maps. To solve the problem of training difficulty, we use the auxiliary supervision strategy to improve the performance of DP-CD-Net. We conduct extensive experiments to validate the performance of the proposed method on the LEVIR-CD dataset. The results demonstrate that the proposed method performs better than existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46813247",
                    "name": "Xiaofan Jiang"
                },
                {
                    "authorId": "2090116166",
                    "name": "Shao Xiang"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                },
                {
                    "authorId": "151447998",
                    "name": "Pen Tang"
                }
            ]
        },
        {
            "paperId": "60b5271872735cf27680c700c99667be3dd8667c",
            "title": "On-Orbit Calibration of Installation Parameter of Multiple Star Sensors System for Optical Remote Sensing Satellite with Ground Control Points",
            "abstract": "Owing to the vibrations and thermal shocks that arise during the launch and orbit penetration process, the on-orbit installation parameters of multiple star sensors are different from the on-ground measured parameters, causing inconsistencies in the attitude determinations from different combination modes and seriously affecting the geometric accuracy of high-resolution optical remote sensing images. This study presents an on-orbit calibration approach for the installation parameters of a multiple star sensors system using ground control points (GCPs). Based on the on-ground installation parameters of the optical axes of conventional star sensors, a fiducial coordinate system is proposed as the calibration coordinate system. The installation parameters of the conventional star sensors are calibrated using the statistical characteristics of angles between axes of the star sensor and three fiducial vectors in the J2000 celestial coordinate system. Based on the GCPs, the relative fiducial parameters are calculated, and the installation parameter of unconventional star sensor is then calibrated with the relative fiducial parameters and statistical characteristics of angles. It can be used for high-resolution optical remote sensing satellite measuring with only two star sensors to unify the fiducial coordinate system. The proposed method is tested using simulated data and on-orbit measurement data. The results demonstrate that the proposed method can calibrate the optical axis of the star sensor without the restriction of the accuracy of horizontal axis. Moreover, the star sensor with a large installation angle error can be calibrated well using the proposed approach. The results of attitude determinations from different star sensor combination modes are consistent, and the geometric accuracy of the remote sensing images is significantly improved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108975876",
                    "name": "Yanli Wang"
                },
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                },
                {
                    "authorId": "2117826907",
                    "name": "Ying Zhu"
                }
            ]
        },
        {
            "paperId": "729b2a1df93c4e81f23f1785be354c349c2004f8",
            "title": "Attitude computation algorithm for star camera based on combining calibration and attitude determination processes.",
            "abstract": "In this paper, a new approach for calculating star camera attitudes, which can calculate calibration parameters and attitude information simultaneously, in situations where precise camera calibration results are unknown, is proposed. This algorithm combines the calibration and attitude determination processes, achieving significantly improved performance as a result. Experiments using 1500 star images from different sky regions show that, compared with the traditional method that separates calibration and attitude determination, the proposed algorithm not only exhibits more precise and stable results, but also shows improved tolerance for the star mismatching which is inevitable in star sensor data process technology.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108932985",
                    "name": "Mi Wang"
                },
                {
                    "authorId": "2130172492",
                    "name": "Jianping Zhao"
                },
                {
                    "authorId": "8129840",
                    "name": "Shuying Jin"
                },
                {
                    "authorId": "1961150",
                    "name": "Yufeng Cheng"
                }
            ]
        }
    ]
}