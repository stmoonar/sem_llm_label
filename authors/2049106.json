{
    "authorId": "2049106",
    "papers": [
        {
            "paperId": "24bff26f19051b1413d1e343322c1ae4bba05428",
            "title": "When to generate hedges in peer-tutoring interactions",
            "abstract": "This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model\u2019s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220550049",
                    "name": "Alafate Abulimiti"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "145431806",
                    "name": "Justine Cassell"
                }
            ]
        },
        {
            "paperId": "74fedee9d809ec766a2089a89435fa7dd1346693",
            "title": "How About Kind of Generating Hedges using End-to-End Neural Models?",
            "abstract": "Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, \u201cface threat\u201d) to one\u2019s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220550049",
                    "name": "Alafate Abulimiti"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "145431806",
                    "name": "Justine Cassell"
                }
            ]
        },
        {
            "paperId": "7b45905b93297c8ac5fe679500e0f17d9230163d",
            "title": "A Survey of Socio-Emotional Strategies for Generation-Based Conversational Agents",
            "abstract": ": As dialogue systems are expected to display more and more \u201chuman\u201d features, a sub\ufb01eld of conversational arti\ufb01cial intelligence (AI) has emerged, aiming to make virtual agents socially competent. As the common outlook \ufb01rmly places emotion in the domain of chit-chatting, most of the studies tackle the problem of social behaviour in open domain applications. In this paper, we provide an overview of such approaches and think about how they can be applied to a task-oriented setting. The angle we explore is the in\ufb02uence of data on socio-emotional neural generation models. We focus on three aspects: dialogue strategies, emotional strategies and persona.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2179784285",
                    "name": "Lorraine Vanel"
                },
                {
                    "authorId": "2079769446",
                    "name": "Alya Yacoubi"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                }
            ]
        },
        {
            "paperId": "91691c66df6bde3d134137dcdc61580503fe7ab9",
            "title": "An Adaptive Layer to Leverage Both Domain and Task Specific Information from Scarce Data",
            "abstract": "Many companies make use of customer service chats to help the customer and try to solve their problem. However, customer service data is confidential and as such, cannot easily be shared in the research community. This also implies that these\ndata are rarely labeled, making it difficult to take advantage of it with machine learning methods. In this paper we present the first work on a customer\u2019s problem status prediction and identification of problematic conversations. Given very small\nsubsets of labeled textual conversations and unlabeled ones, we propose a semi-supervised framework dedicated to customer service data leveraging speaker role information to adapt the model to the domain and the task using a two-step process. Our framework, Task-Adaptive Fine-tuning, goes from predicting customer satisfaction to identifying the status of the customer\u2019s problem, with the latter being the main objective of the multi-task setting. It outperforms recent inductive semi-supervised approaches on this novel task while only considering a relatively low number of parameters to train on during the final target task. We believe it can not only serve models dedicated to customer service but also to any other application making use of confidential conversational data where labeled sets are rare. Source code is available at https://github.com/gguibon/taft",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10669236",
                    "name": "Ga\u00ebl Guibon"
                },
                {
                    "authorId": "1888443",
                    "name": "Matthieu Labeau"
                },
                {
                    "authorId": "2093661892",
                    "name": "Luce Lefeuvre"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                }
            ]
        },
        {
            "paperId": "b3efaa75beada858414a5ba2346dec317203633c",
            "title": "\"You might think about slightly revising the title\u201d: Identifying Hedges in Peer-tutoring Interactions",
            "abstract": "Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2160596647",
                    "name": "Yann Raphalen"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "145431806",
                    "name": "Justine Cassell"
                }
            ]
        },
        {
            "paperId": "c5c3d35f7916d97fa737feabe4e08c38179364ac",
            "title": "It's not Just What You Do but also When You Do It: Novel Perspectives for Informing Interactive Public Speaking Training",
            "abstract": ": Most of the emerging public speaking training systems, while very promising, leverage temporal-aggregate features, which do not take into account the structure of the speech. In this paper, we take a different perspective, testing whether some well-known socio-cognitive theories, like first impressions or primacy and recency effect, apply in the distinct context of public speaking perception. We investigated the impact of the temporal location of speech slices (i.e., at the beginning, middle or end) on the perception of confidence and persua-siveness of speakers giving online movie reviews (the Persuasive Opinion Multimedia dataset). Results show that, when considering multi-modality, usually the middle part of speech is the most informative. Additional findings also suggest the interest to leverage local interpretability (by computing SHAP values) to provide feedback directly, both at a specific time (what speech part?) and for a specific behaviour modality or feature (what behaviour?). This is a first step towards the design of more explainable and pedagogical interactive training systems. Such systems could be more efficient by focusing on improving the speaker\u2019s most important behaviour during the most important moments of their performance, and by situating feedback at specific places within the total speech.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "23567239",
                    "name": "B\u00e9atrice Biancardi"
                },
                {
                    "authorId": "2210774654",
                    "name": "Yingjie Duan"
                },
                {
                    "authorId": "40325099",
                    "name": "Mathieu Chollet"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                }
            ]
        },
        {
            "paperId": "e0a460d77dc29cea3cd5753e8e0bf57cfb812d6e",
            "title": "Fillers in Spoken Language Understanding: Computational and Psycholinguistic Perspectives",
            "abstract": "Disfluencies (i.e. interruptions in the regular flow of speech), are ubiquitous to spoken discourse. Fillers (\"uh\",\"um\") are disfluencies that occur the most frequently compared to other kinds of disfluencies. Yet, to the best of our knowledge, there isn't a resource that brings together the research perspectives influencing Spoken Language Understanding (SLU) on these speech events. This aim of this article is to survey a breadth of perspectives in a holistic way; i.e. from considering underlying (psycho)linguistic theory, to their annotation and consideration in Automatic Speech Recognition (ASR) and SLU systems, to lastly, their study from a generation standpoint. This article aims to present the perspectives in an approachable way to the SLU and Conversational AI community, and discuss moving forward, what we believe are the trends and challenges in each area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72115354",
                    "name": "Tanvi Dinkar"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "1395556312",
                    "name": "I. Vasilescu"
                }
            ]
        },
        {
            "paperId": "1e42f34a97365192e2ed144bbc1cffe90250fa56",
            "title": "One Word, Two Sides: Traces of Stance in Contextualized Word Representations",
            "abstract": "The way we use words is influenced by our opinion. We investigate whether this is reflected in contextualized word embeddings. For example, is the representation of \u201canimal\u201d different between people who would abolish zoos and those who would not? We explore this question from a Lexical Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with stance annotations reveal small but significant differences in word representations between opposing stances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120077253",
                    "name": "Aina Gar\u00ed Soler"
                },
                {
                    "authorId": "1888443",
                    "name": "Matthieu Labeau"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                }
            ]
        },
        {
            "paperId": "21ba26e871560d7101613125628af98cf32a78c8",
            "title": "TINA: Textual Inference with Negation Augmentation",
            "abstract": "Transformer-based language models achieve state-of-the-art results on several natural language processing tasks. One of these is textual entailment , i.e., the task of determining whether a premise logically entails a hypothesis. However, the models perform poorly on this task when the examples contain nega-tions. In this paper, we propose a new definition of textual entailment that captures also negation. This allows us to develop TINA (Textual Inference with Negation Augmentation), a principled technique for negated data augmentation that can be combined with the un-likelihood loss function. Our experiments with different transformer-based models show that our method can significantly improve the performance of the models on textual entailment datasets with negation \u2013 without sacrificing performance on datasets without negation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "17730355",
                    "name": "Chadi Helwe"
                },
                {
                    "authorId": "2119004939",
                    "name": "Simon Coumes"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "37b37b58c19f55c899e99eaa851f9fab0b19277e",
            "title": "LogiTorch: A PyTorch-based library for logical reasoning on natural language",
            "abstract": "Logical reasoning on natural language is one of the most challenging tasks for deep learning models. There has been an increasing interest in developing new benchmarks to evaluate the reasoning capabilities of language models such as BERT. In parallel, new models based on transformers have emerged to achieve ever better performance on these datasets. However, there is currently no library for logical reasoning that includes such benchmarks and models. This paper introduces LogiTorch, a PyTorch-based library that includes different logical reasoning benchmarks, different models, as well as utility functions such as co-reference resolution. This makes it easy to directly use the preprocessed datasets, to run the models, or to finetune them with different hyperparameters. LogiTorch is open source and can be found on GitHub 1 .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "17730355",
                    "name": "Chadi Helwe"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        }
    ]
}