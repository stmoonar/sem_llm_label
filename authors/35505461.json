{
    "authorId": "35505461",
    "papers": [
        {
            "paperId": "0eab64bef16c50399d297ab2544e019487511e4d",
            "title": "Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks",
            "abstract": "While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$\\Delta$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced by our anchoring strategies when sampling hypotheses renders this unnecessary and allows us to support G-$\\Delta$UQ on pretrained models. Indeed, through extensive evaluation under covariate, concept and graph size shifts, we show that G-$\\Delta$UQ leads to better calibrated GNNs for node and graph classification. Further, it also improves performance on the uncertainty-based tasks of out-of-distribution detection and generalization gap estimation. Overall, our work provides insights into uncertainty estimation for GNNs, and demonstrates the utility of G-$\\Delta$UQ in obtaining reliable estimates.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "2a904fa44cdd7d5f276ab7538de75d2dcdb31316",
            "title": "Exploring Classification of Topological Priors With Machine Learning for Feature Extraction",
            "abstract": "In many scientific endeavors, increasingly abstract representations of data allow for new interpretive methodologies and conceptualization of phenomena. For example, moving from raw imaged pixels to segmented and reconstructed objects allows researchers new insights and means to direct their studies toward relevant areas. Thus, the development of new and improved methods for segmentation remains an active area of research. With advances in machine learning and neural networks, scientists have been focused on employing deep neural networks such as U-Net to obtain pixel-level segmentations, namely, defining associations between pixels and corresponding/referent objects and gathering those objects afterward. Topological analysis, such as the use of the Morse-Smale complex to encode regions of uniform gradient flow behavior, offers an alternative approach: first, create geometric priors, and then apply machine learning to classify. This approach is empirically motivated since phenomena of interest often appear as subsets of topological priors in many applications. Using topological elements not only reduces the learning space but also introduces the ability to use learnable geometries and connectivity to aid the classification of the segmentation target. In this article, we describe an approach to creating learnable topological elements, explore the application of ML techniques to classification tasks in a number of areas, and demonstrate this approach as a viable alternative to pixel-level classification, with similar accuracy, improved execution time, and requiring marginal training data.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "87385212",
                    "name": "Samuel Leventhal"
                },
                {
                    "authorId": "2253163",
                    "name": "A. Gyulassy"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "1685087",
                    "name": "Valerio Pascucci"
                }
            ]
        },
        {
            "paperId": "610f0a91b476e3edfcf49523b6789633022ac5a5",
            "title": "On Performance Discrepancies Across Local Homophily Levels in Graph Neural Networks",
            "abstract": "Graph Neural Network (GNN) research has highlighted a relationship between high homophily (i.e., the tendency of nodes of the same class to connect) and strong predictive performance in node classification. However, recent work has found the relationship to be more nuanced, demonstrating that simple GNNs can learn in certain heterophilous settings. To resolve these conflicting findings and align closer to real-world datasets, we go beyond the assumption of a global graph homophily level and study the performance of GNNs when the local homophily level of a node deviates from the global homophily level. Through theoretical and empirical analysis, we systematically demonstrate how shifts in local homophily can introduce performance degradation, leading to performance discrepancies across local homophily levels. We ground the practical implications of this work through granular analysis on five real-world datasets with varying global homophily levels, demonstrating that (a) GNNs can fail to generalize to test nodes that deviate from the global homophily of a graph, and (b) high local homophily does not necessarily confer high performance for a node. We further show that GNNs designed for globally heterophilous graphs can alleviate performance discrepancy by improving performance across local homophily levels, offering a new perspective on how these GNNs achieve stronger global performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064186990",
                    "name": "Donald Loveland"
                },
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "145476099",
                    "name": "Benjamin Fish"
                },
                {
                    "authorId": "2219860006",
                    "name": "Michael T. Shaub"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "78d3cde1da06a51530f7451e4005cd35bad4af20",
            "title": "Heterophily and Graph Neural Networks: Past, Present and Future",
            "abstract": "Recently, there has been interest in understanding the performance of Graph Neural Networks (GNNs) on input graphs exhibiting heterophily, or the tendency for nodes of different classes to connect. Initial findings showed that many standard GNN models struggled on certain benchmark datasets exhibiting high heterophily, prompting research into existing and novel GNN designs that improved learning in these contexts. However, further analyses revealed that certain highly heterophilous settings did not challenge GNNs without these specialized designs, raising questions about the true factors causing performance degradation. In this work, we first review various GNN designs proposed for handling graphs with heterophily, and examine their connections to other GNN research objectives such as robustness, fairness, and oversmoothing avoidance. Next, we conduct an empirical study to investigate the specific heterophilous graph conditions under which GNNs can and cannot perform effectively. Our analysis reveals that although high heterophily does not universally impede conventional GNNs, unique challenges in heterophilous graphs, particularly the intertwined effects with low-degree nodes and complex compatibility patterns, warrant GNN designs specifically tailored to heterophily. In conclusion, we discuss future research directions aimed at advancing the understanding of the impact of heterophily on GNNs across a broader range of contexts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "7957569",
                    "name": "Yujun Yan"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "21613538",
                    "name": "Lingxiao Zhao"
                },
                {
                    "authorId": "3255268",
                    "name": "L. Akoglu"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "bb7cd0e03870c191f7dc5615b0484fccb579794f",
            "title": "Modeling Hierarchical Topological Structure in Scientific Images with Graph Neural Networks",
            "abstract": "Topological analysis reveals meaningful structure in data from a variety of domains. Tasks such as image segmentation can be effectively performed on an image\u2019s topological connectivity using graph neural networks (GNNs). We propose two methods for using GNNs to learn from the hierarchical information captured by complexes at multiple levels of topological persistence: one modifies the training procedure of an existing GNN, and one extends the message passing across all levels of the complex. Experiments on real-world data from three domains show the performance benefits to GNNs from using a hierarchical topological structure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "87385212",
                    "name": "Samuel Leventhal"
                },
                {
                    "authorId": "2253163",
                    "name": "A. Gyulassy"
                },
                {
                    "authorId": "1685087",
                    "name": "Valerio Pascucci"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                }
            ]
        },
        {
            "paperId": "199bbb97ae2d0b0874a25fc8057dc3119de5ed1f",
            "title": "Analyzing Data-Centric Properties for Contrastive Learning on Graphs",
            "abstract": "Recent analyses of self-supervised learning (SSL) \ufb01nd the following data-centric properties to be critical for learning good representations: invariance to task-irrelevant semantics, separability of classes in some latent space, and recoverability of labels from augmented samples. However, given their discrete, non-Euclidean nature, graph datasets and graph SSL methods are unlikely to satisfy these properties. This raises the question: how do graph SSL methods, such as contrastive learning (CL), work well? To systematically probe this question, we perform a generalization analysis for CL when using generic graph augmentations (GGAs), with a focus on data-centric properties. Our analysis yields formal insights into the limitations of GGAs and the necessity of task-relevant augmentations. As we empirically show, GGAs do not induce task-relevant invariances on common benchmark datasets, leading to only marginal gains over naive, untrained baselines. Our theory motivates a synthetic data generation process that enables control over task-relevant information and boasts pre-de\ufb01ned optimal augmentations. This \ufb02exible benchmark helps us identify yet unrecognized limitations in advanced augmentation techniques (e.g., automated methods). Overall, our work rigorously contextualizes, both empirically and theoretically, the effects of data-centric properties on augmentation strategies and learning paradigms for graph SSL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "35573359",
                    "name": "Ekdeep Singh Lubana"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "2049f44d9d85be35dca64c069b7c8e4f1120e7f1",
            "title": "Contrastive Knowledge-Augmented Meta-Learning for Few-Shot Classification",
            "abstract": "Model agnostic meta-learning algorithms aim to infer priors from several observed tasks that can then be used to adapt to a new task with few examples. Given the inherent diversity of tasks arising in existing benchmarks, recent methods have resorted to task-specific adaptation of the prior. Our goal is to improve generalization of meta learners when the task distribution contains challenging distribution shifts and semantic disparities. To this end, we introduce CAML (Contrastive Knowledge-Augmented Meta Learning), a knowledge-enhanced few-shot learning approach that evolves a knowledge graph to encode historical experience, and employs a contrastive distillation strategy to leverage the encoded knowledge for task-aware modulation of the base learner. In addition to the standard few-shot task adaptation, we also consider the more challenging multi-domain task adaptation and few-shot dataset generalization settings in our evaluation with standard benchmarks. Our empirical study shows that CAML (i) enables simple task encoding schemes; (ii) eliminates the need for knowledge extraction at inference time; and most importantly, (iii) effectively aggregates historical experience thus leading to improved performance in both multi-domain adaptation and dataset generalization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175280217",
                    "name": "Rakshith Subramanyam"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "66432861",
                    "name": "Jayram S. Thathachar"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "30fb0044cd58cbf9c4a9e6ca666589547a6c70d8",
            "title": "CAPER: Coarsen, Align, Project, Refine - A General Multilevel Framework for Network Alignment",
            "abstract": "Network alignment, or the task of finding corresponding nodes in different networks, is an important problem formulation in many application domains. We propose CAPER, a multilevel alignment framework that Coarsens the input graphs, Aligns the coarsened graphs, Projects the alignment solution to finer levels and Refines the alignment solution. We show that CAPER can improve upon many different existing network alignment algorithms by enforcing alignment consistency across multiple graph resolutions: nodes matched at finer levels should also be matched at coarser levels. CAPER also accelerates the use of slower network alignment methods, at the modest cost of linear-time coarsening and refinement steps, by allowing them to be run on smaller coarsened versions of the input graphs. Experiments show that CAPER can improve upon diverse network alignment methods by an average of 33% in accuracy and/or an order of magnitude faster in runtime.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146272629",
                    "name": "Jing Zhu"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                }
            ]
        },
        {
            "paperId": "68142fbf9bcda0d50d83cee63f4b63263d43814e",
            "title": "Emerging Patterns in the Continuum Representation of Protein-Lipid Fingerprints",
            "abstract": "Capturing intricate biological phenomena often requires multiscale modeling where coarse and inexpensive models are developed using limited components of expensive and high-\ufb01delity models. Here, we consider such a multiscale framework in the context of cancer biology and address the challenge of evaluating the descriptive capa-bilities of a continuum model developed using 1-dimensional statistics from a molecular dynamics model. Using deep learning, we develop a highly predictive classi\ufb01cation model that identi\ufb01es complex and emergent behavior from the continuum model. With over 99.9% accuracy demonstrated for two simulations, our approach con\ufb01rms the existence of protein-speci\ufb01c \u201clipid \ufb01ngerprints\u201d, i.e., spatial rearrangements of lipids in response to proteins of interest. Through this demonstra-tion, our model also provides external validation of the continuum model, af\ufb01rms the value of such multiscale modeling, and can foster new insights through further analysis of these \ufb01ngerprints.",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12363884",
                    "name": "Konstantia Georgouli"
                },
                {
                    "authorId": "2145761382",
                    "name": "Helgi I. Ing'olfsson"
                },
                {
                    "authorId": "34671366",
                    "name": "Fikret Aydin"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "2682100",
                    "name": "F. Lightstone"
                },
                {
                    "authorId": "145466013",
                    "name": "P. Bremer"
                },
                {
                    "authorId": "144992420",
                    "name": "H. Bhatia"
                }
            ]
        },
        {
            "paperId": "a2bf37d8047735bb6e1f1a59d01aaf1335b5ba75",
            "title": "Analyzing Data-Centric Properties for Graph Contrastive Learning",
            "abstract": "Recent analyses of self-supervised learning (SSL) find the following data-centric properties to be critical for learning good representations: invariance to task-irrelevant semantics, separability of classes in some latent space, and recoverability of labels from augmented samples. However, given their discrete, non-Euclidean nature, graph datasets and graph SSL methods are unlikely to satisfy these properties. This raises the question: how do graph SSL methods, such as contrastive learning (CL), work well? To systematically probe this question, we perform a generalization analysis for CL when using generic graph augmentations (GGAs), with a focus on data-centric properties. Our analysis yields formal insights into the limitations of GGAs and the necessity of task-relevant augmentations. As we empirically show, GGAs do not induce task-relevant invariances on common benchmark datasets, leading to only marginal gains over naive, untrained baselines. Our theory motivates a synthetic data generation process that enables control over task-relevant information and boasts pre-defined optimal augmentations. This flexible benchmark helps us identify yet unrecognized limitations in advanced augmentation techniques (e.g., automated methods). Overall, our work rigorously contextualizes, both empirically and theoretically, the effects of data-centric properties on augmentation strategies and learning paradigms for graph SSL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "35573359",
                    "name": "Ekdeep Singh Lubana"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        }
    ]
}