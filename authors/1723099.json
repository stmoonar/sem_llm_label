{
    "authorId": "1723099",
    "papers": [
        {
            "paperId": "33760960cd067bb82ca2dae9238e896c40573b28",
            "title": "Using Multilevel Business Artifacts for Knowledge Management in Analytics Projects",
            "abstract": "Analytics projects often follow a generic process model, which maps out the main stages and tasks for conducting an analytics project while granting leeway to the project manager regarding the specific execution. A generic process model is instantiated by various organizations for projects applying different types of analytics-descriptive, predictive, prescriptive, etc.-on different use cases in various domains, using vastly different data. Each organization, each type of analytics, and each individual project thus requires a customized process tailored to the specific needs of the organization, type of analytics, and individual project. At each stage of a data analytics project, the project team has to assess the use case (analytics problem) and determine the course of action. Proper documentation of assessment and course of action, i.e., the design decisions and the underlying motivations, facilitates development in the subsequent stages and tasks as well as after deployment when using the developed system. In this paper, we present a use case for multilevel modeling, namely the documentation of knowledge related to analytics projects and data analyses, which are processes aimed at finding patterns in data. We employ the concept of multilevel business artifact, which allows for the representation of data and life cycle models in a single object at multiple levels of abstraction while granting the flexibility to specialize models in objects at lower levels. We use the real-world problem of flight delay prediction as a running example to illustrate the use of multilevel business artifacts for knowledae management in analytics projects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121352055",
                    "name": "Simon Staudinger"
                },
                {
                    "authorId": "2247682251",
                    "name": "Christoph G. Schuetz"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                }
            ]
        },
        {
            "paperId": "e180519d43f740af0e4b1341f37974f5033f08f6",
            "title": "Travel Bird: A Personalized Destination Recommender with TourBERT and Airbnb Experiences",
            "abstract": "We present Travel Bird, a novel personalized destination recommendation and exploration interface which allows its users to find their next tourist destination by describing their specific preferences in a narrative form. Unlike other solutions, Travel Bird is based on TourBERT, a novel NLP model we developed, specifically tailored to the tourism domain. Travel Bird creates a two-dimensional personalized destination exploration space from TourBERT embeddings of social media content and the users' textual description of the experience they are looking for. In this demo, we will showcase several use cases for Travel Bird, which are beneficial for consumers and destination management organizations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087407096",
                    "name": "Veronika Arefieva"
                },
                {
                    "authorId": "12805888",
                    "name": "R. Egger"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "0dafd9cd262610f08057e3a1cf4cb335177a2533",
            "title": "Dual Deep Modeling of Business Processes A Contribution to the Multi-Level Process Challenge",
            "abstract": ". Multi-level modeling (MLM) facilitates conceptual modeling at multiple levels, with clabjects as basic modeling constructs that combine characteristics of metaclasses, classes and objects. Different MLM approaches differ, among others, in the meaning and structure of levels and clabjects, in the strictness or flexibility regarding cross-level relationships, and in the mechanisms for deep characterization by which clabjects at higher levels describe and constrain clabjects at multiple lower levels. The Multi-level Process Challenge provides a testbed for MLM approaches to highlight design decisions regarding these aspects. In this paper we solve the challenge using Dual Deep Modeling (DDM), a MLM approach that features dual potencies which facilitate high flexibility for cross-level relationships. With relationships with dual potencies, a single clabject can play multiple roles at different levels of instantiation, thereby DDM facilitates very compact multi-level models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152383938",
                    "name": "B. Neumayr"
                },
                {
                    "authorId": "2123220",
                    "name": "C. G. Sch\u00fctz"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                }
            ]
        },
        {
            "paperId": "6959c44799844d5182354a310861eab894cb5832",
            "title": "A Reference Process for Judging Reliability of Classification Results in Predictive Analytics",
            "abstract": "Organizations employ data mining to discover patterns in historic data. The models that are learned from the data allow analysts to make predictions about future events of interest. Different global measures, e.g., accuracy, sensitivity, and specificity, are employed to evaluate a predictive model. In order to properly assess the reliability of an individual prediction for a specific input case, global measures may not suffice. In this paper, we propose a reference process for the development of predictive analytics applications that allow analysts to better judge the reliability of individual classification results. The proposed reference process is aligned with the CRISP-DM stages and complements each stage with a number of tasks required for reliability checking. We further explain two generic approaches that assist analysts with the assessment of reliability of individual predictions, namely perturbation and local quality measures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121352055",
                    "name": "Simon Staudinger"
                },
                {
                    "authorId": "2123220",
                    "name": "C. G. Sch\u00fctz"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                }
            ]
        },
        {
            "paperId": "ae14ad54177a551979161d473debd02e6b4ffd85",
            "title": "Towards Multi-level Modeling of Just-in-Time Adaptive Interventions (JITAIs) in Mobile Health",
            "abstract": "The just-in-time adaptive intervention (JITAI) is an intervention design for supporting health behavior changes of an individual especially via mobile technologies. In this position paper we discuss JITAIs as a multi-level modeling problem focusing on the structure of multi-level JITAI models. JITAIs are designed on a generic level, configured for studies, personalized for participants, and evaluated at particular points in time. In this paper we model the multi-level structure of JITAI studies using composition and association classes. We sketch how to transform such models to multi-level models aligned with the multi-level theory. Finally, we discuss challenges and requirements for JITAI systems related to multi-level modeling.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153483482",
                    "name": "Sebastian Gruber"
                },
                {
                    "authorId": "152383938",
                    "name": "B. Neumayr"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                },
                {
                    "authorId": "74303278",
                    "name": "J. Niebauer"
                }
            ]
        },
        {
            "paperId": "4ae819928b9f6356868ca4643d98760aca9d74e0",
            "title": "Predicting Flight Delay Risk Using a Random Forest Classifier Based on Air Traffic Scenarios and Environmental Conditions",
            "abstract": "A reduction of delay costs can be achieved through more adaptable flight planning, which hinges on accurate prediction of delays. In order to counteract the expected delay of flights, air traffic control may adapt flight plans through slot swapping, opening another runway, or changing the runway configuration, for example. Environmental conditions and external events such as runway and airspace closures may render a flight plan obsolete, which must be taken into account when aiming to reduce delay. Air traffic control must recognize changes in the environment and external events such as runway and airspace closures as early as possible in order to adapt flight plans accordingly and avoid delays. Current systems employed by air traffic control do not sufficiently leverage the multitude of available data for the detection of upcoming congestion and, consequently, flight delays. Therefore, flight plans are not adapted fast enough in air traffic scenarios with potentially high delay. In this paper, we aim to predict the risk class of an air traffic scenario based on the expected cost of the delays, and considering information about environmental conditions and external events. In particular, we present a random forest classifier for Atlanta International Airport, which achieves an accuracy of 82.5% for the highest and thus most important risk classes. The development of similar classifiers for other airports may help air traffic control to more accurately predict scenarios with high congestion, and counteract accordingly in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2027012985",
                    "name": "Markus Bardach"
                },
                {
                    "authorId": "2051078",
                    "name": "E. Gringinger"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                },
                {
                    "authorId": "1393568986",
                    "name": "C. Schuetz"
                }
            ]
        },
        {
            "paperId": "85f09e359ff8cb7fba758ac5983f0f23d76f1891",
            "title": "Semantics-based summarisation of ATM information",
            "abstract": "ABSTRACT Pilot briefings, in their traditional form, drown pilots in a sea of information. Rather than unfocused swathes of air traffic management (ATM) information, pilots require only the information for their specific flight, preferably with an emphasis on the most important information. In this paper, we introduce the notion of ATM information cubes \u2013 in analogy to the well-established concept of Online analytical processing (OLAP) cubes in data warehousing. We propose a framework with merge and abstraction operations for the combination and summarization of the information in ATM information cubes to obtain management summaries of relevant information. To this end, we adopt the concept of semantic data container \u2013 a package of data items with a semantic description of the contents. The semantic descriptions then serve to hierarchically organise semantic containers along the dimensions of an ATM information cube. Leveraging this hierarchical organisation, a merge operation combines ATM information from individual semantic containers and collects the data items into composite containers. An abstraction operation summarises the data items within a semantic container, replacing individual data items with more abstract data items with summary information.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2285974450",
                    "name": "Christoph G. Schuetz"
                },
                {
                    "authorId": "152383938",
                    "name": "B. Neumayr"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                },
                {
                    "authorId": "2051078",
                    "name": "E. Gringinger"
                },
                {
                    "authorId": "2110969507",
                    "name": "Scott Wilson"
                }
            ]
        },
        {
            "paperId": "9b62b8edd3f242dfb2b72a8d7edccaa9479242b9",
            "title": "Modelling the Semantics for Model-Driven Interactive Visualizations",
            "abstract": "Visualization of complex information becomes increasingly important in the era of digitalization to convey information in a human readable way and support decision making. Although many visualization tools are available, they are often treated as black boxes and inflexible in customizing visualization and supporting the user in navigating through data and different types of visualizations. This paper presents the semantics of a domain specific modelling language for highly interactive visualizations called VizDSL. VizDSL allows the user to model the navigation on a conceptual level. The semantics are specified by mapping VizDSL concepts to Place Chart Nets which can be used for model validation, simulation and automated tool creation. The mappings are platform independent and can be used by a developer to implement the language.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143848546",
                    "name": "R. Morgan"
                },
                {
                    "authorId": "31843067",
                    "name": "G. Grossmann"
                },
                {
                    "authorId": "1697771",
                    "name": "M. Stumptner"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                }
            ]
        },
        {
            "paperId": "eabe2f22b851d20bb846f429fe636af9b608e097",
            "title": "A Model-Driven Approach for Visualisation Processes",
            "abstract": "With the digital transformation of industries as proposed by Industry 4.0, there will be an increased amount of data collected and exchanged between enterprise systems. Software developers and domain experts are exposed to complex data specifications when dealing with enterprise interoperability. It is a major challenge to understand standards specifications and ensure interoperability in an increasing connected world. In this paper we propose the unique combination of model-driven techniques and interactive data visualisation to simplify the understanding by exploring specifications and data visually without the need to program up front. With our proposed approach it is possible to model and execute interactions of end users with different types of visualisation in a visualisation process. Compared to existing work the advantages of this presented approach are (1) a model-driven tool-independent solution that clearly separates data navigation from change of presentation for increased re-usability and (2) combines them in a visualisation process that (3) can be modelled and executed without the need of programming.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143848546",
                    "name": "R. Morgan"
                },
                {
                    "authorId": "31843067",
                    "name": "G. Grossmann"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                },
                {
                    "authorId": "1697771",
                    "name": "M. Stumptner"
                }
            ]
        },
        {
            "paperId": "0856f7c043b812e684593ed989151e2300e789de",
            "title": "Building an active semantic data warehouse for precision dairy farming",
            "abstract": "ABSTRACT Digitalization of agricultural technology has led to the emergence of precision dairy farming, which strives for the simultaneous improvement of productivity as well as animal well-being in dairy farming through advanced use of technology such as movement sensors and milking parlors to monitor, control, and improve dairy production processes. The data warehouse serves as the appropriate technology for effective and efficient data management, which is paramount to the success of precision dairy farming. This paper presents a joint effort between industry and academia on the experimental development of an active semantic data warehouse to support business intelligence and business analytics in precision dairy farming. The research follows an action research approach, deriving lessons for theory and practice from a set of actions taken in the course of the project. Among these actions are the development of a loading stage to facilitate data integration, the definition of an analysis view as well as the introduction of semantic OLAP patterns to facilitate analysis, and analysis rules to automate periodic analyses. The large volumes of generated sensor data in precision dairy farming required careful decision-making concerning the appropriate level of detail of the data stored in the data warehouse. Semantic technologies played a key role in rendering analysis accessible to end users.",
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123220",
                    "name": "C. G. Sch\u00fctz"
                },
                {
                    "authorId": "27066656",
                    "name": "Simon Schausberger"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                }
            ]
        }
    ]
}