{
    "authorId": "2709512",
    "papers": [
        {
            "paperId": "d51ce0d829d732e4b5d96912c55d2e5725f3dd6a",
            "title": "Characteristics of ChatGPT users from Germany: implications for the digital divide from web tracking data",
            "abstract": "A major challenge of our time is reducing disparities in access to and effective use of digital technologies, with recent discussions highlighting the role of AI in exacerbating the digital divide. We examine user characteristics that predict usage of the AI-powered conversational agent ChatGPT. We combine behavioral and survey data in a web tracked sample of N=1376 German citizens to investigate differences in ChatGPT activity (usage, visits, and adoption) during the first 11 months from the launch of the service (November 30, 2022). Guided by a model of technology acceptance (UTAUT- 2), we examine the role of socio-demographics commonly associated with the digital divide in ChatGPT activity and explore further socio-political attributes identified via stability selection in Lasso regressions. We confirm that lower age and higher education affect ChatGPT usage, but do not find that gender or income do. We find full-time employment and more children to be barriers to ChatGPT activity. Using a variety of social media was positively associated with ChatGPT activity. In terms of political variables, political knowledge and political self-efficacy as well as some political behaviors such as voting, debating political issues online and offline and political action online were all associated with ChatGPT activity, with online political debating and political self-efficacy negatively so. Finally, need for cognition and communication skills such as writing, attending meetings, or giving presentations, were also associated with ChatGPT engagement, though chairing/organizing meetings was negatively associated. Our research informs efforts to address digital disparities and promote digital literacy among underserved populations by presenting implications, recommendations, and discussions on ethical and social issues of our findings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145104204",
                    "name": "C. Kacperski"
                },
                {
                    "authorId": "2237991479",
                    "name": "Roberto Ulloa"
                },
                {
                    "authorId": "2237993077",
                    "name": "Denis Bonnay"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "70171338",
                    "name": "Peter Selb"
                },
                {
                    "authorId": "2237991580",
                    "name": "Andreas Spitz"
                }
            ]
        },
        {
            "paperId": "d97e3d81a1abbab700e3746f0f03f73af4db850e",
            "title": "Browsing behavior exposes identities on the Web",
            "abstract": "How easy is it to uniquely identify a person based solely on their web browsing behavior? Here we show that when people navigate the Web, their online traces produce fingerprints that identify them. Merely the four most visited web domains are enough to identify 95% of the individuals. These digital fingerprints are stable and render high re-identifiability. We demonstrate that we can re-identify 80% of the individuals in separate time slices of data. Such a privacy threat persists even with limited information about individuals' browsing behavior, reinforcing existing concerns around online privacy.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2149065784",
                    "name": "Marcos Oliveira"
                },
                {
                    "authorId": "2276483234",
                    "name": "Jonathan Yang"
                },
                {
                    "authorId": "2276431025",
                    "name": "Daniel Griffiths"
                },
                {
                    "authorId": "2237993077",
                    "name": "Denis Bonnay"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                }
            ]
        },
        {
            "paperId": "4962ce1242ff905b71e199964eafea3d2ad9688d",
            "title": "A Domain-adaptive Pre-training Approach for Language Bias Detection in News",
            "abstract": "Media bias is a multi-faceted construct influencing individual behavior and collective decision-making. Slanted news reporting is the result of one-sided and polarized writing which can occur in various forms. In this work, we focus on an important form of media bias, i.e. bias by word choice. Detecting biased word choices is a challenging task due to its linguistic complexity and the lack of representative gold-standard corpora. We present DA-RoBERTa, a new state-of-the-art transformer-based model adapted to the media bias domain which identifies sentence-level bias with an F1 score of 0.814. In addition, we also train, DA-BERT and DA-BART, two more transformer models adapted to the bias domain. Our proposed domain-adapted models outperform prior bias detection approaches on the same data. CCS CONCEPTS \u2022 Computing methodologies \u2192 Natural language processing; \u2022 Information systems \u2192 Clustering and classification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2140442370",
                    "name": "Jan-David Krieger"
                },
                {
                    "authorId": "1845794923",
                    "name": "Timo Spinde"
                },
                {
                    "authorId": "8837621",
                    "name": "Terry Ruas"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "145151838",
                    "name": "Bela Gipp"
                }
            ]
        },
        {
            "paperId": "b2bcb86f5de31659239a4a00f6118a715ba9832e",
            "title": "Novelty in News Search: A Longitudinal Study of the 2020 US Elections",
            "abstract": "The 2020 US elections news coverage was extensive, with new pieces of information generated rapidly. This evolving scenario presented an opportunity to study the performance of search engines in a context in which they had to quickly process information as it was published. We analyze novelty, a measurement of new items that emerge in the top news search results, to compare the coverage and visibility of different topics. Using virtual agents that simulate human web browsing behavior to collect search engine result pages, we conduct a longitudinal study of news results of five search engines collected in short bursts (every 21 minutes) from two regions (Oregon, US and Frankfurt, Germany), starting on election day and lasting until one day after the announcement of Biden as the winner. We find more new items emerging for election related queries (\u201cjoe biden,\u201d \u201cdonald trump,\u201d and \u201cus elections\u201d) compared to topical (e.g., \u201ccoronavirus\u201d) or stable (e.g., \u201cholocaust\u201d) queries. We demonstrate that our method captures sudden changes in highly covered news topics as well as multiple differences across search engines and regions over time. We highlight novelty imbalances between candidate queries which affect their visibility during electoral periods, and conclude that, when it comes to news, search engines are responsible for such imbalances, either due to their algorithms or the set of news sources that they rely on.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1975336",
                    "name": "R. Ulloa"
                },
                {
                    "authorId": "51428797",
                    "name": "M. Makhortykh"
                },
                {
                    "authorId": "1484797547",
                    "name": "Aleksandra Urman"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                }
            ]
        },
        {
            "paperId": "9a9d6e60b025a3982c0b281a3847f84bea4ad8bb",
            "title": "Misinformation, believability, and vaccine acceptance over 40 countries: Takeaways from the initial phase of the COVID-19 infodemic",
            "abstract": "The COVID-19 pandemic has been damaging to the lives of people all around the world. Accompanied by the pandemic is an infodemic, an abundant and uncontrolled spread of potentially harmful misinformation. The infodemic may severely change the pandemic\u2019s course by interfering with public health interventions such as wearing masks, social distancing, and vaccination. In particular, the impact of the infodemic on vaccination is critical because it holds the key to reverting to pre-pandemic normalcy. This paper presents findings from a global survey on the extent of worldwide exposure to the COVID-19 infodemic, assesses different populations\u2019 susceptibility to false claims, and analyzes its association with vaccine acceptance. Based on responses gathered from over 18,400 individuals from 40 countries, we find a strong association between perceived believability of COVID-19 misinformation and vaccination hesitancy. Our study shows that only half of the online users exposed to rumors might have seen corresponding fact-checked information. Moreover, depending on the country, between 6% and 37% of individuals considered these rumors believable. A key finding of this research is that poorer regions were more susceptible to encountering and believing COVID-19 misinformation; countries with lower gross domestic product (GDP) per capita showed a substantially higher prevalence of misinformation. We discuss implications of our findings to public campaigns that proactively spread accurate information to countries that are more susceptible to the infodemic. We also defend that fact-checking platforms should prioritize claims that not only have wide exposure but are also perceived to be believable. Our findings give insights into how to successfully handle risk communication during the initial phase of a future pandemic.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "48829479",
                    "name": "Karandeep Singh"
                },
                {
                    "authorId": "2053301059",
                    "name": "Gabriel Lima"
                },
                {
                    "authorId": "1775511",
                    "name": "Meeyoung Cha"
                },
                {
                    "authorId": "38090814",
                    "name": "Chiyoung Cha"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "36663090",
                    "name": "Yong-Yeol Ahn"
                },
                {
                    "authorId": "2307347",
                    "name": "Onur Varol"
                }
            ]
        },
        {
            "paperId": "2879f6eb47af06a01727afd4c6f14a0ad63d0dd4",
            "title": "Empirical Evaluation of Three Common Assumptions in Building Political Media Bias Datasets",
            "abstract": "In this work, we empirically validate three common assumptions in building political media bias datasets, which are (i) labelers' political leanings do not affect labeling tasks, (ii) news articles follow their source outlet's political leaning, and (iii) political leaning of a news outlet is stable across different topics. We build a ground-truth dataset of manually annotated article-level political leaning and validate the three assumptions. Our findings warn that the three assumptions could be invalid even for a small dataset. We hope that our work calls attention to the (in)validity of common assumptions in building political media bias datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103923952",
                    "name": "S. Ganguly"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "40660541",
                    "name": "Jisun An"
                },
                {
                    "authorId": "2592694",
                    "name": "Haewoon Kwak"
                }
            ]
        },
        {
            "paperId": "b29171a0de88c5278360e7d101ded3201e4cb493",
            "title": "Web Routineness and Limits of Predictability: Investigating Demographic and Behavioral Differences Using Web Tracking Data",
            "abstract": "Understanding human activities and movements on the Web is not only important for computational social scientists but can also offer valuable guidance for the design of online systems for recommendations, caching, advertising, and personalization. In this work, we demonstrate that people tend to follow routines on the Web, and these repetitive patterns of web visits increase their browsing behavior's achievable predictability. We present an information-theoretic framework for measuring the uncertainty and theoretical limits of predictability of human mobility on the Web. We systematically assess the impact of different design decisions on the measurement. We apply the framework to a web tracking dataset of German internet users. Our empirical results highlight that individual's routines on the Web make their browsing behavior predictable to 85% on average, though the value varies across individuals. We observe that these differences in the users' predictabilities can be explained to some extent by their demographic and behavioral attributes.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "2110649249",
                    "name": "Marcos A. C. Oliveira"
                },
                {
                    "authorId": "2043234640",
                    "name": "Orkut Karacalik"
                },
                {
                    "authorId": "3139034",
                    "name": "Denis Bonnay"
                },
                {
                    "authorId": "144065562",
                    "name": "Claudia Wagner"
                }
            ]
        },
        {
            "paperId": "8937f70c43d348663ba211c809b5d2be0356d5d3",
            "title": "Analyzing Biases in Perception of Truth in News Stories and Their Implications for Fact Checking",
            "abstract": "Misinformation on social media has become a critical problem, particularly during a public health pandemic. Most social platforms today rely on users\u2019 voluntary reports to determine which news stories to fact-check first. Despite the importance, no prior work has explored the potential biases in such a reporting process. This work proposes a novel methodology to assess how users perceive truth or misinformation in online news stories. By conducting a large-scale survey ( $N =15$ 000), we identify the possible biases in news perceptions and explore how partisan leanings influence the news selection algorithm for fact checking. Our survey reveals several perception biases or inaccuracies in estimating the truth level of stories. The first kind, called the total perception bias (TPB), is the aggregate difference in the ground truth and perceived truth level. The next two are the false-positive bias (FPB) and false-negative bias (FNB), which measures users\u2019 gullibility and cynicality of a given claim. We also propose ideological mean perception bias (IMPB), which quantifies a news story\u2019s ideological disputability. Collectively, these biases indicate that user perceptions are not correlated with the ground truth of new stories; users believe some stories to be more false and vice versa. This calls for the need to fact-check news stories that exhibit the most considerable perception biases first, which the current voluntary reporting does not offer. Based on these observations, we propose a new framework that can best leverage users\u2019 truth perceptions to remove false stories, correct misperceptions of users, or decrease ideological disagreements. We discuss how this new prioritizing scheme can aid platforms to significantly reduce the impact of fake news on user beliefs.",
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "authors": [
                {
                    "authorId": "1818176",
                    "name": "Mahmoudreza Babaei"
                },
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "2391370",
                    "name": "Elissa M. Redmiles"
                },
                {
                    "authorId": "1775511",
                    "name": "Meeyoung Cha"
                },
                {
                    "authorId": "1958921",
                    "name": "K. Gummadi"
                }
            ]
        },
        {
            "paperId": "14f8b9729b22fedcc0998fe655cd64a161c36388",
            "title": "Media Bias Monitor: Quantifying Biases of Social Media News Outlets at Large-Scale",
            "abstract": "\n \n As Internet users increasingly rely on social media sites like Facebook and Twitter to receive news, they are faced with a bewildering number of news media choices. For example, thousands of Facebook pages today are registered and categorized as some form of news media outlets. Inferring the bias (or slant) of these media pages poses a difficult challenge for media watchdog organizations that traditionally rely on content analysis. In this paper, we explore a novel scalable methodology to accurately infer the biases of thousands of news sources on social media sites like Facebook and Twitter. Our key idea is to utilize their advertiser interfaces, that offer detailed insights into the demographics of the news source\u2019s audience on the social media site. We show that the ideological (liberal or conservative) leaning of a news source can be accurately estimated by the extent to which liberals or conservatives are over-/under-represented among its audience. Additionally, we show how biases in a news source\u2019s audience demographics, along the lines of race, gender, age, national identity, and income, can be used to infer more fine-grained biases of the source, such as social vs. economic vs. nationalistic conservatism. Finally, we demonstrate the scalability of our approach by building and publicly deploying a system, called \"Media Bias Monitor\", which makes the biases in audience demographics for over 20,000 news outlets on Facebook transparent to any Internet user.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2411946",
                    "name": "Filipe Nunes Ribeiro"
                },
                {
                    "authorId": "2065172027",
                    "name": "Lucas Henrique"
                },
                {
                    "authorId": "1869561",
                    "name": "Fabr\u00edcio Benevenuto"
                },
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "1818176",
                    "name": "Mahmoudreza Babaei"
                },
                {
                    "authorId": "1958921",
                    "name": "K. Gummadi"
                }
            ]
        },
        {
            "paperId": "9b23a0ce202e9e2ab7ccae4c9892143e21eba221",
            "title": "Purple Feed: Identifying High Consensus News Posts on Social Media",
            "abstract": "Although diverse news stories are actively posted on social media, readers often focus on the news which reinforces their pre-existing views, leading to 'filter bubble' effects. To combat this, some recent systems expose and nudge readers toward stories with different points of view. One example is the Wall Street Journal's 'Blue Feed, Red Feed' system, which presents posts from biased publishers on each side of a topic. However, these systems have had limited success. We present a complementary approach which identifies high consensus 'purple' posts that generate similar reactions from both 'blue' and 'red' readers. We define and operationalize consensus for news posts on Twitter in the context of US politics. We show that high consensus posts can be identified and discuss their empirical properties. We present a method for automatically identifying high and low consensus news posts on Twitter, which can work at scale across many publishers. To do this, we propose a novel category of audience leaning based features, which we show are well suited to this task. Finally, we present our 'Purple Feed' system which highlights high consensus posts from publishers on both sides of the political spectrum.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1818176",
                    "name": "Mahmoudreza Babaei"
                },
                {
                    "authorId": "2709512",
                    "name": "Juhi Kulshrestha"
                },
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                },
                {
                    "authorId": "1869561",
                    "name": "Fabr\u00edcio Benevenuto"
                },
                {
                    "authorId": "1958921",
                    "name": "K. Gummadi"
                },
                {
                    "authorId": "145689461",
                    "name": "Adrian Weller"
                }
            ]
        }
    ]
}