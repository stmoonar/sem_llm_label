{
    "authorId": "1722023",
    "papers": [
        {
            "paperId": "9dfdc45d0b9f1b59d8e8737559e8aaf5f5de7f04",
            "title": "Declarative RDF Construction from In-Memory Data Structures with RML",
            "abstract": "Knowledge graphs are often constructed from heterogeneous data sources using declarative mapping languages. Mapping languages define rules that apply ontology terms to raw data to describe how a knowledge graph should be constructed from these raw data. While most mapping languages and systems support knowledge graph construction from different data formats, e.g., CSV, XML or JSON, and different types of data sources, e.g., files, Web APIs or databases, there is still no support for mapping in-memory data structures to knowledge graphs, i.e. data which is temporarily stored in RAM. Currently, this data must first be stored in HDD, locally or in the cloud, for RDF construction systems to access them and construct a knowledge graph. However, writing these data to HDD and reading from HDD is a computationally expensive and redundant task. In this paper, we propose a method to construct RDF graphs from data produced by a software process and stored in RAM. We introduce an extension of RML\u2019s Logical Source to describe data structures produced by software, and exemplify our proposal with Python data structures. We extend a well-known RML system, Morph-KGC, to show the feasibility of our method and validate this extension with two use cases: OpenML, which translates machine learning executions into RDF, and SOMEF, which extracts software metadata from its documentation, converting them to triples. This proposal simplifies the construction of RDF graphs from in-memory data structures stored temporarily in RAM and enables the integration of data stored both in RAM and HDD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220348484",
                    "name": "Ioannis Dasoulas"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "1df5a9fcdcef9461abfdd5da2521331627edb6eb",
            "title": "Declarative Description of Knowledge Graphs Construction Automation: Status & Challenges",
            "abstract": "Nowadays, Knowledge Graphs (KG) are among the most powerful mechanisms to represent knowledge and integrate data from multiple domains. However, most of the available data sources are still described in heterogeneous data structures, schemes, and formats. The conversion of these sources into the desirable KG requires manual and time-consuming tasks, such as programming translation scripts, defining declarative mapping rules, etc. In this vision paper, we analyze the trends regarding the automation of KG construction but also the use of mapping languages for the same process, and align the two by analyzing their tasks and a few exemplary tools. Our aim is not to have a complete study but to investigate if there is potential in this direction and, if so, to discuss what challenges we need to address to guarantee the maintainability, explainability, and reproducibility of the KG construction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "36a50574d46ecc36a54d678c3ee500354733b9f6",
            "title": "Why to Tie to a Single Data Mapping Language? Enabling a Transformation from ShExML to RML",
            "abstract": "Different mapping languages (e.g., RML, SPARQL-Generate and ShExML) have appeared in the last years covering different use cases, scenarios and functionalities. However, users cannot seamlessly interchange between these mapping languages. In this paper, we propose a translation from ShExML to RML letting users benefit from the usability of ShExML and the wide-support and functionalities of RML.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1409722166",
                    "name": "Herminio Garc\u00eda-Gonz\u00e1lez"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "0f32ae0eb2cc0d626a8649c56b13df8f43bba59e",
            "title": "Visual notations for viewing RDF constraints with UnSHACLed",
            "abstract": "The quality of knowledge graphs can be assessed by a validation against specified constraints, typically use-case specific and modeled by human users in a manual fashion. Visualizations can improve the modeling process as they are specifically designed for human information processing, possibly leading to more accurate constraints, and in turn higher quality knowledge graphs. However, it is currently unknown how such visualizations support users when viewing RDF constraints as no scientific evidence for the visualizations\u2019 effectiveness is provided. Furthermore, some of the existing tools are likely suboptimal, as they lack support for edit\u00a0operations or common constraints types. To establish a\u00a0baseline, we have defined visual notations to represent RDF constraints and implemented them in UnSHACLed, a\u00a0tool that is independent of a\u00a0concrete RDF constraint language. In this paper, we (i)\u00a0present two visual notations that support all SHACL core constraints, built upon the commonly used visualizations VOWL and UML, (ii)\u00a0analyze both notations based on cognitive effective design principles, (iii)\u00a0perform a comparative user study between both visual notations, and (iv)\u00a0present our open source tool UnSHACLed incorporating our efforts. Users were presented RDF constraints in both visual notations and had to answer questions based on visualization task taxonomies. Although no statistical significant difference in mean error rates was observed, all study participants preferred ShapeVOWL in a self assessment to answer RDF constraint-related questions. Furthermore, ShapeVOWL adheres to more cognitive effective design principles according to our performed comparison. Study participants argued that the increased visual features of ShapeVOWL made it easier to spot constraints, but a list of constraints\u00a0\u2013 as in ShapeUML\u00a0\u2013 is easier to read. However, also that more deviations from the strict UML specification and introduction of more visual features can improve ShapeUML. From these findings we conclude that ShapeVOWL has a higher potential to represent RDF constraints more effective compared to ShapeUML. But also that the clear and efficient text encoding of ShapeUML can be improved with visual features. A\u00a0one-size-fits-all approach to RDF constraint visualization and editing will be insufficient. Therefore, to support different audiences and use cases, user interfaces of RDF constraint editors need to support different visual notations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38278085",
                    "name": "S. Lieber"
                },
                {
                    "authorId": "2141864424",
                    "name": "Ben De\u00a0Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2141885284",
                    "name": "Femke Br\u00fcckmann"
                },
                {
                    "authorId": "2141886718",
                    "name": "Ruben Wambacq"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "1631d63efdff3b6bca16d600e579e3f5278ad714",
            "title": "BESOCIAL: A Sustainable Knowledge Graph-Based Workflow for Social Media Archiving",
            "abstract": "Social media as infrastructure for public discourse provide valuable information that needs to be preserved. Several tools for social media harvesting exist, but still only fragmented workflows may be formed with different combinations of such tools. On top of that, social media data but also preservation-related metadata standards are heterogeneous, resulting in a costly manual process. In the framework of BESOCIAL at the Royal Library of Belgium (KBR), we develop a sustainable social media archiving workflow that integrates heterogeneous data sources in a Europeana and PREMIS-based data model to describe data preserved by open source tools. This allows data stewardship on a uniform representation and we generate metadata records automatically via queries. In this paper, we present a comparison of social media harvesting tools and our Knowledge Graph-based solution which reuses off-the-shelf open source tools to harvest social media and automatically generate preservation-related metadata records. We validate our solution by generating Encoded Archival Description (EAD) and bibliographic MARC records for preservation of harvested social media collections from Twitter collected at KBR. Other archiving institutions can build upon our solution and customize it to their own social media archiving policies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38278085",
                    "name": "S. Lieber"
                },
                {
                    "authorId": "2134591523",
                    "name": "Dylan Van Assche"
                },
                {
                    "authorId": "48466632",
                    "name": "Sally Chambers"
                },
                {
                    "authorId": "1692970105",
                    "name": "F. Messens"
                },
                {
                    "authorId": "104695937",
                    "name": "Friedel Geeraert"
                },
                {
                    "authorId": "2835451",
                    "name": "Julie M. Birkholz"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "53d26eadb549c5c2b092a341a51c3607a00f5b3b",
            "title": "Shape Fragments",
            "abstract": "In constraint languages for RDF graphs, such as ShEx and SHACL, constraints on nodes and their properties in RDF graphs are known as\"shapes\". Schemas in these languages list the various shapes that certain targeted nodes must satisfy for the graph to conform to the schema. Using SHACL, we propose in this paper a novel use of shapes, by which a set of shapes is used to extract a subgraph from an RDF graph, the so-called shape fragment. Our proposed mechanism fits in the framework of Linked Data Fragments. In this paper, (i) we define our extraction mechanism formally, building on recently proposed SHACL formalizations; (ii) we establish correctness properties, which relate shape fragments to notions of provenance for database queries; (iii) we compare shape fragments with SPARQL queries; (iv) we discuss implementation options; and (v) we present initial experiments demonstrating that shape fragments are a feasible new idea.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091007362",
                    "name": "Thomas Delva"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "152522377",
                    "name": "Maxim Jakubowski"
                },
                {
                    "authorId": "1713880",
                    "name": "J. V. D. Bussche"
                }
            ]
        },
        {
            "paperId": "56d4125aee41a3466f941aeca470f1f81753a1ca",
            "title": "RML2SHACL: RDF Generation Taking Shape",
            "abstract": "RDF graphs are often generated by mapping data in other (semi-)structured data formats to RDF. Such mapped graphs have a repetitive structure defined by (i) the mapping rules and (ii) the schema of the input sources. However, this information is not exploited beyond its original scope. SHACL was recently introduced to model constraints that RDF graphs should validate. SHACL shapes and their constraints are either manually defined or derived from ontologies or RDF graphs. We investigate a method to derive the shapes and their constraints from mapping rules, allowing the generation of the RDF graph and the corresponding shapes in one step. In this paper, we present RML2SHACL: an approach to generate SHACL shapes that validate RDF graphs defined by RML mapping rules. RML2SHACL relies on our proposed set of correspondences between RML and SHACL constructs. RML2SHACL covers a large variety of RML constructs, as proven by generating shapes for the RML test cases. A comparative analysis shows that shapes generated by RML2SHACL are similar to shapes generated by ontology-based tools, with a larger focus on data value-based constraints instead of schema-based constraints. We also found that RML2SHACL has a faster execution time than data-graph based approaches for data sizes of 90MB and higher.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091007362",
                    "name": "Thomas Delva"
                },
                {
                    "authorId": "2141793851",
                    "name": "B. De Smedt"
                },
                {
                    "authorId": "2141791028",
                    "name": "Sitt Min Oo"
                },
                {
                    "authorId": "2134591523",
                    "name": "Dylan Van Assche"
                },
                {
                    "authorId": "38278085",
                    "name": "S. Lieber"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "a133dc2a08d2ccd20e5c9060a9aeca8f41c7fd66",
            "title": "RML-star: A Declarative Mapping Language for RDF-star Generation",
            "abstract": ". RDF-star was recently proposed as a convenient representation to annotate statements in RDF with metadata by introducing the so-called RDF-star triples, bridging the gap between RDF and property graphs. However, even though there are many solutions to generate RDF graphs, there is no systematic approach so far to generate RDF-star graphs from heterogeneous data sources. In this paper, we propose RML-star , an extension of the RML mapping language to generate RDF-star. We introduce the extension of the RML ontology and the associated speci\ufb01cation with representative examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091007362",
                    "name": "Thomas Delva"
                },
                {
                    "authorId": "2107052011",
                    "name": "Juli\u00e1n Arenas-Guerrero"
                },
                {
                    "authorId": "1485497099",
                    "name": "Ana Iglesias-Molina"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "b978c37f2e0aeb09523b8fb25a0a635441f2b46a",
            "title": "PROV4ITDaTa: Transparent and direct transferof personal data to personal stores",
            "abstract": "Data is scattered across service providers, heterogeneously structured in various formats. By lack of interoperability, data portability is hindered, and thus user control is inhibited. An interoperable data portability solution for transferring personal data is needed. We demo PROV4ITDaTa: a Web application, that allows users to transfer personal data into an interoperable format to their personal data store. PROV4ITDaTa leverages the open-source solutions RML.io, Comunica, and Solid: (i) the RML.io toolset to describe how to access data from service providers and generate interoperable datasets; (ii) Comunica to query these and more flexibly generate enriched datasets; and (iii) Solid Pods to store the generated data as Linked Data in personal data stores. As opposed to other (hard-coded) solutions, PROV4ITDaTa is fully transparent, where each component of the pipeline is fully configurable and automatically generates detailed provenance trails. Furthermore, transforming the personal data into RDF allows for an interopable solution. By maximizing the use of open-source tools and open standards, PROV4ITDaTa facilitates the shift towards a data ecosystem wherein users have control of their data, and providers can focus on their service instead of trying to adhere to interoperability requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091080870",
                    "name": "Gertjan De Mulder"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "cfd3929eb7eb98209acea307838be4c9ddc4d33c",
            "title": "Integrating Nested Data into Knowledge Graphs with RML Fields",
            "abstract": "To support business decisions or improve operational efficiency, heterogeneous data is often integrated into a knowledge graph. This integration can be achieved with one of the existing declarative mapping languages, which offer declarative data integration in the form of knowledge graphs. However, current mapping languages cannot always integrate data with nested structure, such as JSON or XML files or JSON documents stored in a database column. We designed a backwards-compatible extension of the RDF Mapping Language (RML) which empowers it to integrate nested data: RML fields. In this paper, we introduce RML fields, compare it with the state of the art in mapping languages, and validate it on mapping challenges formulated by the Knowledge Graph Construction W3C community group. Our extension allows addressing several of the challenges related to nested data that were previously not possible. RML fields can integrate even more datasets into knowledge graphs with all the advantages of using a language specially designed for that purpose. Our extension intends integrating multiple data sets independently, but some use cases require joins or other operations during knowledge graph generation, which we will investigate in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091007362",
                    "name": "Thomas Delva"
                },
                {
                    "authorId": "1742222115",
                    "name": "Dylan Van Assche"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "2959801",
                    "name": "B. Meester"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        }
    ]
}