{
    "authorId": "1405885024",
    "papers": [
        {
            "paperId": "337546b96b1f9f259c4104d83b793374823e03d5",
            "title": "Collaborative Service Placement, Task Scheduling, and Resource Allocation for Task Offloading With Edge-Cloud Cooperation",
            "abstract": "In an edge-cloud cooperative computing network, the task offloading performance can be further improved by the edge-cloud and edge-edge cooperation, in which the tasks can be offloaded from an edge server to the cloud server or another edge server. Such edge-cloud cooperative task offloading can jointly utilize the resources of all the edge servers and the cloud server. This paper proposes a collaborative service placement, task scheduling, computing resource allocation, and transmission rate allocation scheme for a multi-task and multi-service scenario with edge-cloud cooperation. The objective of our optimization problem is to minimize the total task processing delay while guaranteeing long-term task queuing stability. Considering the high complexity of the original optimization problem, we transform the problem into a deterministic problem for each time slot based on the Lyapunov optimization. Then, we design an iterative algorithm to obtain the whole solution to the problem efficiently based on a hybrid method using multiple numerical techniques. Further, considering the inherent difference in the optimization periods of the service placement, resource allocation, and task scheduling sub-problems, we design a multi-timescale algorithm to solve the sub-problems with different optimization periods. The complexity of the proposed algorithms is analyzed, and extensive simulations are conducted by varying multiple crucial parameters. The superiority of our scheme is demonstrated in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2186397028",
                    "name": "Xun Liu"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "103483738",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "583e388d7d9fa038579f0cf9491db608c5b05f51",
            "title": "Resource Matching for Blockchain-Assisted Edge Computing Networks",
            "abstract": "The combination of edge computing (EC) and blockchain can enhance task processing while ensuring security and credibility. To maximize system performance and avoid resource waste in task offloading, it is essential to match the resource allocation of the task computing and the blockchain consensus process. However, the existing works treated the above two processes as two independent processes and optimized them separately and ignored the above matching problem. In this article, we propose a resource management scheme for blockchain-assisted EC networks consisting of multiple devices, multiple base stations equipped with edge servers, a cloud server, and a network controller deployed on the edge layer. To minimize the total task processing delay and energy consumption of the devices, we formulate a joint task processing problem incorporating task scheduling, transmit power control, and computing resource allocation. To match the computing delay and consensus delay of each task, we balance the computing resources allocated for the two processes. We design a deep reinforcement learning (DRL) algorithm that utilizes the twin-delayed deep deterministic policy gradient (TD3) technology embedded with a fast numerical method, which effectively reduces the training complexity of the DRL model. Extensive experiments are conducted by varying four crucial parameters. The superiority of our scheme is demonstrated in comparison with three other reference schemes. The performance of our scheme is about 18.3%\u201324.1% higher than that of other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2178604984",
                    "name": "Zhibo Hao"
                },
                {
                    "authorId": "2274342023",
                    "name": "Bihua Tang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "eb9037b29be6ced20399a98f5362023e1b168035",
            "title": "A Deep Reinforcement Learning Model for a Two-Layer Scheduling Policy in Urban Public Resources",
            "abstract": "The issue of efficient scheduling and deployment of urban public resources has become increasingly important with the development of technological innovations and the mobility of societies. The arbitrary usage behavior of users causes the unbalanced distribution of resources and makes it difficult for users to get adequate resources in some places but redundant resources in others. Therefore, designing an efficient scheduling policy for public resources becomes crucial to promoting resource utilization and customer satisfaction. In this article, we propose a novel scheduling system for public resources that aligns with the actual value-driven scheduling strategy and take the bike-sharing system as an example. Then, we design a deep reinforcement learning algorithm named two action layer proximal policy optimization (TALPPO) to generate an effective sharing-bike scheduling strategy under realistic constraints, which could help enterprises to make better management and operation decisions. Finally, we compare the proposed algorithm with the other ten baseline models and provide extensive experimental results on two data sets called Mobike (dockless) and Citi Bike (docked) to evaluate the performance of our proposed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1744918",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2149699160",
                    "name": "He Wang"
                },
                {
                    "authorId": "2223414007",
                    "name": "Hegeng Zhang"
                },
                {
                    "authorId": "144258295",
                    "name": "Huadong Ma"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "f0e08ebb7b694223f7a489b5e714620265f05f9e",
            "title": "Design and Performance of Passive Virtual MIMO in Ambient Backscatter Communication",
            "abstract": "Ambient backscatter communication (AmBC) is regarded as a cutting-edge technology for the Internet of Things (IoT). In this letter, we explore a low-complexity virtual multiple-input multiple-output (MIMO) architecture for AmBC, which groups a cluster of low-cost single-antenna backscatter devices (BDs) to achieve MIMO transmission rather than using multiple antenna BDs. To overcome difficulties in virtual antenna array (VAA) configuration, a three-step strategy is introduced. After that, a semi-blind channel estimation is combined with a maximum likelihood detector (MLD) for signal detection in the MIMO channel. Numerical simulations show that our proposed strategy is effective and the proposed architectureoutperforms single-antenna AmBC systems under the same signal-to-noise ratio (SNR), which provides better performance to tolerant direct-link interference (DLI).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2271652836",
                    "name": "Diancheng Cheng"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "1744918",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "02e8d415d73b2de34f9ab8d6768837c194e3e44e",
            "title": "Joint Task Offloading and Resource Allocation for Vehicular Edge Computing Based on V2I and V2V Modes",
            "abstract": "In an internet of vehicle (IoV) scenario, vehicular edge computing (VEC) exploits the computing capabilities of the vehicles and roadside unit (RSU) to enhance the task processing capabilities of the vehicles. Resource management is essential to the performance improvement of the VEC system. In this paper, we propose a joint task offloading and resource allocation scheme to minimize the total task processing delay of all the vehicles through task scheduling, channel allocation, and computing resource allocation for the vehicles and RSU. Different from the existing works, our scheme: 1) considers task diversity by profiling the tasks of the vehicles by multiple attributes including data size, computation amount, delay tolerance, and task type; 2) considers vehicle classification by dividing the vehicles into 4 sets according to whether they have task offloading requirements or provide task processing services; 3) considers task processing flexibility by deciding for each vehicle to process its tasks locally, to offload the tasks to the RSU via V2I (Vehicle to Infrastructure) connections, or to the other vehicles via V2V (Vehicle to Vehicle) connections. An algorithm based on the Generalized Benders Decomposition (GBD) and Reformulation Linearization (RL) methods is designed to optimally solve the optimization problem. A heuristic algorithm is also designed to provide the sub-optimal solution with low computational complexity. We analyze the convergence and complexity of the proposed algorithms and conduct extensive simulations in 6 scenarios. The simulation results demonstrate the superiority of our scheme in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2146651089",
                    "name": "Jie Liu"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "40646266",
                    "name": "Wei Huang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "0531ee80c08916b3fbd63513744bcdaef6dd2fe9",
            "title": "Joint DNN Partition and Resource Allocation Optimization for Energy-Constrained Hierarchical Edge-Cloud Systems",
            "abstract": "Hierarchical edge-cloud systems collaboratively utilize the resources of both the edge server and central cloud, enabling deep neural network (DNN) partition between the edge and cloud to accelerate the inference. However, the limited energy budgets of both the edge server and central cloud restrict them from providing optimal DNN inference services. Moreover, considering the high dynamics in stochastic environments, the long-term system performance should be optimized under long-term energy constraints. How to improve the long-term DNN inference performance in such energy-constrained hierarchical edge-cloud systems is less studied by existing related works. In this paper, we aim to jointly optimize DNN partition and computing resource allocation to minimize the long-term average end-to-end delay of multiple types of deep learning (DL) tasks while guaranteeing the energy consumption of the edge server and central cloud within their energy budgets. Based on the Lyapunov optimization technique and reinforcement learning, we design a novel deep deterministic policy gradient based DNN partition and resource allocation (DDPRA) algorithm to train policy to decide DNN partition dynamically by observing the environment. Moreover, the DDPRA algorithm is embedded with a heuristic computing resource allocation (HCRA) algorithm, which effectively reduces the complexity of policy training by decoupling and optimizing the computing resource allocation separately. We analyze the complexity of our algorithms and conduct extensive simulations. The numerical results demonstrate the superiority of our algorithm in comparison with 5 other schemes in multiple scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "13383067",
                    "name": "Li Gao"
                },
                {
                    "authorId": "2065508415",
                    "name": "Lei Qiao"
                },
                {
                    "authorId": "103483738",
                    "name": "Yuan\u2019an Liu"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                }
            ]
        },
        {
            "paperId": "18cc1b86481cb35b6514487014ce751444159a24",
            "title": "Deep Learning-Based Composite Fault Diagnosis",
            "abstract": "As the core component of many large machinery, rotating equipment occupies a high proportion in industrial manufacturing. Intelligent fault diagnosis for them is becoming the core focus of Industry 4.0 and its evolution. To address the problem of poor fault classification accuracy of rotating equipment, this paper proposes a new solution to deploy a composite fault diagnosis model at the front end to achieve low power consumption, continuous automatic identification and monitoring of equipment faults. We creatively combined the idea of speech recognition to solve the problem that traditional feature extraction methods are insufficient in handling composite fault diagnosis when dealing with fault waveform files, and used Fbank speech feature extraction idea to extract fault features, thus simplifying the complex fault diagnosis problem into an image classification problem. The generated composite fault Fbank feature data set is significantly different in visual observation. Therefore, we further designed the LeNet-F network based on the LeNet network for composite fault diagnosis. The model was validated on the K210 development board to achieve an accuracy of 97.41% for hybrid fault classification at a model size of 2.4MB. This makes it possible to apply the deep learning method to the front end to directly complete the composite fault diagnosis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2212803291",
                    "name": "Zining An"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "1744918",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "2215808579",
                    "name": "Jing-liang Ma"
                },
                {
                    "authorId": "145986707",
                    "name": "Bo Sun"
                },
                {
                    "authorId": "33949252",
                    "name": "B. Tang"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "1aa98fa3837a8a4c498594f59b0be16c014070ce",
            "title": "Game-Based Task Offloading and Resource Allocation for Vehicular Edge Computing With Edge-Edge Cooperation",
            "abstract": "Vehicular Edge Computing (VEC) enables task offloading from vehicles to the edge servers deployed on Road Side Units (RSUs), thus enhancing the task processing performance of the vehicles. However, in a multi-RSU VEC scenario, the uneven geographical distribution of the vehicles naturally causes the load imbalance among the edge servers and leads to the overload and performance degradation problems of the edge servers in hot areas. To this end, in this paper, we propose a joint task offloading and resource allocation for VEC with edge-edge cooperation, in which the tasks offloaded to a high-load edge server can be further offloaded to the other low-load edge servers. Our objective is to minimize the total task processing delay of all the vehicles while guaranteeing the task processing delay tolerance and the holding time of each vehicle. An M/M/1 queue is used to model the task queuing and task computing processes on each RSU. An exact potential game is adopted to model the competition process for the task offloading among the RSUs. A two-stage iterative algorithm is designed to decompose the optimization problem into two stages and solve them iteratively. We analyze the computational complexity of the algorithm and conduct extensive simulations by varying different crucial parameters. The superiority of our scheme is demonstrated in comparison with 3 other reference schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2153995001",
                    "name": "Mingyu Hua"
                },
                {
                    "authorId": "2200089182",
                    "name": "Yaoyin Zhang"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2307485286",
                    "name": "Xuewei Li"
                },
                {
                    "authorId": "33949252",
                    "name": "B. Tang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "70b40ff35a09b4be7e7dacd441c7dd5e2eae32db",
            "title": "Joint Task Offloading and Resource Allocation for Quality-Aware Edge-Assisted Machine Learning Task Inference",
            "abstract": "Edge computing is essential to enhance delay-sensitive and computation-intensive machine learning (ML) task inference services. Quality of inference results, which is mainly impacted by the task data and ML models, is an important indicator impacting the system performance. In this paper, we consider a quality-aware edge-assisted ML task inference scenario and propose a resource management scheme to minimize the total task processing delay while guaranteeing the stability of all the task queues and the inference accuracy requirements of all the tasks. In our scheme, the task offloading, task data adjustment, computing resource allocation, and wireless channel allocation are jointly optimized. The Lyapunov optimization technique is adopted to transform the original optimization problem into a deterministic problem for each time slot. Considering the high complexity of the optimization problem, we design an algorithm that decomposes the problem into a task offloading and channel allocation (TOCA) sub-problem, a task data adjustment sub-problem, and a computing resource allocation sub-problem, and then solves them iteratively. A low-complexity heuristic algorithm is also designed to solve the TOCA sub-problem efficiently. Extensive simulations are conducted by varying different crucial parameters. The results demonstrate the superiority of our scheme in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2111434705",
                    "name": "Zeyu Chen"
                },
                {
                    "authorId": "2178604984",
                    "name": "Zhibo Hao"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "ac85903fd13625981867096299c64f935fdfffdd",
            "title": "A Truthful Combinatorial Auction Mechanism Towards Mobile Edge Computing in Industrial Internet of Things",
            "abstract": "Mobile edge computing (MEC) shows prominent application prospects in the Industrial Internet of Things (IIoT) by allowing resource-restricted IIoT mobile devices (MDs) to offload their tasks to geographical proximity edge clouds. An efficient incentive mechanism should be designed jointly addressing resource allocation and pricing to incentivize MDs (i.e., buyers) and edge clouds (i.e., sellers) to participate in offloading service trading. This article aims to solve the social welfare maximization problem of a personalized MEC computation offloading service market where each edge cloud can allocate different computing and wireless resources to each MD according to the MDs\u2019 delay and energy consumption constraints, and each MD submits bids to edge clouds differently based on the resource allocation of the edge clouds. We propose a truthful combinatorial auction (TCA) mechanism which involves three phases of resource allocation, buyer-seller matching, and payment determination. It should be highlighted that our proposed buyer-seller matching algorithm combines optimal matching and heuristic matching, so it greatly improves the auction effect while ensuring computational efficiency. Considerable theoretical analysis and experimental results prove that the performance of the proposed TCA mechanism is significantly superior to that of other auction mechanisms while holding the desirable properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2143862037",
                    "name": "Y. Liu"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                }
            ]
        }
    ]
}