{
    "authorId": "143884453",
    "papers": [
        {
            "paperId": "09cc4b2c870e62b8130af47669e63998e5e90a2b",
            "title": "Implicit Query Parsing at Amazon Product Search",
            "abstract": "Query Parsing aims to extract product attributes, such as color, brand, and product type, from search queries. These attributes play a crucial role in search engines for tasks such as matching, ranking, and recommendation. There are two types of attributes: explicit attributes that are mentioned explicitly in the search query, and implicit attributes that are mentioned implicitly. Existing works on query parsing do not differentiate between explicit query parsing and implicit query parsing, which limits their performance in product search engines. In this work, we demonstrate the critical importance of implicit attributes in real-world product search engines. We then present our solution for implicit query parsing at Amazon Search, which is a unified framework combining recent advancements in knowledge graph technologies and customer behavior analysis. We demonstrate the effectiveness of our proposal through offline experiments on Amazon search log data. We also show how to deploy and use the framework on Amazon search to improve customers' shopping experiences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2223935153",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1809614",
                    "name": "Yangqiu Song"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        },
        {
            "paperId": "45a6f7ca23944aa2050c2bc6d6a580058d032b30",
            "title": "Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation",
            "abstract": "Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks. To test the potential of the dataset, we introduce three tasks in this work: (1) next-product recommendation, (2) next-product recommendation with domain shifts, and (3) next-product title generation. With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice. In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 2023 and have attracted thousands of users and submissions. The winning solutions and the associated workshop can be accessed at our website https://kddcup23.github.io/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "5795999",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2149891871",
                    "name": "Hanqing Lu"
                },
                {
                    "authorId": "8492168",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "47370334",
                    "name": "Ruirui Li"
                },
                {
                    "authorId": "1700892",
                    "name": "Z. Li"
                },
                {
                    "authorId": "2072995251",
                    "name": "Mo Cheng"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2893721",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "48784944",
                    "name": "Xianfeng Tang"
                }
            ]
        },
        {
            "paperId": "80a1c371f9995b898a3b1aaee17f79a26e21ac56",
            "title": "Mitigating Exploitation Bias in Learning to Rank with an Uncertainty-aware Empirical Bayes Approach",
            "abstract": "Ranking is at the core of many artificial intelligence (AI) applications, including search engines, recommender systems, etc. Modern ranking systems are often constructed with learning-to-rank (LTR) models built from user behavior signals. While previous studies have demonstrated the effectiveness of using user behavior signals (e.g., clicks) as both features and labels of LTR algorithms, we argue that existing LTR algorithms that indiscriminately treat behavior and non-behavior signals in input features could lead to suboptimal performance in practice. Because user behavior signals often have strong correlations with the ranking objective and can only be collected on items that have already been shown to users, directly using behavior signals in LTR could create an exploitation bias that hurts the system performance in the long run. To address the exploitation bias, we propose an uncertainty-aware empirical Bayes based ranking algorithm, referred to as EBRank. Specifically, EBRank uses a sole non-behavior feature-based prior model to get a prior estimation of relevance. In the dynamic training and serving of ranking systems, EBRank uses the observed user behaviors to update posterior relevance estimation instead of concatenating behaviors as features in ranking models. Besides, EBRank additionally applies an uncertainty-aware exploration strategy to explore actively and collect user behaviors for empirical Bayesian modeling. Experiments on three public datasets show that EBRank is effective, practical and significantly outperforms state-of-the-art ranking algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1958895984",
                    "name": "Tao Yang"
                },
                {
                    "authorId": "1478235033",
                    "name": "Cuize Han"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "40243462",
                    "name": "Parth Gupta"
                },
                {
                    "authorId": "1795436",
                    "name": "J. M. Phillips"
                },
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                }
            ]
        },
        {
            "paperId": "9f12a8726377b7b67880822c7996090859d67437",
            "title": "Knowledge Graph Reasoning over Entities and Numerical Values",
            "abstract": "A complex logic query in a knowledge graph refers to a query expressed in logic form that conveys a complex meaning, such as where did the Canadian Turing award winner graduate from? Knowledge graph reasoning-based applications, such as dialogue systems and interactive search engines, rely on the ability to answer complex logic queries as a fundamental task. In most knowledge graphs, edges are typically used to either describe the relationships between entities or their associated attribute values. An attribute value can be in categorical or numerical format, such as dates, years, sizes, etc. However, existing complex query answering (CQA) methods simply treat numerical values in the same way as they treat entities. This can lead to difficulties in answering certain queries, such as which Australian Pulitzer award winner is born before 1927, and which drug is a pain reliever and has fewer side effects than Paracetamol. In this work, inspired by the recent advances in numerical encoding and knowledge graph reasoning, we propose numerical complex query answering. In this task, we introduce new numerical variables and operations to describe queries involving numerical attribute values. To address the difference between entities and numerical values, we also propose the framework of Number Reasoning Network (NRN) for alternatively encoding entities and numerical values into separate encoding structures. During the numerical encoding process, NRN employs a parameterized density function to encode the distribution of numerical values. During the entity encoding process, NRN uses established query encoding methods for the original CQA problem. Experimental results show that NRN consistently improves various query encoding methods on three different knowledge graphs and achieves state-of-the-art results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145677395",
                    "name": "Jiaxin Bai"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "1809614",
                    "name": "Yangqiu Song"
                }
            ]
        },
        {
            "paperId": "0a0f09d57ba4b5451e5c0d11397b8e437c38e9b9",
            "title": "Human Preferences as Dueling Bandits",
            "abstract": "The dramatic improvements in core information retrieval tasks engendered by neural rankers create a need for novel evaluation methods. If every ranker returns highly relevant items in the top ranks, it becomes difficult to recognize meaningful differences between them and to build reusable test collections. Several recent papers explore pairwise preference judgments as an alternative to traditional graded relevance assessments. Rather than viewing items one at a time, assessors view items side-by-side and indicate the one that provides the better response to a query, allowing fine-grained distinctions. If we employ preference judgments to identify the probably best items for each query, we can measure rankers by their ability to place these items as high as possible. We frame the problem of finding best items as a dueling bandits problem. While many papers explore dueling bandits for online ranker evaluation via interleaving, they have not been considered as a framework for offline evaluation via human preference judgments. We review the literature for possible solutions. For human preference judgments, any usable algorithm must tolerate ties, since two items may appear nearly equal to assessors, and it must minimize the number of judgments required for any specific pair, since each such comparison requires an independent assessor. Since the theoretical guarantees provided by most algorithms depend on assumptions that are not satisfied by human preference judgments, we simulate selected algorithms on representative test cases to provide insight into their practical utility. Based on these simulations, one algorithm stands out for its potential. Our simulations suggest modifications to further improve its performance. Using the modified algorithm, we collect over 10,000 preference judgments for pools derived from submissions to the TREC 2021 Deep Learning Track, confirming its suitability. We test the idea of best-item evaluation and suggest ideas for further theoretical and practical progress.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116538878",
                    "name": "Xinyi Yan"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "1751287",
                    "name": "C. Clarke"
                },
                {
                    "authorId": "1703980",
                    "name": "Nick Craswell"
                },
                {
                    "authorId": "1746656",
                    "name": "E. Voorhees"
                },
                {
                    "authorId": "2912921",
                    "name": "P. Castells"
                }
            ]
        },
        {
            "paperId": "1ec946bf7cc2fc8989baa02332ca84e1082c8848",
            "title": "Can Clicks Be Both Labels and Features?: Unbiased Behavior Feature Collection and Uncertainty-aware Learning to Rank",
            "abstract": "Using implicit feedback collected from user clicks as training labels for learning-to-rank algorithms is a well-developed paradigm that has been extensively studied and used in modern IR systems. Using user clicks as ranking features, on the other hand, has not been fully explored in existing literature. Despite its potential in improving short-term system performance, whether the incorporation of user clicks as ranking features is beneficial for learning-to-rank systems in the long term is still questionable. Two of the most important problems are (1) the explicit bias introduced by noisy user behavior, and (2) the implicit bias, which we refer to as the exploitation bias, introduced by the dynamic training and serving of learning-to-rank systems with behavior features. In this paper, we explore the possibility of incorporating user clicks as both training labels and ranking features for learning to rank. We formally investigate the problems in feature collection and model training, and propose a counterfactual feature projection function and a novel uncertainty-aware learning to rank framework. Experiments on public datasets show that ranking models learned with the proposed framework can significantly outperform models built with raw click features and algorithms that rank items without considering model uncertainty.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1958895984",
                    "name": "Tao Yang"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "2149891871",
                    "name": "Hanqing Lu"
                },
                {
                    "authorId": "40243462",
                    "name": "Parth Gupta"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "144922928",
                    "name": "Qingyao Ai"
                }
            ]
        },
        {
            "paperId": "940d32e2f5ac604393e8a9ef9195f53e00fc20ad",
            "title": "Short Text Pre-training with Extended Token Classification for E-commerce Query Understanding",
            "abstract": "E-commerce query understanding is the process of inferring the shopping intent of customers by extracting semantic meaning from their search queries. The recent progress of pre-trained masked language models (MLM) in natural language processing is extremely attractive for developing effective query understanding models. Specifically, MLM learns contextual text embedding via recovering the masked tokens in the sentences. Such a pre-training process relies on the sufficient contextual information. It is, however, less effective for search queries, which are usually short text. When applying masking to short search queries, most contextual information is lost and the intent of the search queries may be changed. To mitigate the above issues for MLM pre-training on search queries, we propose a novel pre-training task specifically designed for short text, called Extended Token Classification (ETC). Instead of masking the input text, our approach extends the input by inserting tokens via a generator network, and trains a discriminator to identify which tokens are inserted in the extended input. We conduct experiments in an E-commerce store to demonstrate the effectiveness of ETC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "5795999",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2151070",
                    "name": "Tianyu Cao"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "48784944",
                    "name": "Xianfeng Tang"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "46334890",
                    "name": "Danqing Zhang"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        },
        {
            "paperId": "c811159fbff397e277cfb03426120a91aa26bb70",
            "title": "Query Attribute Recommendation at Amazon Search",
            "abstract": "Query understanding models extract attributes from search queries, like color, product type, brand, etc. Search engines rely on these attributes for ranking, advertising, and recommendation, etc. However, product search queries are usually short, three or four words on average. This information shortage limits the search engine\u2019s power to provide high-quality services. In this talk, we would like to share our year-long journey in solving the information shortage problem and introduce an end-to-end system for attribute recommendation at Amazon Search. We showcase how the system works and how the system contributes to the long-term user experience through offline and online experiments at Amazon Search. We hope this talk can inspire more follow-up works in understanding and improving attribute recommendations in product search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "3020818",
                    "name": "William P. Headden"
                },
                {
                    "authorId": "7885404",
                    "name": "Neela Avudaiappan"
                },
                {
                    "authorId": "2152630772",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2151070",
                    "name": "Tianyu Cao"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "1921742",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        },
        {
            "paperId": "65f03e92d00bb79f167d8e1381dbff243edbd7f2",
            "title": "Evaluation Measures Based on Preference Graphs",
            "abstract": "The offline evaluation of search requires us to define a standard against which we measure the quality of results returned by a ranker. Frequently this standard is defined in absolute terms through relevance grades, but it can also be defined in relative terms through preferences. These preferences might be created through explicit preference judgments, derived from relevance grades, or inferred from clicks and other signals. Preferences from multiple sources might even be combined. In contrast to absolute grades, preferences avoid complex definitions of relevance, indicating only that a ranker should favor one result over another. Despite the simplicity and flexibility of preferences, widespread adoption has been limited by the lack of established evaluation measures. Recent work in this direction has taken two approaches: 1) measures based on weighted counts of agreements and disagreements between a set of preferences and an actual ranking generated by a ranker; and 2) measures that translate preferences into gain values for use with traditional measures, such as nDCG. Both approaches require methods for specifying weights or gains that have little or no theoretical foundation, and the values of these measures have no clear and meaningful interpretation. To address these problems, we propose an evaluation measure that computes the similarity between a directed multigraph of preferences and an actual ranking generated by a ranker. The measure computes an ordering for the vertices of the preference graph that maximizes its similarity to the actual ranking under a rank similarity measure. This maximum similarity becomes the value of the measure. Preference graphs are often acyclic, or nearly so, and to compute the measure we extend an approximate greedy algorithm that is known to produce good results for nearly acyclic graphs. For the rank similarity measure we employ Rank Biased Overlap (RBO) which was explicitly created to match the requirements of search and related applications. We validate the new measure over several collections of preferences explored in recent work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1751287",
                    "name": "C. Clarke"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "1689089",
                    "name": "Mark D. Smucker"
                }
            ]
        }
    ]
}