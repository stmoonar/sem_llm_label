{
    "authorId": "1756038",
    "papers": [
        {
            "paperId": "4df8f1b032ca763c9dc73ec45a2d9c57571eb76f",
            "title": "Detecting Frames in News Headlines and Lead Images in U.S. Gun Violence Coverage",
            "abstract": "News media structure their reporting of events or issues using certain perspectives. When describing an incident involving gun violence, for example, some journalists may focus on mental health or gun regulation, while others may emphasize the discussion of gun rights. Such perspectives are called \\say{frames} in communication research. We study, for the first time, the value of combining lead images and their contextual information with text to identify the frame of a given news article. We observe that using multiple modes of information(article- and image-derived features) improves prediction of news frames over any single mode of information when the images are relevant to the frames of the headlines. We also observe that frame image relevance is related to the ease of conveying frames via images, which we call frame concreteness. Additionally, we release the first multimodal news framing dataset related to gun violence in the U.S., curated and annotated by communication researchers. The dataset will allow researchers to further examine the use of multiple information modalities for studying media framing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72437140",
                    "name": "Isidora Chara Tourni"
                },
                {
                    "authorId": "2110797784",
                    "name": "Lei Guo"
                },
                {
                    "authorId": "2140488680",
                    "name": "T. Daryanto"
                },
                {
                    "authorId": "2140490515",
                    "name": "Fabian Zhafransyah"
                },
                {
                    "authorId": "2065594140",
                    "name": "Edward Edberg Halim"
                },
                {
                    "authorId": "47801182",
                    "name": "Mona Jalal"
                },
                {
                    "authorId": "2882606",
                    "name": "Boqi Chen"
                },
                {
                    "authorId": "98229497",
                    "name": "Shan-Ching Lai"
                },
                {
                    "authorId": "2142605154",
                    "name": "Hengchang Hu"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "2129412",
                    "name": "D. Wijaya"
                }
            ]
        },
        {
            "paperId": "69f8fcc40f568a2bc32008d82024ef74be0c1235",
            "title": "IoMT and AI Enabled Time Critical System for Tele-Cardiac Rehabilitation",
            "abstract": "Tele-rehabilitation has garnered significant interest among clinicians and researchers with its potential to transform cardiac rehabilitation, affecting millions of patients annually. A critical requirement of tele-cardiac rehabilitation is a fail-safe, highly interactive system with timely feedback to both the patient and the therapists or physicians. Current systems often assume ideal network conditions, neglecting the nuances of real-world deployment. We have designed, developed, and tested an end-to-end tele-cardiac rehabilitation system that seamlessly combines Internet of Medical Things (IoMT) devices and AI-powered abnormality and activity detection, providing a fail-safe and real-time actionable closed-feedback loop system for the patient and the doctor. A pilot study evaluates system performance across diverse mobile networks in varying conditions (stable or unstable). The RESNET-18 model for cardiac abnormality detection (0.71 F1-score) and the VGG-16 model for human activity classification (0.89 F1-score) demonstrate significant performance. Furthermore, we optimize these models for edge devices, demonstrating significant speed improvements compared to cloud servers (up to 33 times faster).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52143350",
                    "name": "Shereena Shaji"
                },
                {
                    "authorId": "2176886296",
                    "name": "Rahul Krishnan Pathinarupothi"
                },
                {
                    "authorId": "8341555",
                    "name": "Ramesh Guntha"
                },
                {
                    "authorId": "2287969704",
                    "name": "Ravi Sankaran"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "2305074393",
                    "name": "K. A. Unnikrishna Menon"
                },
                {
                    "authorId": "31379396",
                    "name": "Maneesha Vinodini Ramesh"
                }
            ]
        },
        {
            "paperId": "6a15a41b6e32a070b8cd899daba5f8fcdde42634",
            "title": "A Lesion-aware Edge-based Graph Neural Network for Predicting Language Ability in Patients with Post-stroke Aphasia",
            "abstract": "We propose a lesion-aware graph neural network (LEGNet) to predict language ability from resting-state fMRI (rs-fMRI) connectivity in patients with post-stroke aphasia. Our model integrates three components: an edge-based learning module that encodes functional connectivity between brain regions, a lesion encoding module, and a subgraph learning module that leverages functional similarities for prediction. We use synthetic data derived from the Human Connectome Project (HCP) for hyperparameter tuning and model pretraining. We then evaluate the performance using repeated 10-fold cross-validation on an in-house neuroimaging dataset of post-stroke aphasia. Our results demonstrate that LEGNet outperforms baseline deep learning methods in predicting language ability. LEGNet also exhibits superior generalization ability when tested on a second in-house dataset that was acquired under a slightly different neuroimaging protocol. Taken together, the results of this study highlight the potential of LEGNet in effectively learning the relationships between rs-fMRI connectivity and language ability in a patient cohort with brain lesions for improved post-stroke aphasia evaluation.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Engineering",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2319759803",
                    "name": "Zijian Chen"
                },
                {
                    "authorId": "3730107",
                    "name": "M. Varkanitsa"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "2242030160",
                    "name": "Janusz Konrad"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                },
                {
                    "authorId": "2242026443",
                    "name": "Swathi Kiran"
                },
                {
                    "authorId": "2242031740",
                    "name": "Archana Venkataraman"
                }
            ]
        },
        {
            "paperId": "31db981c4191c1f661c05ddec36f42841c3719c1",
            "title": "Estimating Distances Between People using a Single Overhead Fisheye Camera with Application to Social-Distancing Oversight",
            "abstract": "Unobtrusive monitoring of distances between people indoors is a useful tool in the fight against pandemics. A natural resource to accomplish this are surveillance cameras. Unlike previous distance estimation methods, we use a single, overhead, fisheye camera with wide area coverage and propose two approaches. One method leverages a geometric model of the fisheye lens, whereas the other method uses a neural network to predict the 3D-world distance from people-locations in a fisheye image. To evaluate our algorithms, we collected a first-of-its-kind dataset using single fisheye camera, that comprises a wide range of distances between people (1-58 ft) and will be made publicly available. The algorithms achieve 1-2 ft distance error and over 95% accuracy in detecting social-distance violations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2210774856",
                    "name": "Zhangchi Lu"
                },
                {
                    "authorId": "1630368126",
                    "name": "Mertcan Cokbas"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "144055319",
                    "name": "J. Konrad"
                }
            ]
        },
        {
            "paperId": "34264527d3ec5f3830cb75e85625b1d135f068de",
            "title": "A Principled Approach to Model Validation in Domain Generalization",
            "abstract": "Domain generalization aims to learn a model with good generalization ability, that is, the learned model should not only perform well on several seen domains but also on unseen domains with different data distributions. State-of-the-art domain generalization methods typically train a representation function followed by a classifier jointly to minimize both the classification risk and the domain discrepancy. However, when it comes to model selection, most of these methods rely on traditional validation routines that select models solely based on the lowest classification risk on the validation set. In this paper, we theoretically demonstrate a trade-off between minimizing classification risk and mitigating domain discrepancy, i.e., it is impossible to achieve the minimum of these two objectives simultaneously. Motivated by this theoretical result, we propose a novel model selection method suggesting that the validation process should account for both the classification risk and the domain discrepancy. We validate the effectiveness of the proposed method by numerical results on several domain generalization datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51454393",
                    "name": "Boyang Lyu"
                },
                {
                    "authorId": "123233017",
                    "name": "Thuan Q. Nguyen"
                },
                {
                    "authorId": "121848090",
                    "name": "matthias. scheutz"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "2139553851",
                    "name": "Shuchin Aeron"
                }
            ]
        },
        {
            "paperId": "395bec35efe0a965c88aac013372967bed23dd2f",
            "title": "Consistent long-term practice leads to consistent improvement: Benefits of self-managed therapy for language and cognitive deficits using a digital therapeutic",
            "abstract": "Background Although speech-language therapy (SLT) is proven to be beneficial to recovery of post-stroke aphasia, delivering sufficiently high amounts of dosage remains a problem in real-world clinical practice. Self-managed SLT was introduced to solve the problem. Previous research showed in a 10-week period, increased dosage frequency could lead to better performance, however, it is uncertain if dosage still affects performance over a longer period of practice time and whether gains can be seen following practice over several months. Objective This study aims to evaluate data from a health app (Constant Therapy) to investigate the relationship between dosage amount and improvements following a 30-week treatment period. Two cohorts of users were analyzed. One was comprised of patients with a consistent average weekly dosage amount and the other cohort was comprised of users whose practice had higher variability. Methods We conducted two analyses with two cohorts of post-stroke patients who used Constant Therapy. The first cohort contains 537 \u201cconsistent\u201d users, while the second cohort contains 2,159. The 30-week practice period was split into three consecutive 10-week practice windows to calculate average dosage amount. In each 10-week practice period, patients were grouped by their average dosage into low (0\u201315\u2005min/week), medium (15\u201340\u2005min/week) and moderate dosage (greater than 40\u2005min/week) groups. Linear mixed-effects models were employed to evaluate if dosage amount was a significant factor affecting performance. Pairwise comparison was also applied to evaluate the slope difference between groups. Results For the consistent cohort, medium (\u03b2\u2009=\u2009.002, t17,700\u2009=\u20097.64, P\u2009<\u2009.001) and moderate (\u03b2\u2009=\u2009.003, t9,297\u2009=\u20097.94, P\u2009<\u2009.001) dosage groups showed significant improvement compared to the low dosage group. The moderate group also showed greater improvement compared to the medium group. For the variable cohort in analysis 2, the same trend was shown in the first two 10-week windows, however, in weeks 21\u201330, the difference was insignificant between low and medium groups (\u03b2\u2009=\u2009.001, t\u2009=\u20091.76, P\u2009=\u2009.078). Conclusions This study showed a higher dosage amount is related to greater therapy outcomes in over 6 months of digital self-managed therapy. It also showed that regardless of the exact pattern of practice, self-managed SLT leads to significant and sustained performance gains.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2118960645",
                    "name": "Hantian Liu"
                },
                {
                    "authorId": "37862934",
                    "name": "Claire Cordella"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                },
                {
                    "authorId": "32459665",
                    "name": "S. Kiran"
                }
            ]
        },
        {
            "paperId": "4f74ba7db24f0b24a10eba83d596b3658030d0c9",
            "title": "Complexity Evaluation of Parallel Execution of the RAPiD Deep-Learning Algorithm on Intel CPU",
            "abstract": "Knowing how many and where are people in various indoor spaces is critical for reducing HVAC energy waste, space management, spatial analytics and in emergency scenarios. While a range of technologies have been proposed to detect and track people in large indoor spaces, ceiling-mounted fisheye cameras have recently emerged as strong contenders. Currently, RAPiD is the SOTA algorithm for people detection in images captured by fisheye cameras. However, in large spaces several overhead fisheye cameras are needed to assure high accuracy of counting and thus multiple instances of RAPiD must be executed simultaneously. This report evaluates inference time when multiple instances of RAPiD run in parallel on an Ubuntu NUC PC with Intel I7 8559U CPU. We consider three mechanisms of CPU-resource allocation to handle multiple instances of RAPiD: 1) managed by Ubuntu, 2) managed by user via operating-system calls to assign logical cores, and 3) managed by user via PyTorch-library calls to limit the number of threads used by PyTorch. Each scenario was evaluated on 300 images. The experimental results show, that when one or two instances of RAPiD are executed in parallel all three approaches result in similar inference times of 1.8sec and 3.2sec, respectively. However, when three or more instances of RAPiD run in parallel, limiting the number of threads used by PyTorch results in the shortest inference times. On average, RAPiD completes inference of 2 images simultaneously in about 3sec, 4 images in 6sec and 8 images in less than 14sec. This is important for real-time system design. In HVAC-application scenarios, with a typical reaction time of 10-15min, a latency of 14sec is negligible so a single 8559U CPU can support 8 camera streams thus reducing the system cost. However, in emergency scenarios, when time is of essence, a single CPU may be needed for each camera to reduce the latency to 1.8sec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273534440",
                    "name": "Dominic Konrad"
                },
                {
                    "authorId": "2273414911",
                    "name": "Zhihao Duan"
                },
                {
                    "authorId": "1630368126",
                    "name": "Mertcan Cokbas"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                }
            ]
        },
        {
            "paperId": "89305caf1512a8ec06b30a5984aa678c9faec035",
            "title": "On neural and dimensional collapse in supervised and unsupervised contrastive learning with hard negative sampling",
            "abstract": "For a widely-studied data model and general loss and sample-hardening functions we prove that the Supervised Contrastive Learning (SCL), Hard-SCL (HSCL), and Unsupervised Contrastive Learning (UCL) risks are minimized by representations that exhibit Neural Collapse (NC), i.e., the class means form an Equianglular Tight Frame (ETF) and data from the same class are mapped to the same representation. We also prove that for any representation mapping, the HSCL and Hard-UCL (HUCL) risks are lower bounded by the corresponding SCL and UCL risks. Although the optimality of ETF is known for SCL, albeit only for InfoNCE loss, its optimality for HSCL and UCL under general loss and hardening functions is novel. Moreover, our proofs are much simpler, compact, and transparent. We empirically demonstrate, for the first time, that ADAM optimization of HSCL and HUCL risks with random initialization and suitable hardness levels can indeed converge to the NC geometry if we incorporate unit-ball or unit-sphere feature normalization. Without incorporating hard negatives or feature normalization, however, the representations learned via ADAM suffer from dimensional collapse (DC) and fail to attain the NC geometry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1894532651",
                    "name": "Ruijie Jiang"
                },
                {
                    "authorId": "123233017",
                    "name": "Thuan Q. Nguyen"
                },
                {
                    "authorId": "2139553851",
                    "name": "Shuchin Aeron"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                }
            ]
        },
        {
            "paperId": "d4751612225b6b730671e96228e04d9f4ebb8a2a",
            "title": "Fusion Approaches to Predict Post-stroke Aphasia Severity from Multimodal Neuroimaging Data",
            "abstract": "This paper explores feature selection and fusion methods for predicting the clinical outcome of post-stroke aphasia from medical imaging data. Utilizing a multimodal neu-roimaging dataset derived from 55 individuals with chronic aphasia resulting from left-hemisphere lesions following a stroke, two distinct approaches, namely Early Fusion and Late Fusion, were developed using Support Vector Regression or Random Forest regression models for prognosticating patients\u2019 functional communication skills measured by Western Aphasia Battery (WAB) test scores. A supervised learning method is proposed to reduce the number of features derived from each imaging modality. The fusion approaches were then applied to find combinations of these reduced feature sets that yield the most accurate WAB predictions. The same nested training/validation/test sets were used for the feature selection and fusion methods. Experiments showed that the best model based on the correlation metric is a Late Fusion RF model (r=0.63), while the best model based on the RMSE is an Early Fusion SVR model (RMSE=16.72). Experiments also revealed several feature set combinations that yielded more accurate predictions than both single-modality feature sets and feature sets that combine all modalities, justifying both fusion and reduction of features derived from multimodal neuroimaging data. It was also found that the percentage of tissue in gray matter regions of the brain, spared by the stroke as identified on structural Magnetic Resonance Imaging, is the single feature set that appeared in all highest ranked feature set combinations of both fusion approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189466156",
                    "name": "Saurav Chennuri"
                },
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "1485910247",
                    "name": "Anne Billot"
                },
                {
                    "authorId": "3730107",
                    "name": "M. Varkanitsa"
                },
                {
                    "authorId": "152606129",
                    "name": "Emily J Braun"
                },
                {
                    "authorId": "2242026443",
                    "name": "Swathi Kiran"
                },
                {
                    "authorId": "2242031740",
                    "name": "Archana Venkataraman"
                },
                {
                    "authorId": "2242030160",
                    "name": "Janusz Konrad"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                }
            ]
        },
        {
            "paperId": "2b419a7af4e7b5bccbc63028d610a0be0e4c4888",
            "title": "Supervised Contrastive Learning with Hard Negative Samples",
            "abstract": "Through minimization of an appropriate loss function such as the InfoNCE loss, contrastive learning (CL) learns a useful representation function by pulling positive samples close to each other while pushing negative samples far apart in the embedding space. The positive samples are typically created using \"label-preserving\" augmentations, i.e., domain-specific transformations of a given datum or anchor. In absence of class information, in unsupervised CL (UCL), the negative samples are typically chosen randomly and independently of the anchor from a preset negative sampling distribution over the entire dataset. This leads to class-collisions in UCL. Supervised CL (SCL), avoids this class collision by conditioning the negative sampling distribution to samples having labels different from that of the anchor. In hard-UCL (H-UCL), which has been shown to be an effective method to further enhance UCL, the negative sampling distribution is conditionally tilted, by means of a hardening function, towards samples that are closer to the anchor. Motivated by this, in this paper we propose hard-SCL (H-SCL) wherein the class conditional negative sampling distribution is tilted via a hardening function. Our simulation results confirm the utility of H-SCL over SCL with significant performance gains in downstream classification tasks. Analytically, we show that in the limit of infinite negative samples per anchor and a suitable assumption, the H-SCL loss is upper bounded by the H-UCL loss, thereby justifying the utility of H-UCL for controlling the H-SCL loss in the absence of label information. Through experiments on several datasets, we verify the assumption as well as the claimed inequality between H-UCL and H-SCL losses. We also provide a plausible scenario where H-SCL loss is lower bounded by UCL loss, indicating the limited utility of UCL in controlling the H-SCL loss.1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1894532651",
                    "name": "Ruijie Jiang"
                },
                {
                    "authorId": "123233017",
                    "name": "Thuan Q. Nguyen"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "2139553851",
                    "name": "Shuchin Aeron"
                }
            ]
        }
    ]
}