{
    "authorId": "47221821",
    "papers": [
        {
            "paperId": "fb7abbe77b7a86e4a62f56d1b9b90d0e826d57f5",
            "title": "Enhanced physics\u2010informed neural networks for hyperelasticity",
            "abstract": "Physics\u2010informed neural networks have gained growing interest. Specifically, they are used to solve partial differential equations governing several physical phenomena. However, physics\u2010informed neural network models suffer from several issues and can fail to provide accurate solutions in many scenarios. We discuss a few of these challenges and the techniques, such as the use of Fourier transform, that can be used to resolve these issues. This paper proposes and develops a physics\u2010informed neural network model that combines the residuals of the strong form and the potential energy, yielding many loss terms contributing to the definition of the loss function to be minimized. Hence, we propose using the coefficient of variation weighting scheme to dynamically and adaptively assign the weight for each loss term in the loss function. The developed PINN model is standalone and meshfree. In other words, it can accurately capture the mechanical response without requiring any labeled data. Although the framework can be used for many solid mechanics problems, we focus on three\u2010dimensional (3D) hyperelasticity, where we consider two hyperelastic models. Once the model is trained, the response can be obtained almost instantly at any point in the physical domain, given its spatial coordinates. We demonstrate the framework's performance by solving different problems with various boundary conditions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11499178",
                    "name": "D. Abueidda"
                },
                {
                    "authorId": "2163125",
                    "name": "S. Koric"
                },
                {
                    "authorId": "70581022",
                    "name": "Erman Guleryuz"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                }
            ]
        },
        {
            "paperId": "0b991db3a83f38eb8280c4c41f87f1ead1bdc6da",
            "title": "White blood cell detection, classification and analysis using phase imaging with computational specificity (PICS)",
            "abstract": "In this study, we used spatial light interference microscopy (SLIM), an ultrasensitive QPI method, and deep learning, to first generate a virtually-stained micrograph of a blood smear. This approach of combining label-free QPI data with deep learning to infer chemical specificity has been recently developed in our laboratory and is referred to as PICS [Nat. Comm., in press]. Next, we applied a computational semantic segmentation to identify and delineate the white blood cells. Lastly, we ran a classification model on the leukocytes to identify their type and condition. \nPICS renders synthetically stained blood smears rapidly, at a reduced cost of sample preparation, and provides quantitative clinical information. We validated this approach by successfully creating computationally stained micrographs and classified the leukocytes into five cell classes, with 92% accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12689350",
                    "name": "M. Fanous"
                },
                {
                    "authorId": "2250962630",
                    "name": "Gabriel Popescu"
                },
                {
                    "authorId": "5622596",
                    "name": "Krishnarao V. Tangella"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                }
            ]
        },
        {
            "paperId": "40553df7d17374650afaba35c926375d751256ca",
            "title": "Cell cycle detection using phase imaging with computational specificity (PICS)",
            "abstract": "Quantitative phase imaging (QPI), with its capability to capture intrinsic contrast within transparent samples, has emerged as an important imaging method for biomedical research. However, due to its label-free nature, QPI lacks specificity and thus faces limitations in complex cellular systems. In our previous works, we have proposed phase imaging with computational specificity (PICS), a novel AI-enhanced imaging approach that advances QPI by utilizing deep learning for specificity. Here we present that PICS can be applied to study individual cell behavior and cellular dry mass change across different phases of the cell cycle. The cell cycle information is traditionally obtained by fluorescence microscopy with markers like Fluorescence Ubiquitin Cell Cycle Indicator (FUCCI). Our work showed that using deep learning, we can train a neural network to accurately predict the cell cycle phase (G1, S, or G2) for each individual cell.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1911750",
                    "name": "Yuchen R. He"
                },
                {
                    "authorId": "2115301737",
                    "name": "Shenghua He"
                },
                {
                    "authorId": "6027867",
                    "name": "M. Kandel"
                },
                {
                    "authorId": "2116464330",
                    "name": "Y. J. Lee"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "1768850",
                    "name": "M. Anastasio"
                },
                {
                    "authorId": "144952265",
                    "name": "G. Popescu"
                }
            ]
        },
        {
            "paperId": "f06354b2a87774b7a1dd3d6689b2e214f69b577c",
            "title": "Label-free screening of brain tissue myelin content using phase imaging with computational specificity (PICS)",
            "abstract": "Inadequate myelination in the central nervous system is associated with neurodevelopmental complications. Thus, quantitative, high spatial resolution measurements of myelin levels are highly desirable. We used spatial light interference microcopy (SLIM), a highly sensitive quantitative phase imaging (QPI) technique, to correlate the dry mass content of myelin in piglet brain tissue with dietary changes and gestational size. We combined SLIM micrographs with an AI classifying model that allows us to discern subtle disparities in myelin distributions with high accuracy. This concept of combining QPI label-free data with AI for the purpose of extracting molecular specificity has recently been introduced by our laboratory as phase imaging with computational specificity (PICS). Training on nine thousand SLIM images of piglet brain tissue with the 71-layer transfer learning model Xception, we created a two-parameter classification to differentiate gestational size and diet type with an accuracy of 82% and 80%, respectively. To our knowledge, this type of evaluation is impossible to perform by an expert pathologist or other techniques.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "12689350",
                    "name": "M. Fanous"
                },
                {
                    "authorId": "152194114",
                    "name": "Chuqiao Shi"
                },
                {
                    "authorId": "40811241",
                    "name": "M. Caputo"
                },
                {
                    "authorId": "38117471",
                    "name": "L. Rund"
                },
                {
                    "authorId": "2111257044",
                    "name": "Rodney W. Johnson"
                },
                {
                    "authorId": "2059370842",
                    "name": "Tapas Das"
                },
                {
                    "authorId": "5653948",
                    "name": "M. Kuchan"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "144952265",
                    "name": "G. Popescu"
                }
            ]
        },
        {
            "paperId": "345e0e8c3aed768b51e82c6341f8efc3fdbf5cd9",
            "title": "Machine learning accelerated topology optimization of nonlinear structures",
            "abstract": "The field of optimal design of linear elastic structures has seen many exciting successes that resulted in new architected materials and designs. With the availability of cloud computing, including high-performance computing, machine learning, and simulation, searching for optimal nonlinear structures is now within reach. In this study, we develop two convolutional neural network models to predict optimized designs for a given set of boundary conditions, loads, and volume constraints. The first convolutional neural network model is for the case of materials with a linear elastic response while the second developed model is for hyperelastic response where material and geometric nonlinearities are involved. For the nonlinear elastic case, the neo-Hookean model is utilized. For this purpose, we generate datasets, composed of the optimized designs paired with the corresponding boundary conditions, loads, and constraints, using topology optimization framework to train and validate both models. The developed models are capable of accurately predicting the optimized designs without requiring an iterative scheme and with negligible computational time. The suggested pipeline can be generalized to other nonlinear mechanics scenarios and design domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11499178",
                    "name": "D. Abueidda"
                },
                {
                    "authorId": "2163125",
                    "name": "S. Koric"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                }
            ]
        },
        {
            "paperId": "5507ae0062cb3533ff25c415fc9e8c8dfa97081e",
            "title": "Label-free colorectal cancer screening using deep learning and spatial light interference microscopy (SLIM).",
            "abstract": "Current pathology workflow involves staining of thin tissue slices, which otherwise would be transparent, followed by manual investigation under the microscope by a trained pathologist. While the hematoxylin and eosin (H&E) stain is well-established and a cost-effective method for visualizing histology slides, its color variability across preparations and subjectivity across clinicians remain unaddressed challenges. To mitigate these challenges, recently we have demonstrated that spatial light interference microscopy (SLIM) can provide a path to intrinsic, objective markers, that are independent of preparation and human bias. Additionally, the sensitivity of SLIM to collagen fibers yields information relevant to patient outcome, which is not available in H&E. Here, we show that deep learning and SLIM can form a powerful combination for screening applications: training on 1,660 SLIM images of colon glands and validating on 144 glands, we obtained a benign vs. cancer classification accuracy of 99%. We envision that the SLIM whole slide scanner presented here paired with artificial intelligence algorithms may prove valuable as a pre-screening method, economizing the clinician's time and effort.",
            "fieldsOfStudy": [
                "Physics",
                "Engineering",
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2107949145",
                    "name": "Jingfang K. Zhang"
                },
                {
                    "authorId": "1911750",
                    "name": "Yuchen R. He"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "144952270",
                    "name": "G. Popescu"
                }
            ]
        },
        {
            "paperId": "adb21ca4738d4126c8c9c244e1fbd50e089135e6",
            "title": "ChemNet: A Deep Neural Network for Advanced Composites Manufacturing.",
            "abstract": "Among advanced manufacturing techniques for Fiber-Reinforced Polymer-matrix Composites (FRPCs) which are critical for aerospace, marine, automotive, and energy industries, Frontal Polymerization (FP) has been recently proposed to save orders of magnitude time and energy. However, the cure kinetics of the matrix phase, usually a thermosetting polymer, brings difculty to the design and control of the process. Here, we develop a deep learning model, ChemNet, to solve an inverse problem in predicting and optimizing the cure kinetics parameters of the thermosetting FRPCs for a desired fabrication strategy. ChemNet consists of a fully connected FeedForward 9-layer deep neural network trained on one million examples, and predicts activation energy and reaction enthalpy given the front characteristics such as speed and maximum temperature. ChemNet provides highly accurate predictions measured by the mean square error (MSE) and by the maximum absolute error metrics. The MSE of ChemNet, on the train set and test set attain the values of 1E-4 and 2E-4, respectively.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40928755",
                    "name": "E. Goli"
                },
                {
                    "authorId": "1643911954",
                    "name": "S. Vyas"
                },
                {
                    "authorId": "2163125",
                    "name": "S. Koric"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "2299499",
                    "name": "P. Geubelle"
                }
            ]
        },
        {
            "paperId": "c92a1c4a2f29c06173ac795f091b01dedcf05740",
            "title": "Digital staining with quantitative phase imaging for time-lapse studies of cellular growth and proliferation (Conference Presentation)",
            "abstract": "Microscopic imaging modalities can be classified into two categories: those that form contrast from external agents such as dyes, and label-free methods that generate contrast from the object\u2019s unmodified structure. While label-free methods such as brightfield, phase contrast, or quantitative phase imaging (QPI) are substantially easier to use, as well as non-toxic, their lack of specificity leads many researchers to turn to labels for insights into biological processes, despite limitations due to photobleaching and phototoxicity. The label-free image may contain the structures of interest, but it is often difficult or time-consuming to distinguish these structures from their surroundings. Here we summarize our recent progress in shattering this tradeoff, by using machine learning to perform automated segmentation on label-free, intrinsic contrast, quantitative phase images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6027867",
                    "name": "M. Kandel"
                },
                {
                    "authorId": "2116464330",
                    "name": "Y. J. Lee"
                },
                {
                    "authorId": "1500340866",
                    "name": "T. H. Chen"
                },
                {
                    "authorId": "1911750",
                    "name": "Yuchen R. He"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "144952265",
                    "name": "G. Popescu"
                }
            ]
        },
        {
            "paperId": "d48a1e467f7f081972db5d24b04abda045ae0841",
            "title": "PICS: Phase Imaging with Computational Specificity",
            "abstract": "Due to its specificity, fluorescence microscopy (FM) has been the main imaging tool in cell biology. However, photobleaching, phototoxicity, and related artifacts continue to limit FM's performance. Recently, it has been shown that artificial intelligence (AI) can transform one form of contrast into another. We present PICS, a combination of quantitative phase imaging and AI, which provides quantitative information about unlabeled live cells with high specificity. Our imaging system allows for automatic training, while inference is built into the acquisition software and runs in real-time. Applying the computed specificity maps back to the QPI data, we measured the growth of both nuclei and cytoplasm independently, over many days, without loss of viability. Using a QPI method that suppresses multiple scattering, we measured the dry mass content of individual cell nuclei within spheroids.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6027867",
                    "name": "M. Kandel"
                },
                {
                    "authorId": "1911750",
                    "name": "Yuchen R. He"
                },
                {
                    "authorId": "2116464330",
                    "name": "Y. J. Lee"
                },
                {
                    "authorId": "1500340866",
                    "name": "T. H. Chen"
                },
                {
                    "authorId": "47231890",
                    "name": "Kathryn M. Sullivan"
                },
                {
                    "authorId": "37529537",
                    "name": "Onur Aydin"
                },
                {
                    "authorId": "117970690",
                    "name": "M. Saif"
                },
                {
                    "authorId": "2054238257",
                    "name": "H. Kong"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "144952265",
                    "name": "G. Popescu"
                }
            ]
        },
        {
            "paperId": "dfb3f76dce2932d34b20e2b20d9dc31c8930e4c7",
            "title": "Rapid SARS-CoV-2 Detection and Classification Using Phase Imaging with Computational Specificity",
            "abstract": "Efforts to mitigate the COVID-19 crisis revealed that fast, accurate, and scalable testing is crucial for curbing the current impact and that of future pandemics. We propose an optical method for directly imaging unlabeled viral particles and using deep learning for detection and classification. An ultrasensitive interferometric method was used to image four virus types with nanoscale optical pathlength sensitivity. Pairing these data with fluorescence images for ground truth, we trained semantic segmentation models based on U-Net, a particular type of convolutional neural network. The trained network was applied to classify the viruses from the interferometric images only, containing simultaneously SARS-CoV-2, H1N1 (influenza-A), HAdV (adenovirus), and ZIKV (Zika). Remarkably, due to the nanoscale sensitivity in the input data, the neural network was able to identify SARS-CoV-2 vs. the other viruses with 96% accuracy. The inference time for each image is 60 ms, on a common graphic processing unit. This approach of directly imaging unlabeled viral particles may provide an extremely fast test, of less than a minute per patient. As the imaging instrument operates on regular glass slides, we envision this method as potentially testing on patient breath condensates. The necessary high throughput can be achieved by translating concepts from digital pathology, where a microscope can scan hundreds of slides automatically. One Sentence Summary This work proposes a rapid (<1 min.), label-free testing method for SARS-CoV-2 detection, using quantitative phase imaging and deep learning.",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2042311488",
                    "name": "Neha Goswami"
                },
                {
                    "authorId": "1911750",
                    "name": "Yuchen R. He"
                },
                {
                    "authorId": "2042334393",
                    "name": "Yu-Heng Deng"
                },
                {
                    "authorId": "15087678",
                    "name": "Chamteut Oh"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "35269421",
                    "name": "E. Valera"
                },
                {
                    "authorId": "2466336",
                    "name": "R. Bashir"
                },
                {
                    "authorId": "1477736629",
                    "name": "N. Ismail"
                },
                {
                    "authorId": "2054238257",
                    "name": "H. Kong"
                },
                {
                    "authorId": "9398415",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "1402357661",
                    "name": "C. Best-Popescu"
                },
                {
                    "authorId": "144952265",
                    "name": "G. Popescu"
                }
            ]
        }
    ]
}