{
    "authorId": "2330778",
    "papers": [
        {
            "paperId": "11e3a8915016e714e44799f62d542736bb2fc14f",
            "title": "Query Refinement for Diverse Top-k Selection",
            "abstract": "Database queries are often used to select and rank items as decision support for many applications. As automated decision-making tools become more prevalent, there is a growing recognition of the need to diversify their outcomes. In this paper, we define and study the problem of modifying the selection conditions of an ORDER BY query so that the result of the modified query closely fits some user-defined notion of diversity while simultaneously maintaining the intent of the original query. We show the hardness of this problem and propose a mixed-integer linear programming (MILP) based solution. We further present optimizations designed to enhance the scalability and applicability of the solution in real-life scenarios. We investigate the performance characteristics of our algorithm and show its efficiency and the usefulness of our optimizations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293394122",
                    "name": "Felix S. Campbell"
                },
                {
                    "authorId": "2236742952",
                    "name": "Alon Silberstein"
                },
                {
                    "authorId": "2281825322",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                }
            ]
        },
        {
            "paperId": "8b9a3f71ad489f61a403847a5851927cdbac6f87",
            "title": "Query Refinement for Diverse Top-$k$ Selection",
            "abstract": "Database queries are often used to select and rank items as decision support for many applications. As automated decision-making tools become more prevalent, there is a growing recognition of the need to diversify their outcomes. In this paper, we define and study the problem of modifying the selection conditions of an ORDER BY query so that the result of the modified query closely fits some user-defined notion of diversity while simultaneously maintaining the intent of the original query. We show the hardness of this problem and propose a Mixed Integer Linear Programming (MILP) based solution. We further present optimizations designed to enhance the scalability and applicability of the solution in real-life scenarios. We investigate the performance characteristics of our algorithm and show its efficiency and the usefulness of our optimizations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293394122",
                    "name": "Felix S. Campbell"
                },
                {
                    "authorId": "2236742952",
                    "name": "Alon Silberstein"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                }
            ]
        },
        {
            "paperId": "1825bf69badd79607a2ee8e7c09fdbfdd6291e87",
            "title": "Query Refinement for Diversity Constraint Satisfaction",
            "abstract": "Diversity, group representation, and similar needs often apply to query results, which in turn require constraints on the sizes of various subgroups in the result set. Traditional relational queries only specify conditions as part of the query predicate(s), and do not support such restrictions on the output. In this paper, we study the problem of modifying queries to have the result satisfy constraints on the sizes of multiple subgroups in it. This problem, in the worst case, cannot be solved in polynomial time. Yet, with the help of provenance annotation, we are able to develop a query refinement method that works quite efficiently, as we demonstrate through extensive experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2270923804",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "4416c7a9c582a008ad99aba240d56d88d2b07f5a",
            "title": "Dexer: Detecting and Explaining Biased Representation in Ranking",
            "abstract": "With the growing use of ranking algorithms in real-life decision-making purposes, fairness in ranking has been recognized as an important issue. Recent works have studied different fairness measures in ranking, and many of them consider the representation of different \"protected groups\", in the top-k ranked items, for any reasonable k. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups' definitions may be unknown in advance. To this end, we present Dexer, a system for the detection of groups with biased representation in the top-k. Dexer utilizes the notion of Shapley values to provide the users with visual explanations for the cause of bias. We will demonstrate the usefulness of Dexer using real-life data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "4f3f4d4704a64d6714bfa21693d25ecc106e2fdb",
            "title": "ERICA: Query Refinement for Diversity Constraint Satisfaction",
            "abstract": "Relational queries are commonly used to support decision making in critical domains like hiring and college admissions. For example, a college admissions officer may need to select a subset of the applicants for in-person interviews, who individually meet the qualification requirements (e.g., have a sufficiently high GPA) and are collectively demographically diverse (e.g., include a sufficient number of candidates of each gender and of each race). However, traditional relational queries only support selection conditions checked against each input tuple, and they do not support diversity conditions checked against multiple, possibly overlapping, groups of output tuples. To address this shortcoming, we present Erica, an interactive system that proposes minimal modifications for selection queries to have them satisfy constraints on the cardinalities of multiple groups in the result. We demonstrate the effectiveness of Erica using several real-life datasets and diversity requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "2236742952",
                    "name": "Alon Silberstein"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "8b88b37ba32ecde69901a9bdd6e63ffa21a5d339",
            "title": "NEXUS: On Explaining Confounding Bias",
            "abstract": "When analyzing large datasets, analysts are often interested in the explanations for unexpected results produced by their queries. In this work, we focus on aggregate SQL queries that expose correlations in the data. A major challenge that hinders the interpretation of such queries is confounding bias, which can lead to an unexpected association between variables. For example, a SQL query computes the average Covid-19 death rate in each country, may expose a puzzling correlation between the country and the death rate. In this work, we demonstrate NEXUS, a system that generates explanations in terms of a set of potential confounding variables that explain the unexpected correlation observed in a query. NEXUS mines candidate confounding variables from external sources since, in many real-life scenarios, the explanations are not solely contained in the input data. For instance, NEXUS might extract data about factors explaining the association between countries and the Covid-19 death rate, such as information about countries' economies and health outcomes. We will demonstrate the utility of NEXUS for investigating unexpected query results by interacting with the SIGMOD'23 participants, who will act as data analysts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1725561",
                    "name": "Michael J. Cafarella"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2124624117",
                    "name": "Babak Salimi"
                }
            ]
        },
        {
            "paperId": "34eaec9643c1025065589f5513249431168a2ace",
            "title": "On Explaining Confounding Bias",
            "abstract": "When analyzing large datasets, analysts are often interested in the explanations for unexpected results produced by their queries. In this work, we focus on aggregate SQL queries that expose correlations in the data. A major challenge that hinders the interpretation of such queries is confounding bias, which can lead to an unexpected correlation. We generate explanations in terms of a set of potential confounding variables that explain the unexpected correlation observed in a query. We propose to mine candidate confounding variables from external sources since, in many real-life scenarios, the explanations are not solely contained in the input data. We present an efficient algorithm that finds a concise subset of attributes (mined from external sources and the input dataset) that explain the unexpected correlation. This algorithm is embodied in a system called MESA. We demonstrate experimentally over multiple real-life datasets and through a user study that our approach generates insightful explanations, outperforming existing methods even when are given with the extracted attributes. We further demonstrate the robustness of our system to missing data and the ability of MESA to handle input datasets containing millions of tuples and an extensive search space of candidate confounding attributes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1725561",
                    "name": "Michael J. Cafarella"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2124624117",
                    "name": "Babak Salimi"
                }
            ]
        },
        {
            "paperId": "5fac26dbf6f2bd58ad0ca06dd330f40305405342",
            "title": "Bias analysis and mitigation in data-driven tools using provenance",
            "abstract": "Fairness and bias mitigation in data-driven systems has been extensively studied in recent years. In this paper, we suggest a novel approach towards fairness analysis and bias mitigation utilizing the notion of provenance, which was shown to be useful for similar tasks in the context of data and process analyses. We illustrate the idea using a simple use-case demonstrating a scenario of mitigating bias caused by inadequate minority group representation. We conclude with an outline of opportunities and challenges in developing provenance-based solutions for bias analysis and mitigation in data-driven systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "76b14aa638f77a3bbb9793c64b32b042bd0daa60",
            "title": "Reliability at multiple stages in a data analysis pipeline",
            "abstract": "Data-centric methods designed to increase end-to-end reliability of data-driven decision systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "1738586790",
                    "name": "H. Jagadish"
                }
            ]
        },
        {
            "paperId": "a889c66d9ec4999583052db9310eb3605faf5dd6",
            "title": "Detection of Groups with Biased Representation in Ranking",
            "abstract": "Real-life tools for decision-making in many critical domains are based on ranking results. With the increasing awareness of algorithmic fairness, recent works have presented measures for fairness in ranking. Many of those definitions consider the representation of different \"protected groups\", in the top-k ranked items, for any reasonable k. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups\u2019 definitions may be unknown in advance.In this paper, we study the problem of detecting groups with biased representation in the top-k ranked items, eliminating the need to pre-define protected groups. The number of such groups possible can be exponential, making the problem hard. We propose efficient search algorithms for two different fairness measures: global representation bounds, and proportional representation. Then we propose a method to explain the bias in the representations of groups utilizing the notion of Shapley values. We conclude with an experimental study, showing the scalability of our approach and demonstrating the usefulness of the proposed algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        }
    ]
}