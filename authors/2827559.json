{
    "authorId": "2827559",
    "papers": [
        {
            "paperId": "d405bee39e57d97c23f2023ddebb0dada426a041",
            "title": "Evaluation of Sampling Methods for Discovering Facts from Knowledge Graph Embeddings",
            "abstract": "Knowledge graphs (KGs) are being used in many real-world application domains, ranging from search engines to biomedical data analysis. Even if there is a large corpus of KGs available, they are inherently incomplete due to the incompleteness of the sources based on which they were constructed. Knowledge graph embeddings (KGEs) is a very popular technique to complete KGs. However, they are only capable of answering true or false to a given fact. Thus, users need to provide a concrete query or some test data. Unfortunately, such queries or data are not always available. There are cases where users want to discover all (or as many as possible) missing facts from an input KG. Given a KGE model, users should thus provide to the KGE model candidate facts consisting of the complement of the KG. This is infeasible even for small graphs simply due to the size of the complement graph. In this paper, we define the problem of discovering missing facts from a given KGE model and refer to it as fact discovery . We study sampling methods to get candidate facts and then using KGEs to retrieve the most plausible ones. We extensively evaluate different existing sampling methods and provide guidelines on when each one of them is most suitable. We also discuss the challenges and limitations that we encountered when investigating the different techniques. With these insights, we expect to shed light and attract more researchers on this unexplored direction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2292408927",
                    "name": "Rama Widyadhana Bhagaskoro"
                },
                {
                    "authorId": "2284158271",
                    "name": "Volker Markl"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                }
            ]
        },
        {
            "paperId": "efb9b01c0fb967c9b38b5dbcd2e54244ce37edc8",
            "title": "GRADES-NDA'24: 7th Joint Workshop on Graph Data Management Experiences & Systems (GRADES) and Network Data Analytics (NDA)",
            "abstract": "GRADES-NDA is the premier workshop series on graph data management and analytics that aims to bring together researchers from academia, industry, and governmental organizations. GRADES-NDA'24 is a forum for discussing recent advances in (large-scale) graph data management and analytics systems, as well as proposing and discussing novel methods and techniques for addressing domain-specific challenges. In 2024, GRADES-NDA is in its seventh edition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215622430",
                    "name": "Olaf Hartig"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                }
            ]
        },
        {
            "paperId": "3053cd1588bb64497860c204d5c09ce6a3cc2797",
            "title": "Learn What Really Matters: A Learning-to-Rank Approach for ML-based Query Optimization",
            "abstract": ": Query optimization is crucial for any data management system to achieve good performance. Recent advancements in Machine Learning (ML) have led to several efforts in the database research community that aim at improving query optimization with the help of ML. In particular, many works propose replacing the cost model used during plan enumeration with an ML model. The goal of these works is to learn a regression model from previously executed query plans that estimates the runtime of a given plan. Interestingly, it is well-known that what really matters in query optimization is the relative order of the query plan alternatives and not their actual cost or runtime. We thus take a learning-to-rank approach and propose a novel neural network model architecture that can predict the rank of a plan. It considers a plan in comparison with alternative plans of the same query and together with a loss function that incorporates ranking metrics into the learning process we highlight the learning-to-rank objective.To enable training, we first extract features from query plans by adapting a state-of-the-art deep learning approach so that all features are independent of the input dataset schema. Second, we devise two score functions that map the runtime of plans to scores which are then used as labels during training. We integrate the trained model into an adapted bottom-up plan enumeration algorithm that finds the best possible execution plan for a given query. We evaluate our approach against two state-of-the-art ML models and the highly tuned cost model of a commercial database and measure the runtime of the plans chosen in each case when executed in the database. We show that our approach achieves up to an order of magnitude better query performance than the comparison models and is able to either match (for short and medium-running queries) or outperform the commercial database (up to 5 \u00d7 for long-running queries).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209416996",
                    "name": "Henriette Behr"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                }
            ]
        },
        {
            "paperId": "3377ad969797f7ccbb306ecf72e0e8a474c92ae0",
            "title": "Apache Wayang: A Unified Data Analytics Framework",
            "abstract": "The large variety of specialized data processing platforms and the increased complexity of data analytics has led to the need for unifying data analytics within a single framework. Such a framework should free users from the burden of (i) choosing the right platform( s) and (ii) gluing code between the different parts of their pipelines. Apache Wayang (Incubating) is the only open-source framework that provides a systematic solution to unified data analytics by integrating multiple heterogeneous data processing platforms. It achieves that by decoupling applications from the underlying platforms and providing an optimizer so that users do not have to specify the platforms on which their pipeline should run. Wayang provides a unified view and processing model, effectively integrating the hodgepodge of heterogeneous platforms into a single framework with increased usability without sacrificing performance and total cost of ownership. In this paper, we present the architecture ofWayang, describe its main components, and give an outlook on future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3091174",
                    "name": "Kaustubh Beedkar"
                },
                {
                    "authorId": "1404359012",
                    "name": "Bertty Contreras-Rojas"
                },
                {
                    "authorId": "92265606",
                    "name": "Haralampos Gavriilidis"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                },
                {
                    "authorId": "1720831393",
                    "name": "Rodrigo Pardo-Meza"
                },
                {
                    "authorId": "1399355221",
                    "name": "Jorge-Arnulfo Quian\u00e9-Ruiz"
                }
            ]
        },
        {
            "paperId": "dafca525dfffb5e241f70a2ddecbd074dc6e8dad",
            "title": "Counting Butterflies in Fully Dynamic Bipartite Graph Streams",
            "abstract": "A bipartite graph extensively models relationships between real-world entities of two different types, such as user-product data in e-commerce. Such graph data are inherently becoming more and more streaming, entailing continuous insertions and deletions of edges. A butterfly (i.e., 2 x 2 bi-clique) is the smallest non-trivial cohesive structure that plays a crucial role. Counting such butterfly patterns in streaming bipartite graphs is a core problem in applications such as dense subgraph discovery and anomaly detection. Yet, existing approximate solutions consider insert-only streams and, thus, achieve very low accuracy in fully dynamic bipartite graph streams that involve both insertions and deletions of edges. Adapting them to consider deletions is not trivial either, because different sampling schemes and new accuracy analyses are required. We propose Abacus, a novel approximate algorithm that counts butterflies in the presence of both insertions and deletions by utilizing sampling. We prove that Abacus always delivers unbiased estimates of low variance. Furthermore, we extend Abacus and devise a parallel mini-batch variant, namely, ParAbacus, which counts butterflies in parallel. ParAbacus counts butterflies in a load-balanced manner using versioned samples, which results in significant speedup and is thus ideal for critical applications in the streaming environment. We evaluate ABACUS/PARABACUS using a diverse set of real bipartite graphs and assess its performance in terms of accuracy, throughput, and speedup. The results indicate that our proposal is the first capable of efficiently providing accurate butterfly counts in the most generic setting, i.e., a fully dynamic graph streaming environment that entails both insertions and deletions. It does so without sacrificing throughput, and even improves it with the parallel version.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "87484021",
                    "name": "Serafeim Papadias"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "2266394577",
                    "name": "Varun Pandey"
                },
                {
                    "authorId": "1399355221",
                    "name": "Jorge-Arnulfo Quian\u00e9-Ruiz"
                },
                {
                    "authorId": "2239093550",
                    "name": "Volker Markl"
                }
            ]
        },
        {
            "paperId": "049495a75a494bed68e06e5d3d47ed51ffac3cda",
            "title": "Farming Your ML-based Query Optimizer's Food",
            "abstract": "Machine learning (ML) is becoming a core component in query optimizers, e.g., to estimate costs or cardinalities. This means large heterogeneous sets of labeled query plans or jobs (i.e., plans with their runtime or cardinality output) are needed. However, collecting such a training dataset is a very tedious and time-consuming task: It requires both developing numerous jobs and executing them to acquire ground-truth labels. We demonstrate Datafarm,a novel framework for efficiently generating and labeling training data for ML-based query optimizers to overcome these issues. Datafarmenables generating training data tailored to users' needs by learning from their existing workload patterns, input data, and computational resources. It uses an active learning approach to determine a subset of jobs to be executed and encloses the human into the loop, resulting in higher quality data. The graphical user interface of Datafarmallows users to get informative details of the generated jobs and guides them through the generation process step-by-step. We show how users can intervene and provide feedback to the system in an iterative fashion. As an output, users can download both the generated jobs to use as a benchmark and the training data (jobs with their labels).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069149891",
                    "name": "Robin Van De Water"
                },
                {
                    "authorId": "144846914",
                    "name": "F. Ventura"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "1399355221",
                    "name": "Jorge-Arnulfo Quian\u00e9-Ruiz"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                }
            ]
        },
        {
            "paperId": "069e10048e4b50cabb1748ecda156eac515ba8f1",
            "title": "DataFarm: Farm Your ML-based Query Optimizer's Food! - Human-Guided Training Data Generation -",
            "abstract": "The need for ML-based query optimization. The value that data and AI technologies offer today mandates open environments, where data assets, such as datasets, algorithms, and machine learning (ML) models, are unified under the same ecosystem [3]. Agora 1 is an ecosystem that aims at (i) offering assets to a broader audience via a set of marketplaces and (ii) providing an open execution environment that allows users to run their (composed) assets. In such an open environment, there is a need for heterogeneous task execution, i.e., a task can be executed by combining multiple processing systems. The decision on the set of systems is taken based on query optimization, similarly to the cross-platform systems [1]. However, cost-based optimization in",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069149891",
                    "name": "Robin Van De Water"
                },
                {
                    "authorId": "144846914",
                    "name": "F. Ventura"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "1399355221",
                    "name": "Jorge-Arnulfo Quian\u00e9-Ruiz"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                }
            ]
        },
        {
            "paperId": "297e2ed22af4b9de6264d08d060145881da83b4e",
            "title": "Materialization and Reuse Optimizations for Production Data Science Pipelines",
            "abstract": "Many companies and businesses train and deploy machine learning (ML) pipelines to answer prediction queries. In many applications, new training data continuously becomes available. A typical approach to ensure that ML models are up-to-date is to retrain the ML pipelines following a schedule, e.g., every day on the last seven days of data. Several use cases, such as A/B testing and ensemble learning, require many pipelines to be deployed in parallel. Existing solutions train each pipeline separately, which generates redundant data processing. Our goal is to eliminate redundant data processing in such scenarios using materialization and reuse optimizations. Our solution comprises of two main parts. First, we propose a materialization algorithm that given a storage budget, materializes the subset of the artifacts to minimize the run time of the subsequent executions. Second, we design a reuse algorithm to generate an execution plan by combining the pipelines into a directed acyclic graph (DAG) and reusing the materialized artifacts when appropriate. Our experiments show that our solution can reduce the training time by up to an order of magnitude for different deployment scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2013175",
                    "name": "Behrouz Derakhshan"
                },
                {
                    "authorId": "2113608196",
                    "name": "Alireza Rezaei Mahdiraji"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "1731210",
                    "name": "T. Rabl"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                }
            ]
        },
        {
            "paperId": "305348db7a5b27a8dfcaf756053c194b6c9a99f0",
            "title": "Space-Efficient Random Walks on Streaming Graphs",
            "abstract": "Graphs in many applications, such as social networks and IoT, are inherently streaming, involving continuous additions and deletions of vertices and edges at high rates. Constructing random walks in a graph, i.e., sequences of vertices selected with a specific probability distribution, is a prominent task in many of these graph applications as well as machine learning (ML) on graph-structured data. In a streaming scenario, random walks need to constantly keep up with the graph updates to avoid stale walks and thus, performance degradation in the downstream tasks. We present Wharf, a system that efficiently stores and updates random walks on streaming graphs. It avoids a potential size explosion by maintaining a compressed, high-throughput, and low-latency data structure. It achieves (i) the succinct representation by coupling compressed purely functional binary trees and pairing functions for storing the walks, and (ii) efficient walk updates by effectively pruning the walk search space. We evaluate Wharf, with real and synthetic graphs, in terms of throughput and latency when updating random walks. The results show the high superiority of Wharf over inverted index- and tree-based baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "87484021",
                    "name": "Serafeim Papadias"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "1399355221",
                    "name": "Jorge-Arnulfo Quian\u00e9-Ruiz"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                }
            ]
        },
        {
            "paperId": "4978520a959b103f9dd55ec3ce4545ab06191a18",
            "title": "Good Intentions: Adaptive Parameter Management via Intent Signaling",
            "abstract": "Model parameter management is essential for distributed training of large machine learning (ML) tasks. Some ML tasks are hard to distribute because common approaches to parameter management can be highly inefficient. Advanced parameter management approaches---such as selective replication or dynamic parameter allocation---can improve efficiency, but they typically need to be integrated manually into each task's implementation and they require expensive upfront experimentation to tune correctly. In this work, we explore whether these two problems can be avoided. We first propose a novel intent signaling mechanism that integrates naturally into existing ML stacks and provides the parameter manager with crucial information about parameter accesses. We then describe AdaPM, a fully adaptive, zero-tuning parameter manager based on this mechanism. In contrast to prior parameter managers, our approach decouples how access information is provided (simple) from how and when it is exploited (hard). In our experimental evaluation, AdaPM matched or outperformed state-of-the-art parameter managers out of the box, suggesting that automatic parameter management is possible.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1409353863",
                    "name": "Alexander Renz-Wieland"
                },
                {
                    "authorId": "2167314857",
                    "name": "Andreas Kieslinger"
                },
                {
                    "authorId": "27962385",
                    "name": "R. Gericke"
                },
                {
                    "authorId": "1777107",
                    "name": "Rainer Gemulla"
                },
                {
                    "authorId": "2827559",
                    "name": "Zoi Kaoudi"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                }
            ]
        }
    ]
}