{
    "authorId": "143844410",
    "papers": [
        {
            "paperId": "2e051cb3b0b5d6314e5c3bd97eceea555cb7fea9",
            "title": "Cooperative Trajectory Design of Multiple UAV Base Stations With Heterogeneous Graph Neural Networks",
            "abstract": "Unmanned aerial vehicles as base stations (UAV-BSs) are recognized as effective means for tackling eruptive communication service requirements especially when terrestrial infrastructures are unavailable. Quality of service (QoS) received by ground terminals (GTs) highly depends on the spatial movement of UAV-BSs. In this paper, we investigate the cooperative trajectory design problem of multiple UAV-BSs towards fair throughput maximization of GTs. Considering the restriction of coverage and sensing, we first propose a heterogeneous-graph-based formulation of relations between GTs and UAV-BSs. Subsequently, we design a framework named graph vision and communication (GVis&Comm) to 1) let each UAV-BS efficiently manage time-varying local observations; 2) facilitate cooperation between UAV-BSs through explicit information exchange. To further reduce the overhead of over-the-air cooperation, we realize discretization of the message passing process among UAV-BSs while still enabling end-to-end training. By leveraging multi-agent reinforcement learning (MARL), UAV-BSs as agents learn a distributed trajectory design policy. Extensive numerical simulation shows that our framework on the one hand achieves remarkable efficiency in processing local observations of each UAV-BS, and on the other improves the overall network performance via close cooperation among UAV-BSs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108192984",
                    "name": "Xiaochen Zhang"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "1721544",
                    "name": "Jibo Wei"
                },
                {
                    "authorId": "145071035",
                    "name": "Chao Yan"
                },
                {
                    "authorId": "144394896",
                    "name": "Jun Xiong"
                },
                {
                    "authorId": "144429536",
                    "name": "Xiaoran Liu"
                }
            ]
        },
        {
            "paperId": "086cff9bb35756c54527e64b9fba9b794777bdcf",
            "title": "Adaptive Hierarchical Federated Learning Over Wireless Networks",
            "abstract": "Federated learning (FL) is promising in enabling large-scale model training by massive devices without exposing their local datasets. However, due to limited wireless resources, traditional cloud-based FL system suffers from the bottleneck of communication overhead in core network. Fueled by this issue, we consider a hierarchical FL system and formulate a joint problem of edge aggregation interval control and resource allocation to minimize the weighted sum of training loss and training latency. To quantify the learning performance, an upper bound of the average global gradient deviation, in terms of the edge aggregation interval, the training latency, and the number of successfully participating devices, is derived. Then an alternative problem is formulated, which can be decoupled into an edge aggregation interval control problem and a resource allocation problem, and solved by an iterative optimization algorithm. Specifically, given the resource allocation strategy, a relaxation and rounding method is proposed to optimize the edge aggregation interval. The problem of resource allocation including training time allocation and bandwidth allocation is solved separately based on the convex optimization theory. Simulation results show that the proposed algorithm, compared to the benchmarks, can achieve higher learning performance with lower training latency, and is capable of adaptively adjusting the edge aggregation interval and the resource allocation strategy according to the training process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109511676",
                    "name": "Bo Xu"
                },
                {
                    "authorId": "8876610",
                    "name": "Wenchao Xia"
                },
                {
                    "authorId": "6174647",
                    "name": "Wanli Wen"
                },
                {
                    "authorId": "2217847587",
                    "name": "Pei Liu"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "144439565",
                    "name": "Hongbo Zhu"
                }
            ]
        },
        {
            "paperId": "1d38af8ff589a017c722a72e42f80569ee3d8537",
            "title": "Joint Resource Allocation on Slot, Space and Power towards Concurrent Transmissions in UAV Ad Hoc Networks",
            "abstract": "With innovative applications of unmanned aerial vehicle (UAV) ad hoc networks in various areas, their demands on broad bandwidth, large capacity and low latency become prominent. The combination of millimeter wave, directional antenna and time division multiple access techniques, which enables concurrent transmissions, is promising to deal with it. In this paper, we study the resource allocation problem in UAV ad hoc networks. Specifically, the slot assignment, antenna boresight and transmit power are jointly optimized to promote the network capacity. First, we formulate the optimization problem as the maximization of the fairness-weighted network capacity, subject to the constraint on priority guarantee. Then, because the formulated problem is a mixed integer non-linear programming problem (MINLP), which is NP-hard, two algorithms called dual-based iterative search algorithm (DISA) and sequential exhausted allocation algorithm (SEAA) are respectively proposed to efficiently solve it with acceptable complexity. DISA slacks the MINLP into a continuous-variable optimization problem and solves it with the Lagrangian dual method in an iterative manner. As a heuristic method, SEAA schedules links sequentially, i.e., from high-priority to low-priority ones. Numerical results demonstrate that both DISA and SEAA can efficiently allocate resources for UAVs, while guaranteeing the fairness and priority of links.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1500417220",
                    "name": "Haijun Wang"
                },
                {
                    "authorId": "2114186418",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "51181818",
                    "name": "Jiao Zhang"
                },
                {
                    "authorId": "48207454",
                    "name": "Li Zhou"
                },
                {
                    "authorId": "8912948",
                    "name": "Dongtang Ma"
                },
                {
                    "authorId": "1721544",
                    "name": "Jibo Wei"
                },
                {
                    "authorId": "143698682",
                    "name": "Victor C. M. Leung"
                }
            ]
        },
        {
            "paperId": "50e4c4e1812f36463d7ba4d05577ea2e51b43bb9",
            "title": "Toward Tailored Resource Allocation of Slices in 6G Networks With Softwarization and Virtualization",
            "abstract": "Compared with 5G networks, 6G networks are guaranteed to provide various tailored end-to-end network services and emerging cloud-edge applications. Network slicing (NS) is regarded as the key enabler of 6G networks. Softwarization and virtualization technologies, such as software-defined networking and network function virtualization, are accelerating the way toward NS of 6G networks. The resource allocation issue in 6G NS is very crucial, worthy more research attention. In this article, we propose one efficient resource allocation algorithm, labeled as TailoredSlice-6G, so as to realize the tailored slices in 6G. When receiving one slice request, our TailoredSlice-6G will identify the slice resource type in the first place. Then, our TailoredSlice-6G will select its most suitable subalgorithm to do the resource allocation and slicing deployment. Each type of slice corresponds to its specific resource allocation subalgorithm, inserted in the TailoredSlice-6G algorithm. In addition, each subalgorithm in TailoredSlice-6G is guaranteed to run within polynomial time. Thus, TailoredSlice-6G having the potential to be promoted to real networking application. To highlight the merits of TailoredSlice-6G, we do the comprehensive simulation. Simulation results vividly reveal that our TailoredSlice-6G outperforms the selected heuristics that are representative in the literature.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1866371",
                    "name": "Haotong Cao"
                },
                {
                    "authorId": "2477880",
                    "name": "Jianbo Du"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "34817604",
                    "name": "D. X. Luo"
                },
                {
                    "authorId": "2143693445",
                    "name": "Neeraj Kumar"
                },
                {
                    "authorId": "1774123",
                    "name": "Longxiang Yang"
                },
                {
                    "authorId": "1696615",
                    "name": "F. Yu"
                }
            ]
        },
        {
            "paperId": "5a654ebd3d8280fc031a6457fa0977037ee53954",
            "title": "Analysis on Age of Information in Partial Computing Edge Computing Systems with Multi Source-Destination Pairs",
            "abstract": "Some Internet of Things (IoT) applications represented by vehicular networks, Internet of Medical Things (IoMT), and fire alarm systems have high requirements on the freshness of receiving information. Due to limited computing capability of IoT devices, mobile edge computing (MEC) is applied to reduce packet calculation time and improve packet freshness. In this paper, we investigate a MEC system for sharing vehicle status information and use the age-of-information (AoI) to define the freshness of information in the MEC system. The whole system is modeled as a two-stage tandem queue model with multi source-destination pairs. We derive the closed-form expression for the average AoI of partial computing and analyze the impact of system parameters on the average AoI, which provides guidance on how to set parameters to maximize the information freshness of the MEC system. As a more flexible scheme, partial computing we used reduces the AoI of the MEC system compared to remote computing. Numerical analysis validates our theory.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145539045",
                    "name": "Haozhe Li"
                },
                {
                    "authorId": "2191136664",
                    "name": "Guangwei Gong"
                },
                {
                    "authorId": "51181818",
                    "name": "Jiao Zhang"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "48207454",
                    "name": "Li Zhou"
                },
                {
                    "authorId": "1721544",
                    "name": "Jibo Wei"
                }
            ]
        },
        {
            "paperId": "6a8f59a4e185409537c574117fec824d437d84c7",
            "title": "Context-Based Semantic Communication via Dynamic Programming",
            "abstract": "Standard digital communication techniques allow us to set aside the meaning of the messages to concentrate on the transmission of bits efficiently and reliably. However, with the integration of artificial intelligence into communications technology and the merging of communication and computation within devices, increasing evidence suggests that the semantic aspect of communication cannot be set aside. We propose a part-of-speech-based encoding strategy and context-based decoding strategies, in which various deep learning models are presented to learn the semantic and contextual features as background knowledge. With the background knowledge, our strategies can be applied to some non-jointly-designed communication scenarios with uncertainty. We compare the performances of two proposed decoding strategies, the deep learning models of which are different, to provide model-choice design guidelines in accordance with specific communication conditions. Further, we discuss the impact of several parameters on the performance of our strategies, such as the size of the context window and the size of the feature window. Simulation results indicate the effectiveness and the reliability of our strategies in terms of decreasing the number of bits used to transmit messages and increasing the semantic accuracy between transmitted messages and recovered messages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124815871",
                    "name": "Yichi Zhang"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "1721544",
                    "name": "Jibo Wei"
                },
                {
                    "authorId": "51181818",
                    "name": "Jiao Zhang"
                },
                {
                    "authorId": "8369732",
                    "name": "M. Flanagan"
                },
                {
                    "authorId": "144394896",
                    "name": "Jun Xiong"
                }
            ]
        },
        {
            "paperId": "792f95fc0300295ee2a355086702535c0e576785",
            "title": "Theoretical Analysis of Deep Neural Networks in Physical Layer Communication",
            "abstract": "Recently, deep neural network (DNN)-based physical layer communication techniques have attracted considerable interest. Although their potential to enhance communication systems and superb performance have been validated by simulation experiments, little attention has been paid to the theoretical analysis. Specifically, most studies in the physical layer have tended to focus on the application of DNN models to wireless communication problems but not to theoretically understand how does a DNN work in a communication system. In this paper, we aim to quantitatively analyze why DNNs can achieve comparable performance in the physical layer comparing with traditional techniques, and also drive their cost in terms of computational complexity. To achieve this goal, we first analyze the encoding performance of a DNN-based transmitter and compare it to a traditional one. And then, we theoretically analyze the performance of DNN-based estimator and compare it with traditional estimators. Third, we investigate and validate how information is flown in a DNN-based communication system under the information theoretic concepts. Our analysis develops a concise way to open the \u201cblack box\u201d of DNNs in physical layer communication, which can be applied to support the design of DNN-based intelligent communication techniques and help to provide explainable performance assessment.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "40478976",
                    "name": "J. Liu"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "8912948",
                    "name": "Dongtang Ma"
                },
                {
                    "authorId": "48295463",
                    "name": "Kai Mei"
                },
                {
                    "authorId": "1721544",
                    "name": "Jibo Wei"
                }
            ]
        },
        {
            "paperId": "bb5f1cb2582d9e3ea1c72a50a1552812fc00ed68",
            "title": "Cell-Free IoT Networks With SWIPT: Performance Analysis and Power Control",
            "abstract": "In this article, the performance of simultaneous wireless information and power transfer (SWIPT) in downlink (DL) Internet of Things (IoT) networks relying on the cell-free massive multiple-input\u2013multiple-output (CF-mMIMO) technique is investigated. In such a network, the access points (APs) beam the radio-frequency (RF) energy toward IoT sensors during the DL wireless power transfer phase. Tight closed-form expressions for DL harvested energy (HE) and achievable rate with conjugate beamforming (CB) and normalized CB (NCB) are, respectively, derived, which enable us to analyze the behaviors of CB and NCB schemes in terms of both HE and achievable rate. Apart from this, to guarantee sensor fairness with respect to the HE and achievable rate, a max\u2013min power control strategy based on the accelerated projected gradient (APG) method is proposed. Specifically, the proposed APG-based power control is able to determine the optimal solution in closed form and is more memory efficient than the convex-solver-based counterpart. These analytical results as well as the effectiveness of the proposed power control policy are verified by experimental simulations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118389263",
                    "name": "Yao Zhang"
                },
                {
                    "authorId": "8876610",
                    "name": "Wenchao Xia"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "2333664",
                    "name": "Wei-Qiang Xu"
                },
                {
                    "authorId": "1719290",
                    "name": "Kai\u2010Kit Wong"
                },
                {
                    "authorId": "1774123",
                    "name": "Longxiang Yang"
                }
            ]
        },
        {
            "paperId": "c4c2ee2e66f44fb1ac186eaad97877fe48bf6eeb",
            "title": "Energy-Efficient Virtual Resource Allocation of Slices in Vehicles-Assisted B5G Networks",
            "abstract": "Academia community started the research beyond 5G (B5G) while 5G systems and networks are still being landed for large-scale commercial applications. In order to enhance the agility and flexibility attributes of B5G networks, network function virtualization (NFV) and network slicing (NS) are attracting extensive research attention. Meanwhile, vehicles are promised to connect to the B5G networks so as to expand the service coverage and reach the \u2018last one mile\u2019. In this paper, we research the virtual resource allocation of slices in vehicles-assisted B5G networks. We aim at saving total energy cost of deployed slices while ensuring high slice acceptance ratio. We firstly present the system model of vehicles-assisted B5G networks, supporting both virtualization and slicing schemes. Then, we present the energy cost of vehicles-assisted B5G networks. Afterwards, we propose one energy efficient algorithm, abbreviated as Ener-Eff-Slice, to solve the virtual resource allocation of slices in vehicles-assisted B5G networks. Numerical results are recorded, plotted and discussed, which prove the efficacy of our scheme. Finally, we do the conclusion marks and discuss the next-step work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1866371",
                    "name": "Haotong Cao"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "9492431",
                    "name": "Anish Jindal"
                },
                {
                    "authorId": "8880101",
                    "name": "G. Aujla"
                },
                {
                    "authorId": "1774123",
                    "name": "Longxiang Yang"
                }
            ]
        },
        {
            "paperId": "d2a0c2d94961a8eb6fa1b7ac89946a146297a351",
            "title": "Comparison of Mobile AdHoc Network Routing Protocols Based on NS3",
            "abstract": "Mobile Ad Hoc Networks (MANETs) operate without fixed infrastructures or a central access point. In MANET, the nodes are constantly moving at various speeds, resulting in unpredictable network topologies and path transmission. AODV, OLSR and BATMAN protocols are frequently used for route selection in MANET. In order to compare three routing protocols, three scenarios are created by changing the pause time, moving speed, and the number of nodes. Simulation results show that BATMAN, and OLSR perform well in networks with frequent changes in network topology, AODV has great advantages in fast mobile networks, and OLSR performs well in large-scale networks. Finally, according to the experimental results, the performance of the three protocols, such as packet delivery rate (PDR), end-to-end delay, and mean hops, is evaluated and analyzed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108194682",
                    "name": "Zhe Wang"
                },
                {
                    "authorId": "51181818",
                    "name": "Jiao Zhang"
                },
                {
                    "authorId": "2124815871",
                    "name": "Yichi Zhang"
                },
                {
                    "authorId": "143844410",
                    "name": "Haitao Zhao"
                },
                {
                    "authorId": "1721544",
                    "name": "Jibo Wei"
                }
            ]
        }
    ]
}