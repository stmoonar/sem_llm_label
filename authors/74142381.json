{
    "authorId": "74142381",
    "papers": [
        {
            "paperId": "2542e940063ad0cdce37d9fbab745242bac3bf34",
            "title": "Meta Auxiliary Learning for Top-K Recommendation",
            "abstract": "Recommender systems are playing a significant role in modern society to alleviate the information/choice overload problem, since Internet users may feel hard to identify the most favorite items or products from millions of candidates. Thanks to the recent successes in computer vision, auxiliary learning has become a powerful means to improve the performance of a target (primary) task. Even though helpful, the auxiliary learning scheme is still less explored in recommendation models. To integrate the auxiliary learning scheme, we propose a novel meta auxiliary learning framework to facilitate the recommendation model training, i.e., user and item latent representations. Specifically, we construct two self-supervised learning tasks, regarding both users and items, as auxiliary tasks to enhance the representation effectiveness of users and items. Then the auxiliary and primary tasks are further modeled as a meta learning paradigm to adaptively control the contribution of auxiliary tasks for improving the primary recommendation task. This is achieved by an implicit gradient method guaranteeing less time complexity compared with conventional meta learning methods. Via a comparison using four real-world datasets with a number of state-of-the-art methods, we show that the proposed model outperforms the best existing models on the Top-K recommendation by 3% to 23%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108691206",
                    "name": "Ximing Li"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2108398139",
                    "name": "Guozheng Li"
                },
                {
                    "authorId": "2153915768",
                    "name": "Peng Xu"
                },
                {
                    "authorId": "2144632579",
                    "name": "Chi Harold Liu"
                },
                {
                    "authorId": "2130403581",
                    "name": "Ye Yuan"
                },
                {
                    "authorId": "8349792",
                    "name": "Guoren Wang"
                }
            ]
        },
        {
            "paperId": "26ebeeb1b9172df34ad21f1000bb6f3c374a222e",
            "title": "Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems",
            "abstract": "Recommender systems now consume large-scale data and play a significant role in improving user experience. Graph Neural Networks (GNNs) have emerged as one of the most effective recommender system models because they model the rich relational information. The ever-growing volume of data can make training GNNs prohibitively expensive. To address this, previous attempts propose to train the GNN models incrementally as new data blocks arrive. \nFeature and structure knowledge distillation techniques have been explored to allow the GNN model to train in a fast incremental fashion while alleviating the catastrophic forgetting problem. \nHowever, preserving the same amount of the historical information for all users is sub-optimal since it fails to take into account the dynamics of each user's change of preferences. \nFor the users whose interests shift substantially, retaining too much of the old knowledge can overly constrain the model, preventing it from quickly adapting to the users\u2019 novel interests. \nIn contrast, for users who have static preferences, model performance can benefit greatly from preserving as much of the user's long-term preferences as possible.\nIn this work, we propose a novel training strategy that adaptively learns personalized imitation weights for each user to balance the contribution from the recent data and the amount of knowledge to be distilled from previous time periods.\nWe demonstrate the effectiveness of learning imitation weights via a comparison on five diverse datasets for three state-of-art structure distillation based recommender systems. The performance shows consistent improvement over competitive incremental learning techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108711613",
                    "name": "Yuening Wang"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "1419478649",
                    "name": "Antonios Valkanas"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2069718816",
                    "name": "Jianye Hao"
                },
                {
                    "authorId": "2150349871",
                    "name": "Mark Coates"
                }
            ]
        },
        {
            "paperId": "6f9f52845308d2f57be8032965fe3c20b82ba6b3",
            "title": "Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System",
            "abstract": "With the continuous increase of users and items, conventional recommender systems trained on static datasets can hardly adapt to changing environments. The high-throughput data requires the model to be updated in a timely manner for capturing the user interest dynamics, which leads to the emergence of streaming recommender systems. Due to the prevalence of deep learning-based recommender systems, the embedding layer is widely adopted to represent the characteristics of users, items, and other features in low-dimensional vectors. However, it has been proved that setting an identical and static embedding size is sub-optimal in terms of recommendation performance and memory cost, especially for streaming recommendations. To tackle this problem, we first rethink the streaming model update process and model the dynamic embedding size search as a bandit problem. Then, we analyze and quantify the factors that influence the optimal embedding sizes from the statistics perspective. Based on this, we propose the Dynamic Embedding Size Search (DESS) method to minimize the embedding size selection regret on both user and item sides in a non-stationary manner. Theoretically, we obtain a sublinear regret upper bound superior to previous methods. Empirical results across two recommendation tasks on four public datasets also demonstrate that our approach can achieve better streaming recommendation performance with lower memory cost and higher time efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13358736",
                    "name": "Bowei He"
                },
                {
                    "authorId": "1510737168",
                    "name": "Xu He"
                },
                {
                    "authorId": null,
                    "name": "Renrui Zhang"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                }
            ]
        },
        {
            "paperId": "9a38c738a9bca9144dd8aaf34cd0a154d1a63abc",
            "title": "Feature Representation Learning for Click-through Rate Prediction: A Review and New Perspectives",
            "abstract": "Representation learning has been a critical topic in machine learning. In Click-through Rate Prediction, most features are represented as embedding vectors and learned simultaneously with other parameters in the model. With the development of CTR models, feature representation learning has become a trending topic and has been extensively studied by both industrial and academic researchers in recent years. This survey aims at summarizing the feature representation learning in a broader picture and pave the way for future research. To achieve such a goal, we first present a taxonomy of current research methods on feature representation learning following two main issues: (i) which feature to represent and (ii) how to represent these features. Then we give a detailed description of each method regarding these two issues. Finally, the review concludes with a discussion on the future directions of this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2109888596",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "107747459",
                    "name": "Haolun Wu"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "1996703",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                }
            ]
        },
        {
            "paperId": "bf4f53a5d531b2baf856cb626cca63ff4fb0ff6a",
            "title": "Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation",
            "abstract": "Knowledge distillation aims to train a compact student network using soft supervision from a larger teacher network and hard supervision from ground truths. However, determining an optimal knowledge fusion ratio that balances these supervisory signals remains challenging. Prior methods generally resort to a constant or heuristic-based fusion ratio, which often falls short of a proper balance. In this study, we introduce a novel adaptive method for learning a sample-wise knowledge fusion ratio, exploiting both the correctness of teacher and student, as well as how well the student mimics the teacher on each sample. Our method naturally leads to the intra-sample trilateral geometric relations among the student prediction ($S$), teacher prediction ($T$), and ground truth ($G$). To counterbalance the impact of outliers, we further extend to the inter-sample relations, incorporating the teacher's global average prediction $\\bar{T}$ for samples within the same class. A simple neural network then learns the implicit mapping from the intra- and inter-sample relations to an adaptive, sample-wise knowledge fusion ratio in a bilevel-optimization manner. Our approach provides a simple, practical, and adaptable solution for knowledge distillation that can be employed across various architectures and model sizes. Extensive experiments demonstrate consistent improvements over other loss re-weighting methods on image classification, attack detection, and click-through rate prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11577774",
                    "name": "Chengming Hu"
                },
                {
                    "authorId": "107747459",
                    "name": "Haolun Wu"
                },
                {
                    "authorId": "1870442533",
                    "name": "Xuan Li"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2276755492",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "2276572925",
                    "name": "Jun Yan"
                },
                {
                    "authorId": "2276507277",
                    "name": "Boyu Wang"
                },
                {
                    "authorId": "2151058626",
                    "name": "Xue Liu"
                }
            ]
        },
        {
            "paperId": "cacfb167a39ce152c2e8ea69733006e6549747e3",
            "title": "Doctor Specific Tag Recommendation for Online Medical Record Management",
            "abstract": "With the rapid growth of online medical platforms, more and more doctors are willing to manage and communicate with patients via online services. Considering the large volume and various patient conditions, identifying and classifying patients' medical records has become a crucial problem. To efficiently index these records, a common practice is to annotate them with semantically meaningful tags. However, manual labeling tags by doctors is impractical due to the possibility of thousands of tag candidates, which necessitates a tag recommender system. Due to the long tail distribution of tags and the dominance of low-activity doctors, as well as the unique uploaded medical records, this task is rather challenging. This paper proposes an efficient doctor specific tag recommendation framework for improved medical record management without side information. Specifically, we first utilize effective language models to learn the text representation. Then, we construct a doctor embedding learning module to enhance the recommendation quality by integrating implicit information within text representations and considering latent tag correlations to make more accurate predictions. Extensive experiment results demonstrate the effectiveness of our framework from the viewpoints of all doctors (20% improvement) or low-activity doctors (10% improvement).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "36263371",
                    "name": "Shen Ge"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "144620591",
                    "name": "X. Wu"
                },
                {
                    "authorId": "2151647484",
                    "name": "Tong Xu"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2227734260",
                    "name": "Zhi Zheng"
                }
            ]
        },
        {
            "paperId": "ddb4c10d2957e944af11e02e87dc147a547c256a",
            "title": "Collaborative Edge Caching: a Meta Reinforcement Learning Approach with Edge Sampling",
            "abstract": "Current learning-based edge caching schemes usually suffer from dynamic content popularity, e.g., in the emerging short video platforms, users\u2019 request patterns shift significantly over time and across different edges. An intuitive solution for a specific local edge cache is to collect more request histories from other edge caches. However, uniformly merging these request histories may not perform satisfactorily due to heterogeneous content distributions on different edges. To solve this problem, we propose a collaborative edge caching framework. First, we design a meta-learning-based collaborative strategy to guarantee that the local model can timely meet the continually changing content popularity. Then, we design an edge sampling method to select more \"valuable\" neighbor edges to participate in the local training. To evaluate the proposed framework, we conduct trace-driven experiments to demonstrate the effectiveness of our design: it improves the average cache hit rate by up to 10.12% (normalized) compared with other baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13358736",
                    "name": "Bowei He"
                },
                {
                    "authorId": "1840978357",
                    "name": "Yinan Mao"
                },
                {
                    "authorId": "2149195194",
                    "name": "Shiji Zhou"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2135451795",
                    "name": "Zhi Wang"
                }
            ]
        },
        {
            "paperId": "e45401f1c1cca2127bd8d96f8ed773e6208bfe40",
            "title": "Dynamically Expandable Graph Convolution for Streaming Recommendation",
            "abstract": "Personalized recommender systems have been widely studied and deployed to reduce information overload and satisfy users\u2019 diverse needs. However, conventional recommendation models solely conduct a one-time training-test fashion and can hardly adapt to evolving demands, considering user preference shifts and ever-increasing users and items in the real world. To tackle such challenges, the streaming recommendation is proposed and has attracted great attention recently. Among these, continual graph learning is widely regarded as a promising approach for the streaming recommendation by academia and industry. However, existing methods either rely on the historical data replay which is often not practical under increasingly strict data regulations, or can seldom solve the over-stability issue. To overcome these difficulties, we propose a novel Dynamically Expandable Graph Convolution (DEGC) algorithm from a model isolation perspective for the streaming recommendation which is orthogonal to previous methods. Based on the motivation of disentangling outdated short-term preferences from useful long-term preferences, we design a sequence of operations including graph convolution pruning, refining, and expanding to only preserve beneficial long-term preference-related parameters and extract fresh short-term preferences. Moreover, we model the temporal user preference, which is utilized as user embedding initialization, for better capturing the individual-level preference shifts. Extensive experiments on the three most representative GCN-based recommendation models and four industrial datasets demonstrate the effectiveness and robustness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13358736",
                    "name": "Bowei He"
                },
                {
                    "authorId": "1510737168",
                    "name": "Xu He"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                }
            ]
        },
        {
            "paperId": "08ac9fc139aed960fdfed1093cf5e7931c9c98a1",
            "title": "Intent-aware Multi-source Contrastive Alignment for Tag-enhanced Recommendation",
            "abstract": "To offer accurate and diverse recommendation services, recent methods use auxiliary information to foster the learning process of user and item representations. Many state-of-the-art (SOTA) methods fuse different sources of information (user, item, knowledge graph, tags, etc.) into a graph and use Graph Neural Networks (GNNs) to introduce the auxiliary information through the message passing paradigm. In this work, we seek an alternative framework that is light and effective through self-supervised learning across different sources of information, particularly for the commonly accessible item tag information. We use a self-supervision signal to pair users with the auxiliary information (tags) associated with the items they have interacted with before. To achieve the pairing, we create a proxy training task. For a given item, the model predicts which is the correct pairing between the representations obtained from the users that have interacted with this item and the tags assigned to it. This design provides an efficient solution, using the auxiliary information directly to enhance the quality of user and item embeddings. User behavior in recommendation systems is driven by the complex interactions of many factors behind the users\u2019 decision-making processes. To make the pairing process more fine-grained and avoid embedding collapse, we propose a user intent-aware self-supervised pairing process where we split the user embeddings into multiple sub-embedding vectors. Each sub-embedding vector captures a specific user intent via self-supervised alignment with a particular cluster of tags. We integrate our designed framework with various recommendation models, demonstrating its flexibility and compatibility. Through comparison with numerous SOTA methods on seven real-world datasets, we show that our method can achieve better performance while requiring less training time. This indicates the potential of applying our approach on web-scale datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "107747459",
                    "name": "Haolun Wu"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2109155646",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2151058626",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2150349871",
                    "name": "Mark Coates"
                }
            ]
        },
        {
            "paperId": "0c4b514700a638972378732fb291ca32b4849907",
            "title": "Hyperspherical Quantization: Toward Smaller and More Accurate Models",
            "abstract": "Model quantization enables the deployment of deep neural networks under resource-constrained devices. Vector quantization aims at reducing the model size by indexing model weights with full-precision embeddings, i.e., codewords, while the index needs to be restored to 32-bit during computation. Binary and other low-precision quantization methods can reduce the model size up to 32\u00d7, however, at the cost of a considerable accuracy drop. In this paper, we propose an efficient framework for ternary quantization to produce smaller and more accurate compressed models. By integrating hyperspherical learning, pruning and reinitialization, our proposed Hyperspherical Quantization (HQ) method reduces the cosine distance between the full-precision and ternary weights, thus reducing the bias of the straight-through gradient estimator during ternary quantization. Compared with existing work at similar compression levels (~30\u00d7, ~40\u00d7), our method significantly improves the test accuracy and reduces the model size.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146031949",
                    "name": "Dan Liu"
                },
                {
                    "authorId": "37866883",
                    "name": "X. Chen"
                },
                {
                    "authorId": "74142381",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "2151058626",
                    "name": "Xue Liu"
                }
            ]
        }
    ]
}