{
    "authorId": "2152845491",
    "papers": [
        {
            "paperId": "301a9a8dbc747b0868926dc29fe82db93652187b",
            "title": "Deep Unsupervised Momentum Contrastive Hashing for Cross-modal Retrieval",
            "abstract": "Unsupervised cross-modal hashing (UCMH) methods often start from the similarity of sample features and design a reconstruction loss to achieve similarity preservation. However, these methods suffer from inaccurate similarity problems, be-cause different feature representations may share similar semantic information. In this paper, we propose Deep Unsupervised Momentum Contrastive Hashing (DUMCH). Specifically, we introduce momentum contrastive learning for unsupervised cross-modal hashing, which allows us to flexibly define a robust loss by comparing positive and negative samples. Moreover, in order to achieve similarity retention of hash codes in Hamming space and fully utilize the potential of contrastive learning in Hamming space, we remove the L2 normalization corresponding to cosine similarity and design a novel normalization method called hash normalization, which has been proved to greatly improve the model performance. We conducted extensive experiments on three datasets, and the experimental results demonstrate the superiority of DUMCH.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9452979",
                    "name": "Kangkang Lu"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "50847093",
                    "name": "M. Liang"
                },
                {
                    "authorId": "2233606072",
                    "name": "Min Zhang"
                },
                {
                    "authorId": "2034186530",
                    "name": "Xiaowen Cao"
                },
                {
                    "authorId": "2202243345",
                    "name": "Zehua Zhao"
                },
                {
                    "authorId": "2184849566",
                    "name": "Mengran Yin"
                },
                {
                    "authorId": "2052285030",
                    "name": "Zhe Xue"
                }
            ]
        },
        {
            "paperId": "b6948df388eb9eb1d24c70be319dc95e3291458c",
            "title": "Intent-aware Recommendation via Disentangled Graph Contrastive Learning",
            "abstract": "Graph neural network (GNN) based recommender systems have become one of the mainstream trends due to the powerful learning ability from user behavior data. Understanding the user intents from behavior data is the key to recommender systems, which poses two basic requirements for GNN-based recommender systems. One is how to learn complex and diverse intents especially when the user behavior is usually inadequate in reality. The other is different behaviors have different intent distributions, so how to establish their relations for a more explainable recommender system. In this paper, we present the Intent-aware Recommendation via Disentangled Graph Contrastive Learning (IDCL), which simultaneously learns interpretable intents and behavior distributions over those intents. Specifically, we first model the user behavior data as a user-item-concept graph, and design a GNN based behavior disentangling module to learn the different intents. Then we propose the intent-wise contrastive learning to enhance the intent disentangling and meanwhile infer the behavior distributions. Finally, the coding rate reduction regularization is introduced to make the behaviors of different intents orthogonal. Extensive experiments demonstrate the effectiveness of IDCL in terms of substantial improvement and the interpretability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115664393",
                    "name": "Yuling Wang"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2760554",
                    "name": "Xiangzhou Huang"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "48985404",
                    "name": "Mengdi Zhang"
                },
                {
                    "authorId": "114361215",
                    "name": "Zirui Guo"
                },
                {
                    "authorId": "2118256000",
                    "name": "Wei Wu"
                }
            ]
        },
        {
            "paperId": "45fcf8b7528da3d0847de430742d339003fb0100",
            "title": "Automatic Graph Generation for Document-Level Relation Extraction",
            "abstract": "Relation extraction, one of important natural language processing tasks, aims to find out the semantic relations between entities in text. It has been raised to the document level recently, which is a complex task that requires a logical inference to extract relations from multiple entities in intra-and inter-sentence. Existing methods mainly utilize co-references or syntactic trees to establish static document-level graphs. Different from these heuristic models which may not always yield the optimal structures, we propose a novel model that can automatically construct task-specific graphs. We regard the process of establishing a graph as a sequence problem and utilize a gated recurrent unit (GRU) recurrent neural networks (RNNs) to construct a document graph. Afterwards, we utilize the graph convolutional networks (GCNs) to calculate the node representation. Particularly, our model exhibits comparable performance to state-of-the-art models on the large-scale human annotated document-level relation extraction dataset (DocRED).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "2186559086",
                    "name": "Fangting Shen"
                },
                {
                    "authorId": "2161014609",
                    "name": "Shengli Yang"
                },
                {
                    "authorId": "2155870582",
                    "name": "Jie Li"
                },
                {
                    "authorId": "2115664393",
                    "name": "Yuling Wang"
                },
                {
                    "authorId": "2186558116",
                    "name": "Ang Ma"
                }
            ]
        },
        {
            "paperId": "18c93bd633e8746287a1c9d91c0dd4619dd4ac0d",
            "title": "3R: Reading - Ranking - Recognizing for Multi- Passage Reading Comprehension",
            "abstract": "multi-passage reading comprehension aims to answer questions about a set of passages. The current models include selecting the most related passage for reading using reinforcement learning or using all passages for reading and then re-ranking answer candidates. But these models can\u2019t deal with some noise passages properly. Besides, the answer ranking methods cannot take all valuable information into consideration. So, we propose to select all informative passages, then reading these passages to extract answer candidates, finally re-ranking these answer candidates so that the top ranked answer candidate is the best answer. In the answer re-ranker module, we consider both answer-to-answer verify and question-to-answer verify. Also, we add a no answer recognition section to detect no answer cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143719070",
                    "name": "Jin Wang"
                },
                {
                    "authorId": "2145973815",
                    "name": "Yan Gao"
                },
                {
                    "authorId": "2155870582",
                    "name": "Jie Li"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "1707937",
                    "name": "Binyang Li"
                }
            ]
        },
        {
            "paperId": "d71d9225c319c44fb14377f1ecd75a04574eb1e1",
            "title": "Residuals-based deep least square support vector machine with redundancy test based model selection to predict time series",
            "abstract": ": In this paper, we propose a novel Residuals-Based Deep Least Squares Support Vector Machine (RBD-LSSVM). In the RBD-LSSVM, multiple LSSVMs are sequentially connected. The second LSSVM uses the \ufb01tting residuals of the \ufb01rst LSSVM as input time series, and the third LSSVM trains the residuals of the second, and so on. The original time series is the input of the \ufb01rst LSSVM. Additionally, to obtain the best hyper-parameters for the RBD-LSSVM, we propose a model validation method based on redundancy test using Omni-Directional Correlation Function (ODCF). This method is based on the fact when a model is appropriate for a given time series, there should be no information or correlation in the residuals. We propose the use of ODCF as a statistic to detect nonlinear correlation between two random variables. Thus, we can select hyper-parameters without encountering over\ufb01tting, which cannot be avoided by only cross validation using the validation set. We conducted experiments on two time series: annual sunspot number series and monthly Total Column Ozone (TCO) series in New Delhi. Analysis of the prediction results and comparisons with recent and past studies demonstrate the promising performance of the proposed RBD-LSSVM approach with redundancy test based model selection method for modeling and predicting nonlinear time series.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "2155870582",
                    "name": "Jie Li"
                }
            ]
        },
        {
            "paperId": "038c0b12f4e35042bc983d15987b2afece35b603",
            "title": "Network Intrusion Detection Based on Stacked Sparse Autoencoder and Binary Tree Ensemble Method",
            "abstract": "With the increasing of network attacks, the traditional machine learning method can not solve the classification problem of massive intrusion data effectively. This paper proposes a Xgboost based on stacked sparse autoencoder network(SSAE-XGB) method to learn latent representation of original data. Due to inconsistent category distribution of training and test dataset, we use the sparsity constraint to enhance the generalization ability of the model. Stacked sparse autoencoder network is employed to reduce the dimension of high-dimensional and unlabeled original data, so as to obtain the deep feature representation of the original data. Due to the class imbalance of intrusion data, this paper proposes a novel hybrid classifier, which is constructed by using binary tree and ensemble method. Our experiments with all NSL-KDD dataset demonstrate that our proposed SSAE-XGB binary tree and ensemble method can achieve incredibly high performance in terms of F1 and it outperforms the previous work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118875770",
                    "name": "Baoan Zhang"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "2155870582",
                    "name": "Jie Li"
                }
            ]
        },
        {
            "paperId": "5eecfd8a9a7032d5a404d282362c4518b35ef3c8",
            "title": "Linguistic attention-based model for aspect extraction",
            "abstract": "Aspect extraction plays an important role in aspect-level sentiment analysis. Most existing approaches focus on explicit aspect extraction and either seriously rely on syntactic rules or only make use of neural network without linguistic knowledge. This paper proposes a linguistic attention-based model (LABM) to implement explicit and implicit aspect extraction together. The linguistic attention mechanism incorporates the knowledge of linguistics which has proven to be very useful in aspect extraction. We also propose a novel unsupervised training approach, distributed aspect learning (DAL), the core idea of DAL is that the aspect vector should align closely to the neural word embeddings of nouns which are tightly associated with the valid aspect indicators. Experimental results using six datasets demonstrate that our model is explainable and outperforms baseline models on evaluation tasks.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "24780166",
                    "name": "Yunjie Ji"
                },
                {
                    "authorId": "2155870582",
                    "name": "Jie Li"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                }
            ]
        },
        {
            "paperId": "2d5dfc234a6d11e1dcf434cffc6991424c25ef2c",
            "title": "WSpCPs: Weighted sequential pattern mining based on cluster-pruning mechanism",
            "abstract": "One of the major important problems in sequential pattern mining is the explosion of the number of results. To solve this problem, a new algorithm, called weighted sequential pattern mining based on cluster-pruning strategy (WSpCPs), is proposed in this paper. The purpose of our algorithm is to select some high-quality sequences that describe the full result. It utilizes I-step and S-step operations to generate new sequences and their bitmaps in iterative process. WSpCPs proposes cluster-pruning strategy to select sequences from the full result. Experiments show that WSpCPs is an efficient method to reduce the number of result.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118638308",
                    "name": "Yu Fu"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "1701530",
                    "name": "Meina Song"
                }
            ]
        },
        {
            "paperId": "6557e94ef5cb9242e497d41cb6e7ea7e250d511b",
            "title": "Traffic prediction in 3G mobile networks based on multifractal exploration",
            "abstract": "Traffic prediction plays an integral role in telecommunication network planning and network optimization. In this paper, we investigate the traffic forecasting for data services in 3G mobile networks. Although the Box-Jenkins model has been proven to be appropriate for voice traffic (since the arrival of calls follows a Poisson distribution), it has been demonstrated that the Internet traffic exhibits statistical self-similarity and has to be modeled using the Fractional AutoRegressive Integrated Moving Average (FARIMA) process. However, a few studies have concluded that the FARIMA process may fail in modeling the Internet traffic. To this end, we conducted experiments on the modeling of benchmark Internet traffic and found that the FARIMA process fails because of the significant multifractal characteristic inherent in the traffic series. Thereafter, we investigate the traffic series of data services in a 3G mobile network from a province in China. Rich multifractal spectra are found in this series. Based on this observation, an integrated method combining the AutoRegressive Moving Average (ARMA) and FARIMA processes is applied. The obtained experimental results verify the effectiveness of the integrated prediction method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "1701530",
                    "name": "Meina Song"
                },
                {
                    "authorId": "2118638308",
                    "name": "Yu Fu"
                },
                {
                    "authorId": "1804427",
                    "name": "Junde Song"
                }
            ]
        },
        {
            "paperId": "90b28b4570fa156011ab66c931fe35f11aa21db4",
            "title": "Soft-CsGDT: soft cost-sensitive Gaussian decision tree for cost-sensitive classification of data streams",
            "abstract": "Nowadays in many real-world scenarios, high speed data streams are usually with non-uniform misclassification costs and thus call for cost-sensitive classification algorithms of data streams. However, only little literature focuses on this issue. On the other hand, the existing algorithms for cost-sensitive classification can achieve excellent performance in the metric of total misclassification costs, but always lead to obvious reduction of accuracy, which restrains the practical application greatly. In this paper, we present an improved folk theorem. Based on the new theorem, the existing accuracy-based classification algorithm can be converted into soft cost-sensitive one immediately, which allows us to take both accuracy and cost into account. Following the idea of this theorem, the soft-CsGDT algorithm is proposed to process the data streams with non-uniform misclassification costs, which is an expansion of GDT. With both synthetic and real-world datasets, the experimental results show that compared with the cost-sensitive algorithm, the accuracy in our soft-CsGDT is significantly improved, while the total misclassification costs are approximately the same.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112461062",
                    "name": "Ning Guo"
                },
                {
                    "authorId": "2152845491",
                    "name": "Yanhua Yu"
                },
                {
                    "authorId": "1701530",
                    "name": "Meina Song"
                },
                {
                    "authorId": "1804427",
                    "name": "Junde Song"
                },
                {
                    "authorId": "2118638308",
                    "name": "Yu Fu"
                }
            ]
        }
    ]
}