{
    "authorId": "2163436495",
    "papers": [
        {
            "paperId": "5e159c0f1f56ebc51e8d44c18cf579a891ef1c5f",
            "title": "Unsupervised Deep Learning for IoT Time Series",
            "abstract": "Internet of Things (IoT) time-series analysis has found numerous applications in a wide variety of areas, ranging from health informatics to network security. Nevertheless, the complex spatial\u2013temporal dynamics and high dimensionality of IoT time series make the analysis increasingly challenging. In recent years, the powerful feature extraction and representation learning capabilities of deep learning (DL) have provided an effective means for IoT time-series analysis. However, few existing surveys on time series have systematically discussed unsupervised DL-based methods. To fill this void, we investigate unsupervised DL for IoT time series, i.e., unsupervised anomaly detection and clustering, under a unified framework. We also discuss the application scenarios, public data sets, existing challenges, and future research directions in this area.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2144468029",
                    "name": "Ya Liu"
                },
                {
                    "authorId": "2118860403",
                    "name": "Ying Zhou"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "47119537",
                    "name": "X. Wang"
                }
            ]
        },
        {
            "paperId": "5f5811fc2d8af1509dd7a7f9b3cea4597e15048b",
            "title": "Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks",
            "abstract": "Several approximate inference methods have been proposed for deep discrete latent variable models. However, non-parametric methods which have previously been successfully employed for classical sparse coding models have largely been unexplored in the context of deep models. We propose a non-parametric iterative algorithm for learning discrete latent representations in such deep models. Additionally, to learn scale invariant discrete features, we propose local data scaling variables. Lastly, to encourage sparsity in our representations, we propose a Beta-Bernoulli process prior on the latent factors. We evaluate our spare coding model coupled with different likelihood models. We evaluate our method across datasets with varying characteristics and compare our results to current amortized approximate inference methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "4125365",
                    "name": "Arunesh Mittal"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "1812793",
                    "name": "P. Sajda"
                },
                {
                    "authorId": "143855009",
                    "name": "J. Paisley"
                }
            ]
        },
        {
            "paperId": "f81ea4626d83adcdaa9c1a9955d0be962457e0f4",
            "title": "Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis",
            "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "2c5f6080a69efe76cf56d225808324fb5b692c1b",
            "title": "Asynchronous Distributed Bilevel Optimization",
            "abstract": "Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches require collecting massive amount of data to a single server, which inevitably incur significant communication expenses and may give rise to data privacy risks. Synchronous distributed bilevel optimization algorithms, on the other hand, often face the straggler problem and will immediately stop working if a few workers fail to respond. As a remedy, we propose Asynchronous Distributed Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel optimization problems with both nonconvex upper-level and lower-level objective functions, and its convergence is theoretically guaranteed. Furthermore, it is revealed through theoretic analysis that the iteration complexity of ADBO to obtain the $\\epsilon$-stationary point is upper bounded by $\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public datasets have been conducted to elucidate the effectiveness and efficiency of the proposed ADBO.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2142035704",
                    "name": "Chen Jian"
                }
            ]
        },
        {
            "paperId": "404e862cc02b9024b40bfe059439299d0a239f98",
            "title": "Task-aware Similarity Learning for Event-triggered Time Series",
            "abstract": "\u2014Time series analysis has achieved great success in diverse applications such as network security, environmental monitoring, and medical informatics. Learning similarities among different time series is a crucial problem since it serves as the foundation for downstream analysis such as clustering and anomaly detection. It often remains unclear what kind of distance metric is suitable for similarity learning due to the complex temporal dynamics of the time series generated from event-triggered sensing, which is common in diverse applications, including automated driving, interactive healthcare, and smart home automation. The overarching goal of this paper is to develop an unsupervised learning framework that is capable of learning task-aware similarities among unlabeled event-triggered time series. From the machine learning vantage point, the proposed framework harnesses the power of both hierarchical multi-scale sequence autoencoders and Gaussian Mixture Model (GMM) to effectively learn the low-dimensional representations from the time series. Finally, the obtained similarity measure can be easily visualized for explaining. The proposed framework aspires to offer a stepping stone that gives rise to a systematic approach to model and learn similarities among a multitude of event-triggered time series. Through extensive qualitative and quantitative experiments, it is revealed that the proposed method outperforms state-of-the-art methods considerably.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10675825",
                    "name": "Shaoyu Dou"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": null,
                    "name": "Chengbo Qiu"
                },
                {
                    "authorId": "2145257973",
                    "name": "Kui Ren"
                }
            ]
        },
        {
            "paperId": "4bacb656077a138df6b79c5b846b9afd7cace141",
            "title": "AI Empowered Net-RCA for 6G",
            "abstract": "6G is envisioned to offer higher data rate, improved reliability, ubiquitous AI services, and support massive scale of connected devices. As a consequence, 6G will be much more complex than its predecessors. The growth of the system scale and complexity as well as the coexistence with the legacy networks and the diversified service requirements will inevitably incur huge maintenance cost and efforts for future 6G networks. Network Root Cause Analysis (Net-RCA) plays a critical role in identifying root causes of network faults. In this article, we first give an introduction about the envisioned 6G networks. Next, we discuss the challenges and potential solutions of 6G network operation and management, and comprehensively survey existing RCA methods. Then we propose an artificial intelligence (AI)-empowered Net-RCA framework for 6G. Performance comparisons on both synthetic and real-world network data are carried out to demonstrate that the proposed method outperforms the existing method considerably.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31667436",
                    "name": "C. Qiu"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2190585011",
                    "name": "Ji Wang"
                },
                {
                    "authorId": "2143590599",
                    "name": "Shenjie Zhao"
                }
            ]
        },
        {
            "paperId": "78dfc9800a537f0a1bc9c717f73b917e97603484",
            "title": "Distributed Distributionally Robust Optimization with Non-Convex Objectives",
            "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the distributed distributionally robust optimization (DDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                }
            ]
        }
    ]
}