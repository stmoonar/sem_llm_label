{
    "authorId": "28075447",
    "papers": [
        {
            "paperId": "10c17afcd6f77c29250b8f0a7ebddd403eb6814e",
            "title": "Evaluating AI Group Fairness: a Fuzzy Logic Perspective",
            "abstract": "Artificial intelligence systems often address fairness concerns by evaluating and mitigating measures of group discrimination, for example that indicate biases against certain genders or races. However, what constitutes group fairness depends on who is asked and the social context, whereas definitions are often relaxed to accept small deviations from the statistical constraints they set out to impose. Here we decouple definitions of group fairness both from the context and from relaxation-related uncertainty by expressing them in the axiomatic system of Basic fuzzy Logic (BL) with loosely understood predicates, like encountering group members. We then evaluate the definitions in subclasses of BL, such as Product or Lukasiewicz logics. Evaluation produces continuous instead of binary truth values by choosing the logic subclass and truth values for predicates that reflect uncertain context-specific beliefs, such as stakeholder opinions gathered through questionnaires. Internally, it follows logic-specific rules to compute the truth values of definitions. We show that commonly held propositions standardize the resulting mathematical formulas and we transcribe logic and truth value choices to layperson terms, so that anyone can answer them. We also use our framework to study several literature definitions of algorithmic fairness, for which we rationalize previous expedient practices that are non-probabilistic and show how to re-interpret their formulas and parameters in new contexts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "2276779989",
                    "name": "Symeon Papadopoulos"
                }
            ]
        },
        {
            "paperId": "ad6c86f56d30933a577c5a515fc114c06cd42dcf",
            "title": "Towards Standardizing AI Bias Exploration",
            "abstract": "Creating fair AI systems is a complex problem that involves the assessment of context-dependent bias concerns. Existing research and programming libraries express specific concerns as measures of bias that they aim to constrain or mitigate. In practice, one should explore a wide variety of (sometimes incompatible) measures before deciding which ones warrant corrective action, but their narrow scope means that most new situations can only be examined after devising new measures. In this work, we present a mathematical framework that distils literature measures of bias into building blocks, hereby facilitating new combinations to cover a wide range of fairness concerns, such as classification or recommendation differences across multiple multi-value sensitive attributes (e.g., many genders and races, and their intersections). We show how this framework generalizes existing concepts and present frequently used blocks. We provide an open-source implementation of our framework as a Python library, called FairBench, that facilitates systematic and extensible exploration of potential bias concerns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "2276779989",
                    "name": "Symeon Papadopoulos"
                }
            ]
        },
        {
            "paperId": "cca4cdf0897944c45a65c771dfe3f138a63ba630",
            "title": "Graph Neural Network Surrogates of Fair Graph Filtering",
            "abstract": "Graph filters that transform prior node values to posterior scores via edge propagation often support graph mining tasks affecting humans, such as recommendation and ranking. Thus, it is important to make them fair in terms of satisfying statistical parity constraints between groups of nodes (e.g., distribute score mass between genders proportionally to their representation). To achieve this while minimally perturbing the original posteriors, we introduce a filter-aware universal approximation framework for posterior objectives. This defines appropriate graph neural networks trained at runtime to be similar to filters but also locally optimize a large class of objectives, including fairness-aware ones. Experiments on a collection of 8 filters and 5 graphs show that our approach performs equally well or better than alternatives in meeting parity constraints while preserving the AUC of score-based community member recommendation and creating minimal utility loss in prior diffusion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                }
            ]
        },
        {
            "paperId": "369c33aab01f685df3776b838e4a410e503215b6",
            "title": "A Graph Diffusion Scheme for Decentralized Content Search based on Personalized PageRank",
            "abstract": "Decentralization is emerging as a key feature of the future Internet. However, effective algorithms for search are missing from state-of-the-art decentralized technologies, such as distributed hash tables and blockchain. This is surprising, since decentralized search has been studied extensively in earlier peer- to-peer (P2P) literature. In this work, we adopt a fresh outlook for decentralized search in P2P networks that is inspired by advancements in dense information retrieval and graph signal processing. In particular, we generate latent representations of P2P nodes based on their stored documents and diffuse them to the rest of the network with graph filters, such as person-alized PageRank. We then use the diffused representations to guide search queries towards relevant content. Our preliminary approach is successful in locating relevant documents in nearby nodes but the accuracy declines sharply with the number of stored documents, highlighting the need for more sophisticated techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8084337",
                    "name": "Nikolaos Giatsoglou"
                },
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "1715604",
                    "name": "Y. Kompatsiaris"
                }
            ]
        },
        {
            "paperId": "fd5e08d0599df9fcdbaf8c4ddcd96ac5f7ae6517",
            "title": "Fast Library Recommendation in Software Dependency Graphs with Symmetric Partially Absorbing Random Walks",
            "abstract": "To help developers discover libraries suited to their software projects, automated approaches often start from already employed libraries and recommend more based on co-occurrence patterns in other projects. The most accurate project\u2013library recommendation systems employ Graph Neural Networks (GNNs) that learn latent node representations for link prediction. However, GNNs need to be retrained when dependency graphs are updated, for example, to recommend libraries for new projects, and are thus unwieldy for scalable deployment. To avoid retraining, we propose that recommendations can instead be performed with graph filters; by analyzing dependency graph dynamics emulating human-driven library discovery, we identify low-pass filtering with memory as a promising direction and introduce a novel filter, called symmetric partially absorbing random walks, which infers rather than trains the parameters of filters with node-specific memory to guarantee low-pass filtering. Experiments on a dependency graph between Android projects and third-party libraries show that our approach makes recommendations with a quality and diversification loosely comparable to those state-of-the-art GNNs without computationally intensive retraining for new predictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "145937532",
                    "name": "A. Symeonidis"
                }
            ]
        },
        {
            "paperId": "575f8c13ecff9ca415230a338f3c8ff9677f368d",
            "title": "Prior Signal Editing for Graph Filter Posterior Fairness Constraints",
            "abstract": "Graph filters are an emerging paradigm that systematizes information propagation in graphs as transformation of prior node values, called graph signals, to posterior scores. In this work, we study the problem of mitigating disparate impact, i.e. posterior score differences between a protected set of sensitive nodes and the rest, while minimally editing scores to preserve recommendation quality. To this end, we develop a scheme that respects propagation mechanisms by editing graph signal priors according to their posteriors and node sensitivity, where a small number of editing parameters can be tuned to constrain or eliminate disparate impact. We also theoretically explain that coarse prior editing can locally optimize posteriors objectives thanks to graph filter robustness. We experiment on a diverse collection of 12 graphs with varying number of nodes, where our approach performs equally well or better than previous ones in minimizing disparate impact and preserving posterior AUC under fairness constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "1715604",
                    "name": "Y. Kompatsiaris"
                },
                {
                    "authorId": "145937532",
                    "name": "A. Symeonidis"
                }
            ]
        },
        {
            "paperId": "b0f5a538a7a08f82a53c1b2618a0ee0e44939cd3",
            "title": "p2pGNN: A Decentralized Graph Neural Network for Node Classification in Peer-to-Peer Networks",
            "abstract": "In this work, we aim to classify nodes of unstructured peer-to-peer networks with communication uncertainty, such as users of decentralized social networks. Graph Neural Networks (GNNs) are known to improve the accuracy of simple classifiers in centralized settings by leveraging naturally occurring network links, but graph convolutional layers are challenging to implement in decentralized settings when node neighbors are not constantly available. We address this problem by employing decoupled GNNs, where base classifier predictions and errors are diffused through graphs after training. For these, we deploy pre-trained and gossip-trained base classifiers and implement peer-to-peer graph diffusion under communication uncertainty. In particular, we develop an asynchronous decentralized formulation of diffusion that converges to centralized predictions in distribution and linearly with respect to communication rates. We experiment on three real-world graphs with node features and labels and simulate peer-to-peer networks with uniformly random communication frequencies; given a portion of known labels, our decentralized graph diffusion achieves comparable accuracy to centralized GNNs with minimal communication overhead (less than 3% of what gossip training already adds).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "119661806",
                    "name": "I. Kompatsiaris"
                }
            ]
        },
        {
            "paperId": "17f423a5e542a4bd4de0243548e127038dea6ab5",
            "title": "Bias in data\u2010driven artificial intelligence systems\u2014An introductory survey",
            "abstract": "Artificial Intelligence (AI)\u2010based systems are widely employed nowadays to make decisions that have far\u2010reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well\u2010grounded in a legal frame. In this survey, we focus on data\u2010driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1804618",
                    "name": "Eirini Ntoutsi"
                },
                {
                    "authorId": "2393008",
                    "name": "P. Fafalios"
                },
                {
                    "authorId": "2516584",
                    "name": "U. Gadiraju"
                },
                {
                    "authorId": "3176896",
                    "name": "Vasileios Iosifidis"
                },
                {
                    "authorId": "1744808",
                    "name": "W. Nejdl"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "1707206",
                    "name": "F. Turini"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "119661806",
                    "name": "I. Kompatsiaris"
                },
                {
                    "authorId": "1404596968",
                    "name": "K. Kinder-Kurlanda"
                },
                {
                    "authorId": "144065562",
                    "name": "Claudia Wagner"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "145842687",
                    "name": "Harith Alani"
                },
                {
                    "authorId": "2990203",
                    "name": "Bettina Berendt"
                },
                {
                    "authorId": "3144221",
                    "name": "Tina Kruegel"
                },
                {
                    "authorId": "49729602",
                    "name": "C. Heinze"
                },
                {
                    "authorId": "2102011",
                    "name": "Klaus Broelemann"
                },
                {
                    "authorId": "1686448",
                    "name": "Gjergji Kasneci"
                },
                {
                    "authorId": "1726746",
                    "name": "T. Tiropanis"
                },
                {
                    "authorId": "1752093",
                    "name": "Steffen Staab"
                }
            ]
        },
        {
            "paperId": "711a53fc3e7adab45d5f3b301e0f8d5be24d2f4e",
            "title": "Stopping Personalized PageRank without an Error Tolerance Parameter",
            "abstract": "Personalized PageRank (PPR) is a popular scheme for scoring the relevance of network nodes to a set of seed ones through a random walk with restart process. Calculating the scores of all network nodes often involves the power method, which iterates the PPR formula until convergence to an empirically selected numerical tolerance. However, finding a tolerance that is not so lax as to impact pairwise node comparisons but not so strict as to require a high number of iterations to converge requires time-consuming empirical investigation. In this work we aim to avoid this investigation by stopping power method iterations when node score order is robust against subsequent changes. To do this, we analyse the expected fraction of random walks considered at a given iteration and identify a potential stopping point that depends on a (fixed) confidence level of future iterations preserving node order. Experiments on four real-world networks show that a confidence level of 98% runs in a fraction of the time and yields more than 0.999 Spearman correlation with the node order of 10\u221220 numerical tolerance. Furthermore, that stopping point is comparable to empirically selecting a numerical tolerance that yields robust node order.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "1715604",
                    "name": "Y. Kompatsiaris"
                }
            ]
        },
        {
            "paperId": "8de3c0d82673657e39aeefef589c4a06b45d4ae1",
            "title": "Bias in Data-driven AI Systems - An Introductory Survey",
            "abstract": "AI-based systems are widely employed nowadays to make decisions that have far-reaching impacts on individuals and society. Their decisions might affect everyone, everywhere and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multi-disciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well-grounded in a legal frame. In this survey, we focus on data-driven AI, as a large part of AI is powered nowadays by (big) data and powerful Machine Learning (ML) algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features like race, sex, etc.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1804618",
                    "name": "Eirini Ntoutsi"
                },
                {
                    "authorId": "2393008",
                    "name": "P. Fafalios"
                },
                {
                    "authorId": "2516584",
                    "name": "U. Gadiraju"
                },
                {
                    "authorId": "3176896",
                    "name": "Vasileios Iosifidis"
                },
                {
                    "authorId": "1744808",
                    "name": "W. Nejdl"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "1707206",
                    "name": "F. Turini"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "119661806",
                    "name": "I. Kompatsiaris"
                },
                {
                    "authorId": "1404596968",
                    "name": "K. Kinder-Kurlanda"
                },
                {
                    "authorId": "144065562",
                    "name": "Claudia Wagner"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "145842687",
                    "name": "Harith Alani"
                },
                {
                    "authorId": "2990203",
                    "name": "Bettina Berendt"
                },
                {
                    "authorId": "3144221",
                    "name": "Tina Kruegel"
                },
                {
                    "authorId": "49729602",
                    "name": "C. Heinze"
                },
                {
                    "authorId": "2102011",
                    "name": "Klaus Broelemann"
                },
                {
                    "authorId": "1686448",
                    "name": "Gjergji Kasneci"
                },
                {
                    "authorId": "1726746",
                    "name": "T. Tiropanis"
                },
                {
                    "authorId": "1752093",
                    "name": "Steffen Staab"
                }
            ]
        }
    ]
}