{
    "authorId": "1523619467",
    "papers": [
        {
            "paperId": "87ec5cd167e972b3352d06eada73ef2acb1b7e74",
            "title": "Exploring Language Model's Code Generation Ability with Auxiliary Functions",
            "abstract": "Auxiliary function is a helpful component to improve language model's code generation ability. However, a systematic exploration of how they affect has yet to be done. In this work, we comprehensively evaluate the ability to utilize auxiliary functions encoded in recent code-pretrained language models. First, we construct a human-crafted evaluation set, called HumanExtension, which contains examples of two functions where one function assists the other. With HumanExtension, we design several experiments to examine their ability in a multifaceted way. Our evaluation processes enable a comprehensive understanding of including auxiliary functions in the prompt in terms of effectiveness and robustness. An additional implementation style analysis captures the models' various implementation patterns when they access the auxiliary function. Through this analysis, we discover the models' promising ability to utilize auxiliary functions including their self-improving behavior by implementing the two functions step-by-step. However, our analysis also reveals the model's underutilized behavior to call the auxiliary function, suggesting the future direction to enhance their implementation by eliciting the auxiliary function call ability encoded in the models. We release our code and dataset to facilitate this research direction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287842444",
                    "name": "Seonghyeon Lee"
                },
                {
                    "authorId": "2287988207",
                    "name": "Sanghwan Jang"
                },
                {
                    "authorId": "1523619467",
                    "name": "Seongbo Jang"
                },
                {
                    "authorId": "3067773",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2286165699",
                    "name": "Hwanjo Yu"
                }
            ]
        },
        {
            "paperId": "a23599aef366be9492e924a2861dc381fed048af",
            "title": "KoDialogBench: Evaluating Conversational Understanding of Language Models with Korean Dialogue Benchmark",
            "abstract": "As language models are often deployed as chatbot assistants, it becomes a virtue for models to engage in conversations in a user\u2019s first language. While these models are trained on a wide range of languages, a comprehensive evaluation of their proficiency in low-resource languages such as Korean has been lacking. In this work, we introduce KoDialogBench, a benchmark designed to assess language models\u2019 conversational capabilities in Korean. To this end, we collect native Korean dialogues on daily topics from public sources, or translate dialogues from other languages. We then structure these conversations into diverse test datasets, spanning from dialogue comprehension to response selection tasks. Leveraging the proposed benchmark, we conduct extensive evaluations and analyses of various language models to measure a foundational understanding of Korean dialogues. Experimental results indicate that there exists significant room for improvement in models\u2019 conversation skills. Furthermore, our in-depth comparisons across different language models highlight the effectiveness of recent training techniques in enhancing conversational proficiency. We anticipate that KoDialogBench will promote the progress towards conversation-aware Korean language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1523619467",
                    "name": "Seongbo Jang"
                },
                {
                    "authorId": "2287842444",
                    "name": "Seonghyeon Lee"
                },
                {
                    "authorId": "2286165699",
                    "name": "Hwanjo Yu"
                }
            ]
        },
        {
            "paperId": "e5872aa1bb24ee3497d233f9f242d1f1fd888431",
            "title": "Toward Interpretable Semantic Textual Similarity via Optimal Transport-based Contrastive Sentence Learning",
            "abstract": "Recently, finetuning a pretrained language model to capture the similarity between sentence embeddings has shown the state-of-the-art performance on the semantic textual similarity (STS) task. However, the absence of an interpretation method for the sentence similarity makes it difficult to explain the model output. In this work, we explicitly describe the sentence distance as the weighted sum of contextualized token distances on the basis of a transportation problem, and then present the optimal transport-based distance measure, named RCMD; it identifies and leverages semantically-aligned token pairs. In the end, we propose CLRCMD, a contrastive learning framework that optimizes RCMD of sentence pairs, which enhances the quality of sentence similarity and their interpretation. Extensive experiments demonstrate that our learning framework outperforms other baselines on both STS and interpretable-STS benchmarks, indicating that it computes effective sentence similarity and also provides interpretation consistent with human judgement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72490748",
                    "name": "Seonghyeon Lee"
                },
                {
                    "authorId": "3067773",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "1523619467",
                    "name": "Seongbo Jang"
                },
                {
                    "authorId": "1723357",
                    "name": "Hwanjo Yu"
                }
            ]
        },
        {
            "paperId": "28459083ba624020c8f1c1ed7c3a075f48b4e709",
            "title": "KLUE: Korean Language Understanding Evaluation",
            "abstract": "We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE is a collection of 8 Korean natural language understanding (NLU) tasks, including Topic Classification, SemanticTextual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking. We build all of the tasks from scratch from diverse source corpora while respecting copyrights, to ensure accessibility for anyone without any restrictions. With ethical considerations in mind, we carefully design annotation protocols. Along with the benchmark tasks and data, we provide suitable evaluation metrics and fine-tuning recipes for pretrained language models for each task. We furthermore release the pretrained language models (PLM), KLUE-BERT and KLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby facilitate future research. We make a few interesting observations from the preliminary experiments using the proposed KLUE benchmark suite, already demonstrating the usefulness of this new benchmark suite. First, we find KLUE-RoBERTa-large outperforms other baselines, including multilingual PLMs and existing open-source Korean PLMs. Second, we see minimal degradation in performance even when we replace personally identifiable information from the pretraining corpus, suggesting that privacy and NLU capability are not at odds with each other. Lastly, we find that using BPE tokenization in combination with morpheme-level pre-tokenization is effective in tasks involving morpheme-level tagging, detection and generation. In addition to accelerating Korean NLP research, our comprehensive documentation on creating KLUE will facilitate creating similar resources for other languages in the future. KLUE is available at https://klue-benchmark.com.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9149651",
                    "name": "Sungjoon Park"
                },
                {
                    "authorId": "2105675738",
                    "name": "Jihyung Moon"
                },
                {
                    "authorId": "2829848",
                    "name": "Sungdong Kim"
                },
                {
                    "authorId": "153091253",
                    "name": "Won Ik Cho"
                },
                {
                    "authorId": "50201607",
                    "name": "Jiyoon Han"
                },
                {
                    "authorId": "2116003711",
                    "name": "Jangwon Park"
                },
                {
                    "authorId": "2116334796",
                    "name": "Chisung Song"
                },
                {
                    "authorId": "2109985113",
                    "name": "Junseong Kim"
                },
                {
                    "authorId": "2115417555",
                    "name": "Yongsook Song"
                },
                {
                    "authorId": "153055843",
                    "name": "Tae Hwan Oh"
                },
                {
                    "authorId": "2051569523",
                    "name": "Joohong Lee"
                },
                {
                    "authorId": "2110912827",
                    "name": "Juhyun Oh"
                },
                {
                    "authorId": "34915449",
                    "name": "Sungwon Lyu"
                },
                {
                    "authorId": "97503202",
                    "name": "Young-kuk Jeong"
                },
                {
                    "authorId": "2152635849",
                    "name": "I. Lee"
                },
                {
                    "authorId": "102994350",
                    "name": "Sang-gyu Seo"
                },
                {
                    "authorId": null,
                    "name": "Dongjun Lee"
                },
                {
                    "authorId": "32609381",
                    "name": "Hyunwoo Kim"
                },
                {
                    "authorId": "2108893124",
                    "name": "Myeonghwa Lee"
                },
                {
                    "authorId": "1523619467",
                    "name": "Seongbo Jang"
                },
                {
                    "authorId": "2072457550",
                    "name": "Seungwon Do"
                },
                {
                    "authorId": "36781770",
                    "name": "SunKyoung Kim"
                },
                {
                    "authorId": "145893361",
                    "name": "Kyungtae Lim"
                },
                {
                    "authorId": "2146049341",
                    "name": "Jongwon Lee"
                },
                {
                    "authorId": "2152042873",
                    "name": "Kyumin Park"
                },
                {
                    "authorId": "51228826",
                    "name": "Jamin Shin"
                },
                {
                    "authorId": "2143060005",
                    "name": "Seonghyun Kim"
                },
                {
                    "authorId": "2059041395",
                    "name": "Lucy Park"
                },
                {
                    "authorId": "2463290",
                    "name": "Alice H. Oh"
                },
                {
                    "authorId": "2577039",
                    "name": "Jung-Woo Ha"
                },
                {
                    "authorId": "2111049203",
                    "name": "Kyunghyun Cho"
                }
            ]
        },
        {
            "paperId": "68f2d74f82ec544433f3936dbbf6b6f5255fee10",
            "title": "An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks",
            "abstract": "Typically, tokenization is the very first step in most text processing works. As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model. Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks. In this paper, we test several tokenization strategies in order to answer our primary research question, that is, \u201cWhat is the best tokenization strategy for Korean NLP tasks?\u201d Experimental results demonstrate that a hybrid approach of morphological segmentation followed by BPE works best in Korean to/from English machine translation and natural language understanding tasks such as KorNLI, KorSTS, NSMC, and PAWS-X. As an exception, for KorQuAD, the Korean extension of SQuAD, BPE segmentation turns out to be the most effective. Our code and pre-trained models are publicly available at https://github.com/kakaobrain/kortok.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51268566",
                    "name": "Kyubyong Park"
                },
                {
                    "authorId": "2051569523",
                    "name": "Joohong Lee"
                },
                {
                    "authorId": "1523619467",
                    "name": "Seongbo Jang"
                },
                {
                    "authorId": "2082603145",
                    "name": "Dawoon Jung"
                }
            ]
        }
    ]
}