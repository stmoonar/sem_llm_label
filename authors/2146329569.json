{
    "authorId": "2146329569",
    "papers": [
        {
            "paperId": "86b89c788d749ea3eea0267c8f4d84ed9cff0c9f",
            "title": "Incorporating Least-Effort Loss to Stabilize Training of Wasserstein GAN",
            "abstract": "In order to further improve the convergence properties of generative adversarial networks, in this paper, we analyze how the stability can be affected by the so-called best-effort manner of the discriminator in the minimax game. We point out that this manner can cause the multistate problem and the optimization entangling problem. To alleviate these, we proposed an alternative least-effort loss to regularize the training behaviors of the discriminator. With this loss, the discriminator only updates when it is unable to distinguish distributions. To evaluate the effectiveness of the least-effort loss, we introduce it into Wasserstein GAN. Experiments on Dirac delta distribution and image datasets demonstrate that the least-effort loss can effectively improve the convergence properties and generation quality of WGAN. Furthermore, the behaviors of the discriminator and generator during the training show that, with the least-effort loss, the state space of the discriminator shrinks, and the optimization of the discriminator and the generator disentangles in some way.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146329569",
                    "name": "Fanqi Li"
                },
                {
                    "authorId": "46660076",
                    "name": "L. Wang"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2181685915",
                    "name": "Pengwei Guan"
                }
            ]
        },
        {
            "paperId": "7102417cddf26d581591780aaa2f2066cb282ad9",
            "title": "Solid Texture Synthesis using Generative Adversarial Networks",
            "abstract": "Solid texture synthesis (STS), as an effective way to extend 2D exemplar to a 3D solid volume, exhibits advantages in numerous application domains. However, existing methods generally synthesize solid texture with speci\ufb01c features, which may result in the failure of capturing diversi\ufb01ed textural information. In this paper, we propose a novel generative adversarial nets-based approach (STS-GAN) to hierarchically learn solid texture with a feature-free nature. Our multi-scale discriminators evaluate the similarity between patch from exemplar and slice from the generated volume, promoting the generator to synthesize realistic solid textures. Experimental results demonstrate that the proposed method can generate high-quality solid textures with similar visual characteristics to the exemplar.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145734886",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "48169697",
                    "name": "Lin Wang"
                },
                {
                    "authorId": "15563174",
                    "name": "Jifeng Guo"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2115843401",
                    "name": "Junteng Zheng"
                },
                {
                    "authorId": "2146329569",
                    "name": "Fanqi Li"
                }
            ]
        },
        {
            "paperId": "89ce04c63050703c57983abe866543a0020015d9",
            "title": "STS-GAN: Can We Synthesize Solid Texture with High Fidelity from Arbitrary 2D Exemplar?",
            "abstract": "Solid texture synthesis (STS), an effective way to extend a 2D exemplar to a 3D solid volume, exhibits advantages in computational photography. However, existing methods generally fail to accurately learn arbitrary textures, which may result in the failure to synthesize solid textures with high fidelity. In this paper, we propose a novel generative adversarial nets-based framework (STS-GAN) to extend the given 2D exemplar to arbitrary 3D solid textures. In STS-GAN, multi-scale 2D texture discriminators evaluate the similarity between the given 2D exemplar and slices from the generated 3D texture, promoting the 3D texture generator synthesizing realistic solid textures. Finally, experiments demonstrate that the proposed method can generate high-fidelity solid textures with similar visual characteristics to the 2D exemplar.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2145734886",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "15563174",
                    "name": "Jifeng Guo"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2146329569",
                    "name": "Fanqi Li"
                },
                {
                    "authorId": "2115843401",
                    "name": "Junteng Zheng"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                }
            ]
        }
    ]
}