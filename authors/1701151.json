{
    "authorId": "1701151",
    "papers": [
        {
            "paperId": "4b1e9812c71c4a243e84cf99aef8f4a2fc9ccd60",
            "title": "AdvSQLi: Generating Adversarial SQL Injections Against Real-World WAF-as-a-Service",
            "abstract": "As the first defensive layer that attacks would hit, the web application firewall (WAF) plays an indispensable role in defending against malicious web attacks like SQL injection (SQLi). With the development of cloud computing, WAF-as-a-service, as one kind of Security-as-a-service, has been proposed to facilitate the deployment, configuration, and update of WAFs in the cloud. Despite its tremendous popularity, the security vulnerabilities of WAF-as-a-service are still largely unknown, which is highly concerning given its massive usage. In this paper, we propose a general and extendable attack framework, namely AdvSQLi, in which a minimal series of transformations are performed on the hierarchical tree representation of the original SQLi payload, such that the generated SQLi payloads can not only bypass WAF-as-a-service under black-box settings but also keep the same functionality and maliciousness as the original payload. With AdvSQLi, we make it feasible to inspect and understand the security vulnerabilities of WAFs automatically, helping vendors make products more secure. To evaluate the attack effectiveness and efficiency of AdvSQLi, we first employ two public datasets to generate adversarial SQLi payloads, leading to a maximum attack success rate of 100% against state-of-the-art ML-based SQLi detectors. Furthermore, to demonstrate the immediate security threats caused by AdvSQLi, we evaluate the attack effectiveness against 7 WAF-as-a-service solutions from mainstream vendors and find all of them are vulnerable to AdvSQLi. For instance, AdvSQLi achieves an attack success rate of over 79% against the F5 WAF. Through in-depth analysis of the evaluation results, we further condense out several general yet severe flaws of these vendors that cannot be easily patched.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149703865",
                    "name": "Zhenqing Qu"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2278623383",
                    "name": "Ting Wang"
                },
                {
                    "authorId": "2143735590",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2248114065",
                    "name": "Shouling Ji"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                }
            ]
        },
        {
            "paperId": "e01aad52f551c220eab565efdb1543fb5160500d",
            "title": "Robust Backdoor Attacks on Object Detection in Real World",
            "abstract": "Deep learning models are widely deployed in many applications, such as object detection in various security fields. However, these models are vulnerable to backdoor attacks. Most backdoor attacks were intensively studied on classified models, but little on object detection. Previous works mainly focused on the backdoor attack in the digital world, but neglect the real world. Especially, the backdoor attack's effect in the real world will be easily influenced by physical factors like distance and illumination. In this paper, we proposed a variable-size backdoor trigger to adapt to the different sizes of attacked objects, overcoming the disturbance caused by the distance between the viewing point and attacked object. In addition, we proposed a backdoor training named malicious adversarial training, enabling the backdoor object detector to learn the feature of the trigger with physical noise. The experiment results show this robust backdoor attack (RBA) could enhance the attack success rate in the real world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877805",
                    "name": "Yaguan Qian"
                },
                {
                    "authorId": "2241468745",
                    "name": "Boyuan Ji"
                },
                {
                    "authorId": "2242904337",
                    "name": "Shuke He"
                },
                {
                    "authorId": "2241476978",
                    "name": "Shenhui Huang"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2256857379",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "47825073",
                    "name": "Wen Wang"
                }
            ]
        },
        {
            "paperId": "8e6d1470e8d52b46b07db84bcdc727963b6bf7dd",
            "title": "MalGraph: Hierarchical Graph Neural Networks for Robust Windows Malware Detection",
            "abstract": "With the ever-increasing malware threats, malware detection plays an indispensable role in protecting information systems. Although tremendous research efforts have been made, there are still two key challenges hindering them from being applied to accurately and robustly detect malwares. Firstly, most of them represent executables with shallow features, but ignore their semantic and structural information. Secondly, they are primarily based on representations that can be easily modified by attackers and thus cannot provide robustness against adversarial attacks. To tackle the challenges, we present MalGraph, which first represents executables with hierarchical graphs and then uses an end-to-end learning framework based on graph neural networks for malware detection. In particular, a hierarchical graph consists of a function call graph that captures the interaction semantics among different functions at the inter-function level and corresponding control-flow graphs for learning the structural semantics of each function at the intra-function level. We argue the abstraction and hierarchy nature of hierarchical graphs makes them not only easy to capture rich structural information of executables, but also be immune to adversarial attacks. Evaluations show that MalGraph not only outperforms state-of-the-art malware detection, but also exhibits stronger robustness against adversarial attacks by a large margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2066621473",
                    "name": "Wei Deng"
                },
                {
                    "authorId": "2149703865",
                    "name": "Zhenqing Qu"
                },
                {
                    "authorId": "2155241302",
                    "name": "Jiangyu Zhang"
                },
                {
                    "authorId": "38654394",
                    "name": "Shenmin Zhang"
                },
                {
                    "authorId": "1901958",
                    "name": "Tengyu Ma"
                },
                {
                    "authorId": "2152594370",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "b3780e9287b7315669556ee84416832f18af248b",
            "title": "Toward Low-Overhead Inter-Switch Coordination in Network-Wide Data Plane Program Deployment",
            "abstract": "In modern networks, administrators realize their desired functions such as network measurement in several data plane programs. They often employ the network-wide program deployment paradigm that decomposes input programs into match-action tables (MATs) while deploying each MAT on a specific programmable switch. Since MATs may be deployed on different switches, existing solutions propose the inter-switch coordination that uses the per-packet header space to deliver crucial packet processing information among switches. However, such coordination introduces non-trivial per-packet byte overhead, leading to significant end-to-end network performance degradation. In this paper, we propose Hermes, a program deployment framework that aims to minimize the per-packet byte overhead. The key idea of Hermes is to formulate the network-wide program deployment as a mixed-integer linear programming (MILP) problem with the objective of minimizing the per-packet byte overhead. In view of the NP hardness of the MILP problem, Hermes further offers a greedy-based heuristic that solves the problem in a near-optimal and timely manner. We have implemented Hermes on Tofino-based switches. Our experiments show that compared to existing frameworks, Hermes decreases the per-packet byte overhead by 156 bytes while preserving end-to-end performance in terms of flow completion time and goodput.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143735590",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2115669436",
                    "name": "Hongyan Liu"
                },
                {
                    "authorId": "2187822282",
                    "name": "Qingjiang Xiao"
                },
                {
                    "authorId": "2180898037",
                    "name": "Kaiwei Guo"
                },
                {
                    "authorId": "2187839449",
                    "name": "Tingxin Sun"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "26966619",
                    "name": "Xuan Liu"
                },
                {
                    "authorId": "1391129727",
                    "name": "Qun Huang"
                },
                {
                    "authorId": "47844917",
                    "name": "Dong Zhang"
                },
                {
                    "authorId": "49565897",
                    "name": "Haifeng Zhou"
                },
                {
                    "authorId": "2153305222",
                    "name": "Fan Zhang"
                },
                {
                    "authorId": "49762743",
                    "name": "Chunming Wu"
                }
            ]
        },
        {
            "paperId": "da155d953755e95e80acbf4a6ef163a89bb68daf",
            "title": "Towards the Desirable Decision Boundary by Moderate-Margin Adversarial Training",
            "abstract": "Adversarial training, as one of the most effective defense methods against adversarial attacks, tends to learn an inclusive decision boundary to increase the robustness of deep learning models. However, due to the large and unnecessary increase in the margin along adversarial directions, adversarial training causes heavy cross-over between natural examples and adversarial examples, which is not conducive to balancing the trade-off between robustness and natural accuracy. In this paper, we propose a novel adversarial training scheme to achieve a better trade-off between robustness and natural accuracy. It aims to learn a moderate-inclusive decision boundary, which means that the margins of natural examples under the decision boundary are moderate. We call this scheme Moderate-Margin Adversarial Training (MMAT), which generates finer-grained adversarial examples to mitigate the cross-over problem. We also take advantage of logits from a teacher model that has been well-trained to guide the learning of our model. Finally, MMAT achieves high natural accuracy and robustness under both black-box and white-box attacks. On SVHN, for example, state-of-the-art robustness and natural accuracy are achieved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153398079",
                    "name": "Xiaoyu Liang"
                },
                {
                    "authorId": "1877805",
                    "name": "Yaguan Qian"
                },
                {
                    "authorId": "2176928632",
                    "name": "Jianchang Huang"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2152594370",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "3083255",
                    "name": "Wassim Swaileh"
                }
            ]
        },
        {
            "paperId": "8b4c857311c001f6ed0cd790cce4af4dfcfb6533",
            "title": "Deep Graph Matching and Searching for Semantic Code Retrieval",
            "abstract": "Code retrieval is to find the code snippet from a large corpus of source code repositories that highly matches the query of natural language description. Recent work mainly uses natural language processing techniques to process both query texts (i.e., human natural language) and code snippets (i.e., machine programming language), however, neglecting the deep structured features of query texts and source codes, both of which contain rich semantic information. In this article, we propose an end-to-end deep graph matching and searching (DGMS) model based on graph neural networks for the task of semantic code retrieval. To this end, we first represent both natural language query texts and programming language code snippets with the unified graph-structured data, and then use the proposed graph matching and searching model to retrieve the best matching code snippet. In particular, DGMS not only captures more structural information for individual query texts or code snippets, but also learns the fine-grained similarity between them by cross-attention based semantic matching operations. We evaluate the proposed DGMS model on two public code retrieval datasets with two representative programming languages (i.e., Java and Python). Experiment results demonstrate that DGMS significantly outperforms state-of-the-art baseline models by a large margin on both datasets. Moreover, our extensive ablation studies systematically investigate and illustrate the impact of each part of DGMS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "84527483",
                    "name": "Sai-gang Wang"
                },
                {
                    "authorId": "1562978050",
                    "name": "Gaoning Pan"
                },
                {
                    "authorId": "1488667108",
                    "name": "Tengfei Ma"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2148770609",
                    "name": "A. Liu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "a1319d88d364b9075107e0dec635eeb8f0a8d4d1",
            "title": "Towards Imperceptible Adversarial Image Patches Based on Network Explanations",
            "abstract": "The vulnerability of deep neural networks (DNNs) for adversarial examples have attracted more attention. Many algorithms are proposed to craft powerful adversarial examples. However, these algorithms modifying the global or local region of pixels without taking into account network explanations. Hence, the perturbations are redundancy and easily detected by human eyes. In this paper, we propose a novel method to generate local region perturbations. The main idea is to find the contributing feature regions (CFRs) of images based on network explanations for perturbations. Due to the network explanations, the perturbations added to the CFRs are more effective than other regions. In our method, a soft mask matrix is designed to represent the CFRs for finely characterizing the contributions of each pixel. Based on this soft mask, we develop a new objective function with inverse temperature to search for optimal perturbations in CFRs. Extensive experiments are conducted on CIFAR-10 and ILSVRC2012, which demonstrate the effectiveness, including attack success rate, imperceptibility,and transferability.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1877805",
                    "name": "Yaguan Qian"
                },
                {
                    "authorId": "2109014290",
                    "name": "Jiamin Wang"
                },
                {
                    "authorId": "2152594370",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "1697068",
                    "name": "Zhaoquan Gu"
                },
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                }
            ]
        },
        {
            "paperId": "d3f4749bb7955c9f50c76a27809b17be196c5326",
            "title": "Multilevel Graph Matching Networks for Deep Graph Similarity Learning",
            "abstract": "While the celebrated graph neural networks (GNNs) yield effective representations for individual nodes of a graph, there has been relatively less success in extending to the task of graph similarity learning. Recent work on graph similarity learning has considered either global-level graph\u2013graph interactions or low-level node\u2013node interactions, however, ignoring the rich cross-level interactions (e.g., between each node of one graph and the other whole graph). In this article, we propose a multilevel graph matching network (MGMN) framework for computing the graph similarity between any pair of graph-structured objects in an end-to-end fashion. In particular, the proposed MGMN consists of a node\u2013graph matching network (NGMN) for effectively learning cross-level interactions between each node of one graph and the other whole graph, and a siamese GNN to learn global-level interactions between two input graphs. Furthermore, to compensate for the lack of standard benchmark datasets, we have created and collected a set of datasets for both the graph\u2013graph classification and graph\u2013graph regression tasks with different sizes in order to evaluate the effectiveness and robustness of our models. Comprehensive experiments demonstrate that MGMN consistently outperforms state-of-the-art baseline models on both the graph\u2013graph classification and graph\u2013graph regression tasks. Compared with previous work, multilevel graph matching network (MGMN) also exhibits stronger robustness as the sizes of the two input graphs increase.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "84527483",
                    "name": "Sai-gang Wang"
                },
                {
                    "authorId": "1488667108",
                    "name": "Tengfei Ma"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2148770609",
                    "name": "A. Liu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "19fbae5a316cf2e114c32a16095a04e9b5bbe478",
            "title": "Hierarchical Graph Matching Networks for Deep Graph Similarity Learning",
            "abstract": "While the celebrated graph neural networks yield effective representations for individual nodes of a graph, there has been relatively less success in extending to deep graph similarity learning. Recent work has considered either global-level graph-graph interactions or low-level node-node interactions, ignoring the rich cross-level interactions ( e . g ., between nodes and a whole graph). In this paper, we propose a Hierarchical Graph Matching Network (HGMN) for computing the graph similarity between any pair of graph-structured objects. Our model jointly learns graph representations and a graph matching metric function for computing graph similarities in an end-to-end fashion. The proposed HGMN model consists of a node-graph matching network for effectively learning cross-level interactions between nodes of a graph and a whole graph, and a siamese graph neural network for learning global-level interactions between two graphs. Our comprehensive experiments demonstrate that HGMN consistently outperforms state-of-the-art graph matching network baselines for both classi\ufb01cation and regression tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "84527483",
                    "name": "Sai-gang Wang"
                },
                {
                    "authorId": "1488667108",
                    "name": "Tengfei Ma"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2118839825",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "fda5f4facce9d5567c090d7ac733158e0fe93dc7",
            "title": "DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model",
            "abstract": "Deep learning (DL) models are inherently vulnerable to adversarial examples \u2013 maliciously crafted inputs to trigger target DL models to misbehave \u2013 which significantly hinders the application of DL in security-sensitive domains. Intensive research on adversarial learning has led to an arms race between adversaries and defenders. Such plethora of emerging attacks and defenses raise many questions: Which attacks are more evasive, preprocessing-proof, or transferable? Which defenses are more effective, utility-preserving, or general? Are ensembles of multiple defenses more robust than individuals? Yet, due to the lack of platforms for comprehensive evaluation on adversarial attacks and defenses, these critical questions remain largely unsolved. In this paper, we present the design, implementation, and evaluation of DEEPSEC, a uniform platform that aims to bridge this gap. In its current implementation, DEEPSEC incorporates 16 state-of-the-art attacks with 10 attack utility metrics, and 13 state-of-the-art defenses with 5 defensive utility metrics. To our best knowledge, DEEPSEC is the first platform that enables researchers and practitioners to (i) measure the vulnerability of DL models, (ii) evaluate the effectiveness of various attacks/defenses, and (iii) conduct comparative studies on attacks/defenses in a comprehensive and informative manner. Leveraging DEEPSEC, we systematically evaluate the existing adversarial attack and defense methods, and draw a set of key findings, which demonstrate DEEPSEC\u2019s rich functionality, such as (1) the trade-off between misclassification and imperceptibility is empirically confirmed; (2) most defenses that claim to be universally applicable can only defend against limited types of attacks under restricted settings; (3) it is not necessary that adversarial examples with higher perturbation magnitude are easier to be detected; (4) the ensemble of multiple defenses cannot improve the overall defense capability, but can improve the lower bound of the defense effectiveness of individuals. Extensive analysis on DEEPSEC demonstrates its capabilities and advantages as a benchmark platform which can benefit future adversarial learning research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1701151",
                    "name": "Xiang Ling"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                },
                {
                    "authorId": "122011580",
                    "name": "Jiaxu Zou"
                },
                {
                    "authorId": "2128721926",
                    "name": "Jiannan Wang"
                },
                {
                    "authorId": "49762743",
                    "name": "Chunming Wu"
                },
                {
                    "authorId": "1490934734",
                    "name": "Bo Li"
                },
                {
                    "authorId": "2155389584",
                    "name": "Ting Wang"
                }
            ]
        }
    ]
}