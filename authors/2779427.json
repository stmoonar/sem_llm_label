{
    "authorId": "2779427",
    "papers": [
        {
            "paperId": "2a0b4024687fc28d92c7dfa5feaccc607b67bbae",
            "title": "Interface Design to Mitigate Inflation in Recommender Systems",
            "abstract": "Recommendation systems rely on user-provided data to learn about item quality and provide personalized recommendations. An implicit assumption when aggregating ratings into item quality is that ratings are strong indicators of item quality. In this work, we test this assumption using data collected from a music discovery application. Our study focuses on two factors that cause rating inflation: heterogeneous user rating behavior and the dynamics of personalized recommendations. We show that user rating behavior substantially varies by user, leading to item quality estimates that reflect the users who rated an item more than the item quality itself. Additionally, items that are more likely to be shown via personalized recommendations can experience a substantial increase in their exposure and potential bias toward them. To mitigate these effects, we analyze the results of a randomized controlled trial in which the rating interface was modified. The test resulted in a substantial improvement in user rating behavior and a reduction in item quality inflation. These findings highlight the importance of carefully considering the assumptions underlying recommendation systems and designing interfaces that encourage accurate rating behavior.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41017226",
                    "name": "Rana Shahout"
                },
                {
                    "authorId": "2224619100",
                    "name": "Yehonatan Peisakhovsky"
                },
                {
                    "authorId": "39283371",
                    "name": "Sasha Stoikov"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                }
            ]
        },
        {
            "paperId": "2bf64ff61e823bc423af3bbf781511797f3e4e25",
            "title": "Reconciling the Accuracy-Diversity Trade-off in Recommendations",
            "abstract": "When making recommendations, there is an apparent trade-off between the goals of accuracy (to recommend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity into recommendations, at the cost of accuracy. We study the accuracy-diversity trade-off by bringing in a third concept: user utility. We argue that accuracy is misaligned with user utility because it fails to incorporate a user's consumption constraints: at any given time, users can typically only use at most a few recommended items (e.g., dine at one restaurant, or watch a couple of movies). In a theoretical model, we show that utility-maximizing recommendations---when accounting for consumption constraints---are naturally diverse due to diminishing returns of recommending similar items. Therefore, while increasing diversity may come at the cost of accuracy, it can also help align accuracy-based recommendations toward the more fundamental objective of user utility. Our theoretical results yield practical guidance into how recommendations should incorporate diversity to serve user ends.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124925996",
                    "name": "Kenny Peng"
                },
                {
                    "authorId": "38009222",
                    "name": "Manish Raghavan"
                },
                {
                    "authorId": "145192191",
                    "name": "E. Pierson"
                },
                {
                    "authorId": "3371403",
                    "name": "J. Kleinberg"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                }
            ]
        },
        {
            "paperId": "a29564d0ccdff94c1ff2b523d9040d35a1b3b0cc",
            "title": "Coarse race data conceals disparities in clinical risk score performance",
            "abstract": "Healthcare data in the United States often records only a patient's coarse race group: for example, both Indian and Chinese patients are typically coded as\"Asian.\"It is unknown, however, whether this coarse coding conceals meaningful disparities in the performance of clinical risk scores across granular race groups. Here we show that it does. Using data from 418K emergency department visits, we assess clinical risk score performance disparities across 26 granular groups for three outcomes, five risk scores, and four performance metrics. Across outcomes and metrics, we show that the risk scores exhibit significant granular performance disparities within coarse race groups. In fact, variation in performance within coarse groups often *exceeds* the variation between coarse groups. We explore why these disparities arise, finding that outcome rates, feature distributions, and the relationships between features and outcomes all vary significantly across granular groups. Our results suggest that healthcare providers, hospital systems, and machine learning researchers should strive to collect, release, and use granular race data in place of coarse race data, and that existing analyses may significantly underestimate racial disparities in performance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1405369173",
                    "name": "Rajiv Movva"
                },
                {
                    "authorId": "52223029",
                    "name": "Divya Shanmugam"
                },
                {
                    "authorId": "96261220",
                    "name": "Kaihua Hou"
                },
                {
                    "authorId": "2062740601",
                    "name": "P. Pathak"
                },
                {
                    "authorId": "1724429",
                    "name": "J. Guttag"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                },
                {
                    "authorId": "34207665",
                    "name": "E. Pierson"
                }
            ]
        },
        {
            "paperId": "c231220c2274015b2d979cdb1743818fefcaf5fb",
            "title": "Reflections from the Workshop on AI-Assisted Decision Making for Conservation",
            "abstract": "In this white paper, we synthesize key points made during presentations and discussions from the AI-Assisted Decision Making for Conservation workshop, hosted by the Center for Research on Computation and Society at Harvard University on October 20-21, 2022. We identify key open research questions in resource allocation, planning, and interventions for biodiversity conservation, highlighting conservation challenges that not only require AI solutions, but also require novel methodological advances. In addition to providing a summary of the workshop talks and discussions, we hope this document serves as a call-to-action to orient the expansion of algorithmic decision-making approaches to prioritize real-world conservation challenges, through collaborative efforts of ecologists, conservation decision-makers, and AI researchers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "19429172",
                    "name": "Lily Xu"
                },
                {
                    "authorId": "144322309",
                    "name": "Esther Rolf"
                },
                {
                    "authorId": "31937047",
                    "name": "Sara Beery"
                },
                {
                    "authorId": "100906556",
                    "name": "J. Bennett"
                },
                {
                    "authorId": "1399635506",
                    "name": "T. Berger-Wolf"
                },
                {
                    "authorId": "31238914",
                    "name": "Tanya Birch"
                },
                {
                    "authorId": "2311117055",
                    "name": "Elizabeth Bondi-Kelly"
                },
                {
                    "authorId": "5929147",
                    "name": "J. Brashares"
                },
                {
                    "authorId": "50774682",
                    "name": "Melissa S. Chapman"
                },
                {
                    "authorId": "91389692",
                    "name": "Anthony W. Corso"
                },
                {
                    "authorId": "2223751482",
                    "name": "Andrew Davies"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                },
                {
                    "authorId": "46944498",
                    "name": "A. Gaylard"
                },
                {
                    "authorId": "13284067",
                    "name": "Robert Heilmayr"
                },
                {
                    "authorId": "151024247",
                    "name": "H. Kerner"
                },
                {
                    "authorId": "7576393",
                    "name": "Konstantin Klemmer"
                },
                {
                    "authorId": "2125432987",
                    "name": "Vipin Kumar"
                },
                {
                    "authorId": "143722101",
                    "name": "Lester W. Mackey"
                },
                {
                    "authorId": "1806678",
                    "name": "C. Monteleoni"
                },
                {
                    "authorId": "144243996",
                    "name": "P. Moorcroft"
                },
                {
                    "authorId": "2072955412",
                    "name": "Jonathan Palmer"
                },
                {
                    "authorId": "49092378",
                    "name": "A. Perrault"
                },
                {
                    "authorId": "2532288",
                    "name": "D. Thau"
                },
                {
                    "authorId": "1965937258",
                    "name": "M. Tambe"
                }
            ]
        },
        {
            "paperId": "d1e77962084523219f7702518ac0fffdb32805e8",
            "title": "Choosing the Right Weights: Balancing Value, Strategy, and Noise in Recommender Systems",
            "abstract": "Many recommender systems are based on optimizing a linear weighting of different user behaviors, such as clicks, likes, shares, etc. Though the choice of weights can have a significant impact, there is little formal study or guidance on how to choose them. We analyze the optimal choice of weights from the perspectives of both users and content producers who strategically respond to the weights. We consider three aspects of user behavior: value-faithfulness (how well a behavior indicates whether the user values the content), strategy-robustness (how hard it is for producers to manipulate the behavior), and noisiness (how much estimation error there is in predicting the behavior). Our theoretical results show that for users, upweighting more value-faithful and less noisy behaviors leads to higher utility, while for producers, upweighting more value-faithful and strategy-robust behaviors leads to higher welfare (and the impact of noise is non-monotonic). Finally, we discuss how our results can help system designers select weights in practice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3458938",
                    "name": "S. Milli"
                },
                {
                    "authorId": "145192191",
                    "name": "E. Pierson"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                }
            ]
        },
        {
            "paperId": "02cb8bf16adf20848ff73d65ff21668b087610b2",
            "title": "Equity in Resident Crowdsourcing: Measuring Under-reporting without Ground Truth Data",
            "abstract": "Modern city governance relies heavily on crowdsourcing (or \"co-production\") to identify problems such as downed trees and power-lines. A major concern in these systems is that residents do not report problems at the same rates, leading to an inequitable allocation of government resources. However, measuring such under-reporting is a difficult statistical task, as, almost by definition, we do not observe incidents that are not reported. Thus, distinguishing between low reporting rates and low ground-truth incident rates is challenging. We develop a method to identify (heterogeneous) reporting rates, without using external (proxy) ground truth data. Our insight is that rates on duplicate reports about the same incident can be leveraged, to turn the question into a standard Poisson rate estimation task---even though the full incident reporting interval is also unobserved. We apply our method to over 100,000 resident reports made to the New York City Department of Parks and Recreation, finding that there are substantial spatial and socio-economic disparities in reporting rates, even after controlling for incident characteristics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118357288",
                    "name": "Zhi Liu"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                }
            ]
        },
        {
            "paperId": "2839009c867435ebcf117d341a28f1534382a02b",
            "title": "Supply-Side Equilibria in Recommender Systems",
            "abstract": "Algorithmic recommender systems such as Spotify and Netflix affect not only consumer behavior but also producer incentives. Producers seek to create content that will be shown by the recommendation algorithm, which can impact both the diversity and quality of their content. In this work, we investigate the resulting supply-side equilibria in personalized content recommender systems. We model users and content as $D$-dimensional vectors, the recommendation algorithm as showing each user the content with highest dot product, and producers as maximizing the number of users who are recommended their content minus the cost of production. Two key features of our model are that the producer decision space is multi-dimensional and the user base is heterogeneous, which contrasts with classical low-dimensional models. Multi-dimensionality and heterogeneity create the potential for specialization, where different producers create different types of content at equilibrium. Using a duality argument, we derive necessary and sufficient conditions for whether specialization occurs: these conditions depend on the extent to which users are heterogeneous and to which producers can perform well on all dimensions at once without incurring a high cost. Then, we characterize the distribution of content at equilibrium in concrete settings with two populations of users. Lastly, we show that specialization can enable producers to achieve positive profit at equilibrium, which means that specialization can reduce the competitiveness of the marketplace. At a conceptual level, our analysis of supply-side competition takes a step towards elucidating how personalized recommendations shape the marketplace of digital goods, and towards understanding what new phenomena arise in multi-dimensional competitive settings.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "145096211",
                    "name": "Meena Jagadeesan"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                },
                {
                    "authorId": "5164568",
                    "name": "J. Steinhardt"
                }
            ]
        },
        {
            "paperId": "4fc6929590ccddf6d79cef4e52fb08e1c5e72586",
            "title": "Fair ranking: a critical review, challenges, and future directions",
            "abstract": "Ranking, recommendation, and retrieval systems are widely used in online platforms and other societal systems, including e-commerce, media-streaming, admissions, gig platforms, and hiring. In the recent past, a large \u201cfair ranking\u201d research literature has been developed around making these systems fair to the individuals, providers, or content that are being ranked. Most of this literature defines fairness for a single instance of retrieval, or as a simple additive notion for multiple instances of retrievals over time. This work provides a critical overview of this literature, detailing the often context-specific concerns that such approaches miss: the gap between high ranking placements and true provider utility, spillovers and compounding effects over time, induced strategic incentives, and the effect of statistical uncertainty. We then provide a path forward for a more holistic and impact-oriented fair ranking research agenda, including methodological lessons from other fields and the role of the broader stakeholder community in overcoming data bottlenecks and designing effective regulatory environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51964560",
                    "name": "Gourab K. Patro"
                },
                {
                    "authorId": "74248595",
                    "name": "Lorenzo Porcaro"
                },
                {
                    "authorId": "2152051189",
                    "name": "Laura Mitchell"
                },
                {
                    "authorId": "51456850",
                    "name": "Qiuyue Zhang"
                },
                {
                    "authorId": "41154657",
                    "name": "Meike Zehlike"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                }
            ]
        },
        {
            "paperId": "0a05d08d0ae997bce8db9610df7ebe3d08419ea7",
            "title": "Strategic Ranking",
            "abstract": "Strategic classification studies the design of a classifier robust to the manipulation of input by strategic individuals. However, the existing literature does not consider the effect of competition among individuals as induced by the algorithm design. Motivated by constrained allocation settings such as college admissions, we introduce strategic ranking, in which the (designed) individual reward depends on an applicant's post-effort rank in a measurement of interest. Our results illustrate how competition among applicants affects the resulting equilibria and model insights. We analyze how various ranking reward designs, belonging to a family of step functions, trade off applicant, school, and societal utility, as well as how ranking design counters inequities arising from disparate access to resources. In particular, we find that randomization in the reward design can mitigate two measures of disparate impact, welfare gap and access.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1748108610",
                    "name": "Lydia T. Liu"
                },
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                },
                {
                    "authorId": "1721812",
                    "name": "C. Borgs"
                }
            ]
        },
        {
            "paperId": "0a8235f105d317eac8672fb717258f09956688b9",
            "title": "Combatting Gerrymandering with Social Choice: The Design of Multi-member Districts",
            "abstract": "The Fair Representation Act, first introduced in 2017 and reintroduced in 2019 and 2021, would mandate the use of multi-member districts (MMDs) to elect members to the United States House of Representatives, i.e., having fewer, larger districts each with multiple representatives. The bill is supported by good governance organizations such as FairVote; the American Academy of Arts and Sciences in 2020 released a report advocating states to use multi-member districts - however, \"on the condition that they adopt a non-winner-take-all election model.\" Despite the popular focus on single-member district (SMD) elections, such MMDs have a long history in the United States, especially at the state and local level. In 1962, 41 state legislatures had MMDs, often with winner-take-all models; even today, 10 state legislatures elect representatives for at least one chamber in such a manner. City councils, state parties, and other organizations often adopt more sophisticated techniques, using variations on Ranked Choice Voting (RCV) to elect multiple winners from each of several districts. This paper considers the design of such multi-member districts and, in the process, opens a rich research agenda at the intersection of two well-studied, but hitherto distinct, aspects of the design of representative democracies: redistricting, and social choice for multiple winners. The redistricting literature assumes winnertakes- all in SMDs and, given a fixed set of voters, studies how to divide the voters into districts such that the set of winners across districts satisfies desirable properties (e.g., for a gerrymandering party, maximizing the number of winners belonging to their party; for a neutral rule-maker, devising rules to ensure 'proportionality,' such that the fraction of winners of each party matches the fraction of voters). The social choice literature, on the other hand, considers a single district and studies voting rules (functions from voter rankings to a set of winners) such that the set of winners in that district satisfies similar properties, including proportionality. A map consisting of multiple MMDs (e.g., 30 two-member districts in Arizona) requires both partitioning voters into districts and devising how each district collects and aggregates votes. The challenge cannot be decomposed: drawing districts depends on the social choice function, and the same social choice function has different effects depending on district size and composition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2779427",
                    "name": "Nikhil Garg"
                },
                {
                    "authorId": "2056771333",
                    "name": "Wes Gurnee"
                },
                {
                    "authorId": "145792941",
                    "name": "David M. Rothschild"
                },
                {
                    "authorId": "1747127",
                    "name": "D. Shmoys"
                }
            ]
        }
    ]
}