{
    "authorId": "1793409",
    "papers": [
        {
            "paperId": "022ade66d28c03b3a5245f3962d34b9c373f92b9",
            "title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback",
            "abstract": "Large language models (LLMs) have been applied to a wide range of tasks, including text summarization, web navigation, and chatbots. They have benefitted from supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) following an unsupervised pretraining. These datasets can be difficult to collect, limited in scope, and vary in sample quality. Additionally, datasets can vary extensively in supervision format, from numerical to binary as well as multi-dimensional with many different values. We present a framework for fine-tuning LLMs using heterogeneous feedback, which has two main components. First, we combine the heterogeneous feedback data into a single supervision format, compatible with methods like SFT and RLHF. Next, given this unified feedback dataset, we extract a high-quality and diverse subset to obtain performance increases potentially exceeding the full dataset. We conduct extensive experiments to understand the effectiveness of these techniques for incorporating heterogeneous feedback, and demonstrate improvements from using a high-quality and diverse subset of the data. We find that our framework is able to improve models in multiple areas simultaneously, such as in instruction following and bias reduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2199012507",
                    "name": "Ryan Aponte"
                },
                {
                    "authorId": "2299780933",
                    "name": "Ryan Rossi"
                },
                {
                    "authorId": "2314927890",
                    "name": "Shunan Guo"
                },
                {
                    "authorId": "2257962368",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2301760185",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2285606681",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2314964541",
                    "name": "Subrata Mitra"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                }
            ]
        },
        {
            "paperId": "3968aff6f813f1b1998b3ede3a89dd4b75173b1a",
            "title": "ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection",
            "abstract": "Aspect-Based Sentiment Analysis (ABSA) has experienced tremendous expansion and diversity due to various shared tasks spanning several languages and fields and organized via SemEval workshops and Germeval. Nonetheless, a few shortcomings still need to be addressed, such as the lack of low-resource language evaluations and the emphasis on sentence-level analysis. To thoroughly assess ABSA techniques in the context of complete reviews, this research presents a novel task, Review-Level Opinion Aspect Sentiment Target (ROAST). ROAST seeks to close the gap between sentence-level and text-level ABSA by identifying every ABSA constituent at the review level. We extend the available datasets to enable ROAST, addressing the drawbacks noted in previous research by incorporating low-resource languages, numerous languages, and a variety of topics. Through this effort, ABSA research will be able to cover more ground and get a deeper comprehension of the task and its practical application in a variety of languages and domains (https://github.com/RiTUAL-UH/ROAST-ABSA).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1417179629",
                    "name": "Siva Uday Sampreeth Chebolu"
                },
                {
                    "authorId": "2257962368",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                }
            ]
        },
        {
            "paperId": "56ae7d5917654026fddba54026ef78ceeb6563d8",
            "title": "A Multi-LLM Debiasing Framework",
            "abstract": "Large Language Models (LLMs) are powerful tools with the potential to benefit society immensely, yet, they have demonstrated biases that perpetuate societal inequalities. Despite significant advancements in bias mitigation techniques using data augmentation, zero-shot prompting, and model fine-tuning, biases continuously persist, including subtle biases that may elude human detection. Recent research has shown a growing interest in multi-LLM approaches, which have been demonstrated to be effective in improving the quality of reasoning and factuality in LLMs. Building on this approach, we propose a novel multi-LLM debiasing framework aimed at reducing bias in LLMs. Our work is the first to introduce and evaluate two distinct approaches within this framework for debiasing LLMs: a centralized method, where the conversation is facilitated by a single central LLM, and a decentralized method, where all models communicate directly. Our findings reveal that our multi-LLM framework significantly reduces bias in LLMs, outperforming the baseline method across several social groups.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2322447547",
                    "name": "Deonna M. Owens"
                },
                {
                    "authorId": "2317012495",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2299908109",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "2301760185",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2257962368",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2312278435",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2283147661",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "2274190457",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "2322441755",
                    "name": "Hanieh Deilamsalehy"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                }
            ]
        },
        {
            "paperId": "5b2f5c995218e85971a8944f427d737aed5c0b5f",
            "title": "Augmenting Textual Generation via Topology Aware Retrieval",
            "abstract": "Despite the impressive advancements of Large Language Models (LLMs) in generating text, they are often limited by the knowledge contained in the input and prone to producing inaccurate or hallucinated content. To tackle these issues, Retrieval-augmented Generation (RAG) is employed as an effective strategy to enhance the available knowledge base and anchor the responses in reality by pulling additional texts from external databases. In real-world applications, texts are often linked through entities within a graph, such as citations in academic papers or comments in social networks. This paper exploits these topological relationships to guide the retrieval process in RAG. Specifically, we explore two kinds of topological connections: proximity-based, focusing on closely connected nodes, and role-based, which looks at nodes sharing similar subgraph structures. Our empirical research confirms their relevance to text relationships, leading us to develop a Topology-aware Retrieval-augmented Generation framework. This framework includes a retrieval module that selects texts based on their topological relationships and an aggregation module that integrates these texts into prompts to stimulate LLMs for text generation. We have curated established text-attributed networks and conducted comprehensive experiments to validate the effectiveness of this framework, demonstrating its potential to enhance RAG with topological awareness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284900711",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2303636546",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "2233085914",
                    "name": "Alexa F. Siu"
                },
                {
                    "authorId": "2124210729",
                    "name": "Yuying Zhao"
                },
                {
                    "authorId": "2303464225",
                    "name": "Bo Ni"
                },
                {
                    "authorId": "2304410306",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2238208116",
                    "name": "Ryan Rossi"
                },
                {
                    "authorId": "2067148039",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "5ccdc2ae2e8db7dd84d23f2de088d64fd2993713",
            "title": "KaPQA: Knowledge-Augmented Product Question-Answering",
            "abstract": "Question-answering for domain-specific applications has recently attracted much interest due to the latest advancements in large language models (LLMs). However, accurately assessing the performance of these applications remains a challenge, mainly due to the lack of suitable benchmarks that effectively simulate real-world scenarios. To address this challenge, we introduce two product question-answering (QA) datasets focused on Adobe Acrobat and Photoshop products to help evaluate the performance of existing models on domain-specific product QA tasks. Additionally, we propose a novel knowledge-driven RAG-QA framework to enhance the performance of the models in the product QA task. Our experiments demonstrated that inducing domain knowledge through query reformulation allowed for increased retrieval and generative performance when compared to standard RAG-QA methods. This improvement, however, is slight, and thus illustrates the challenge posed by the datasets introduced.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2312395859",
                    "name": "Swetha Eppalapally"
                },
                {
                    "authorId": "2312397639",
                    "name": "Daksh Dangi"
                },
                {
                    "authorId": "2312398606",
                    "name": "Chaithra Bhat"
                },
                {
                    "authorId": "2313102073",
                    "name": "Ankita Gupta"
                },
                {
                    "authorId": "2303636546",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "2311640933",
                    "name": "Shubham Agarwal"
                },
                {
                    "authorId": "2297846982",
                    "name": "Karishma Bagga"
                },
                {
                    "authorId": "2110654003",
                    "name": "Seunghyun Yoon"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2299780933",
                    "name": "Ryan Rossi"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                }
            ]
        },
        {
            "paperId": "a1ffbc4b2c5e307d5f5b92e01e9408a2364d7989",
            "title": "Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models",
            "abstract": "Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2299332766",
                    "name": "Raymond Fok"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2300338822",
                    "name": "Tong Sun"
                },
                {
                    "authorId": "2233085914",
                    "name": "Alexa F. Siu"
                }
            ]
        },
        {
            "paperId": "b618998f9f3634331c8762342bbf110b74ad3fc0",
            "title": "LongLaMP: A Benchmark for Personalized Long-form Text Generation",
            "abstract": "Long-text generation is seemingly ubiquitous in real-world applications of large language models such as generating an email or writing a review. Despite the fundamental importance and prevalence of long-text generation in many practical applications, existing work on personalized generation has focused on the generation of very short text. To overcome these limitations, we study the problem of personalized long-text generation, that is, generating long-text that is personalized for a specific user while being practically useful for the vast majority of real-world applications that naturally require the generation of longer text. In this work, we demonstrate the importance of user-specific personalization for long-text generation tasks and develop the Long-text Language Model Personalization (LongLaMP) Benchmark. LongLaMP provides a comprehensive and diverse evaluation framework for personalized long-text generation. Extensive experiments on LongLaMP for zero-shot and fine-tuned language tasks demonstrate the effectiveness of the proposed benchmark and its utility for developing and evaluating techniques for personalized long-text generation across a wide variety of long-text generation tasks. The results highlight the importance of personalization across a wide variety of long-text generation tasks. Finally, we release the benchmark for others to use for this important problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2311502672",
                    "name": "Ishita Kumar"
                },
                {
                    "authorId": "2311502900",
                    "name": "Snigdha Viswanathan"
                },
                {
                    "authorId": "2311502181",
                    "name": "Sushrita Yerra"
                },
                {
                    "authorId": "2073044451",
                    "name": "Alireza Salemi"
                },
                {
                    "authorId": "2238208116",
                    "name": "Ryan Rossi"
                },
                {
                    "authorId": "2257962368",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "1787977",
                    "name": "Hanieh Deilamsalehy"
                },
                {
                    "authorId": "2312278435",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2303636546",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "2311640933",
                    "name": "Shubham Agarwal"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2295731593",
                    "name": "Hamed Zamani"
                }
            ]
        },
        {
            "paperId": "60d0b4dba75f4f026ac4db01d8fd408ac609217b",
            "title": "How Small Businesses Transform PDF Agreements into Action",
            "abstract": "A legal agreement is a type of procedural document that describes the steps that parties must take to fulfill legal obligations. Following these steps requires human interpretation, which is often inefficient and error prone. For a Small to Medium Sized Business (SMB), this process is laborious. We conduct an interview study to understand how information in PDF agreements is currently understood, processed, and acted upon by SMB employees working in small teams of non-domain experts. Through qualitative analysis and a text highlighting activity, we observe knowledge transfer workflows in SMBs and propose design principles for using AI-extracted information to create actionable documents that address gaps in efficiency, understanding, and agency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257765639",
                    "name": "Jianna So"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2233085914",
                    "name": "Alexa F. Siu"
                },
                {
                    "authorId": "2238208116",
                    "name": "Ryan Rossi"
                },
                {
                    "authorId": "2257962368",
                    "name": "Franck Dernoncourt"
                }
            ]
        },
        {
            "paperId": "629f44f5fb78ec390ef66633dc627f1d04f3eb85",
            "title": "Knowledge Graph Prompting for Multi-Document Question Answering",
            "abstract": "The `pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or document structural relations. For graph traversal, we design an LLM-based graph traversal agent that navigates across nodes and gathers supporting passages assisting LLMs in MD-QA. The constructed graph serves as the global ruler that regulates the transitional space among passages and reduces retrieval latency. Concurrently, the graph traversal agent acts as a local navigator that gathers pertinent context to progressively approach the question and guarantee retrieval quality. Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the potential of leveraging graphs in enhancing the prompt design and retrieval augmented generation for LLMs. Our code: https://github.com/YuWVandy/KG-LLM-MDQA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2233085914",
                    "name": "Alexa F. Siu"
                },
                {
                    "authorId": "1390533012",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "68d7c9693022eefb45f2d73e121c641a00912d68",
            "title": "TaleStream: Supporting Story Ideation with Trope Knowledge",
            "abstract": "Story ideation is a critical part of the story-writing process. It is challenging to support computationally due to its exploratory and subjective nature. Tropes, which are recurring narrative elements across stories, are essential in stories as they shape the structure of narratives and our understanding of them. In this paper, we propose to use tropes as an intermediate representation of stories to approach story ideation. We present TaleStream, a canvas system that uses tropes as building blocks of stories while providing steerable suggestions of story ideas in the form of tropes. Our trope suggestion methods leverage data from the tvtropes.org wiki. We find that 97% of the time, trope suggestions generated by our methods provide better story ideation materials than random tropes. Our system evaluation suggests that TaleStream can support writers\u2019 creative flow and greatly facilitates story development. Tropes, as a rich lexicon of narratives with available examples, play a key role in TaleStream and hold promise for story-creation support systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210350",
                    "name": "Jean-Peic Chou"
                },
                {
                    "authorId": "2233085914",
                    "name": "Alexa F. Siu"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2238208116",
                    "name": "Ryan Rossi"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "1820412",
                    "name": "Maneesh Agrawala"
                }
            ]
        }
    ]
}