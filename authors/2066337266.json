{
    "authorId": "2066337266",
    "papers": [
        {
            "paperId": "33f365dcb70ce4b881c1420577d26ff5fde223c6",
            "title": "Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits",
            "abstract": "Web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of large language models (LLMs). Online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost. Organizations faces decisions like whether to employ a costly API-based LLM or a locally finetuned small LLM, weighing cost against performance. Traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning LLMs. Moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models. While some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend in model performances as the model is iteratively finetuned, leading to less accurate predictions and suboptimal model selections. In this paper, we propose a time-increasing bandit algorithm TI-UCB, which effectively predicts the increase of model performances due to training or finetuning and efficiently balances exploration and exploitation in model selection. To further capture the converging points of models, we develop a change detection mechanism by comparing consecutive increase predictions. We theoretically prove that our algorithm achieves a lower regret upper bound, improving from prior works' polynomial regret to logarithmic in a similar setting. The advantage of our method is also empirically validated through extensive experiments on classification model selection and online selection of LLMs. Our results highlight the importance of utilizing increasing-then-converging pattern for more efficient and economic model selection in the deployment of LLMs.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2282516443",
                    "name": "Yu Xia"
                },
                {
                    "authorId": "2112394890",
                    "name": "Fang-yuan Kong"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2290912970",
                    "name": "Liya Guo"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2261424174",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "2277604667",
                    "name": "Shuai Li"
                }
            ]
        },
        {
            "paperId": "405a5cef2b1a146b7f437169717ce5b4b1a8eb6c",
            "title": "Causal Discovery in Semi-Stationary Time Series",
            "abstract": "Discovering causal relations from observational time series without making the stationary assumption is a significant challenge. In practice, this challenge is common in many areas, such as retail sales, transportation systems, and medical science. Here, we consider this problem for a class of non-stationary time series. The structural causal model (SCM) of this type of time series, called the semi-stationary time series, exhibits that a finite number of different causal mechanisms occur sequentially and periodically across time. This model holds considerable practical utility because it can represent periodicity, including common occurrences such as seasonality and diurnal variation. We propose a constraint-based, non-parametric algorithm for discovering causal relations in this setting. The resulting algorithm, PCMCI$_{\\Omega}$, can capture the alternating and recurring changes in the causal mechanisms and then identify the underlying causal graph with conditional independence (CI) tests. We show that this algorithm is sound in identifying causal relations on discrete time series. We validate the algorithm with extensive experiments on continuous and discrete simulated data. We also apply our algorithm to a real-world climate dataset.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2288347927",
                    "name": "Shanyun Gao"
                },
                {
                    "authorId": "40897986",
                    "name": "Raghavendra Addanki"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2287939257",
                    "name": "Murat Kocaoglu"
                }
            ]
        },
        {
            "paperId": "4a2a1a107964c19a8b4a523a7fcd78e166e85f21",
            "title": "Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes",
            "abstract": "Large language models (LLMs) have shown remarkable advances in language generation and understanding but are also prone to exhibiting harmful social biases. While recognition of these behaviors has generated an abundance of bias mitigation techniques, most require modifications to the training data, model parameters, or decoding strategy, which may be infeasible without access to a trainable model. In this work, we leverage the zero-shot capabilities of LLMs to reduce stereotyping in a technique we introduce as zero-shot self-debiasing. With two approaches, self-debiasing via explanation and self-debiasing via reprompting, we show that self-debiasing can significantly reduce the degree of stereotyping across nine different social groups while relying only on the LLM itself and a simple prompt, with explanations correctly identifying invalid assumptions and reprompting delivering the greatest reductions in bias. We hope this work opens inquiry into other zero-shot techniques for bias mitigation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237806749",
                    "name": "Isabel O. Gallegos"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2284591479",
                    "name": "Joe Barrow"
                },
                {
                    "authorId": "35631602",
                    "name": "Md. Mehrab Tanjim"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "1787977",
                    "name": "Hanieh Deilamsalehy"
                },
                {
                    "authorId": "2283147661",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "2261424174",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                }
            ]
        },
        {
            "paperId": "73fcdb8763ec86f3472403cb071b420c4bbc0689",
            "title": "Learning to Reduce: Optimal Representations of Structured Data in Prompting Large Language Models",
            "abstract": "Large Language Models (LLMs) have been widely used as general-purpose AI agents showing comparable performance on many downstream tasks. However, existing work shows that it is challenging for LLMs to integrate structured data (e.g. KG, tables, DBs) into their prompts; LLMs need to either understand long text data or select the most relevant evidence prior to inference, and both approaches are not trivial. In this paper, we propose a framework, Learning to Reduce, that fine-tunes a language model to generate a reduced version of an input context, given a task description and context input. The model learns to reduce the input context using On-Policy Reinforcement Learning and aims to improve the reasoning performance of a fixed LLM. Experimental results illustrate that our model not only achieves comparable accuracies in selecting the relevant evidence from an input context, but also shows generalizability on different datasets. We further show that our model helps improve the LLM's performance on downstream tasks especially when the context is long.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2285093289",
                    "name": "Younghun Lee"
                },
                {
                    "authorId": "2261424174",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2285606681",
                    "name": "Xiang Chen"
                }
            ]
        },
        {
            "paperId": "87e122d0e51a3b8afcf22ce99ca3651d7e569731",
            "title": "SciCapenter: Supporting Caption Composition for Scientific Figures with Machine-Generated Captions and Ratings",
            "abstract": "Crafting effective captions for figures is important. Readers heavily depend on these captions to grasp the figure\u2019s message. However, despite a well-developed set of AI technologies for figures and captions, these have rarely been tested for usefulness in aiding caption writing. This paper introduces SciCapenter, an interactive system that puts together cutting-edge AI technologies for scientific figure captions to aid caption composition. SciCapenter generates a variety of captions for each figure in a scholarly article, providing scores and a comprehensive checklist to assess caption quality across multiple critical aspects, such as helpfulness, OCR mention, key takeaways, and visual properties reference. Users can directly edit captions in SciCapenter, resubmit for revised evaluations, and iteratively refine them. A user study with Ph.D. students indicates that SciCapenter significantly lowers the cognitive load of caption writing. Participants\u2019 feedback further offers valuable design insights for future systems aiming to enhance caption writing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4500245",
                    "name": "Ting-Yao Hsu"
                },
                {
                    "authorId": "2261579861",
                    "name": "Chieh-Yang Huang"
                },
                {
                    "authorId": "2110443181",
                    "name": "Shih-Hong Huang"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2261424174",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2250617677",
                    "name": "C. L. Giles"
                },
                {
                    "authorId": "2261392350",
                    "name": "\u2018Kenneth\u2019 Huang"
                }
            ]
        },
        {
            "paperId": "93c63dbcdaaf0682c99078c9489f76c66907e927",
            "title": "Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data",
            "abstract": "Large Language Models (LLMs) have been achieving competent performance on a wide range of downstream tasks, yet existing work shows that inference on structured data is challenging for LLMs. This is because LLMs need to either understand long structured data or select the most relevant evidence before inference, and both approaches are not trivial. This paper proposes a framework, Learning to Reduce, that fine-tunes a language model with On-Policy Learning to generate a reduced version of an input structured data. When compared to state-of-the-art LLMs like GPT-4, Learning to Reduce not only achieves outstanding performance in reducing the input, but shows generalizability on different datasets. We further show that the model fine-tuned with our framework helps LLMs better perform on table QA tasks especially when the context is longer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2285093289",
                    "name": "Younghun Lee"
                },
                {
                    "authorId": "2299908109",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2301760185",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2285606681",
                    "name": "Xiang Chen"
                }
            ]
        },
        {
            "paperId": "bcc2d63331e665fbe7123359dbf81c685a692775",
            "title": "Tackling Long-Tail Entities for Temporal Knowledge Graph Completion",
            "abstract": "Most Temporal Knowledge Graphs (TKGs) exhibit a long-tail entity distribution, where the majority of entities have sparse connections. Existing TKG completion methods struggle with managing new or unseen entities that often lack sufficient connections. In this paper, we introduce a model-agnostic enhancement layer that can be integrated with any existing TKG completion method to improve its performance. This enhancement layer employs a broader, global definition of entity similarity, transcending the limitations of local neighborhood proximity found in Graph Neural Network (GNN) based methods. Additionally, we conduct our evaluations in a novel, realistic setup that treats the TKG as a stream of evolving data. Evaluations on two benchmark datasets demonstrate that our framework surpasses existing methods in overall link prediction, inductive link prediction, and in addressing long-tail entities. Notably, our approach achieves a 10% improvement in MRR on one dataset and a 15% increase on another.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35416435",
                    "name": "Mehrnoosh Mirtaheri"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2299908109",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "39015414",
                    "name": "K. Mahadik"
                },
                {
                    "authorId": "2301760185",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2285606681",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2301211883",
                    "name": "Mohammad Rostami"
                }
            ]
        },
        {
            "paperId": "f767f0a883c8fc70de03fb8b65ed87e1fef5f415",
            "title": "Hallucination Diversity-Aware Active Learning for Text Summarization",
            "abstract": "Large Language Models (LLMs) have shown propensity to generate hallucinated outputs, i.e., texts that are factually incorrect or unsupported. Existing methods for alleviating hallucinations typically require costly human annotations to identify and correct hallucinations in LLM outputs. Moreover, most of these methods focus on a specific type of hallucination, e.g., entity or token errors, which limits their effectiveness in addressing various types of hallucinations exhibited in LLM outputs. To our best knowledge, in this paper we propose the first active learning framework to alleviate LLM hallucinations, reducing costly human annotations of hallucination needed. By measuring fine-grained hallucinations from errors in semantic frame, discourse and content verifiability in text summarization, we propose HAllucination Diversity-Aware Sampling (HADAS) to select diverse hallucinations for annotations in active learning for LLM finetuning. Extensive experiments on three datasets and different backbone models demonstrate advantages of our method in effectively and efficiently mitigating LLM hallucinations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282516443",
                    "name": "Yu Xia"
                },
                {
                    "authorId": "2290239365",
                    "name": "Xu Liu"
                },
                {
                    "authorId": "2281159998",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2261424174",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2289987062",
                    "name": "Anup B. Rao"
                },
                {
                    "authorId": "144396718",
                    "name": "Tung Mai"
                },
                {
                    "authorId": "2294834537",
                    "name": "Shuai Li"
                }
            ]
        },
        {
            "paperId": "0112e4bd72165a9aca8aaf32e6ba116050798523",
            "title": "Structured Dynamic Pricing: Optimal Regret in a Global Shrinkage Model",
            "abstract": "We consider dynamic pricing strategies in a streamed longitudinal data set-up where the objective is to maximize, over time, the cumulative profit across a large number of customer segments. We consider a dynamic model with the consumers' preferences as well as price sensitivity varying over time. Building on the well-known finding that consumers sharing similar characteristics act in similar ways, we consider a global shrinkage structure, which assumes that the consumers' preferences across the different segments can be well approximated by a spatial autoregressive (SAR) model. In such a streamed longitudinal set-up, we measure the performance of a dynamic pricing policy via regret, which is the expected revenue loss compared to a clairvoyant that knows the sequence of model parameters in advance. We propose a pricing policy based on penalized stochastic gradient descent (PSGD) and explicitly characterize its regret as functions of time, the temporal variability in the model parameters as well as the strength of the auto-correlation network structure spanning the varied customer segments. Our regret analysis results not only demonstrate asymptotic optimality of the proposed policy but also show that for policy planning it is essential to incorporate available structural information as policies based on unshrunken models are highly sub-optimal in the aforementioned set-up. We conduct simulation experiments across a wide range of regimes as well as real-world networks based studies and report encouraging performance for our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2212910388",
                    "name": "Rashmi Ranjan Bhuyan"
                },
                {
                    "authorId": "2548570",
                    "name": "Adel Javanmard"
                },
                {
                    "authorId": "2109571021",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "48529633",
                    "name": "Gourab Mukherjee"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "7574699",
                    "name": "Handong Zhao"
                }
            ]
        },
        {
            "paperId": "4f5a5a7f4f90fde2b23fc496ec7fc8d429d4bc5e",
            "title": "Learning the Visualness of Text Using Large Vision-Language Models",
            "abstract": "Visual text evokes an image in a person's mind, while non-visual text fails to do so. A method to automatically detect visualness in text will enable text-to-image retrieval and generation models to augment text with relevant images. This is particularly challenging with long-form text as text-to-image generation and retrieval models are often triggered for text that is designed to be explicitly visual in nature, whereas long-form text could contain many non-visual sentences. To this end, we curate a dataset of 3,620 English sentences and their visualness scores provided by multiple human annotators. We also propose a fine-tuning strategy that adapts large vision-language models like CLIP by modifying the model's contrastive learning objective to map text identified as non-visual to a common NULL image while matching visual text to their corresponding images in the document. We evaluate the proposed approach on its ability to (i) classify visual and non-visual text accurately, and (ii) attend over words that are identified as visual in psycholinguistic studies. Empirical evaluation indicates that our approach performs better than several heuristics and baseline models for the proposed task. Furthermore, to highlight the importance of modeling the visualness of text, we conduct qualitative analyses of text-to-image generation systems like DALL-E. Project webpage: https://gaurav22verma.github.io/text-visualness/",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145816931",
                    "name": "Gaurav Verma"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "67319819",
                    "name": "Chris Tensmeyer"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "3115414",
                    "name": "A. Nenkova"
                }
            ]
        }
    ]
}