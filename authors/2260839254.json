{
    "authorId": "2260839254",
    "papers": [
        {
            "paperId": "07cc88dc2d3421a94bc3c0cbd3be3da09db1da83",
            "title": "HR and LiDAR Data Collaborative Semantic Segmentation Based on Adaptive Cross-Modal Fusion Network",
            "abstract": "Semantic segmentation using cross-modal data is a hot topic in the field of Earth observation. Compared with single-modal strategies, cross-modal networks fuse multiaspect information and yield higher segmentation accuracy, which is widely used in urban planning, environmental monitoring and so on. In this study, an end-to-end adaptive cross-modal fusion network (ACFNet) is proposed for semantic segmentation task using high resolution and light detection and ranging images, because of the difference of sensor resolution, different modal data have different abilities of ground object expression. Therefore, multimodal data fusion should consider the features with different spatial scales, while most existing methods simply use the same spatial scale features for fusion. In this work, we first design an adaptive scale fusion module that can automatically choose the features with optimal spatial scales, making full use of the representation properties of ground object details. Second, the important feature guidance module is designed, which can evaluate the influence weights of deep semantic features and shallow spatial detailed features, achieving adaptive deep and shallow feature fusion, and reducing the semantic-spatial information dilution caused by layer-by-layer up and down sampling. Finally, we introduce a divide Fourier context learning (DFCL) module to transform the feature maps from spatial domain to frequency domain. Compared to the limited perception of current spatial convolution kernels, the DFCL module can easily model the contextual dependencies of cross-modal features, which will improve the segmentaion accuracy for complex ground objects of cities, especially for occlusion. To demonstrate the generalisation performance of our module, we conduct extensive experiments and ablation studies on three datasets: Potsdam, Vaihingen, and IEEE GRSS DFC 2018. Results show that the proposed ACFNet is effective in semantic segmentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268029504",
                    "name": "Zhen Ye"
                },
                {
                    "authorId": "2299916751",
                    "name": "Zhen Li"
                },
                {
                    "authorId": "2261638530",
                    "name": "Nan Wang"
                },
                {
                    "authorId": "2110481500",
                    "name": "Yuan-bao Li"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "09cf8c5f0432c8de7777f888d3f10e68d116d190",
            "title": "An Object Fine-Grained Change Detection Method Based on Frequency Decoupling Interaction for High-Resolution Remote Sensing Images",
            "abstract": "Change detection is a prominent research direction in the field of remote sensing image processing. However, most current change detection methods focus solely on detecting changes without being able to differentiate the types of changes, such as \u201cappear\u201d or \u201cdisappear\u201d of objects. Accurate detection of change types is of great significance in guiding decision-making processes. To address this issue, this article introduces the object fine-grained change detection (OFCD) task and proposes a method based on frequency decoupling interaction (FDINet). Specifically, in order to enhance the model\u2019s ability to detect change types and improve its robustness to temporal information, a temporal exchange framework is designed. Additionally, to better capture spatial\u2013temporal correlation in bi-temporal features, a wavelet interaction module (WIM) is proposed. This module utilizes wavelet transform for frequency decoupling, separating features into different components based on their frequency magnitudes. Then the module applies different interaction methods according to the characteristics of these frequency components. Finally, to aggregate complementary information from different-scale feature maps and enhance the representational capabilities of the extracted features, a feature aggregation and upsampling module (FAUM) is adopted. A series of experiments show the superiority of FDINet over most state-of-the-art methods, achieving good results on three different datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260832843",
                    "name": "Yingjie Tang"
                },
                {
                    "authorId": "51339535",
                    "name": "Shou Feng"
                },
                {
                    "authorId": "2239999972",
                    "name": "Chunhui Zhao"
                },
                {
                    "authorId": "2186369620",
                    "name": "Yuanze Fan"
                },
                {
                    "authorId": "2184328924",
                    "name": "Qian Shi"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2070824819",
                    "name": "Ran Tao"
                }
            ]
        },
        {
            "paperId": "1171a39c7cdd7bf8ead3d8d73a59443ccf886c69",
            "title": "Relationship Learning From Multisource Images via Spatial-Spectral Perception Network",
            "abstract": "Advances in multisource remote sensing have allowed for the development of more comprehensive observation. The adoption of deep convolutional neural networks (CNN) naturally includes spatial-spectral information, which has achieved promising performance in multisource data classification. However, challenges are still found with the extraction of spatial distribution and spectrum relationships, which eventually limit the classification performance. To solve the issue, a spatial-spectral perception network (S2PNet) is proposed to extract the advantages of different data sources and the cross information between data sources in a targeted manner. Specifically, the spatial perception network is developed to build the spatial distribution relationship from high-resolution images, while the spectral perception network extracts the spectrum relationship from spectral images. For perceiving cross information, a memory unit is utilized to store the features from different data sources in succession. In addition, the distance loss and reconstruction loss are introduced to keep the feature integrity, and the cross-entropy loss ensures that features can distinguish different classes. The comprehensive experiments are conducted on several datasets to validate the superiority of the proposed algorithm. The proposed S2PNet outperforms the considered classifiers with an average improvement of +0.77%, +5.62%, +1.58%, and +1.79% for overall accuracy values.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278969253",
                    "name": "Yunhao Gao"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2109764122",
                    "name": "Junjie Wang"
                },
                {
                    "authorId": "2153204738",
                    "name": "Mengmeng Zhang"
                },
                {
                    "authorId": "2070824819",
                    "name": "Ran Tao"
                }
            ]
        },
        {
            "paperId": "15110416b1b5707dda4d29aefd112df0d73ad268",
            "title": "Contrastive Adaptive Segmentation Method for Spartina Alterniflora Based on Intermediate Domain Prototypes",
            "abstract": "Observing spartina alterniflora (S.alterniflora) with multi-temporal remote sensing data aids in comprehending its development and spread in wetland ecosystems, thereby facilitating the formulation of effective strategies for its containment and control. Unsupervised Domain Adaptation (UDA) techniques uncover its spatio-temporal patterns, but most methods miss critical domain and class differences, whereas Intermediate Domain Prototype Class-level Learning Network (IDCNet) addresses these gaps. IDCNet generates class prototypes based on intermediate domain features, incorporating inter-class information for more accurate distribution alignment. Experimental results on two cross-year multi-spectral datasets demonstrate that the proposed IDCNet outperforms several state-of-the-art UDA methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279382763",
                    "name": "Boyu Zhao"
                },
                {
                    "authorId": "2272095702",
                    "name": "Zhengmao Li"
                },
                {
                    "authorId": "2143393198",
                    "name": "X. Jiang"
                },
                {
                    "authorId": "2153204738",
                    "name": "Mengmeng Zhang"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2248955967",
                    "name": "Yuxiang Zhang"
                },
                {
                    "authorId": "2267309966",
                    "name": "Xiukai Song"
                }
            ]
        },
        {
            "paperId": "1a2d5c3db0dbe42c7488983b3b31de23d9c90810",
            "title": "TS-Track: Trajectory Self-Adjusted Ship Tracking for GEO Satellite Image Sequences via Multilevel Supervision Paradigm",
            "abstract": "Accurate and efficient ship tracking by geosynchronous orbit (GEO) satellites holds great significance for large-scale maritime surveillance. Nevertheless, ship tracking continues to grapple with a multitude of challenges as follows: 1) the targets are small and often obscured by cloud interference, leading to weakened features; 2) the contrasts between the ships and the background are relatively low, complicating the identification and tracking process; and 3) the frame-to-frame relative positioning accuracy is poor, posing difficulties in reflecting the actual movement trends of ships. In response to these challenges, we proposed TS-Track, a novel framework employing multilevel supervision paradigm to improve tracking performance. Initially, this framework restructured the tracking task into three key sub-modules: image enhancement, object tracking, and trajectory adjustment, inherently fostering a unified training protocol that naturally encompasses all components. Subsequently, a trajectory-based frame fusion strategy was proposed, utilizing consecutive three-frame images to enhance target features and produce consistent motion feature patterns; Last but not least, a trajectory adjustment network was developed to correct the position of ships during tracking, resulting in stable tracking trajectories, and reproduce the actual movement trends of ships. The experimental results on GaoFen-4 dataset validated that our method delivered a significant improvement in ship tracking and achieved state-of-the-art (SOTA) performance. Source codes are available at https://github.com/KTqizhi/KTqizhi.github.io.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260692938",
                    "name": "Ziyang Kong"
                },
                {
                    "authorId": "2260852476",
                    "name": "Qizhi Xu"
                },
                {
                    "authorId": "2118204526",
                    "name": "Yuan Li"
                },
                {
                    "authorId": "2073599",
                    "name": "Xiaolin Han"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "242b35eb25062545b7d6c03ca87639ee2e2f5988",
            "title": "Spatial-Spectral\u2013Semantic Cross-Domain Few-Shot Learning for Hyperspectral Image Classification",
            "abstract": "Preprocessing procedures are commonly employed to reduce water-absorption bands and noise in hyperspectral images (HSIs). Nevertheless, they typically do not entirely eradicate noise. This is especially evident in scenarios that necessitate data of exceptional quality, such as cross-domain few-shot classification tasks. Within these specific conditions, the influence of remaining background noise on the ultimate results of classification is substantial. Furthermore, the presence of sample selection biases in the few-shot task might lead to the emergence of false statistical correlations between data from distinct domains, resulting in a decrease in the model\u2019s ability to generalize. We propose a new method called spatial-spectral\u2013semantic cross-domain few-shot learning (S3CFSL) to address the challenge. This method promotes the learning of transferable information by incorporating feature denoising operations in the feature extraction process to restore essential information. Concurrently, it enhances cross-domain distributional consistency by introducing a semantic-aware strategy to strengthen the association between cross-domain data and semantic information. Specifically, the spatial and spectral dual channels (SSDCs), in conjunction with the cross-spatial-spectral transformer (CSST), are designed as a feature extractor to acquire interactive spatial-spectral features. The feature-denoising operations can further acquiring transferable information from cross-domain features, thus facilitating meta-learning in both the source domain (SD) and the target domain (TD). Meanwhile, a semantic-enhanced domain alignment (SEDA) is designed to promote domain adaptation by using a semantic-aware strategy, which significantly enhances distributional consistency for cross-domain tasks. Our results exhibit exceptional classification efficacy in comparison to other state-of-the-art approaches on three public HSI datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240084807",
                    "name": "Mengxin Cao"
                },
                {
                    "authorId": "2260823473",
                    "name": "Xu Zhang"
                },
                {
                    "authorId": "2277423319",
                    "name": "Jinyong Cheng"
                },
                {
                    "authorId": "2239844600",
                    "name": "Guixin Zhao"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2241078714",
                    "name": "Xiangjun Dong"
                }
            ]
        },
        {
            "paperId": "275d3251d29b893bf749cc725c4def529b286c8f",
            "title": "Hyperspherical Structural-Aware Distillation Enhanced Spatial\u2013Spectral Bidirectional Interaction Network for Hyperspectral Image Classification",
            "abstract": "The existing methods for hyperspectral image classification (HSIC) mainly focus on the extraction of spectral and spatial features while paying less attention to the interaction of each other. Besides, most of them directly use a parameterized classifier as the final layer of the network. While this design is convenient for end-to-end optimization with the backbone, it overlooks the utilization of the metric space. In this article, a novel hyperspherical structural-aware distillation enhanced spatial\u2013spectral bidirectional interaction network (HSDBIN) is proposed for HSIC. HSDBIN uses a dual-branch design combining the 1-D CNN and transformer to separately learn the detailed spectral correlations and global spatial relationships in parallel. Then, by interacting and aggregating the independent information between two parallel branches, a bidirectional interaction block across branches is designed to explore complementary clues between spectral and spatial pipelines. Finally, to enhance the utilization of metric space and keep compact intraclass relationship, we propose a hyperspherical structural-aware distillation (HSD) to transfer the geometric relationship of hyperspherical space into the metric space of output logits. Extensive experiments and analysis on three public HSI datasets suggest the superiority of the proposed method and verify the effectiveness of the proposed modules.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134909263",
                    "name": "Boao Qin"
                },
                {
                    "authorId": "51339535",
                    "name": "Shou Feng"
                },
                {
                    "authorId": "2267431724",
                    "name": "Chunhui Zhao"
                },
                {
                    "authorId": "40377746",
                    "name": "Bobo Xi"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2267334931",
                    "name": "Ran Tao"
                },
                {
                    "authorId": "2258339560",
                    "name": "Yunsong Li"
                }
            ]
        },
        {
            "paperId": "292f613595e2a0e9f778e96008b5eb85681eab53",
            "title": "A Multiscale Incremental Learning Network for Remote Sensing Scene Classification",
            "abstract": "To infer unknown remote sensing scenarios, for remote sensing scene classification (RSSC), most existing deep neural networks (DNNs) are trained on closed datasets. When the acquisition speed and quantity of remote sensing images increase rapidly, these models cannot be used to classify new scenes. Currently, incremental learning as an effective solution for solving the catastrophic forgetting issue, but ignoring the stability-plasticity dilemma. In this article, we propose a new incremental learning network, named efficient channel attention-based multiscale depthwise network (ECA-MSDWNet), in which efficient channel attention (ECA) improves the model\u2019s ability to focus on critical information in complex context, and multiscale depthwise convolution (MSDW Conv) extracts multiscale features in a fine-grained way. In addition, in incremental learning process, we expand new modules based on a dynamic-structure method to fit the residuals between the labels and the outputs of the old model, enhancing the plasticity of the new model for new tasks while maintaining the performance of the old tasks. Finally, we compress the model to reduce redundant parameters and feature dimensions through an effective knowledge distillation strategy. Experiments on four open datasets demonstrate the effectiveness of our method. Our code is available at https://github.com/zhangyu-chd/ECA-MSDWNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268029504",
                    "name": "Zhen Ye"
                },
                {
                    "authorId": "2267725538",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2248971546",
                    "name": "Jinxin Zhang"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2075397419",
                    "name": "Lin Bai"
                }
            ]
        },
        {
            "paperId": "2be8396f9af64bc93e19073986f30faaa549fbaf",
            "title": "Cross-Domain Few-Shot Learning Based on Feature Disentanglement for Hyperspectral Image Classification",
            "abstract": "Existing hyperspectral cross-domain few-shot learning (FSL) methods focus mainly on elaborating on training strategies or domain alignment algorithms, while paying less attention to the biased metaknowledge introduced by a large amount of source data and the implicit encouragement of learning target domain-specific attributes. In this article, from the perspective of disentangled representation learning, a novel cross-domain FSL method based on feature disentanglement (FDFSL) is proposed for hyperspectral image classification (HSIC). Specifically, to suppress the representation biased toward the source data and enable the model to implicitly focus on the inherent knowledge of the target domain, an orthogonal low-rank feature disentanglement method is employed to acquire desired features of source and target pipelines. Furthermore, to preserve more shared and discriminative information from the heterogeneous data space (i.e., the spectral dimensions of the source and target scenes are typically different), a multiorder spectral interaction block based on central position encoding (MICD) is proposed to fully integrate the respective features into the spectral domain, which allows the model to emphasize informative spectral dimensions in a data-driven manner. Finally, to diversify the feature representation space while preventing the model overfitting to domain alignment task, a self-distillation scheme is developed to facilitate the acquisition of task-relevant feature components. Extensive experiments and analysis on three public HSI datasets suggest the superiority of the proposed method. The code will be available on the website at https://github.com/Qba-heu/FDFSL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134909263",
                    "name": "Boao Qin"
                },
                {
                    "authorId": "51339535",
                    "name": "Shou Feng"
                },
                {
                    "authorId": "2239999972",
                    "name": "Chunhui Zhao"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2070824819",
                    "name": "Ran Tao"
                },
                {
                    "authorId": "2052727274",
                    "name": "Wei Xiang"
                }
            ]
        },
        {
            "paperId": "2fe33a26a263634b005ea33ec9b5ab449b9ad581",
            "title": "Fractional Fourier-Based Frequency-Spatial\u2013Spectral Prototype Network for Agricultural Hyperspectral Image Open-Set Classification",
            "abstract": "At present, hyperspectral image classification (HSIC) technology has been warmly concerned in all walks of life, especially in agriculture. However, existing classification methods operate under the closed-set assumption, which deviates from the real world with open properties. At the same time, there are more serious phenomena of different crops with similar spectrums and the same crops with different spectrum in agricultural hyperspectral data, which is also a great challenge to existing methods. In this work, a fractional Fourier-based frequency-spatial\u2013spectral prototype network (FrFSSPN) is proposed to address the challenges of open-set HSIC in agricultural scenarios. First, fractional Fourier transform (FrFT) is introduced into the network to combine the information in the frequency domain with the spatial\u2013spectral information, so as to expand the difference between different classes on the premise of ensuring the similarity between classes. Then, the prototype learning strategy is introduced into the network to improve the feature recognition capability of the network through prototype loss. Finally, in order to break the stubbornly closed-set property of the closed-set classification (CSC) method, the open-set recognition module is proposed. The difference between the prototype vector and the feature vector is used to judge the unknown class. Experiments on three agricultural hyperspectral datasets show that this method can effectively identify unknown classes without sacrificing the classification accuracy of closed-set, and has satisfactory classification performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2041807352",
                    "name": "Maoyang Chen"
                },
                {
                    "authorId": "51339535",
                    "name": "Shou Feng"
                },
                {
                    "authorId": "2239999972",
                    "name": "Chunhui Zhao"
                },
                {
                    "authorId": "2296074301",
                    "name": "Bo Qu"
                },
                {
                    "authorId": "47634506",
                    "name": "Nan Su"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2070824819",
                    "name": "Ran Tao"
                }
            ]
        }
    ]
}