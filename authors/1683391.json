{
    "authorId": "1683391",
    "papers": [
        {
            "paperId": "01fac76c587a5a28c2646d100bc4bc1ae1048679",
            "title": "CQSumDP: A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia",
            "abstract": "Debatepedia is a publicly available dataset consisting of arguments and counter-arguments on controversial topics that has been widely used for the single-document query-focused abstractive summarization task in recent years. However, it has been recently found that this dataset is limited by noise and even most queries in this dataset do not have any relevance to the respective document. In this paper, we present a methodology for cleaning the Debatepedia dataset by leveraging the generative power of large language models to make it suitable for query-focused abstractive summarization. More specifically, we harness the language generation capabilities of ChatGPT to regenerate its queries. We evaluate the effectiveness of the proposed ChatGPT annotated version of the Debatepedia dataset using several benchmark summarization models and demonstrate that the newly annotated version of Debatepedia outperforms the original dataset in terms of both query relevance as well as summary generation quality. We will make this annotated and cleaned version of the dataset publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46437970",
                    "name": "Md Tahmid Rahman Laskar"
                },
                {
                    "authorId": "2218664824",
                    "name": "Mizanur Rahman"
                },
                {
                    "authorId": "2216718110",
                    "name": "Israt Jahan"
                },
                {
                    "authorId": "2939577",
                    "name": "Enamul Hoque"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "6ef403fe13d2af72af24a920980d11f53ef01a38",
            "title": "Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation",
            "abstract": "Dialogue systems for non-English languages have long been under-explored. In this paper, we take the first step to investigate few-shot cross-lingual transfer learning (FS-XLT) and multitask learning (MTL) in the context of open-domain dialogue generation for non-English languages with limited data. We observed catastrophic forgetting in both FS-XLT and MTL for all 6 languages in our preliminary experiments. To mitigate the issue, we propose a simple yet effective prompt learning approach that can preserve the multilinguality of multilingual pre-trained language model (mPLM) in FS-XLT and MTL by bridging the gap between pre-training and fine-tuning with Fixed-prompt LM Tuning and our hand-crafted prompts. Experimental results on all 6 languages in terms of both automatic and human evaluations demonstrate the effectiveness of our approach. Our code is available at https://github.com/JeremyLeiLiu/XLinguDial.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152044904",
                    "name": "Lei Liu"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "b3f0cdc217a3d192d2671e44913542903c94105b",
            "title": "TARGAT: A Time-Aware Relational Graph Attention Model for Temporal Knowledge Graph Embedding",
            "abstract": "Temporal knowledge graph embedding (TKGE) aims to learn the embedding of entities and relations in a temporal knowledge graph (TKG). Although the previous graph neural networks (GNN) based models have achieved promising results, they cannot directly capture the interactions of multi-facts at different timestamps. To address the above limitation, we propose a time-aware relational graph attention model (TARGAT), which takes the multi-facts at different timestamps as a unified graph. First, we develop a relational generator to dynamically generate a series of time-aware relational message transformation matrices, which jointly models the relations and the timestamp information into a unified way. Then, we apply the generated message transformation matrices to project the neighborhood features into different time-aware spaces and aggregate these neighborhood features to explicitly capture the interactions of multi-facts. Finally, a temporal transformer classifier is applied to learn the representation of the query quadruples and predict the missing entities. The experimental results show that our TARGAT model beats the GNN-based models by a large margin and achieves new state-of-the-art results on four popular benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3408236",
                    "name": "Zhiwen Xie"
                },
                {
                    "authorId": "3852723",
                    "name": "Runjie Zhu"
                },
                {
                    "authorId": "2108457408",
                    "name": "Jin Liu"
                },
                {
                    "authorId": "143652253",
                    "name": "Guangyou Zhou"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "d3060876d9ad4e4e50e1c88a8c04186df00f24e2",
            "title": "A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets",
            "abstract": "The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instructions that we mostly found in ChatGPT and other instruction-tuned models. Our extensive evaluation shows that even though ChatGPT is capable of performing a wide variety of tasks, and may obtain impressive performance in several benchmark datasets, it is still far from achieving the ability to reliably solve many challenging tasks. By providing a thorough assessment of ChatGPT's performance across diverse NLP tasks, this paper sets the stage for a targeted deployment of ChatGPT-like LLMs in real-world applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46437970",
                    "name": "Md Tahmid Rahman Laskar"
                },
                {
                    "authorId": "31773000",
                    "name": "M Saiful Bari"
                },
                {
                    "authorId": "2218664824",
                    "name": "Mizanur Rahman"
                },
                {
                    "authorId": "145505476",
                    "name": "Md Amran Hossen Bhuiyan"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "ea7e6df5b48f36dd13c838fd56744aae6189ee8b",
            "title": "Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers",
            "abstract": "ChatGPT is a large language model developed by OpenAI. Despite its impressive performance across various tasks, no prior work has investigated its capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of ChatGPT on various benchmark biomedical tasks, such as relation extraction, document classification, question answering, and summarization. To the best of our knowledge, this is the first work that conducts an extensive evaluation of ChatGPT in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative transformer models, such as BioGPT and BioBART. This suggests that ChatGPT\u2019s pre-training on large text corpora makes it quite specialized even in the biomedical domain. Our findings demonstrate that ChatGPT has the potential to be a valuable tool for various tasks in the biomedical domain that lack large annotated data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216718110",
                    "name": "Israt Jahan"
                },
                {
                    "authorId": "46437970",
                    "name": "Md Tahmid Rahman Laskar"
                },
                {
                    "authorId": "2219207734",
                    "name": "Chun Peng"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "162e1d7f7921bc2537e8ab2080fc51c4fbb52d9e",
            "title": "HGEN: Learning Hierarchical Heterogeneous Graph Encoding for Math Word Problem Solving",
            "abstract": "Designing algorithms to solve math word problems (MWPs) is an important research topic in natural language processing and smart education domains. The task of solving MWPs involves transforming math problem texts into math equations. Although recent Graph2Tree-based models, which adopt homogeneous graph encoders to learn quantity representations, have obtained very promising results in generating math equations, they do not consider the heterogeneous issue and the long-distance dependencies of heterogeneous nodes. In this paper, we propose a novel hierarchical heterogeneous graph encoding called HGEN for MWPs. Specifically, HGEN first introduces a heterogeneous graph consisting of a node-level attention layer and a type-aware attention layer to learn the heterogeneous node embedding. HGEN then captures the long-distance dependent information by propagating the multi-hop nodes in a hierarchical manner. We conduct extensive experiments on two popular MWP datasets. Our empirical results show that HGEN significantly outperforms the state-of-the-art Graph2Tree-based models in the literature.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153913528",
                    "name": "Yi Zhang"
                },
                {
                    "authorId": "143652253",
                    "name": "Guangyou Zhou"
                },
                {
                    "authorId": "3408236",
                    "name": "Zhiwen Xie"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "46d3018afbb31e31be97d18a8ee5f60f49635d81",
            "title": "Hypergraph Contrastive Collaborative Filtering",
            "abstract": "Collaborative Filtering (CF) has emerged as fundamental paradigms for parameterizing users and items into latent representation space, with their correlative patterns from interaction data. Among various CF techniques, the development of GNN-based recommender systems, e.g., PinSage and LightGCN, has offered the state-of-the-art performance. However, two key challenges have not been well explored in existing solutions: i) The over-smoothing effect with deeper graph-based CF architecture, may cause the indistinguishable user representations and degradation of recommendation results. ii) The supervision signals (i.e., user-item interactions) are usually scarce and skewed distributed in reality, which limits the representation power of CF paradigms. To tackle these challenges, we propose a new self-supervised recommendation framework Hypergraph Contrastive Collaborative Filtering (HCCF) to jointly capture local and global collaborative relations with a hypergraph-enhanced cross-view contrastive learning architecture. In particular, the designed hypergraph structure learning enhances the discrimination ability of GNN-based CF paradigm, in comprehensively capturing the complex high-order dependencies among users. Additionally, our HCCF model effectively integrates the hypergraph structure encoding with self-supervised learning to reinforce the representation quality of recommender systems, based on the hypergraph self-discrimination. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods, and the robustness against sparse user interaction data. The implementation codes are available at https://github.com/akaxlh/HCCF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1830455155",
                    "name": "Lianghao Xia"
                },
                {
                    "authorId": "2110926729",
                    "name": "Chao Huang"
                },
                {
                    "authorId": "2146648728",
                    "name": "Yong Xu"
                },
                {
                    "authorId": "2109974571",
                    "name": "Jiashu Zhao"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "672524688552788d319da3917dd7c7540cabc926",
            "title": "How to Approach Ambiguous Queries in Conversational Search: A Survey of Techniques, Approaches, Tools, and Challenges",
            "abstract": "The advent of recent Natural Language Processing technology has led human and machine interactions more toward conversation. In Conversational Search Systems (CSS) like chatbots and Virtual Personal Assistants such as Apple\u2019s Siri, Amazon Alexa, Microsoft\u2019s Cortana, and Google Assistant, both user and device have a limited platform to communicate through chatting or voice. In the information-seeking process, often users do not know how to properly describe their information need in a machine understandable language. Consequently, it is hard for the assistant agent to predict the user\u2019s intent and yield relevant results by only relying on the original query. Studies have shown many unsatisfactory results can be enhanced with the benefit of CSS, which can dig deeper into the user\u2019s query to reveal the real need. This survey intends to provide a comprehensive and comparative overview of ambiguous query clarification task in the context of conversational search technology. We investigate different approaches, their evaluation methods, and future work. We also address the importance of understanding a query for retrieving the most relevant document(s) and satisfying user\u2019s need by predicting their potential request. This work provides an overview of characteristics of ambiguous queries and contributes to better understanding of the existing technologies and challenges in CSS focus on disambiguation of unclear queries from various dimensions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166141141",
                    "name": "Kimiya Keyvan"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "d20b12b537b067ee2c966eb777654baaba2be3e9",
            "title": "Generating Factoid Questions with Question Type Enhanced Representation and Attention-based Copy Mechanism",
            "abstract": "Question generation over knowledge bases is an important research topic. How to deal with rare and low-frequency words in traditional generation models is a key challenge for question generation. Although the copy mechanism provides significant performance improvements, the original copy mechanism weakens the focus on aspect generation in the overall representations. In this article, we present a novel method to improve question generation with a question type enhanced representation and attention-based copy mechanism. The proposed method exploits the advantages of the generate mode in the copy mechanism and replaces objects in the factual triples with question types, which attempts to improve the output quality in the generate mode and effectively generate questions with proper interrogative words. We evaluate the proposed method on two standard benchmark datasets. The experimental results demonstrate that our proposed method can produce higher-quality questions than these of the Encoder-Decoder-based and CopyNet-based methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112321688",
                    "name": "Yue Hu"
                },
                {
                    "authorId": "3292660",
                    "name": "Haitong Yang"
                },
                {
                    "authorId": "143652253",
                    "name": "Guangyou Zhou"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                }
            ]
        },
        {
            "paperId": "2f196591ba950f5ef105c8f4fbee9f6c38136142",
            "title": "Neural Attention Frameworks for Explainable Recommendation",
            "abstract": "Neural attention, an emerging technique used to identify important inputs within neural networks, have become increasingly popular in the area of recommender systems. Not only allowing to better identify what defines users and items, attention-based recommender systems are further able to provide accompanying explanations. However, these representations usually capture only part of users\u2019 preferences and items\u2019 attributes, resulting in limited reasoning and accuracy. We therefore propose Dual Attention Recommender with Items and Attributes (DARIA), a novel approach able to combine two dependable neural attention mechanisms to better justify its suggestions. Utilizing the personalized history of users, DARIA identifies the most relevant past activities while considering the real-world features that contributed to the similarity. In addition, we adopt the novel approach of self-attention and introduce Self-Attention Recommender based on Attributes and History (SARAH). As a variation to DARIA, SARAH utilizes two self-attention components to describe users by their most characteristic past activities and items by their best depicting attributes. Various experiments establish the significant improvement of SARAH and DARIA over seven key baselines in diverse recommendation settings. By comparing our two proposed frameworks, we demonstrate the potential benefit of applying self-attention in different scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070494521",
                    "name": "Omer Tal"
                },
                {
                    "authorId": "46399556",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                },
                {
                    "authorId": "2139764431",
                    "name": "Xiaohui Yu"
                },
                {
                    "authorId": "1453731461",
                    "name": "Bushra Aljbawi"
                }
            ]
        }
    ]
}