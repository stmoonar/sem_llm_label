{
    "authorId": "2108020140",
    "papers": [
        {
            "paperId": "1725ad1d8cc0e539ac5d0a85657d5c95b4538c5e",
            "title": "Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects",
            "abstract": "Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages and disadvantages. To facilitate the experiments and validation of time series SSL methods, we also summarize datasets commonly used in time series forecasting, classification, anomaly detection, and clustering tasks. Finally, we present the future directions of SSL for time series analysis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2119059780",
                    "name": "Kexin Zhang"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2152737103",
                    "name": "Chaoli Zhang"
                },
                {
                    "authorId": "2136700261",
                    "name": "Rongyao Cai"
                },
                {
                    "authorId": "2072905592",
                    "name": "Ming Jin"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "72322304",
                    "name": "Y. Liang"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2585415",
                    "name": "Shirui Pan"
                }
            ]
        },
        {
            "paperId": "56230e01543e4e38ae50061990d2382eed3206f6",
            "title": "Automatic Deduction Path Learning via Reinforcement Learning with Environmental Correction",
            "abstract": "Automatic bill payment is an important part of business operations in fintech companies. The practice of deduction was mainly based on the total amount or heuristic search by dividing the bill into smaller parts to deduct as much as possible. This article proposes an end-to-end approach of automatically learning the optimal deduction paths (deduction amount in order), which reduces the cost of manual path design and maximizes the amount of successful deduction. Specifically, in view of the large search space of the paths and the extreme sparsity of historical successful deduction records, we propose a deep hierarchical reinforcement learning approach which abstracts the action into a two-level hierarchical space: an upper agent that determines the number of steps of deductions each day and a lower agent that decides the amount of deduction at each step. In such a way, the action space is structured via prior knowledge and the exploration space is reduced. Moreover, the inherited information incompleteness of the business makes the environment just partially observable. To be precise, the deducted amounts indicate merely the lower bounds of the available account balance. To this end, we formulate the problem as a partially observable Markov decision problem (POMDP) and employ an environment correction algorithm based on the characteristics of the business. In the world's largest electronic payment business, we have verified the effectiveness of this scheme offline and deployed it online to serve millions of users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216553545",
                    "name": "Shuai Xiao"
                },
                {
                    "authorId": "2220288252",
                    "name": "Chen Pan"
                },
                {
                    "authorId": "2157302650",
                    "name": "Min Wang"
                },
                {
                    "authorId": "8362224",
                    "name": "Xinxin Zhu"
                },
                {
                    "authorId": "2149919635",
                    "name": "Siqiao Xue"
                },
                {
                    "authorId": "2152449891",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "2167252593",
                    "name": "Yun Hu"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "2145121258",
                    "name": "Jinghua Feng"
                }
            ]
        },
        {
            "paperId": "5eedf94cb84612ed2091014321dfdf989293e5a8",
            "title": "Full Scaling Automation for Sustainable Development of Green Data Centers",
            "abstract": "The rapid rise in cloud computing has resulted in an alarming increase in data centers' carbon emissions, which now accounts for >3% of global greenhouse gas emissions, necessitating immediate steps to combat their mounting strain on the global climate. An important focus of this effort is to improve resource utilization in order to save electricity usage. Our proposed Full Scaling Automation (FSA) mechanism is an effective method of dynamically adapting resources to accommodate changing workloads in large-scale cloud computing clusters, enabling the clusters in data centers to maintain their desired CPU utilization target and thus improve energy efficiency. FSA harnesses the power of deep representation learning to accurately predict the future workload of each service and automatically stabilize the corresponding target CPU usage level, unlike the previous autoscaling methods, such as Autopilot or FIRM, that need to adjust computing resources with statistical models and expert knowledge. Our approach achieves significant performance improvement compared to the existing work in real-world datasets. We also deployed FSA on large-scale cloud computing clusters in industrial data centers, and according to the certification of the China Environmental United Certification Center (CEC), a reduction of 947 tons of carbon dioxide, equivalent to a saving of 1538,000 kWh of electricity, was achieved during the Double 11 shopping festival of 2022, marking a critical step for our company\u2019s strategic goal towards carbon neutrality by 2030.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128713436",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "2177453552",
                    "name": "Yinbo Sun"
                },
                {
                    "authorId": "2119204984",
                    "name": "X. Shi"
                },
                {
                    "authorId": "34827142",
                    "name": "Shiyi Zhu"
                },
                {
                    "authorId": "2231621304",
                    "name": "Linfao Ma"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "2215876533",
                    "name": "Yifei Zheng"
                },
                {
                    "authorId": "2216418586",
                    "name": "Jian Liu"
                }
            ]
        },
        {
            "paperId": "6b180f97412efe688d335f409a6589c1de6675a5",
            "title": "SLOTH: Structured Learning and Task-based Optimization for Time Series Forecasting on Hierarchies",
            "abstract": "Multivariate time series forecasting with hierarchical structure\nis widely used in real-world applications, e.g., sales\npredictions for the geographical hierarchy formed by cities,\nstates, and countries. The hierarchical time series (HTS) forecasting\nincludes two sub-tasks, i.e., forecasting and reconciliation.\nIn the previous works, hierarchical information is only\nintegrated in the reconciliation step to maintain coherency,\nbut not in forecasting step for accuracy improvement. In this\npaper, we propose two novel tree-based feature integration\nmechanisms, i.e., top-down convolution and bottom-up attention\nto leverage the information of the hierarchical structure\nto improve the forecasting performance. Moreover, unlike\nmost previous reconciliation methods which either rely\non strong assumptions or focus on coherent constraints only,\nwe utilize deep neural optimization networks, which not only\nachieve coherency without any assumptions, but also allow\nmore flexible and realistic constraints to achieve task-based\ntargets, e.g., lower under-estimation penalty and meaningful\ndecision-making loss to facilitate the subsequent downstream\ntasks. Experiments on real-world datasets demonstrate that\nour tree-based feature integration mechanism achieves superior\nperformances on hierarchical forecasting tasks compared\nto the state-of-the-art methods, and our neural optimization\nnetworks can be applied to real-world tasks effectively without\nany additional effort under coherence and task-based constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "100637212",
                    "name": "Fang-le Zhou"
                },
                {
                    "authorId": "2084643394",
                    "name": "Chenle Pan"
                },
                {
                    "authorId": "2115502966",
                    "name": "Lintao Ma"
                },
                {
                    "authorId": "2146402648",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "2128713436",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "2145144321",
                    "name": "Xinxin Zhu"
                },
                {
                    "authorId": "2149474513",
                    "name": "Xu Hu"
                },
                {
                    "authorId": "2167252593",
                    "name": "Yun Hu"
                },
                {
                    "authorId": "1720800802",
                    "name": "Yang Zheng"
                },
                {
                    "authorId": "2176802054",
                    "name": "Lei Lei"
                },
                {
                    "authorId": "2167252593",
                    "name": "Yun Hu"
                }
            ]
        },
        {
            "paperId": "cce94bcb0450131db4ca7f3d66ad60926e1297ca",
            "title": "Continual Learning in Predictive Autoscaling",
            "abstract": "Predictive Autoscaling is used to forecast the workloads of servers and prepare the resources in advance to ensure service level objectives (SLOs) in dynamic cloud environments. However, in practice, its prediction task often suffers from performance degradation under abnormal traffics caused by external events (such as sales promotional activities and applications' re-configurations), for which a common solution is to re-train the model with data of a long historical period, but at the expense of high computational and storage costs. To better address this problem, we propose a replay-based continual learning method, i.e., Density-based Memory Selection and Hint-based Network Learning Model (DMSHM), using only a small part of the historical log to achieve accurate predictions. First, we discover the phenomenon of sample overlap when applying replay-based continual learning in prediction tasks. In order to surmount this challenge and effectively integrate new sample distribution, we propose a density-based sample selection strategy that utilizes kernel density estimation to calculate sample density as a reference to compute sample weight, and employs weight sampling to construct a new memory set. Then we implement hint-based network learning based on hint representation to optimize the parameters. Finally, we conduct experiments on public and industrial datasets to demonstrate that our proposed method outperforms state-of-the-art continual learning methods in terms of memory capacity and prediction accuracy. Furthermore, we demonstrate remarkable practicability of DMSHM in real industrial applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065513241",
                    "name": "Hongyan Hao"
                },
                {
                    "authorId": "1491708389",
                    "name": "Zhixuan Chu"
                },
                {
                    "authorId": "34827142",
                    "name": "Shiyi Zhu"
                },
                {
                    "authorId": "66129075",
                    "name": "Gangwei Jiang"
                },
                {
                    "authorId": "2152544063",
                    "name": "Yan Wang"
                },
                {
                    "authorId": "2109256934",
                    "name": "Caigao Jiang"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "2152123961",
                    "name": "Wei Jiang"
                },
                {
                    "authorId": "2149919635",
                    "name": "Siqiao Xue"
                },
                {
                    "authorId": "2151553113",
                    "name": "Junqing Zhou"
                }
            ]
        },
        {
            "paperId": "58e4eb1967c38840b0ecf24f26e8f3f1a13ab8a7",
            "title": "Learning Large-scale Universal User Representation with Sparse Mixture of Experts",
            "abstract": "Learning user sequence behaviour embedding is very sophisticated and challenging due to the complicated feature interactions over time and high dimensions of user features. Recent emerging foundation models, e.g., BERT and its variants, encourage a large body of researchers to investigate in this field. However, unlike natural language processing (NLP) tasks, the parameters of user behaviour model come mostly from user embedding layer, which makes most existing works fail in training a universal user embedding of large scale. Furthermore, user representations are learned from multiple downstream tasks, and the past research work do not address the seesaw phenomenon. In this paper, we propose SUPERMOE, a generic framework to obtain high quality user representation from multiple tasks. Specifically, the user behaviour sequences are encoded by MoE transformer, and we can thus increase the model capacity to billions of parameters, or even to trillions of parameters. In order to deal with seesaw phenomenon when learning across multiple tasks, we design a new loss function with task indicators. We perform extensive offline experiments on public datasets and online experiments on private real-world business scenarios. Our approach achieves the best performance over state-of-the-art models, and the results demonstrate the effectiveness of our framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109256934",
                    "name": "Caigao Jiang"
                },
                {
                    "authorId": "2149919635",
                    "name": "Siqiao Xue"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "2146022784",
                    "name": "Lingyue Liu"
                },
                {
                    "authorId": "49658826",
                    "name": "Zhibo Zhu"
                },
                {
                    "authorId": "2065513241",
                    "name": "Hongyan Hao"
                }
            ]
        },
        {
            "paperId": "5fb615d405ae37173e889b6d99b65ed508aafb6c",
            "title": "End-to-End Modeling of Hierarchical Time Series Using Autoregressive Transformer and Conditional Normalizing Flow-based Reconciliation",
            "abstract": "Multivariate time series forecasting with hierarchi-cal structure is pervasive in real-world applications, demanding not only predicting each level of the hierarchy, but also recon-ciling all forecasts to ensure coherency, i.e., the forecasts should satisfy the hierarchical aggregation constraints. Moreover, the disparities of statistical characteristics between levels can be huge, worsened by non-Gaussian distributions and non-linear correlations. To this extent, we propose a novel end-to-end hierarchical time series forecasting model, based on conditioned normalizing flow-based autoregressive transformer reconciliation, to represent complex data distribution while simultaneously reconciling the forecasts to ensure coherency. Unlike other state-of-the-art methods, we achieve the forecasting and reconciliation simultaneously without requiring any explicit post-processing step. In addition, by harnessing the power of deep model, we do not rely on any assumption such as unbiased estimates or Gaussian distribution. Our evaluation experiments are conducted on four real-world hierarchical datasets from different industrial domains (three public ones and a dataset from the application servers of Alipay11Alipay is the world's leading company in payment technology. https:/len.wikipedia.org/wiki/Alipay) and the preliminary results demonstrate efficacy of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128713436",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "2114904451",
                    "name": "Fan Zhou"
                },
                {
                    "authorId": "2177453552",
                    "name": "Yinbo Sun"
                },
                {
                    "authorId": "2115502966",
                    "name": "Lintao Ma"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "1720800802",
                    "name": "Yang Zheng"
                },
                {
                    "authorId": "2176802054",
                    "name": "Lei Lei"
                },
                {
                    "authorId": "2167252593",
                    "name": "Yun Hu"
                }
            ]
        },
        {
            "paperId": "7cf779d889dbf155e089289bab1495be2b186b11",
            "title": "Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes",
            "abstract": "We consider a sequential decision making problem where the agent faces the environment characterized by the stochastic discrete events and seeks an optimal intervention policy such that its long-term reward is maximized. This problem exists ubiquitously in social media, finance and health informatics but is rarely investigated by the conventional research in reinforcement learning. To this end, we present a novel framework of the model-based reinforcement learning where the agent's actions and observations are asynchronous stochastic discrete events occurring in continuous-time. We model the dynamics of the environment by Hawkes process with external intervention control term and develop an algorithm to embed such process in the Bellman equation which guides the direction of the value gradient. We demonstrate the superiority of our method in both synthetic simulator and real-data experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064702529",
                    "name": "C. Qu"
                },
                {
                    "authorId": "2153585312",
                    "name": "Xiaoyu Tan"
                },
                {
                    "authorId": "2149919635",
                    "name": "Siqiao Xue"
                },
                {
                    "authorId": "2119204984",
                    "name": "X. Shi"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "33344744",
                    "name": "Hongyuan Mei"
                }
            ]
        },
        {
            "paperId": "8f502a85ed14fecab7c04d3523ef01458e5e8d1d",
            "title": "A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud",
            "abstract": "Predictive autoscaling (autoscaling with workload forecasting) is an important mechanism that supports autonomous adjustment of computing resources in accordance with fluctuating workload demands in the Cloud. In recent works, Reinforcement Learning (RL) has been introduced as a promising approach to learn the resource management policies to guide the scaling actions under the dynamic and uncertain cloud environment. However, RL methods face the following challenges in steering predictive autoscaling, such as lack of accuracy in decision-making, inefficient sampling and significant variability in workload patterns that may cause policies to fail at test time. To this end, we propose an end-to-end predictive meta model-based RL algorithm, aiming to optimally allocate resource to maintain a stable CPU utilization level, which incorporates a specially-designed deep periodic workload prediction model as the input and embeds the Neural Process [11, 16] to guide the learning of the optimal scaling actions over numerous application services in the Cloud. Our algorithm not only ensures the predictability and accuracy of the scaling strategy, but also enables the scaling decisions to adapt to the changing workloads with high sample efficiency. Our method has achieved significant performance improvement compared to the existing algorithms and has been deployed online at Alipay, supporting the autoscaling of applications for the world-leading payment platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149919635",
                    "name": "Siqiao Xue"
                },
                {
                    "authorId": "2064702529",
                    "name": "C. Qu"
                },
                {
                    "authorId": "2119204984",
                    "name": "X. Shi"
                },
                {
                    "authorId": "2167153231",
                    "name": "Cong Liao"
                },
                {
                    "authorId": "34827142",
                    "name": "Shiyi Zhu"
                },
                {
                    "authorId": "2153585312",
                    "name": "Xiaoyu Tan"
                },
                {
                    "authorId": "2115502966",
                    "name": "Lintao Ma"
                },
                {
                    "authorId": "2128713436",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "2108620748",
                    "name": "Shijun Wang"
                },
                {
                    "authorId": "2167252593",
                    "name": "Yun Hu"
                },
                {
                    "authorId": "2066702326",
                    "name": "Lei Lei"
                },
                {
                    "authorId": "1720800802",
                    "name": "Yang Zheng"
                },
                {
                    "authorId": "2118506218",
                    "name": "Jianguo Li"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                }
            ]
        },
        {
            "paperId": "bbddfa0b214f47df4a5d47640b770de7804108e7",
            "title": "Memory Augmented State Space Model for Time Series Forecasting",
            "abstract": "State space model (SSM) provides a general and flexible forecasting framework for time series. Conventional SSM with fixed-order Markovian assumption often falls short in handling the long-range temporal dependencies and/or highly non-linear correlation in time-series data, which is crucial for accurate forecasting. To this extend, we present External Memory Augmented State Space Model (EMSSM) within the sequential Monte Carlo (SMC) framework. Unlike the common fixed-order Markovian SSM, our model features an external memory system, in which we store informative latent state experience, whereby to create ``memoryful\" latent dynamics modeling complex long-term dependencies. Moreover, conditional normalizing flows are incorporated in our emission model, enabling the adaptation to a broad class of underlying data distributions. We further propose a Monte Carlo Objective that employs an efficient variational proposal distribution, which fuses the filtering and the dynamic prior information, to approximate the posterior state with proper particles. Our results demonstrate the competitiveness of forecasting performance of our proposed model comparing with other state-of-the-art SSMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2177453552",
                    "name": "Yinbo Sun"
                },
                {
                    "authorId": "2115502966",
                    "name": "Lintao Ma"
                },
                {
                    "authorId": "2257024328",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "2108620748",
                    "name": "Shijun Wang"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "1720800802",
                    "name": "Yang Zheng"
                },
                {
                    "authorId": "2176799518",
                    "name": "Hu Yun"
                },
                {
                    "authorId": "2176802054",
                    "name": "Lei Lei"
                },
                {
                    "authorId": "2182514010",
                    "name": "Yulin Kang"
                },
                {
                    "authorId": "2176803651",
                    "name": "Llinbao Ye"
                }
            ]
        }
    ]
}