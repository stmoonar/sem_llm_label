{
    "authorId": "37866790",
    "papers": [
        {
            "paperId": "a24ab4c0d758fa62ce18ce8afa2d904563c365c8",
            "title": "Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset",
            "abstract": "Users in consumption domains, like music, are often able to more efficiently provide preferences over a set of items (e.g. a playlist or radio) than over single items (e.g. songs). Unfortunately, this is an underexplored area of research, with most existing recommendation systems limited to understanding preferences over single items. Curating an item set exponentiates the search space that recommender systems must consider (all subsets of items!): this motivates conversational approaches-where users explicitly state or refine their preferences and systems elicit preferences in natural language-as an efficient way to understand user needs. We call this task conversational item set curation and present a novel data collection methodology that efficiently collects realistic preferences about item sets in a conversational setting by observing both item-level and set-level feedback. We apply this methodology to music recommendation to build the Conversational Playlist Curation Dataset (CPCD), where we show that it leads raters to express preferences that would not be otherwise expressed. Finally, we propose a wide range of conversational retrieval models as baselines for this task and evaluate them on the dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2719924",
                    "name": "Arun Tejasvi Chaganty"
                },
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "2108088736",
                    "name": "Shu Zhang"
                },
                {
                    "authorId": "1958631",
                    "name": "R. Ganti"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                },
                {
                    "authorId": "1803571",
                    "name": "Filip Radlinski"
                }
            ]
        },
        {
            "paperId": "be4e245c8359b3dac52016106436cc2fe52b6142",
            "title": "Demonstration of Geyser: Provenance Extraction and Applications over Data Science Scripts",
            "abstract": "As enterprises have started developing and deploying complicated data science workloads at scale, the need for mechanisms that enable enterprise-grade data science (e.g., compliance or auditing) has become more pronounced. In this paper, we present Geyser, an extensible provenance system for data science workloads that can be used as a foundation for enterprise-grade data science. Our system supports both static and dynamic provenance, over a wide range of data science scripts, driven by a knowledge base of data science APIs. We demonstrate the wide applicability of the system using various industrial applications: provenance extraction, model compliance, model linting, model versioning, and poisoning detection. A video of the demonstration is available at https://aka.ms/geyserdemo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2493657",
                    "name": "Fotis Psallidas"
                },
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "2872113",
                    "name": "M. Namaki"
                },
                {
                    "authorId": "2327080",
                    "name": "Avrilia Floratou"
                },
                {
                    "authorId": "9490513",
                    "name": "Ashvin Agrawal"
                },
                {
                    "authorId": "2687553",
                    "name": "Konstantinos Karanasos"
                },
                {
                    "authorId": "2494730",
                    "name": "Subru Krishnan"
                },
                {
                    "authorId": "2672375",
                    "name": "Pavle Suboti\u0107"
                },
                {
                    "authorId": "2965406",
                    "name": "Markus Weimer"
                },
                {
                    "authorId": "2948541",
                    "name": "Yinghui Wu"
                },
                {
                    "authorId": "2139103184",
                    "name": "Yiwen Zhu"
                }
            ]
        },
        {
            "paperId": "c0f1fb3314b42aeff192bcee8a723cb35cabd78e",
            "title": "Generating Synthetic Data for Conversational Music Recommendation Using Random Walks and Language Models",
            "abstract": "Conversational recommendation systems (CRSs) enable users to use natural language feedback to control their recommendations, overcoming many of the challenges of traditional recommendation systems. However, the practical adoption of CRSs remains limited due to a lack of rich and diverse conversational training data that pairs user utterances with recommendations. To address this problem, we introduce a new method to generate synthetic training data by transforming curated item collections, such as playlists or movie watch lists, into item-seeking conversations. First, we use a biased random walk to generate a sequence of slates, or sets of item recommendations; then, we use a language model to generate corresponding user utterances. We demonstrate our approach by generating a conversational music recommendation dataset with over one million conversations, which were found to be consistent with relevant recommendations by a crowdsourced evaluation. Using the synthetic data to train a CRS, we significantly outperform standard retrieval baselines in offline and online evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "1958631",
                    "name": "R. Ganti"
                },
                {
                    "authorId": "2108088736",
                    "name": "Shu Zhang"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                },
                {
                    "authorId": "2065812052",
                    "name": "Filip Radlinski"
                },
                {
                    "authorId": "2067616758",
                    "name": "Fernando Pereira"
                },
                {
                    "authorId": "2719924",
                    "name": "Arun Tejasvi Chaganty"
                }
            ]
        },
        {
            "paperId": "f32dd0fcb421aaf96593dc9c4be740a1399c9e64",
            "title": "Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation",
            "abstract": "Recommender systems are ubiquitous yet often difficult for users to control, and adjust if recommendation quality is poor. This has motivated conversational recommender systems (CRSs), with control provided through natural language feedback. However, as with most application domains, building robust CRSs requires training data that reflects system usage$\\unicode{x2014}$here conversations with user utterances paired with items that cover a wide range of preferences. This has proved challenging to collect scalably using conventional methods. We address the question of whether it can be generated synthetically, building on recent advances in natural language. We evaluate in the setting of item set recommendation, noting the increasing attention to this task motivated by use cases like music, news, and recipe recommendation. We present TalkTheWalk, which synthesizes realistic high-quality conversational data by leveraging domain expertise encoded in widely available curated item collections, generating a sequence of hypothetical yet plausible item sets, then using a language model to produce corresponding user utterances. We generate over one million diverse playlist curation conversations in the music domain, and show these contain consistent utterances with relevant item sets nearly matching the quality of an existing but small human-collected dataset for this task. We demonstrate the utility of the generated synthetic dataset on a conversational item retrieval task and show that it improves over both unsupervised baselines and systems trained on a real dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "1958631",
                    "name": "R. Ganti"
                },
                {
                    "authorId": "2108088736",
                    "name": "Shu Zhang"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                },
                {
                    "authorId": "2065812052",
                    "name": "Filip Radlinski"
                },
                {
                    "authorId": "2067616758",
                    "name": "Fernando Pereira"
                },
                {
                    "authorId": "2719924",
                    "name": "Arun Tejasvi Chaganty"
                }
            ]
        },
        {
            "paperId": "b4c793fc05644979b405e79d9a6112dcbf85b11c",
            "title": "TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval",
            "abstract": "Entity retrieval\u2014retrieving information about entity mentions in a query\u2014is a key step in open-domain tasks, such as question answering or fact checking. However, state-of-the-art entity retrievers struggle to retrieve rare entities for ambiguous mentions due to biases towards popular entities. Incorporating knowledge graph types during training could help overcome popularity biases, but there are several challenges: (1) existing type-based retrieval methods require mention boundaries as input, but open-domain tasks run on unstructured text, (2) type-based methods should not compromise overall performance, and (3) type-based methods should be robust to noisy and missing types. In this work, we introduce TABi, a method to jointly train bi-encoders on knowledge graph types and unstructured text for entity retrieval for open-domain tasks. TABi leverages a type-enforced contrastive loss to encourage entities and queries of similar types to be close in the embedding space. TABi improves retrieval of rare entities on the Ambiguous Entity Retrieval (AmbER) sets, while maintaining strong overall retrieval performance on open-domain tasks in the KILT benchmark compared to state-of-the-art retrievers. TABi is also robust to incomplete type systems, improving rare entity retrieval over baselines with only 5% type coverage of the training dataset. We make our code publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "49577833",
                    "name": "Daniel Y. Fu"
                },
                {
                    "authorId": "48622329",
                    "name": "Mayee F. Chen"
                },
                {
                    "authorId": "2061444681",
                    "name": "Christopher R'e"
                }
            ]
        },
        {
            "paperId": "6b3f7927d69ed1ba338bb94221f51b996ec370ac",
            "title": "Managing ML Pipelines: Feature Stores and the Coming Wave of Embedding Ecosystems",
            "abstract": "The industrial machine learning pipeline requires iterating on model features, training and deploying models, and monitoring deployed models at scale. Feature stores were developed to manage and standardize the engineer's workflow in this end-to-end pipeline, focusing on traditional tabular feature data. In recent years, however, model development has shifted towards using self-supervised pretrained embeddings as model features. Managing these embeddings and the downstream systems that use them introduces new challenges with respect to managing embedding training data, measuring embedding quality, and monitoring downstream models that use embeddings. These challenges are largely unaddressed in standard feature stores. Our goal in this tutorial is to introduce the feature store system and discuss the challenges and current solutions to managing these new embedding-centric pipelines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4773175",
                    "name": "Laurel J. Orr"
                },
                {
                    "authorId": "2123005528",
                    "name": "Atindriyo Sanyal"
                },
                {
                    "authorId": "145787377",
                    "name": "Xiao Ling"
                },
                {
                    "authorId": "1822288",
                    "name": "Karan Goel"
                },
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                }
            ]
        },
        {
            "paperId": "fdcffd9d14ed1a1d9ab39eed8250f58f7839919d",
            "title": "Cross-Domain Data Integration for Named Entity Disambiguation in Biomedical Text",
            "abstract": "Named entity disambiguation (NED), which involves mapping textual mentions to structured entities, is particularly challenging in the medical domain due to the presence of rare entities. Existing approaches are limited by the presence of coarse-grained structural resources in biomedical knowledge bases as well as the use of training datasets that provide low coverage over uncommon resources. In this work, we address these issues by proposing a cross-domain data integration method that transfers structural knowledge from a general text knowledge base to the medical domain. We utilize our integration scheme to augment structural resources and generate a large biomedical NED dataset for pretraining. Our pretrained model with injected structural knowledge achieves state-of-the-art performance on two benchmark medical NED datasets: MedMentions and BC5CDR. Furthermore, we improve disambiguation of rare entities by up to 57 accuracy points.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145859954",
                    "name": "M. Varma"
                },
                {
                    "authorId": "4773175",
                    "name": "Laurel J. Orr"
                },
                {
                    "authorId": "144766615",
                    "name": "Sen Wu"
                },
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "2125181001",
                    "name": "Xiao Ling"
                },
                {
                    "authorId": "2061444681",
                    "name": "Christopher R'e"
                }
            ]
        },
        {
            "paperId": "2ccf080582aba40d74adbecfac5aa66dacb96816",
            "title": "Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation",
            "abstract": "A challenge for named entity disambiguation (NED), the task of mapping textual mentions to entities in a knowledge base, is how to disambiguate entities that appear rarely in the training data, termed tail entities. Humans use subtle reasoning patterns based on knowledge of entity facts, relations, and types to disambiguate unfamiliar entities. Inspired by these patterns, we introduce Bootleg, a self-supervised NED system that is explicitly grounded in reasoning patterns for disambiguation. We define core reasoning patterns for disambiguation, create a learning procedure to encourage the self-supervised model to learn the patterns, and show how to use weak supervision to enhance the signals in the training data. Encoding the reasoning patterns in a simple Transformer architecture, Bootleg meets or exceeds state-of-the-art on three NED benchmarks. We further show that the learned representations from Bootleg successfully transfer to other non-disambiguation tasks that require entity-based knowledge: we set a new state-of-the-art in the popular TACRED relation extraction task by 1.0 F1 points and demonstrate up to 8% performance lift in highly optimized production search and assistant tasks at a major technology company",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4773175",
                    "name": "Laurel J. Orr"
                },
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "47038321",
                    "name": "Simran Arora"
                },
                {
                    "authorId": "144766615",
                    "name": "Sen Wu"
                },
                {
                    "authorId": "2820009",
                    "name": "Neel Guha"
                },
                {
                    "authorId": "145787377",
                    "name": "Xiao Ling"
                },
                {
                    "authorId": "2114485554",
                    "name": "C. R\u00e9"
                }
            ]
        },
        {
            "paperId": "79be0a97213a38ea60a5cabb7421b3963fdc81c0",
            "title": "Understanding the Downstream Instability of Word Embeddings",
            "abstract": "Many industrial machine learning (ML) systems require frequent retraining to keep up-to-date with constantly changing data. This retraining exacerbates a large challenge facing ML systems today: model training is unstable, i.e., small changes in training data can cause significant changes in the model's predictions. In this paper, we work on developing a deeper understanding of this instability, with a focus on how a core building block of modern natural language processing (NLP) pipelines---pre-trained word embeddings---affects the instability of downstream NLP models. We first empirically reveal a tradeoff between stability and memory: increasing the embedding memory 2x can reduce the disagreement in predictions due to small changes in training data by 5% to 37% (relative). To theoretically explain this tradeoff, we introduce a new measure of embedding instability---the eigenspace instability measure---which we prove bounds the disagreement in downstream predictions introduced by the change in word embeddings. Practically, we show that the eigenspace instability measure can be a cost-effective way to choose embedding parameters to minimize instability without training downstream models, outperforming other embedding distance measures and performing competitively with a nearest neighbor-based measure. Finally, we demonstrate that the observed stability-memory tradeoffs extend to other types of embeddings as well, including knowledge graph and contextual word embeddings.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "40353015",
                    "name": "Avner May"
                },
                {
                    "authorId": "2151810148",
                    "name": "Jian Zhang"
                },
                {
                    "authorId": "144766615",
                    "name": "Sen Wu"
                },
                {
                    "authorId": "145284500",
                    "name": "Christopher R. Aberger"
                },
                {
                    "authorId": "1803218",
                    "name": "Christopher R\u00e9"
                }
            ]
        },
        {
            "paperId": "a68c3412e60560290400d2707596f82a914b7c00",
            "title": "Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps",
            "abstract": "Modern neural network architectures use structured linear transformations, such as low-rank matrices, sparse matrices, permutations, and the Fourier transform, to improve inference speed and reduce memory usage compared to general linear maps. However, choosing which of the myriad structured transformations to use (and its associated parameterization) is a laborious task that requires trading off speed, space, and accuracy. We consider a different approach: we introduce a family of matrices called kaleidoscope matrices (K-matrices) that provably capture any structured matrix with near-optimal space (parameter) and time (arithmetic operation) complexity. We empirically validate that K-matrices can be automatically learned within end-to-end pipelines to replace hand-crafted procedures, in order to improve model quality. For example, replacing channel shuffles in ShuffleNet improves classification accuracy on ImageNet by up to 5%. Learnable K-matrices can also simplify hand-engineered pipelines---we replace filter bank feature computation in speech data preprocessing with a kaleidoscope layer, resulting in only 0.4% loss in accuracy on the TIMIT speech recognition task. K-matrices can also capture latent structure in models: for a challenging permuted image classification task, adding a K-matrix to a standard convolutional architecture can enable learning the latent permutation and improve accuracy by over 8 points. We provide a practically efficient implementation of our approach, and use K-matrices in a Transformer network to attain 36% faster end-to-end inference speed on a language translation task.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "24593911",
                    "name": "Tri Dao"
                },
                {
                    "authorId": "145193121",
                    "name": "N. Sohoni"
                },
                {
                    "authorId": "39499001",
                    "name": "Albert Gu"
                },
                {
                    "authorId": "41022841",
                    "name": "Matthew Eichhorn"
                },
                {
                    "authorId": "1581517872",
                    "name": "Amit Blonder"
                },
                {
                    "authorId": "37866790",
                    "name": "Megan Leszczynski"
                },
                {
                    "authorId": "1755572",
                    "name": "A. Rudra"
                },
                {
                    "authorId": "1803218",
                    "name": "Christopher R\u00e9"
                }
            ]
        }
    ]
}