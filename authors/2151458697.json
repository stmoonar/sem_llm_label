{
    "authorId": "2151458697",
    "papers": [
        {
            "paperId": "4c19e9d2f0da6e28f53617f355fb58f53b2f3aca",
            "title": "Graph Contrastive Invariant Learning from the Causal Perspective",
            "abstract": "Graph contrastive learning (GCL), learning the node representation by contrasting two augmented graphs in a self-supervised way, has attracted considerable attention. GCL is usually believed to learn the invariant representation. However, does this understanding always hold in practice? In this paper, we first study GCL from the perspective of causality. By analyzing GCL with the structural causal model (SCM), we discover that traditional GCL may not well learn the invariant representations due to the non-causal information contained in the graph. How can we fix it and encourage the current GCL to learn better invariant representations? The SCM offers two requirements and motives us to propose a novel GCL method. Particularly, we introduce the spectral graph augmentation to simulate the intervention upon non-causal factors. Then we design the invariance objective and independence objective to better capture the causal factors. Specifically, (i) the invariance objective encourages the encoder to capture the invariant information contained in causal variables, and (ii) the independence objective aims to reduce the influence of confounders on the causal variables. Experimental results demonstrate the effectiveness of our approach on node classification tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186301319",
                    "name": "Yanhu Mo"
                },
                {
                    "authorId": "2118449003",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "48635390",
                    "name": "Shaohua Fan"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "c9845a625e2dac5e32db172d353f81d377760a5f",
            "title": "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
            "abstract": "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (CIT) mechanism (Code available at https://github.com/BUPT-GAMMA/CITGNN), which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290074141",
                    "name": "Donglin Xia"
                },
                {
                    "authorId": "2118449003",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2087010708",
                    "name": "Nian Liu"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "f02237ed9eef969fc60656c2355aab1f81b04aa2",
            "title": "Graph Fairness Learning under Distribution Shifts",
            "abstract": "Graph neural networks (GNNs) have achieved remarkable performance on graph-structured data. However, GNNs may inherit prejudice from the training data and make discriminatory predictions based on sensitive attributes, such as gender and race. Recently, there has been an increasing interest in ensuring fairness on GNNs, but all of them are under the assumption that the training and testing data are under the same distribution, i.e., training data and testing data are from the same graph. Will graph fairness performance decrease under distribution shifts? How does distribution shifts affect graph fairness learning? All these open questions are largely unexplored from a theoretical perspective. To answer these questions, we first theoretically identify the factors that determine bias on a graph. Subsequently, we explore the factors influencing fairness on testing graphs, with a noteworthy factor being the representation distances of certain groups between the training and testing graph. Motivated by our theoretical analysis, we propose our framework FatraGNN. Specifically, to guarantee fairness performance on unknown testing graphs, we propose a graph generator to produce numerous graphs with significant bias and under different distributions. Then we minimize the representation distances for each certain group between the training graph and generated graphs. This empowers our model to achieve high classification and fairness performance even on generated graphs with significant bias, thereby effectively handling unknown testing graphs. Experiments on real-world and semi-synthetic datasets demonstrate the effectiveness of our model in terms of both accuracy and fairness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274190647",
                    "name": "Yibo Li"
                },
                {
                    "authorId": "2118449003",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2281845717",
                    "name": "Yujie Xing"
                },
                {
                    "authorId": "48635390",
                    "name": "Shaohua Fan"
                },
                {
                    "authorId": "144902428",
                    "name": "Ruijia Wang"
                },
                {
                    "authorId": "2187868315",
                    "name": "Yaoqi Liu"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "289496506a60b17622963cafbf7d7f8ecb0c09ce",
            "title": "Towards Adaptive Information Fusion in Graph Convolutional Networks",
            "abstract": "Graph Convolutional Networks (GCNs) have gained great popularity in tackling various analytic tasks on graph and network data. However, some recent studies raise concerns about whether GCNs can optimally integrate node features and topological structures in a complex graph. In this paper, we first present an experimental investigation. Surprisingly, our experimental results clearly show that the capability of the state-of-the-art GCNs in fusing node features and topological structures is distant from optimal or even satisfactory. The weakness may severely hinder the capability of GCNs in some classification tasks, since GCNs may not be able to adaptively learn some deep correlation information between topological structures and node features. Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and, at the same time, enhance the capability of fusing topological structures and node features substantially? We tackle the challenge and propose an Adaptive Multi-channel Graph Convolutional Network for semi-supervised classification (AM-GCN). The central idea is that we extract the specific and common embeddings from node features, topological structures, and their combinations simultaneously, and use the attention mechanism to learn adaptive importance weights of the embeddings. However, considering that the input topology and feature structure in AM-GCN are still predefined and fixed, once the properties of graph structures are not consistent with tasks, the fusion performance of AM-GCN will be hindered from the beginning. Therefore, we need to adjust the structure and further propose the Label Propagation guided Multi-channel Graph Convolutional Network (LPM-GCN). LPM-GCN introduces edge weights learning on both topology and feature spaces to improve structural homophily, which can better promote the fusion process of graph convolutional networks. Our extensive experiments on benchmark data sets clearly show that our proposed models extract the most correlated information from both node features and topological structures substantially, and improves the classification accuracy with a clear margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109834004",
                    "name": "Meiqi Zhu"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                },
                {
                    "authorId": "2155425867",
                    "name": "Yibo Li"
                },
                {
                    "authorId": "8491162",
                    "name": "Junping Du"
                }
            ]
        },
        {
            "paperId": "32a35e04a32cf62459181538899847bf89504568",
            "title": "A Post-Training Framework for Improving Heterogeneous Graph Neural Networks",
            "abstract": "Recent years have witnessed the success of heterogeneous graph neural networks (HGNNs) in modeling heterogeneous information networks (HINs). In this paper, we focus on the benchmark task of HGNNs, i.e., node classification, and empirically find that typical HGNNs are not good at predicting the label of a test node whose receptive field (1) has few training nodes from the same category or (2) has multiple training nodes from different categories. A possible explanation is that their message passing mechanisms may involve noises from different categories, and cannot fully explore task-specific knowledge such as the label dependency between distant nodes. Therefore, instead of introducing a new HGNN model, we propose a general post-training framework that can be applied on any pretrained HGNNs to further inject task-specific knowledge and enhance their prediction performance. Specifically, we first design an auxiliary system that estimates node labels based on (1) a global inference module of multi-channel label propagation and (2) a local inference module of network schema-aware prediction. The mechanism of our auxiliary system can complement the pretrained HGNNs by providing extra task-specific knowledge. During the post-training process, we will strengthen both system-level and module-level consistencies to encourage the cooperation between a pretrained HGNN and our auxiliary system. In this way, both systems can learn from each other for better performance. In experiments, we apply our framework to four typical HGNNs. Experimental results on three benchmark datasets show that compared with pretrained HGNNs, our post-training framework can enhance Micro-F1 by a relative improvement of on average. Code, data and appendix are available at https://github.com/GXM1141/HGPF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3443627",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "2152012853",
                    "name": "Xumeng Gong"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "4d6030acebbe27f741263cced24b2a97b8b54e47",
            "title": "Hierarchical Contrastive Learning Enhanced Heterogeneous Graph Neural Network",
            "abstract": "Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-view contrastive mechanism. Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively supervise each other and finally learn high-level node embeddings. Moreover, to further boost the performance of HeCo, two additional methods are designed to generate harder negative samples with high quality. The essence of HeCo is to make positive samples from different views close to each other by cross-view contrast, and learn the factors invariant to two proposed views. However, besides the invariant factors, view-specific factors complementally provide the diverse structure information between different nodes, which also should be contained into the final embeddings. Therefore, we need to further explore each view independently and propose a modified model, called HeCo++. Specifically, HeCo++ conducts hierarchical contrastive learning, including cross-view and intra-view contrasts, which aims to enhance the mining of respective structures. Extensive experiments conducted on a variety of real-world networks show the superior performance of the proposed methods over the state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087010708",
                    "name": "Nian Liu"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2112488351",
                    "name": "Hui-jun Han"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "5a51ed549a1cb45c71d077ddb1cef2c279a60766",
            "title": "Clustering-Based Supervised Contrastive Learning for Identifying Risk Items on Heterogeneous Graph",
            "abstract": "Risk item identification is vital for protecting the health of ecommerce trades. Existing solutions prefer to model structure information besides item attributes and optimize parameters in cross-entropy (CE) manners. However, the few labeled and imbalanced supervision in real-world scenarios usually results in poor generalization of CE optimization. More seriously, the pattern-level difference of risk items is often neglected in binary supervised learning, leading to limited performance. In this paper, we propose a novel Clustering-based Supervised Contrastive Learning (CSCL) to address the two challenges. CSCL first devises a contrastive heterogeneous graph neural network that fully exploits multiple risk relations in contrastive learning, keeping generalization performance. It then designs a clustering-based reweighted sampling strategy to search informative positive and negative training instances for effective pattern-level optimization. We test the performance on Xianyu Platform, and experimental results demonstrate that CSCL outperforms all baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112329744",
                    "name": "Ao Li"
                },
                {
                    "authorId": "3441331",
                    "name": "Yugang Ji"
                },
                {
                    "authorId": "2115980095",
                    "name": "Guanyi Chu"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2206556022",
                    "name": "Dong Li"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "60057b812d3170c9f7ad15fcecbc8b55672f89ae",
            "title": "A Generalized Neural Diffusion Framework on Graphs",
            "abstract": "Recent studies reveal the connection between GNNs and the diffusion process, which motivates many diffusion based GNNs to be proposed. However, since these two mechanisms are closely related, one fundamental question naturally arises: Is there a general diffusion framework that can formally unify these GNNs? The answer to this question can not only deepen our understanding of the learning process of GNNs, but also may open a new door to design a broad new class of GNNs. In this paper, we propose a general diffusion equation framework with the fidelity term, which formally establishes the relationship between the diffusion process with more GNNs. Meanwhile, with this framework, we identify one characteristic of graph diffusion networks, i.e., the current neural diffusion process only corresponds to the first-order diffusion equation. However, by an experimental investigation, we show that the labels of high-order neighbors actually appear monophily property, which induces the similarity based on labels among high-order neighbors without requiring the similarity among first-order neighbors. This discovery motives to design a new high-order neighbor-aware diffusion equation, and derive a new type of graph diffusion network (HiD-Net) based on the framework. With the high-order diffusion equation, HiD-Net is more robust against attacks and works on both homophily and heterophily graphs. We not only theoretically analyze the relation between HiD-Net with high-order random walk, but also provide a theoretical convergence guarantee. Extensive experimental results well demonstrate the effectiveness of HiD-Net over state-of-the-art graph diffusion networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274190647",
                    "name": "Yibo Li"
                },
                {
                    "authorId": "2118449003",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2274205897",
                    "name": "Hongrui Liu"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "76d04818252ccb87f38c8ea8a02bc700b4519f5a",
            "title": "Provable Training for Graph Contrastive Learning",
            "abstract": "Graph Contrastive Learning (GCL) has emerged as a popular training approach for learning node embeddings from augmented graphs without labels. Despite the key principle that maximizing the similarity between positive node pairs while minimizing it between negative node pairs is well established, some fundamental problems are still unclear. Considering the complex graph structure, are some nodes consistently well-trained and following this principle even with different graph augmentations? Or are there some nodes more likely to be untrained across graph augmentations and violate the principle? How to distinguish these nodes and further guide the training of GCL? To answer these questions, we first present experimental evidence showing that the training of GCL is indeed imbalanced across all nodes. To address this problem, we propose the metric\"node compactness\", which is the lower bound of how a node follows the GCL principle related to the range of augmentations. We further derive the form of node compactness theoretically through bound propagation, which can be integrated into binary cross-entropy as a regularization. To this end, we propose the PrOvable Training (POT) for GCL, which regularizes the training of GCL to encode node embeddings that follows the GCL principle better. Through extensive experiments on various benchmarks, POT consistently improves the existing GCL approaches, serving as a friendly plugin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1633124736",
                    "name": "Yue Yu"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "16003017",
                    "name": "Mengmei Zhang"
                },
                {
                    "authorId": "2087010708",
                    "name": "Nian Liu"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                }
            ]
        },
        {
            "paperId": "9ac5f02dff405b274f9c8b6580e432d690953d4b",
            "title": "Minimum Topology Attacks for Graph Neural Networks",
            "abstract": "With the great popularity of Graph Neural Networks (GNNs), their robustness to adversarial topology attacks has received significant attention. Although many attack methods have been proposed, they mainly focus on fixed-budget attacks, aiming at finding the most adversarial perturbations within a fixed budget for target node. However, considering the varied robustness of each node, there is an inevitable dilemma caused by the fixed budget, i.e., no successful perturbation is found when the budget is relatively small, while if it is too large, the yielding redundant perturbations will hurt the invisibility. To break this dilemma, we propose a new type of topology attack, named minimum-budget topology attack, aiming to adaptively find the minimum perturbation sufficient for a successful attack on each node. To this end, we propose an attack model, named MiBTack, based on a dynamic projected gradient descent algorithm, which can effectively solve the involving non-convex constraint optimization on discrete topology. Extensive results on three GNNs and four real-world datasets show that MiBTack can successfully lead all target nodes misclassified with the minimum perturbation edges. Moreover, the obtained minimum budget can be used to measure node robustness, so we can explore the relationships of robustness, topology, and uncertainty for nodes, which is beyond what the current fixed-budget topology attacks can offer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16003017",
                    "name": "Mengmei Zhang"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                },
                {
                    "authorId": "145225199",
                    "name": "Lingjuan Lyu"
                },
                {
                    "authorId": "2800519",
                    "name": "Tianchi Yang"
                },
                {
                    "authorId": "8491162",
                    "name": "Junping Du"
                }
            ]
        }
    ]
}