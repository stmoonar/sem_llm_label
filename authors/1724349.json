{
    "authorId": "1724349",
    "papers": [
        {
            "paperId": "ec128d8386e5c98a2beafce9d9268ab4ce4662ec",
            "title": "Delay Threshold for Social Interaction in Volumetric eXtended Reality Communication",
            "abstract": "Immersive technologies like eXtended Reality (XR) are the next step in videoconferencing. In this context, understanding the effect of delay on communication is crucial. This article presents the first study on the impact of delay on collaborative tasks using a realistic Social XR system. Specifically, we design an experiment and evaluate the impact of end-to-end delays of 300, 600, 900, 1,200, and 1,500 ms on the execution of a standardized task involving the collaboration of two remote users that meet in a virtual space and construct block-based shapes. To measure the impact of the delay in this communication scenario, objective and subjective data were collected. As objective data, we measured the time required to execute the tasks and computed conversational characteristics by analyzing the recorded audio signals. As subjective data, a questionnaire was prepared and completed by every user to evaluate different factors such as overall quality, perception of delay, annoyance using the system, level of presence, cybersickness, and other subjective factors associated with social interaction. The results show a clear influence of the delay on the perceived quality and a significant negative effect as the delay increases. Specifically, the results indicate that the acceptable threshold for end-to-end delay should not exceed 900 ms. This article additionally provides guidelines for developing standardized XR tasks for assessing interaction in Social XR environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056668320",
                    "name": "Carlos Cort\u00e9s"
                },
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "2258514372",
                    "name": "Jes\u00daS Guti\u00c9Rrez"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "3921978",
                    "name": "E. Alexiou"
                },
                {
                    "authorId": "2163712597",
                    "name": "Pablo P\u00e9rez"
                },
                {
                    "authorId": "2066835582",
                    "name": "Narciso Garc\u00eda"
                },
                {
                    "authorId": "2249603733",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "ec43b10430d47e96d60f2219bc79d06bfe915575",
            "title": "VR2Gather: A Collaborative, Social Virtual Reality System for Adaptive, Multiparty Real-Time Communication",
            "abstract": "Virtual reality telecommunication systems promise to overcome the limitations of current real-time teleconferencing solutions by enabling a better sense of immersion and fostering more natural interpersonal interactions. Many solutions that currently enable immersive teleconferencing employ synthetic avatars to represent their users. However, photorealistic reconstructions have been shown to increase the sense of presence with respect to synthetic avatars in teleimmersive scenarios. In this article, we present VR2Gather, a costumizable, end-to-end system to transmit volumetric contents in multiparty, real-time communication. We present the architecture and evaluate the costs and benefits of using different modules and transport mechanisms in terms of CPU usage, latency, and bandwidth. Moreover, we report the user experience based on applications the system has been used for and how it was customized to meet the requirements using different acquisition and rendering modules.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "73266843",
                    "name": "Ignacio Reimat"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "ec6b45b46410242941610eea1bf204a33d88cbc5",
            "title": "QAVA-DPC: Eye-Tracking Based Quality Assessment and Visual Attention Dataset for Dynamic Point Cloud in 6 DoF",
            "abstract": "Perceptual quality assessment of Dynamic Point Cloud (DPC) contents plays an important role in various Virtual Reality (VR) applications that involve human beings as the end user, understanding and modeling perceptual quality assessment is greatly enriched by insights from visual attention. However, incorporating aspects of visual attention in DPC quality models is largely unexplored, as ground-truth visual attention data is scarcely available. This paper presents a dataset containing subjective opinion scores and visual attention maps of DPCs, collected in a VR environment using eye-tracking technology. The data was collected during a subjective quality assessment experiment, in which subjects were instructed to watch and rate DPCs at various degradation levels under 6 degrees-of-freedom inspection, using a head-mounted display. The dataset comprises 5 reference DPC contents, with each reference encoded at 3 distortion levels using 3 different codecs, amounting to a total of 9 degraded DPC contents. Moreover, it includes 1,000 gaze trials from 40 participants, resulting in 15,000 visual attention maps in total. The curated dataset can serve as authentic benchmark data for assessing the performance of objective DPC quality metrics. Additionally, it establishes a link between quality assessment and visual attention within the context of DPC. This work deepens our understanding of DPC quality and visual attention, driving progress in the realm of VR experiences and perception.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268430350",
                    "name": "Xuemei Zhou"
                },
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "3921978",
                    "name": "E. Alexiou"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "2249603733",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "0d8ebf539769504fc613bfdfdec29866d244a8d5",
            "title": "Mediascape XR: A Cultural Heritage Experience in Social VR",
            "abstract": "Social virtual reality (VR) allows multiple remote users to interact in a shared space, unveiling new possibilities for communication in immersive environments. Mediascape XR presents a social VR experience that teleports 3D representations of remote users, using volumetric video, to a virtual museum. It enables visitors to interact with cultural heritage artifacts while allowing social interactions in real time between them. The application is designed following a human-centered approach, enabling an interactive, educating, and entertaining experience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "73266843",
                    "name": "Ignacio Reimat"
                },
                {
                    "authorId": "2086813258",
                    "name": "Yanni Mei"
                },
                {
                    "authorId": "3921978",
                    "name": "E. Alexiou"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "2155418723",
                    "name": "Jie Li"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "1736482",
                    "name": "J. Oomen"
                },
                {
                    "authorId": "1677086160",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "8910c31c1c3f8ff2f1dc457c72569bc64dfe59b0",
            "title": "Subjective QoE Evaluation of User-Centered Adaptive Streaming of Dynamic Point Clouds",
            "abstract": "Technological advances in head-mounted displays and novel real-time 3D acquisition and reconstruction solutions have fostered the development of 6 Degrees of Freedom (6DoF) teleimmersive systems for social VR applications. Point clouds have emerged as a popular format for such applications, owing to their simplicity and versatility; yet, dense point cloud contents are too large to deliver directly over bandwidth-limited networks. In this context, user-adaptive delivery mechanisms are a promising solution to exploit the increased range of motion offered by 6DoF VR applications to yield gains in perceived quality of 3D point cloud user representations, while reducing their bandwidth requirements. In this paper, we perform a user study in VR to quantify the gains adaptive tile selection strategies can bring with respect to non-adaptive solutions. In particular, we define an auxiliary utility function, we employ established methods from the literature and newly-proposed schemes for distributing the bit budget across the tiles, and we evaluate them together with non-adaptive streaming baselines through subjective QoE assessment. Results confirm that considerable gains can be obtained with user-adaptive streaming, achieving bit rate gains of up to 65% with respect to a non-adaptive approach to deliver comparable quality. Our analysis provides useful insights for the design and development of social VR applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "3921978",
                    "name": "E. Alexiou"
                },
                {
                    "authorId": "1718099",
                    "name": "A. Hanjalic"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "b5ba9f66136042d8e79eea410055eea597ab0cbf",
            "title": "Evaluating the Impact of Tiled User-Adaptive Real-Time Point Cloud Streaming on VR Remote Communication",
            "abstract": "Remote communication has rapidly become a part of everyday life in both professional and personal contexts. However, popular video conferencing applications present limitations in terms of quality of communication, immersion and social meaning. VR remote communication applications offer a greater sense of co-presence and mutual sensing of emotions between remote users. Previous research on these applications has shown that realistic point cloud user reconstructions offer better immersion and communication as compared to synthetic user avatars. However, photorealistic point clouds require a large volume of data per frame and are challenging to transmit over bandwidth-limited networks. Recent research has demonstrated significant improvements to perceived quality by optimizing the usage of bandwidth based on the position and orientation of the user's viewport with user-adaptive streaming. In this work, we developed a real-time VR communication application with an adaptation engine that features tiled user-adaptive streaming based on user behaviour. The application also supports traditional network adaptive streaming. The contribution of this work is to evaluate the impact of tiled user-adaptive streaming on quality of communication, visual quality, system performance and task completion in a functional live VR remote communication system. We performed a subjective evaluation with 33 users to compare the different streaming conditions with a neck exercise training task. As a baseline, we use uncompressed streaming requiring approximately 300 megabits per second and our solution achieves similar visual quality with tiled adaptive streaming at 14 megabits per second. We also demonstrate statistically significant gains in the quality of interaction and improvements to system performance and CPU consumption with tiled adaptive streaming as compared to the more traditional network adaptive streaming.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "3921978",
                    "name": "E. Alexiou"
                },
                {
                    "authorId": "1718099",
                    "name": "A. Hanjalic"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "48ebb4ef9ca0d584d628efacbd61a67647bcb371",
            "title": "A Collaborative VR Murder Mystery using Photorealistic User Representations",
            "abstract": "The VRTogether project has developed a Social VR platform for remote communication and collaboration. The hyper-realistic representation of users, as volumetric video, allows for natural interaction in a virtual environment with others. This video shows one of the use cases, an escape room style, where remote users need to collaboratively resolve a murder mystery. The experience takes place in the victim\u2019s apartment where the police team (avatars) together with up to four real-time captured users (point clouds), work as a team to find clues and come up with a conclusion about what happened to the victim and who was the criminal. This experience includes a layer of interaction, enabling the users to interact with the environment, by touching objects, and to talk to the characters. It also allows for navigating between the rooms of the apartment. The experience provides immersion and social connectedness, where users are protagonists of the story, sharing the virtual environment and following the narrative. The combination of virtual reality environments (space and characters) with novel technologies for real-time volumetric video conferencing enables unique new experiences in a number of areas such as healthcare, broadcasting, and gaming.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119485318",
                    "name": "A. Revilla"
                },
                {
                    "authorId": "2089476919",
                    "name": "Sergio Zamarvide"
                },
                {
                    "authorId": "1868687155",
                    "name": "Ignacio Lacosta"
                },
                {
                    "authorId": "2065357664",
                    "name": "Fernando P\u00e9rez"
                },
                {
                    "authorId": "1868686157",
                    "name": "Javier Lajara"
                },
                {
                    "authorId": "1713605264",
                    "name": "Bart Kevelham"
                },
                {
                    "authorId": "2089478766",
                    "name": "Val\u00e9rie Juillard"
                },
                {
                    "authorId": "2089568192",
                    "name": "Brian Rochat"
                },
                {
                    "authorId": "2089565063",
                    "name": "Michelle Drocco"
                },
                {
                    "authorId": "2089476945",
                    "name": "Natasha Devaud"
                },
                {
                    "authorId": "2089569519",
                    "name": "Olivier Barbeau"
                },
                {
                    "authorId": "2947402",
                    "name": "C. Charbonnier"
                },
                {
                    "authorId": "35582912",
                    "name": "Patrick Lange"
                },
                {
                    "authorId": "2155418723",
                    "name": "Jie Li"
                },
                {
                    "authorId": "2086813258",
                    "name": "Yanni Mei"
                },
                {
                    "authorId": "14519533",
                    "name": "K. Lawicka"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "2089476940",
                    "name": "Nacho Reimat"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "9037d5eaf963047553a1287cb6e028e94258417b",
            "title": "Evaluating the user Experience of a Photorealistic Social VR Movie",
            "abstract": "We all enjoy watching movies together. However, this is not always possible if we live apart. While we can remotely share our screens, the experience differs from being together. We present a social Virtual Reality (VR) system that captures, reconstructs, and transmits multiple users\u2019 volumetric representations into a commercially produced 3D virtual movie, so they have the feeling of \u201cbeing there\u201d together. We conducted a 48-user experiment where we invited users to experience the virtual movie either using a Head Mounted Display (HMD) or using a 2D screen with a game controller. In addition, we invited 14 VR experts to experience both the HMD and the screen version of the movie and discussed their experiences in two focus groups. Our results showed that both end-users and VR experts found that the way they navigated and interacted inside a 3D virtual movie was novel. They also found that the photorealistic volumetric representations enhanced feelings of co-presence. Our study lays the groundwork for future interactive and immersive VR movie co-watching experiences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155418723",
                    "name": "Jie Li"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "2086813258",
                    "name": "Yanni Mei"
                },
                {
                    "authorId": "73266843",
                    "name": "Ignacio Reimat"
                },
                {
                    "authorId": "14519533",
                    "name": "K. Lawicka"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "9b944aa02c3687eba69c086af6a8bb2eaa880e1e",
            "title": "Influence of Narrative Elements on User Behaviour in Photorealistic Social VR",
            "abstract": "Social Virtual Reality (VR) applications represent a big step forward in the field of remote communication. Social VR provides the possibility for participants to explore and interact with virtual environments and objects, feelings of a full sense of immersion, and being together. Understanding how user behaviour is influenced by the shared virtual space and its elements becomes the key to design and optimize novel immersive experiences. This paper presents a behavioural analysis of user navigating in 6 degrees of freedom social VR movie. Specifically, we analyse 48 user trajectories from a photorealistic telepresence experiment, in which subjects watch a crime movie together in VR. We investigate how users are affected by salient agents (i.e., virtual characters) and by narrative elements of the VR movie (i.e., dialogues versus interactive part). We complete our assessment by conducting a statistical analysis of the collected data. Results indicate that user behaviour is affected by different narrative and interactive elements. We conclude by presenting our observations and drawing conclusions on future paths for social VR experiences. This work has been supported by Royal Society under grant IES R1180128 and by Cisco under Cisco Research Center Donation scheme.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145005536",
                    "name": "Silvia Rossi"
                },
                {
                    "authorId": "10399052",
                    "name": "Irene Viola"
                },
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "2114802624",
                    "name": "Laura Toni"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        },
        {
            "paperId": "66f276ebd75ef8153f0af05afbc3e25a7f23685b",
            "title": "A pipeline for multiparty volumetric video conferencing: transmission of point clouds over low latency DASH",
            "abstract": "The advent of affordable 3D capture and display hardware is making volumetric videoconferencing feasible. This technology increases the immersion of the participants, breaking the flat restriction of 2D screens, by allowing them to collaborate and interact in shared virtual reality spaces. In this paper we introduce the design and development of an architecture intended for volumetric videoconferencing that provides a highly realistic 3D representation of the participants, based on pointclouds. A pointcloud representation is suitable for real-time applications like video conferencing, due to its low-complexity and because it does not need a time consuming reconstruction process. As transport protocol we selected low latency DASH, due to its popularity and client-based adaptation mechanisms for tiling. This paper presents the architectural design, details the implementation, and provides some referential results. The demo will showcase the system in action, enabling volumetric videoconferencing using pointclouds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724349",
                    "name": "Jack Jansen"
                },
                {
                    "authorId": "49662661",
                    "name": "S. Subramanyam"
                },
                {
                    "authorId": "2105739",
                    "name": "R. Bouqueau"
                },
                {
                    "authorId": "2917914",
                    "name": "G. Cernigliaro"
                },
                {
                    "authorId": "1720845613",
                    "name": "Marc Martos Cabr\u00e9"
                },
                {
                    "authorId": "2065357664",
                    "name": "Fernando P\u00e9rez"
                },
                {
                    "authorId": "144022557",
                    "name": "Pablo C\u00e9sar"
                }
            ]
        }
    ]
}