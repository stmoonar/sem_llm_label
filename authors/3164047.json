{
    "authorId": "3164047",
    "papers": [
        {
            "paperId": "8d0ddeab6ef624d15db320eaa38df282c4dfa33a",
            "title": "FPI: Failure Point Isolation in Large-scale Conversational Assistants",
            "abstract": "Large-scale conversational assistants such as Cortana, Alexa, Google Assistant and Siri process requests through a series of modules for wake word detection, speech recognition, language understanding and response generation. An error in one of these modules can cascade through the system. Given the large traffic volumes in these assistants, it is infeasible to manually analyze the data, identify requests with processing errors and isolate the source of error. We present a machine learning system to address this challenge. First, we embed the incoming request and context, such as system response and subsequent turns, using pre-trained transformer models. Then, we combine these embeddings with encodings of additional metadata features (such as confidence scores from different modules in the online system) using a \u201cmixing-encoder\u201d to output the failure point predictions. Our system obtains 92.2% of human performance on this task while scaling to analyze the entire traffic in 8 different languages of a large-scale conversational assistant. We present detailed ablation studies analyzing the impact of different modeling choices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145964537",
                    "name": "R. Khaziev"
                },
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "2240075710",
                    "name": "Tobias R\u00f6ding"
                },
                {
                    "authorId": "147887099",
                    "name": "Rakesh Chada"
                },
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                }
            ]
        },
        {
            "paperId": "acc5a82962b6b80a51d0aa125be110a662d331c4",
            "title": "Detecting and understanding moral biases in news",
            "abstract": "We describe work in progress on detecting and understanding the moral biases of news sources by combining framing theory with natural language processing. First we draw connections between issue-specific frames and moral frames that apply to all issues. Then we analyze the connection between moral frame presence and news source political leaning. We develop and test a simple classification model for detecting the presence of a moral frame, highlighting the need for more sophisticated models. We also discuss some of the annotation and frame detection challenges that can inform future research in this area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "1745798",
                    "name": "Barbara Maria Di Eugenio"
                },
                {
                    "authorId": "2473827",
                    "name": "Andrew Rojecki"
                },
                {
                    "authorId": "2392370",
                    "name": "E. Zheleva"
                }
            ]
        },
        {
            "paperId": "b20db215418a6d70b6665715899a4037d402c5b3",
            "title": "High-Level Concepts for Affective Understanding of Images",
            "abstract": "This paper aims to bridge the affective gap between image content and the emotional response of the viewer it elicits by using High-Level Concepts (HLCs). In contrast to previous work that relied solely on low-level features or used convolutional neural network (CNN) as a blackbox, we use HLCs generated by pretrained CNNs in an explicit way to investigate the relations/associations between these HLCs and a (small) set of Ekman's emotional classes. As a proof-of-concept, we first propose a linear admixture model for modeling these relations, and the resulting computational framework allows us to determine the associations between each emotion class and certain HLCs (objects and places). This linear model is further extended to a nonlinear model using support vector regression (SVR) that aims to predict the viewer's emotional response using both low-level image features and HLCs extracted from images. These class-specific regressors are then assembled into a regressor ensemble that provide a flexible and effective predictor for predicting viewer's emotional responses from images. Experimental results have demonstrated that our results are comparable to existing methods, with a clear view of the association between HLCs and emotional classes that is ostensibly missing in most existing work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10771870",
                    "name": "Afsheen Rafaqat Ali"
                },
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "144908682",
                    "name": "Mohsen Ali"
                },
                {
                    "authorId": "144850973",
                    "name": "J. Ho"
                }
            ]
        },
        {
            "paperId": "c66855cef9561de23ec1978a431767950c2f2f83",
            "title": "Accurate Detection of Automatically Spun Content via Stylometric Analysis",
            "abstract": "Spammers use automated content spinning techniques to evade plagiarism detection by search engines. Text spinners help spammers in evading plagiarism detectors by automatically restructuring sentences and replacing words or phrases with their synonyms. Prior work on spun content detection relies on the knowledge about the dictionary used by the text spinning software. In this work, we propose an approach to detect spun content and its seed without needing the text spinner's dictionary. Our key idea is that text spinners introduce stylometric artifacts that can be leveraged for detecting spun documents. We implement and evaluate our proposed approach on a corpus of spun documents that are generated using a popular text spinning software. The results show that our approach can not only accurately detect whether a document is spun but also identify its source (or seed) document - all without needing the dictionary used by the text spinner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "39416427",
                    "name": "Shehroze Farooqi"
                },
                {
                    "authorId": "2054233538",
                    "name": "Raza Ahmad"
                },
                {
                    "authorId": "34616778",
                    "name": "Zubair Shafiq"
                },
                {
                    "authorId": "144684950",
                    "name": "P. Srinivasan"
                },
                {
                    "authorId": "1685939",
                    "name": "Fareed Zaffar"
                }
            ]
        },
        {
            "paperId": "7becdbe555ca8d3c0c179fb06ef8197b87da5158",
            "title": "Speakmytext: A Platform To Support Crowd-Sourced Text-To-Audio Translations",
            "abstract": "People with little or no reading abilities may not be able to read important information such as: instructions on medicine, warning sign boards, employment/property affidavits, government announcements in emergencies like viral diseases and storm alerts. This reading disability is further compounded when there is no literate around to explain meaning of the displayed information. In this paper, we present SpeakMyText - a platform which facilitates collaboration between reading-illiterates and volunteer literates to promote learning. SpeakMyText's mobile application enables a user to share an image containing text with a volunteer-translator who could then record and share-back its audio translation. The platform is specifically designed for non-literate users with several easy-to-use features like auto-signup; auto-login; multilingual graphical interface, 2-click interface to upload image and other similar features. This paper details its functionality and initial evaluation on a group of 60 reading-illiterates of different age groups and professions. System evaluation reveals promising results; more than 70 % of the non-literate/semi-literate users were able to easily access its basic functionality.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2485535",
                    "name": "I. Ghaznavi"
                },
                {
                    "authorId": "3124430",
                    "name": "Shan Randhawa"
                },
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "35055697",
                    "name": "Bilal Saleem"
                },
                {
                    "authorId": "2868135",
                    "name": "U. Saif"
                }
            ]
        },
        {
            "paperId": "db05dd3b328bf47e8744b235a2752164ee95edd8",
            "title": "VillageApps: a platform to educate underprivileged communities in their mother tongue",
            "abstract": "Illiteracy is one of the biggest development challenges, especially in the developing regions. There are 785M adult illiterates in the world; one in every five people has little or no basic reading skills. Illiteracy poses the following challenges: It limits the ability to understand essential information, it increases unemployment, poverty and it has a negative impact on health. In this study, we present VillageApps -- a framework to educate underprivileged communities in their mother tongue. The paper details the platform, its functionality, and its initial evaluation on a group of 30 school-aged children. Our framework consists of a web and a mobile application; the web application provides an interface to upload content and record its page by page audio translation; the mobile application provides an interface to view each page and simultaneously listen to its audio translation.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2485535",
                    "name": "I. Ghaznavi"
                },
                {
                    "authorId": "2004831",
                    "name": "Umar Muneer"
                },
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "3124430",
                    "name": "Shan Randhawa"
                },
                {
                    "authorId": "2034372225",
                    "name": "Kashif Ali"
                },
                {
                    "authorId": "1755518",
                    "name": "Tapan S. Parikh"
                },
                {
                    "authorId": "2868135",
                    "name": "U. Saif"
                }
            ]
        }
    ]
}