{
    "authorId": "151240818",
    "papers": [
        {
            "paperId": "00b1c039c3233ae5803803e4acb276f9242508a8",
            "title": "Improving NL-to-Query Systems through Re-ranking of Semantic Hypothesis",
            "abstract": "Natural Language-to-Query systems translate a natural language question into a formal query language such as SQL. Typically the translation results in a set of candidate query statements due to the ambiguity of natural language. Hence, an important aspect of NL-to-Query systems is to rank the query statements so that the most relevant query is ranked on top. We pro-pose a novel approach to significantly improve the query ranking and thus the accuracy of such systems . First, we use existing methods to translate the natural language question ( NL in ) into k query statements and rank them. Then we translate each of the k query statements back into a natural language question ( NL gen ) and use the semantic similarity between the original question NL in and each of the k generated questions NL gen to re-rank the output . Our experiments on two standard datasets, OTTA and Spider, show that this technique improves even strong state-of-the-art NL-to-Query systems by up to 9 percentage points. A detailed error analysis shows that our method correctly down-ranks queries with missing relations and wrong query types. While this work is focused on NL-to-Query, our method could be applied to any other semantic parsing problems as long as a text generation method is available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1737826518",
                    "name": "P. von D\u00e4niken"
                },
                {
                    "authorId": "145116511",
                    "name": "Jan Deriu"
                },
                {
                    "authorId": "1733049",
                    "name": "Eneko Agirre"
                },
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "2648584",
                    "name": "Mark Cieliebak"
                },
                {
                    "authorId": "2113917675",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "04769dfda81ba3e57fd74fb025aef60d1f8d3a56",
            "title": "ValueNet: A Natural Language-to-SQL System that Learns from Database Information",
            "abstract": "In this paper we propose ValueNet light and ValueNet \u2013 two end-to-end Natural Language-to-SQL systems that incor-porate values using the challenging Spider dataset. The main idea of our approach is to use not only metadata information from the underlying database but also information on the base data as input for our neural network architecture. In particular, we propose a novel architecture sketch to extract values from a user question and come up with possible value candidates which are not explicitly mentioned in the question. We then use a neural model based on an encoder-decoder architecture to synthesize the SQL query. Finally, we evaluate our model on the Spider challenge using the Execution Accuracy metric, a more difficult metric than used by most participants of the challenge. Our experimental evaluation demonstrates that ValueNet light and ValueNet reach state-of-the-art results of 67% and 62% accuracy, respectively, for translating from NL to SQL whilst incorporating values.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "2113917675",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "e80aba67e92aec3ef06ed31193832c6f81e9a2ed",
            "title": "INODE",
            "abstract": "A full-fledged data exploration system must combine different access modalities with a powerful concept of guiding the user in the exploration process, by being reactive and anticipative both for data discovery and for data linking. Such systems are a real opportunity for our community to cater to users with different domain and data science expertise. We introduce INODE - an end-to-end data exploration system - that leverages, on the one hand, Machine Learning and, on the other hand, semantics for the purpose of Data Management (DM). Our vision is to develop a classic unified, comprehensive platform that provides extensive access to open datasets, and we demonstrate it in three significant use cases in the fields of Cancer Biomarker Research, Research and Innovation Policy Making, and Astrophysics. INODE offers sustainable services in (a) data modeling and linking, (b) integrated query processing using natural language, (c) guidance, and (d) data exploration through visualization, thus facilitating the user in discovering new insights. We demonstrate that our system is uniquely accessible to a wide range of users from larger scientific communities to the public. Finally, we briefly illustrate how this work paves the way for new research opportunities in DM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "2463025",
                    "name": "Fr\u00e9d\u00e9ric B. Bastian"
                },
                {
                    "authorId": "1726022751",
                    "name": "Theofilos Belmpas"
                },
                {
                    "authorId": "3075644",
                    "name": "Martin Braschler"
                },
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                },
                {
                    "authorId": "14469238",
                    "name": "M. Fabricius"
                },
                {
                    "authorId": "1726045725",
                    "name": "Orest Gkini"
                },
                {
                    "authorId": "2072251887",
                    "name": "Catherine Kosten"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "40469553",
                    "name": "Antonis Litke"
                },
                {
                    "authorId": "1403433652",
                    "name": "Hendrik L\u00fccke-Tieke"
                },
                {
                    "authorId": "1970432",
                    "name": "F. Massucci"
                },
                {
                    "authorId": "1725471",
                    "name": "T. M. Farias"
                },
                {
                    "authorId": "1806182",
                    "name": "A. Mosca"
                },
                {
                    "authorId": "2072251867",
                    "name": "Francesco Multari"
                },
                {
                    "authorId": "145679608",
                    "name": "N. Papadakis"
                },
                {
                    "authorId": "153516669",
                    "name": "D. Papadopoulos"
                },
                {
                    "authorId": "2061639772",
                    "name": "Yogendra Patil"
                },
                {
                    "authorId": "2072259106",
                    "name": "Aur\u00e9lien Personnaz"
                },
                {
                    "authorId": "3235045",
                    "name": "Guillem Rull"
                },
                {
                    "authorId": "2723088",
                    "name": "A. Sima"
                },
                {
                    "authorId": "153437025",
                    "name": "Ellery Smith"
                },
                {
                    "authorId": "1807115",
                    "name": "Dimitrios Skoutas"
                },
                {
                    "authorId": "2075402169",
                    "name": "S. Subramanian"
                },
                {
                    "authorId": "2055961473",
                    "name": "G. Xiao"
                },
                {
                    "authorId": "2113917675",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "4e6e90c32b30eae80d42fc91261715752ef29c7d",
            "title": "Entity Matching with Transformer Architectures - A Step Forward in Data Integration",
            "abstract": "Transformer architectures have proven to be very effective and provide state-of-the-art results in many natural language tasks. Theattention-basedarchitectureincombinationwith pre-training on large amounts of text lead to the recent breakthrough and a variety of slightly different implementations. In this paper we analyze how well four of the most recent attention-based transformer architectures (BERT[6], XLNet[33], RoBERTa[17] and DistilBERT [23]) perform on the task of entity matching - a crucial part of data integration. Entity matching (EM) is the task of finding data instances that refer to the same real-world entity. It is a challenging task if the data instances consist of long textual data or if the data instances are \"dirty\" due to misplaced values. To evaluate the capability of transformer architectures and transfer-learning on the task of EM, we empirically compare the four approaches on inherently difficult data sets. We show that transformer architectures outperform classical deep learning methods in EM[7, 20] by an average margin of 27.5%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "2113917675",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "fea343ea0aefcafc4dbb87b710d47c329df83bc5",
            "title": "ValueNet: A Neural Text-to-SQL Architecture Incorporating Values",
            "abstract": "Building natural language interfaces for databases has been a long-standing challenge for several decades. The major advantage of these so-called text-to-SQL systems is that end-users can query complex databases without the need to know SQL or the underlying database schema. Due to significant advancements in machine learning, the recent focus of research has been on neural networks to tackle this challenge on complex datasets like Spider. Several recent text-to-SQL systems achieve promising results on this dataset. However, none of them extracts and incorporates values from the user questions for generating SQL statements. Thus, the practical use of these systems in a real-world scenario has not been sufficiently demonstrated yet. \nIn this paper we propose ValueNet light and ValueNet -- the first end-to-end text-to-SQL system incorporating values on the challenging Spider dataset. The main idea of our approach is to use not only metadata information about the underlying database but also information on the base data as input for our neural network architecture. In particular, we propose a novel architecture sketch to extract values from a user question and come up with possible value candidates which are not explicitly mentioned in the question. We then use a neural model based on an encoder-decoder architecture to synthesize the SQL query. Finally, we evaluate our model on the Spider challenge using the Execution Accuracy metric, a more difficult metric than used by most participants of the challenge. Our experimental evaluation demonstrates that ValueNet light and ValueNet reach state-of-the-art results of 64% and 60% accuracy, respectively, for translating from text to SQL, even when applying this more difficult metric than used by previous work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "2113917675",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "bf87f542b84bb380a8d6184a96b4817c8445088e",
            "title": "Entity Matching on Unstructured Data: An Active Learning Approach",
            "abstract": "With the growing number of data sources in enterprises, entity matching becomes a crucial part of every data integration project. In order to reduce the human effort involved in identifying matching entities between different database tables, typically machine learning algorithms are applied. Moreover, active learning is often combined with supervised machine learning methods to further reduce the effort of labeling entities as true or false matches. However, while state-of-the-art active learning algorithms have proven to work well on structured data sets, unstructured data still poses a challenge in entity matching. This paper proposes an end-to-end entity matching pipeline to minimize the human labeling effort for entity matching on unstructured data sets. We use several natural language processing techniques such as soft tf-idf to pre-process the record pairs before we classify them using a novel Active Learning with Uncertainty Sampling (ALWUS) algorithm. We designed our algorithm as a plugin system to work with any state-of-the-art classifier such as support vector machines, random forests or deep neural networks. Detailed experimental results demonstrate that our end-to-end entity matching pipeline clearly outperforms comparable entity matching approaches on an unstructured realword data set. Our approach achieves significantly better scores (F1-score) while using 1 to 2 orders of magnitude fewer human labeling efforts than existing state-of-the-art algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "1892227",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "ecb9136f04ea92b9af848a6dda0f8d7bfd098d18",
            "title": "Entity matching on unstructured data : an active learning approach",
            "abstract": "With the growing number of data sources in enterprises, entity matching becomes a crucial part of every data integration project. In order to reduce the human effort involved in identifying matching entities between different database tables, typically machine learning algorithms are applied. Moreover, active learning is often combined with supervised machine learning methods to further reduce the effort of labeling entities as true or false matches. However, while state-of-the-art active learning algorithms have proven to work well on structured data sets, unstructured data still poses a challenge in entity matching. This paper proposes an end-to-end entity matching pipeline to minimize the human labeling effort for entity matching on unstructured data sets. We use several natural language processing techniques such as soft tf-idf to pre-process the record pairs before we classify them using a novel Active Learning with Uncertainty Sampling (ALWUS) algorithm. We designed our algorithm as a plugin system to work with any state-of-the-art classifier such as support vector machines, random forests or deep neural networks. Detailed experimental results demonstrate that our end-to-end entity matching pipeline clearly outperforms comparable entity matching approaches on an unstructured realword data set. Our approach achieves significantly better scores (F1-score) while using 1 to 2 orders of magnitude fewer human labeling efforts than existing state-of-the-art algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "1892227",
                    "name": "Kurt Stockinger"
                }
            ]
        }
    ]
}