{
    "authorId": "16278568",
    "papers": [
        {
            "paperId": "71929cb4d08d2bd09c10202818b2988aa33caa66",
            "title": "DREAM: A Dual Representation Learning Model for Multimodal Recommendation",
            "abstract": "Multimodal recommendation focuses primarily on effectively exploiting both behavioral and multimodal information for the recommendation task. However, most existing models suffer from the following issues when fusing information from two different domains: (1) Previous works do not pay attention to the sufficient utilization of modal information by only using direct concatenation, addition, or simple linear layers for modal information extraction. (2) Previous works treat modal features as learnable embeddings, which causes the modal embeddings to gradually deviate from the original modal features during learning. We refer to this issue as Modal Information Forgetting. (3) Previous approaches fail to account for the significant differences in the distribution between behavior and modality, leading to the issue of representation misalignment. To address these challenges, this paper proposes a novel Dual REpresentAtion learning model for Multimodal Recommendation called DREAM. For sufficient information extraction, we introduce separate dual lines, including Behavior Line and Modal Line, in which the Modal-specific Encoder is applied to empower modal representations. To address the issue of Modal Information Forgetting, we introduce the Similarity Supervised Signal to constrain the modal representations. Additionally, we design a Behavior-Modal Alignment module to fuse the dual representations through Intra-Alignment and Inter-Alignment. Extensive experiments on three public datasets demonstrate that the proposed DREAM method achieves state-of-the-art (SOTA) results. The source code will be available upon acceptance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258697236",
                    "name": "Kangning Zhang"
                },
                {
                    "authorId": "2292277684",
                    "name": "Yingjie Qin"
                },
                {
                    "authorId": "2292183059",
                    "name": "Ruilong Su"
                },
                {
                    "authorId": "2237947577",
                    "name": "Yifan Liu"
                },
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2129458791",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2297055830",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "9b614735fdf3730304c54fcac91bb15850945e24",
            "title": "InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization",
            "abstract": "Ranking items regarding individual user interests is a core technique of multiple downstream tasks such as recommender systems. Learning such a personalized ranker typically relies on the implicit feedback from users' past click-through behaviors. However, collected feedback is biased toward previously highly-ranked items and directly learning from it would result in \"rich-get-richer\" phenomena. In this paper, we propose a simple yet sufficient unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously address both position and popularity biases. We begin by consolidating the impacts of those biases into a single observation factor, thereby providing a unified approach to addressing bias-related issues. Subsequently, we minimize the mutual information between the observation estimation and the relevance estimation conditioned on the input features. By doing so, our relevance estimation can be proved to be free of bias. To implement InfoRank, we first incorporate an attention mechanism to capture latent correlations within user-item features, thereby generating estimations of observation and relevance. We then introduce a regularization term, grounded in conditional mutual information, to promote conditional independence between relevance estimation and observation estimation. Experimental evaluations conducted across three extensive recommendation and search datasets reveal that InfoRank learns more precise and unbiased ranking strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "145788064",
                    "name": "Mengyue Yang"
                },
                {
                    "authorId": "2244690305",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2119021541",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2256981980",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                }
            ]
        },
        {
            "paperId": "a97ce13485a5ae06e91e02110cbbc118d98cf7a0",
            "title": "AlignRec: Aligning and Training in Multimodal Recommendations",
            "abstract": "With the development of multimedia systems, multimodal recommendations are playing an essential role, as they can leverage rich contexts beyond interactions. Existing methods mainly regard multimodal information as an auxiliary, using them to help learn ID features; However, there exist semantic gaps among multimodal content features and ID-based features, for which directly using multimodal information as an auxiliary would lead to misalignment in representations of users and items. In this paper, we first systematically investigate the misalignment issue in multimodal recommendations, and propose a solution named AlignRec. In AlignRec, the recommendation objective is decomposed into three alignments, namely alignment within contents, alignment between content and categorical ID, and alignment between users and items. Each alignment is characterized by a specific objective function and is integrated into our multimodal recommendation framework. To effectively train AlignRec, we propose starting from pre-training the first alignment to obtain unified multimodal features and subsequently training the following two alignments together with these features as input. As it is essential to analyze whether each multimodal feature helps in training and accelerate the iteration cycle of recommendation models, we design three new classes of metrics to evaluate intermediate performance. Our extensive experiments on three real-world datasets consistently verify the superiority of AlignRec compared to nine baselines. We also find that the multimodal features generated by AlignRec are better than currently used ones, which are to be open-sourced in our repository https://github.com/sjtulyf123/AlignRec_CIKM24.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237947577",
                    "name": "Yifan Liu"
                },
                {
                    "authorId": "2258697236",
                    "name": "Kangning Zhang"
                },
                {
                    "authorId": "2292220410",
                    "name": "Xiangyuan Ren"
                },
                {
                    "authorId": "2292485947",
                    "name": "Yanhua Huang"
                },
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2292277684",
                    "name": "Yingjie Qin"
                },
                {
                    "authorId": "2292183059",
                    "name": "Ruilong Su"
                },
                {
                    "authorId": "2292215243",
                    "name": "Ruiwen Xu"
                },
                {
                    "authorId": "2129458791",
                    "name": "Weinan Zhang"
                }
            ]
        },
        {
            "paperId": "4a2ac894fad19b6c8bd0984ed5e205d63376cdb7",
            "title": "Set-to-Sequence Ranking-based Concept-aware Learning Path Recommendation",
            "abstract": "With the development of the online education system, personalized education recommendation has played an essential role. In this paper, we focus on developing path recommendation systems that aim to generating and recommending an entire learning path to the given user in each session. Noticing that existing approaches fail to consider the correlations of concepts in the path, we propose a novel framework named Set-to-Sequence Ranking-based Concept-aware Learning Path Recommendation (SRC), which formulates the recommendation task under a set-to-sequence paradigm. Specifically, we first design a concept-aware encoder module which can capture the correlations among the input learning concepts. The outputs are then fed into a decoder module that sequentially generates a path through an attention mechanism that handles correlations between the learning and target concepts. Our recommendation policy is optimized by policy gradient. In addition, we also introduce an auxiliary module based on knowledge tracing to enhance the model\u2019s stability by evaluating students\u2019 learning effects on learning concepts. We conduct extensive experiments on two real-world public datasets and one industrial dataset, and the experimental results demonstrate the superiority and effectiveness of SRC. Code now is available at https://gitee.com/mindspore/models/tree/master/research/recommend/SRC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2044658373",
                    "name": "Xian-Xu Chen"
                },
                {
                    "authorId": "143808691",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "2154454480",
                    "name": "Wei Xia"
                },
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2218340969",
                    "name": "Ya-Zhen Song"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "1384787219",
                    "name": "Menghui Zhu"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2181335910",
                    "name": "Kai Dong"
                },
                {
                    "authorId": "2173940958",
                    "name": "Dingyin Xia"
                },
                {
                    "authorId": "2156098229",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "88224efc7a510e5cec3e1d99c955923bdbcb3e6d",
            "title": "Search-based Time-Aware Graph-Enhanced Recommendation with Sequential Behavior Data",
            "abstract": "Extending from sequential recommendation models, in this paper, we present a novel framework named Search-based Time-Aware Recommendation (STARec), which first retrieves the historical behaviors of the given user through a search-based retriever, and then captures the user\u2019s evolving demands over time through a time-aware sequential network. We notice that the key insight of STARec is to use the feature and labels to augment the representations, and thus the effectiveness of STARec relies on the acquisition of rich browsing records of the target user and powerful representation of each browsed item and thus its performance could heavily drop regarding long-tail users and items. To this end, we extend STARec by constructing a graph upon the user-item interactions and leveraging the graph structure to enhance the representation learning. We call this extended version Search-based Time-Aware Graph-Enhanced Recommendation (STAGE). We conduct extensive experiments on three real-world datasets and STARec achieves consistent superiority. We further compare STAGE against STARec long-tail users and our results demonstrate that STAGE could outperform STARec at most cases. Results of online A/B tests show that STARec and STAGE achieve an average CTR improvement of around 6% and 1.5% in the two main item recommendation scenarios respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115223579",
                    "name": "Lei Zheng"
                },
                {
                    "authorId": "2220553287",
                    "name": "Huacan Chai"
                },
                {
                    "authorId": "150343399",
                    "name": "Xianyu Chen"
                },
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2156098229",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2146370869",
                    "name": "Xiaodong Guo"
                },
                {
                    "authorId": "2220554158",
                    "name": "Can Ge"
                },
                {
                    "authorId": "7357821",
                    "name": "Ziming Feng"
                }
            ]
        },
        {
            "paperId": "afe70574f74eb84677218e272b05b8e863b42a55",
            "title": "Replace Scoring with Arrangement: A Contextual Set-to-Arrangement Framework for Learning-to-Rank",
            "abstract": "Learning-to-rank is a core technique in the top-N recommendation task, where an ideal ranker would be a mapping from an item set to an arrangement (a.k.a. permutation). Most existing solutions fall in the paradigm of probabilistic ranking principle (PRP), i.e., first score each item in the candidate set and then perform a sort operation to generate the top ranking list. However, these approaches neglect the contextual dependence among candidate items during individual scoring, and the sort operation is non-differentiable. To bypass the above issues, we propose Set-To-Arrangement Ranking (STARank), a new framework directly generates the permutations of the candidate items without the need for individually scoring and sort operations; and is end-to-end differentiable. As a result, STARank can operate when only the ground-truth permutations are accessible without requiring access to the ground-truth relevance scores for items. For this purpose, STARank first reads the candidate items in the context of the user browsing history, whose representations are fed into a Plackett-Luce module to arrange the given items into a list. To effectively utilize the given ground-truth permutations for supervising STARank, we leverage the internal consistency property of Plackett-Luce models to derive a computationally efficient list-wise loss. Experimental comparisons against 9 the state-of-the-art methods on 2 learning-to-rank benchmark datasets and 3 top-N real-world recommendation datasets demonstrate the superiority of STARank in terms of conventional ranking metrics. Notice that these ranking metrics do not consider the effects of the contextual dependence among the items in the list, we design a new family of simulation-based ranking metrics, where existing metrics can be regarded as special cases. STARank can consistently achieve better performance in terms of PBM and UBM simulation-based metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "150343399",
                    "name": "Xianyu Chen"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "145788064",
                    "name": "Mengyue Yang"
                },
                {
                    "authorId": "2256978190",
                    "name": "Yang Wang"
                },
                {
                    "authorId": "1390662136",
                    "name": "Yali Du"
                },
                {
                    "authorId": "2156098229",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "66063792",
                    "name": "J. Wang"
                }
            ]
        },
        {
            "paperId": "e04c1ccf87d16fcf361ee3810dedca951d4589e6",
            "title": "Lending Interaction Wings to Recommender Systems with Conversational Agents",
            "abstract": "Recommender systems trained on offline historical user behaviors are embracing conversational techniques to online query user preference. Unlike prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, we propose CORE, a new offline-training and online-checking paradigm that bridges a COnversational agent and REcommender systems via a unified uncertainty minimization framework. It can benefit any recommendation platform in a plug-and-play style. Here, CORE treats a recommender system as an offline relevance score estimator to produce an estimated relevance score for each item; while a conversational agent is regarded as an online relevance score checker to check these estimated scores in each session. We define uncertainty as the summation of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Based on the uncertainty minimization framework, we derive the expected certainty gain of querying each attribute and item, and develop a novel online decision tree algorithm to decide what to query at each turn. Experimental results on 8 industrial datasets show that CORE could be seamlessly employed on 9 popular recommendation approaches. We further demonstrate that our conversational agent could communicate as a human if empowered by a pre-trained large language model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "150343399",
                    "name": "Xianyu Chen"
                },
                {
                    "authorId": "2256989748",
                    "name": "Fanghua Ye"
                },
                {
                    "authorId": "145788064",
                    "name": "Mengyue Yang"
                },
                {
                    "authorId": "2257019446",
                    "name": "Yue Feng"
                },
                {
                    "authorId": "2244690305",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2119021541",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2256981980",
                    "name": "Jun Wang"
                }
            ]
        },
        {
            "paperId": "10d2aaa5bdfb3daa261da4bd7e1f8133501396c5",
            "title": "Multi-Scale User Behavior Network for Entire Space Multi-Task Learning",
            "abstract": "Modelling the user's multiple behaviors is an essential part of modern e-commerce, whose widely adopted application is to jointly optimize click-through rate (CTR) and conversion rate (CVR) predictions. Most of existing methods overlook the effect of two key characteristics of the user's behaviors: for each item list, (i) contextual dependence refers to that the user's behaviors on any item are not purely determinated by the item itself but also are influenced by the user's previous behaviors (e.g., clicks, purchases) on other items in the same sequence; (ii) multiple time scales means that users are likely to click frequently but purchase periodically. To this end, we develop a new multi-scale user behavior network named H ierarchical r E current R anking O n the E ntire S pace (HEROES) which incorporates the contextual information to estimate the user multiple behaviors in a multi-scale fashion. Concretely, we introduce a hierarchical framework, where the lower layer models the user's engagement behaviors while the upper layer estimates the user's satisfaction behaviors. The proposed architecture can automatically learn a suitable time scale for each layer to capture the dynamic user's behavioral patterns. Besides the architecture, we also introduce the Hawkes process to form a novel recurrent unit which can not only encode the items' features in the context but also formulate the excitation or discouragement from the user's previous behaviors. We further show that HEROES can be extended to build unbiased ranking systems through combinations with the survival analysis technique. Extensive experiments over three large-scale industrial datasets demonstrate the superiority of our model compared with the state-of-the-art methods. characteristics of the user's behaviors: for each item list, (i) contex- tual dependence refers to that the user's behaviors on any item are not purely determinated by the item itself but also are influenced by the user's previous behaviors (e.g., clicks, purchases) on other items in the same sequence; (ii) multiple time scales means that users are likely to click frequently but purchase periodically. To this end, we develop a new multi-scale user behavior network named Hierarchical rEcurrent Ranking On the Entire Space (HEROES) which incorporates the contextual information to estimate the user multiple behaviors in a multi-scale fashion. Concretely, we intro- duce a hierarchical framework, where the lower layer models the user's engagement behaviors while the upper layer estimates the user's satisfaction behaviors. The proposed architecture can auto- matically learn a suitable time scale for each layer to capture the dynamic user's behavioral patterns. Besides the architecture, we also introduce the Hawkes process to form a novel recurrent unit which can not only encode the items' features in the context but also formulate the excitation or discouragement from the user's previous behaviors. We further show that HEROES can be extended to build unbiased ranking systems through combinations with the survival analysis technique. Extensive experiments over three large- scale industrial datasets demonstrate the superiority of our model compared with the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "150343399",
                    "name": "Xianyu Chen"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2144034191",
                    "name": "Yuanbo Chen"
                },
                {
                    "authorId": "2155332248",
                    "name": "Zaifan Jiang"
                },
                {
                    "authorId": "2307300",
                    "name": "Zekun Zhu"
                },
                {
                    "authorId": "2153851086",
                    "name": "Zhewen Su"
                },
                {
                    "authorId": "2156098229",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "12fa8f62d2ac5d77bef36fafd02644ffa51c6c7e",
            "title": "Learn over Past, Evolve for Future: Search-based Time-aware Recommendation with Sequential Behavior Data",
            "abstract": "The personalized recommendation is an essential part of modern e-commerce, where user\u2019s demands are not only conditioned by their profile but also by their recent browsing behaviors as well as periodical purchases made some time ago. In this paper, we propose a novel framework named Search-based Time-Aware Recommendation (STARec), which captures the evolving demands of users over time through a unified search-based time-aware model. More concretely, we first design a search-based module to retrieve a user\u2019s relevant historical behaviors, which are then mixed up with her recent records to be fed into a time-aware sequential network for capturing her time-sensitive demands. Besides retrieving relevant information from her personal history, we also propose to search and retrieve similar user\u2019s records as an additional reference. All these sequential records are further fused to make the final recommendation. Beyond this framework, we also develop a novel label trick that uses the previous labels (i.e., user\u2019s feedbacks) as the input to better capture the user\u2019s browsing pattern. We conduct extensive experiments on three real-world commercial datasets on click-through-rate prediction tasks against state-of-the-art methods. Experimental results demonstrate the superiority and efficiency of our proposed framework and techniques. Furthermore, results of online experiments on a daily item recommendation platform of Company X show that STARec gains average performance improvement of around 6% and 1.5% in its two main item recommendation scenarios on CTR metric respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2135112730",
                    "name": "Xianyu Chen"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": null,
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "7357821",
                    "name": "Ziming Feng"
                },
                {
                    "authorId": "2119021541",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "271f40f4fad4d112e436565e668b79ede690d755",
            "title": "Inductive Relation Prediction Using Analogy Subgraph Embeddings",
            "abstract": "Prevailing methods for relation prediction in heterogeneous graphs including knowledge graphs aim at learning the latent representations (i.e., embeddings) of observed nodes and relations, and are thus limited to the transductive setting where the relation types must be known during training. In this paper, we propose ANalogy SubGraph Embedding Learning (GraphANGEL), a novel relation prediction framework that predicts relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraphs containing the considered relation. Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relation types and leads to more explainable predictive models. Our model consistently outperforms existing models in terms of heterogeneous graph based recommendation as well as knowledge graph completion. We also empirically demonstrate the capability of our model in generalizing to new relation types while producing explainable heat maps of attention scores across the discovered logics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2146020415",
                    "name": "Yangkun Wang"
                },
                {
                    "authorId": "1780721965",
                    "name": "Kounianhua Du"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2148906289",
                    "name": "Zheng Zhang"
                },
                {
                    "authorId": "2242717",
                    "name": "D. Wipf"
                },
                {
                    "authorId": "2156098229",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                }
            ]
        }
    ]
}