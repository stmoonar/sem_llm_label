{
    "authorId": "2110972323",
    "papers": [
        {
            "paperId": "1c10f092ee7cddfcef08fb5eb4e55acc6b71a95e",
            "title": "Distillation from Heterogeneous Models for Top-K Recommendation",
            "abstract": "Recent recommender systems have shown remarkable performance by using an ensemble of heterogeneous models. However, it is exceedingly costly because it requires resources and inference latency proportional to the number of models, which remains the bottleneck for production. Our work aims to transfer the ensemble knowledge of heterogeneous teachers to a lightweight student model using knowledge distillation (KD), to reduce the huge inference costs while retaining high accuracy. Through an empirical study, we find that the efficacy of distillation severely drops when transferring knowledge from heterogeneous teachers. Nevertheless, we show that an important signal to ease the difficulty can be obtained from the teacher\u2019s training trajectory. This paper proposes a new KD framework, named HetComp, that guides the student model by transferring easy-to-hard sequences of knowledge generated from the teachers\u2019 trajectories. To provide guidance according to the student\u2019s learning state, HetComp uses dynamic knowledge construction to provide progressively difficult ranking knowledge and adaptive knowledge transfer to gradually transfer finer-grained ranking information. Our comprehensive experiments show that HetComp significantly improves the distillation quality and the generalization of the student model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "71965979",
                    "name": "SeongKu Kang"
                },
                {
                    "authorId": "1643930327",
                    "name": "Wonbin Kweon"
                },
                {
                    "authorId": "3067773",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2813328",
                    "name": "Jianxun Lian"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "1723357",
                    "name": "Hwanjo Yu"
                }
            ]
        },
        {
            "paperId": "c237a22698223e4060d83027f399f4fb2aa24291",
            "title": "Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations",
            "abstract": "Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient. In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called \\textbf{InteRecAgent}, which employs LLMs as the brain and recommender models as tools. We first outline a minimal set of essential tools required to transform LLMs into InteRecAgent. We then propose an efficient workflow within InteRecAgent for task execution, incorporating key components such as memory components, dynamic demonstration-augmented task planning, and reflection. InteRecAgent enables traditional recommender systems, such as those ID-based matrix factorization models, to become interactive systems with a natural language interface through the integration of LLMs. Experimental results on several public datasets show that InteRecAgent achieves satisfying performance as a conversational recommender system, outperforming general-purpose LLMs. The source code of InteRecAgent is released at https://aka.ms/recagent.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2236672137",
                    "name": "Xu Huang"
                },
                {
                    "authorId": "2813328",
                    "name": "Jianxun Lian"
                },
                {
                    "authorId": "2226475380",
                    "name": "Yuxuan Lei"
                },
                {
                    "authorId": "2237129499",
                    "name": "Jing Yao"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "ff43970c754c27b6808053d9de8e2c64f468c25e",
            "title": "Network Representation Lightening From Hashing to Quantization",
            "abstract": "Information network embedding is an important way to enable efficient graph analytics. However, it still faces with computational challenges in problems such as link prediction and node recommendation, particularly with the increasing scale of networks. Both hashing and quantization are promising approaches for accelerating these problems by orders of magnitude. In the preliminary work, we have proposed to learn binary codes for information networks, but graph analytics may suffer from large accuracy degradation. To reduce information loss while achieving memory and search efficiency, we further propose to learn quantized codes for information networks. In particular, each node is represented by compositing multiple latent vectors, each of which is optimally selected from a distinct set. Since (generalized) matrix factorization unifies several well-known embedding methods with high-order proximity preserved, we propose a Network Representation Lightening framework based on Matrix Factorization (NRL-MF) to learn binary and quantized codes. We also propose an alternating optimization algorithm for efficient parameter learning, even for the generalized matrix factorization case. We finally evaluate NRL-MF on four real-world information network datasets with respect to the tasks of node classification and node recommendation. The results show that NRL-MF significantly outperforms competing baselines in both tasks, and that quantized representations indeed incur much smaller information loss than binarized codes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2118353327",
                    "name": "Zhihao Zhu"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "144143228",
                    "name": "Yong Ge"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2227868312",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "0633da19767ce8253f3681a2bc6ee180775cc4dd",
            "title": "CDSM: Cascaded Deep Semantic Matching on Textual Graphs Leveraging Ad-hoc Neighbor Selection",
            "abstract": "Deep semantic matching aims at discriminating the relationship between documents based on deep neural networks. In recent years, it becomes increasingly popular to organize documents with a graph structure, then leverage both the intrinsic document features and the extrinsic neighbor features to derive discrimination. Most of the existing works mainly care about how to utilize the presented neighbors, whereas limited effort is made to filter appropriate neighbors. We argue that the neighbor features could be highly noisy and partially useful. Thus, a lack of effective neighbor selection will not only incur a great deal of unnecessary computation cost but also restrict the matching accuracy severely. In this work, we propose a novel framework, Cascaded Deep Semantic Matching (CDSM), for accurate and efficient semantic matching on textual graphs. CDSM is highlighted for its two-stage workflow. In the first stage, a lightweight CNN-based ad-hod neighbor selector is deployed to filter useful neighbors for the matching task with a small computation cost. We design both one-step and multi-step selection methods. In the second stage, a high-capacity graph-based matching network is employed to compute fine-grained relevance scores based on the well-selected neighbors. It is worth noting that CDSM is a generic framework which accommodates most of the mainstream graph-based semantic matching networks. The major challenge is how the selector can learn to discriminate the neighbors\u2019 usefulness which has no explicit labels. To cope with this problem, we design a weak-supervision strategy for optimization, where we train the graph-based matching network at first and then the ad-hoc neighbor selector is learned on top of the annotations from the matching network. We conduct extensive experiments with three large-scale datasets, showing that CDSM notably improves the semantic matching accuracy and efficiency thanks to the selection of high-quality neighbors. The source code is released at https://github.com/jingjyyao/CDSM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110070113",
                    "name": "Jing Yao"
                },
                {
                    "authorId": "2145976175",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "9008621",
                    "name": "Junhan Yang"
                },
                {
                    "authorId": "1897235",
                    "name": "Zhicheng Dou"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "099775ec9f69da6c8858b65151f20e9b323c455f",
            "title": "Cooperative Retriever and Ranker in Deep Recommenders",
            "abstract": "Deep recommender systems (DRS) are intensively applied in modern web services. To deal with the massive web contents, DRS employs a two-stage workflow: retrieval and ranking, to generate its recommendation results. The retriever aims to select a small set of relevant candidates from the entire items with high efficiency; while the ranker, usually more precise but time-consuming, is supposed to further refine the best items from the retrieved candidates. Traditionally, the two components are trained either independently or within a simple cascading pipeline, which is prone to poor collaboration effect. Though some latest works suggested to train retriever and ranker jointly, there still exist many severe limitations: item distribution shift between training and inference, false negative, and misalignment of ranking order. As such, it remains to explore effective collaborations between retriever and ranker. In this work, we present a novel framework for the joint training of retriever and ranker, named CoRR (Cooperative Retriever and Ranker). With CoRR, the retriever is improved by deriving high-quality training signals from the ranker, while the ranker is improved by learning to discriminate hard negatives sampled by the retriever. We introduce two critical techniques. Firstly, we develop an adaptive and scalable sampler based on the retriever, to generate hard negative samples for the ranker\u2019s training. Compared with the widely-used exact top-k sampling, our method effectively alleviates the issues of false negative and item distribution shift, and thus improves the ranker\u2019s discriminability. Secondly, we propose a novel asymptotic-unbiased estimation of KL divergence, which serves as the objective for knowledge distillation. The new objective can be efficiently optimized with commonly-used optimizers. More importantly, it leads to better alignment of ranking order between retriever and ranker, which helps to improve the retrieval quality. We conduct comprehensive experiments over four large-scale datasets, where CoRR outperforms both conventional DRS and the existing joint training methods with notable advantages. Our code will be open-sourced to facilitate future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22640218",
                    "name": "Xunpeng Huang"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2108459889",
                    "name": "Jin Chen"
                },
                {
                    "authorId": "2025990230",
                    "name": "Liu Zheng"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2113754294",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "0eb19e852013f83e2001e3191ccd3b46b280d417",
            "title": "Distill-VQ: Learning Retrieval Oriented Vector Quantization By Distilling Knowledge from Dense Embeddings",
            "abstract": "Vector quantization (VQ) based ANN indexes, such as Inverted File System (IVF) and Product Quantization (PQ), have been widely applied to embedding based document retrieval thanks to the competitive time and memory efficiency. Originally, VQ is learned to minimize the reconstruction loss, i.e., the distortions between the original dense embeddings and the reconstructed embeddings after quantization. Unfortunately, such an objective is inconsistent with the goal of selecting ground-truth documents for the input query, which may cause severe loss of retrieval quality. Recent works identify such a defect, and propose to minimize the retrieval loss through contrastive learning. However, these methods intensively rely on queries with ground-truth documents, whose performance is limited by the insufficiency of labeled data. In this paper, we propose Distill-VQ, which unifies the learning of IVF and PQ within a knowledge distillation framework. In Distill-VQ, the dense embeddings are leveraged as \"teachers'', which predict the query's relevance to the sampled documents. The VQ modules are treated as the \"students'', which are learned to reproduce the predicted relevance, such that the reconstructed embeddings may fully preserve the retrieval result of the dense embeddings. By doing so, Distill-VQ is able to derive substantial training signals from the massive unlabeled data, which significantly contributes to the retrieval quality. We perform comprehensive explorations for the optimal conduct of knowledge distillation, which may provide useful insights for the learning of VQ based ANN index. We also experimentally show that the labeled data is no longer a necessity for high-quality vector quantization, which indicates Distill-VQ's strong applicability in practice. The evaluations are performed on MS MARCO and Natural Questions benchmarks, where Distill-VQ notably outperforms the SOTA VQ methods in Recall and MRR. Our code is avaliable at https://github.com/staoxiao/LibVQ.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051175765",
                    "name": "Shitao Xiao"
                },
                {
                    "authorId": "2145976175",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2114924471",
                    "name": "Weihao Han"
                },
                {
                    "authorId": "2144231046",
                    "name": "Jianjin Zhang"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2171182",
                    "name": "Yeyun Gong"
                },
                {
                    "authorId": "2157956050",
                    "name": "Qi Chen"
                },
                {
                    "authorId": "145338263",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2118180377",
                    "name": "Hao Sun"
                },
                {
                    "authorId": "2237813",
                    "name": "Yingxia Shao"
                },
                {
                    "authorId": "2150171067",
                    "name": "Denvy Deng"
                },
                {
                    "authorId": null,
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "2e53d3646a4e1605fad29063e01a0333080a11da",
            "title": "Ada-Ranker: A Data Distribution Adaptive Ranking Paradigm for Sequential Recommendation",
            "abstract": "A large-scale recommender system usually consists of recall and ranking modules. The goal of ranking modules (aka rankers) is to elaborately discriminate users' preference on item candidates proposed by recall modules. With the success of deep learning techniques in various domains, we have witnessed the mainstream rankers evolve from traditional models to deep neural models. However, the way that we design and use rankers remains unchanged: offline training the model, freezing the parameters, and deploying it for online serving. Actually, the candidate items are determined by specific user requests, in which underlying distributions (e.g., the proportion of items for different categories, the proportion of popular or new items) are highly different from one another in a production environment. The classical parameter-frozen inference manner cannot adapt to dynamic serving circumstances, making rankers' performance compromised. In this paper, we propose a new training and inference paradigm, termed as Ada-Ranker, to address the challenges of dynamic online serving. Instead of using parameter-frozen models for universal serving, Ada-Ranker can adaptively modulate parameters of a ranker according to the data distribution of the current group of item candidates. We first extract distribution patterns from the item candidates. Then, we modulate the ranker by the patterns to make the ranker adapt to the current data distribution. Finally, we use the revised ranker to score the candidate list. In this way, we empower the ranker with the capacity of adapting from a global model to a local model which better handles the current task. As a first study, we examine our Ada-Ranker paradigm in the sequential recommendation scenario. Experiments on three datasets demonstrate that Ada-Ranker can effectively enhance various base sequential models and also outperform a comprehensive set of competitive baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46515856",
                    "name": "Xinyan Fan"
                },
                {
                    "authorId": "2813328",
                    "name": "Jianxun Lian"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2145976175",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "541070dde226770469d483a7d1601bae5cee083f",
            "title": "MINDSim: User Simulator for News Recommenders",
            "abstract": "Recommender system is playing an increasingly important role in online news platforms nowadays. Recently, there is a growing demand for applying reinforcement learning (RL) algorithms to news recommendation aiming to maximize long-term and/or non-differentiable objectives. However, without an interactive simulated environment, it is extremely costly to develop powerful RL agents for news recommendation. In this paper, we build a user simulator, namely MINDSim, for news recommendation. Targeting at new user generation and corresponding behavior simulation, we first construct a hidden space for users using a generative adversarial network, so that new users can be generated by sampling from this hidden space. To capture complex and fast user interest drifts over time, we adopt an encoder-decoder architecture, which takes the clicked news during the simulation as input and outputs the new user interests for the next period of time. Finally, we build the MINDSim simulator using MIcrosoft News Dataset (MIND), and extensive experimental results on this large-scale real-world dataset demonstrate that MINDSim can simulate the behaviors of real users with high quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13289447",
                    "name": "Xufang Luo"
                },
                {
                    "authorId": "2145976175",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2051175765",
                    "name": "Shitao Xiao"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2136275905",
                    "name": "Dongsheng Li"
                }
            ]
        },
        {
            "paperId": "7b87395bc4e9963c20c4dcfb17c47238b758212a",
            "title": "Uni-Retriever: Towards Learning the Unified Embedding Based Retriever in Bing Sponsored Search",
            "abstract": "Embedding based retrieval (EBR) is a fundamental building block in many web applications. However, EBR in sponsored search is distinguished from other generic scenarios and technically challenging due to the need of serving multiple retrieval purposes: firstly, it has to retrieve high-relevance ads, which may exactly serve user's search intent; secondly, it needs to retrieve high-CTR ads so as to maximize the overall user clicks. In this paper, we present a novel representation learning framework Uni-Retriever developed for Bing Search, which unifies two different training modes knowledge distillation and contrastive learning to realize both required objectives. On one hand, the capability of making high-relevance retrieval is established by distilling knowledge from the \"relevance teacher model''. On the other hand, the capability of making high-CTR retrieval is optimized by learning to discriminate user's clicked ads from the entire corpus. The two training modes are jointly performed as a multi-objective learning process, such that the ads of high relevance and CTR can be favored by the generated embeddings. Besides the learning strategy, we also elaborate our solution for EBR serving pipeline built upon the substantially optimized DiskANN, where massive-scale EBR can be performed with competitive time and memory efficiency, and accomplished in high-quality. We make comprehensive offline and online experiments to evaluate the proposed techniques, whose findings may provide useful insights for the future development of EBR systems. Uni-Retriever has been mainstreamed as the major retrieval path in Bing's production thanks to the notable improvements on the representation and EBR serving quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144231046",
                    "name": "Jianjin Zhang"
                },
                {
                    "authorId": "2145976175",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2114924471",
                    "name": "Weihao Han"
                },
                {
                    "authorId": "2051175765",
                    "name": "Shitao Xiao"
                },
                {
                    "authorId": "2058585152",
                    "name": "Rui Zheng"
                },
                {
                    "authorId": "2237813",
                    "name": "Yingxia Shao"
                },
                {
                    "authorId": "2118180377",
                    "name": "Hao Sun"
                },
                {
                    "authorId": "2115315923",
                    "name": "Hanqing Zhu"
                },
                {
                    "authorId": "2154412922",
                    "name": "Premkumar Srinivasan"
                },
                {
                    "authorId": "2150171067",
                    "name": "Denvy Deng"
                },
                {
                    "authorId": null,
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "aa1d21b5d34b705ceeb5698d9a2ecfc802125e92",
            "title": "Reinforcement Routing on Proximity Graph for Efficient Recommendation",
            "abstract": "We focus on Maximum Inner Product Search (MIPS), which is an essential problem in many machine learning communities. Given a query, MIPS finds the most similar items with the maximum inner products. Methods for Nearest Neighbor Search (NNS) which is usually defined on metric space do not exhibit the satisfactory performance for MIPS problem since inner product is a non-metric function. However, inner products exhibit many good properties compared with metric functions, such as avoiding vanishing and exploding gradients. As a result, inner product is widely used in many recommendation systems, which makes efficient Maximum Inner Product Search a key for speeding up many recommendation systems. Graph-based methods for NNS problem show the superiorities compared with other class methods. Each data point of the database is mapped to a node of the proximity graph. Nearest neighbor search in the database can be converted to route on the proximity graph to find the nearest neighbor for the query. This technique can be used to solve MIPS problem. Instead of searching the nearest neighbor for the query, we search the item with a maximum inner product with query on the proximity graph. In this article, we propose a reinforcement model to train an agent to search on the proximity graph automatically for MIPS problem if we lack the ground truths of training queries. If we know the ground truths of some training queries, our model can also utilize these ground truths by imitation learning to improve the agent\u2019s searchability. By experiments, we can see that our proposed mode which combines reinforcement learning with imitation learning shows the superiorities over the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153286417",
                    "name": "Chao Feng"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2108045320",
                    "name": "Xiting Wang"
                },
                {
                    "authorId": "2145976175",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2227868312",
                    "name": "Enhong Chen"
                }
            ]
        }
    ]
}