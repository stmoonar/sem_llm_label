{
    "authorId": "103226724",
    "papers": [
        {
            "paperId": "3a74772a6011675ce2bdc87100fffcf4d18f5907",
            "title": "Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey",
            "abstract": "Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2146666303",
                    "name": "Junda Wu"
                },
                {
                    "authorId": "2261901774",
                    "name": "Jiaxin Yuan"
                },
                {
                    "authorId": "2257361107",
                    "name": "Yifan Yang"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "52220309",
                    "name": "Fuxiao Liu"
                },
                {
                    "authorId": "2291143084",
                    "name": "Tianrui Guan"
                },
                {
                    "authorId": "2291313121",
                    "name": "Haoliang Wang"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2284680226",
                    "name": "Julian McAuley"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2257407889",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "4a402c7f4f2a5aaa1f8429be9dd19469d24b6d67",
            "title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications",
            "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become prevalent in social network communications. This has spurred increasing scholarly interest in exploring their attributes and functionalities. However, emoji-related research and application face two primary challenges. First, researchers typically rely on crowd-sourcing to annotate emojis in order to understand their sentiments, usage intentions, and semantic meanings. Second, subjective interpretations by users can often lead to misunderstandings of emojis and cause the communication barrier. Large Language Models (LLMs) have achieved significant success in various annotation tasks, with ChatGPT demonstrating expertise across multiple domains. In our study, we assess ChatGPT's effectiveness in handling previously annotated and downstream tasks. Our objective is to validate the hypothesis that ChatGPT can serve as a viable alternative to human annotators in emoji research and that its ability to explain emoji meanings can enhance clarity and transparency in online communications. Our findings indicate that ChatGPT has extensive knowledge of emojis. It is adept at elucidating the meaning of emojis across various application scenarios and demonstrates the potential to replace human annotators in a range of tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2282902714",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "2282572921",
                    "name": "Xuan Lu"
                },
                {
                    "authorId": "2282528493",
                    "name": "Ge Gao"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "6fa3544f42bc026ac684cf6c7a8cd50f59b3ee7d",
            "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
            "abstract": "Large language models (LLMs) have significantly advanced various natural language processing tasks, but deploying them remains computationally expensive. Knowledge distillation (KD) is a promising solution, enabling the transfer of capabilities from larger teacher LLMs to more compact student models. Particularly, sequence-level KD, which distills rationale-based reasoning processes instead of merely final outcomes, shows great potential in enhancing students' reasoning capabilities. However, current methods struggle with sequence level KD under long-tailed data distributions, adversely affecting generalization on sparsely represented domains. We introduce the Multi-Stage Balanced Distillation (BalDistill) framework, which iteratively balances training data within a fixed computational budget. By dynamically selecting representative head domain examples and synthesizing tail domain examples, BalDistill achieves state-of-the-art performance across diverse long-tailed datasets, enhancing both the efficiency and efficacy of the distilled models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2307469621",
                    "name": "Jing Zhu"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2282902714",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2268686199",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "96b3c4d0afb5ccee486e2a99f52426a5c565cd74",
            "title": "The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education",
            "abstract": "Assessing instruction quality is a fundamental component of any improvement efforts in the education system. However, traditional manual assessments are expensive, subjective, and heavily dependent on observers\u2019 expertise and idiosyncratic factors, preventing teachers from getting timely and frequent feedback. Different from prior research that mostly focuses on low-inference instructional practices on a singular basis, this paper presents the first study that leverages Natural Language Processing (NLP) techniques to assess multiple high-inference instructional practices in two distinct educational settings: in-person K-12 classrooms and simulated performance tasks for pre-service teachers. This is also the first study that applies NLP to measure a teaching practice that is widely acknowledged to be particularly effective for students with special needs. We confront two challenges inherent in NLP-based instructional analysis, including noisy and long input data and highly skewed distributions of human ratings. Our results suggest that pretrained Language Models (PLMs) demonstrate performances comparable to the agreement level of human raters for variables that are more discrete and require lower inference, but their efficacy diminishes with more complex teaching practices. Interestingly, using only teachers\u2019 utterances as input yields strong results for student-centered variables, alleviating common concerns over the difficulty of collecting and transcribing high-quality student speech data in in-person teaching settings. Our findings highlight both the potential and the limitations of current NLP techniques in the education domain, opening avenues for further exploration.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2295104638",
                    "name": "Jing Liu"
                },
                {
                    "authorId": "2294722467",
                    "name": "Nathan Jones"
                },
                {
                    "authorId": "2295911167",
                    "name": "Julie Cohen"
                },
                {
                    "authorId": "2241315338",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "01efb3fd2d3ae4b5f4389c916c94f2c6d9c11b81",
            "title": "Explore Spurious Correlations at the Concept Level in Language Models for Text Classification",
            "abstract": "Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label distributions in training data or ICL exemplars. Previous research has primarily concentrated on word, phrase, and syntax features, neglecting the concept level, often due to the absence of concept labels and difficulty in identifying conceptual content in input texts. This paper introduces two main contributions. First, we employ ChatGPT to assign concept labels to texts, assessing concept bias in models during fine-tuning or ICL on test data. We find that LMs, when encountering spurious correlations between a concept and a label in training or prompts, resort to shortcuts for predictions. Second, we introduce a data rebalancing technique that incorporates ChatGPT-generated counterfactual data, thereby balancing label distribution and mitigating spurious correlations. Our method's efficacy, surpassing traditional token removal approaches, is validated through extensive testing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145926835",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2256993596",
                    "name": "Bang An"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2257407877",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "9806cac2d36feda043dcdfe0f4de2608127da27c",
            "title": "Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps",
            "abstract": "We investigate the role of various demonstration components in the in-context learning (ICL) performance of large language models (LLMs). Specifically, we explore the impacts of ground-truth labels, input distribution, and complementary explanations, particularly when these are altered or perturbed. We build on previous work, which offers mixed findings on how these elements influence ICL. To probe these questions, we employ explainable NLP (XNLP) methods and utilize saliency maps of contrastive demonstrations for both qualitative and quantitative analysis. Our findings reveal that flipping ground-truth labels significantly affects the saliency, though it's more noticeable in larger LLMs. Our analysis of the input distribution at a granular level reveals that changing sentiment-indicative terms in a sentiment analysis task to neutral ones does not have as substantial an impact as altering ground-truth labels. Finally, we find that the effectiveness of complementary explanations in boosting ICL performance is task-dependent, with limited benefits seen in sentiment analysis tasks compared to symbolic reasoning tasks. These insights are critical for understanding the functionality of LLMs and guiding the development of effective demonstrations, which is increasingly relevant in light of the growing use of LLMs in applications such as ChatGPT. Our research code is publicly available at https://github.com/paihengxu/XICL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46948092",
                    "name": "Zongxi Li"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "52220309",
                    "name": "Fuxiao Liu"
                },
                {
                    "authorId": "2112927266",
                    "name": "Hyemi Song"
                }
            ]
        },
        {
            "paperId": "bf12eb5959d7e2d365893a038805c623815033db",
            "title": "GFairHint: Improving Individual Fairness for Graph Neural Networks via Fairness Hint",
            "abstract": "Given the growing concerns about fairness in machine learning and the impressive performance of Graph Neural Networks (GNNs) on graph data learning, algorithmic fairness in GNNs has attracted significant attention. While many existing studies improve fairness at the group level, only a few works promote individual fairness, which renders similar outcomes for similar individuals. A desirable framework that promotes individual fairness should (1) balance between fairness and performance, (2) accommodate two commonly-used individual similarity measures (externally annotated and computed from input features), (3) generalize across various GNN models, and (4) be computationally efficient. Unfortunately, none of the prior work achieves all the desirables. In this work, we propose a novel method, GFairHint, which promotes individual fairness in GNNs and achieves all aforementioned desirables. GFairHint learns fairness representations through an auxiliary link prediction task, and then concatenates the representations with the learned node embeddings in original GNNs as a\"fairness hint\". Through extensive experimental investigations on five real-world graph datasets under three prevalent GNN models covering both individual similarity measures above, GFairHint achieves the best fairness results in almost all combinations of datasets with various backbone models, while generating comparable utility results, with much less computational cost compared to the previous state-of-the-art (SoTA) method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2145926835",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "49640821",
                    "name": "Bang An"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2117426487",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "1d52942c836fe3e32f0fe5748f4c137fceea50a6",
            "title": "The Twitter Social Mobility Index: Measuring Social Distancing Practices from Geolocated Tweets",
            "abstract": "Social distancing is an important component of the response to the novel Coronavirus (COVID-19) pandemic. Minimizing social interactions and travel reduces the rate at which the infection spreads, and \"flattens the curve\" such that the medical system can better treat infected individuals. However, it remains unclear how the public will respond to these policies. This paper presents the Twitter Social Mobility Index, a measure of social distancing and travel derived from Twitter data. We use public geolocated Twitter data to measure how much a user travels in a given week. We find a large reduction in travel in the United States after the implementation of social distancing policies, with larger reductions in states that were early adopters and smaller changes in states without policies. Our findings are presented on this http URL and we will continue to update our analysis during the pandemic.",
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "1782853",
                    "name": "Mark Dredze"
                },
                {
                    "authorId": "2145020703",
                    "name": "David A. Broniatowski"
                }
            ]
        },
        {
            "paperId": "7ccc13da5ed0f2dbfde7e02b7d590c74cf4bdae2",
            "title": "Using Noisy Self-Reports to Predict Twitter User Demographics",
            "abstract": "Computational social science studies often contextualize content analysis within standard demographics. Since demographics are unavailable on many social media platforms (e.g. Twitter), numerous studies have inferred demographics automatically. Despite many studies presenting proof-of-concept inference of race and ethnicity, training of practical systems remains elusive since there are few annotated datasets. Existing datasets are small, inaccurate, or fail to cover the four most common racial and ethnic groups in the United States. We present a method to identify self-reports of race and ethnicity from Twitter profile descriptions. Despite the noise of automated supervision, our self-report datasets enable improvements in classification performance on gold standard self-report survey data. The result is a reproducible method for creating large-scale training resources for race and ethnicity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1411379613",
                    "name": "Zach Wood-Doughty"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2146023325",
                    "name": "Xiao Liu"
                },
                {
                    "authorId": "1782853",
                    "name": "Mark Dredze"
                }
            ]
        }
    ]
}