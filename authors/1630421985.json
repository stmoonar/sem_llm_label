{
    "authorId": "1630421985",
    "papers": [
        {
            "paperId": "05d2264d5bf06a3cac36be999af72d2c55f283a6",
            "title": "3D-IncNet: Head and Neck (H&N) Primary Tumors Segmentation and Survival Prediction",
            "abstract": "Cancer begins when healthy cells change and grow out of control, forming a mass called a tumor. Head and neck (H&N) cancers usually develop in or around the head and neck, including the mouth (oral cavity), nose and sinuses, throat (pharynx), and voice box (larynx). 4% of all cancers are H&N cancers with a very low survival rate (a five-year survival rate of 64.7%). FDG-PET/CT imaging is often used for early diagnosis and staging of H&N tumors, thus improving these patients' survival rates. This work presents a novel 3D-Inception-Residual aided with 3D depth-wise convolution and squeeze and excitation block. We introduce a 3D depth-wise convolution-inception encoder consisting of an additional 3D squeeze and excitation block and a 3D depth-wise convolution-based residual learning decoder (3D-IncNet), which not only helps to recalibrate the channel-wise features but adaptively through explicit inter-dependencies modeling but also integrate the coarse and fine features resulting in accurate tumor segmentation. We further demonstrate the effectiveness of inception-residual encoder-decoder architecture in achieving better dice scores and the impact of depth-wise convolution in lowering the computational cost. We applied random forest for survival prediction on deep, clinical, and radiomics features. Experiments are conducted on the benchmark HECKTOR21 challenge, which showed significantly better performance by surpassing the state-of-the-artwork and achieved 0.836 and 0.811 concordance index and dice scores, respectively. We made the model and code publicly available.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150283773",
                    "name": "Abdul Qayyum"
                },
                {
                    "authorId": "2641751",
                    "name": "A. Benzinou"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "9437414",
                    "name": "Moona Mazher"
                },
                {
                    "authorId": "2190424062",
                    "name": "Thanh Thi Nguyen"
                },
                {
                    "authorId": "143844336",
                    "name": "D. Puig"
                },
                {
                    "authorId": "2560124",
                    "name": "Fatemeh Vafaee"
                }
            ]
        },
        {
            "paperId": "1024f287b9e8ad6e530cc92ec627901bccbe1a11",
            "title": "BTS: Building Timeseries Dataset: Empowering Large-Scale Building Analytics",
            "abstract": "Buildings play a crucial role in human well-being, influencing occupant comfort, health, and safety. Additionally, they contribute significantly to global energy consumption, accounting for one-third of total energy usage, and carbon emissions. Optimizing building performance presents a vital opportunity to combat climate change and promote human flourishing. However, research in building analytics has been hampered by the lack of accessible, available, and comprehensive real-world datasets on multiple building operations. In this paper, we introduce the Building TimeSeries (BTS) dataset. Our dataset covers three buildings over a three-year period, comprising more than ten thousand timeseries data points with hundreds of unique ontologies. Moreover, the metadata is standardized using the Brick schema. To demonstrate the utility of this dataset, we performed benchmarks on two tasks: timeseries ontology classification and zero-shot forecasting. These tasks represent an essential initial step in addressing challenges related to interoperability in building analytics. Access to the dataset and the code used for benchmarking are available here: https://github.com/cruiseresearchgroup/DIEF_BTS .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1380742035",
                    "name": "Arian Prabowo"
                },
                {
                    "authorId": "2303055866",
                    "name": "Xiachong Lin"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2302775049",
                    "name": "Hao Xue"
                },
                {
                    "authorId": "2306265096",
                    "name": "Emily W. Yap"
                },
                {
                    "authorId": "2302803663",
                    "name": "Matthew Amos"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        },
        {
            "paperId": "14646083d6826b9437cae15deb9f2182e0fe56ff",
            "title": "A Gap in Time: The Challenge of Processing Heterogeneous IoT Point Data in Buildings",
            "abstract": "The growing need for sustainable energy solutions has driven the integration of digitalized buildings into the power grid, utilizing Internet-of-Things technology to optimize building performance and energy efficiency. However, incorporating IoT point data within deep-learning frameworks for energy management presents a complex challenge, predominantly due to the inherent data heterogeneity. This paper comprehensively analyzes the multifaceted heterogeneity present in real-world building IoT data streams. We meticulously dissect the heterogeneity across multiple dimensions, encompassing ontology, etiology, temporal irregularity, spatial diversity, and their combined effects on the IoT point data distribution. In addition, experiments using state-of-the-art forecasting models are conducted to evaluate their impacts on the performance of deep-learning models for forecasting tasks. By charting the diversity along these dimensions, we illustrate the challenges and delineate pathways for future research to leverage this heterogeneity as a resource rather than a roadblock. This exploration sets the stage for advancing the predictive abilities of deep-learning algorithms and catalyzing the evolution of intelligent energy-efficient buildings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2303055866",
                    "name": "Xiachong Lin"
                },
                {
                    "authorId": "1380742035",
                    "name": "Arian Prabowo"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2302775049",
                    "name": "Hao Xue"
                },
                {
                    "authorId": "2302803663",
                    "name": "Matthew Amos"
                },
                {
                    "authorId": "2302764538",
                    "name": "Sam Behrens"
                },
                {
                    "authorId": "2302798088",
                    "name": "Stephen White"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        },
        {
            "paperId": "2b442374671e6360302c05e77e420cedebdb7e8b",
            "title": "A Novel Collaborative SRU Network With Dynamic Behaviour Aggregation, Reduced Communication Overhead and Explainable Features",
            "abstract": "Leakage and tampering problems in collection and transmission of biomedical data have attracted much attention as these concerns instigates negative impression regarding privacy, security, and reputation of medical networks. This article presents a novel security model that establishes a threat-vector database based on the dynamic behaviours of smart healthcare systems. Then, an improved and privacy-preserved SRU network is designed that aims to alleviate fading gradient issue and enhance the learning process by reducing computational cost. Then, an intelligent federated learning algorithm is deployed to enable multiple healthcare networks to form a collaborative security model in a personalized manner without the loss of privacy. The proposed security method is both parallelizable and computationally effective since the dynamic behaviour aggregation strategy empowers the model to work collaboratively and reduce communication overhead by dynamically adjusting the number of participating clients. Additionally, the visualization of the decision process based on the explainability of features enhances the understanding of security experts by enabling them to comprehend the underlying data evidence and causal reasoning. Compared to existing methods, the proposed security method is capable of thoroughly analyzing and detecting severe security threats with high accuracy, reduce overhead and lower computation cost along with enhanced privacy of biomedical data.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49525434",
                    "name": "I. A. Khan"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2064637985",
                    "name": "Dechang Pi"
                },
                {
                    "authorId": "2066186747",
                    "name": "U. Zia"
                },
                {
                    "authorId": "2279009867",
                    "name": "Shaharyar Kamal"
                },
                {
                    "authorId": "48377962",
                    "name": "Yasir Hussain"
                }
            ]
        },
        {
            "paperId": "31297efc56b1c31c7254d3dc6c882ba349385308",
            "title": "Automated Detection and Segmentation of Glioblastoma in MRI Using Multi-Level Diffusion Transformer U-Net",
            "abstract": "Detecting malignant tumors at an early stage is crucial for effective treatment and an improved prognosis of brain cancer. Radiologists use MRI imaging modality to detect and diagnose glioblastoma. For efficient detection, numerous deeplearning methods have been proposed in the past decade. Detecting brain tumors in MR images is challenging owing to the heterogeneity in anatomical structures across patients, and difficulties posed by low contrast, inhomogeneous intensity levels, and artifacts. In this paper, we proposed a multi-level Diffusion Transformer U-Net (mDT-UNet) with a modified cross-attention module. Our model extracts features from both global and local levels of the MR images and manual segmentations providing a wider range of contextual information. Our proposed model attained an average accuracy of 95% on the BraTS 2020 dataset whereas U-Net achieved 81% and Swin Transformer achieved 86% accuracy. In addition, we evaluated our model on various benchmark datasets; CPM-RadPath, UCSF PDGM, EGD, and IvyGAP. With appropriate pre-training on large medical datasets, our model can be optimized for various medical image segmentation tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283326491",
                    "name": "Anum Masood"
                },
                {
                    "authorId": "2301210198",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "2158396126",
                    "name": "Junaid Rashid"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                }
            ]
        },
        {
            "paperId": "378d96c43e212291248ac18bd82048cea6f8d898",
            "title": "Dynamic Hypersphere Embedding Scale Against Adversarial Attacks",
            "abstract": "Learning robust features against adversarial attacks is a challenging task that requires highly complex models, especially on aerial images, because they are subject to environmental and adversarial changes. Embedding hypersphere normalization, along with adversarial settings, causes performance degradation and enables the feature to overlap. To address this, in this article, we propose a dynamic hypersphere embedding scale (DHS) method that remaps the normalized features to a relative scale to learn robust features. The proposed method combines the benefits of hypersphere embedding without scarifying softmax advantages. The DHS aggregates the normalized features and the non-normalized ones. It uses a hypersphere embedding to enforce maximum-margin to the features that yield shorter magnitude and utilizes a dynamic scale to avoid features overlapping in the case of adversarial attacks. We validate the DHS's effectiveness by embedding the adversarial training attacks such as Projected Gradient Descent (PGD), CW, and DeepFool. Empirical experiments revealed that the DHS improves the model performance by 12% when using the PGD attack, with less computation than legacy hypersphere models. Another set of experiments showed that the DHS does not obfuscate the gradient.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145867132",
                    "name": "Mohammed Hassanin"
                },
                {
                    "authorId": "3193106",
                    "name": "Nour Moustafa"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2497319",
                    "name": "Md. Iftekhar Tanveer"
                },
                {
                    "authorId": "122897729",
                    "name": "D. Ormrod"
                },
                {
                    "authorId": "9087628",
                    "name": "J. Slay"
                }
            ]
        },
        {
            "paperId": "3f69dedaff5f4fd430f18c0272f0905d3ba53d15",
            "title": "DHGCN: Dynamic Hop Graph Convolution Network for Self-Supervised Point Cloud Learning",
            "abstract": "Recent works attempt to extend Graph Convolution Networks (GCNs) to point clouds for classification and segmentation tasks. These works tend to sample and group points to create smaller point sets locally and mainly focus on extracting local features through GCNs, while ignoring the relationship between point sets. In this paper, we propose the Dynamic Hop Graph Convolution Network (DHGCN) for explicitly learning the contextual relationships between the voxelized point parts, which are treated as graph nodes. Motivated by the intuition that the contextual information between point parts lies in the pairwise adjacent relationship, which can be depicted by the hop distance of the graph quantitatively, we devise a novel self-supervised part-level hop distance reconstruction task and design a novel loss function accordingly to facilitate training. In addition, we propose the Hop Graph Attention (HGA), which takes the learned hop distance as input for producing attention weights to allow edge features to contribute distinctively in aggregation. Eventually, the proposed DHGCN is a plug-and-play module that is compatible with point-based backbone networks. Comprehensive experiments on different backbones and tasks demonstrate that our self-supervised method achieves state-of-the-art performance. Our source codes are available at: https://github.com/Jinec98/DHGCN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40791864",
                    "name": "Jincen Jiang"
                },
                {
                    "authorId": "2125091917",
                    "name": "Lizhi Zhao"
                },
                {
                    "authorId": "2278401209",
                    "name": "Xuequan Lu"
                },
                {
                    "authorId": "2278778284",
                    "name": "Wei Hu"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2278411068",
                    "name": "Meili Wang"
                }
            ]
        },
        {
            "paperId": "8a18689fa58b9e0305c13ced9a585b12760c8be5",
            "title": "GRA: Graph Representation Alignment for Semi-Supervised Action Recognition",
            "abstract": "Graph convolutional networks (GCNs) have emerged as a powerful tool for action recognition, leveraging skeletal graphs to encapsulate human motion. Despite their efficacy, a significant challenge remains the dependency on huge labeled datasets. Acquiring such datasets is often prohibitive, and the frequent occurrence of incomplete skeleton data, typified by absent joints and frames, complicates the testing phase. To tackle these issues, we present graph representation alignment (GRA), a novel approach with two main contributions: 1) a self-training (ST) paradigm that substantially reduces the need for labeled data by generating high-quality pseudo-labels, ensuring model stability even with minimal labeled inputs and 2) a representation alignment (RA) technique that utilizes consistency regularization to effectively reduce the impact of missing data components. Our extensive evaluations on the NTU RGB+D and Northwestern-UCLA (N-UCLA) benchmarks demonstrate that GRA not only improves GCN performance in data-constrained environments but also retains impressive performance in the face of data incompleteness.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279276013",
                    "name": "Kuan-Hung Huang"
                },
                {
                    "authorId": "2279318748",
                    "name": "Yao-Bang Huang"
                },
                {
                    "authorId": "151476997",
                    "name": "Yong-Xiang Lin"
                },
                {
                    "authorId": "145525478",
                    "name": "K. Hua"
                },
                {
                    "authorId": "2239837271",
                    "name": "M. Tanveer"
                },
                {
                    "authorId": "2278401209",
                    "name": "Xuequan Lu"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                }
            ]
        },
        {
            "paperId": "8fcf5e276368c17d74e55d626a5ce5841bf64cdc",
            "title": "Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings",
            "abstract": "Large language models (LLMs) have garnered significant interest in natural language processing (NLP), particularly their remarkable performance in various downstream tasks in resource-rich languages. Recent studies have highlighted the limitations of LLMs in low-resource languages, primarily focusing on binary classification tasks and giving minimal attention to South Asian languages. These limitations are primarily attributed to constraints such as dataset scarcity, computational costs, and research gaps specific to low-resource languages. To address this gap, we present datasets for sentiment and hate speech tasks by translating from English to Bangla, Hindi, and Urdu, facilitating research in low-resource language processing. Further, we comprehensively examine zero-shot learning using multiple LLMs in English and widely spoken South Asian languages. Our findings indicate that GPT-4 consistently outperforms Llama 2 and Gemini, with English consistently demonstrating superior performance across diverse tasks compared to low-resource languages. Furthermore, our analysis reveals that natural language inference (NLI) exhibits the highest performance among the evaluated tasks, with GPT-4 demonstrating superior capabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261399237",
                    "name": "Md. Arid Hasan"
                },
                {
                    "authorId": "2176643875",
                    "name": "Prerona Tarannum"
                },
                {
                    "authorId": "2261403738",
                    "name": "Krishno Dey"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2301210198",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "9b7c8adfae5545aa9518fe0e733960c5361b3f9f",
            "title": "Unveiling Misogyny Memes: A Multimodal Analysis of Modality Effects on Identification",
            "abstract": "In today's digital era, memes have become a popular means of communication that often reflect societal attitudes as well as prejudices. Misogyny memes are a form of memes that explicitly discriminate against women in various aspects, such as shaming or stereotyping. This research aims to identify misogynous memes through deep learning multimodal analysis and determine which modality, text or image, plays a more significant role in fairness considerations. To achieve this, we utilized the dataset GOAT-benchmarks, which comprises over 6,000 diverse memes covering topics like implicit hate speech, sexism, and cyberbullying. Furthermore, we evaluated the fairness of these models by assessing their performance across different demographic groups. Our findings revealed that while both text and image modalities contribute to identifying misogynous memes, text plays a significant role in misogyny identification, while image contributes further in terms of fairness. This study emphasizes the importance of multimodal analysis in recognizing and mitigating biases in online content. Disclaimer: This paper contains content that may be disturbing to some readers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301225724",
                    "name": "Shijing Chen"
                },
                {
                    "authorId": "2301210198",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "1630421985",
                    "name": "Imran Razzak"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        }
    ]
}