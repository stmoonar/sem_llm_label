{
    "authorId": "2109341751",
    "papers": [
        {
            "paperId": "02fa878ecc2c4426d22482a8e5cda952877b5f70",
            "title": "STERLING: Synergistic Representation Learning on Bipartite Graphs",
            "abstract": "A fundamental challenge of bipartite graph representation learning is how to extract informative node embeddings. Self-Supervised Learning (SSL) is a promising paradigm to address this challenge. Most recent bipartite graph SSL methods are based on contrastive learning which learns embeddings by discriminating positive and negative node pairs. Contrastive learning usually requires a large number of negative node pairs, which could lead to computational burden and semantic errors. In this paper, we introduce a novel synergistic representation learning model (STERLING) to learn node embeddings without negative node pairs. STERLING preserves the unique local and global synergies in bipartite graphs. The local synergies are captured by maximizing the similarity of the inter-type and intra-type positive node pairs, and the global synergies are captured by maximizing the mutual information of co-clusters. Theoretical analysis demonstrates that STERLING could improve the connectivity between different node types in the embedding space. Extensive empirical evaluation on various benchmark datasets and tasks demonstrates the effectiveness of STERLING for extracting node embeddings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "66807781",
                    "name": "Kaize Ding"
                },
                {
                    "authorId": "2109120259",
                    "name": "Chanyoung Park"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "2155337763",
                    "name": "Huan Liu"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "12b20c26a718a2aa2457b3908f107c0e74637a45",
            "title": "Continual Learning on Dynamic Graphs via Parameter Isolation",
            "abstract": "Many real-world graph learning tasks require handling dynamic graphs where new nodes and edges emerge. Dynamic graph learning methods commonly suffer from the catastrophic forgetting problem, where knowledge learned for previous graphs is overwritten by updates for new graphs. To alleviate the problem, continual graph learning methods are proposed. However, existing continual graph learning methods aim to learn new patterns and maintain old ones with the same set of parameters of fixed size, and thus face a fundamental tradeoff between both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN) for continual learning on dynamic graphs that circumvents the tradeoff via parameter isolation and expansion. Our motivation lies in that different parameters contribute to learning different graph patterns. Based on the idea, we expand model parameters to continually learn emerging graph patterns. Meanwhile, to effectively preserve knowledge for unaffected patterns, we find parameters that correspond to them via optimization and freeze them to prevent them from being rewritten. Experiments on eight real-world datasets corroborate the effectiveness of PI-GNN compared to state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115512664",
                    "name": "Peiyan Zhang"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "3210262",
                    "name": "Senzhang Wang"
                },
                {
                    "authorId": "2110972816",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2072633489",
                    "name": "Guojie Song"
                },
                {
                    "authorId": "2118021616",
                    "name": "Sunghun Kim"
                }
            ]
        },
        {
            "paperId": "5bba9dfb9b8f12ff105498fd192bb04f95ce6514",
            "title": "Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning",
            "abstract": "This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both \\textit{false negative issue} (i.e., potential true facts being excluded) and \\textit{false positive issue} (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call \\textit{label posterior}) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies missing facts to provide high-quality grounds of reasoning. They are unified in a simple yet effective self-training procedure. Empirically, extensive experiments on three benchmark KG and one Twitter dataset with various degrees of false negative/positive cases demonstrate the effectiveness of nPUGraph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144408471",
                    "name": "Ruijie Wang"
                },
                {
                    "authorId": "2118424577",
                    "name": "Baoyu Li"
                },
                {
                    "authorId": "2156141201",
                    "name": "Yichen Lu"
                },
                {
                    "authorId": "1630209136",
                    "name": "Dachun Sun"
                },
                {
                    "authorId": "2109377974",
                    "name": "Jinning Li"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "1390628682",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "685e3d87032d3530f639c9d46bab7e75307f357c",
            "title": "TransGNN: Harnessing the Collaborative Power of Transformers and Graph Neural Networks for Recommender Systems",
            "abstract": "Graph Neural Networks (GNNs) have emerged as promising solutions for collaborative filtering (CF) through the modeling of user-item interaction graphs. The nucleus of existing GNN-based recommender systems involves recursive message passing along user-item interaction edges to refine encoded embeddings. Despite their demonstrated effectiveness, current GNN-based methods encounter challenges of limited receptive fields and the presence of noisy\"interest-irrelevant\"connections. In contrast, Transformer-based methods excel in aggregating information adaptively and globally. Nevertheless, their application to large-scale interaction graphs is hindered by inherent complexities and challenges in capturing intricate, entangled structural information. In this paper, we propose TransGNN, a novel model that integrates Transformer and GNN layers in an alternating fashion to mutually enhance their capabilities. Specifically, TransGNN leverages Transformer layers to broaden the receptive field and disentangle information aggregation from edges, which aggregates information from more relevant nodes, thereby enhancing the message passing of GNNs. Additionally, to capture graph structure information effectively, positional encoding is meticulously designed and integrated into GNN layers to encode such structural knowledge into node attributes, thus enhancing the Transformer's performance on graphs. Efficiency considerations are also alleviated by proposing the sampling of the most relevant nodes for the Transformer, along with two efficient sample update strategies to reduce complexity. Furthermore, theoretical analysis demonstrates that TransGNN offers increased expressiveness compared to GNNs, with only a marginal increase in linear complexity. Extensive experiments on five public datasets validate the effectiveness and efficiency of TransGNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115512664",
                    "name": "Peiyan Zhang"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "2302364906",
                    "name": "Xi Zhang"
                },
                {
                    "authorId": "2869810",
                    "name": "Chaozhuo Li"
                },
                {
                    "authorId": "3210262",
                    "name": "Senzhang Wang"
                },
                {
                    "authorId": "2261394511",
                    "name": "Feiran Huang"
                },
                {
                    "authorId": "2118021616",
                    "name": "Sunghun Kim"
                }
            ]
        },
        {
            "paperId": "97c9132680cc88af9fb07db5453bb6363c9563b3",
            "title": "A Matrix Ensemble Kalman Filter-based Multi-arm Neural Network to Adequately Approximate Deep Neural Networks",
            "abstract": "Deep Learners (DLs) are the state-of-art predictive mechanism with applications in many fields requiring complex high dimensional data processing. Although conventional DLs get trained via gradient descent with back-propagation, Kalman Filter (KF)-based techniques that do not need gradient computation have been developed to approximate DLs. We propose a multi-arm extension of a KF-based DL approximator that can mimic DL when the sample size is too small to train a multi-arm DL. The proposed Matrix Ensemble Kalman Filter-based multi-arm ANN (MEnKF-ANN) also performs explicit model stacking that becomes relevant when the training sample has an unequal-size feature set. Our proposed technique can approximate Long Short-term Memory (LSTM) Networks and attach uncertainty to the predictions obtained from these LSTMs with desirable coverage. We demonstrate how MEnKF-ANN can\"adequately\"approximate an LSTM network trained to classify what carbohydrate substrates are digested and utilized by a microbiome sample whose genomic sequences consist of polysaccharide utilization loci (PULs) and their encoded genes.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2141446596",
                    "name": "Ved Piyush"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "2143504531",
                    "name": "Yuzhen Zhou"
                },
                {
                    "authorId": "2109678935",
                    "name": "Yanbin Yin"
                },
                {
                    "authorId": "4704127",
                    "name": "Souparno Ghosh"
                }
            ]
        },
        {
            "paperId": "c3bc9a26d5be75efccb7d605493333b33b6c5521",
            "title": "Neural Exploitation and Exploration of Contextual Bandits",
            "abstract": "In this paper, we study utilizing neural networks for the exploitation and exploration of contextual multi-armed bandits. Contextual multi-armed bandits have been studied for decades with various applications. To solve the exploitation-exploration trade-off in bandits, there are three main techniques: epsilon-greedy, Thompson Sampling (TS), and Upper Confidence Bound (UCB). In recent literature, a series of neural bandit algorithms have been proposed to adapt to the non-linear reward function, combined with TS or UCB strategies for exploration. In this paper, instead of calculating a large-deviation based statistical bound for exploration like previous methods, we propose, ``EE-Net,'' a novel neural-based exploitation and exploration strategy. In addition to using a neural network (Exploitation network) to learn the reward function, EE-Net uses another neural network (Exploration network) to adaptively learn the potential gains compared to the currently estimated reward for exploration. We provide an instance-based $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret upper bound for EE-Net and show that EE-Net outperforms related linear and neural contextual bandit baselines on real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51280934",
                    "name": "Yikun Ban"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "144205696",
                    "name": "A. Banerjee"
                },
                {
                    "authorId": "31108652",
                    "name": "Jingrui He"
                }
            ]
        },
        {
            "paperId": "ebb8b4eb5a9ebca7775ce230021414f1748c5e06",
            "title": "Networked Time Series Imputation via Position-aware Graph Enhanced Variational Autoencoders",
            "abstract": "Multivariate time series (MTS) imputation is a widely studied problem in recent years. Existing methods can be divided into two main groups, including (1) deep recurrent or generative models that primarily focus on time series features, and (2) graph neural networks (GNNs) based models that utilize the topological information from the inherent graph structure of MTS as relational inductive bias for imputation. Nevertheless, these methods either neglect topological information or assume the graph structure is fixed and accurately known. Thus, they fail to fully utilize the graph dynamics for precise imputation in more challenging MTS data such as networked time series (NTS), where the underlying graph is constantly changing and might have missing edges. In this paper, we propose a novel approach to overcome these limitations. First, we define the problem of imputation over NTS which contains missing values in both node time series features and graph structures. Then, we design a new model named PoGeVon which leverages variational autoencoder (VAE) to predict missing values over both node time series features and graph structures. In particular, we propose a new node position embedding based on random walk with restart (RWR) in the encoder with provable higher expressive power compared with message-passing based graph neural networks (GNNs). We further design a decoder with 3-stage predictions from the perspective of multi-task learning to impute missing values in both time series and graph structures reciprocally. Experiment results demonstrate the effectiveness of our model over baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150084152",
                    "name": "Dingsu Wang"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "2187298875",
                    "name": "Ruizhong Qiu"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "49934133",
                    "name": "Kaiyu Guan"
                },
                {
                    "authorId": "12866575",
                    "name": "A. Margenot"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "147475ad48f26f76c8862e6980917d78110982f0",
            "title": "COIN: Co-Cluster Infomax for Bipartite Graphs",
            "abstract": "Bipartite graphs are powerful data structures to model interactions between two types of nodes, which have been used in a variety of applications, such as recommender systems, information retrieval, and drug discovery. A fundamental challenge for bipartite graphs is how to learn informative node embeddings. Despite the success of recent self-supervised learning methods on bipartite graphs, their objectives are discriminating instance-wise positive and negative node pairs, which could contain cluster-level errors. In this paper, we introduce a novel co-cluster infomax (COIN) framework, which captures the cluster-level information by maximizing the mutual information of co-clusters. Different from previous infomax methods which estimate mutual information by neural networks, COIN could easily calculate mutual information. Besides, COIN is an end-to-end coclustering method which can be trained jointly with other objective functions and optimized via back-propagation. Furthermore, we also provide theoretical analysis for COIN. We theoretically prove that COIN is able to effectively maximize the mutual information of node embeddings and COIN is upper-bounded by the prior distributions of nodes. We extensively evaluate the proposed COIN framework on various benchmark datasets and tasks to demonstrate the effectiveness of COIN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "1f540f93fb42ade932ca9fb83017b07a6604622e",
            "title": "The Disyllabic Tone Production and Tone Context Effect in Mandarin-speaking Children with Cochlear Implants",
            "abstract": "This study investigated the production of tones in disyllabic words by Mandarin-speaking children with cochlear implants (CIs). The speech materials consisted of 141 disyllabic and 153 monosyllabic words that were produced by 45 children with CIs. We first compared the accuracy and error patterns of disyllabic tone pairs, and then analyzed the production performance of lexical tones with regard to different contexts and positions. The results showed that: 1) The mean accuracy rate of 20 disyllabic tone pairs was 60.59%, and the tone pairs containing tone 2, tone 3, or tone 5 were produced less correctly by children with CIs. Complex error patterns were found in the present study. 2) The lexical tones had lower accuracy and different error patterns in the first syllable position of disyllable compared with when they were in the second syllable position of disyllable and in the monosyllable. Among the four lexical tones, tone 2 and tone 3 were more affected by the contexts and positions. This study sheds light on tone acquisition of the disyllabic words for children with CIs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158372106",
                    "name": "Jingwen Cheng"
                },
                {
                    "authorId": "2118543175",
                    "name": "Yingming Gao"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "47460304",
                    "name": "Xiaoli Feng"
                },
                {
                    "authorId": "3186130",
                    "name": "Binghuai Lin"
                },
                {
                    "authorId": "2368143",
                    "name": "Jinsong Zhang"
                }
            ]
        },
        {
            "paperId": "50d7d7624d15efd9473cb011f8ecc7d0a88a4fa6",
            "title": "SciGraph: A Knowledge Graph Constructed by Function and Topic Annotation of Scientific Papers (poster)",
            "abstract": "In researchers\u2019 literature exploration, a knowledge structure of certain domain helps those without clear purposes gain a quick understanding of new topics. Besides that, a paper set classified by function save the exploration time of those with clear purposes. This paper proposes a solution to annotate the function and topics of scientific papers, and construct a knowledge graph, named SciGraph, which helps researchers obtain both purpose-oriented papers and the knowledge structure of a domain. A dataset of 0.9 million scientific papers from different disciplines is collected, and the proposed solutions are applied to form SciGraph, within which a total of ca. 1.9 million nodes and ca. 16.4 million relations are generated. The contribution of this study includes, (1) organizing the functions and topics of scientific papers within a unified knowledge graph, which may support explorative retrieval; (2) proposing a DF-ITF method to identify the candidate feature words in the function definition; and (3) applying a method based on term co-occurrence to extract and rank the hyponymy relation of topic",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "2110239633",
                    "name": "Chong Chen"
                }
            ]
        }
    ]
}