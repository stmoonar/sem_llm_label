{
    "authorId": "2261997735",
    "papers": [
        {
            "paperId": "004e4cbaf54b1e83ea475df4b04b6705856e1c0e",
            "title": "Does It Matter Who Said It? Exploring the Impact of Deepfake-Enabled Profiles on User Perception towards Disinformation",
            "abstract": "Recently, deepfake techniques have been adopted by real-world adversaries to fabricate believable personas (posing as experts or insiders) in disinformation campaigns to promote false narratives and deceive the public. In this paper, we investigate how fake personas influence the user perception of the disinformation shared by such accounts. Using Twitter as an exemplary platform, we conduct a user study (N=417) where participants read tweets of fake news with (and without) the presence of the tweet authors' profiles. Our study examines and compares three types of fake profiles: deepfake profiles, profiles of relevant organizations, and simple bot profiles. Our results highlight the significant impact of deepfake and organization profiles on increasing the perceived information accuracy of and engagement with fake news. Moreover, deepfake profiles are rated as significantly more real than other profile types. Finally, we observe that users may like/reply/share a tweet even though they believe it was inaccurate (e.g., for fun or truth-seeking), which could further disseminate false information. We then discuss the implications of our findings and directions for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188817804",
                    "name": "Margie Ruffin"
                },
                {
                    "authorId": "150127148",
                    "name": "Haeseung Seo"
                },
                {
                    "authorId": "2261997735",
                    "name": "Aiping Xiong"
                },
                {
                    "authorId": "2299175131",
                    "name": "Gang Wang"
                }
            ]
        },
        {
            "paperId": "6612b372d838e74d8365ae96a90d981b541ed081",
            "title": "The Strange Case of Jekyll and Hyde: Analysis of R/ToastMe and R/RoastMe Users on Reddit",
            "abstract": "This study, focusing on two Reddit subcommunities of r/ToastMe and r/RoastMe, aims to (1) characterize and understand users (named Jekyll and Hyde) who simultaneously participate in two subreddits with opposing tones and purposes, (2) build predictive models detecting those Jekyll and Hyde users to assess how unique and idiosyncratic their characteristics are, and (3) investigate their motivations of participation and potential interaction between the two contrasting activities through a survey and one-on-one interviews. Our results reveal that the Jekyll and Hyde users are generally more active and popular than ordinary users. Also, they use assimilated language customized to each community\u2019s tone. Combining these findings with their motivations unveiled through the survey and interviews, we conclude that the Jekyll and Hyde users are digitally culture-savvy, who know how to utilize online community benefits and enjoy each community\u2019s culture by assimilating themselves into the community and observing its rules. Moreover, the users\u2019 duality observed in this process underscores the dynamic and multifaceted nature of online personas. These findings highlight the need for a nuanced approach to understanding online behaviors and provide insights for designing healthier online environments, emphasizing the importance of clear community norms and the potential interplay of users\u2019 activities across different communities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268425455",
                    "name": "Wooyong Jung"
                },
                {
                    "authorId": "2268426349",
                    "name": "Nishant Asati"
                },
                {
                    "authorId": "2304185169",
                    "name": "Phuong (Lucy) Doan"
                },
                {
                    "authorId": "2260345102",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2261997735",
                    "name": "Aiping Xiong"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "d67d3e31ce219a82eb6315295f60ab663edebc96",
            "title": "Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations",
            "abstract": "The widespread adoption and transformative effects of large language models (LLMs) have sparked concerns regarding their capacity to produce inaccurate and fictitious content, referred to as `hallucinations'. Given the potential risks associated with hallucinations, humans should be able to identify them. This research aims to understand the human perception of LLM hallucinations by systematically varying the degree of hallucination (genuine, minor hallucination, major hallucination) and examining its interaction with warning (i.e., a warning of potential inaccuracies: absent vs. present). Participants (N=419) from Prolific rated the perceived accuracy and engaged with content (e.g., like, dislike, share) in a Q/A format. Participants ranked content as truthful in the order of genuine, minor hallucination, and major hallucination, and user engagement behaviors mirrored this pattern. More importantly, we observed that warning improved the detection of hallucination without significantly affecting the perceived truthfulness of genuine content. We conclude by offering insights for future tools to aid human detection of hallucinations. All survey materials, demographic questions, and post-session questions are available at: https://github.com/MahjabinNahar/fakes-of-varying-shades-survey-materials",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "113162705",
                    "name": "Mahjabin Nahar"
                },
                {
                    "authorId": "150127148",
                    "name": "Haeseung Seo"
                },
                {
                    "authorId": "2295516363",
                    "name": "Eun-Ju Lee"
                },
                {
                    "authorId": "2261997735",
                    "name": "Aiping Xiong"
                },
                {
                    "authorId": "2148665965",
                    "name": "Dongwon Lee"
                }
            ]
        }
    ]
}