{
    "authorId": "38330039",
    "papers": [
        {
            "paperId": "32c9aafeb6eb60dc4bdf16064e1b8ef2745f1e35",
            "title": "TurQUaz at CheckThat! 2024: Creating Adversarial Examples using Genetic Algorithm",
            "abstract": "As we increasingly integrate artificial intelligence into our daily tasks, it is crucial to ensure that these systems are reliable and robust against adversarial attacks. In this paper, we present our participation in Task 6 of CLEF CheckThat! 2024 lab. In our work, we explore several methods, which can be grouped into two categories. The first group focuses on using a genetic algorithm to detect words and changing them via several methods such as adding/deleting words and using homoglyphs. In the second group of methods, we use large language models to generate adversarial attacks. Based on our comprehensive experiments, we pick the genetic algorithm-based model which utilizes a combination of splitting words and homoglyphs as a text manipulation method, as our primary model. We are ranked third based on both BODEGA metric and manual evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315434756",
                    "name": "Basak Demirok"
                },
                {
                    "authorId": "2315434890",
                    "name": "Selin Mergen"
                },
                {
                    "authorId": "2315433341",
                    "name": "Bugra Oz"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "3609ad9d531949faab9897475865809f0523da63",
            "title": "Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language",
            "abstract": "Over the past century, the Turkish language has undergone substantial changes, primarily driven by governmental interventions. In this work, our goal is to investigate the evolution of the Turkish language since the establishment of T\\\"urkiye in 1923. Thus, we first introduce Turkronicles which is a diachronic corpus for Turkish derived from the Official Gazette of T\\\"urkiye. Turkronicles contains 45,375 documents, detailing governmental actions, making it a pivotal resource for analyzing the linguistic evolution influenced by the state policies. In addition, we expand an existing diachronic Turkish corpus which consists of the records of the Grand National Assembly of T\\\"urkiye by covering additional years. Next, combining these two diachronic corpora, we seek answers for two main research questions: How have the Turkish vocabulary and the writing conventions changed since the 1920s? Our analysis reveals that the vocabularies of two different time periods diverge more as the time between them increases, and newly coined Turkish words take the place of their old counterparts. We also observe changes in writing conventions. In particular, the use of circumflex noticeably decreases and words ending with the letters\"-b\"and\"-d\"are successively replaced with\"-p\"and\"-t\"letters, respectively. Overall, this study quantitatively highlights the dramatic changes in Turkish from various aspects of the language in a diachronic perspective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301455400",
                    "name": "Togay Yazar"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "1456571628",
                    "name": "Isa Kerem Bayirli"
                }
            ]
        },
        {
            "paperId": "a33cbc6d75b0dc2a36a359b4e6e6ff085690191f",
            "title": "NativQA: Multilingual Culturally-Aligned Natural Query for LLMs",
            "abstract": "Natural Question Answering (QA) datasets play a crucial role in evaluating the capabilities of large language models (LLMs), ensuring their effectiveness in real-world applications. Despite the numerous QA datasets that have been developed, there is a notable lack of region-specific datasets generated by native users in their own languages. This gap hinders the effective benchmarking of LLMs for regional and cultural specificities. Furthermore, it also limits the development of fine-tuned models. In this study, we propose a scalable, language-independent framework, NativQA, to seamlessly construct culturally and regionally aligned QA datasets in native languages, for LLM evaluation and tuning. We demonstrate the efficacy of the proposed framework by designing a multilingual natural QA dataset, \\mnqa, consisting of ~64k manually annotated QA pairs in seven languages, ranging from high to extremely low resource, based on queries from native speakers from 9 regions covering 18 topics. We benchmark open- and closed-source LLMs with the MultiNativQA dataset. We also showcase the framework efficacy in constructing fine-tuning data especially for low-resource and dialectally-rich languages. We made both the framework NativQA and MultiNativQA dataset publicly available for the community (https://nativqa.gitlab.io).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151116677",
                    "name": "Md. Arid Hasan"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2311384605",
                    "name": "Fatema Ahmad"
                },
                {
                    "authorId": "12352363",
                    "name": "Sahinur Rahman Laskar"
                },
                {
                    "authorId": "2311437171",
                    "name": "Sunaya Upadhyay"
                },
                {
                    "authorId": "2155270590",
                    "name": "Vrunda N. Sukhadia"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "1725417821",
                    "name": "Shammur A. Chowdhury"
                },
                {
                    "authorId": "2257274157",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "e85cc8a0a08ddf44bf94fc847b170c4a4dec5201",
            "title": "TurQUaz at CheckThat! 2024: A Hybrid Approach of Fine-Tuning and In-Context Learning for Check-Worthiness Estimation",
            "abstract": "This paper presents our participation in the CLEF2024 CheckThat! Lab\u2019s Task-1 which focuses on determining whether passages from tweets or transcriptions are check-worthy. Task 1 covers three languages including English, Arabic, and Dutch. We propose utilizing several different instruct-tuned large language models (LLM) and aggregating their results for the Dutch dataset. In English and Arabic datasets, in addition to LLMs, we also use a fine-tuned XLM-R classifier. Our proposed method is ranked first in the Dutch dataset, fourth in the Arabic dataset, and eleventh in the English dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315433436",
                    "name": "Mehmet Eren Bulut"
                },
                {
                    "authorId": "2269745447",
                    "name": "Kaan Efe Keles"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "27aac9b5ffee011e502b1b3ddbdf96ddfc6b5ea3",
            "title": "A machine learning approach for dyslexia detection using Turkish audio records",
            "abstract": ": Dyslexia is a learning disorder, characterized by impairment in the ability to read, spell, and decode letters. It is vital to detect dyslexia in earlier stages to reduce its effects. However, diagnosing dyslexia is a time-consuming and costly process. In this paper, we propose a machine-learning model that predicts whether a Turkish-speaking child has dyslexia using his/her audio records. Therefore, our model can be easily used by smart phones and work as a warning system such that children who are likely to be dyslexic according to our model can seek an examination by experts. In order to train and evaluate, we first create a unique dataset that includes audio recordings of 12 dyslexic children and 13 nondyslexic children in an 8-month period. We explore various machine learning algorithms such as KNN and SVM and use the following features: Mel-frequency cepstral coe\ufb00icients, reading rate, reading accuracy, the ratio of missing words, and confidence scores of the speech-to-text process. In our experiments, we show that children with dyslexia can be detected with 95.63% accuracy even though we use single-sentence long audio records. In addition, we show that the prediction performance of our model is similar to that of the humans\u2019. In this paper, we provide a preliminary study showing that detecting children with dyslexia based on their audio records is possible. Once the mobile application version of our model is developed, parents can easily check whether their children are likely to be dyslexic or not, and seek professional help accordingly",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2249660005",
                    "name": "Tu\u011fberk Ta\u015f"
                },
                {
                    "authorId": "107731195",
                    "name": "M. A. B\u00fclb\u00fcl"
                },
                {
                    "authorId": "2022444491",
                    "name": "Abas Ha\u015fimo\u011flu"
                },
                {
                    "authorId": "2249645531",
                    "name": "Yavuz Meral"
                },
                {
                    "authorId": "51885571",
                    "name": "Yasin Caliskan"
                },
                {
                    "authorId": "2249637043",
                    "name": "Gunay Budagova"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "29745c2f62e65af4cc3f2516ce2ae010cae317d2",
            "title": "Overview of the CLEF-2023 CheckThat! Lab: Task 2 on Subjectivity Detection",
            "abstract": "We describe the outcome of the 2023 edition of the CheckThat! Lab at CLEF. We focus on subjectivity (Task 2), which has been proposed for the first time. It aims at fostering the technology for the identification of subjective text fragments in news articles. For that, we produced corpora consisting of 9,530 manually-annotated sentences, covering six languages \u2014Arabic, Dutch, English, German, Italian, and Turkish. Task 2 attracted 12 teams, which submitted a total of 40 final runs covering all languages. The most successful approaches addressed the task using state-of-the-art multilingual transformer models, which were fine-tuned on language-specific data. Teams also experimented with a rich set of other neural architectures, including foundation models, zero-shot classifiers, and standard transformers, mainly coupled with data augmentation and multilingual training strategies to address class imbalance. We publicly release all the datasets and evaluation scripts, with the purpose of promoting further research on this topic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143978279",
                    "name": "Andrea Galassi"
                },
                {
                    "authorId": "2241527223",
                    "name": "Federico Ruggeri"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "2257274157",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "2261403233",
                    "name": "Tommaso Caselli"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "2264714",
                    "name": "Julia Maria Stru\u00df"
                },
                {
                    "authorId": "2127115553",
                    "name": "Francesco Antici"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2181067879",
                    "name": "Juliane K\u00f6hler"
                },
                {
                    "authorId": "2093365921",
                    "name": "Katerina Korre"
                },
                {
                    "authorId": "2121382337",
                    "name": "Folkert Leistra"
                },
                {
                    "authorId": "2038102772",
                    "name": "Arianna Muti"
                },
                {
                    "authorId": "2261403474",
                    "name": "Melanie Siegel"
                },
                {
                    "authorId": "2235689778",
                    "name": "Mehmet Deniz T\u00fcrkmen"
                },
                {
                    "authorId": "2261403527",
                    "name": "Michael Wiegand"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        },
        {
            "paperId": "7f08eb623f96bd1342bf52f37e10c30e53e771d3",
            "title": "Exploring the impact of training datasets on Turkish stance detection",
            "abstract": ": Stance detection has garnered considerable attention from researchers due to its broad range of applications, including fact-checking and social computing. While state-of-the-art stance detection models are usually based on supervised machine learning methods, their effectiveness is heavily reliant on the quality of training data. This problem is more prevalent in stance detection task because the stance of a text is intimately tied to the target under consideration. While numerous datasets exist for stance detection, determining their suitability for a specific target can be challenging. In this work, we focus on Turkish stance detection and explore the impact of training data on the model performance. In particular, we fine-tune BERT model with various datasets and assess their performance when the test data is the same/different compared to the training data in terms of target and domain. In addition, given the scarcity of resources for Turkish stance detection, we investigate i) whether we can use existing datasets in other languages in a cross-lingual setup, and ii) the effectiveness of data augmentation with simple automatic labeling methods. In order to conduct our experiments, we also create new Turkish stance detection datasets for various targets in different domains. In our comprehensive experiments, our findings are as follows. 1) Using training data with multiple targets in the same domain yields high performance as the model is able to learn more characteristics of expressing stance with additional data. 2) The domain of the training data plays a crucial role in achieving high performance. 3) Automatically generated data enhances performance when combined with manually annotated data. 4) Training solely on Turkish data outperforms training with the combination of Turkish and English data. Overall, our study points out the importance of creating Turkish annotated datasets for different domains to achieve high performance in stance detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120339869",
                    "name": "Muhammed Said Zengin"
                },
                {
                    "authorId": "2269297457",
                    "name": "Berk Utku Yeni\u0307sey"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "7f3fc9c5a6e9d05e45d66206160f5069794abd25",
            "title": "Deep Learning Based Social Bot Detection on Twitter",
            "abstract": "While social bots can be used for various good causes, they can also be utilized to manipulate people and spread malware. Therefore, it is crucial to detect bots running on social media platforms. However, social bots are increasingly successful in creating human-like messages with the recent developments in artificial intelligence. Thus, we need more sophisticated solutions to detect them. In this study, we propose a novel deep learning architecture in which three long short-term memory (LSTM) models and a fully connected layer are utilized to capture complex social media activity of humans and bots. Since our architecture involves many components connected at different levels, we explore three learning schemes to train each component effectively. In our extensive experiments, we analyze the impact of each component of our architecture on classification accuracy using four different datasets. Furthermore, we show that our proposed architecture outperforms all baselines used in our experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52136683",
                    "name": "Efe Arin"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "8d34c95aa916094f5668500c76d154b441df9afc",
            "title": "Re-Think Before You Share: A Comprehensive Study on Prioritizing Check-Worthy Claims",
            "abstract": "The massive amount of misinformation spreading on the internet on a daily basis has enormous negative impacts on societies. Therefore, we need systems to help fact-checkers to combat misinformation and to raise public awareness of this important problem. In this article, we propose a hybrid model which combines bidirectional encoder representations from transformer (BERT) model with various features to prioritize claims based on their check-worthiness. Features we use include domain-specific controversial topics (CT), word embeddings (WE), part-of-speech (POS) tags, and others. In addition, we explore various ways of increasing labeled data size to effectively train the models, such as increasing positive (IncPos) samples, active learning (AL), and utilizing labeled data in other languages. In our extensive experiments, we show that our model outperforms all state-of-the-art models in test collections of Conference and Labs of Evaluation Forum (CLEF) CheckThat! Lab (CTL) 2018 and 2019. In addition, when positive samples are increased in the training set, our model achieves the best mean average precision (MAP) score reported so far for the test collection of CTL 2020. Furthermore, we show that cross-lingual training is effective for prioritizing Arabic and Turkish claims, but not for English.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "ddf729c5cbbdb5c14360180c69afd8923e0ffc2f",
            "title": "Predicting Election Results Via Social Media: A Case Study for 2018 Turkish Presidential Election",
            "abstract": "Social media platforms provide massive amounts of data that can be used to analyze social issues and forecast events in the future. However, it is a challenging task due to the biased and noisy nature of the data. In this work, we propose a method to predict election results via Twitter. In particular, we first detect the stance of social media accounts using their retweets. Subsequently, we develop four different counting methods for our prediction task. In the simple user counting (SC) method, we count labeled users without taking any further steps to reduce bias. In the city-based weighted counting (CBWC) method, we apply a weighted counting based on the number of electorate in each city. The closest-city-based prediction (CCBP) method utilizes sociological similarity between cities to predict results for cities with limited sample sizes. The using former election results (UFERs) method compares predictions for each city against former election results to detect data bias and uses them accordingly. We evaluate our proposed methods with the data collected for the presidential election of Turkey held in 2018. In our extensive evaluation, we show that utilizing domain-specific information and location-based weighted counting is effective in reducing bias. CBWC, CCBP, and UFER methods outperform tweet-counting-based baseline methods. Furthermore, UFER and CCBP outperform almost all traditional polls, suggesting that social media platforms are alternative mediums for conducting election polls.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51040156",
                    "name": "Cansin Bayrak"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        }
    ]
}