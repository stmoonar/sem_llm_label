{
    "authorId": "25158823",
    "papers": [
        {
            "paperId": "2030d1efaf5fed3ab282ff57a44729630d12dbff",
            "title": "Improving Application Artifact Inference Using Matched Sector Adjacency Weighting",
            "abstract": "Digital forensics investigators may need to infer the past presence of an application which was uninstalled prior to device seizure or media imaging. Some existing approaches use a catalog of fixed data block hashes to scan for evidence of a previously installed but now uninstalled application, but false positive sector-level matches may negatively impact algorithm performance. In an effort to get more accurate results when inferring prior application presence, we propose using a sector adjacency weighting method whereby we codify the intuition that an apparent application file remnant is more likely to be from the file of interest if we observe a run of contiguous matched sectors, and less likely if we observe scattered (singleton) matched sectors on the disk image. Test results show that the amount of false positive matching is reduced and the resulting inference is more accurate with the introduction of matched sector adjacency weighting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1393883486",
                    "name": "Oluwaseun Adegbehingbe"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                }
            ]
        },
        {
            "paperId": "a21a356be7aa5a5871e1b720fa9a193a68ef1cae",
            "title": "Assessing the Impact of Matched Fragments' Relative Locations on Application Artifact Inference",
            "abstract": "One challenge in digital forensics is finding evidence of applications that have been uninstalled. When an application is uninstalled, the files making up the application are deleted. However, deleting a file doesn't necessarily immediately overwrite all the data (sectors) of the file. Investigators can find these orphaned file fragments (sectors) at some time after an application has been uninstalled and use them to infer the prior presence of whole files and hence associated applications. Prior work used a simple TF-IDF based weighting scheme to infer the prior presence of deleted application files and hence uninstalled applications. However, this method has limited accuracy because matching sectors not actually associated with a previously installed application result in application inference false positives. Most file systems write file sectors contiguously and files are cluster-aligned, suggesting a revised computation that might exploit these known and common behaviors to filter out many of these false matches. In this work, we add consideration of the relative locations of the matched sectors, where relative means (a) matching sector alignment relative to the original file of interest, and (b) matching sector alignment relative to cluster boundaries. We also add exponential weighting for file matches based on other work suggesting that the additional inferential value of each matching sector declines as more sectors are matched (i.e., two matches are not twice as useful as one match, etc.). Test results show that our proposed approach produces more accurate results than the prior work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1393883486",
                    "name": "Oluwaseun Adegbehingbe"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                }
            ]
        },
        {
            "paperId": "62b214738804299fd5ebbf360114722c439e4c50",
            "title": "Online User Profiling to Detect Social Bots on Twitter",
            "abstract": "Social media platforms can expose influential trends in many aspects of everyday life. However, the movements they represent can be contaminated by disinformation. Social bots are one of the significant sources of disinformation in social media. Social bots can pose serious cyber threats to society and public opinion. This research aims to develop machine learning models to detect bots based on the extracted user's profile from a Tweet's text. Online users' profile shows the user's personal information, such as age, gender, education, and personality. In this work, the user's profile is constructed based on the user's online posts. This work's main contribution is three-fold: First, we aim to improve bot detection through machine learning models based on the user's personal information generated by the user's online comments. When comparing two online posts, the similarity of personal information makes it difficult to differentiate a bot from a human user. However, this research turns personal information similarity among two online posts into an advantage for the new bot detection model. The new proposed model for bot detection creates user profiles based on personal information such as age, personality, gender, education from users' online posts and introduces a machine learning model to detect social bots with high prediction accuracy based on personal information. Second, create a new public data set that shows the user's profile for more than 6900 Twitter accounts in the Cresci 2017 data set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                },
                {
                    "authorId": "1723337",
                    "name": "\u00d6zlem Uzuner"
                }
            ]
        },
        {
            "paperId": "8ad8f1772d267c33f9604157687aab48db557ea6",
            "title": "The Distributed Digital Body Farm: Enabling the Analysis of Deleted File Decay Patterns",
            "abstract": "Estimating the rate and pattern of deleted file decay on digital media is of interest to digital forensic investigators. Understanding how deleted file contents decay and the factors that affect the process is useful in making decisions about artifact recovery during a forensic investigation. Although the mechanisms that cause deleted file content decay are well known, the actual decay behavior and patterns of decay are not well understood, and one cannot predict with certainty if some or all of a file may be recovered after it has been deleted. This work demonstrates a novel method for collecting data about deleted file content decay from real world systems, without violating user privacy. We present the design of the distributed digital body farm (DDBF) and demonstrate its application in collecting deleted file decay data from geographically dispersed computers. The DDBF is a remote software agent that collects content free and privacy preserving data about deleted file decay on an active computer system. The data collected is consolidated in a central repository and preliminary analysis is performed to reveal patterns in the data and show the value of the DDBF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2176237230",
                    "name": "Omoche Cheche Agada"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                },
                {
                    "authorId": "3165226",
                    "name": "K. Fairbanks"
                }
            ]
        },
        {
            "paperId": "9452d40ccb84606981b1cadf0b6cc926bf819a98",
            "title": "Offensive Language Detection on Social Media Based on Text Classification",
            "abstract": "There is a concerning rise of offensive language on the content generated by the crowd over various social platforms. Such language might bully or hurt the feelings of an individual or a community. Recently, the research community has investigated and developed different supervised approaches and training datasets to detect or prevent offensive monologues or dialogues automatically. In this study, we propose a model for text classification consisting of modular cleaning phase and tokenizer, three embedding methods, and eight classifiers. Our experiments shows a promising result for detection of offensive language on our dataset obtained from Twitter. Considering hyperparameter optimization, three methods of AdaBoost, SVM and MLP had highest average of F1-score on popular embedding method of TF-IDF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037676113",
                    "name": "P. Hajibabaee"
                },
                {
                    "authorId": "2143337352",
                    "name": "Masoud Malekzadeh"
                },
                {
                    "authorId": "32140952",
                    "name": "Mohsen Ahmadi"
                },
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "2056549500",
                    "name": "Armin Esmaeilzadeh"
                },
                {
                    "authorId": "1805958417",
                    "name": "Reyhaneh Abdolazimi"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                }
            ]
        },
        {
            "paperId": "34c8976f50e83aeaff75a32055e8e9880f2d11f5",
            "title": "Emotion Detection of Textual Data: An Interdisciplinary Survey",
            "abstract": "Emotion is a primary aspect of communication and can be expressed in many modalities. Text-Based Emotion Detection (TBED), one of the fastest growing branches of Natural Language Processing (NLP), is the process of classifying syntactic or semantic units of a corpus into a given set of emotion classes proposed by a psychological model. Automatic TBED mechanisms use machine learning approaches to create computational platforms automating the process of extracting emotions. TBED has a wide variety of applications in the area of artificial intelligence: Semantic analysis of documents and public messages related to terrorist attacks (to mitigate risks), automated analysis of historical corpora, and study of product reviews (to assess customer satisfaction). This work reviews the current literature of TBED and the psychological models associated with them.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1805988818",
                    "name": "Samira Zad"
                },
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                },
                {
                    "authorId": "1390465945",
                    "name": "\u00d6zlem Uzuner"
                }
            ]
        },
        {
            "paperId": "3873967de1a21c8451d15a756ad9ad406efba218",
            "title": "A Survey on Concept-Level Sentiment Analysis Techniques of Textual Data",
            "abstract": "Text mining is one of the branches of data mining and refers to as the computing process of finding new patterns and relations among datasets which appear not to be related. Data mining is an interdisciplinary field which uses statistics, artificial intelligence, and database systems to generate new tools for discovering patterns among datasets. Similarly, when dealing with textual data, we need to use various methods in different branches of computer science (e.g. linguistics) and statistics. This study reviews the techniques of text-based sentiment analysis pipeline including preprocessing, aspect extraction, feature selection, and classification techniques used by scholars recently. It also surveys different applications of semantic analysis in the context of social media, marketing, and product reviews.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1805988818",
                    "name": "Samira Zad"
                },
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                },
                {
                    "authorId": "1723337",
                    "name": "\u00d6zlem Uzuner"
                }
            ]
        },
        {
            "paperId": "5e00ffd2549a4ff4749e7c0fd7e5bb0db68ca44a",
            "title": "BERT Model for Fake News Detection Based on Social Bot Activities in the COVID-19 Pandemic",
            "abstract": "In the global pandemic, social media platforms are the primary source of information exchange. Social bots are one of the main sources of misinformation in the COVID-19 pandemic but do social bots spread the fake and real news with the same ratio as human accounts on social media platforms? Can bot detection improve fake news detection on social media platforms? Who presents more fake news in the COVID-19 pandemic, Human or social bots? This work provides preliminary research results based on limited data to answer these questions, but it opens a new perspective on fake news detection and bot detection on online platforms. We use Bidirectional Encoder Representations from Transformers(BERT) to create a new model for fake news detection. We use the transfer learning model to detect bot accounts in the COVID-19 data set. Then apply new features to improve the new fake news detection model in the COVID-19 data set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "1805988818",
                    "name": "Samira Zad"
                },
                {
                    "authorId": "2037676113",
                    "name": "P. Hajibabaee"
                },
                {
                    "authorId": "2143337352",
                    "name": "Masoud Malekzadeh"
                },
                {
                    "authorId": "1603562798",
                    "name": "SeyyedPooya HekmatiAthar"
                },
                {
                    "authorId": "1390465945",
                    "name": "\u00d6zlem Uzuner"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                }
            ]
        },
        {
            "paperId": "ea69f54a08b590a60ea38d5cd5954406796e6532",
            "title": "Review of Graph Neural Network in Text Classification",
            "abstract": "Text classification is one of the fundamental problems in Natural Language Processing (NLP). Several research studies have used deep learning approaches such as Convolution Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for text classification. Over the past decade, graph-based approaches have been used to solve various NLP tasks including text classification. This paper reviews the most recent state-of-the-art graph-based text classification, datasets, and performance evaluations versus baseline models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143337352",
                    "name": "Masoud Malekzadeh"
                },
                {
                    "authorId": "2037676113",
                    "name": "P. Hajibabaee"
                },
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "1805988818",
                    "name": "Samira Zad"
                },
                {
                    "authorId": "2257172942",
                    "name": "\u00d6zlem Uzuner"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                }
            ]
        },
        {
            "paperId": "1ed15531e935641f0cfeee6be8856b53c567ff61",
            "title": "Using BERT to Extract Topic-Independent Sentiment Features for Social Media Bot Detection",
            "abstract": "Millions of online posts about different topics and products are shared on popular social media platforms. One use of this content is to provide crowd-sourced information about a specific topic, event, or product. However, this use raises an important question: what percentage of the information available through these services is trustworthy? In particular, might some of this information be generated by a machine, i.e., a \"bot\" instead of a human? Bots can be, and often are, purposely designed to generate enough volume to skew an apparent trend or position on a topic, yet the consumer of such content cannot easily distinguish a bot post from a human post. This paper introduces a new model that uses Bidirectional Encoder Representations from Transformers (Google Bert) for sentiment classification of tweets to identify topic-independent features for the social media bot detection model. Using a Natural Language Processing approach to derive topic-independent features for the new bot detection model distinguishes this work from previous bot detection models. We achieve 94% accuracy classifying the contents of Cresci data set [1] as generated by a bot or a human, where the most accurate prior work achieved an accuracy of 92%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2023178116",
                    "name": "Maryam Heidari"
                },
                {
                    "authorId": "25158823",
                    "name": "James H. Jones"
                }
            ]
        }
    ]
}