{
    "authorId": "39657876",
    "papers": [
        {
            "paperId": "23213568a9fe9fef029f4258582b08d950ceec8a",
            "title": "DNNShifter: An Efficient DNN Pruning System for Edge Computing",
            "abstract": "Deep neural networks (DNNs) underpin many machine learning applications. Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint. This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources. To address this, models are pruned to create lightweight, more suitable variants for these devices. Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases. Our work rapidly derives suitable model variants while maintaining the accuracy of the original model. The model variants can be swapped quickly when system and network conditions change to match workload demand. This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching system that addresses the challenges mentioned above. At the heart of DNNShifter is a novel methodology that prunes sparse models using structured pruning. The pruned model variants generated by DNNShifter are smaller in size and thus faster than dense and sparse model predecessors, making them suitable for inference at the edge while retaining near similar accuracy as of the original dense model. DNNShifter generates a portfolio of model variants that can be swiftly interchanged depending on operational conditions. DNNShifter produces pruned model variants up to 93x faster than conventional training methods. Compared to sparse models, the pruned model variants are up to 5.14x smaller and have a 1.67x inference latency speedup, with no compromise to sparse model accuracy. In addition, DNNShifter has up to 11.9x lower overhead for switching models and up to 3.8x lower memory utilisation than existing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239202278",
                    "name": "Bailey J. Eccles"
                },
                {
                    "authorId": "2209882604",
                    "name": "Philip Rodgers"
                },
                {
                    "authorId": "2239201921",
                    "name": "Peter Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "288f5fc358bdd3ddd94cd5e3c6e9f910244f201d",
            "title": "Communication Efficient DNN Partitioning-based Federated Learning",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "92148538",
                    "name": "Di Wu"
                },
                {
                    "authorId": "1754190",
                    "name": "R. Ullah"
                },
                {
                    "authorId": "2209882604",
                    "name": "Philip Rodgers"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "ca67c54f76df43a4458b897dc054e92d8ae0f718",
            "title": "EcoFed: Efficient Communication for DNN Partitioning-Based Federated Learning",
            "abstract": "Efficiently running federated learning (FL) on resource-constrained devices is challenging since they are required to train computationally intensive deep neural networks (DNN) independently. DNN partitioning-based FL (DPFL) has been proposed as one mechanism to accelerate training where the layers of a DNN (or computation) are offloaded from the device to the server. However, this creates significant communication overheads since the intermediate activation and gradient need to be transferred between the device and the server during training. While current research reduces the communication introduced by DNN partitioning using local loss-based methods, we demonstrate that these methods are ineffective in improving the overall efficiency (communication overhead and training speed) of a DPFL system. This is because they suffer from accuracy degradation and ignore the communication costs incurred when transferring the activation from the device to the server. This article proposes EcoFed \u2013 a communication efficient framework for DPFL systems. EcoFed eliminates the transmission of the gradient by developing pre-trained initialization of the DNN model on the device for the first time. This reduces the accuracy degradation seen in local loss-based methods. In addition, EcoFed proposes a novel replay buffer mechanism and implements a quantization-based compression technique to reduce the transmission of the activation. It is experimentally demonstrated that EcoFed can reduce the communication cost by up to 133\u00d7 and accelerate training by up to 21\u00d7 when compared to classic FL. Compared to vanilla DPFL, EcoFed achieves a 16\u00d7 communication reduction and 2.86\u00d7 training time speed-up.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "92148538",
                    "name": "Di Wu"
                },
                {
                    "authorId": "1754190",
                    "name": "R. Ullah"
                },
                {
                    "authorId": "2209882604",
                    "name": "Philip Rodgers"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "7d0a2d36bddaf05d423f551776ff51483a4be826",
            "title": "CONTINUER: Maintaining Distributed DNN Services During Edge Failures",
            "abstract": "Partitioning and deploying Deep Neural Networks (DNNs) across edge nodes may be used to meet performance objectives of applications. However, the failure of a single node may result in cascading failures that will adversely impact the delivery of the service and will result in failure to meet specific objectives. The impact of these failures needs to be minimised at runtime. Three techniques are explored in this paper, namely repartitioning, early-exit and skip-connection. When an edge node fails, the repartitioning technique will repartition and redeploy the DNN thus avoiding the failed nodes. The early-exit technique makes provision for a request to exit (early) before the failed node. The skip connection technique dynamically routes the request by skipping the failed nodes. This paper will leverage trade-offs in accuracy, end-to-end latency and downtime for selecting the best technique given user-defined objectives (accuracy, latency and downtime thresholds) when an edge node fails. To this end, CONTINUER is developed. Two key activities of the framework are estimating the accuracy and latency when using the techniques for distributed DNNs and selecting the best technique. It is demonstrated on a lab-based experimental testbed that CONTINUER estimates accuracy and latency when using the techniques with no more than an average error of 0.28% and 13.06%, respectively, and selects the suitable technique with a low overhead of no more than 16.82 milliseconds and an accuracy of up to 99.86%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1606006664",
                    "name": "A. Majeed"
                },
                {
                    "authorId": "2057915031",
                    "name": "Peter Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "110f781d5914221010b1c5b5ec1f4afe59053443",
            "title": "The Case for Adaptive Deep Neural Networks in Edge Computing",
            "abstract": "Deep Neural Networks (DNNs) are an application class that benefit from being distributed across the edge and cloud. A DNN is partitioned such that specific layers of the DNN are deployed onto the edge and the cloud to meet performance and privacy objectives. However, there is limited understanding of: whether and how evolving operational conditions (increased CPU and memory utilization at the edge or reduced data transfer rates between the edge and cloud) affect the performance of already deployed DNNs, and whether a new partition configuration is required to maximize performance. A DNN that adapts to changing operational conditions is referred to as an \u2018adaptive DNN\u2019. This paper investigates whether there is a case for adaptive DNNs by considering four questions: (i) Are DNNs sensitive to operational conditions? (ii) How sensitive are DNNs to operational conditions? (iii) Do individual or a combination of operational conditions equally affect DNNs? (iv) Is DNN partitioning sensitive to hardware architectures? The exploration is carried out in the context of 8 pre-trained DNN models and the results presented are from analyzing nearly 8 million data points. The results highlight that network conditions affect DNN performance more than CPU or memory related operational conditions. Repartitioning is noted to provide a performance gain in a number of cases, but a specific trend is not noted in relation to the underlying hardware architecture. Nonetheless, the need for adaptive DNNs is confirmed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1854645300",
                    "name": "Francis McNamee"
                },
                {
                    "authorId": "1691109",
                    "name": "S. Dustdar"
                },
                {
                    "authorId": "2239201921",
                    "name": "Peter Kilpatrick"
                },
                {
                    "authorId": "2257597417",
                    "name": "Weisong Shi"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "420681c6c3d34c7faa1909f4504327061f6e8969",
            "title": "NEUKONFIG: Reducing Edge Service Downtime When Repartitioning DNNs",
            "abstract": "Deep Neural Networks (DNNs) may be partitioned across the edge and the cloud to improve the performance efficiency of inference. DNN partitions are determined based on operational conditions such as network speed. When operational conditions change DNNs will need to be repartitioned to maintain the overall performance. However, repartitioning using existing approaches, such as Pause and Resume, will incur a service downtime on the edge. This paper presents the NEUKONFIG framework that identifies the service downtime incurred when repartitioning DNNs and proposes approaches for reducing edge service downtime. The proposed approaches are based on \u2018Dynamic Switching\u2019 in which, when the network speed changes and given an existing edge-cloud pipeline, a new edge-cloud pipeline is initialised with new DNN partitions. Incoming inference requests are switched to the new pipeline for processing data. Experimental studies are carried out on a lab-based testbed to demonstrate that Dynamic Switching reduces the downtime by at least an order of magnitude when compared to a baseline using Pause and Resume that has a downtime of 6 seconds. A trade-off in the edge service downtime and memory required is noted. The Dynamic Switching approach that requires the same amount of memory as the baseline reduces the edge service downtime to 0.6 seconds and to less than 1 millisecond in the best case when twice the amount of memory as the baseline is available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1606006664",
                    "name": "A. Majeed"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "4fb6c2a8cb2d0f99d12e9de64aaab966e1d3bf06",
            "title": "FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning",
            "abstract": "Applying federated learning (FL) on Internet of Things (IoT) devices is necessitated by the large volumes of data they produce and growing concerns of data privacy. However, there are three challenges that need to be addressed to make FL efficient: 1) execution on devices with limited computational capabilities; 2) accounting for stragglers due to computational heterogeneity of devices; and 3) adaptation to the changing network bandwidths. This article presents FedAdapt, an adaptive offloading FL framework to mitigate the aforementioned challenges. FedAdapt accelerates local training in computationally constrained devices by leveraging layer offloading of deep neural networks (DNNs) to servers. Furthermore, FedAdapt adopts reinforcement learning (RL)-based optimization and clustering to adaptively identify which layers of the DNN should be offloaded for each individual device on to a server to tackle the challenges of computational heterogeneity and changing network bandwidth. The experimental studies are carried out on a lab-based testbed and it is demonstrated that by offloading a DNN from the device to the server FedAdapt reduces the training time of a typical IoT device by over half compared to classic FL. The training time of extreme stragglers and the overall training time can be reduced by up to 57%. Furthermore, with changing network bandwidth, FedAdapt is demonstrated to reduce the training time by up to 40% when compared to classic FL, without sacrificing accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "92148538",
                    "name": "Di Wu"
                },
                {
                    "authorId": "1754190",
                    "name": "R. Ullah"
                },
                {
                    "authorId": "145651607",
                    "name": "P. Harvey"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "796502a1d76d7843467a72984c4b059c1d3a41d4",
            "title": "FedFly: Toward Migration in Edge-Based Distributed Federated Learning",
            "abstract": "Federated learning (FL) is a privacy-preserving distributed machine learning technique that trains models while keeping all the original data generated on devices locally. Since devices may be resource-constrained, offloading can be used to improve FL performance by transferring computational workload from devices to edge servers. However, due to mobility, devices participating in FL may leave the network during training and need to connect to a different edge server. This is challenging because the offloaded computations from an edge server need to be migrated. In line with this assertion, we present FedFly, which is, to the best of our knowledge, the first work to migrate a deep neural network (ONN) when devices move between edge servers during FL training. Our empirical results on the CIFAR-10 dataset, with both balanced and imbalanced data distribution, support our claims that FedFly can reduce training time by up to 33 percent when a device moves after 50 percent of the training is completed, and by up to 45 percent when 90 percent of the training is completed when compared to the state-of-the-art offloading approach in FL. FedFly has negligible overhead of up to two seconds and does not compromise accuracy. Finally, we highlight a number of open research issues for further investigation. FedFly can be downloaded from https://github.com/qub-bless-on/FedFly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1754190",
                    "name": "R. Ullah"
                },
                {
                    "authorId": null,
                    "name": "Di Wu"
                },
                {
                    "authorId": "145651607",
                    "name": "P. Harvey"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "eef2545baed8bef91d06ead539c37e9b11dd6f27",
            "title": "Power Log\u2019n\u2019Roll: Power-Efficient Localized Rollback for MPI Applications Using Message Logging Protocols",
            "abstract": "In fault tolerance for parallel and distributed systems, message logging protocols have played a prominent role in the last three decades. Such protocols enable local rollback to provide recovery from fail-stop errors. Global rollback techniques can be straightforward to implement but at times lead to slower recovery than local rollback. Local rollback is more complicated but can offer faster recovery times. In this work, we study the power and energy efficiency implications of global and local rollback. We propose a power-efficient version of local rollback to reduce power consumption for non-critical, blocked processes, using Dynamic Voltage and Frequency Scaling (DVFS) and clock modulation (CM). Our results for 3 different MPI codes on 2 parallel systems show that power-efficient local rollback reduces CPU energy waste up to 50% during the recovery phase, compared to existing global and local rollback techniques, without introducing significant overheads. Furthermore, we show that savings manifest for all blocked processes, which grow linearly with the process count. We estimate that for settings with high recovery overheads the total energy waste of parallel codes is reduced with the proposed local rollback.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067652",
                    "name": "K. Dichev"
                },
                {
                    "authorId": "133823364",
                    "name": "Daniele De Sensi"
                },
                {
                    "authorId": "51911341",
                    "name": "Dimitrios S. Nikolopoulos"
                },
                {
                    "authorId": "1717511",
                    "name": "K. Cameron"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "0f826ae166d726f9d21c7a3e0991ba04512dde9d",
            "title": "A Case For Adaptive Deep Neural Networks in Edge Computing",
            "abstract": "Edge computing offers an additional layer of compute infrastructure closer to the data source before raw data from privacy-sensitive and performance-critical applications is transferred to a cloud data center. Deep Neural Networks (DNNs) are one class of applications that are reported to benefit from collaboratively computing between the edge and the cloud. A DNN is partitioned such that specific layers of the DNN are deployed onto the edge and the cloud to meet performance and privacy objectives. However, there is limited understanding of: (a) whether and how evolving operational conditions (increased CPU and memory utilization at the edge or reduced data transfer rates between the edge and the cloud) affect the performance of already deployed DNNs, and (b) whether a new partition configuration is required to maximize performance. A DNN that adapts to changing operational conditions is referred to as an `adaptive DNN'. This paper investigates whether there is a case for adaptive DNNs in edge computing by considering three questions: (i) Are DNNs sensitive to operational conditions? (ii) How sensitive are DNNs to operational conditions? (iii) Do individual or a combination of operational conditions equally affect DNNs? The exploration is carried out in the context of 8 pre-trained DNN models and the results presented are from analyzing nearly 2 million data points. The results highlight that network conditions affects DNN performance more than CPU or memory related operational conditions. Repartitioning is noted to provide a performance gain in a number of cases, thus demonstrating the need for adaptive DNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1854645300",
                    "name": "Francis McNamee"
                },
                {
                    "authorId": "1691109",
                    "name": "S. Dustdar"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "38737155",
                    "name": "Weisong Shi"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "1adc1cac342facb1f909979765db38f78d2a052f",
            "title": "Computing integrals for electron molecule scattering on heterogeneous accelerator systems",
            "abstract": "Using heterogeneous accelerators to obtain high performance for mathematical kernels remains an active research frontier in computational science. The accelerators have compute architectures that are different from the CPUs and in addition have memory spaces independent of the CPU systems to which they are connected. It follows that accelerators require a different approach to writing optimal code than that needed on a multi\u2010CPU system. Taken together these issues have represented a significant barrier to widespread adoption of accelerators for execution with large legacy code bases. OpenCL has emerged as a common programming language with which to implement code that runs across a range of parallel architectures, including multi\u2010core CPUs. This article is a case study on how the instruction\u2010level parallelism offered by field programmable gate arrays (FPGAs) and GPUs through OpenCL can be exploited in molecular physics. The algorithm which we study is the evaluation of tail integrals between Gaussian type basis functions for the R\u2010matrix method, a task that arises in the study of scattering of low energy electrons by molecular targets. The results of our productivity study, which is the first application of OpenCL in this problem domain, show that significant performance can be obtained from both FPGA and graphics processing unit (GPU) accelerators for this application. We discuss suitable transformations unique to each accelerator architecture for the integrals studied and present performance results comparing the FPGA and GPU with execution on Intel multi\u2010core systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "1be51d323ce7c52587053c6aaffca9f92673e713",
            "title": "Incremental Density-Based Clustering on Multicore Processors",
            "abstract": "The density-based clustering algorithm is a fundamental data clustering technique with many real-world applications. However, when the database is frequently changed, how to effectively update clustering results rather than reclustering from scratch remains a challenging task. In this work, we introduce IncAnyDBC, a unique parallel incremental data clustering approach to deal with this problem. First, IncAnyDBC can process changes in bulks rather than batches like state-of-the-art methods for reducing update overheads. Second, it keeps an underlying cluster structure called the object node graph during the clustering process and uses it as a basis for incrementally updating clusters wrt. inserted or deleted objects in the database by propagating changes around affected nodes only. In additional, IncAnyDBC actively and iteratively examines the graph and chooses only a small set of most meaningful objects to produce exact clustering results of DBSCAN or to approximate results under arbitrary time constraints. This makes it more efficient than other existing methods. Third, by processing objects in blocks, IncAnyDBC can be efficiently parallelized on multicore CPUs, thus creating a work-efficient method. It runs much faster than existing techniques using one thread while still scaling well with multiple threads. Experiments are conducted on various large real datasets for demonstrating the performance of IncAnyDBC.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "144891660",
                    "name": "Jon Jacobsen"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1500614044",
                    "name": "N. Tran"
                },
                {
                    "authorId": "1713664",
                    "name": "I. Assent"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "92a78eae2388101c97ef9653c02c68469395b26d",
            "title": "Modelling Fog Offloading Performance",
            "abstract": "Fog computing has emerged as a computing paradigm aimed at addressing the issues of latency, bandwidth and privacy when mobile devices are communicating with remote cloud services. The concept is to offload compute services closer to the data. However many challenges exist in the realisation of this approach. During offloading, (part of) the application underpinned by the services may be unavailable, which the user will experience as down time. This paper describes work aimed at building models to allow prediction of such down time based on metrics (operational data) of the underlying and surrounding infrastructure. Such prediction would be invaluable in the context of automated Fog offloading and adaptive decision making in Fog orchestration. Models that cater for four container-based stateless and stateful offload techniques, namely Save and Load, Export and Import, Push and Pull and Live Migration, are built using four (linear and non-linear) regression techniques. Experimental results comprising over 42 million data points from multiple lab-based Fog infrastructure are presented. The results highlight that reasonably accurate predictions (measured by the coefficient of determination for regression models, mean absolute percentage error, and mean absolute error) may be obtained when considering 25 metrics relevant to the infrastructure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1606006664",
                    "name": "A. Majeed"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "324780b1b3f379975614025d79fff0c7b86568ff",
            "title": "Stream-Based Representation and Incremental optimization of Technical Market Indicators",
            "abstract": "Technical market indicators are used to measure the trends of financial markets. In practice they are conventionally expressed using a non-formal notation or a DSL specific to a certain development platform, which poorly correlates between individual trades and the high-level formulas operating on those trades and leaving very little room for optimization. In this paper we propose a formal, mathematically based notation for expressing technical market indicators, which represents trades as streams of data. We argue that this notation is more accurate and open to optimizations. We express three technical indicators from the ground up, demonstrate our optimization approach, and implement the indicators using Click router runtime. Finally, we benchmark various configurations and versions of the implemented indicators, running in kernel space as well as user space, and discuss the findings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49175351",
                    "name": "K. Bakanov"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144114375",
                    "name": "Hans Vandierendonck"
                }
            ]
        },
        {
            "paperId": "4bc3d255883234e5523e58e9f9d22148bf900b5f",
            "title": "Performance Estimation of Container-Based Cloud-to-Fog Offloading",
            "abstract": "Fog computing offloads latency critical services of a Cloud application onto resources located at the edge of the network that are in close proximity to end-user devices. The research in this paper is motivated towards characterising and estimating the time taken to offload a service using containers, which is investigated in the context of the 'Save and Load' container migration technique. To this end, the research addresses questions such as whether fog offloading can be accurately modelled and which system and network related parameters influence offloading. These are addressed by exploring a catalogue of 21 different metrics both at the system and process levels that is used as input to four estimation techniques using a collective model and individual models to predict the time taken for offloading. The study is pursued by collecting over 1.1 million data points and the preliminary results indicate that offloading can be modelled accurately.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1606006664",
                    "name": "A. Majeed"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1683999",
                    "name": "B. Varghese"
                }
            ]
        },
        {
            "paperId": "a0c09c4cb027063bb15b2ad29bca01e165515fcc",
            "title": "Supporting Cloud IaaS Users in Detecting Performance-Based Violation for Streaming Applications",
            "abstract": "Cloud infrastructure-as-a-service (IaaS) users require stable performance for their applications so that the Quality of Service (QoS) constraints are satisfied. However, they generally experience performance variability, primarily due to multi-tenancy. Such variability may lead to QoS violations for the deployed applications. Existing cloud infrastructure solutions offered by cloud providers (CPs) do not have facilities to detect such violations. Hence, cloud users need to take responsibility for monitoring the performance of their applications in order to detect application-specific QoS violations. In this paper, we propose a novel algorithm for detecting QoS violation for media streaming applications. The algorithm compares the cumulative value of the expected streamed data against the cumulative value of the measured streamed data. Based on this comparison, the algorithm may raise QoS violation alarms. We evaluate the algorithm by deploying a media streaming application in a lab-based cloud setup. Experimental results demonstrate the correctness of the proposed algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3482235",
                    "name": "Esha Barlaskar"
                },
                {
                    "authorId": "2067652",
                    "name": "K. Dichev"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "01fa9cbccdb4f43657639d5612937f67ee55fc7a",
            "title": "MyMinder: A User-centric Decision Making Framework for Intercloud Migration",
            "abstract": "Each cloud infrastructure-as-a-service (IaaS) provider offers its own set of virtual machine (VM) images and hypervisors. This creates a vendor lock-in problem when cloud users try to change cloud provider (CP). Although, recently a few user-side inter-cloud migration techniques have been proposed (e.g. nested virtualisation), these techniques do not provide dynamic cloud management facilities which could help users to decide whether or not to proceed with migration, when and where to migrate, etc. Such decision-making support in the post-deployment phase is crucial when the current CP\u2019s Quality of Service (QoS) degrades while other CPs offer better QoS or the same service at a lower price. To ensure that users\u2019 required QoS constraints are achieved, dynamic monitoring and management of the acquired cloud services are very important and should be integrated with the inter-cloud migration techniques. In this paper, we present the problem formulation and the architecture of a Multi-objective dYnamic MIgratioN Decision makER (MyMinder) framework that enables users to monitor and appropriately manage their deployed applications by providing decisions on whether to continue with the currently selected CP or to migrate to a different CP. The paper also discusses experimental results obtained when running a Spark linear regression application in Amazon EC2 and Microsoft Azure as an initial investigation to understand the motivating factors for live-migration of cloud applications across cloud providers in the post-deployment phase.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3482235",
                    "name": "Esha Barlaskar"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "9935ef2973a1c68102147bfb1c625b1d926de3b3",
            "title": "GPU Virtualization and Scheduling Methods",
            "abstract": "The integration of graphics processing units (GPUs) on high-end compute nodes has established a new accelerator-based heterogeneous computing model, which now permeates high-performance computing. The same paradigm nevertheless has limited adoption in cloud computing or other large-scale distributed computing paradigms. Heterogeneous computing with GPUs can benefit the Cloud by reducing operational costs and improving resource and energy efficiency. However, such a paradigm shift would require effective methods for virtualizing GPUs, as well as other accelerators. In this survey article, we present an extensive and in-depth survey of GPU virtualization techniques and their scheduling methods. We review a wide range of virtualization techniques implemented at the GPU library, driver, and hardware levels. Furthermore, we review GPU scheduling methods that address performance and fairness issues between multiple virtual machines sharing GPUs. We believe that our survey delivers a perspective on the challenges and opportunities for virtualization of heterogeneous computing environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2634930",
                    "name": "Cheol-Ho Hong"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "eb47c704a241f82b5fa3198f28364d5e1ee1117b",
            "title": "FairGV: Fair and Fast GPU Virtualization",
            "abstract": "Increasingly high performance computing (HPC) application developers are opting to use cloud resources due to higher availability. Virtualized GPUs would be an obvious and attractive option for HPC application developers using cloud hosting services. Unfortunately, existing GPU virtualization software is not ready to address fairness, utilization, and performance limitations associated with consolidating mixed HPC workloads. This paper presents FairGV, a radically redesigned GPU virtualization system that achieves system-wide weighted fair sharing and strong performance isolation in mixed workloads that use GPUs with variable degrees of intensity. To achieve its objectives, FairGV introduces a trap-less GPU processing architecture, a new fair queuing method integrated with work-conserving and GPU-centric coscheduling polices, and a collaborative scheduling method for non-preemptive GPUs. Our prototype implementation achieves near ideal fairness (<inline-formula><tex-math notation=\"LaTeX\">$\\geq 0.97$</tex-math><alternatives> <inline-graphic xlink:href=\"nikolopoulos-ieq1-2717908.gif\"/></alternatives></inline-formula> Min-Max Ratio) with little performance degradation (<inline-formula><tex-math notation=\"LaTeX\">$\\leq 1.02$</tex-math><alternatives> <inline-graphic xlink:href=\"nikolopoulos-ieq2-2717908.gif\"/></alternatives></inline-formula> aggregated overhead) in a range of mixed HPC workloads that leverage GPUs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2634930",
                    "name": "Cheol-Ho Hong"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "1117465642377c6b9f8ff8c2357d7717b00c89fb",
            "title": "NanoStreams: Codesigned microservers for edge analytics in real time",
            "abstract": "NanoStreams explores the design, implementation, and system software stack of micro-servers aimed at processing data in-situ and in real time. These micro-servers can serve the emerging Edge computing ecosystem, namely the provisioning of advanced computational, storage, and networking capability near data sources to achieve both low latency event processing and high throughput analytical processing, before considering off-loading some of this processing to high-capacity data centres. Nano Streams explores a scale-out micro-server architecture that can achieve equivalent QoS to that of conventional rack-mounted servers for high-capacity data centres, but with dramatically reduced form factors and power consumption. To this end, Nano Streams introduces novel solutions in programmable & configurable hardware accelerators, as well as the system software stack used to access, share, and program those accelerators. Our Nano Streams micro-server prototype has demonstrated 5.5 x higher energy-efficiency than a standard Xeon Server. Simulations of the micro server's memory system extended to leverage hybrid DDR/NVM main memory indicated 5x higher energy-efficiency than a conventional DDR-based system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2825891",
                    "name": "Giorgis Georgakoudis"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "2112151014",
                    "name": "Ahmad Hassan"
                },
                {
                    "authorId": "3288941",
                    "name": "U. Minhas"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "3058058",
                    "name": "George Tzenakis"
                },
                {
                    "authorId": "144114375",
                    "name": "Hans Vandierendonck"
                },
                {
                    "authorId": "145363456",
                    "name": "Roger Francis Woods"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                },
                {
                    "authorId": "5743206",
                    "name": "M. Shyamsundar"
                },
                {
                    "authorId": "2066207095",
                    "name": "P. Barber"
                },
                {
                    "authorId": "153587270",
                    "name": "M. Russell"
                },
                {
                    "authorId": "1805177",
                    "name": "A. Bilas"
                },
                {
                    "authorId": "8750831",
                    "name": "S. Kaloutsakis"
                },
                {
                    "authorId": "1804495",
                    "name": "Heiner Giefers"
                },
                {
                    "authorId": "1831851",
                    "name": "P. Staar"
                },
                {
                    "authorId": "10107014",
                    "name": "C. Bekas"
                },
                {
                    "authorId": "39562111",
                    "name": "Neil Horlock"
                },
                {
                    "authorId": "2380010",
                    "name": "R. Faloon"
                },
                {
                    "authorId": "2058905379",
                    "name": "Colin Pattison"
                }
            ]
        },
        {
            "paperId": "c6446de9127ea22fedd2587a1b5986c6a06fc49b",
            "title": "A Scalable Runtime for the ECOSCALE Heterogeneous Exascale Hardware Platform",
            "abstract": "Exascale computation is the next target of high performance computing. In the push to create exascale computing platforms, simply increasing the number of hardware devices is not an acceptable option given the limitations of power consumption, heat dissipation, and programming models which are designed for current hardware platforms. Instead, new hardware technologies, coupled with improved programming abstractions and more autonomous runtime systems, are required to achieve this goal. This position paper presents the design of a new runtime for a new heterogeneous hardware platform being developed to explore energy efficient, high performance computing. By extending and enhancing the OpenCL framework, this work will both simplify the programming of current and future HPC applications, as well as automating the scheduling of data and computation across this new hardware platform. Also, this work explores the use of FPGAs to achieve both the power and performance goals of exascale, as well as utilising the runtime to automatically effect dynamic configuration and reconfiguration of hardware platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145651607",
                    "name": "P. Harvey"
                },
                {
                    "authorId": "49175351",
                    "name": "K. Bakanov"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "15e20e0413ee8e7bdb524311c5095db838b2e16b",
            "title": "GPU Acceleration of Partial Differential Equation Solvers",
            "abstract": "Differential equations are often directly solvable by analytical means only in their 1-D version. Partial differential equations are generally not solvable by analytical means in 2-D and 3-D, with the exception of few special cases. In all other cases, numerical approximation methods need to be utilized. One of the most popular such methods is the \ufb01nite element method. Our main areas of focus are the Poisson heat equation and the plate bending equation. The purpose of the current paper is to provide a quick walk through of the various approaches we followed in pursuit of creating optimal solvers, accelerated with the use of graphical processing units, and comparing them in terms of accuracy and time ef\ufb01ciency with existing or self-made non-accelerated solvers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3466924",
                    "name": "P. Iosifidis"
                },
                {
                    "authorId": "123857619",
                    "name": "P. Weit"
                },
                {
                    "authorId": "150262503",
                    "name": "P. Marlappan"
                },
                {
                    "authorId": "40385092",
                    "name": "R. Flanagan"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "2057915022",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "46229646",
                    "name": "J. Fitzsimons"
                }
            ]
        },
        {
            "paperId": "745cdbf1f2d5a665e1d2b6db3b2aba00fb511185",
            "title": "Optimizations of the GPU-based three-dimensional FDTD program with CPML boundary condition on Kepler architecture GPU",
            "abstract": "An effective way to accelerate the Finite-difference time-domain (FDTD) method is the use of a Graphic Processing Unit (GPU). This paper describes an implementation of the three dimensional FDTD method with CPML boundary condition on a Kepler (GK110) architecture GPU. We optimize the FDTD domain decomposition method on Kepler GPU. And then, several Kepler-based optimizations are studied and applied to the FDTD program. The optimized program achieved up to 270.9 times speedup compared to the CPU sequential version. The experiments show that 22.2% of the simulation time is saved compared to the GPU version without optimizations. The solution is also faster than previous works.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2069518317",
                    "name": "Ran Shao"
                },
                {
                    "authorId": "143685769",
                    "name": "D. Linton"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "2065869376",
                    "name": "Ning Zheng"
                }
            ]
        },
        {
            "paperId": "ba188e853dc20180a6c8dc1047b490bec75046a9",
            "title": "Weakening Cardinality Constraints Creates Harder Satisfiability Benchmarks",
            "abstract": "For some time, the satisfiability formulae that have been the most difficult to solve for their size have been crafted to be unsatisfiable by the use of cardinality constraints. Recent solvers have introduced explicit checking of such constraints, rendering previously difficult formulae trivial to solve. A family of unsatisfiable formulae is described that is derived from the sgen4 family but cannot be solved using cardinality constraints detection and reasoning alone. These formulae were found to be the most difficult during the SAT2014 competition by a significant margin and include the shortest unsolved benchmark in the competition, sgen6-1200-5-1.cnf.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "c4bf11b19f1411f8cd37777b4f8d319728312420",
            "title": "Iso-Quality of Service: Fairly Ranking Servers for Real-Time Data Analytics",
            "abstract": "We present a mathematically rigorous iso-Quality-of-Service (QoS) metric which relates the achievable quality of service (QoS) for a real-time analytics service with workload specific and use case specific performance and output quality requirements to the energy cost of offering the service by different server architectures. Using a new iso-QoS evaluation methodology, we scale server resources to meet QoS targets and directly rank the servers in terms of their energy-efficiency and by extension cost of ownership. Our metric and method are platform-independent and enable fair comparison of datacenter compute servers with significant architectural diversity, including micro-servers. We deploy our metric and methodology to compare three servers running financial option pricing workloads on real-life market data. We find that server ranking is sensitive to data inputs and desired QoS level and that although scale-out micro-servers can be up to two times more energy-efficient than conventional heavyweight ser...",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2825891",
                    "name": "Giorgis Georgakoudis"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "150921743",
                    "name": "Ahmed Sayed"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "2380010",
                    "name": "R. Faloon"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "5d8c6a34b6962efea91eec0573a35718d9e34957",
            "title": "On the Viability of Microservers for Financial Analytics",
            "abstract": "Energy consumption and total cost of ownership are daunting challenges for Datacenters, because they scale disproportionately with performance. Datacenters running financial analytics may incur extremely high operational costs in order to meet performance and latency requirements of their hosted applications. Recently, ARM-based microservers have emerged as a viable alternative to high-end servers, promising scalable performance via scale-out approaches and low energy consumption.In this paper, we investigate the viability of ARM-based microservers for option pricing, using the Monte Carlo and Binomial Tree kernels. We compare an ARM-based microserver against a state-of-the-art x86 server. We define application-related but platform-independent energy and performance metrics to compare those platforms fairly in the context of datacenters for financial analytics and give insight on the particular requirements of option pricing. Our experiments show that through scaling out energy-efficient compute nodes within a 2U rack-mounted unit, an ARM-based microserver consumes as little as about 60% of the energy per option pricing compared to an x86 server, despite having significantly slower cores. We also find that the ARM microserver scales enough to meet a high fraction of market throughput demand, while consuming up to 30% less energy than an Intel server.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                },
                {
                    "authorId": "2825891",
                    "name": "Giorgis Georgakoudis"
                },
                {
                    "authorId": "2380010",
                    "name": "R. Faloon"
                },
                {
                    "authorId": "3058058",
                    "name": "George Tzenakis"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "d91ba43d62f6196cfe2bf1933989608a07065e2a",
            "title": "Rigorous specification and low-latency implementation of technical market indicators",
            "abstract": "Technical market indicators are tools used by technical analysts to understand trends in trading markets. Technical (market) indicators are often calculated in real-time, as trading progresses. This paper presents a mathematically-founded framework for calculating technical indicators. Our framework consists of a domain specific language for the unambiguous specification of technical indicators, and a runtime system based on Click, for computing the indicators. We argue that our solution enhances the ease of programming due to aligning our domain-specific language to the mathematical description of technical indicators, and that it enables executing programs in kernel space for decreased latency, without exposing the system to users' programming errors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49175351",
                    "name": "K. Bakanov"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144114375",
                    "name": "Hans Vandierendonck"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                }
            ]
        },
        {
            "paperId": "e9a2b56f3530a4a8e9467ee1814bc994bd494231",
            "title": "Methods and metrics for fair server assessment under real\u2010time financial workloads",
            "abstract": "We present a rigorous methodology and new metrics for fair comparison of server and microserver platforms. Deploying our methodology and metrics, we compare a microserver with ARM cores against two servers with \u00d786 cores running the same real\u2010time financial analytics workload. We define workload\u2010specific but platform\u2010independent performance metrics for platform comparison, targeting both datacenter operators and end users. Our methodology establishes that a server based on the Xeon Phi co\u2010processor delivers the highest performance and energy efficiency. However, by scaling out energy\u2010efficient microservers, we achieve competitive or better energy efficiency than a power\u2010equivalent server with two Sandy Bridge sockets, despite the microserver's slower cores. Using a new iso\u2010QoS metric, we find that the ARM microserver scales enough to meet market throughput demand, that is, a 100% QoS in terms of timely option pricing, with as little as 55% of the energy consumed by the Sandy Bridge server. Copyright \u00a9 2015 John Wiley & Sons, Ltd.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2825891",
                    "name": "Giorgis Georgakoudis"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "150921743",
                    "name": "Ahmed Sayed"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "2380010",
                    "name": "R. Faloon"
                },
                {
                    "authorId": "1698312",
                    "name": "Dimitrios S. Nikolopoulos"
                }
            ]
        },
        {
            "paperId": "42665ea97d9cf468f6a1ebd04197fd2bdbfa1455",
            "title": "Detection and GPU accelerationof 3D FDTD algorithms based on memory access patterns",
            "abstract": "A semi-automatic tool is reported that first analyzes the sequential FDTD program to obtain memory access patterns and related features, and then optimizes the FDTD program with combined use of several types of CUDA memory on both Fermi and Kepler architecture GPUs. The experiments show a 13% and 18% speedup using Fermi and Kepler GPUs respectively compared to the GPU version program without optimization. Up to 142 times speedup is achieved compared to the sequential FDTD C program at a FDTD 3D mesh size of 250* 250* 250 (15.625 million mesh cells) with 10 layers CPML boundary conditions in 4096 time steps.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069518317",
                    "name": "Ran Shao"
                },
                {
                    "authorId": "143685769",
                    "name": "D. Linton"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "145010283",
                    "name": "P. Milligan"
                },
                {
                    "authorId": "2065869376",
                    "name": "Ning Zheng"
                }
            ]
        },
        {
            "paperId": "9579db0a35bce515220c21b5fa1be3d7315a8e03",
            "title": "Comparing the implementation of two\u2010dimensional numerical quadrature on GPU, FPGA and ClearSpeed systems to study electron scattering by atoms",
            "abstract": "The use of accelerators, with compute architectures different and distinct from the CPU, has become a new research frontier in high\u2010performance computing over the past five years. This paper is a case study on how the instruction\u2010level parallelism offered by three accelerator technologies, FPGA, GPU and ClearSpeed, can be exploited in atomic physics. The algorithm studied is the evaluation of two electron integrals, using direct numerical quadrature, a task that arises in the study of intermediate energy electron scattering by hydrogen atoms. The results of our \u2018productivity\u2019 study show that while each accelerator is viable, there are considerable differences in the implementation strategies that must be followed on each. Copyright \u00a9 2011 John Wiley & Sons, Ltd.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "145268083",
                    "name": "T. Steinke"
                },
                {
                    "authorId": "145001527",
                    "name": "J. Bock"
                },
                {
                    "authorId": "144283472",
                    "name": "S. Borchert"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "145111382",
                    "name": "N. Scott"
                }
            ]
        },
        {
            "paperId": "b81453e514f3b66aaaee8922825e7edd3d96a763",
            "title": "Case Study: Using ADLARS to Design and Develop a Real-Time Network Emulator",
            "abstract": "As testing and benchmarking performance of web \nservices and networked applications has proven to be cost-effective, and crucial in some applications, increased \nsignificance has been attached to the development of hardware \nand software network emulators and simulators. In this paper, \nwe discuss a possible design of a light-weight real-time IP \nnetwork emulator that can provide the same functionality and \nperformance as hardware simulators. Also, as the systematic \nsoftware engineering discipline has become a necessity in the \nsoftware development life-cycle, we present a possible \napproach, utilizing mature software engineering disciplines, for \nbuilding the software architecture of the emulator. We then use \nADLARS [1], an Architecture Description Language for Real-time Systems to describe the architecture. The emulator\u2019s \narchitecture serves as a good test-bed for our ADL because of \nits real-time and concurrent nature. We conclude by testing our \ndesign and presenting a possible JAVA implementation of the \nemulator over a UNIX system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "1399133087",
                    "name": "Ameer Al-Nemrat"
                },
                {
                    "authorId": "2605080",
                    "name": "Mohammad Bachrouch"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "0e2d88de52c1d43c4daae0f9b3ab4fce8b06afd4",
            "title": "sgen1: A generator of small but difficult satisfiability benchmarks",
            "abstract": "The satisfiability problem is known to be NP-Complete; therefore, there should be relatively small problem instances that take a very long time to solve. However, most of the smaller benchmarks that were once thought challenging, especially the satisfiable ones, can be processed quickly by modern SAT-solvers. We describe and make available a generator that produces both unsatisfiable and, more significantly, satisfiable formulae that take longer to solve than any others known. At the two most recent international SAT Competitions, the smallest unsolved benchmarks were created by this generator. We analyze the results of all solvers in the most recent competition when applied to these benchmarks and also present our own more focused experiments.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "d69304e29c33292d7e2cf1f50dd4f4ab61af6bdf",
            "title": "Programming Challenges for the Implementation of Numerical Quadrature in Atomic Physics on FPGA and GPU Accelerators",
            "abstract": "Although the need for heterogeneous chips in high performance numerical computing was identified by Chillemi and co-authors in 2001 it is only over the past five years that it has emerged as the new frontier for HPC. In this environment one or more accelerators works symbiotically, on each node, with a multi-core CPU. Two such accelerator technologies are FPGA and GPU each of which works with instruction level parallelism. This paper provides a case study on implementing one computational algorithm on each of these heterogeneous environments. The algorithm is the evaluation of two electron integrals using direct numerical quadrature and is drawn from atomic physics. The results of the study show that while each accelerator is viable, there are considerable differences in the implementation strategies that must be followed on each.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "145268083",
                    "name": "T. Steinke"
                },
                {
                    "authorId": "145001527",
                    "name": "J. Bock"
                },
                {
                    "authorId": "144283472",
                    "name": "S. Borchert"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "145111382",
                    "name": "N. Scott"
                }
            ]
        },
        {
            "paperId": "efb091b57c82364240f5ccd3082a53cc04399fef",
            "title": "A Scalable Approach to Annotate Arbitrary Modelling Languages",
            "abstract": "Refinement via annotations is a common practice in Model-Driven Engineering (MDE). For instance, in the case of our Model-Driven Performance Engineering (MDPE) architecture, we are required to annotate different types of process models with performance objectives, constraints and other information. This is used to enable domain experts, such as business analysts, to benefit from an automated performance prediction based decision support. Currently, the process models are annotated manually, element by element. This approach is not scalable, for instance, in the case where numerous model elements in large model repositories need to be annotated with the same information. Thus, a scalable annotation mechanism is needed which can be used for arbitrary modelling languages. In this paper we propose an architecture which uses a specialized modelling language to express annotations in an efficient way. This language is transformed to model transformation scripts in order to generate annotation models, which separate the annotated information from the target models and, therefore, supports scalable model annotations for modelling languages of choice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34746396",
                    "name": "M. Fritzsche"
                },
                {
                    "authorId": "1706996",
                    "name": "Wasif Gilani"
                },
                {
                    "authorId": "49588650",
                    "name": "Michael Thiele"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                }
            ]
        },
        {
            "paperId": "0cd81c51d56c13ebd0c5aceb6ac8f48da7996f93",
            "title": "Towards Performance Related Decision Support for Model Driven Engineering of Enterprise SOA Applications",
            "abstract": "Model driven performance engineering (MDPE) enables early performance feedback in a MDE process, in order to avoid late identification of performance problems which could cause significant additional development costs. In our past work we argued that a synchronization mechanism between development and performance analysis models is required to adequately integrate analysis results into the development process enabling performance related decision support. In this paper we present a solution for this requirement. We present a new multi-view based approach and its implementation enabling systematic performance related decision support. We currently apply our research on the model driven engineering of process orchestrations on top of SAP's enterprise service oriented architecture (Enterprise SOA).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34746396",
                    "name": "M. Fritzsche"
                },
                {
                    "authorId": "1706996",
                    "name": "Wasif Gilani"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                }
            ]
        },
        {
            "paperId": "4a5f756486a6eb9bee99626b7c6c6fc0c1e9ed1c",
            "title": "A Multiple Views Model for Variability Management in Software Product Lines",
            "abstract": "\\With current trends towards moving variability \nfrom hardware to software, and given the increasing \ndesire to postpone design decisions as much as is \neconomically feasible, managing the variability from \nrequirements elicitation to implementation is \nbecoming a primary business requirement in the \nproduct line process. Nowadays, a medium size \nsoftware system may encompass hundreds if not \nthousands of variability points introducing a new level \nof complexity that current techniques struggle to \nmanage. In this paper, we present a new approach to \nvariability management by introducing a multiple \nviews model (4VM) where each view caters for specific \nset of concerns that relate to a particular group of \nstakeholders.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "2245018972",
                    "name": "John Brown"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                }
            ]
        },
        {
            "paperId": "711ea83a2e1e29b00bea8a9530697af68b0130e3",
            "title": "tts: A SAT-Solver for Small, Difficult Instances",
            "abstract": "The Ternary Tree Solver (tts) is a complete solver for propositional satisfiability which was designed to have good performance on the most difficult small instances. It usesa static ternary tree data structure to represent the simplified proposition under all permissible partial assignments and maintains a database of derived propositions known to be unsatisfiable. In the SAT2007 competition version 4.0 won the silver medal for the category handmade, speciality UNSAT solvers and was the top qualifier for the second stage for handmade benchmarks, solving 11 benchmarks which were not solved by any other entrant. We describe the methods used by the solver and analyse the competition Phase 1 results on small benchmarks. We propose a first version of a comprehensive suite of small difficult satisfiability benchmarks ( sdsb) and compare the worst-case performance of the competition medallists on these benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "73f67750b69591bbc367f4d1266be1010d0aa35f",
            "title": "ALI: An Extensible Architecture Description Language for Industrial Applications",
            "abstract": "While architecture description languages (ADLs) have gained wide acceptance in the research community as a means of describing system designs, the uptake in industry has been slower than might have been expected. A contributory cause may be the perceived lack of flexibility and, as yet, the limited tool support. This paper describes ALI, a new ADL that aims to address these deficiencies by providing a rich, extensible and flexible syntax for describing component interface types and the use of patterns and meta-information. These enhanced capabilities are intended to encourage more widespread industrial usage.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "1706996",
                    "name": "Wasif Gilani"
                },
                {
                    "authorId": "34746396",
                    "name": "M. Fritzsche"
                }
            ]
        },
        {
            "paperId": "7030300a91fa22f67a4190cf88652ae079821382",
            "title": "Ternary Tree Solver (TTS 4.0)",
            "abstract": "The Ternary Tree Solver (tts) algorithm is a complete, deterministic solver for CNF satisfiability. This note describes the operation of version 4.x. Version 4.0 was entered into the SAT 2007 competition. The solver is very loosely based on the well-known Davis-Putnam model and has five phases, namely: Minimization; Variable ordering; Tree building; Tree walking, Rebuilding. The solver cannot compete with the state-ofthe-art solution of large industrial and random benchmarks but appears to have good worstcase performance on hand-crafted benchmarks (such as hgen8, holen, xor-chain etc.) that others find difficult. Brief descriptions of the five phases follow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "76277547cd866eb37b8422e0ae7035bc31c3ef61",
            "title": "Requirements Modelling and Design Notations for Software Product Lines",
            "abstract": "Although feature modelling is a frequently used \napproach to the task of modelling commonality and \nvariability within product lines, there is currently no \nstandard modelling notation or methodology. On the \nassumption that the commonality/variability model will \nbe used as a basis for architecture design, our \nmodelling notation allows features to be augmented \nwith behavioural detail, captured using the UCM path \nnotation. This gives rise to models that capture \ncommonality and variability in behaviour as well as in \nproduct features, and are thus more valuable for \ndownstream design activities. This paper outlines the \nmodelling notation and describes ongoing work on the \ncharacterisation of variability points within models \nbased on this notation, and on the relationships between \nmodel fragments and solution domain techniques such \nas design patterns or variability realisation techniques. \nIt also describes preliminary work, aimed at evolving an \nintelligent tool that can characterise feature and \nbehavioural model fragments and suggest design and \nrealisation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "2943314",
                    "name": "Rachel E. Gawley"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                }
            ]
        },
        {
            "paperId": "f5191121bbe26cbca95bf842f5aeecf9e2b353ed",
            "title": "Challenges in the Application of Feature Modelling in Fixed Line Telecommunications",
            "abstract": "The global telephone system is a complex transmission \nnetwork, the features of which are defined to a very high \nlevel by ITU-T standards. It is therefore a prime candidate \nat which to target the application of software product line \ntechniques, and feature modelling in particular, in order to \nhandle the inherent commonality of protocols and variability \nin equipment functionality. This paper reports on an experimental \nfeature modelling notation and illustrates it with \napplication to the modelling of embedded software for the \ncore network elements. We look at three of the fundamental \nchallenges facing the adoption of feature modelling in \nthe field and explain how we have strived to address these \nwithin our tools set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "2943314",
                    "name": "Rachel E. Gawley"
                }
            ]
        },
        {
            "paperId": "8b49818afb54f2c74088e988c5824c42a43c3ec0",
            "title": "Weaving behavior into feature models for embedded system families",
            "abstract": "Product line software engineering depends on capturing the commonality and variability within a family of products, typically using feature modeling, and using this information to evolve a generic reference architecture for the family. For embedded systems, possible variability in hardware and operating system platforms is an added complication. The design process can be facilitated by first exploring the behavior associated with features. In this paper we outline a bidirectional feature modeling scheme that supports the capture of commonality and variability in the platform environment as well as within the required software. Additionally, 'behavior' associated with features can be included in the overall model. This is achieved by integrating the UCM path notation in a way that exploits UCM's static and dynamic stubs to capture behavioral variability and link it to the feature model structure. The resulting model is a richer source of information to support the architecture development process",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "2943314",
                    "name": "Rachel E. Gawley"
                },
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                }
            ]
        },
        {
            "paperId": "0d7249f5198786c7986f5a471fb2423b6dacbabe",
            "title": "A generic reference software architecture for load balancing over mirrored Web servers: NaSr case study",
            "abstract": "Summary form only given. With the rapid expansion of the Internet and the increasing demand on Web servers, many techniques were developed to overcome the servers' hardware performance limitation. Mirrored Web servers is one of the techniques used where a number of servers carrying the same \"mirrored\" set of services are deployed. Client access requests are then distributed over the set of mirrored servers to even up the load. In this paper, we present a generic reference software architecture for load balancing over mirrored Web servers. The architecture was designed adopting the latest NaSr architectural style and described using the ADLARS architecture description language. With minimal effort, different tailored product architectures can be generated from the reference architecture to serve different network protocols and server operating systems. An example product system is described and a sample Java implementation is presented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                }
            ]
        },
        {
            "paperId": "27a97e4e0c057eb59c4e88ad103f80bd1cde3690",
            "title": "ADLARS: An Architecture Description Language for Software Product Lines",
            "abstract": "Software product line (SPL) engineering has emerged to become a mature domain for maximizing reuse within the context of a family of related software products. Within the process of SPL, the variability and commonality among the different products within the scope of a family is captured and modeled into a system's `feature model'. Currently, there are no architecture description languages (ADLs) that support the relationship between the feature model domain and the system architecture domain, leaving a gap which significantly increases the complexity of analyzing the system's architecture and insuring that it complies with its set feature model and variability requirements. In this paper we present ADLARS, an architecture description language that supports the relationship between the system's feature model and the architectural structures in an attempt to alleviate the aforementioned problem. The link between the two spaces also allows the automatic generation of product architectures from the family reference architecture",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                }
            ]
        },
        {
            "paperId": "fd621ba712363f050cdd2d5dbf46cc76658b4a6d",
            "title": "Feature-Guided Architecture Development for Embedded System Families",
            "abstract": "Software product-line engineering aims to maximize reuse by exploiting the commonality within families of related systems. Its success depend on capturing the commonality and variability, and using this to evolve a reference architecture for the product family. With embedded system families, the possibility of variability in hardware and operating system platforms is an added complication. In this paper we outline a strategy for evolving reference architectures from bi-directional feature models. The proposed strategy complements information provided by the feature model with scenarios that help to elaborate feature behavior.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "145579839",
                    "name": "C. Gillan"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                }
            ]
        },
        {
            "paperId": "262322e5de5238f03c44ae2170c5f49ffd5e6ebf",
            "title": "A Real-time Network Emulator: ADLARS Case Study",
            "abstract": "As testing and benchmarking performance of \nweb services and networked applications has proven to \nbe cost-effective, and crucial in some applications, \nincreased significance has been attached to the \ndevelopment of hardware and software network \nemulators and simulators. In this paper, we discuss a \npossible design of a light-w eight real-time IP network \nemulator that can provide the same functionality and \nperformance as hardware simulators. Also, as the \nsystematic software engineering discipline has become a \nnecessity in the software development life-cycle, we \npresent a possible approach, utilizing mature software \nengineering disciplines, for building the software \narchitecture of the emulator. We then use ADLARS [1], \nan A rchitecture D escription Language for Real-time \nSystems developed within our research team to describe \nthe architecture. The emulator\u2019s architecture serves as a \ngood test-bed for our ADL because of its real-time and \nconcurrent nature. We conclude by testing our design \nand presenting a possible JAVA instantiation of the \nemulator over a UNIX system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "2116700469",
                    "name": "John Brown"
                }
            ]
        },
        {
            "paperId": "5f18b01f3d0e69c78d7db385bfa5531f98964991",
            "title": "The contribution of architecture description languages to the evaluation of software architectures",
            "abstract": "Identifying limitations and mistakes within software \narchitectures at the design stage is often cost- \nefficient and reduces the overall system\u2019s \ndevelopment and marketing time. A number of \ntechniques have emerged over recent years, for \nassessing both single-systems, and product-line \narchitectures. These techniques do not assume any \nparticular format or language for the description of \nthe architecture. Often however, they do require the \nability to extract a range of information from the \narchitecture description. In this research, we looked \nat the relationships between the features that might \nbe provided by a formal architecture description \nlanguage (ADL), and the information required for \narchitecture assessment purposes. We also designed \na set of visual tools for use within the architecture \ndevelopment and assessment process in order to \nalleviate and aid the human part of the process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "2116699289",
                    "name": "John Brown"
                }
            ]
        },
        {
            "paperId": "6b1a1d5d6bc26afe80698bf598afedcb94ca6915",
            "title": "A network architectural style for real-time systems: NaSr",
            "abstract": "Inter-component communication has always been of great importance in the design of software architectures and connectors have been considered as first-class entities in many approaches by R. Allen and D. Garlan (1994), M. Shaw et al., (1995), and D. Batory and S. O'Malley (1992). We present a novel architectural style that is derived from the well-established domain of computer networks. The style adopts the inter-component communication protocol in a novel way that allows large scale software reuse. It mainly targets real-time, distributed, concurrent, and heterogeneous systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                }
            ]
        },
        {
            "paperId": "73a38b28c82b616b6de00120ea281c6652edf6d1",
            "title": "Towards an automated evaluation process for software architectures",
            "abstract": "Optimizing and editing enterprise software systems, after \nthe implementation process has started, is widely \nrecognized to be an expensive process. This has led to \nincreasing emphasis on locating mistakes within software \nsystems at the design stage, to help minimize \ndevelopment costs. There is increasing interest in the field \nof architecture evaluation techniques that can identify \nproblems at the design stage, either within complete, or \npartially complete architectures. Most current techniques \nrely on manual review-based evaluation methods that \nrequire advanced skills from architects and evaluators. \nWe are currently considering what a formal Architecture \nDescription Language (ADL) can contribute to the \nprocess of architecture eval uation and validation. Our \ninvestigation is considering the inter-relationships \nbetween the activities performed during the architecture \nevaluation process, the characteristics an ADL should \npossess to support these activities, and the tools needed to \nprovide convenient access to, and presentation of \narchitectural information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                }
            ]
        },
        {
            "paperId": "b9d077af05fc59b0fa20386d7cc9b63c92191205",
            "title": "Using the NaSr architectural style to solve the broken hyperlink problem",
            "abstract": "According to a Web usability study [1] by the Georgia \nInstitute of Technology, net use rs rate broken hyperlinks as \nthe second-biggest problem online, right behind slow-loading pages. The problem of broken hyperlinks (or dead \nlinks) is a common problem within enterprise websites \ncomprising hundreds or thousands of interconnected web \npages that are continuously modified and updated [2]. \nBroken links can occur due to many reasons such as file \nrename, delete or path modification, which are likely events \nwithin enterprises. Many commercial tools were developed \nto deal with this problem [3][4]. In this paper, we present a novel architecture for linking web pages following the NaSr style [5] that provides a potential solution for the broken hyperlink problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                }
            ]
        },
        {
            "paperId": "f229837d975a771c098dd315fbbcc0571ff5f124",
            "title": "Deriving Product Architectures from an ADLARS Described Reference Architecture using Leopard",
            "abstract": "In Product Line Architectures, a reference architecture is designed for a family of software systems that share a set of common properties. Variability points are used to capture variations among the different family members. Different product architectures within the family are then derived from the reference architecture based on the set of features chosen for each given product. No methods have been formalized yet on how to derive product architectures from a reference architecture. This process can, in many cases, be very time consuming especially with large-scale systems comprising thousands of variability points. In this case, manual techniques could become tedious and would introduce a high error margin which makes the need for automation and tool support of high importance. \nIn this presentation we demonstrate a technique for deriving product architectures from an ADLARS described reference architecture using Leopard . \nADLARS is an architecture description language that was developed within our research group. ADLARS relates system features to architectural structure: Tasks, Components, and Connectors enabling the generation of product architectures from a reference architecture by specifying the product desired feature set. \nLeopard is one of the tools within the ADLARS Development Studio, a toolset used for developing and maintaining ADLARS architectures. It is an ADLARS integrated development environment (IDE) and compiler. It can parse ADLARS reference architectures and automatically generate product architectures based on the feature set included. \nBoth ADLARS and Leopard are mature projects and have been used to develop different case studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206089",
                    "name": "R. Bashroush"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                },
                {
                    "authorId": "2116699289",
                    "name": "John Brown"
                }
            ]
        },
        {
            "paperId": "ce1111da37b869d547858eaa4d5e774e624d96a3",
            "title": "A Java framework for the static reflection, composition and synthesis of software components",
            "abstract": "The development of distributed embedded real-time telecommunication systems requires close coupling of hardware and software components. Current component models lack support for large-scale reuse at the hardware/software interface. A component model is proposed that separates the component's core functionality from its variable facets. Generative programming techniques are applied to enable component-based engineering whilst maintaining close coupling with the underlying hardware. The described technique is illustrated by generating a simple device driver for a System on a Programmable Chip (SOPC) device from an XML specification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2860627",
                    "name": "I. McRitchie"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "e0abd8b2b7cb2f0a4e8c98e4d5922e59a77b43cc",
            "title": "Mixin programming in Java with reflection and dynamic invocation",
            "abstract": "The concept of mixin programming has emerged as an important implementation technique in the context ol software reuse and software productivity. In mixin based programming classes are defined which support particular roles or capabilities, which may require to be attached to a number of other classes. Mixin classes can be composed dynamically so that composite objects with differing combinations of roles and capabilities may be created without redundancy. Implementing the mixin concept in C++ is straightforward, using the parameterized inheritance capabilities provided by C++ templates. In standard Java it is not possible to use this approach because Java does not currently provide templates. But the Java language has other powerfull facilities, of which one is reflection. In this paper we outline an approach to mixin programming in Java, which is subject to ongoing development and which is based on exploiting Java's reflection capabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144768669",
                    "name": "P. Kilpatrick"
                }
            ]
        },
        {
            "paperId": "06911f563a1da871cb505ec0683bbd4be075a8f9",
            "title": "But who will guard the guardians? [OOP]",
            "abstract": "Design by Contract is widely accepted as a valuable software design methodology for improving software quality. Its incorporation into the Eiffel language has been largely responsible for this. However, the Eiffel language restricts the expressivity of what may be verified in the contract primarily to propositional logic. When the contract is non-trivial, if we wish to retain contract-checking then we must write our own validation routines. How can we be sure that the code that checks the correctness is itself correct? The question was first posed by Juvenal in the first century A.D. 'Sed quis custodiet ipsos custodes?'. The level of genericity now possible in C++ at last offers a possible step forward.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11252068",
                    "name": "David Maley"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "633c15dc96eccb1391f6dc13fe8475337333f4d0",
            "title": "Config: a case study in combining software engineering techniques",
            "abstract": "Config is a software component of the Graphical R-Matrix Atomic Collision Environment. Its development is documented as a case study combining several software engineering techniques: formal specification, generic programming, object-oriented programming, and design by contract. It is specified in VDM$++$; and implemented in C$++$, a language which is becoming more than a curiosity amongst the scientific programming community. C$++$supports object orientation, a powerful architectural paradigm in designing the structure of software systems, and genericity, an orthogonal dimension to the inheritance hierarchies facilitated by object oriented languages. Support in C$++$ for design by contract can be added in library form. The combination of techniques make a substantial contribution to the overall software quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11252068",
                    "name": "David Maley"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "e0b130304e4fe9fe3a9e8b2d99065d85e5ea9717",
            "title": "But Who Will Guard the Guardians",
            "abstract": "Design by Contract is widely accepted as a valuable software design methodology for improving software quality. Its incorporation into the Eiffel language has been largely responsible for this. However, the Eiffel language restricts the expressivity of what may be verified in the contract primarily to propositional logic. When the contract is non-trivial, if we wish to retain contract checking then we must write our own validation routines. How can we be sure that the code that checks the correctness is itself correct? Juvenal first posed the question in the first century A.D. ?Sed quis custodiet ipsos custodes?? The level of genericity now possible in C++ at last offers a possible step forward.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11252068",
                    "name": "David Maley"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "57c738897c16419ad913c0031ad83fb8508ccac0",
            "title": "Efficient implementation of a portable parallel programming model for image processing",
            "abstract": "This paper describes a domain specific programming model for execution on parallel and distributed architectures. The model has initially been targeted at the application area of image processing, though the techniques developed may be more generally applicable to other domains where an algebraic or library-based approach is common. Efficiency is achieved by the concept of a self-optimising class library of primitive image processing operations, which allows programs to be written in a high level, algebraic notation and which is automatically parallelised (using an application-specific data parallel approach). The class library is extended automatically with optimised operations, generated by a transformation system, giving improved execution performance. The parallel implementation of the model described here is based on MPI and has been tested on a C40 processor network, a quad-processor Unix workstation, and a network of PCs running Linux. Timings are included to indicate the impact of the automatic optimisation facility (rather than the effect of parallelisation). Copyright \u00a9 1999 John Wiley & Sons, Ltd.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059686908",
                    "name": "P. Morrow"
                },
                {
                    "authorId": "143964618",
                    "name": "D. Crookes"
                },
                {
                    "authorId": "39003067",
                    "name": "T. Brown"
                },
                {
                    "authorId": "2095639",
                    "name": "G. McAleese"
                },
                {
                    "authorId": "2151247",
                    "name": "D. Roantree"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "ef7a5b4be605eb9e76161bfe3968aa16351e6d9e",
            "title": "Emulating design by contract in C++",
            "abstract": "To date, much of the software written in computational physics has been produced with little regard paid to modern software engineering techniques. The paper documents experiences in beginning to address this shortcoming for Config, a component of the Graphical R-Matrix Atomic Collision Environment (GRACE). The work is based around a formal specification of the Config component. The principal focus of the paper will be on a non-intrusive mechanism for monitoring constraints such as class invariants, preconditions and postconditions for highly structured data types based on the containers and algorithms of the Standard Template Library (STL), a mechanism which can be extended to handle structured object update and display prototyping.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11252068",
                    "name": "David Maley"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "c8dceb9d7279660d8d886179062744e3613f5b40",
            "title": "Specification for testing\u2014the removal of abstraction",
            "abstract": "A good specification of a software system is the best foundation for good testing, and automated testing really requires a formal specification. A formal specification of the operations provided by a system is typically written at an abstract level. The data types of any arguments and result values may not be directly supported by the user interface and there is no indication of the precise means by which an operation is invoked. This abstraction is essential for considering the overall functionality but means that the system is under\u2010specified from the point of view of the tester\u2014particularly if automated testing is envisaged. Some techniques are presented for including concrete user interface details with the abstract description of a formal specification, and these are illustrated with a worked example. The formal notation used is VDM\u2010SL. \u00a9 1998 John Wiley & Sons, Ltd.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                }
            ]
        },
        {
            "paperId": "da497beae62af44e5df9bc6e9d18238bfb30e224",
            "title": "An efficient, portable software platform for parallel image processing",
            "abstract": "A software development environment for image processing is described, which has as one of its aims to achieve portability and efficiency over a range of parallel architectures. The environment includes several tools, one of which is an optimiser which automatically generates very efficient code from a high level user coding. The first time the program is run, it does so rather inefficiently. But after an off-line optimisation phase, the same program can be rerun with significant performance improvements. Timings to date indicate a speed-up of around 5 can be achieved in the computation parts of a typical program.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143964618",
                    "name": "D. Crookes"
                },
                {
                    "authorId": "2110786790",
                    "name": "Judy Brown"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "2059686908",
                    "name": "P. Morrow"
                },
                {
                    "authorId": "2151247",
                    "name": "D. Roantree"
                },
                {
                    "authorId": "2095639",
                    "name": "G. McAleese"
                }
            ]
        },
        {
            "paperId": "520315eb57892d47be814eef907e309ff1123942",
            "title": "Customers do not want frozen specifications",
            "abstract": "A technique is described that has been used to introduce flexibility into the specification of an interactive computer system. For the most part, the specification is written in English, but the portion of interest here uses a graphical notation which has a precise meaning, yet can readily be understood by a non-specialist. This portion of the specification can easily be changed in a controlled manner. The technique was carried right through to the design and implementation, which retained the same flexibility. It is described here by means of a simple illustrative example.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "144414224",
                    "name": "B. Carey"
                }
            ]
        },
        {
            "paperId": "cb661df000bc8992462707f0f42888d0730f3787",
            "title": "Generation Of Software Tests From Specifications",
            "abstract": "Thorough testing is widely acknowledged to be a very expensive part of the software development process. The conventional method of constructing and executing tests for software systems is contrasted with automatic techniques which generate and execute tests derived from the software under test and/or from its formal specification. We present a review of techniques which are currently being used or developed for generating tests, and discuss the approach which we are using.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "2822508",
                    "name": "C. Meudec"
                }
            ]
        }
    ]
}