{
    "authorId": "2046758017",
    "papers": [
        {
            "paperId": "25a84b841f4f8c565b212b130d848f2550292937",
            "title": "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference",
            "abstract": "Selection bias in recommender system arises from the recommendation process of system filtering and the interactive process of user selection. Many previous studies have focused on addressing selection bias to achieve unbiased learning of the prediction model, but ignore the fact that potential outcomes for a given user-item pair may vary with the treatments assigned to other user-item pairs, named neighborhood effect. To fill the gap, this paper formally formulates the neighborhood effect as an interference problem from the perspective of causal inference and introduces a treatment representation to capture the neighborhood effect. On this basis, we propose a novel ideal loss that can be used to deal with selection bias in the presence of neighborhood effect. We further develop two new estimators for estimating the proposed ideal loss. We theoretically establish the connection between the proposed and previous debiasing methods ignoring the neighborhood effect, showing that the proposed methods can achieve unbiased learning when both selection bias and neighborhood effect are present, while the existing methods are biased. Extensive semi-synthetic and real-world experiments are conducted to demonstrate the effectiveness of the proposed methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2051689367",
                    "name": "Haoxuan Li"
                },
                {
                    "authorId": "2051688235",
                    "name": "Chunyuan Zheng"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2287982205",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2228992995",
                    "name": "Zhi Geng"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "28731357886909f5de5ec9fbae42964e2a52e5b6",
            "title": "Understanding and Counteracting Feature-Level Bias in Click-Through Rate Prediction",
            "abstract": "Common click-through rate (CTR) prediction recommender models tend to exhibit feature-level bias, which leads to unfair recommendations among item groups and inaccurate recommendations for users. While existing methods address this issue by adjusting the learning of CTR models, such as through additional optimization objectives, they fail to consider how the bias is caused within these models. In this paper, we discover a generation path of feature-level bias: biased positive sample ratios \u2192 biased linear weights in CTR model \u2192 biased prediction scores \u2192 biased recommendations. Based on this understanding, we propose a minimally invasive yet effective strategy to counteract feature-level bias in CTR models by removing the biased linear weights from well-trained models. Additionally, we present a linear weight adjusting strategy that requires fewer random exposure records than relevant debiasing methods. The superiority of our proposed strategies are validated through extensive experiments on three real-world datasets. The code is available at https://github.com/mitao-cat/feature-level_bias",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2164713563",
                    "name": "Jinqiu Jin"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2280911299",
                    "name": "Fuli Feng"
                }
            ]
        },
        {
            "paperId": "b8d2482005f6cb87d3b4b8a47b5d5cc7dfe67463",
            "title": "Learning Continuous Normalizing Flows For Faster Convergence To Target Distribution via Ascent Regularizations",
            "abstract": "Normalizing flows (NFs) have been shown to be advantageous in modeling complex distributions and improving sampling efficiency for unbiased sampling. In this work, we propose a new class of continuous NFs, ascent continuous normalizing flows (ACNFs), that makes a base distribution converge faster to a target distribution. As solving such a flow is non-trivial and barely possible, we propose a practical implementation to learn flexibly parametric ACNFs via ascent regularization and apply it in two learning cases: maximum likelihood learning for density estimation and minimizing reverse KL divergence for unbiased sampling and variational inference. The learned ACNFs demonstrate faster convergence towards the target distributions, therefore, achieving better density estimations, unbiased sampling and variational approximation at lower computational costs. Furthermore, the flows show to stabilize themselves to mitigate performance deterioration and are less sensitive to the choice of training flow length T .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110790764",
                    "name": "Shuangshuang Chen"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "1778250",
                    "name": "Y. Karayiannidis"
                },
                {
                    "authorId": "7347502",
                    "name": "M\u00e5rten Bj\u00f6rkman"
                }
            ]
        },
        {
            "paperId": "40184ce4016efbe3466d68f613fc71a6aeec7d9c",
            "title": "Addressing Unmeasured Confounder for Recommendation with Sensitivity Analysis",
            "abstract": "Recommender systems should answer the intervention question \"if recommending an item to a user, what would the feedback be\", calling for estimating the causal effect of a recommendation on user feedback. Generally, this requires blocking the effect of confounders that simultaneously affect the recommendation and feedback. To mitigate the confounding bias, a strategy is incorporating propensity into model learning. However, existing methods forgo possible unmeasured confounders (e.g., user financial status), which can result in biased propensities and hurt recommendation performance. This work combats the risk of unmeasured confounders in recommender systems. Towards this end, we propose Robust Deconfounder (RD) that accounts for the effect of unmeasured confounders on propensities, under the mild assumption that the effect is bounded. It estimates the bound with sensitivity analysis, learning a recommender model robust to unmeasured confounders within the bound by adversarial learning. However, pursuing robustness within a bound may restrict model accuracy. To avoid the trade-off between robustness and accuracy, we further propose Benchmarked RD (BRD) that incorporates a pre-trained model into the learning as the benchmark. Theoretical analyses prove the stronger robustness of our methods compared to existing propensity-based deconfounders, and also prove the no-harm property of BRD. Our methods are applicable to any propensity-based estimators, where we select three representative ones: IPS, Doubly Robust, and AutoDebias. We conduct experiments on three real-world datasets to demonstrate the effectiveness of our methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2153093673",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2165313960",
                    "name": "Yitong Wang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2114122035",
                    "name": "Yong Liao"
                },
                {
                    "authorId": "2164724337",
                    "name": "Yongdong Zhang"
                }
            ]
        },
        {
            "paperId": "7f1454913a73d35477c462812de7dae86ecb19a3",
            "title": "Deformable Radar Polygon: A Lightweight and Predictable Occupancy Representation for Short-Range Collision Avoidance",
            "abstract": "Inferring the drivable area in a scene is crucial for ensuring a vehicle avoids obstacles and facilitates safe autonomous driving. In this article, we concentrate on detecting the instantaneous free space surrounding the ego vehicle, targeting short-range automotive applications. We introduce a novel polygon-based occupancy representation, where the interior signifies free space, and the exterior represents undrivable areas for the ego vehicle. The radar polygon consists of vertices selected from point cloud measurements provided by radars, with each vertex incorporating Doppler velocity information from automotive radars. This information indicates the movement of the vertex along the radial direction. This characteristic allows for the prediction of the shape of future radar polygons, leading to its designation as a \u201cdeformable radar polygon.\u201d We propose two approaches to leverage noisy radar measurements for producing accurate and smooth radar polygons. The first approach is a basic radar polygon formation algorithm, which independently selects polygon vertices for each frame, using SNR-based evidence for vertex fitness verification. The second approach is the radar polygon update algorithm, which employs a probabilistic and tracking-based mechanism to update the radar polygon over time, further enhancing accuracy and smoothness. To accommodate the unique radar polygon format, we also designed a collision detection method for short-range applications. Through extensive experiments and analysis on both a self-collected dataset and the open-source RadarScenes dataset, we demonstrate that our radar polygon algorithms achieve significantly higher IoU-gt and IoU-smooth values compared with other occupancy detection baselines, highlighting their accuracy and smoothness.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2149395833",
                    "name": "Xiangyu Gao"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2316399710",
                    "name": "Harshavardhan Reddy Dasari"
                }
            ]
        },
        {
            "paperId": "f5f1b274f202fe967603c66ca07f0b16cc637a1e",
            "title": "Interpolative Distillation for Unifying Biased and Debiased Recommendation",
            "abstract": "Most recommender systems evaluate model performance offline through either: 1) normal biased test on factual interactions; or 2) debiased test with records from the randomized controlled trial. In fact, both tests only reflect part of the whole picture: factual interactions are collected from the recommendation policy, fitting them better implies benefiting the platform with higher click or conversion rate; in contrast, debiased test eliminates system-induced biases and thus is more reflective of user true preference. Nevertheless, we find that existing models exhibit trade-off on the two tests, and there lacks methods that perform well on both tests. In this work, we aim to develop a win-win recommendation method that is strong on both tests. It is non-trivial, since it requires to learn a model that can make accurate prediction in both factual environment (ie normal biased test) and counterfactual environment (ie debiased test). Towards the goal, we perform environment-aware recommendation modeling by considering both environments. In particular, we propose an Interpolative Distillation (InterD) framework, which interpolates the biased and debiased models at user-item pair level by distilling a student model. We conduct experiments on three real-world datasets with both tests. Empirical results justify the rationality and effectiveness of InterD, which stands out on both tests especially demonstrates remarkable gains on less popular items.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2164713563",
                    "name": "Jinqiu Jin"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2114122035",
                    "name": "Yong Liao"
                },
                {
                    "authorId": "2164724337",
                    "name": "Yongdong Zhang"
                }
            ]
        },
        {
            "paperId": "0b8c232cf1feadca218fa9ef74c7e6b3db951564",
            "title": "Causal Incremental Graph Convolution for Recommender System Retraining",
            "abstract": "The real-world recommender system needs to be regularly retrained to keep with the new data. In this work, we consider how to efficiently retrain graph convolution network (GCN)-based recommender models that are state-of-the-art techniques for the collaborative recommendation. To pursue high efficiency, we set the target as using only new data for model updating, meanwhile not sacrificing the recommendation accuracy compared with full model retraining. This is nontrivial to achieve since the interaction data participates in both the graph structure for model construction and the loss function for model learning, whereas the old graph structure is not allowed to use in model updating. Toward the goal, we propose a causal incremental graph convolution (IGC) approach, which consists of two new operators named IGC and colliding effect distillation (CED) to estimate the output of full graph convolution. In particular, we devise simple and effective modules for IGC to ingeniously combine the old representations and the incremental graph and effectively fuse the long- and short-term preference signals. CED aims to avoid the out-of-date issue of inactive nodes that are not in the incremental graph, which connects the new data with inactive nodes through causal inference. In particular, CED estimates the causal effect of new data on the representation of inactive nodes through the control of their collider. Extensive experiments on three real-world datasets demonstrate both accuracy gains and significant speed-ups over the existing retraining mechanism.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2114122035",
                    "name": "Yong Liao"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "1699819",
                    "name": "Yongdong Zhang"
                }
            ]
        },
        {
            "paperId": "33e334a605f8c25f2498a39527f37d2b59387296",
            "title": "Monte Carlo Filtering Objectives: A New Family of Variational Objectives to Learn Generative Model and Neural Adaptive Proposal for Time Series",
            "abstract": "Learning generative models and inferring latent trajectories have shown to be challenging for time series due to the intractable marginal likelihoods of flexible generative models. It can be addressed by surrogate objectives for optimization. We propose Monte Carlo filtering objectives (MCFOs), a family of variational objectives for jointly learning parametric generative models and amortized adaptive importance proposals of time series. MCFOs extend the choices of likelihood estimators beyond Sequential Monte Carlo in state-of-the-art objectives, possess important properties revealing the factors for the tightness of objectives, and allow for less biased and variant gradient estimates. We demonstrate that the proposed MCFOs and gradient estimations lead to efficient and stable model learning, and learned generative models well explain data and importance proposals are more sample efficient on various kinds of time series data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2110790764",
                    "name": "Shuangshuang Chen"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "1778250",
                    "name": "Y. Karayiannidis"
                },
                {
                    "authorId": "7347502",
                    "name": "M\u00e5rten Bj\u00f6rkman"
                }
            ]
        },
        {
            "paperId": "61fcdbbf7b6764525e50afd68783c799eb4190aa",
            "title": "Amortized Variational Inference for Road Friction Estimation",
            "abstract": "Road friction estimation concerns inference of the coefficient between the tire and road surface to facilitate active safety features. Current state-of-the-art methods lack generalization capability to cope with different tire characteristics and models are restricted when using Bayesian inference in estimation while recent supervised learning methods lack uncertainty prediction on estimates. This paper introduces variational inference to approximate intractable posterior of friction estimates and learns an amortized variational inference model from tire measurement data to facilitate probabilistic estimation while sustaining the flexibility of tire models. As a by-product, a probabilistic tire model can be learned jointly with friction estimator model. Experiments on simulated and field test data show that the learned friction estimator provides accurate estimates with robust uncertainty measures in a wide range of tire excitation levels. Meanwhile, the learned tire model reflects well-studied tire characteristics from field test data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110790764",
                    "name": "Shuangshuang Chen"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2120832",
                    "name": "L. S. Muppirisetty"
                },
                {
                    "authorId": "1778250",
                    "name": "Y. Karayiannidis"
                },
                {
                    "authorId": "7347502",
                    "name": "M\u00e5rten Bj\u00f6rkman"
                }
            ]
        }
    ]
}