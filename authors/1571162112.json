{
    "authorId": "1571162112",
    "papers": [
        {
            "paperId": "23cc318882b295fda5233768d59740333b9c4e63",
            "title": "Beyond Two-Tower Matching: Learning Sparse Retrievable Cross-Interactions for Recommendation",
            "abstract": "Two-tower models are a prevalent matching framework for recommendation, which have been widely deployed in industrial applications. The success of two-tower matching attributes to its efficiency in retrieval among a large number of items, since the item tower can be precomputed and used for fast Approximate Nearest Neighbor (ANN) search. However, it suffers two main challenges, including limited feature interaction capability and reduced accuracy in online serving. Existing approaches attempt to design novel late interactions instead of dot products, but they still fail to support complex feature interactions or lose retrieval efficiency. To address these challenges, we propose a new matching paradigm named SparCode, which supports not only sophisticated feature interactions but also efficient retrieval. Specifically, SparCode introduces an all-to-all interaction module to model fine-grained query-item interactions. Besides, we design a discrete code-based sparse inverted index jointly trained with the model to achieve effective and efficient model inference. Extensive experiments have been conducted on open benchmark datasets to demonstrate the superiority of our framework. The results show that SparCode significantly improves the accuracy of candidate item matching while retaining the same level of retrieval efficiency with two-tower models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "2223746444",
                    "name": "Fan Yan"
                },
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2153019995",
                    "name": "Xi Xiao"
                },
                {
                    "authorId": "2223764345",
                    "name": "Haoyi Duan"
                },
                {
                    "authorId": "2187385241",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "2f06c35c0ddaafd8a80690141b7044968a434448",
            "title": "STEM: Unleashing the Power of Embeddings for Multi-task Recommendation",
            "abstract": "Multi-task learning (MTL) has gained significant popularity in recommender systems as it enables simultaneous optimization of multiple objectives. A key challenge in MTL is negative transfer, but existing studies explored negative transfer on all samples, overlooking the inherent complexities within them. We split the samples according to the relative amount of positive feedback among tasks. Surprisingly, negative transfer still occurs in existing MTL methods on samples that receive comparable feedback across tasks. Existing work commonly employs a shared-embedding paradigm, limiting the ability of modeling diverse user preferences on different tasks. In this paper, we introduce a novel Shared and Task-specific EMbeddings (STEM) paradigm that aims to incorporate both shared and task-specific embeddings to effectively capture task-specific user preferences. Under this paradigm, we propose a simple model STEM-Net, which is equipped with an All Forward Task-specific Backward gating network to facilitate the learning of task-specific embeddings and direct knowledge transfer across tasks. Remarkably, STEM-Net demonstrates exceptional performance on comparable samples, achieving positive transfer. Comprehensive evaluation on three public MTL recommendation datasets demonstrates that STEM-Net outperforms state-of-the-art models by a substantial margin. Our code is released at https://github.com/LiangcaiSu/STEM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "12692416",
                    "name": "Junwei Pan"
                },
                {
                    "authorId": "2561964",
                    "name": "Ximei Wang"
                },
                {
                    "authorId": "2153019995",
                    "name": "Xi Xiao"
                },
                {
                    "authorId": "2234352886",
                    "name": "Shijie Quan"
                },
                {
                    "authorId": "2192666804",
                    "name": "Xihua Chen"
                },
                {
                    "authorId": "2203425092",
                    "name": "Jie Jiang"
                }
            ]
        },
        {
            "paperId": "4af58fc20efaa3856df8609921b6a022f8f9d3ac",
            "title": "FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction",
            "abstract": "Click-through rate (CTR) prediction is one of the fundamental tasks in online advertising and recommendation. Multi-layer perceptron (MLP) serves as a core component in many deep CTR prediction models, but it has been widely shown that applying a vanilla MLP network alone is ineffective in learning complex feature interactions. As such, many two-stream models (e.g., Wide&Deep, DeepFM, and DCN) have recently been proposed, aiming to integrate two parallel sub-networks to learn feature interactions from two different views for enhanced CTR prediction. In addition to one MLP stream that learns feature interactions implicitly, most of the existing research focuses on designing another stream to complement the MLP stream with explicitly enhanced feature interactions. Instead, this paper presents a simple two-stream feature interaction model, namely FinalMLP, which employs only MLPs in both streams yet achieves surprisingly strong performance. In contrast to sophisticated network design in each stream, our work enhances CTR modeling through a feature selection module, which produces differentiated feature inputs to two streams, and a group-wise bilinear fusion module, which effectively captures stream-level interactions across two streams. We show that FinalMLP achieves competitive or even better performance against many existing two-stream CTR models on four open benchmark datasets and also brings significant CTR improvements during an online A/B test in our industrial news recommender system. We envision that the simple yet effective FinalMLP model could serve as a new strong baseline for future development of two-stream CTR models. Our source code will be available at MindSpore/models and FuxiCTR/model_zoo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1580228663",
                    "name": "Kelong Mao"
                },
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "24140498",
                    "name": "Guohao Cai"
                },
                {
                    "authorId": "2110427386",
                    "name": "Yuru Li"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                }
            ]
        },
        {
            "paperId": "659f3cdad25f7930d5e3adbc97c72b10015cc35f",
            "title": "Deep Spatio-temporal Adaptive 3D Convolutional Neural Networks for Traffic Flow Prediction",
            "abstract": "Traffic flow prediction is the upstream problem of path planning, intelligent transportation system, and other tasks. Many studies have been carried out on the traffic flow prediction of the spatio-temporal network, but the effects of spatio-temporal flexibility (historical data of the same type of time intervals in the same location will change flexibly) and spatio-temporal correlation (different road conditions have different effects at different times) have not been considered at the same time. We propose the Deep Spatio-temporal Adaptive 3D Convolution Neural Network (ST-A3DNet), which is a new scheme to solve both spatio-temporal correlation and flexibility, and consider spatio-temporal complexity (complex external factors, such as weather and holidays). Different from other traffic forecasting models, ST-A3DNet captures the spatio-temporal relationship at the same time through the Adaptive 3D convolution module, assigns different weights flexibly according to the influence of historical data, and obtains the impact of external factors on the flow through the ex-mask module. Considering the holidays and weather conditions, we train our model for experiments in Xi\u2019an and Chengdu. We evaluate the ST-A3DNet and the results show that we have better results than the other 11 baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153613968",
                    "name": "He Li"
                },
                {
                    "authorId": "2136111274",
                    "name": "Xuejiao Li"
                },
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "2117909309",
                    "name": "D. Jin"
                },
                {
                    "authorId": "123202097",
                    "name": "Jianbin Huang"
                },
                {
                    "authorId": "2115747512",
                    "name": "Deshuang Huang"
                }
            ]
        },
        {
            "paperId": "c0c546b6b8029203f2e65c7348e712efea881625",
            "title": "PEAR: Personalized Re-ranking with Contextualized Transformer for Recommendation",
            "abstract": "The goal of recommender systems is to provide ordered item lists to users that best match their interests. As a critical task in the recommendation pipeline, re-ranking has received increasing attention in recent years. In contrast to conventional ranking models that score each item individually, re-ranking aims to explicitly model the mutual influences among items to further refine the ordering of items given an initial ranking list. In this paper, we present a personalized re-ranking model (dubbed PEAR) based on contextualized transformer. PEAR makes several major improvements over the existing methods. Specifically, PEAR not only captures feature-level and item-level interactions, but also models item contexts from both the initial ranking list and the historical clicked item list. In addition to item-level ranking score prediction, we also augment the training of PEAR with a list-level classification task to assess users\u2019 satisfaction on the whole ranking list. Experimental results on both public and production datasets have shown the superior effectiveness of PEAR compared to the previous re-ranking models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153684869",
                    "name": "Yi Li"
                },
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "24140498",
                    "name": "Guohao Cai"
                },
                {
                    "authorId": "2145908338",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2153019995",
                    "name": "Xi Xiao"
                },
                {
                    "authorId": "1996703",
                    "name": "Xiuqiang He"
                }
            ]
        },
        {
            "paperId": "eb217e5e245305e3cb628f5a2e9b6d0a25d1032d",
            "title": "BARS: Towards Open Benchmarking for Recommender Systems",
            "abstract": "The past two decades have witnessed the rapid development of personalized recommendation techniques. Despite the significant progress made in both research and practice of recommender systems, to date, there is a lack of a widely-recognized benchmarking standard in this field. Many of the existing studies perform model evaluations and comparisons in an ad-hoc manner, for example, by employing their own private data splits or using a different experimental setting. However, such conventions not only increase the difficulty in reproducing existing studies, but also lead to inconsistent experimental results among them. This largely limits the credibility and practical value of research results in this field. To tackle these issues, we present an initiative project aimed for open benchmarking for recommender systems. In contrast to some earlier attempts towards this goal, we take one further step by setting up a standardized benchmarking pipeline for reproducible research, which integrates all the details about datasets, source code, hyper-parameter settings, running logs, and evaluation results. The benchmark is designed with comprehensiveness and sustainability in mind. It spans both matching and ranking tasks, and also allows anyone to easily follow and contribute. We believe that our benchmark could not only reduce the redundant efforts of researchers to re-implement or re-run existing baselines, but also drive more solid and reproducible research on recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "1580228663",
                    "name": "Kelong Mao"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "2165650825",
                    "name": "Ronglin Ma"
                },
                {
                    "authorId": "2108510525",
                    "name": "Jinyang Liu"
                },
                {
                    "authorId": "24140498",
                    "name": "Guohao Cai"
                },
                {
                    "authorId": "1897235",
                    "name": "Zhicheng Dou"
                },
                {
                    "authorId": "2153019995",
                    "name": "Xi Xiao"
                },
                {
                    "authorId": "2163112250",
                    "name": "Rui Zhang"
                }
            ]
        },
        {
            "paperId": "05750bd0145bcca381f7fe86e25622e4ff6fc949",
            "title": "DetectorNet: Transformer-enhanced Spatial Temporal Graph Neural Network for Traffic Prediction",
            "abstract": "Detectors with high coverage have direct and far-reaching benefits for road users in route planning and avoiding traffic congestion, but utilizing these data presents unique challenges including: the dynamic temporal correlation, and the dynamic spatial correlation caused by changes in road conditions. Although the existing work considers the significance of modeling with spatial-temporal correlation, what it has learned is still a static road network structure, which cannot reflect the dynamic changes of roads, and eventually loses much valuable potential information. To address these challenges, we propose DetectorNet enhanced by Transformer. Differs from previous studies, our model contains a Multi-view Temporal Attention module and a Dynamic Attention module, which focus on the long-distance and short-distance temporal correlation, and dynamic spatial correlation by dynamically updating the learned knowledge respectively, so as to make accurate prediction. In addition, the experimental results on two public datasets and the comparison results of four ablation experiments proves that the performance of DetectorNet is better than the eleven advanced baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153613968",
                    "name": "He Li"
                },
                {
                    "authorId": "2145409330",
                    "name": "Shiyu Zhang"
                },
                {
                    "authorId": "2136111274",
                    "name": "Xuejiao Li"
                },
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "2115735860",
                    "name": "Hongjie Huang"
                },
                {
                    "authorId": "2117909309",
                    "name": "D. Jin"
                },
                {
                    "authorId": "2260649932",
                    "name": "Ling-Hao Chen"
                },
                {
                    "authorId": "2135652242",
                    "name": "Jianbin Huang"
                },
                {
                    "authorId": "2115662053",
                    "name": "Jaesoo Yoo"
                }
            ]
        },
        {
            "paperId": "1f9725e97d5075436391ef8ca6c5b6d838c57fce",
            "title": "GraphSANet: A Graph Neural Network and Self Attention Based Approach for Spatial Temporal Prediction in Sensor Network",
            "abstract": "Traffic prediction has become increasingly hot in real-world applications. However, even though massive previous works have been conducted, traffic prediction based on the sensor is still confronted with unique challenges. In a nutshell, it is difficult for us to model both spatial dependency and temporal dependency. In this paper, we propose a novel model called GraphSANet which ensures both spatial and temporal dependencies are considered. With the usage of Temporal Self Attention, the temporal dependency could be captured perfectly and effectively, even if the problem caused by long-distance dependency could be alleviated. In the end, we conducted extensive experiments on two datasets, and vastly better prediction results prove the effectiveness of our model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153613968",
                    "name": "He Li"
                },
                {
                    "authorId": "2145409330",
                    "name": "Shiyu Zhang"
                },
                {
                    "authorId": "1571162112",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "2115735860",
                    "name": "Hongjie Huang"
                },
                {
                    "authorId": "2117909309",
                    "name": "D. Jin"
                },
                {
                    "authorId": "2136111274",
                    "name": "Xuejiao Li"
                }
            ]
        }
    ]
}