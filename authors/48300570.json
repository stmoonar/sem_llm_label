{
    "authorId": "48300570",
    "papers": [
        {
            "paperId": "815de24dff4a4069da08027606d52db52b6fc9a0",
            "title": "HyperGraphDis: Leveraging Hypergraphs for Contextual and Social-Based Disinformation Detection",
            "abstract": "In light of the growing impact of disinformation on social, economic, and political landscapes, accurate and efficient identification methods are increasingly critical. This paper introduces HyperGraphDis, a novel approach for detecting disinformation on Twitter that employs a hypergraph-based representation to capture (i) the intricate social structures arising from retweet cascades, (ii) relational features among users, and (iii) semantic and topical nuances. Evaluated on four Twitter datasets -- focusing on the 2016 U.S. presidential election and the COVID-19 pandemic -- HyperGraphDis outperforms existing methods in both accuracy and computational efficiency, underscoring its effectiveness and scalability for tackling the challenges posed by disinformation dissemination. HyperGraphDis displays exceptional performance on a COVID-19-related dataset, achieving an impressive F1 score (weighted) of approximately 89.5%. This result represents a notable improvement of around 4% compared to the other state-of-the-art methods. Additionally, significant enhancements in computation time are observed for both model training and inference. In terms of model training, completion times are accelerated by a factor ranging from 2.3 to 7.6 compared to the second-best method across the four datasets. Similarly, during inference, computation times are 1.3 to 6.8 times faster than the state-of-the-art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2955951",
                    "name": "Nikos Salamanos"
                },
                {
                    "authorId": "1828780498",
                    "name": "Pantelitsa Leonidou"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                },
                {
                    "authorId": "2698864",
                    "name": "Michael Sirivianos"
                },
                {
                    "authorId": "46246512",
                    "name": "M. Aspri"
                },
                {
                    "authorId": "2065704166",
                    "name": "Marius Paraschiv"
                }
            ]
        },
        {
            "paperId": "8e6299ae49fc7231183928544696bce608500248",
            "title": "Second Data Economy Workshop (DEC)",
            "abstract": "Welcome to the second ACM DATA ECONOMY WORKSHOP (DEC), co-located with ACM SIGCMOD 2023. Data-driven decision making through machine learning algorithms (ML) is transforming the way society and the economy work and is having a profound positive impact on our daily lives. With the exception of very large companies that have both the data and the capabilities to develop powerful ML-driven services, the vast majority of demonstrably possible ML services, from e-health to transportation to predictive maintenance, to name a few, still remain at the level of ideas or prototypes for the simple reason that data, the capabilities to manipulate it, and the business models to bring it to market rarely exist under one roof. Data must somehow meet the ML and business skills that can unleash its full power for society and the economy. This has given rise to an extremely dynamic sector around the Data Economy, involving Data Providers/Controllers, data Intermediaries, often-times in the form of Data Marketplaces or Personal Information Management Systems for end users to control and even monetize their personal data. Despite its enormous potential and observed initial growth, the Data Economy is still in its early stages and therefore faces a still uncertain future and a number of existential challenges. These challenges include a wide range of technical issues that affect multiple disciplines of computer science, including networks and distributed systems, security and privacy, machine learning, and human-computer interaction. The mission of the ACM DEC workshop will be to bring together all CS capabilities needed to support the Data Economy. We would like to thank the entire technical program committee for reviewing and selecting papers for the workshop. We hope you will find the papers interesting and stimulating.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                },
                {
                    "authorId": "153875144",
                    "name": "Martino Trevisan"
                }
            ]
        },
        {
            "paperId": "91625e141950723249002ff9066dc137a656c263",
            "title": "Understanding the Price of Data in Commercial Data Marketplaces",
            "abstract": "A large number of Data Marketplaces (DMs) have appeared in the last few years to help owners monetize their data, and data buyers optimize their marketing campaigns, train their ML models, and facilitate other data-driven decision processes. In this paper, we present a first of its kind measurement study of the growing DM ecosystem, focused on understanding which features of data are actually driving their prices in the market. We show that data products listed in commercial DMs may cost from few to hundreds of thousands of US dollars. We analyze the prices of different categories of data and show that products about telecommunications, manufacturing, automotive, and gaming command the highest prices. We also develop classifiers for comparing data products across different DMs, as well as a regression analysis for revealing features that correlate with data product prices of specific categories, such as update rate or history for financial data, and volume and geographical scope for marketing data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3157364",
                    "name": "Santiago Andr\u00e9s Azcoitia"
                },
                {
                    "authorId": "2331162",
                    "name": "Costas Iordanou"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                }
            ]
        },
        {
            "paperId": "cb30b83b4a340facda7c5cc3289ec57a39680476",
            "title": "FreqyWM: Frequency Watermarking for the New Data Economy",
            "abstract": "We present a novel technique for modulating the appearance frequency of a few tokens within a dataset for encoding an invisible watermark that can be used to protect ownership rights upon data. We develop optimal as well as fast heuristic algorithms for creating and verifying such watermarks. We also demonstrate the robustness of our technique against various attacks and derive analytical bounds for the false positive probability of erroneously \u201cdetecting\u201d a watermark on a dataset that does not carry it. Our technique is applicable to both single dimensional and multidimensional datasets, is independent of token type, allows for a fine control of the introduced distortion, and can be used in a variety of use cases that involve buying and selling data in contemporary data marketplaces.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27365514",
                    "name": "Devris Isler"
                },
                {
                    "authorId": "94258850",
                    "name": "Elisa Cabana"
                },
                {
                    "authorId": "1405705144",
                    "name": "\u00c1lvaro Garc\u00eda-Recuero"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                }
            ]
        },
        {
            "paperId": "d9ffac2d4a17710595fc99411ef67cc1c7db890e",
            "title": "Puppy: A Publicly Verifiable Watermarking Protocol",
            "abstract": "In this paper, we propose Puppy, the first formally defined framework for converting any symmetric watermarking into a publicly verifiable one. Puppy allows anyone to verify a watermark any number of times with the help of an untrusted third party, without requiring owner presence during detection. We formally define and prove security of Puppy using the ideal/real-world simulation paradigm and construct two practical and secure instances: (1) Puppy-TEE that uses Trusted Execution Environments (TEEs), and (2) Puppy-2PC that relies on two-party computation (2PC) based on garbled circuits. We then convert four current symmetric watermarking schemes into publicly verifiable ones and run extensive experiments using Puppy-TEE and Puppy-2PC. Evaluation results show that, while Puppy-TEE incurs some overhead, its total latency is on the order of milliseconds for three out of four watermarking schemes. Although the overhead of Puppy-2PC is higher (on the order of seconds), it is viable for settings that lack a TEE or where strong trust assumptions about a TEE need to be avoided. We further optimize the solution to increase its scalability and resilience to denial of service attacks via memoization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27365514",
                    "name": "Devris Isler"
                },
                {
                    "authorId": "2275027918",
                    "name": "Seoyeon Hwang"
                },
                {
                    "authorId": "49641152",
                    "name": "Yoshimichi Nakatsuka"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                },
                {
                    "authorId": "2274106718",
                    "name": "Gene Tsudik"
                }
            ]
        },
        {
            "paperId": "f095b84479f8c962341996006a48dbd8df79fbf7",
            "title": "Image Watermarking for Machine Learning Datasets",
            "abstract": "Machine learning has received increasing attention for the last decade due to its significant success in classification problems in almost every application domain. For its success, the amount of available data for training plays a crucial role in the creation of a machine-learning model. However, the data-gathering process for machine learning algorithms is a tedious and time-consuming task. In many cases, the developers rely on publicly available datasets, which are not always of high quality. Recently, we are witnessing a data market paradigm where valuable datasets are sold. Thus, once the dataset is created or bought, protecting the dataset against illegal use or (re)sale and establishing intellectual property rights is necessary. In this paper, we investigate the question of deploying well-studied image watermarking techniques to be applied to classification algorithm datasets, without degrading the quality of the dataset. We investigate whether Singular Value Decomposition (SVD)-based techniques from image watermarking could be deployed on machine learning datasets or not. To this end, we chose the watermarking technique described in [8] and applied it to a machine-learning dataset. We provide experimental results on the robustness of the scheme. Our results show that the watermark embedding scheme provides decent imperceptibility and robustness against update, zero-out, and insertion attacks but, it is not successful against deletion attacks. We believe our work can inspire researchers who might want to consider applying well-studied image watermarking techniques to machine learning datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238216447",
                    "name": "Palle Maesen"
                },
                {
                    "authorId": "27365514",
                    "name": "Devris Isler"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                },
                {
                    "authorId": "2631421",
                    "name": "Z. Erkin"
                }
            ]
        },
        {
            "paperId": "f379df3dd163791fd5d45586116e6c721ae81cbb",
            "title": "Graph Database Watermarking Using Pseudo-Nodes",
            "abstract": "Watermarking is used as proof of ownership for various data types such as images, videos, software, machine learning models, and databases. Datasets are crucial for data driven decision making using Machine Learning for tasks like prediction, recommendation, classification, and anomaly detection. Hence, it is not surprising that entire databases are being sold in data marketplaces. Protecting ownership rights upon such databases is, therefore, becoming increasingly important. Watermarking for relational databases has been an active field of research since 2002. However, how to watermark non-relational databases involving complex data types has largely remained understudied. In this paper we revise previously proposed techniques for non-relational database watermarking and introduce an improved technique for graph database watermarking inspired by Zhuang et al. [28]. Our technique employs randomization to generate a watermark in an efficient manner that avoids the computational complex genetic algorithm optimization of Zhuang et al. We evaluated our technique in terms of performance, usability, security, and robustness by implementing it as a proof-of-concept. Our results showed that our technique is efficient, secure and robust against guessing and deletion attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51940468",
                    "name": "Tsvetomir Hristov"
                },
                {
                    "authorId": "27365514",
                    "name": "Devris Isler"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                },
                {
                    "authorId": "2631421",
                    "name": "Z. Erkin"
                }
            ]
        },
        {
            "paperId": "364c2174b6c480736fb6b2359afdc5f355d4cf32",
            "title": "A Survey of Data Marketplaces and Their Business Models",
            "abstract": "Data is becoming an indispensable production factor for the modern economy, matching or exceeding in importance traditional factors such as land, infrastructure, labor and capital. As part of this, a wide range of applications in different sectors require huge amounts of information to feed machine learning models and algorithms responsible for critical roles in production chains and business processes. A variety of data trading entities including, but not limited to data marketplaces, have thus appeared in order to satisfy and match the offer with the demand for data. In this paper, we present the results and conclusions from a comprehensive survey covering 190 commercial data trading entities, the types of data that their trade, as well as their business models and the technologies that they rely upon. We also point to promising open research questions in the areas of data marketplace federation, pricing, and data ownership protection that could benefit the growing ecosystem of data trading entities that we have surveyed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3157364",
                    "name": "Santiago Andr\u00e9s Azcoitia"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                }
            ]
        },
        {
            "paperId": "52c8eec84e361a4fae30effc27fe9d6d244f7b40",
            "title": "A PIMS Development Kit for New Personal Data Platforms",
            "abstract": "The web ecosystem is based on a market where stakeholders collect and sell personal data, but nowadays users expect stronger guarantees of transparency and privacy. With the PIMCity personal information management system (PIMS) development kit, we provide an open-source development kit for building PIMSs to foster the development of open and user-centric data markets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1820934470",
                    "name": "Nikhil Jha"
                },
                {
                    "authorId": "153875144",
                    "name": "Martino Trevisan"
                },
                {
                    "authorId": "2822483",
                    "name": "L. Vassio"
                },
                {
                    "authorId": "1703450",
                    "name": "M. Mellia"
                },
                {
                    "authorId": "1699595",
                    "name": "S. Traverso"
                },
                {
                    "authorId": "1405705144",
                    "name": "\u00c1lvaro Garc\u00eda-Recuero"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                },
                {
                    "authorId": "2174391277",
                    "name": "Amir Mehrjoo"
                },
                {
                    "authorId": "3157364",
                    "name": "Santiago Andr\u00e9s Azcoitia"
                },
                {
                    "authorId": "6140312",
                    "name": "R. C. Rum\u00edn"
                },
                {
                    "authorId": "2226725",
                    "name": "Kleomenis Katevas"
                },
                {
                    "authorId": "2423797",
                    "name": "P. Papadopoulos"
                },
                {
                    "authorId": "1946641",
                    "name": "N. Kourtellis"
                },
                {
                    "authorId": "2174429583",
                    "name": "Roberto Gonzalez"
                },
                {
                    "authorId": "2174392040",
                    "name": "Xavi Olivares"
                },
                {
                    "authorId": "2140681602",
                    "name": "George-Marios Kalatzantonakis-Jullien"
                },
                {
                    "authorId": "1701132",
                    "name": "Munindar P. Singh"
                },
                {
                    "authorId": "3345119",
                    "name": "Pradeep K. Murukannaiah"
                }
            ]
        },
        {
            "paperId": "69d334f52b687f2592c2c0ac8cd96adef2db3354",
            "title": "Computing the relative value of spatio-temporal data in data marketplaces",
            "abstract": "Spatio-temporal information is used for driving a plethora of intelligent transportation, smart-city and crowd-sensing applications. Data is now a valuable production factor and data marketplaces have appeared to help individuals and enterprises bring it to market and the ever-growing demand. Such marketplaces are able to combine data from different sources to meet the requirements of different applications. In this paper we study the problem of estimating the relative value of spatio-temporal datasets combined in marketplaces for predicting transportation demand and travel time in metropolitan areas. Using large datasets of taxi rides from Chicago, Porto and New York we show that simplistic but popular approaches for estimating the relative value of data, such as splitting it equally among the data sources, more complex ones based on volume or the \"leave-one-out\" heuristic, are inaccurate. Instead, more complex notions of value from economics and game-theory, such as the Shapley value, need to be employed if one wishes to capture the complex effects of mixing different datasets on the accuracy of forecasting algorithms. This does not seem to be a coincidental observation related to a particular use case but rather a general trend across different use cases with different objective functions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3157364",
                    "name": "Santiago Andr\u00e9s Azcoitia"
                },
                {
                    "authorId": "2065704166",
                    "name": "Marius Paraschiv"
                },
                {
                    "authorId": "48300570",
                    "name": "Nikolaos Laoutaris"
                }
            ]
        }
    ]
}