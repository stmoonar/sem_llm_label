{
    "authorId": "2113279258",
    "papers": [
        {
            "paperId": "0f6297a1bd9311bacbe57fdde945d0e1d46f59be",
            "title": "DSGPT: Domain-Specific Generative Pre-Training of Transformers for Text Generation in E-commerce Title and Review Summarization",
            "abstract": "We propose a novel domain-specific generative pre-training (DSGPT) method for text generation and apply it to the product title and review summarization problems on E-commerce mobile display. First, we adopt a decoder-only transformer architecture, which fits well for fine-tuning tasks by combining input and output all together. Second, we demonstrate utilizing only small amount of pre-training data in related domains is powerful. Pre-training a language model from a general corpus such as Wikipedia or the Common Crawl requires tremendous time and resource commitment, and can be wasteful if the downstream tasks are limited in variety. Our DSGPT is pre-trained on a limited dataset, the Chinese short text summarization dataset (LCSTS). Third, our model does not require product-related human-labeled data. For title summarization task, the state of art explicitly uses additional background knowledge in training and predicting stages. In contrast, our model implicitly captures this knowledge and achieves significant improvement over other methods, after fine-tuning on the public Taobao.com dataset. For review summarization task, we utilize JD.com in-house dataset, and observe similar improvement over standard machine translation methods which lack the flexibility of fine-tuning. Our proposed work can be simply extended to other domains for a wide range of text generation tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118889880",
                    "name": "Xueying Zhang"
                },
                {
                    "authorId": "2131218",
                    "name": "Yunjiang Jiang"
                },
                {
                    "authorId": "2053234459",
                    "name": "Yue Shang"
                },
                {
                    "authorId": "2113279258",
                    "name": "Zhaomeng Cheng"
                },
                {
                    "authorId": "2145179631",
                    "name": "Chi Zhang"
                },
                {
                    "authorId": "49537566",
                    "name": "Xiaochuan Fan"
                },
                {
                    "authorId": "2122427161",
                    "name": "Yun Xiao"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "6c88f39d65d56fd362cc7ea19be9b320ef678796",
            "title": "Heterogeneous Network Embedding for Deep Semantic Relevance Match in E-commerce Search",
            "abstract": "Result relevance prediction is an essential task of e-commerce search engines to boost the utility of search engines and ensure smooth user experience. The last few years eyewitnessed a flurry of research on the use of Transformer-style models and deep text-match models to improve relevance. However, these two types of models ignored the inherent bipartite network structures that are ubiquitous in e-commerce search logs, making these models ineffective. We propose in this paper a novel Second-order Relevance, which is fundamentally different from the previous First-order Relevance, to improve result relevance prediction. We design, for the first time, an end-to-end First-and-Second-order Relevance prediction model for e-commerce item relevance. The model is augmented by the neighborhood structures of bipartite networks that are built using the information of user behavioral feedback, including clicks and purchases. To ensure that edges accurately encode relevance information, we introduce external knowledge generated from BERT to refine the network of user behaviors. This allows the new model to integrate information from neighboring items and queries, which are highly relevant to the focus query-item pair under consideration. Results of offline experiments showed that the new model significantly improved the prediction accuracy in terms of human relevance judgment. An ablation study showed that the First-and-Second-order model gained a 4.3% average gain over the First-order model. Results of an online A/B test revealed that the new model derived more commercial benefits compared to the base model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39789747",
                    "name": "Ziyang Liu"
                },
                {
                    "authorId": "2113279258",
                    "name": "Zhaomeng Cheng"
                },
                {
                    "authorId": "2131218",
                    "name": "Yunjiang Jiang"
                },
                {
                    "authorId": "2053234459",
                    "name": "Yue Shang"
                },
                {
                    "authorId": "2055448780",
                    "name": "Wei Xiong"
                },
                {
                    "authorId": "1752741172",
                    "name": "Sulong Xu"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2068347799",
                    "name": "Di Jin"
                }
            ]
        },
        {
            "paperId": "703bd0a54ada0c2b2c30933227a1524a89ce2c49",
            "title": "BiTe-GCN: A New GCN Architecture via Bidirectional Convolution of Topology and Features on Text-Rich Networks",
            "abstract": "Graph convolutional networks (GCNs), aiming to obtain node embeddings by integrating high-order neighborhood information through stacked graph convolution layers, have demonstrated great power in many network analysis tasks such as node classification and link prediction. However, a fundamental weakness of GCNs, that is, topological limitations, including over-smoothing and local homophily of topology, limits their ability to represent networks. Existing studies for solving these topological limitations typically focus only on the convolution of features on network topology, which inevitably relies heavily on network structure. Moreover, most networks are text-rich, so it is important to integrate not only document-level information, but also the local text information which is particularly significant while often ignored by the existing methods. To solve these limitations, we propose BiTe-GCN, a novel GCN architecture modeling via bidirectional convolution of topology and features on text-rich networks. Specifically, we first transform the original text-rich network into an augmented bi-typed heterogeneous network, capturing both the global document-level information and the local text-sequence information from texts. We then introduce discriminative convolution mechanisms, which performs convolution on this augmented bi-typed network, realizing the convolutions of topology and features altogether in the same system, and learning different contributions of these two parts (i.e., network part and text part), automatically for the given learning objectives. Extensive experiments on text-rich networks demonstrate that our new architecture outperforms the state-of-the-arts by a breakout improvement. Moreover, this architecture can also be applied to several e-commerce search scenes such as JD searching, and experiments on JD dataset show the superiority of the proposed architecture over the related methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1864018750",
                    "name": "Di Jin"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "12073135",
                    "name": "Zhizhi Yu"
                },
                {
                    "authorId": "39789747",
                    "name": "Ziyang Liu"
                },
                {
                    "authorId": "2153525789",
                    "name": "Heling Zhang"
                },
                {
                    "authorId": "2113279258",
                    "name": "Zhaomeng Cheng"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        }
    ]
}