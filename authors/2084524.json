{
    "authorId": "2084524",
    "papers": [
        {
            "paperId": "037b4345769b0608819cddc9bb2cff3a6daf8699",
            "title": "On the Evaluation of Large Language Models in Unit Test Generation",
            "abstract": "Unit testing is an essential activity in software development for verifying the correctness of software components. However, manually writing unit tests is challenging and time-consuming. The emergence of Large Language Models (LLMs) offers a new direction for automating unit test generation. Existing research primarily focuses on closed-source LLMs (e.g., ChatGPT and CodeX) with fixed prompting strategies, leaving the capabilities of advanced open-source LLMs with various prompting settings unexplored. Particularly, open-source LLMs offer advantages in data privacy protection and have demonstrated superior performance in some tasks. Moreover, effective prompting is crucial for maximizing LLMs' capabilities. In this paper, we conduct the first empirical study to fill this gap, based on 17 Java projects, five widely-used open-source LLMs with different structures and parameter sizes, and comprehensive evaluation metrics. Our findings highlight the significant influence of various prompt factors, show the performance of open-source LLMs compared to the commercial GPT-4 and the traditional Evosuite, and identify limitations in LLM-based unit test generation. We then derive a series of implications from our study to guide future research and practical use of LLM-based unit test generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2308300663",
                    "name": "Lin Yang"
                },
                {
                    "authorId": "2223406543",
                    "name": "Chen Yang"
                },
                {
                    "authorId": "2233731746",
                    "name": "Shutao Gao"
                },
                {
                    "authorId": "2308422191",
                    "name": "Weijing Wang"
                },
                {
                    "authorId": "2308500996",
                    "name": "Bo Wang"
                },
                {
                    "authorId": "2308982081",
                    "name": "Qihao Zhu"
                },
                {
                    "authorId": "2308276707",
                    "name": "Xiao Chu"
                },
                {
                    "authorId": "2296059777",
                    "name": "Jianyi Zhou"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2253829508",
                    "name": "Qianxiang Wang"
                },
                {
                    "authorId": "2295677048",
                    "name": "Junjie Chen"
                }
            ]
        },
        {
            "paperId": "352f843fa870125922d1c6978169f4c68c712a0c",
            "title": "SWE-bench-java: A GitHub Issue Resolving Benchmark for Java",
            "abstract": "GitHub issue resolving is a critical task in software engineering, recently gaining significant attention in both industry and academia. Within this task, SWE-bench has been released to evaluate issue resolving capabilities of large language models (LLMs), but has so far only focused on Python version. However, supporting more programming languages is also important, as there is a strong demand in industry. As a first step toward multilingual support, we have developed a Java version of SWE-bench, called SWE-bench-java. We have publicly released the dataset, along with the corresponding Docker-based evaluation environment and leaderboard, which will be continuously maintained and updated in the coming months. To verify the reliability of SWE-bench-java, we implement a classic method SWE-agent and test several powerful LLMs on it. As is well known, developing a high-quality multi-lingual benchmark is time-consuming and labor-intensive, so we welcome contributions through pull requests or collaboration to accelerate its iteration and refinement, paving the way for fully automated programming.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134434187",
                    "name": "Daoguang Zan"
                },
                {
                    "authorId": "2316953296",
                    "name": "Zhirong Huang"
                },
                {
                    "authorId": "2151121986",
                    "name": "Ailun Yu"
                },
                {
                    "authorId": "2316780443",
                    "name": "Shaoxin Lin"
                },
                {
                    "authorId": "2265936025",
                    "name": "Yifan Shi"
                },
                {
                    "authorId": "2316742211",
                    "name": "Wei Liu"
                },
                {
                    "authorId": "2304895824",
                    "name": "Dong Chen"
                },
                {
                    "authorId": "2316961288",
                    "name": "Zongshuai Qi"
                },
                {
                    "authorId": "2296050795",
                    "name": "Hao Yu"
                },
                {
                    "authorId": "2316959029",
                    "name": "Lei Yu"
                },
                {
                    "authorId": "2038503437",
                    "name": "Dezhi Ran"
                },
                {
                    "authorId": "2304477776",
                    "name": "Muhan Zeng"
                },
                {
                    "authorId": "2293292326",
                    "name": "Bo Shen"
                },
                {
                    "authorId": "2304471393",
                    "name": "Pan Bian"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "36923691",
                    "name": "Bei Guan"
                },
                {
                    "authorId": "2317043738",
                    "name": "Pengjie Huang"
                },
                {
                    "authorId": "2304599644",
                    "name": "Tao Xie"
                },
                {
                    "authorId": "2275749758",
                    "name": "Yongji Wang"
                },
                {
                    "authorId": "2253829508",
                    "name": "Qianxiang Wang"
                }
            ]
        },
        {
            "paperId": "81a953de95f4932b6342fa55b2040926b2590e9c",
            "title": "CodeR: Issue Resolving with Multi-Agent and Task Graphs",
            "abstract": "GitHub issue resolving recently has attracted significant attention from academia and industry. SWE-bench is proposed to measure the performance in resolving issues. In this paper, we propose CodeR, which adopts a multi-agent framework and pre-defined task graphs to Repair&Resolve reported bugs and add new features within code Repository. On SWE-bench lite, CodeR is able to solve 28.33% of issues, when submitting only once for each issue. We examine the performance impact of each design of CodeR and offer insights to advance this research direction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2304895824",
                    "name": "Dong Chen"
                },
                {
                    "authorId": "2316780443",
                    "name": "Shaoxin Lin"
                },
                {
                    "authorId": "2304477776",
                    "name": "Muhan Zeng"
                },
                {
                    "authorId": "2134434187",
                    "name": "Daoguang Zan"
                },
                {
                    "authorId": "2304515651",
                    "name": "Jian-Gang Wang"
                },
                {
                    "authorId": "2304470645",
                    "name": "Anton Cheshkov"
                },
                {
                    "authorId": "2267508408",
                    "name": "Jun Sun"
                },
                {
                    "authorId": "2296050795",
                    "name": "Hao Yu"
                },
                {
                    "authorId": "2059261893",
                    "name": "Guoliang Dong"
                },
                {
                    "authorId": "2304471915",
                    "name": "Artem Aliev"
                },
                {
                    "authorId": "2307237447",
                    "name": "Jie Wang"
                },
                {
                    "authorId": "2304584825",
                    "name": "Xiao Cheng"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2304523047",
                    "name": "Yuchi Ma"
                },
                {
                    "authorId": "2304471393",
                    "name": "Pan Bian"
                },
                {
                    "authorId": "2300201756",
                    "name": "Tao Xie"
                },
                {
                    "authorId": "2253829508",
                    "name": "Qianxiang Wang"
                }
            ]
        },
        {
            "paperId": "e7deca86d3fbd922c4939e81221b5c1ba07f0369",
            "title": "Efficiently Trimming the Fat: Streamlining Software Dependencies with Java Reflection and Dependency Analysis",
            "abstract": "Numerous third-party libraries introduced into client projects are not actually required, resulting in modern software being gradually bloated. Software developers may spend much unnecessary effort to manage the bloated dependencies: keeping the library versions up-to-date, making sure that heterogeneous licenses are compatible, and resolving dependency conflict or vulnerability issues. However, the prior debloating techniques can easily produce false alarms of bloated dependencies since they are less effective in analyzing Java reflections. Besides, the solutions given by the existing approaches for removing bloated dependencies may induce new issues that are not conducive to dependency management. To address the above limitations, in this paper, we developed a technique, Slimming, to remove bloated dependencies from software projects reliably. Slimming statically analyzes the Java reflections that are commonly leveraged by popular frameworks (e.g., Spring Boot) and resolves the reflective targets via parsing configuration files (*. xml, *. ym1 and *. properties). By modeling string manipulations, Slimming fully resolves the string arguments of our concerned reflection APIs to identify all the required dependencies. More importantly, it helps developers analyze the debloating solutions by weighing the benefits against the costs of dependency management. Our evaluation results show that the static reflection analysis capability of Slimming outperforms all the other existing techniques with 97.0% of Precision and 98.8% of Recall. Compared with the prior debloating techniques, Slimming can reliably remove the bloated dependencies with a 100% test passing ratio and improve the rationality of debloating solutions. In our large-scale study in the Maven ecosystem, Slimming reported 484 bloated dependencies to 66 open-source projects. 38 reports (57.6%) have been confirmed by developers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296535182",
                    "name": "Xiaohu Song"
                },
                {
                    "authorId": "2296637061",
                    "name": "Ying Wang"
                },
                {
                    "authorId": "2296672383",
                    "name": "Xiao Cheng"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2253829508",
                    "name": "Qianxiang Wang"
                },
                {
                    "authorId": "2296575909",
                    "name": "Zhiliang Zhu"
                }
            ]
        },
        {
            "paperId": "1624aafbef9e78246fb2cd21146c8007b59ab097",
            "title": "Eunomia: Enabling User-Specified Fine-Grained Search in Symbolically Executing WebAssembly Binaries",
            "abstract": "Although existing techniques have proposed automated approaches to alleviate the path explosion problem of symbolic execution, users still need to optimize symbolic execution by applying various searching strategies carefully. As existing approaches mainly support only coarse-grained global searching strategies, they cannot efficiently traverse through complex code structures. In this paper, we propose Eunomia, a symbolic execution technique that supports fine-grained search with local domain knowledge. Eunomia uses Aes, a DSL that lets users specify local searching strategies for different parts of the program. Eunomia also isolates the context of variables for different local searching strategies, avoiding conflicts. We implement Eunomia for WebAssembly, which can analyze applications written in various languages. Eunomia is the first symbolic execution engine that supports the full features of WebAssembly. We evaluate Eunomia with a microbenchmark suite and six real-world applications. Our evaluation shows that Eunomia improves bug detection by up to three orders of magnitude. We also conduct a user study that shows the benefits of using Aes. Moreover, Eunomia verifies six known bugs and detects two new zero-day bugs in Collections-C.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066081427",
                    "name": "Ningyu He"
                },
                {
                    "authorId": "2152619389",
                    "name": "Zhehao Zhao"
                },
                {
                    "authorId": "2214543553",
                    "name": "Jikai Wang"
                },
                {
                    "authorId": "2112240517",
                    "name": "Yubin Hu"
                },
                {
                    "authorId": "2659927",
                    "name": "Shengjian Guo"
                },
                {
                    "authorId": "2109570965",
                    "name": "Haoyu Wang"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2151495692",
                    "name": "Ding Li"
                },
                {
                    "authorId": "2143733795",
                    "name": "Xiangqun Chen"
                },
                {
                    "authorId": "145508275",
                    "name": "Yao Guo"
                }
            ]
        },
        {
            "paperId": "44b3b9752e0644ce43b2af3557b39aa6ac3f02fe",
            "title": "Identifying Vulnerable Third-Party Java Libraries from Textual Descriptions of Vulnerabilities and Libraries",
            "abstract": "To address security vulnerabilities arising from third-party libraries, security researchers maintain databases monitoring and curating vulnerability reports. Application developers can identify vulnerable libraries by directly querying the databases with their used libraries. However, the querying results of vulnerable libraries are not reliable due to the incompleteness of vulnerability reports. Thus, current approaches model the task of identifying vulnerable libraries as a named-entity-recognition (NER) task or an extreme multi-label learning (XML) task. These approaches suffer from highly inaccurate results in identifying vulnerable libraries with complex and similar names, e.g., Java libraries. To address these limitations, in this paper, we propose VulLibMiner, the first to identify vulnerable libraries from textual descriptions of both vulnerabilities and libraries, together with VulLib, a Java vulnerability dataset with their affected libraries. VulLibMiner consists of a TF-IDF matcher to efficiently screen out a small set of candidate libraries and a BERT-FNN model to identify vulnerable libraries from these candidates effectively. We evaluate VulLibMiner using four state-of-the-art/practice approaches of identifying vulnerable libraries on both their dataset named VeraJava and our VulLib dataset. Our evaluation results show that VulLibMiner can effectively identify vulnerable libraries with an average F1 score of 0.657 while the state-of-the-art/practice approaches achieve only 0.521.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117180359",
                    "name": "Tianyu Chen"
                },
                {
                    "authorId": "2148946070",
                    "name": "Lin Li"
                },
                {
                    "authorId": "2223644462",
                    "name": "Bingjie Shan"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2223703882",
                    "name": "Ding Li"
                },
                {
                    "authorId": "7417844",
                    "name": "Qianxiang Wang"
                },
                {
                    "authorId": "2144071699",
                    "name": "Tao Xie"
                }
            ]
        },
        {
            "paperId": "51cab7285b10f447a2c91ef68a3394ab73fdcced",
            "title": "VulLibGen: Generating Names of Vulnerability-Affected Packages via a Large Language Model",
            "abstract": "Security practitioners maintain vulnerability reports (e.g., GitHub Advisory) to help developers mitigate security risks. An important task for these databases is automatically extracting structured information mentioned in the report, e.g., the affected software packages, to accelerate the defense of the vulnerability ecosystem. However, it is challenging for existing work on affected package identification to achieve a high accuracy. One reason is that all existing work focuses on relatively smaller models, thus they cannot harness the knowledge and semantic capabilities of large language models. To address this limitation, we propose VulLibGen, the first method to use LLM for affected package identification. In contrast to existing work, VulLibGen proposes the novel idea to directly generate the affected package. To improve the accuracy, VulLibGen employs supervised fine-tuning (SFT), retrieval augmented generation (RAG) and a local search algorithm. The local search algorithm is a novel postprocessing algorithm we introduce for reducing the hallucination of the generated packages. Our evaluation results show that VulLibGen has an average accuracy of 0.806 for identifying vulnerable packages in the four most popular ecosystems in GitHub Advisory (Java, JS, Python, Go) while the best average accuracy in previous work is 0.721. Additionally, VulLibGen has high value to security practice: we submitted 60pairs to GitHub Advisory (covers four ecosystems). 34 of them have been accepted and merged and 20 are pending approval. Our code and dataset can be found in the attachments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2255884021",
                    "name": "Tianyu Chen"
                },
                {
                    "authorId": "2148946070",
                    "name": "Lin Li"
                },
                {
                    "authorId": "2316634327",
                    "name": "ZhuLiuchuan ZhuLiuchuan"
                },
                {
                    "authorId": "2118207557",
                    "name": "Zongyang Li"
                },
                {
                    "authorId": "2301497687",
                    "name": "Xueqing Liu"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2253829508",
                    "name": "Qianxiang Wang"
                },
                {
                    "authorId": "2144071699",
                    "name": "Tao Xie"
                }
            ]
        },
        {
            "paperId": "6ab8aca8f631f42760a86cc614dfd7208b3fe58e",
            "title": "Learning-based Widget Matching for Migrating GUI Test Cases",
            "abstract": "GUI test case migration is to migrate GUI test cases from a source app to a target app. The key of test case migration is widget matching. Recently, researchers have proposed various approaches by formulating widget matching as a matching task. However, since these matching approaches depend on static word embeddings without using contextual information to represent widgets and manually formulated matching functions, there are main limitations of these matching approaches when handling complex matching relations in apps. To address the limitations, we propose the first learning-based widget matching approach named TEMdroid ( TEst Migration) for test case migration. Unlike the existing approaches, TEMdroid uses BERT to capture contextual information and learns a matching model to match widgets. Additionally, to balance the significant imbalance between positive and negative samples in apps, we design a two-stage training strategy where we first train a hard-negative sample miner to mine hard-negative samples, and further train a matching model using positive samples and mined hard-negative samples. Our evaluation on 34 apps shows that TEM-droid is effective in event matching (i.e., widget matching and target event synthesis) and test case migration. For event matching, TEM-droid's Top1 accuracy is 76%, improving over 17% compared to baselines. For test case migration, TEMdroid's F1 score is 89%, also 7% improvement compared to the baseline approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110752255",
                    "name": "Hao Yu"
                },
                {
                    "authorId": "2089966950",
                    "name": "Bo Shen"
                },
                {
                    "authorId": "2038503437",
                    "name": "Dezhi Ran"
                },
                {
                    "authorId": null,
                    "name": "Jiaxin Zhang"
                },
                {
                    "authorId": "2145906426",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2304523047",
                    "name": "Yuchi Ma"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2172444921",
                    "name": "Ying Li"
                },
                {
                    "authorId": "2057038049",
                    "name": "Tao Xie"
                },
                {
                    "authorId": "7417844",
                    "name": "Qianxiang Wang"
                }
            ]
        },
        {
            "paperId": "d07a15aba636f04b2d021779eee40f21d2fc295b",
            "title": "VulLibGen: Identifying Vulnerable Third-Party Libraries via Generative Pre-Trained Model",
            "abstract": "To avoid potential risks posed by vulnerabilities in third-party libraries, security researchers maintain vulnerability databases (e.g., NVD) containing vulnerability reports, each of which records the description of a vulnerability and the name list of libraries affected by the vulnerability (a.k.a. vulnerable libraries). However, recent studies on about 200,000 vulnerability reports in NVD show that 53.3% of these reports do not include the name list of vulnerable libraries, and 59.82% of the included name lists of vulnerable libraries are incomplete or incorrect. To address the preceding issue, in this paper, we propose the first generative approach named VulLibGen to generate the name list of vulnerable libraries (out of all the existing libraries) for the given vulnerability by utilizing recent enormous advances in Large Language Models (LLMs), in order to achieve high accuracy. VulLibGen takes only the description of a vulnerability as input and achieves high identification accuracy based on LLMs\u2019 prior knowledge of all the existing libraries. VulLibGen also includes the input augmentation technique to help identify zero-shot vulnerable libraries (those not occurring during training) and the post-processing technique to help address VulLibGen\u2019s hallucinations. We evaluate VulLib-Gen using three state-of-the-art/practice approaches (LightXML, Chronos, and VulLibMiner) that identify vulnerable libraries on an open-source dataset (VulLib). Our evaluation results show that VulLibGen can accurately identify vulnerable libraries with an average F1 score of 0.626 while the state-of-the-art/practice approaches achieve only 0.561. The post-processing technique helps VulLib-Gen achieve an average improvement of F1@1 by 9.3%. The input",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117180359",
                    "name": "Tianyu Chen"
                },
                {
                    "authorId": "2148946070",
                    "name": "Lin Li"
                },
                {
                    "authorId": "2230201293",
                    "name": "Liuchuan Zhu"
                },
                {
                    "authorId": "2118207557",
                    "name": "Zongyang Li"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2223703882",
                    "name": "Ding Li"
                },
                {
                    "authorId": "7417844",
                    "name": "Qianxiang Wang"
                },
                {
                    "authorId": "2144071699",
                    "name": "Tao Xie"
                }
            ]
        },
        {
            "paperId": "df152b79d90c1672c2ec652d01abe291732c623d",
            "title": "CompVPD: Iteratively Identifying Vulnerability Patches Based on Human Validation Results with a Precise Context",
            "abstract": "Applying security patches in open source software timely is critical for ensuring the security of downstream applications. However, it is challenging to apply these patches promptly because notifications of patches are often incomplete and delayed. To address this issue, existing approaches employ deep-learning (DL) models to identify additional vulnerability patches by determining whether a code commit addresses a vulnerability. Nonetheless, these approaches suffer from low accuracy due to the imprecise context provided for the patches. To provide precise context for patches, we propose a multi-granularity slicing algorithm and an adaptive-expanding algorithm to accurately identify code related to the patches. Additionally, the precise context enables to design an iterative identification framework, CompVPD, which utilizes the human validation results, and substantially improve the effectiveness. We empirically compare CompVPD with four state-of-the-art/practice (SOTA) approaches in identifying vulnerability patches. The results demonstrate that CompVPD improves the F1 score by 20% compared to the best scores of the SOTA approaches. Additionally, CompVPD contributes to security practice by helping identify 20 vulnerability patches and 18 fixes for high-risk bugs from 2,500 recent code commits in five highly popular open-source projects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2255884021",
                    "name": "Tianyu Chen"
                },
                {
                    "authorId": "2148946070",
                    "name": "Lin Li"
                },
                {
                    "authorId": "2253668940",
                    "name": "Taotao Qian"
                },
                {
                    "authorId": "2213942973",
                    "name": "Jingyi Liu"
                },
                {
                    "authorId": "2306149225",
                    "name": "Wei Yang"
                },
                {
                    "authorId": "2223703882",
                    "name": "Ding Li"
                },
                {
                    "authorId": "2084524",
                    "name": "Guangtai Liang"
                },
                {
                    "authorId": "2253829508",
                    "name": "Qianxiang Wang"
                },
                {
                    "authorId": "2144071699",
                    "name": "Tao Xie"
                }
            ]
        }
    ]
}