{
    "authorId": "2108182762",
    "papers": [
        {
            "paperId": "6259e35a12c98483a2d4dae3f1ffe1b60053925d",
            "title": "Measuring Your ASTE Models in The Wild: A Diversified Multi-domain Dataset For Aspect Sentiment Triplet Extraction",
            "abstract": "Aspect Sentiment Triplet Extraction (ASTE) is widely used in various applications. However, existing ASTE datasets are limited in their ability to represent real-world scenarios, hindering the advancement of research in this area. In this paper, we introduce a new dataset, named DMASTE, which is manually annotated to better fit real-world scenarios by providing more diverse and realistic reviews for the task. The dataset includes various lengths, diverse expressions, more aspect types, and more domains than existing datasets. We conduct extensive experiments on DMASTE in multiple settings to evaluate previous ASTE approaches. Empirical results demonstrate that DMASTE is a more challenging ASTE dataset. Further analyses of in-domain and cross-domain settings provide promising directions for future research. Our code and dataset are available at https://github.com/NJUNLP/DMASTE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145878896",
                    "name": "Ting Xu"
                },
                {
                    "authorId": "2156109735",
                    "name": "Huiyun Yang"
                },
                {
                    "authorId": "47040114",
                    "name": "Zhanghua Wu"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "2152335026",
                    "name": "Fei Zhao"
                },
                {
                    "authorId": "3035069",
                    "name": "Xinyu Dai"
                }
            ]
        },
        {
            "paperId": "097688d43af6ed3ab74bd198b30a543b15f06f96",
            "title": "Diversified Query Generation Guided by Knowledge Graph",
            "abstract": "Relevant articles recommendation plays an important role in online news platforms. Directly displaying recalled articles by a search engine lacks a deep understanding of the article contents. Generating clickable queries, on the other hand, summarizes an article in various aspects, which can be henceforth utilized to better connect relevant articles. Most existing approaches for generating article queries, however, do not consider the diversity of queries or whether they are appealing enough, which are essential for boosting user experience and platform drainage. To this end, we propose a Knowledge-Enhanced Diversified QuerY Generator (KEDY), which leverages an external knowledge graph (KG) as guidance. We diversify the query generation with the information of semantic neighbors of the entities in articles. We further constrain the diversification process with entity popularity knowledge to build appealing queries that users may be more interested in. The information within KG is propagated towards more popular entities with popularity-guided graph attention. We collect a news-query dataset from the search logs of a real-world search engine. Extensive experiments demonstrate our proposed KEDY can generate more diversified and insightful related queries than several strong baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111114976",
                    "name": "Xi Shen"
                },
                {
                    "authorId": "5040052",
                    "name": "Jiangjie Chen"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "2154454736",
                    "name": "Chun Zeng"
                },
                {
                    "authorId": "2116642640",
                    "name": "Yanghua Xiao"
                }
            ]
        },
        {
            "paperId": "30a0717872ed6951db28c11ae270099accfc29d0",
            "title": "Contrastive Aligned Joint Learning for Multilingual Summarization",
            "abstract": "Multilingual text summarization requires the ability to understand documents in multiple languages and generate summaries in the corresponding language, which poses more challenges on current summarization systems. However, this problem has been rarely studied due to the lack of large-scale supervised summarization data in multiple languages. In this paper, we \ufb01rst provide a large-scale multilingual summarization corpus MLGSum consisting of 1.1 million articles and summaries in 12 different languages. Based on it, we develop a uni\ufb01ed summarization model to understand the document and generate summaries in different languages. We use the contrastive learning strategy to train our multilingual summarization system (CALMS), which consists of two training objectives, contrastive sentence ranking (CSR) and sentence aligned substitution (SAS). The two training objectives are designed to share salient information extractive ability and align sentence-level representation across different languages. Experimental results indicate that CALMS achieves signi\ufb01cant improvement over mono-lingual models in all languages. We further transfer CALMS to other languages and \ufb01nd that it will also bene\ufb01t similar languages. Our code and dataset are available at https://github.com/brxx122/CALMS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49371126",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": null,
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "1767521",
                    "name": "Xipeng Qiu"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "63bcd68cde70af774eb24a13c12f9133e7aacc48",
            "title": "MTG: A Benchmarking Suite for Multilingual Text Generation",
            "abstract": "We introduce MTG, a new benchmark suite for training and evaluating multilingual text generation. It is the \ufb01rst and largest text generation benchmark with 120k human-annotated multi-way parallel data for three tasks (story generation, question generation, and title generation) across four languages (English, German, French, and Spanish). Based on it, we set various evaluation scenarios and make a deep analysis of several popular multilingual generation models from different aspects. Our benchmark suite will encourage the multilin-gualism for text generation community with more human-annotated parallel data and more diverse generation scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257351770",
                    "name": "Yiran Chen"
                },
                {
                    "authorId": "6872825",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "2141480480",
                    "name": "Xianze Wu"
                },
                {
                    "authorId": "2254643264",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "2257464374",
                    "name": "Jingjing Xu"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "2257558361",
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "76be63767799fa50357fab6516b668960b67aa78",
            "title": "Taxonomy Completion via Triplet Matching Network",
            "abstract": "Automatically constructing taxonomy finds many applications in e-commerce and web search. One critical challenge is as data and business scope grow in real applications, new concepts are emerging and needed to be added to the existing taxonomy. Previous approaches focus on the taxonomy expansion, i.e. finding an appropriate hypernym concept from the taxonomy for a new query concept. In this paper, we formulate a new task, \u201ctaxonomy completion\u201d, by discovering both the hypernym and hyponym concepts for a query. We propose Triplet Matching Network (TMN), to find the appropriate pairs for a given query concept. TMN consists of one primal scorer and multiple auxiliary scorers. These auxiliary scorers capture various fine-grained signals (e.g., query to hypernym or query to hyponym semantics), and the primal scorer makes a holistic prediction on triplet based on the internal feature representations of all auxiliary scorers. Also, an innovative channel-wise gating mechanism that retains task-specific information in concept representations is introduced to further boost model performance. Experiments on four real-world large-scale datasets show that TMN achieves the best performance on both taxonomy completion task and the previous taxonomy expansion task, outperforming existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47540245",
                    "name": "Jieyu Zhang"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "2111106416",
                    "name": "Ying Zeng"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "3363642",
                    "name": "Jiaming Shen"
                },
                {
                    "authorId": "3375249",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "9e0e84f120cab51b8dfd0525dba552d2b3fb8042",
            "title": "Gradient-Based Adversarial Factual Consistency Evaluation for Abstractive Summarization",
            "abstract": "Neural abstractive summarization systems have gained significant progress in recent years. However, abstractive summarization often produce inconsisitent statements or false facts. How to automatically generate highly abstract yet factually correct summaries? In this paper, we proposed an efficient weak-supervised adversarial data augmentation approach to form the factual consistency dataset. Based on the artificial dataset, we train an evaluation model that can not only make accurate and robust factual consistency discrimination but is also capable of making interpretable factual errors tracing by backpropagated gradient distribution on token embeddings. Experiments and analysis conduct on public annotated summarization and factual consistency datasets demonstrate our approach effective and reasonable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2101321888",
                    "name": "Zhiyuan Zeng"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "1753096",
                    "name": "Weiran Xu"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "c7f38384ed156cdfb706fccc8c4dbbbf08635941",
            "title": "Triangular Bidword Generation for Sponsored Search Auction",
            "abstract": "Sponsored search auction is a crucial component of modern search engines. It requires a set of candidate bidwords that advertisers can place bids on. Existing methods generate bidwords from search queries or advertisement content. However, they suffer from the data noise in (query, bidword) and (advertisement, bidword) pairs. In this paper, we propose a triangular bidword generation model (TRIDENT), which takes the high-quality data of paired (query, advertisement) as a supervision signal to indirectly guide the bidword generation process. Our proposed model is simple yet effective: by using bidword as the bridge between search query and advertisement, the generation of search query, advertisement and bidword can be jointly learned in the triangular training framework. This alleviates the problem that the training data of bidword may be noisy. Experimental results, including automatic and human evaluations, show that our proposed TRIDENT can generate relevant and diverse bidwords for both search queries and advertisements. Our evaluation on online real data validates the effectiveness of the TRIDENT's generated bidwords for product search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114789983",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": null,
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "cebaf1435bcee484b41cf0b97ba6fd86a36b38d0",
            "title": "Probabilistic Graph Reasoning for Natural Proof Generation",
            "abstract": "In this paper, we investigate the problem of reasoning over natural language statements. Prior neural based approaches do not explicitly consider the inter-dependency among answers and their proofs. In this paper, we propose PRobr, a novel approach for joint answer prediction and proof generation. PRobr defines a joint probabilistic distribution over all possible proof graphs and answers via an induced graphical model. We then optimize the model using variational approximation on top of neural textual representation. Experiments on multiple datasets under diverse settings (fully supervised, few-shot and zero-shot evaluation) verify the effectiveness of PRobr, e.g., achieving 10%-30% improvement on QA accuracy in few/zero-shot evaluation. Our codes and models can be found at https://github.com/changzhisun/PRobr/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118133838",
                    "name": "Changzhi Sun"
                },
                {
                    "authorId": "2108167542",
                    "name": "Xinbo Zhang"
                },
                {
                    "authorId": "5040052",
                    "name": "Jiangjie Chen"
                },
                {
                    "authorId": "2056157609",
                    "name": "Chun Gan"
                },
                {
                    "authorId": "3174675",
                    "name": "Yuanbin Wu"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "2111824520",
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "ddde271db4611bf7cd821f8b89ecf701c2e34d5b",
            "title": "MTG: A Benchmark Suite for Multilingual Text Generation",
            "abstract": "We introduce MTG, a new benchmark suite for training and evaluating multilingual text generation. It is the first-proposed multilingual multiway text generation dataset with the largest human-annotated data (400k). It includes four generation tasks (story generation, question generation, title generation and text summarization) across five languages (English, German, French, Spanish and Chinese). The multiway setup enables testing knowledge transfer capabilities for a model across languages and tasks. Using MTG, we train and analyze several popular multilingual generation models from different aspects. Our benchmark suite fosters model performance enhancement with more human-annotated parallel data. It provides comprehensive evaluations with diverse generation scenarios. Code and data are available at \\url{https://github.com/zide05/MTG}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2135836407",
                    "name": "Yiran Chen"
                },
                {
                    "authorId": "6872825",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "2141480480",
                    "name": "Xianze Wu"
                },
                {
                    "authorId": "49371126",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "47883405",
                    "name": "Jingjing Xu"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": null,
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "e0852ac1b41fdd1e53505db3b2b9c3e76eb1d88a",
            "title": "CNewSum: A Large-scale Chinese News Summarization Dataset with Human-annotated Adequacy and Deducibility Level",
            "abstract": "Automatic text summarization aims to produce a brief but crucial summary for the input documents. Both extractive and abstractive methods have witnessed great success in English datasets in recent years. However, there has been a minimal exploration of text summarization in Chinese, limited by the lack of large-scale datasets. In this paper, we present a large-scale Chinese news summarization dataset CNewSum, which consists of 304,307 documents and human-written summaries for the news feed. It has long documents with high-abstractive summaries, which can encourage document-level understanding and generation for current summarization models. An additional distinguishing feature of CNewSum is that its test set contains adequacy and deducibility annotations for the summaries. The adequacy level measures the degree of summary information covered by the document, and the deducibility indicates the reasoning ability the model needs to generate the summary. These annotations can help researchers analyze and target their model performance bottleneck. We examine recent methods on CNewSum and release our dataset to provide a solid testbed for automatic Chinese summarization research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155681127",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "2141480480",
                    "name": "Xianze Wu"
                },
                {
                    "authorId": null,
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "2151530622",
                    "name": "Lei Li"
                }
            ]
        }
    ]
}