{
    "authorId": "1739134268",
    "papers": [
        {
            "paperId": "161eaa0ea15044ea0c35ae25c3f0f77ce510a0a3",
            "title": "Privacy-preserving transactive energy systems: Key topics and open research challenges",
            "abstract": "This manuscript aims to formalize and conclude the discussions initiated during the PriTEM workshop 22-23 March 2023. We present important ideas and discussion topics in the context of transactive energy systems. Moreover, the conclusions from the discussions articulate potential aspects to be explored in future studies on transactive energy management. Particularly, these conclusions cover research topics in energy technology and energy informatics, energy law, data law, energy market and socio-psychology that are relevant to the seamless integration of renewable energy resources and the transactive energy systems-in smart microgrids-focusing on distributed frameworks such as peer-to-peer (P2P) energy trading. We clarify issues, identify barriers, and suggest possible solutions to open questions in diversified topics, such as block-chain interoperability, consumer privacy and data sharing, and participation incentivization. Furthermore, we also elaborate challenges associated with cross-disciplinary collaboration and coordination for transactive energy systems, and enumerate the lessons learned from our work so far.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1443759711",
                    "name": "Daniel Gerbi Duguma"
                },
                {
                    "authorId": "2275275227",
                    "name": "Juliana Zhang"
                },
                {
                    "authorId": "2138211844",
                    "name": "Meysam Aboutalebi"
                },
                {
                    "authorId": "2237993901",
                    "name": "Shiliang Zhang"
                },
                {
                    "authorId": "2275232390",
                    "name": "Catherine Banet"
                },
                {
                    "authorId": "81427606",
                    "name": "C. Bj\u00f8rkli"
                },
                {
                    "authorId": "2167783415",
                    "name": "Chinmayi Prabhu Baramashetru"
                },
                {
                    "authorId": "2275236211",
                    "name": "Frank Eliassen"
                },
                {
                    "authorId": "2275609374",
                    "name": "Hui Zhang"
                },
                {
                    "authorId": "122084467",
                    "name": "Jonathan Muringani"
                },
                {
                    "authorId": "2275235872",
                    "name": "Josef Noll"
                },
                {
                    "authorId": "3311376",
                    "name": "K. I. Fostervold"
                },
                {
                    "authorId": "2279567073",
                    "name": "Lars B\u00f6cker"
                },
                {
                    "authorId": "1778489",
                    "name": "L. Bygrave"
                },
                {
                    "authorId": "1820008",
                    "name": "M. Bagherpour"
                },
                {
                    "authorId": "73032851",
                    "name": "Maunya Doroudi Moghadam"
                },
                {
                    "authorId": "2275234205",
                    "name": "Olaf Owe"
                },
                {
                    "authorId": "1739134268",
                    "name": "Poushali Sengupta"
                },
                {
                    "authorId": "2238052053",
                    "name": "Roman Vitenberg"
                },
                {
                    "authorId": "2461792",
                    "name": "Sabita Maharjan"
                },
                {
                    "authorId": "2238047375",
                    "name": "Thiago Garrett"
                },
                {
                    "authorId": "2275284436",
                    "name": "Yushuai Li"
                },
                {
                    "authorId": "2275236261",
                    "name": "Zhengyu Shan"
                }
            ]
        },
        {
            "paperId": "3289c5b90739c5f5d4b355791f840a7430f6ef20",
            "title": "Balancing Explainability-Accuracy of Complex Models",
            "abstract": "Explainability of AI models is an important topic that can have a significant impact in all domains and applications from autonomous driving to healthcare. The existing approaches to explainable AI (XAI) are mainly limited to simple machine learning algorithms, and the research regarding the explainability-accuracy tradeoff is still in its infancy especially when we are concerned about complex machine learning techniques like neural networks and deep learning (DL). In this work, we introduce a new approach for complex models based on the co-relation impact which enhances the explainability considerably while also ensuring the accuracy at a high level. We propose approaches for both scenarios of independent features and dependent features. In addition, we study the uncertainty associated with features and output. Furthermore, we provide an upper bound of the computation complexity of our proposed approach for the dependent features. The complexity bound depends on the order of logarithmic of the number of observations which provides a reliable result considering the higher dimension of dependent feature space with a smaller number of observations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739134268",
                    "name": "Poushali Sengupta"
                },
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2461792",
                    "name": "Sabita Maharjan"
                },
                {
                    "authorId": "1743900",
                    "name": "F. Eliassen"
                }
            ]
        },
        {
            "paperId": "497d7a3b33b8ce8924695020c0df2fef07ea80fd",
            "title": "FLaPS: Federated Learning and Privately Scaling",
            "abstract": "Federated learning (FL) is a distributed learning process where the model (weights and checkpoints) is transferred to the devices that posses data rather than the classical way of transferring and aggregating the data centrally. In this way, sensitive data does not leave the user devices. FL uses the FedAvg algorithm, which is trained in the iterative model averaging way, on the non-iid and unbalanced distributed data, without depending on the data quantity. Some issues with the FL are, 1) no scalability, as the model is iteratively trained over all the devices, which amplifies with device drops; 2) security and privacy trade-off of the learning process still not robust enough and 3) overall communication efficiency and the cost are higher. To mitigate these challenges we present Federated Learning and Privately Scaling (FLaPS) architecture, which improves scalability as well as the security and privacy of the system. The devices are grouped into clusters which further gives better privacy scaled turn around time to finish a round of training. Therefore, even if a device gets dropped in the middle of training, the whole process can be started again after a definite amount of time. The data and model both are communicated using differentially private reports with iterative shuffling which provides a better privacy-utility trade-off. We evaluated FLaPS on MNIST, CIFAR10, and TINY-IMAGENET-200 dataset using various CNN models. Experimental results prove FLaPS to be an improved, time and privacy scaled environment having better and comparable after-learning-parameters with respect to the central and FL models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "120496336",
                    "name": "Sudipta Paul"
                },
                {
                    "authorId": "1739134268",
                    "name": "Poushali Sengupta"
                },
                {
                    "authorId": "2109876",
                    "name": "Subhankar Mishra"
                }
            ]
        },
        {
            "paperId": "a2555d0fa9d9ebe7aea371c6d3e2a89c34f4438d",
            "title": "BUDS: Balancing Utility and Differential Privacy by Shuffling",
            "abstract": "Balancing utility and differential privacy by shuffling or BUDS is an approach towards crowd sourced, statistical databases, with strong privacy and utility balance using differential privacy theory. Here, a novel algorithm is proposed using one-hot encoding and iterative shuffling with the loss estimation and risk minimization techniques, to balance both the utility and privacy. In this work, after collecting one-hot encoded data from different sources and clients, a step of novel attribute shuffling technique using iterative shuffling (based on the query asked by the analyst) and loss estimation with an updation function and risk minimization produces a utility and privacy balanced differential private report. During empirical test of balanced utility and privacy, BUDS produces $\\epsilon=0.02$ which is a very promising result. Our algorithm maintains a privacy bound of $\\epsilon=ln[t/((n_{1}-1)^{S})]$ and loss bound of $c^{\\prime}\\vert e^{ln[t/((n_{1}-1)^{S})]}-1\\vert$.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1739134268",
                    "name": "Poushali Sengupta"
                },
                {
                    "authorId": "120496336",
                    "name": "Sudipta Paul"
                },
                {
                    "authorId": "2109876",
                    "name": "Subhankar Mishra"
                }
            ]
        },
        {
            "paperId": "ef220d6910a5546c30e26c2555c8fd416d0b4b28",
            "title": "Learning With Differential Privacy",
            "abstract": "The leakage of data might have an extreme effect on the personal level if it contains sensitive information. Common prevention methods like encryption-decryption, endpoint protection, intrusion detection systems are prone to leakage. Differential privacy comes to the rescue with a proper promise of protection against leakage, as it uses a randomized response technique at the time of collection of the data which promises strong privacy with better utility. Differential privacy allows one to access the forest of data by describing their pattern of groups without disclosing any individual trees. The current adaption of differential privacy by leading tech companies and academia encourages authors to explore the topic in detail. The different aspects of differential privacy, its application in privacy protection and leakage of information, a comparative discussion on the current research approaches in this field, its utility in the real world as well as the trade-offs will be discussed.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1739134268",
                    "name": "Poushali Sengupta"
                },
                {
                    "authorId": "120496336",
                    "name": "Sudipta Paul"
                },
                {
                    "authorId": "2109876",
                    "name": "Subhankar Mishra"
                }
            ]
        }
    ]
}