{
    "authorId": "2291705807",
    "papers": [
        {
            "paperId": "240ac1cc47a00d2c4fe62e228c1fb0dfe85b0c39",
            "title": "Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation",
            "abstract": "We study the code generation behavior of instruction-tuned models built on top of code pre-trained language models when they could access an auxiliary function to implement a function. We design several ways to provide auxiliary functions to the models by adding them to the query or providing a response prefix to incorporate the ability to utilize auxiliary functions with the instruction-following capability. Our experimental results show the effectiveness of combining the base models' auxiliary function utilization ability with the instruction following ability. In particular, the performance of adopting our approaches with the open-sourced language models surpasses that of the recent powerful proprietary language models, i.e., gpt-4o.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287842444",
                    "name": "Seonghyeon Lee"
                },
                {
                    "authorId": "2303885004",
                    "name": "Suyeon Kim"
                },
                {
                    "authorId": "2291705807",
                    "name": "Joonwon Jang"
                },
                {
                    "authorId": "2317010068",
                    "name": "Heejae Chon"
                },
                {
                    "authorId": "3067773",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2286165699",
                    "name": "Hwanjo Yu"
                }
            ]
        },
        {
            "paperId": "b48d21a75ff76a3969a24b43bd3e1a2644d60a23",
            "title": "Rectifying Demonstration Shortcut in In-Context Learning",
            "abstract": "Large language models (LLMs) are able to solve various tasks with only a few demonstrations utilizing their in-context learning (ICL) abilities.However, LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction. In this work, we term this phenomenon as the \u2018Demonstration Shortcut\u2019.While previous works have primarily focused on improving ICL prediction results for predefined tasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLM to effectively learn new input-label relationships from demonstrations.To achieve this, we introduce In-Context Calibration, a demonstration-aware calibration method.We evaluate the effectiveness of the proposed method in two settings: (1) the Original ICL Task using the standard label space and (2) the Task Learning setting, where the label space is replaced with semantically unrelated tokens.In both settings, In-Context Calibration demonstrates substantial improvements, with results generalized across three LLM families (OPT, GPT, and Llama2) under various configurations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2291705807",
                    "name": "Joonwon Jang"
                },
                {
                    "authorId": "2287988207",
                    "name": "Sanghwan Jang"
                },
                {
                    "authorId": "1643930327",
                    "name": "Wonbin Kweon"
                },
                {
                    "authorId": "2291142849",
                    "name": "Minjin Jeon"
                },
                {
                    "authorId": "2286165699",
                    "name": "Hwanjo Yu"
                }
            ]
        }
    ]
}