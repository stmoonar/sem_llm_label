{
    "authorId": "143894459",
    "papers": [
        {
            "paperId": "0615b10d90a3b5dac5ce1ccf1f41b27fc371599f",
            "title": "DI-2022: The Third Document Intelligence Workshop",
            "abstract": "Business documents are central to the operation of all organizations, and they come in all shapes and sizes: project reports, planning documents, technical specifications, financial statements, meeting minutes, legal agreements, contracts, resumes, purchase orders, invoices, and many more. The ability to read, understand and interpret these documents, referred to here as Document Intelligence (DI), is challenging due to not only many domains of knowledge involved, but also their complex formats and structures, internal and external cross references deployed, and even less-than-ideal quality of scans and OCR oftentimes performed on them. This workshop aims to explore and advance the current state of research and practice in answering these challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3115414",
                    "name": "A. Nenkova"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "1947062",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "144020023",
                    "name": "David Bruce Lewis"
                },
                {
                    "authorId": "2519906",
                    "name": "Sandeep Tata"
                },
                {
                    "authorId": "1769641",
                    "name": "Dan G. Tecuci"
                }
            ]
        },
        {
            "paperId": "643f81009db989ea3ce009d5d123548c47811e71",
            "title": "DI-2021: The Second Document Intelligence Workshop",
            "abstract": "Business documents are central to the operation of all organizations, and they come in all shapes and sizes: project reports, planning documents, technical specifications, financial statements, meeting minutes, legal agreements, contracts, resumes, purchase orders, invoices, and many more. The ability to read, understand and interpret these documents, referred to here as Document Intelligence (DI), is challenging due to not only many domains of knowledge involved, but also their complex formats and structures, internal and external cross references deployed, and even less-than-ideal quality of scans and OCR oftentimes performed on them. This workshop aims to explore and advance the current state of research and practice in answering these challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1947062",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "144020023",
                    "name": "David Bruce Lewis"
                },
                {
                    "authorId": "38534822",
                    "name": "Yijuan Lu"
                },
                {
                    "authorId": "3464856",
                    "name": "Hamid Motahari"
                },
                {
                    "authorId": "2519906",
                    "name": "Sandeep Tata"
                }
            ]
        },
        {
            "paperId": "759314189ecdffdc979deebf334646e847d93b1b",
            "title": "KAAPA: Knowledge Aware Answers from PDF Analysis",
            "abstract": "We present KaaPa (Knowledge Aware Answers from Pdf Analysis), an integrated solution for machine reading comprehension over both text and tables extracted from PDFs. KaaPa enables interactive question refinement using facets generated from an automatically induced Knowledge Graph. In addition it provides a concise summary of the supporting evidence for the provided answers by aggregating information across multiple sources. KaaPa can be applied consistently to any collection of documents in English with zero domain adaptation effort. We showcase the use of KaaPa for QA on scientific literature using the COVID-19 Open Research Dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107085016",
                    "name": "Nicolas R. Fauceglia"
                },
                {
                    "authorId": "1888104",
                    "name": "Mustafa Canim"
                },
                {
                    "authorId": "1711133",
                    "name": "A. Gliozzo"
                },
                {
                    "authorId": "50685486",
                    "name": "Jennifer J. Liang"
                },
                {
                    "authorId": "31856827",
                    "name": "N. Wang"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "2689774",
                    "name": "Nandana Mihindukulasooriya"
                },
                {
                    "authorId": "2879453",
                    "name": "Vittorio Castelli"
                },
                {
                    "authorId": "2169082",
                    "name": "Guy Feigenblat"
                },
                {
                    "authorId": "1775524",
                    "name": "D. Konopnicki"
                },
                {
                    "authorId": "2208580",
                    "name": "Yannis Katsis"
                },
                {
                    "authorId": "1707117",
                    "name": "Radu Florian"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "1781292",
                    "name": "S. Roukos"
                },
                {
                    "authorId": "2707234",
                    "name": "Avirup Sil"
                }
            ]
        },
        {
            "paperId": "9dbb26e4f04f38aa2a11289cbc82a2d9ed533741",
            "title": "TableLab: An Interactive Table Extraction System with Adaptive Deep Learning",
            "abstract": "Table extraction from PDF and image documents is a ubiquitous task in the real-world. Perfect extraction quality is difficult to achieve with one single out-of-box model due to (1) the wide variety of table styles, (2) the lack of training data representing this variety and (3) the inherent ambiguity and subjectivity of table definitions between end-users. Meanwhile, building customized models from scratch can be difficult due to the expensive nature of annotating table data. We attempt to solve these challenges with TableLab by providing a system where users and models seamlessly work together to quickly customize high-quality extraction models with a few labelled examples for the user\u2019s document collection, which contains pages with tables. Given an input document collection, TableLab first detects tables with similar structures (templates) by clustering embeddings from the extraction model. Document collections often contain tables created with a limited set of templates or similar structures. It then selects a few representative table examples already extracted with a pre-trained base deep learning model. Via an easy-to-use user interface, users provide feedback to these selections without necessarily having to identify every single error. TableLab then applies such feedback to finetune the pre-trained model and returns the results of the finetuned model back to the user. The user can choose to repeat this process iteratively until obtaining a customized model with satisfactory performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31856827",
                    "name": "N. Wang"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "73a906a988e54defee536a120125f957059d595e",
            "title": "Global Table Extractor (GTE): A Framework for Joint Table Identification and Cell Structure Recognition Using Visual Context",
            "abstract": "Documents are often used for knowledge sharing and preservation in business and science, within which are tables that capture most of the critical data. Unfortunately, most documents are stored and distributed as PDF or scanned images, which fail to preserve logical table structure. Recent vision-based deep learning approaches have been proposed to address this gap, but most still cannot achieve state-of-the-art results. We present Global Table Extractor (GTE), a vision-guided systematic framework for joint table detection and cell structured recognition, which could be built on top of any object detection model. With GTE-Table, we invent a new penalty based on the natural cell containment constraint of tables to train our table network aided by cell location predictions. GTE-Cell is a new hierarchical cell detection network that leverages table styles. Further, we design a method to automatically label table and cell structure in existing documents to cheaply create a large corpus of training and test data. We use this to enhance PubTabNet with cell labels and create FinTabNet, real-world and complex scientific and financial datasets with detailed table structure annotations to help train and test structure recognition. Our framework surpasses previous state-of-the-art results on the ICDAR 2013 and ICDAR 2019 table competition in both table detection and cell structure recognition. Further experiments demonstrate a greater than 45% improvement in cell structure recognition when compared to a vanilla RetinaNet object detection model in our new out-of-domain FinTabNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1662767314",
                    "name": "Xinyi Zheng"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "145378077",
                    "name": "Lucian Popa"
                },
                {
                    "authorId": "31856827",
                    "name": "N. Wang"
                }
            ]
        },
        {
            "paperId": "751b3b064f41a78c267eb969f6b7617015b0a901",
            "title": "Table extraction and understanding for scientific and enterprise applications",
            "abstract": "Valuable high-precision data are often published in the form of tables in both scientific and business documents. While humans can easily identify, interpret and contextualize tables, developing general-purpose automated techniques for extraction of information from tables is difficult due to the wide variety of table formats employed across corpora. To extract useful data from tables, data cells must be correctly extracted and linked to all relevant headers, units of measure and in-text references. Table extraction involves identifying the border and cell structure for each document table, while table understanding provides context by linking cells with semantic information inside and outside the table, such as row and column headers, footnotes, titles, and references in surrounding text. The objective of this tutorial is to provide a detailed synopsis of existing approaches for table extraction and understanding, highlight open research problems, and provide an overview of potential applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "3351526",
                    "name": "A. Evfimievski"
                },
                {
                    "authorId": "2208580",
                    "name": "Yannis Katsis"
                },
                {
                    "authorId": "31856827",
                    "name": "N. Wang"
                }
            ]
        },
        {
            "paperId": "3fa1d6611c26a96614bb348d4c7ed71281c0c5bb",
            "title": "DSMM'19: The 5th Workshop on Data Science for Macro-modeling with Financial and Economic Datasets",
            "abstract": "DSMM 2019 will explore the challenges of macro-modeling with financial and economic datasets. The workshop will also showcase the 2019 Financial Entity Identification and Information Integration (FEIII) Challenge which involves two challenge tasks, one over small business data and the other over customs data for shipping manifests.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "3252167",
                    "name": "R. Krishnamurthy"
                },
                {
                    "authorId": "1733877",
                    "name": "L. Raschid"
                }
            ]
        },
        {
            "paperId": "589362e341b6ad667e80cc75e13ef7143023f876",
            "title": "Learning Explainable Entity Resolution Algorithms for Small Business Data using SystemER",
            "abstract": "The 2019 FEIII CALI data challenge aims at linking different representations of the same real-world entities across multiple public datasets that collect identification and activity data about small to medium enterprises (SMEs) in California. We formalize this challenge as a learning-based entity resolution (ER) task, the goal of which is to learn a high-precision and high-recall pair-wise ER model that classifies small business entity pairs into matches and non-matches. Realistic ER tasks usually involve a pipeline of laborintensive and error-prone tasks, such as data preprocesing, gathering of training data, feature engineering, and model tuning. In this task, we apply an advanced human-in-the-loop system, named SystemER, to learn ER algorithms for SME entities. Powered by active learning and via a carefully designed user interface, SystemER can learn high-quality explainable ER algorithms with low human effort, while achieving high-accuracy on the datasets provided by the FEIII CALI data challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053225294",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "1963709",
                    "name": "Sairam Gurajada"
                },
                {
                    "authorId": "145378077",
                    "name": "Lucian Popa"
                }
            ]
        },
        {
            "paperId": "6b17373b06bac0dbe5423658eb3fb6e146522934",
            "title": "Financial Entity Identification and Information Integration (FEIII) 2019 Challenge: The Report of the Organizing Committee",
            "abstract": "This report presents the goals and outcomes of the 2019 Financial Entity Identification and Information Integration (FEIII) Challenge. We describe two challenge datasets and tasks. FEIII SHIP was a bill of lading dataset for incoming shipments to the United States and the task was to identify the major shippers for some product, from some country. FEIII CALI included state and local regulatory data from California, and the task was entity linkage for San Francisco restaurants. The report summarizes plans for the 2020 Challenge and the Business Open Knowledge Network (BOKN).",
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733877",
                    "name": "L. Raschid"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "2034743",
                    "name": "C. D. Pablo"
                },
                {
                    "authorId": "40060618",
                    "name": "M. Flood"
                },
                {
                    "authorId": "2057864872",
                    "name": "John Grant"
                },
                {
                    "authorId": "50279013",
                    "name": "J. Langsam"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "1663735097",
                    "name": "Elena Tomas"
                },
                {
                    "authorId": "144526707",
                    "name": "I. Soboroff"
                }
            ]
        },
        {
            "paperId": "91c31c673cbf19368098718d3b4fe3ba366e73dd",
            "title": "Simultaneous Optimisation of Image Quality Improvement and Text Content Extraction from Scanned Documents",
            "abstract": "Convolutional neural networks are shown to achieve breakthrough performance for the task of single image super resolution (SISR) for natural images. These state-of-the-art (SOA) networks have been adapted to the task of single text image super resolution and have been shown to boost the optical character recognition (OCR) performance. However, these approaches depend on variations of the standard mean squared error (MSE) loss in order to train the SR network for improving the text image quality which does not guarantee optimal OCR performance. In this paper, we propose to combine the OCR performance into the loss function during network training. This results in the generation of high resolution text images that achieve high OCR performance that is comparable to the ground truth high-resolution text images and surpassing those of the SOA baseline results. We define novel intuitive metrics to capture the improvement in the OCR performance and provide extensive experiments to qualitatively and quantitatively assess improvement in the results of our proposed approach against the SOA baselines on the standard UNLV dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33906968",
                    "name": "Shashank Mujumdar"
                },
                {
                    "authorId": "2115343577",
                    "name": "Nitin Gupta"
                },
                {
                    "authorId": "144243819",
                    "name": "Abhinav Jain"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                }
            ]
        }
    ]
}