{
    "authorId": "2296792230",
    "papers": [
        {
            "paperId": "4f60009234e76f9f8969f6cca23b3b07e944e984",
            "title": "Towards Uncovering How Large Language Model Works: An Explainability Perspective",
            "abstract": "Large language models (LLMs) have led to breakthroughs in language tasks, yet the internal mechanisms that enable their remarkable generalization and reasoning abilities remain opaque. This lack of transparency presents challenges such as hallucinations, toxicity, and misalignment with human values, hindering the safe and beneficial deployment of LLMs. This paper aims to uncover the mechanisms underlying LLM functionality through the lens of explainability. First, we review how knowledge is architecturally composed within LLMs and encoded in their internal parameters via mechanistic interpretability techniques. Then, we summarize how knowledge is embedded in LLM representations by leveraging probing techniques and representation engineering. Additionally, we investigate the training dynamics through a mechanistic perspective to explain phenomena such as grokking and memorization. Lastly, we explore how the insights gained from these explanations can enhance LLM performance through model editing, improve efficiency through pruning, and better align with human values.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237987232",
                    "name": "Haiyan Zhao"
                },
                {
                    "authorId": "2276509067",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2296792230",
                    "name": "Bo Shen"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "2237804196",
                    "name": "Mengnan Du"
                }
            ]
        },
        {
            "paperId": "a865474bcf484c8165dcde2382ab446c1d76eb17",
            "title": "Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution",
            "abstract": "Probing learned concepts in large language models (LLMs) is crucial for understanding how semantic knowledge is encoded internally. Training linear classifiers on probing tasks is a principle approach to denote the vector of a certain concept in the representation space. However, the single vector identified for a concept varies with both data and training, making it less robust and weakening its effectiveness in real-world applications. To address this challenge, we propose an approach to approximate the subspace representing a specific concept. Built on linear probing classifiers, we extend the concept vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's effectiveness through measuring its faithfulness and plausibility across multiple LLMs with different sizes and architectures. Additionally, we use representation intervention tasks to showcase its efficacy in real-world applications such as emotion steering. Experimental results indicate that GCS concept vectors have the potential to balance steering performance and maintaining the fluency in natural language generation tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2300964499",
                    "name": "Haiyan Zhao"
                },
                {
                    "authorId": "2323848799",
                    "name": "Heng Zhao"
                },
                {
                    "authorId": "2296792230",
                    "name": "Bo Shen"
                },
                {
                    "authorId": "2323739837",
                    "name": "Ali Payani"
                },
                {
                    "authorId": "2323793056",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2302403200",
                    "name": "Mengnan Du"
                }
            ]
        }
    ]
}