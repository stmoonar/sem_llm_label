{
    "authorId": "36701727",
    "papers": [
        {
            "paperId": "aeb755976e5ac0f73d39ab6679bc92d9061c62ea",
            "title": "Beyond the Surface: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation",
            "abstract": "Recent studies have highlighted the issue of stereotypical depictions for people of different identity groups in Text-to-Image (T2I) model generations. However, these existing approaches have several key limitations, including a noticeable lack of coverage of global identity groups in their evaluation, and the range of their associated stereotypes. Additionally, they often lack a critical distinction between inherently visual stereotypes, such as \u2018under-weight\u2019 or \u2018sombrero\u2019, and culturally dependent stereotypes like \u2018attractive\u2019 or \u2018terrorist\u2019. In this work, we address these limitations with a multifaceted approach that leverages existing textual resources to ground our evaluation of geo-cultural stereotypes in the generated images from T2I models. We employ existing stereotype benchmarks to identify and evaluate visual stereotypes at global scale, spanning 135 nationality based identity groups. We demonstrate that stereotypical attributes are thrice as likely to be present in images of these identities as compared to other attributes. We further investigate how disparately offensive the de-pictions of generated images are for different nationalities. Finally, through a detailed case study, we reveal how the \u2018default\u2019 representations of all identity groups have a stereotypical appearance. Moreover, for the Global South, images across different attributes are visually similar, even when explicitly prompted otherwise. CONTENT WARNING: Some examples may contain offensive stereotypes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2265650491",
                    "name": "Vinodkumar Prabhakaran"
                },
                {
                    "authorId": "2268676053",
                    "name": "Remi Denton"
                },
                {
                    "authorId": "2279338830",
                    "name": "Sarah Laszlo"
                },
                {
                    "authorId": "2160404",
                    "name": "Shachi Dave"
                },
                {
                    "authorId": "101513478",
                    "name": "Rida Qadri"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "50991767",
                    "name": "Sunipa Dev"
                }
            ]
        },
        {
            "paperId": "b265ad93aa9d349ba7cab7829f81b1be88c37bb1",
            "title": "ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation",
            "abstract": "Recent studies have shown that Text-to-Image (T2I) model generations can reflect social stereotypes present in the real world. However, existing approaches for evaluating stereotypes have a noticeable lack of coverage of global identity groups and their associated stereotypes. To address this gap, we introduce the ViSAGe (Visual Stereotypes Around the Globe) dataset to enable the evaluation of known nationality-based stereotypes in T2I models, across 135 nationalities. We enrich an existing textual stereotype resource by distinguishing between stereotypical associations that are more likely to have visual depictions, such as `sombrero', from those that are less visually concrete, such as 'attractive'. We demonstrate ViSAGe's utility through a multi-faceted evaluation of T2I generations. First, we show that stereotypical attributes in ViSAGe are thrice as likely to be present in generated images of corresponding identities as compared to other attributes, and that the offensiveness of these depictions is especially higher for identities from Africa, South America, and South East Asia. Second, we assess the stereotypical pull of visual depictions of identity groups, which reveals how the 'default' representations of all identity groups in ViSAGe have a pull towards stereotypical depictions, and that this pull is even more prominent for identity groups from the Global South. CONTENT WARNING: Some examples contain offensive stereotypes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2265650491",
                    "name": "Vinodkumar Prabhakaran"
                },
                {
                    "authorId": "2268676053",
                    "name": "Remi Denton"
                },
                {
                    "authorId": "2279338830",
                    "name": "Sarah Laszlo"
                },
                {
                    "authorId": "2160404",
                    "name": "Shachi Dave"
                },
                {
                    "authorId": "101513478",
                    "name": "Rida Qadri"
                },
                {
                    "authorId": "2262444977",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "50991767",
                    "name": "Sunipa Dev"
                }
            ]
        },
        {
            "paperId": "e682e4a39c3597d3be8a921919989077047db2dd",
            "title": "Transformer-based Models for Long-Form Document Matching: Challenges and Empirical Analysis",
            "abstract": "Recent advances in the area of long document matching have primarily focused on using transformer-based models for long document encoding and matching. There are two primary challenges associated with these models. Firstly, the performance gain provided by transformer-based models comes at a steep cost \u2013 both in terms of the required training time and the resource (memory and energy) consumption. The second major limitation is their inability to handle more than a pre-defined input token length at a time. In this work, we empirically demonstrate the effectiveness of simple neural models (such as feed-forward networks, and CNNs) and simple embeddings (like GloVe, and Paragraph Vector) over transformer-based models on the task of document matching. We show that simple models outperform the more complex BERT-based models while taking significantly less training time, energy, and memory. The simple models are also more robust to variations in document length and text perturbations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2124016792",
                    "name": "Adithya Samavedhi"
                },
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "f4f154892800008894ebbf57add31fcaac4f27ca",
            "title": "SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models",
            "abstract": "Stereotype benchmark datasets are crucial to detect and mitigate social stereotypes about groups of people in NLP models. However, existing datasets are limited in size and coverage, and are largely restricted to stereotypes prevalent in the Western society. This is especially problematic as language technologies gain hold across the globe. To address this gap, we present SeeGULL, a broad-coverage stereotype dataset, built by utilizing generative capabilities of large language models such as PaLM, and GPT-3, and leveraging a globally diverse rater pool to validate the prevalence of those stereotypes in society. SeeGULL is in English, and contains stereotypes about identity groups spanning 178 countries across 8 different geo-political regions across 6 continents, as well as state-level identities within the US and India. We also include fine-grained offensiveness scores for different stereotypes and demonstrate their global disparities. Furthermore, we include comparative annotations about the same groups by annotators living in the region vs. those that are based in North America, and demonstrate that within-region stereotypes about groups differ from those prevalent in North America.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2132006618",
                    "name": "A. Davani"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "2160404",
                    "name": "Shachi Dave"
                },
                {
                    "authorId": "3331141",
                    "name": "Vinodkumar Prabhakaran"
                },
                {
                    "authorId": "50991767",
                    "name": "Sunipa Dev"
                }
            ]
        },
        {
            "paperId": "d18287d5ef8653aa1276a11957f2b3934c7c93e1",
            "title": "CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models",
            "abstract": "Pre-trained programming language (PL) models (such as CodeT5, CodeBERT, GraphCodeBERT, etc.,) have the potential to automate software engineering tasks involving code understanding and code generation. However, these models operate in the natural channel of code, i.e., primarily concerned with the human understanding of code. They are not robust to changes in the input and thus, are potentially susceptible to adversarial attacks in the natural channel. We propose, Code Attack, a simple yet effective black-box attack model that uses code structure to generate effective, efficient, and imperceptible adversarial code samples and demonstrates the vulnerabilities of the state-of-the-art PL models to code-specific adversarial attacks. We evaluate the transferability of CodeAttack on several code-code (translation and repair) and code-NL (summarization) tasks across different programming languages. Code Attack outperforms state-of-the-art adversarial NLP attack models to achieve the best overall drop in performance while being more efficient, imperceptible, consistent, and fluent. The code can be found at https://github.com/reddy-lab-code-research/CodeAttack.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "65f534e6e04e0e79ffa4c5be085cb63e1b330959",
            "title": "Fair Representation Learning using Interpolation Enabled Disentanglement",
            "abstract": "With the growing interest in the machine learning community to solve real-world problems, it has become crucial to uncover the hidden reasoning behind their decisions by focusing on the fairness and auditing the predictions made by these black-box models. In this paper, we propose a novel method to address two key issues: (a) Can we simultaneously learn fair disentangled representations while ensuring the utility of the learned representation for downstream tasks, and (b)Can we provide theoretical insights into when the proposed approach will be both fair and accurate. To address the former, we propose the method FRIED, Fair Representation learning using Interpolation Enabled Disentanglement. In our architecture, by imposing a critic-based adversarial framework, we enforce the interpolated points in the latent space to be more realistic. This helps in capturing the data manifold effectively and enhances the utility of the learned representation for downstream prediction tasks. We address the latter question by developing a theory on fairness-accuracy trade-offs using classifier-based conditional mutual information estimation. We demonstrate the effectiveness of FRIED on datasets of different modalities - tabular, text, and image datasets. We observe that the representations learned by FRIED are overall fairer in comparison to existing baselines and also accurate for downstream prediction tasks. Additionally, we evaluate FRIED on a real-world healthcare claims dataset where we conduct an expert aided model auditing study providing useful insights into opioid ad-diction patterns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "3236313",
                    "name": "B. Vinzamuri"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "86e0c6e038ba928b091329950400b8debe79363f",
            "title": "Supervised Contrastive Learning for Interpretable Long Document Comparison",
            "abstract": "Recent advancements in deep learning techniques have transformed the area of semantic text matching. However, most of the state-of-the-art models are designed to operate with short documents such as tweets, user reviews, comments, etc., and have fundamental limitations when applied to long-form documents such as scientific papers, legal documents, and patents. When handling such long documents, there are three primary challenges: (i) The presence of different contexts for the same word throughout the document, (ii) Small sections of contextually similar text between two documents, but dissimilar text in the remaining parts \u2013 this defies the basic understanding of \"similarity\", and (iii) The coarse nature of a single global similarity measure which fails to capture the heterogeneity of the document content. In this paper, we describe CoLDE : Co ntrastive L ong D ocument E ncoder \u2013 a transformer-based framework that addresses these challenges and allows for interpretable comparisons of long documents. CoLDE uses unique positional embeddings and a multi-headed chunkwise attention layer in conjunction with a contrastive learning framework to capture similarity at three different levels: (i) high-level similarity scores between a pair of documents, (ii) similarity scores between different sections within and across documents, and (iii) similarity scores between different chunks in the same document and also other documents. These fine-grained similarity scores aid in better interpretability. We evaluate CoLDE on three long document datasets namely, ACL Anthology publications, Wikipedia articles, and USPTO patents. Besides outperforming the state-of-the-art methods on the document comparison task, CoLDE also proves interpretable and robust to changes in document length and text perturbations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "2124016792",
                    "name": "Adithya Samavedhi"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "e9fe90baf1b811411943d73f40daf4d947f9102e",
            "title": "Supervised Contrastive Learning for Interpretable Long-Form Document Matching",
            "abstract": "Recent advancements in deep learning techniques have transformed the area of semantic text matching (STM). However, most state-of-the-art models are designed to operate with short documents such as tweets, user reviews, comments, and so on. These models have fundamental limitations when applied to long-form documents such as scientific papers, legal documents, and patents. When handling such long documents, there are three primary challenges: (i) the presence of different contexts for the same word throughout the document, (ii) small sections of contextually similar text between two documents, but dissimilar text in the remaining parts (this defies the basic understanding of \u201csimilarity\u201d), and (iii) the coarse nature of a single global similarity measure which fails to capture the heterogeneity of the document content. In this article, we describe CoLDE: Contrastive Long Document Encoder\u2014a transformer-based framework that addresses these challenges and allows for interpretable comparisons of long documents. CoLDE uses unique positional embeddings and a multi-headed chunkwise attention layer in conjunction with a supervised contrastive learning framework to capture similarity at three different levels: (i) high-level similarity scores between a pair of documents, (ii) similarity scores between different sections within and across documents, and (iii) similarity scores between different chunks in the same document and across other documents. These fine-grained similarity scores aid in better interpretability. We evaluate CoLDE on three long document datasets namely, ACL Anthology publications, Wikipedia articles, and USPTO patents. Besides outperforming the state-of-the-art methods on the document matching task, CoLDE is also robust to changes in document length and text perturbations and provides interpretable results. The code for the proposed model is publicly available at https://github.com/InterDigitalInc/CoLDE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "2124016792",
                    "name": "Adithya Samavedhi"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "161dfc76ace91bedf2770b3de5c6aac882453749",
            "title": "When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data",
            "abstract": "Sexism is prevalent in today\u2019s society, both offline and online, and poses a credible threat to social equality with respect to gender. According to ambivalent sexism theory (Glick and Fiske, 1996), it comes in two forms: Hostile and Benevolent. While hostile sexism is characterized by an explicitly negative attitude, benevolent sexism is more subtle. Previous works on computationally detecting sexism present online are restricted to identifying the hostile form. Our objective is to investigate the less pronounced form of sexism demonstrated online. We achieve this by creating and analyzing a dataset of tweets that exhibit benevolent sexism. By using Support Vector Machines (SVM), sequence-to-sequence models and FastText classifier, we classify tweets into \u2018Hostile\u2019, \u2018Benevolent\u2019 or \u2018Others\u2019 class depending on the kind of sexism they exhibit. We have been able to achieve an F1-score of 87.22% using FastText classifier. Our work helps analyze and understand the much prevalent ambivalent sexism in social media.",
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "1829635",
                    "name": "R. Mamidi"
                }
            ]
        }
    ]
}