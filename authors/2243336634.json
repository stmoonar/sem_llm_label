{
    "authorId": "2243336634",
    "papers": [
        {
            "paperId": "5118df03ae5c226f3875f34845438b09951a3e45",
            "title": "Open Domain Knowledge Extraction for Knowledge Graphs",
            "abstract": "The quality of a knowledge graph directly impacts the quality of downstream applications (e.g. the number of answerable questions using the graph). One ongoing challenge when building a knowledge graph is to ensure completeness and freshness of the graph's entities and facts. In this paper, we introduce ODKE, a scalable and extensible framework that sources high-quality entities and facts from open web at scale. ODKE utilizes a wide range of extraction models and supports both streaming and batch processing at different latency. We reflect on the challenges and design decisions made and share lessons learned when building and deploying ODKE to grow an industry-scale open domain knowledge graph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261737666",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2261740020",
                    "name": "Anton Belyi"
                },
                {
                    "authorId": "2261869967",
                    "name": "Fei Wu"
                },
                {
                    "authorId": "2261739744",
                    "name": "Samira Khorshidi"
                },
                {
                    "authorId": "1902199",
                    "name": "Azadeh Nikfarjam"
                },
                {
                    "authorId": "2274930671",
                    "name": "Rahul Khot"
                },
                {
                    "authorId": "2261737773",
                    "name": "Yisi Sang"
                },
                {
                    "authorId": "2274942692",
                    "name": "Katherine Luna"
                },
                {
                    "authorId": "2274937033",
                    "name": "Xianqi Chu"
                },
                {
                    "authorId": "2275050999",
                    "name": "Eric Choi"
                },
                {
                    "authorId": "10766676",
                    "name": "Yash Govind"
                },
                {
                    "authorId": "2274942694",
                    "name": "Chloe Seivwright"
                },
                {
                    "authorId": "2274931010",
                    "name": "Yiwen Sun"
                },
                {
                    "authorId": "2265974380",
                    "name": "Ahmed Fakhry"
                },
                {
                    "authorId": "2243336634",
                    "name": "Theo Rekatsinas"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "2274957519",
                    "name": "Xiaoguang Qi"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "bb86a2592e9efa196aefd6bbc39bf62a3202e9db",
            "title": "Construction of Paired Knowledge Graph - Text Datasets Informed by Cyclic Evaluation",
            "abstract": "Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Informed by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2243337763",
                    "name": "Xin Zhan"
                },
                {
                    "authorId": "37374479",
                    "name": "Richard He Bai"
                },
                {
                    "authorId": "2243340600",
                    "name": "Peng Shi"
                },
                {
                    "authorId": "2243336634",
                    "name": "Theo Rekatsinas"
                },
                {
                    "authorId": "2243377351",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2243336030",
                    "name": "Jeff Pound"
                },
                {
                    "authorId": "2243336902",
                    "name": "Josh Susskind"
                },
                {
                    "authorId": "2243335295",
                    "name": "Natalie Schluter"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "3111912",
                    "name": "N. Jaitly"
                }
            ]
        }
    ]
}