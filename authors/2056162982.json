{
    "authorId": "2056162982",
    "papers": [
        {
            "paperId": "220603c36fe10a007671128dca35fd16fa07ad88",
            "title": "KluSIM: Speeding up K-Medoids Clustering over Dimensional Data with Metric Access Method",
            "abstract": ".",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2299605299",
                    "name": "L. Teixeira"
                },
                {
                    "authorId": "2299673373",
                    "name": "I. A. R. Eleut\u00e9rio"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2299767030",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "96a363534c9394ad20b236dfa1fc32367a2f2f66",
            "title": "MIGUE-Sim: Speeding Up Similarity Queries with Native RDBMS Resources",
            "abstract": "Many applications require storing, managing, and retrieving complex data, such as multidimensional vectors and images in databases. In this paper, we propose MIGUE-Sim, a system to quickly execute exact Range and kNN similarity queries in Postgres. The queries are expressed following a straightforward, SQL-compatible representation seamlessly integrated into the language, whereas the system executes each query using just the native resources of Postgres. MIGUE-Sim uses the Postgres's Cube native extension to perform kNN faster, using the GIST R-Tree index available. The execution of kNN in our system without any index overcame our main competitor by up to 10% in execution time. However, when using GIST R-Tree, MIGUE-Sim can significantly speed up queries - experiments revealed that MIGUE-Sim is up to 96% faster than our closest competitor. We contribute with a framework that uses existing index structures from Postgres to speed up kNN queries with no modifications on the RDBMS; with the evaluation of different ways to write similarity queries in plain SQL; with the implementation of kNN queries with indices already available on Postgres. Our approach is easy to understand, to use, and it is extensible to include other distance functions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162902964",
                    "name": "Igor A. R. Eleut\u00e9rio"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2299605299",
                    "name": "L. Teixeira"
                },
                {
                    "authorId": "2299767030",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "b4d094751ecba9d6aef3d2d83f98fc1280ed95ee",
            "title": "Similarity-Slim Extension: Reducing Financial and Computational Costs of Similarity Queries in Document Collections in NoSQL Databases",
            "abstract": ": Several popular cloud NoSQL data stores, such as MongoDB and Firestore, organize data as document collections. However, they provide few resources for querying complex data by similarity. The comparison conditions provided to express queries over documents are based only on identity, containment, or order relationships. Thus, reading through an entire collection is often the only way to execute a similarity query. This can be both computationally and financially expensive, because data storage licenses charge for the number of document reads and writes. This paper presents Similarity-Slim, an innovative extension for NoSQL databases, designed to reduce the financial and computational costs associated with similarity queries. The extension was evaluated on the Firestore repository as a case study, considering three application scenarios: geospatial, image recommendation and medical support systems. Experiments have shown that it can reduce costs by up to 2,800 times and speed up queries by up to 85 times.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2299778073",
                    "name": "William Silva"
                },
                {
                    "authorId": "2299673373",
                    "name": "I. A. R. Eleut\u00e9rio"
                },
                {
                    "authorId": "2299605299",
                    "name": "L. Teixeira"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "2068707342",
                    "name": "C. J\u00fanior"
                }
            ]
        },
        {
            "paperId": "c58051e0100b201516286e20244519ee49a53658",
            "title": "A symptom-based community-weighted similarity approach for inpatient health condition monitoring",
            "abstract": "Given a patient\u2019s series of exams conducted over time, how can we identify cases with similar abnormalities or symptoms? Hospitals and medical facilities continuously monitor patients through periodic exams, a crucial practice for assessing their current condition and potential progression, thereby supporting decision-making. However, similarity-based searches often consider several exams of a patient, most times overlooking the temporal aspect, which is crucial for patient monitoring. In this paper, we present: (1) a novel similarity search framework that identifies similar cases based on symptoms while considering the temporal evolution of the patients\u2019 conditions; and (2) a novel similarity function, called GCWei function, which is built upon the traditional Levenshtein similarity and improves the quality of the search by penalizing the similarity between non-related sets of symptoms. To identify relations, GCWei relies on well-established graph community detection procedures using all patients\u2019 historical data. By combining (1) and (2), we obtain a search approach called GCWei-based search, which efficiently retrieves similar cases with similar developments and thus gives the specialist a broader view of the patient\u2019s condition based on past cases of other patients. To demonstrate the value of our approach, we evaluate it both quantitatively and qualitatively using the recent and publicly available MIMIC-IV database.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11048638",
                    "name": "Jean R. Ponciano"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2299767030",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "fcff77cc5422b343d77149977f16ab3afc3b46bb",
            "title": "RADAR-MIX: How to Uncover Adversarial Attacks in Medical Image Analysis through Explainability",
            "abstract": "Medical image analysis is an important asset in the clinical process, providing resources to assist physicians in detecting diseases and making accurate diagnoses. Deep Learning (DL) models have been widely applied in these tasks, improving the ability to recognize patterns, including accurate and fast diagnosis. However, DL can present issues related to security violations that reduce the system\u2019s confidence. Uncovering these attacks before they happen and visualizing their behavior is challenging. Current solutions are limited to binary analysis of the problem, only classifying the sample into attacked or not attacked. In this paper, we propose the RADAR-MIX framework for uncovering adversarial attacks using quantitative metrics and analysis of the attack\u2019s behavior based on visual analysis. The RADAR-MIX provides a framework to assist practitioners in checking the possibility of adversarial examples in medical applications. Our experimental evaluation shows that the Deep-Fool and Carlini & Wagner (CW) attacks significantly evade the ResNet50V2 with a slight noise level of 0.001. Furthermore, our results revealed that the gradient-based methods, such as Gradient-weighted Class Activation Mapping (Grad-CAM) and SHapley Additive exPlanations (SHAP), achieved high attack detection effectiveness. While Local Interpretable Model-agnostic Explanations (LIME) presents low consistency, implying the most ability to uncover robust attacks supported by visual analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2170226211",
                    "name": "Erikson J\u00falio De Aguiar"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "01455fad2fb9f0469abefe23fffbacc0c1fd9690",
            "title": "A Deep Learning-based Radiomics Approach for COVID-19 Detection from CXR Images using Ensemble Learning Model",
            "abstract": "Medical image analysis plays a major role in aiding physicians in decision-making. Specifically in detecting COVID-19, Deep Learning (DL) and radiomic approaches have achieved promising results separately. However, DL results are hard to interpret/visualize, and the radiomic approach encompasses successive steps, such as image acquisition, image processing, segmentation, feature extraction, and analysis. In this paper, we integrate DL with radiomic approaches, aiding in detecting COVID-19. We use DL models to extract 128 relevant deep radiomic features to assess COVID-19 from several image sources of 392 representative chest X-ray (CXR) exams. We avoid successive radiomic steps by employing DL (transfer learning) from Imagenet's VGG-16, ResNet50V2, and DenseNet201 networks. We considered a set of Machine Learning (ML) algorithms to further validate our results, providing an ensemble model to detect COVID-19. Our experimental results show that our approach achieved 95% AUC using 128 relevant features from DenseNet201. Conversely, our ensemble model presented 91% AUC, indicating that deep learning-based radiomics could increase binary classification performance in a real scenario. In addition, we highlight that our approach can be adapted to create other DL-based radiomics tools. For reproducibility, we made our code available at https://github.com/usmarcv/CBMS-DL-based-radiomics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183568675",
                    "name": "M\u00e1rcus V. L. Costa"
                },
                {
                    "authorId": "2170226211",
                    "name": "Erikson J\u00falio De Aguiar"
                },
                {
                    "authorId": "134329314",
                    "name": "L. S. Rodrigues"
                },
                {
                    "authorId": "145758150",
                    "name": "Jonathan S. Ramos"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "3f020ffbfe8ab71fbfd2c55e13b3a5114c1bba22",
            "title": "TDANetVis: Suggesting temporal resolutions for graph visualization using zigzag persistent homology",
            "abstract": "Temporal graphs are commonly used to represent complex systems and track the evolution of their constituents over time. Visualizing these graphs is crucial as it allows one to quickly identify anomalies, trends, patterns, and other properties leading to better decision-making. In this context, the to-be-adopted temporal resolution is crucial in constructing and analyzing the layout visually. The choice of a resolution is critical, e.g., when dealing with temporally sparse graphs. In such cases, changing the temporal resolution by grouping events (i.e., edges) from consecutive timestamps, a technique known as timeslicing, can aid in the analysis and reveal patterns that might not be discernible otherwise. However, choosing a suitable temporal resolution is not trivial. In this paper, we propose TDANetVis, a methodology that suggests temporal resolutions potentially relevant for analyzing a given graph, i.e., resolutions that lead to substantial topological changes in the graph structure. To achieve this goal, TDANetVis leverages zigzag persistent homology, a well-established technique from Topological Data Analysis (TDA). To enhance visual graph analysis, TDANetVis also incorporates the colored barcode, a novel timeline-based visualization built on the persistence barcodes commonly used in TDA. We demonstrate the usefulness and effectiveness of TDANetVis through a usage scenario and a user study involving 27 participants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237985302",
                    "name": "Raphael Tinarrage"
                },
                {
                    "authorId": "11048638",
                    "name": "Jean R. Ponciano"
                },
                {
                    "authorId": "38265600",
                    "name": "Claudio D. G. Linhares"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "1998171",
                    "name": "Jorge Poco"
                }
            ]
        },
        {
            "paperId": "7563a9d0a231976ef51f16f85cd1979b79a8307d",
            "title": "CallMine: Fraud Detection and Visualization of Million-Scale Call Graphs",
            "abstract": "Given a million-scale dataset of who-calls-whom data containing imperfect labels, how can we detect existing and new fraud patterns? We propose CallMine, with carefully designed features and visualizations. Our CallMine method has the following properties: (a) Scalable, being linear on the input size, handling about 35 million records in around one hour on a stock laptop; (b) Effective, allowing natural interaction with human analysts; (c) Flexible, being applicable in both supervised and unsupervised settings; (d) Automatic, requiring no user-defined parameters. In the real world, in a multi-million-scale dataset, CallMine was able to detect fraudsters 7,000x faster, namely in a matter of hours, while expert humans took over 10 months to detect them. CIKM-ARP Categories: Application; Analytics and machine learning; Data presentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2203247479",
                    "name": "Saranya Vijayakumar"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "46260548",
                    "name": "Catalina Vajiac"
                },
                {
                    "authorId": "2867343",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "2164254613",
                    "name": "Pedro Fidalgo"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "2256724188",
                    "name": "Christos Faloutsos"
                }
            ]
        },
        {
            "paperId": "8a3c7496b18ecf0fbbed7d915b651e665aedb4de",
            "title": "TgrApp: Anomaly Detection and Visualization of Large-Scale Call Graphs",
            "abstract": "Given a million-scale dataset of who-calls-whom data containing imperfect labels, how can we detect existing and new fraud patterns? We propose TgrApp, which extracts carefully designed features and provides visualizations to assist analysts in spotting fraudsters and suspicious behavior. Our TgrApp method has the following properties: (a) Scalable, as it is linear on the input size; and (b) Effective, as it allows natural interaction with human analysts, and is applicable in both supervised and unsupervised settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2203247479",
                    "name": "Saranya Vijayakumar"
                },
                {
                    "authorId": "1662767314",
                    "name": "Xinyi Zheng"
                },
                {
                    "authorId": "2867343",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "2164254613",
                    "name": "Pedro Fidalgo"
                },
                {
                    "authorId": "2203100493",
                    "name": "Bruno Lages"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                }
            ]
        },
        {
            "paperId": "90e03bc4d9bab7401a8e45402afb852d362ad764",
            "title": "BoCS: Image Retrieval Using Explicable Methods",
            "abstract": "In recent years, image generation has been growing at a very fast pace, demanding specific systems for managing large image datasets. For example, we can mention the content-based image retrieval (CBIR) systems. Usually, they use a representation of feature vectors based on the images' visual content to store/retrieve them and to perform demanded queries. Currently, neural networks perform the task of generating image representations with great mastery. However, these networks usually create methods that are difficult to understand or to explain, which for some applications, such as medical decisionmaking systems, can be a significant disadvantage. Thinking about the explainability aspect, in this work, we present a new technique based on the bag of visual words (BoVW) which, in addition to generating promising explainable methods, has long been the state of the art for generating image representations. The results showed that the presented method BoCS overcomes similar methods and still has the potential to be further explored.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275538830",
                    "name": "Endi D. C. Silva"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        }
    ]
}