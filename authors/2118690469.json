{
    "authorId": "2118690469",
    "papers": [
        {
            "paperId": "1e80802a2fef00f2e10dfd4ab0ecce18ee2af82b",
            "title": "Exploring the Potential of Large Language Models in Graph Generation",
            "abstract": "Large language models (LLMs) have achieved great success in many fields, and recent works have studied exploring LLMs for graph discriminative tasks such as node classification. However, the abilities of LLMs for graph generation remain unexplored in the literature. Graph generation requires the LLM to generate graphs with given properties, which has valuable real-world applications such as drug discovery, while tends to be more challenging. In this paper, we propose LLM4GraphGen to explore the ability of LLMs for graph generation with systematical task designs and extensive experiments. Specifically, we propose several tasks tailored with comprehensive experiments to address key questions regarding LLMs' understanding of different graph structure rules, their ability to capture structural type distributions, and their utilization of domain knowledge for property-based graph generation. Our evaluations demonstrate that LLMs, particularly GPT-4, exhibit preliminary abilities in graph generation tasks, including rule-based and distribution-based generation. We also observe that popular prompting methods, such as few-shot and chain-of-thought prompting, do not consistently enhance performance. Besides, LLMs show potential in generating molecules with specific properties. These findings may serve as foundations for designing good LLMs based models for graph generation and provide valuable insights and further research.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2292399289",
                    "name": "Xu Chu"
                },
                {
                    "authorId": "2292430960",
                    "name": "Yuekui Yang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "35c07f14c5edd6dc87d0ad9ab9849bb6ab6055aa",
            "title": "Unsupervised Graph Neural Architecture Search with Disentangled Self-Supervision",
            "abstract": "The existing graph neural architecture search (GNAS) methods heavily rely on supervised labels during the search process, failing to handle ubiquitous scenarios where supervisions are not available. In this paper, we study the problem of unsupervised graph neural architecture search, which remains unexplored in the literature. The key problem is to discover the latent graph factors that drive the formation of graph data as well as the underlying relations between the factors and the optimal neural architectures. Handling this problem is challenging given that the latent graph factors together with architectures are highly entangled due to the nature of the graph and the complexity of the neural architecture search process. To address the challenge, we propose a novel Disentangled Self-supervised Graph Neural Architecture Search (DSGAS) model, which is able to discover the optimal architectures capturing various latent graph factors in a self-supervised fashion based on unlabeled graph data. Specifically, we first design a disentangled graph super-network capable of incorporating multiple architectures with factor-wise disentanglement, which are optimized simultaneously. Then, we estimate the performance of architectures under different factors by our proposed self-supervised training with joint architecture-graph disentanglement. Finally, we propose a contrastive search with architecture augmentations to discover architectures with factor-specific expertise. Extensive experiments on 11 real-world datasets demonstrate that the proposed model is able to achieve state-of-the-art performance against several baseline methods in an unsupervised manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "1993657377",
                    "name": "Guangyao Shen"
                },
                {
                    "authorId": "2279330465",
                    "name": "Shiqi Shen"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "38977b3ffc5edd84f9ce942f2299ce65b966e6f8",
            "title": "LLM-Enhanced Causal Discovery in Temporal Domain from Interventional Data",
            "abstract": "In the field of Artificial Intelligence for Information Technology Operations (AIOps), causal discovery is pivotal for operation and maintenance of graph construction, facilitating downstream industrial tasks such as root cause analysis. Temporal causal discovery, as an emerging method, aims to identify temporal causal relationships between variables directly from observations by utilizing interventional data. However, existing methods mainly focus on synthetic datasets with heavy reliance on interventional targets and ignore the textual information hidden in real-world systems, failing to conduct causal discovery for real industrial scenarios. To tackle this problem, in this paper we propose to investigate temporal causal discovery in industrial scenarios, which faces two critical challenges: 1) how to discover causal relationships without the interventional targets that are costly to obtain in practice, and 2) how to discover causal relations via leveraging the textual information in systems which can be complex yet abundant in industrial contexts. To address these challenges, we propose the RealTCD framework, which is able to leverage domain knowledge to discover temporal causal relationships without interventional targets. Specifically, we first develop a score-based temporal causal discovery method capable of discovering causal relations for root cause analysis without relying on interventional targets through",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260834123",
                    "name": "Peiwen Li"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2260668917",
                    "name": "Yuan Meng"
                },
                {
                    "authorId": "71883951",
                    "name": "Fang-lin Shen"
                },
                {
                    "authorId": "2249140468",
                    "name": "Yue Li"
                },
                {
                    "authorId": "2249121211",
                    "name": "Jialong Wang"
                },
                {
                    "authorId": "2298224490",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2298096084",
                    "name": "Wenweu Zhu"
                }
            ]
        },
        {
            "paperId": "4f015f1a144940193de5aa4687ad58e2ffcbbfb1",
            "title": "Multi-Modal Generative AI: Multi-modal LLM, Diffusion and Beyond",
            "abstract": "Multi-modal generative AI has received increasing attention in both academia and industry. Particularly, two dominant families of techniques are: i) The multi-modal large language model (MLLM) such as GPT-4V, which shows impressive ability for multi-modal understanding; ii) The diffusion model such as Sora, which exhibits remarkable multi-modal powers, especially with respect to visual generation. As such, one natural question arises: Is it possible to have a unified model for both understanding and generation? To answer this question, in this paper, we first provide a detailed review of both MLLM and diffusion models, including their probabilistic modeling procedure, multi-modal architecture design, and advanced applications to image/video large language models as well as text-to-image/video generation. Then, we discuss the two important questions on the unified model: i) whether the unified model should adopt the auto-regressive or diffusion probabilistic modeling, and ii) whether the model should utilize a dense architecture or the Mixture of Experts(MoE) architectures to better support generation and understanding, two objectives. We further provide several possible strategies for building a unified model and analyze their potential advantages and disadvantages. We also summarize existing large-scale multi-modal datasets for better model pretraining in the future. To conclude the paper, we present several challenging future directions, which we believe can contribute to the ongoing advancement of multi-modal generative AI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191043236",
                    "name": "Hong Chen"
                },
                {
                    "authorId": "2256599610",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2261888564",
                    "name": "Yuwei Zhou"
                },
                {
                    "authorId": "2268807072",
                    "name": "Bin Huang"
                },
                {
                    "authorId": "2129509567",
                    "name": "Yipeng Zhang"
                },
                {
                    "authorId": "2260613991",
                    "name": "Wei Feng"
                },
                {
                    "authorId": "2261888448",
                    "name": "Houlun Chen"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "1993657480",
                    "name": "Siao Tang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "7ede5d34d3e418c102fae9677554cdefd56497aa",
            "title": "Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification",
            "abstract": "Graph Neural Architecture Search (GNAS) has achieved superior performance on various graph-structured tasks. However, existing GNAS studies overlook the applications of GNAS in resource-constraint scenarios. This paper proposes to design a joint graph data and architecture mechanism, which identifies important sub-architectures via the valuable graph data. To search for optimal lightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural Architecture Search with Graph SparsIfication and Network Pruning (GASSIP) method. In particular, GASSIP comprises an operation-pruned architecture search module to enable efficient lightweight GNN search. Meanwhile, we design a novel curriculum graph data sparsification module with an architecture-aware edge-removing difficulty measurement to help select optimal sub-architectures. With the aid of two differentiable masks, we iteratively optimize these two modules to efficiently search for the optimal lightweight architecture. Extensive experiments on five benchmarks demonstrate the effectiveness of GASSIP. Particularly, our method achieves on-par or even higher node classification performance with half or fewer model parameters of searched GNNs and a sparser graph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181504062",
                    "name": "Beini Xie"
                },
                {
                    "authorId": "2140312584",
                    "name": "Heng Chang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2308044035",
                    "name": "Simin Wu"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2260668917",
                    "name": "Yuan Meng"
                },
                {
                    "authorId": "2277687596",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "854b58d5126fd536e9e512069452370641e346a2",
            "title": "Causal-Aware Graph Neural Architecture Search under Distribution Shifts",
            "abstract": "Graph NAS has emerged as a promising approach for autonomously designing GNN architectures by leveraging the correlations between graphs and architectures. Existing methods fail to generalize under distribution shifts that are ubiquitous in real-world graph scenarios, mainly because the graph-architecture correlations they exploit might be spurious and varying across distributions. We propose to handle the distribution shifts in the graph architecture search process by discovering and exploiting the causal relationship between graphs and architectures to search for the optimal architectures that can generalize under distribution shifts. The problem remains unexplored with following challenges: how to discover the causal graph-architecture relationship that has stable predictive abilities across distributions, and how to handle distribution shifts with the discovered causal graph-architecture relationship to search the generalized graph architectures. To address these challenges, we propose Causal-aware Graph Neural Architecture Search (CARNAS), which is able to capture the causal graph-architecture relationship during the architecture search process and discover the generalized graph architecture under distribution shifts. Specifically, we propose Disentangled Causal Subgraph Identification to capture the causal subgraphs that have stable prediction abilities across distributions. Then, we propose Graph Embedding Intervention to intervene on causal subgraphs within the latent space, ensuring that these subgraphs encapsulate essential features for prediction while excluding non-causal elements. Additionally, we propose Invariant Architecture Customization to reinforce the causal invariant nature of the causal subgraphs, which are utilized to tailor generalized graph architectures. Extensive experiments demonstrate that CARNAS achieves advanced out-of-distribution generalization ability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260834123",
                    "name": "Peiwen Li"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2249121211",
                    "name": "Jialong Wang"
                },
                {
                    "authorId": "2298224490",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "b9d5e237ca163c719aed189d3fc8efc3748bc509",
            "title": "Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts",
            "abstract": "Dynamic graph neural networks (DyGNNs) currently struggle with handling distribution shifts that are inherent in dynamic graphs. Existing work on DyGNNs with out-of-distribution settings only focuses on the time domain, failing to handle cases involving distribution shifts in the spectral domain. In this paper, we discover that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain, and propose to study distribution shifts on dynamic graphs in the spectral domain for the first time. However, this investigation poses two key challenges: i) it is non-trivial to capture different graph patterns that are driven by various frequency components entangled in the spectral domain; and ii) it remains unclear how to handle distribution shifts with the discovered spectral patterns. To address these challenges, we propose Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts (SILD), which can handle distribution shifts on dynamic graphs by capturing and utilizing invariant and variant spectral patterns. Specifically, we first design a DyGNN with Fourier transform to obtain the ego-graph trajectory spectrums, allowing the mixed dynamic graph patterns to be transformed into separate frequency components. We then develop a disentangled spectrum mask to filter graph dynamics from various frequency components and discover the invariant and variant spectral patterns. Finally, we propose invariant spectral filtering, which encourages the model to rely on invariant patterns for generalization under distribution shifts. Experimental results on synthetic and real-world dynamic graph datasets demonstrate the superiority of our method for both node classification and link prediction tasks under distribution shifts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2273698217",
                    "name": "Zhou Qin"
                },
                {
                    "authorId": "2070076938",
                    "name": "Weigao Wen"
                },
                {
                    "authorId": "2273682025",
                    "name": "Hui Xue"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "0e87f4c721c2a5302e9cf7e2b3a6ceacfaceb469",
            "title": "LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?",
            "abstract": "In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs\u2019 capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs\u2019 competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs\u2019 spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts ( DST2 ) for LLMs on dynamic graphs to enhance LLMs\u2019 spatial-temporal understanding abilities. Our main observations are: 1) LLMs have prelim-inary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs\u2019 spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes will be open-sourced at publication time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2308044035",
                    "name": "Simin Wu"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "8dd0869fd671682fa2d8e5f5f0ef14ecef04df0d",
            "title": "Dynamic Heterogeneous Graph Attention Neural Architecture Search",
            "abstract": "Dynamic heterogeneous graph neural networks (DHGNNs) have been shown to be effective in handling the ubiquitous dynamic heterogeneous graphs. However, the existing DHGNNs are hand-designed, requiring extensive human efforts and failing to adapt to diverse dynamic heterogeneous graph scenarios. In this paper, we propose to automate the design of DHGNN, which faces two major challenges: 1) how to design the search space to jointly consider the spatial-temporal dependencies and heterogeneous interactions in graphs; 2) how to design an efficient search algorithm in the potentially large and complex search space. To tackle these challenges, we propose a novel Dynamic Heterogeneous Graph Attention Search (DHGAS) method. Our proposed method can automatically discover the optimal DHGNN architecture and adapt to various dynamic heterogeneous graph scenarios without human guidance. In particular, we first propose a unified dynamic heterogeneous graph attention (DHGA) framework, which enables each node to jointly attend its heterogeneous and dynamic neighbors. Based on the framework, we design a localization space to determine where the attention should be applied and a parameterization space to determine how the attention should be parameterized. Lastly, we design a multi-stage differentiable search algorithm to efficiently explore the search space. Extensive experiments on real-world dynamic heterogeneous graph datasets demonstrate that our proposed method significantly outperforms state-of-the-art baselines for tasks including link prediction, node classification and node regression. To the best of our knowledge, DHGAS is the first dynamic heterogeneous graph neural architecture search method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2099587015",
                    "name": "Zhou Qin"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "b4646815d5107489e7660d71e83c6584a926d280",
            "title": "Graph Meets LLMs: Towards Large Graph Models",
            "abstract": "Large models have emerged as the most recent groundbreaking achievements in artificial intelligence, and particularly machine learning. However, when it comes to graphs, large models have not achieved the same level of success as in other fields, such as natural language processing and computer vision. In order to promote applying large models for graphs forward, we present a perspective paper to discuss the challenges and opportunities associated with developing large graph models. First, we discuss the desired characteristics of large graph models. Then, we present detailed discussions from three key perspectives: representation basis, graph data, and graph models. In each category, we provide a brief overview of recent advances and highlight the remaining challenges together with our visions. Finally, we discuss valuable applications of large graph models. We believe this perspective can encourage further investigations into large graph models, ultimately pushing us one step closer towards artificial general intelligence (AGI). We are the first to comprehensively study large graph models, to the best of our knowledge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        }
    ]
}