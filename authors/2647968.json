{
    "authorId": "2647968",
    "papers": [
        {
            "paperId": "220603c36fe10a007671128dca35fd16fa07ad88",
            "title": "KluSIM: Speeding up K-Medoids Clustering over Dimensional Data with Metric Access Method",
            "abstract": ".",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2299605299",
                    "name": "L. Teixeira"
                },
                {
                    "authorId": "2299673373",
                    "name": "I. A. R. Eleut\u00e9rio"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2299767030",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "913ffd0a2e7f794e9b2e60b9728673044be47b2a",
            "title": "T-NET: Weakly Supervised Graph Learning for Combatting Human Trafficking",
            "abstract": "Human trafficking (HT) for forced sexual exploitation, often described as modern-day slavery, is a pervasive problem that affects millions of people worldwide. Perpetrators of this crime post advertisements (ads) on behalf of their victims on adult service websites (ASW). These websites typically contain hundreds of thousands of ads including those posted by independent escorts, massage parlor agencies and spammers (fake ads). Detecting suspicious activity in these ads is difficult and developing data-driven methods is challenging due to the hard-to-label, complex and sensitive nature of the data. \n\nIn this paper, we propose T-Net, which unlike previous solutions, formulates this problem as weakly supervised classification. Since it takes several months to years to investigate a case and obtain a single definitive label, we design domain-specific signals or indicators that provide weak labels. T-Net also looks into connections between ads and models the problem as a graph learning task instead of classifying ads independently. We show that T-Net outperforms all baselines on a real-world dataset of ads by 7% average weighted F1 score. Given that this data contains personally identifiable information, we also present a realistic data generator and provide the first publicly available dataset in this domain which may be leveraged by the wider research community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48761500",
                    "name": "Pratheeksha Nair"
                },
                {
                    "authorId": "2273909422",
                    "name": "Javin Liu"
                },
                {
                    "authorId": "46260548",
                    "name": "Catalina Vajiac"
                },
                {
                    "authorId": "3254065",
                    "name": "Andreas M. Olligschlaeger"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2115254512",
                    "name": "Cara Jones"
                },
                {
                    "authorId": "2256724188",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "96a363534c9394ad20b236dfa1fc32367a2f2f66",
            "title": "MIGUE-Sim: Speeding Up Similarity Queries with Native RDBMS Resources",
            "abstract": "Many applications require storing, managing, and retrieving complex data, such as multidimensional vectors and images in databases. In this paper, we propose MIGUE-Sim, a system to quickly execute exact Range and kNN similarity queries in Postgres. The queries are expressed following a straightforward, SQL-compatible representation seamlessly integrated into the language, whereas the system executes each query using just the native resources of Postgres. MIGUE-Sim uses the Postgres's Cube native extension to perform kNN faster, using the GIST R-Tree index available. The execution of kNN in our system without any index overcame our main competitor by up to 10% in execution time. However, when using GIST R-Tree, MIGUE-Sim can significantly speed up queries - experiments revealed that MIGUE-Sim is up to 96% faster than our closest competitor. We contribute with a framework that uses existing index structures from Postgres to speed up kNN queries with no modifications on the RDBMS; with the evaluation of different ways to write similarity queries in plain SQL; with the implementation of kNN queries with indices already available on Postgres. Our approach is easy to understand, to use, and it is extensible to include other distance functions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162902964",
                    "name": "Igor A. R. Eleut\u00e9rio"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2299605299",
                    "name": "L. Teixeira"
                },
                {
                    "authorId": "2299767030",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "c58051e0100b201516286e20244519ee49a53658",
            "title": "A symptom-based community-weighted similarity approach for inpatient health condition monitoring",
            "abstract": "Given a patient\u2019s series of exams conducted over time, how can we identify cases with similar abnormalities or symptoms? Hospitals and medical facilities continuously monitor patients through periodic exams, a crucial practice for assessing their current condition and potential progression, thereby supporting decision-making. However, similarity-based searches often consider several exams of a patient, most times overlooking the temporal aspect, which is crucial for patient monitoring. In this paper, we present: (1) a novel similarity search framework that identifies similar cases based on symptoms while considering the temporal evolution of the patients\u2019 conditions; and (2) a novel similarity function, called GCWei function, which is built upon the traditional Levenshtein similarity and improves the quality of the search by penalizing the similarity between non-related sets of symptoms. To identify relations, GCWei relies on well-established graph community detection procedures using all patients\u2019 historical data. By combining (1) and (2), we obtain a search approach called GCWei-based search, which efficiently retrieves similar cases with similar developments and thus gives the specialist a broader view of the patient\u2019s condition based on past cases of other patients. To demonstrate the value of our approach, we evaluate it both quantitatively and qualitatively using the recent and publicly available MIMIC-IV database.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11048638",
                    "name": "Jean R. Ponciano"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2299767030",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "7563a9d0a231976ef51f16f85cd1979b79a8307d",
            "title": "CallMine: Fraud Detection and Visualization of Million-Scale Call Graphs",
            "abstract": "Given a million-scale dataset of who-calls-whom data containing imperfect labels, how can we detect existing and new fraud patterns? We propose CallMine, with carefully designed features and visualizations. Our CallMine method has the following properties: (a) Scalable, being linear on the input size, handling about 35 million records in around one hour on a stock laptop; (b) Effective, allowing natural interaction with human analysts; (c) Flexible, being applicable in both supervised and unsupervised settings; (d) Automatic, requiring no user-defined parameters. In the real world, in a multi-million-scale dataset, CallMine was able to detect fraudsters 7,000x faster, namely in a matter of hours, while expert humans took over 10 months to detect them. CIKM-ARP Categories: Application; Analytics and machine learning; Data presentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2203247479",
                    "name": "Saranya Vijayakumar"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "46260548",
                    "name": "Catalina Vajiac"
                },
                {
                    "authorId": "2867343",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "2164254613",
                    "name": "Pedro Fidalgo"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "2256724188",
                    "name": "Christos Faloutsos"
                }
            ]
        },
        {
            "paperId": "8a3c7496b18ecf0fbbed7d915b651e665aedb4de",
            "title": "TgrApp: Anomaly Detection and Visualization of Large-Scale Call Graphs",
            "abstract": "Given a million-scale dataset of who-calls-whom data containing imperfect labels, how can we detect existing and new fraud patterns? We propose TgrApp, which extracts carefully designed features and provides visualizations to assist analysts in spotting fraudsters and suspicious behavior. Our TgrApp method has the following properties: (a) Scalable, as it is linear on the input size; and (b) Effective, as it allows natural interaction with human analysts, and is applicable in both supervised and unsupervised settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2203247479",
                    "name": "Saranya Vijayakumar"
                },
                {
                    "authorId": "1662767314",
                    "name": "Xinyi Zheng"
                },
                {
                    "authorId": "2867343",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "2164254613",
                    "name": "Pedro Fidalgo"
                },
                {
                    "authorId": "2203100493",
                    "name": "Bruno Lages"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                }
            ]
        },
        {
            "paperId": "d71ebaf2bd6772693351bcdc8b6da71e3f6afeb6",
            "title": "Exploratory Data Analysis in Electronic Health Records Graphs: Intuitive Features and Visualization Tools",
            "abstract": "Given a large, unlabeled set of Electronic Health Records (EHRs) acquired from multiple hospitals, how can we analyze the available entities and identify relationships in the data? Also, how can we perform Exploratory Data Analysis (EDA) over such EHR data? Many medical institutions generate EHRs as tabular data with entities and attributes in common. However, due to a large number of records, attributes, and high cardinality, exploring the different datasets and finding patterns and insights become laborious and prone to errors. In this work, we propose GraF- Eda for EDA over EHR data from different institutions. GraF-EDA models EHRs as time-evolving graphs, allowing the interoperability of such data into a single representation. We extract meaningful features from the graph nodes and provide intuitive visualizations to improve data explainability. We evaluate GraF-EDA with four COVID-19 datasets from hospitals of the S\u00e3o Paulo state, Brazil, resulting in million-scale graphs. Our method identified correlations, similarities and dissimilarities among medical treatments, exams, clinics, and outcomes. With the visual tools provided by GraF-EDA, we were able to spot cases of interest and check more details about them. Our results indicate that GraF-EDA is a fast, effective, open-sourced tool for EDA of EHRs from multiple institutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "144381171",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "2d334c37c9e9840d8a032fa48d8c9bce8fffc197",
            "title": "Sketch+ for Visual and Correlation-Based Exploratory Data Analysis: A Case Study with COVID-19 Databases",
            "abstract": "The amount of data daily generated by different sources grows exponentially and brings new challenges to the information technology experts. The recorded data usually include heterogeneous attribute types, such as the traditional date, numerical, textual, and categorical information, as well as complex ones, such as images, videos, and multidimensional data. Simply posing similarity queries over such records can underestimate the semantics and potential usefulness of particular attributes. In this context, the Exploratory Data Analysis (EDA) technology is well-suited to understand data and perform knowledge extraction and visualization of existing patterns. In this paper, we propose Sketch+ , a technique and a corresponding supporting tool to compare electronic health records (provided by hospitals) by similarity, supporting correlation-based exploratory analysis over attributes of different types and allowing data preprocessing tasks for visualization and knowledge extraction. Sketch+ computes partial and overall data correlation considering distance spaces induced by the attributes. It employs both ANOVA and association rules with lift correlations to study relationships between variables, allowing extensive data analysis. Among the tools provided, a pixel-oriented one drives the analysts to observe visual correlations among dates, categorical and numerical attributes. As a running case study, we employed three open databases of COVID-19 cases, showing that specialists can benefit from the inference modules of Sketch+ to analyze electronic records. The study highlights how Sketch+ can be employed to spot strong correlations among tuples and attributes, with statistically significant results. The exploratory analysis has been shown to be an essential complement for similarity search tasks, identifying and evaluating patterns from heterogeneous attributes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "134329314",
                    "name": "L. S. Rodrigues"
                },
                {
                    "authorId": "1791547",
                    "name": "M. X. Ribeiro"
                },
                {
                    "authorId": "144381171",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "341489abe1b665a612c9724b82b1824f65603b45",
            "title": "FeatSet+: Visual Features Extracted from Public Image Datasets",
            "abstract": "Real-world applications generate large amounts of images every day. With the generalized use of social media, users frequently share images acquired by smartphones. Also, hospitals, clinics, exhibits, factories, and other facilities generate images with potential use for many applications. Processing the generated images usually requires feature extraction, which can be time-consuming and laborious. In this paper, we present FeatSet+, a compilation of color, texture and shape visual features extracted from 17 open image datasets reported in the literature. FeatSet+ provides a collection of 11 distinct visual features, extracted by well-known Feature Extraction Methods (FEMs) such as LBP, Haralick, and Color Layout. We organized the available features in a standard collection, including the metadata and labels, when available. Eleven of the datasets also contain classes, which aid the evaluation of supervised methods such as classifiers and clustering tasks. FeatSet+ is available for download in a public repository as sql scripts and csv files. Additionally, FeatSet+ provides a description of the domain of each dataset, including the reference to the original work and link. We show the potential applicability of FeatSet+ in four computational tasks: multi-attribute analysis and retrieval, visual analysis using Multidimensional Scaling (MDS) and Principal Components Analysis (PCA), global feature classification, and dimensionality reduction. FeatSet+ can be employed to evaluate supervised and non-supervised learning tasks, also widely supporting Content-Based Image Retrieval (CBIR) applications and complex data indexing using Metric Access Methods (MAMs).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "3440669",
                    "name": "L. C. Scabora"
                },
                {
                    "authorId": "40991665",
                    "name": "Guilherme F. Zabot"
                },
                {
                    "authorId": "2067919824",
                    "name": "M. A. Gutierrez"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        },
        {
            "paperId": "8f748c38809a788fe88512165096d76fcd0f7bd9",
            "title": "Analysis of vertebrae without fracture on spine MRI to assess bone fragility: A Comparison of Traditional Machine Learning and Deep Learning",
            "abstract": "Bone mineral density (BMD) is the international standard for evaluating osteoporosis/osteopenia. The success rate of BMD alone in estimating the risk of vertebral fragility fracture (VFF) is approximately 50%, making BMD far from ideal in predicting VFF. In addition, whether or not a patient has been diagnosed with osteoporosis or osteopenia, he or she may suffer a VFF. For this reason, we conducted an extensive empirical study to assess VFFs in postmenopausal women. We considered a representative dataset of 94 T1- and T2-weighted routine spine MRI (with osteopenia or osteoporosis), split into 2,400 samples (slices). Comparing the classification results of machine learning and deep learning (DL) techniques showed that DL generally achieved better results at the cost of higher computational power and hard explainability. ResNet achieved the best results in discriminating patients from groups with and without VFFs with 83% accuracy and 90% AUC (with a confidence interval of 99%). Our results represent a significant step toward prospective and longitudinal studies investigating methods to achieve higher accuracy in predicting VFFs based on spine MRI features of vertebrae without fracture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145758150",
                    "name": "Jonathan S. Ramos"
                },
                {
                    "authorId": "2170226211",
                    "name": "Erikson J\u00falio De Aguiar"
                },
                {
                    "authorId": "134092631",
                    "name": "Ivar Vargas Belizario"
                },
                {
                    "authorId": "2183568675",
                    "name": "M\u00e1rcus V. L. Costa"
                },
                {
                    "authorId": "8181516",
                    "name": "J. G. Maciel"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "1401224278",
                    "name": "M. Nogueira-Barbosa"
                },
                {
                    "authorId": "2056162982",
                    "name": "A. J. Traina"
                }
            ]
        }
    ]
}