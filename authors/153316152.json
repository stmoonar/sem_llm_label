{
    "authorId": "153316152",
    "papers": [
        {
            "paperId": "01934cee257cdb24aec4245221ccb1361c3555db",
            "title": "Unsupervised Multiplex Graph learning with Complementary and Consistent Information",
            "abstract": "Unsupervised multiplex graph learning (UMGL) has been shown to achieve significant effectiveness for different downstream tasks by exploring both complementary information and consistent information among multiple graphs. However, previous methods usually overlook the issues in practical applications, i.e., the out-of-sample issue and the noise issue. To address the above issues, in this paper, we propose an effective and efficient UMGL method to explore both complementary and consistent information. To do this, our method employs multiple MLP encoders rather than graph convolutional network (GCN) to conduct representation learning with two constraints, i.e., preserving the local graph structure among nodes to handle the out-of-sample issue, and maximizing the correlation of multiple node representations to handle the noise issue. Comprehensive experiments demonstrate that our proposed method achieves superior effectiveness and efficiency over the comparison methods and effectively tackles those two issues. Code is available at https://github.com/LarryUESTC/CoCoMG.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144454465",
                    "name": "Liang Peng"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                }
            ]
        },
        {
            "paperId": "189ab24ec496d3c78b6bdb9ab684906cf884a8f1",
            "title": "A Clustering Framework for Unsupervised and Semi-supervised New Intent Discovery",
            "abstract": "New intent discovery is of great value to natural language processing, allowing for a better understanding of user needs and providing friendly services. However, most existing methods struggle to capture the complicated semantics of discrete text representations when limited or no prior knowledge of labeled data is available. To tackle this problem, we propose a novel clustering framework, USNID, for unsupervised and semi-supervised new intent discovery, which has three key technologies. First, it fully utilizes unsupervised or semi-supervised data to mine shallow semantic similarity relations and provide well-initialized representations for clustering. Second, it designs a centroid-guided clustering mechanism to address the issue of cluster allocation inconsistency and provide high-quality self-supervised targets for representation learning. Third, it captures high-level semantics in unsupervised or semi-supervised data to discover fine-grained intent-wise clusters by optimizing both cluster-level and instance-level objectives. We also propose an effective method for estimating the cluster number in open-world scenarios without knowing the number of new intents beforehand. USNID performs exceptionally well on several benchmark intent datasets, achieving new state-of-the-art results in unsupervised and semi-supervised new intent discovery and demonstrating robust performance with different cluster numbers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13390595",
                    "name": "Hanlei Zhang"
                },
                {
                    "authorId": "153194461",
                    "name": "Huanlin Xu"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2066587074",
                    "name": "Fei Long"
                },
                {
                    "authorId": "49834418",
                    "name": "Kai Gao"
                }
            ]
        },
        {
            "paperId": "1b7dd80616ace40b49cf83f8f66a48df6e4dc90f",
            "title": "An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis",
            "abstract": "Multi-sequence MRI is valuable in clinical settings for reliable diagnosis and treatment prognosis, but some sequences may be unusable or missing for various reasons. To address this issue, MRI synthesis is a potential solution. Recent deep learning-based methods have achieved good performance in combining multiple available sequences for missing sequence synthesis. Despite their success, these methods lack the ability to quantify the contributions of different input sequences and estimate the quality of generated images, making it hard to be practical. Hence, we propose an explainable task-specific synthesis network, which adapts weights automatically for specific sequence generation tasks and provides interpretability and reliability from two sides: (1) visualize the contribution of each input sequence in the fusion stage by a trainable task-specific weighted average module; (2) highlight the area the network tried to refine during synthesizing by a task-specific attention module. We conduct experiments on the BraTS2021 dataset of 1251 subjects, and results on arbitrary sequence synthesis indicate that the proposed method achieves better performance than the state-of-the-art methods. Our code is available at \\url{https://github.com/fiy2W/mri_seq2seq}.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2112708227",
                    "name": "Luyi Han"
                },
                {
                    "authorId": "2146331891",
                    "name": "Tianyu Zhang"
                },
                {
                    "authorId": "2108831879",
                    "name": "Yunzhi Huang"
                },
                {
                    "authorId": "10669778",
                    "name": "Haoran Dou"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "48146495",
                    "name": "Yuan Gao"
                },
                {
                    "authorId": "2828701",
                    "name": "Chun-Ta Lu"
                },
                {
                    "authorId": "2221011241",
                    "name": "Tan Tao"
                },
                {
                    "authorId": "1794036",
                    "name": "R. Mann"
                }
            ]
        },
        {
            "paperId": "292f3e534bf335c6afadaa33a527e2c14ab2566d",
            "title": "Synthesis-based Imaging-Differentiation Representation Learning for Multi-Sequence 3D/4D MRI",
            "abstract": "Multi-sequence MRIs can be necessary for reliable diagnosis in clinical practice due to the complimentary information within sequences. However, redundant information exists across sequences, which interferes with mining efficient representations by learning-based models. To handle various clinical scenarios, we propose a sequence-to-sequence generation framework (Seq2Seq) for imaging-differentiation representation learning. In this study, not only do we propose arbitrary 3D/4D sequence generation within one model to generate any specified target sequence, but also we are able to rank the importance of each sequence based on a new metric estimating the difficulty of a sequence being generated. Furthermore, we also exploit the generation inability of the model to extract regions that contain unique information for each sequence. We conduct extensive experiments using three datasets including a toy dataset of 20,000 simulated subjects, a brain MRI dataset of 1251 subjects, and a breast MRI dataset of 2101 subjects, to demonstrate that (1) top-ranking sequences can be used to replace complete sequences with non-inferior performance; (2) combining MRI with our imaging-differentiation map leads to better performance in clinical tasks such as glioblastoma MGMT promoter methylation status prediction and breast cancer pathological complete response status prediction. Our code is available at https://github.com/fiy2W/mri_seq2seq.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2112708227",
                    "name": "Luyi Han"
                },
                {
                    "authorId": "145695707",
                    "name": "T. Tan"
                },
                {
                    "authorId": "2189911154",
                    "name": "Tianyu Zhang"
                },
                {
                    "authorId": "2108831879",
                    "name": "Yunzhi Huang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "48146495",
                    "name": "Yuan Gao"
                },
                {
                    "authorId": "32649341",
                    "name": "Jonas Teuwen"
                },
                {
                    "authorId": "1794036",
                    "name": "R. Mann"
                }
            ]
        },
        {
            "paperId": "2f25de023d0b23b338cda5d51e89fde3b3857028",
            "title": "Distinguish Abnormal Tensile and Torsional Stresses of Steel Wire Rope Using Magnetoelastic Effect",
            "abstract": "Nondestructive testing and structural health monitoring are highly important for the safe operation of industrial systems. Steel wire ropes are key load-bearing components in these systems. Under the condition where multiple wire ropes are used simultaneously, the safe operation of the system will then be affected if the stress in these wire ropes is inconsistent. To date, research has focused mainly on changes in the tensile stress in steel wire ropes. Steel wire ropes are also affected by torsional stress during actual operation. The spiral structure of the wire rope means that when the torsional stress in the wire rope changes, then the tensile stress will also change. Abnormal tensile or torsional stresses in a wire rope will cause abnormal tensile stress in the wire rope. However, the treatment methods for these two stresses are different. It is thus necessary to distinguish the tensile and torsional stresses in steel wire ropes. This study uses the magnetoelastic effect to measure abnormal tensile and torsional stresses in steel wire rope through the time-domain and frequency-domain characteristics of a white noise signal. The method is to detect and distinguish the relative change of stresses in the multiple steel wire ropes. The frequency spectrum of the detection signal is used to detect abnormal stresses. The root mean square and center of gravity frequency of the detection signal are extracted to distinguish abnormal tensile and torsional stresses in multiple steel wire ropes and monitor its health.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153711124",
                    "name": "Wei Gao"
                },
                {
                    "authorId": "2109567744",
                    "name": "Donglai Zhang"
                },
                {
                    "authorId": "8073017",
                    "name": "Xiaolan Yan"
                },
                {
                    "authorId": "2694780",
                    "name": "Enchao Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                }
            ]
        },
        {
            "paperId": "536d22c496474cf8e1313d1a67291603c869dee5",
            "title": "Advances in spatiotemporal graph neural network prediction research",
            "abstract": "ABSTRACT Being a kind of non-Euclidean data, spatiotemporal graph data exists everywhere from traffic flow, air quality index to crime case, etc. Unlike the raster data, the irregular and disordered characteristics of spatiotemporal graph data have attracted the research interest of scholars, with the prediction of spatiotemporal graph data being one of the research hot spots. The emergence of spatiotemporal graph neural networks (ST-GNNs) provides a new insight for solving the problem of obtaining spatial correlation for spatiotemporal graph data prediction while achieving state-of-the-art performance. In this paper, a comprehensive survey of research on ST-GNNs prediction domain is presented, where the background of ST-GNNs is introduced before the computational paradigm of ST-GNN is thoroughly reviewed. From the perspective of model construction, 59 well-known models in recent years are classified and discussed. Some of these models are further analyzed in terms of performance and efficiency. Subsequently, the categories and application fields of spatiotemporal graph data are summarized, providing a clear idea of technology selection for different applications. Finally, the evolution history and future direction of ST-GNNs are also summarized, to facilitate future researchers to timely understand the current state of prediction research by ST-GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130418648",
                    "name": "Jianghong Zhao"
                },
                {
                    "authorId": "2222837513",
                    "name": "Yi Wang"
                },
                {
                    "authorId": "2114437255",
                    "name": "X. Dou"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2223110656",
                    "name": "Ming Guo"
                },
                {
                    "authorId": "2311645652",
                    "name": "Ruiju Zhang"
                },
                {
                    "authorId": "2223168589",
                    "name": "Haimeng Li"
                }
            ]
        },
        {
            "paperId": "5d00e8f305d20ad937938fa4db054a33186626f7",
            "title": "AutoGT: Automated Graph Transformer Architecture Search",
            "abstract": "Although Transformer architectures have been successfully applied to graph data with the advent of Graph Transformer, the current design of Graph Transformers still heavily relies on human labor and expertise knowledge to decide on proper neural architectures and suitable graph encoding strategies at each Transformer layer. In literature, there have been some works on the automated design of Transformers focusing on non-graph data such as texts and images without considering graph encoding strategies, which fail to handle the non-euclidean graph data. In this paper, we study the problem of automated graph Transformers, for the first time. However, solving these problems poses the following challenges: i) how can we design a unified search space for graph Transformer, and ii) how to deal with the coupling relations between Transformer architectures and the graph encodings of each Transformer layer. To address these challenges, we propose Automated Graph Transformer (AutoGT), a neural architecture search framework that can automatically discover the optimal graph Transformer architectures by joint optimization of Transformer architecture and graph encoding strategies. Specifically, we first propose a unified graph Transformer formulation that can represent most state-ofthe-art graph Transformer architectures. Based upon the unified formulation, we further design the graph Transformer search space that includes both candidate architectures and various graph encodings. To handle the coupling relations, we propose a novel encoding-aware performance estimation strategy by gradually training and splitting the supernets according to the correlations between graph encodings and architectures. The proposed strategy can provide a more consistent and fine-grained performance prediction when evaluating the jointly optimized graph encodings and architectures. Extensive experiments and ablation studies show that our proposed AutoGT gains sufficient improvement over state-of-the-art hand-crafted baselines on all datasets, demonstrating its effectiveness and wide applicability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128158461",
                    "name": "Zizhao Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "133761917",
                    "name": "Chaoyu Guan"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "669d2e30753eb215bf14bcde18081bb60385c886",
            "title": "EnhancE: Enhanced Entity and Relation Embedding for Knowledge Hypergraph Link Prediction",
            "abstract": "Knowledge Hypergraphs, as the generalization of knowledge graphs, have attracted increasingly widespread attention due to their friendly compatibility with real-world facts. However, link prediction in knowledge hypergraph is still an underexplored field despite the ubiquity of n-ary facts in the real world. Several recent representative embedding-based knowledge hypergraph link prediction methods have proven to be effective in a series of benchmarks, however, they only consider the position (or role) information, ignoring the neighborhood structure among entities and rich semantic information within each fact. To this end, we propose a model named EnhancE for effective link prediction in knowledge hypergraphs. On the one hand, a more expressive entity representation is obtained with both position and neighborhood information added to the initial embedding. On the other hand, rich semantic information of the involved entities within each tuple is incorporated into relation embedding for enhanced representation. Extensive experimental results over real datasets of both knowledge hypergraph and knowledge graph demonstrate the excellent performance of EnhancE compared with a variety of state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2174159125",
                    "name": "Chenxu Wang"
                },
                {
                    "authorId": "48459088",
                    "name": "Zhao Li"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "8157332",
                    "name": "Zi-Yuan Chen"
                }
            ]
        },
        {
            "paperId": "66b54fb4c0cefba28fbe6fe170355e3c625ceef1",
            "title": "Adversarially Robust Neural Architecture Search for Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) obtain tremendous success in modeling relational data. Still, they are prone to adversarial attacks, which are massive threats to applying GNNs to risk-sensitive domains. Existing defensive methods neither guarantee performance facing new data/tasks or adversarial attacks nor provide insights to understand GNN robustness from an architectural perspective. Neural Architecture Search (NAS) has the potential to solve this problem by automating GNN architecture designs. Nevertheless, current graph NAS approaches lack robust design and are vulnerable to adversarial attacks. To tackle these challenges, we propose a novel Robust Neural Architecture search framework for GNNs (G-RNA). Specifically, we design a robust search space for the message-passing mechanism by adding graph structure mask operations into the search space, which comprises various defensive operation candidates and allows us to search for defensive GNNs. Furthermore, we define a robustness metric to guide the search procedure, which helps to filter robust architectures. In this way, G-RNA helps understand GNN robustness from an architectural perspective and effectively searches for optimal adversarial robust GNNs. Extensive experimental results on benchmark datasets show that G-RNA significantly outperforms manually designed robust GNNs and vanilla graph NAS baselines by 12.1% to 23.4% under adversarial attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181504062",
                    "name": "Beini Xie"
                },
                {
                    "authorId": "144188238",
                    "name": "Heng Chang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2057764",
                    "name": "Daixin Wang"
                },
                {
                    "authorId": "2144443017",
                    "name": "Zhiqiang Zhang"
                },
                {
                    "authorId": "83539859",
                    "name": "Rex Ying"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "6ccf31f3022016b393225944c3edcfb13a9123cc",
            "title": "Selectively Hard Negative Mining for Alleviating Gradient Vanishing in Image-Text Matching",
            "abstract": "Recently, a series of Image-Text Matching (ITM) methods achieve impressive performance. However, we observe that most existing ITM models suffer from gradients vanishing at the beginning of training, which makes these models prone to falling into local minima. Most ITM models adopt triplet loss with Hard Negative mining (HN) as the optimization objective. We find that optimizing an ITM model using only the hard negative samples can easily lead to gradient vanishing. In this paper, we derive the condition under which the gradient vanishes during training. When the difference between the positive pair similarity and the negative pair similarity is close to 0, the gradients on both the image and text encoders will approach 0. To alleviate the gradient vanishing problem, we propose a Selectively Hard Negative Mining (SelHN) strategy, which chooses whether to mine hard negative samples according to the gradient vanishing condition. SelHN can be plug-and-play applied to existing ITM models to give them better training behavior. To further ensure the back-propagation of gradients, we construct a Residual Visual Semantic Embedding model with SelHN, denoted as RVSE++. Extensive experiments on two ITM benchmarks demonstrate the strength of RVSE++, achieving state-of-the-art performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146247689",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2186341116",
                    "name": "Caili Guo"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "1751482331",
                    "name": "Zerun Feng"
                },
                {
                    "authorId": "2042532776",
                    "name": "Zhongtian Du"
                }
            ]
        }
    ]
}