{
    "authorId": "2257032956",
    "papers": [
        {
            "paperId": "028d75496e51943f52c7b2177344a3c089c18058",
            "title": "Fine-grained Hallucination Detection and Editing for Language Models",
            "abstract": "Large language models (LMs) are prone to generate factual errors, which are often called hallucinations. In this paper, we introduce a comprehensive taxonomy of hallucinations and argue that hallucinations manifest in diverse forms, each requiring varying degrees of careful assessments to verify factuality. We propose a novel task of automatic fine-grained hallucination detection and construct a new evaluation benchmark, FavaBench, that includes about one thousand fine-grained human judgments on three LM outputs across various domains. Our analysis reveals that ChatGPT and Llama2-Chat (70B, 7B) exhibit diverse types of hallucinations in the majority of their outputs in information-seeking scenarios. We train FAVA, a retrieval-augmented LM by carefully creating synthetic data to detect and correct fine-grained hallucinations. On our benchmark, our automatic and human evaluations show that FAVA significantly outperforms ChatGPT and GPT-4 on fine-grained hallucination detection, and edits suggested by FAVA improve the factuality of LM-generated text.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279677197",
                    "name": "Abhika Mishra"
                },
                {
                    "authorId": "35584853",
                    "name": "Akari Asai"
                },
                {
                    "authorId": "143820870",
                    "name": "Vidhisha Balachandran"
                },
                {
                    "authorId": "1705260",
                    "name": "Yizhong Wang"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                },
                {
                    "authorId": "2257032956",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "2548384",
                    "name": "Hannaneh Hajishirzi"
                }
            ]
        },
        {
            "paperId": "eac59779da7262968a9043985e7cd933c00247a5",
            "title": "MatFormer: Nested Transformer for Elastic Inference",
            "abstract": "Transformer models are deployed in a wide range of settings, from multi-accelerator clusters to standalone mobile phones. The diverse inference constraints in these scenarios necessitate practitioners to train foundation models such as PaLM 2, Llama,&ViTs as a series of models of varying sizes. Due to significant training costs, only a select few model sizes are trained and supported, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy. This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints. Each Feed Forward Network (FFN) block of a MatFormer model is jointly optimized with a few nested smaller FFN blocks. This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized. We empirically demonstrate MatFormer's effectiveness across different model classes (decoders&encoders), modalities (language&vision), and scales (up to 2.6B parameters). We find that a 2.6B decoder-only MatFormer language model (MatLM) allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting comparable validation loss and one-shot downstream evaluations to their independently trained counterparts. Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval. Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1396692136",
                    "name": "Devvrit"
                },
                {
                    "authorId": "35871436",
                    "name": "Sneha Kudugunta"
                },
                {
                    "authorId": "52207562",
                    "name": "Aditya Kusupati"
                },
                {
                    "authorId": "2288469507",
                    "name": "Tim Dettmers"
                },
                {
                    "authorId": "2166250082",
                    "name": "Kaifeng Chen"
                },
                {
                    "authorId": "2257038095",
                    "name": "Inderjit S. Dhillon"
                },
                {
                    "authorId": "2257032956",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "2548384",
                    "name": "Hannaneh Hajishirzi"
                },
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                },
                {
                    "authorId": "2257020375",
                    "name": "Ali Farhadi"
                },
                {
                    "authorId": "2189156327",
                    "name": "Prateek Jain"
                }
            ]
        }
    ]
}