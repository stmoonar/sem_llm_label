{
    "authorId": "31834207",
    "papers": [
        {
            "paperId": "d2f22bfa22e50071cf93e20558c06caf8fa858b7",
            "title": "Evaluation Methodology for Large Language Models for Multilingual Document Question and Answer",
            "abstract": "With the widespread adoption of Large Language Models (LLMs), in this paper we investigate the multilingual capability of these models. Our preliminary results show that, translating the native language context, question and answer into a high resource language produced the best results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103588611",
                    "name": "Adar Kahana"
                },
                {
                    "authorId": "2282471276",
                    "name": "Jaya Susan Mathew"
                },
                {
                    "authorId": "2282471862",
                    "name": "Said Bleik"
                },
                {
                    "authorId": "2282732871",
                    "name": "Jeremy Reynolds"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                }
            ]
        },
        {
            "paperId": "d32871dd44a7a3c8e3a8af5319fc8135e802e2cf",
            "title": "ReMatch: Retrieval Enhanced Schema Matching with LLMs",
            "abstract": "Schema matching is a crucial task in data integration, involving the alignment of a source schema with a target schema to establish correspondence between their elements. This task is challenging due to textual and semantic heterogeneity, as well as differences in schema sizes. Although machine-learning-based solutions have been explored in numerous studies, they often suffer from low accuracy, require manual mapping of the schemas for model training, or need access to source schema data which might be unavailable due to privacy concerns. In this paper we present a novel method, named ReMatch, for matching schemas using retrieval-enhanced Large Language Models (LLMs). Our method avoids the need for predefined mapping, any model training, or access to data in the source database. Our experimental results on large real-world schemas demonstrate that ReMatch is an effective matcher. By eliminating the requirement for training data, ReMatch becomes a viable solution for real-world scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2744108",
                    "name": "Eitam Sheetrit"
                },
                {
                    "authorId": "2217252086",
                    "name": "Menachem Brief"
                },
                {
                    "authorId": "2273563114",
                    "name": "Moshik Mishaeli"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                }
            ]
        },
        {
            "paperId": "8da3be4d25f2f97fc8683de286b35dbe3f46483d",
            "title": "MessageNet: Message Classification using Natural Language Processing and Meta-data",
            "abstract": "In this paper we propose a new Deep Learning (DL) approach for message classification. Our method is based on the state-of-the-art Natural Language Processing (NLP) building blocks, combined with a novel technique for infusing the meta-data input that is typically available in messages such as the sender information, timestamps, attached image, audio, affiliations, and more. As we demonstrate throughout the paper, going beyond the mere text by leveraging all available channels in the message, could yield an improved representation and higher classification accuracy. To achieve message representation, each type of input is processed in a dedicated block in the neural network architecture that is suitable for the data type. Such an implementation enables training all blocks together simultaneously, and forming cross channels features in the network. We show in the Experiments Section that in some cases, message's meta-data holds an additional information that cannot be extracted just from the text, and when using this information we achieve better performance. Furthermore, we demonstrate that our multi-modality block approach outperforms other approaches for injecting the meta data to the the text classifier.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103588611",
                    "name": "Adar Kahana"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                }
            ]
        },
        {
            "paperId": "b512451d431df9e411bea4c99f7135d010275445",
            "title": "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs",
            "abstract": "Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing them to numerous variations of the same fact during training could alleviate this problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40265559",
                    "name": "O. Ovadia"
                },
                {
                    "authorId": "2217252086",
                    "name": "Menachem Brief"
                },
                {
                    "authorId": "2273563114",
                    "name": "Moshik Mishaeli"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                }
            ]
        },
        {
            "paperId": "c76c8ad4b668542cb61ef3401f67bc613ec54a81",
            "title": "Detection of Infectious Disease Outbreaks in Search Engine Time Series Using Non-Specific Syndromic Surveillance with Effect-Size Filtering",
            "abstract": "Novel infectious disease outbreaks, including most recently that of the COVID-19 pandemic, could be detected by non-specific syndromic surveillance systems. Such systems, utilizing a variety of data sources ranging from Electronic Health Records to internet data such as aggregated search engine queries, create alerts when unusually high rates of symptom reports occur. This is especially important for the detection of novel diseases, where their manifested symptoms are unknown. Here we improve upon a set of previously-proposed non-specific syndromic surveillance methods by taking into account both how unusual a preponderance of symptoms is and their effect size. We demonstrate that our method is as accurate as previously-proposed methods for low dimensional data and show its effectiveness for high-dimensional aggregated data by applying it to aggregated time-series health-related search engine queries. We find that in 2019 the method would have raised alerts related to several disease outbreaks earlier than health authorities did. During the COVID-19 pandemic the system identified the beginning of pandemic waves quickly, through combinations of symptoms which varied from wave to wave. Thus, the proposed method could be used as a practical tool for decision makers to detect new disease outbreaks using time series derived from search engine data even in the absence of specific information on the diseases of interest and their symptoms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40265559",
                    "name": "O. Ovadia"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                },
                {
                    "authorId": "1388775854",
                    "name": "E. Yom-Tov"
                }
            ]
        },
        {
            "paperId": "610c67ffebfcd256b876f0dc6fa4cb75fbf9140d",
            "title": "Low Latency Privacy Preserving Inference",
            "abstract": "When applying machine learning to sensitive data, one has to find a balance between accuracy, information security, and computational-complexity. Recent studies combined Homomorphic Encryption with neural networks to make inferences while protecting against information leakage. However, these methods are limited by the width and depth of neural networks that can be used (and hence the accuracy) and exhibit high latency even for relatively simple networks. In this study we provide two solutions that address these limitations. In the first solution, we present more than 10\u00d7 improvement in latency and enable inference on wider networks compared to prior attempts with the same level of security. The improved performance is achieved by novel methods to represent the data during the computation. In the second solution, we apply the method of transfer learning to provide private inference services using deep networks with latency of \u223c0.16 seconds. We demonstrate the efficacy of our methods on several computer vision tasks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2470453",
                    "name": "Alon Brutzkus"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "95273fea8734863dab07cdac80d292309c5812b5",
            "title": "Wavelet Decomposition of Gradient Boosting",
            "abstract": "In this paper we introduce a significant improvement to the popular tree-based Stochastic Gradient Boosting algorithm using a wavelet decomposition of the trees. This approach is based on harmonic analysis and approximation theoretical elements, and as we show through extensive experimentation, our wavelet based method generally outperforms existing methods, particularly in difficult scenarios of class unbalance and mislabeling in the training data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "35253326",
                    "name": "S. Dekel"
                },
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                },
                {
                    "authorId": "41051923",
                    "name": "Ohad Morgan"
                }
            ]
        },
        {
            "paperId": "6880ef044a99f9c597b422e75b2718a617b0028a",
            "title": "Function space analysis of deep learning representation layers",
            "abstract": "In this paper we propose a function space approach to Representation Learning and the analysis of the representation layers in deep learning architectures. We show how to compute a weak-type Besov smoothness index that quantifies the geometry of the clustering in the feature space. This approach was already applied successfully to improve the performance of machine learning algorithms such as the Random Forest and tree-based Gradient Boosting. Our experiments demonstrate that in well-known and well-performing trained networks, the Besov smoothness of the training set, measured in the corresponding hidden layer feature map representation, increases from layer to layer. We also contribute to the understanding of generalization by showing how the Besov smoothness of the representations, decreases as we add more mis-labeling to the training data. We hope this approach will contribute to the de-mystification of some aspects of deep learning.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                },
                {
                    "authorId": "35253326",
                    "name": "S. Dekel"
                }
            ]
        },
        {
            "paperId": "286208c11b3345e4078965cb1062e73227076120",
            "title": "Wavelet decompositions of Random Forests - smoothness analysis, sparse approximation and applications",
            "abstract": "In this paper we introduce, in the setting of machine learning, a generalization of wavelet analysis which is a popular approach to low dimensional structured signal analysis. The wavelet decomposition of a Random Forest provides a sparse approximation of any regression or classification high dimensional function at various levels of detail, with a concrete ordering of the Random Forest nodes: from 'significant' elements to nodes capturing only 'insignificant' noise. Motivated by function space theory, we use the wavelet decomposition to compute numerically a 'weak-type' smoothness index that captures the complexity of the underlying function. As we show through extensive experimentation, this sparse representation facilitates a variety of applications such as improved regression for difficult datasets, a novel approach to feature importance, resilience to noisy or irrelevant features, compression of ensembles, etc.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                },
                {
                    "authorId": "35253326",
                    "name": "S. Dekel"
                }
            ]
        },
        {
            "paperId": "37cea94ed22bb8ba7bb59934208e5850c545d938",
            "title": "Detection of obstructive sleep apnea using speech signal analysis",
            "abstract": "obstructive sleep apnea (osa) is a prevalent sleep related breathing disorder associated with several anatomical abnormalities of the upper airway. acoustic parameters of human speech are influenced by properties of the vocal tract, which includes the upper airway. We hypothesize that it is possible to differentiate osa patients from non-osa (healthy) subjects by analyzing potential patients\u2019 speech signals. using speaker recognition and signal processing techniques, we designed a system for classifying a given speech signal into one of the two groups. the database for this research was constructed from 92 subjects who were recorded reading a one-minute speech protocol immediately prior to a full polysomnography study; one hundred and three acoustic features were extracted from each signal; seven independent Gaussian mixture models (GMM)-based classifiers were implemented; a fusion process was designed to combine the scores of these classifiers and a validation procedure took place in order to examine the system\u2019s performance. specificity and sensitivity of 91.66% and 91.66% were achieved for the male population; and 88.89% and 85.71% were achieved for female population, respectively. such a system can be used as a tool for initial screening of potential osa patients.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "31834207",
                    "name": "Oren Elisha"
                },
                {
                    "authorId": "2077038",
                    "name": "A. Tarasiuk"
                },
                {
                    "authorId": "1683721",
                    "name": "Y. Zigel"
                }
            ]
        }
    ]
}