{
    "authorId": "145531067",
    "papers": [
        {
            "paperId": "16664b2201b36100ff6090aadf8ce4081f4b153a",
            "title": "Next-generation Challenges of Responsible Data Integration",
            "abstract": "Data integration has been extensively studied by the data management community and is a core task in the data pre-processing step of ML pipelines. When the integrated data is used for analysis and model training, responsible data science requires addressing concerns about data quality and bias. We present a tutorial on data integration and responsibility, highlighting the existing efforts in responsible data integration along with research opportunities and challenges. In this tutorial, we encourage the community to audit data integration tasks with responsibility measures and develop integration techniques that optimize the requirements of responsible data science. We focus on three critical aspects: (1) the requirements to be considered for evaluating and auditing data integration tasks for quality and bias; (2) the data integration tasks that elicit attention to data responsibility measures and methods to satisfy these requirements; and, (3) techniques, tasks, and open problems in data integration that help achieve data responsibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315516",
                    "name": "F. Nargesian"
                },
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "4416c7a9c582a008ad99aba240d56d88d2b07f5a",
            "title": "Dexer: Detecting and Explaining Biased Representation in Ranking",
            "abstract": "With the growing use of ranking algorithms in real-life decision-making purposes, fairness in ranking has been recognized as an important issue. Recent works have studied different fairness measures in ranking, and many of them consider the representation of different \"protected groups\", in the top-k ranked items, for any reasonable k. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups' definitions may be unknown in advance. To this end, we present Dexer, a system for the detection of groups with biased representation in the top-k. Dexer utilizes the notion of Shapley values to provide the users with visual explanations for the cause of bias. We will demonstrate the usefulness of Dexer using real-life data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "4f3f4d4704a64d6714bfa21693d25ecc106e2fdb",
            "title": "ERICA: Query Refinement for Diversity Constraint Satisfaction",
            "abstract": "Relational queries are commonly used to support decision making in critical domains like hiring and college admissions. For example, a college admissions officer may need to select a subset of the applicants for in-person interviews, who individually meet the qualification requirements (e.g., have a sufficiently high GPA) and are collectively demographically diverse (e.g., include a sufficient number of candidates of each gender and of each race). However, traditional relational queries only support selection conditions checked against each input tuple, and they do not support diversity conditions checked against multiple, possibly overlapping, groups of output tuples. To address this shortcoming, we present Erica, an interactive system that proposes minimal modifications for selection queries to have them satisfy constraints on the cardinalities of multiple groups in the result. We demonstrate the effectiveness of Erica using several real-life datasets and diversity requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "2236742952",
                    "name": "Alon Silberstein"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "5cb13825a91e1dfbe3d2890c4c2c62affacc4ecd",
            "title": "Pylon: Semantic Table Union Search in Data Lakes",
            "abstract": "The large size and fast growth of data repositories, such as data lakes, has spurred the need for data discovery to help analysts find related data. The problem has become challenging as (i) a user typically does not know what datasets exist in an enormous data repository; and (ii) there is usually a lack of a unified data model to capture the interrelationships between heterogeneous datasets from disparate sources. In this work, we address one important class of discovery needs: finding union-able tables. The task is to find tables in a data lake that can be unioned with a given query table. The challenge is to recognize union-able columns even if they are represented differently. In this paper, we propose a data-driven learning approach: specifically, an unsupervised representation learning and embedding retrieval task. Our key idea is to exploit self-supervised contrastive learning to learn an embedding model that takes into account the indexing/search data structure and produces embeddings close by for columns with semantically similar values while pushing apart columns with semantically dissimilar values. We then find union-able tables based on similarities between their constituent columns in embedding space. On a real-world data lake, we demonstrate that our best-performing model achieves significant improvements in precision ($16\\% \\uparrow$), recall ($17\\% \\uparrow $), and query response time (7x faster) compared to the state-of-the-art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1432234356",
                    "name": "Tianji Cong"
                },
                {
                    "authorId": "2315516",
                    "name": "F. Nargesian"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "d8dc36340376c80b4c493f77137e84d165f3444e",
            "title": "SMARTFEAT: Efficient Feature Construction through Feature-Level Foundation Model Interactions",
            "abstract": "Before applying data analytics or machine learning to a data set, a vital step is usually the construction of an informative set of features from the data. In this paper, we present SMARTFEAT, an efficient automated feature engineering tool to assist data users, even non-experts, in constructing useful features. Leveraging the power of Foundation Models (FMs), our approach enables the creation of new features from the data, based on contextual information and open-world knowledge. Our method incorporates an intelligent operator selector that discerns a subset of operators, effectively avoiding exhaustive combinations of original features, as is typically observed in traditional automated feature engineering tools. Moreover, we address the limitations of performing data tasks through row-level interactions with FMs, which could lead to significant delays and costs due to excessive API calls. We introduce a function generator that facilitates the acquisition of efficient data transformations, such as dataframe built-in methods or lambda functions, ensuring the applicability of SMARTFEAT to generate new features for large datasets. Code repo with prompt details and datasets: (https://github.com/niceIrene/SMARTFEAT).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117033724",
                    "name": "Yin Lin"
                },
                {
                    "authorId": "2240531318",
                    "name": "Bolin Ding"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                },
                {
                    "authorId": "2237499232",
                    "name": "Jingren Zhou"
                }
            ]
        },
        {
            "paperId": "f638eeeab33a16d922014cc13abc9a886a6fe275",
            "title": "Observatory: Characterizing Embeddings of Relational Tables",
            "abstract": "Language models and specialized table embedding models have recently demonstrated strong performance on many tasks over tabular data. Researchers and practitioners are keen to leverage these models in many new application contexts; but limited understanding of the strengths and weaknesses of these models, and the table representations they generate, makes the process of finding a suitable model for a given task reliant on trial and error. There is an urgent need to gain a comprehensive understanding of these models to minimize inefficiency and failures in downstream usage. To address this need, we propose Observatory, a formal framework to systematically analyze embedding representations of relational tables. Motivated both by invariants of the relational data model and by statistical considerations regarding data distributions, we define eight primitive properties, and corresponding measures to quantitatively characterize table embeddings for these properties. Based on these properties, we define an extensible framework to evaluate language and table embedding models. We collect and synthesize a suite of datasets and use Observatory to analyze seven such models. Our analysis provides insights into the strengths and weaknesses of learned representations over tables. We find, for example, that some models are sensitive to table structure such as column order, that functional dependencies are rarely reflected in embeddings, and that specialized table embedding models have relatively lower sample fidelity. Such insights help researchers and practitioners better anticipate model behaviors and select appropriate models for their downstream tasks, while guiding researchers in the development of new models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1432234356",
                    "name": "Tianji Cong"
                },
                {
                    "authorId": "51309767",
                    "name": "Madelon Hulsebos"
                },
                {
                    "authorId": "2257391303",
                    "name": "Zhenjie Sun"
                },
                {
                    "authorId": "2257346461",
                    "name": "Paul Groth"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "0368102a9510ab93ab500322dbc7709b0a8a6e1b",
            "title": "Representation Bias in Data: A Survey on Identification and Resolution Techniques",
            "abstract": "Data-driven algorithms are only as good as the data they work with, while datasets, especially social data, often fail to represent minorities adequately. Representation Bias in data can happen due to various reasons, ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. Given that \u201cbias in, bias out,\u201d one cannot expect AI-based solutions to have equitable outcomes for societal applications, without addressing issues such as representation bias. While there has been extensive study of fairness in machine learning models, including several review papers, bias in the data has been less studied. This article reviews the literature on identifying and resolving representation bias as a feature of a dataset, independent of how consumed later. The scope of this survey is bounded to structured (tabular) and unstructured (e.g., image, text, graph) data. It presents taxonomies to categorize the studied techniques based on multiple design dimensions and provides a side-by-side comparison of their properties. There is still a long way to fully address representation bias issues in data. The authors hope that this survey motivates researchers to approach these challenges in the future by observing existing work within their respective domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1927032",
                    "name": "N. Shahbazi"
                },
                {
                    "authorId": "2117033724",
                    "name": "Yin Lin"
                },
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        },
        {
            "paperId": "03f417be3da7923a72525e58671d1b0832ad9924",
            "title": "The Many Facets of Data Equity",
            "abstract": "Data-driven systems can induce, operationalize, and amplify systemic discrimination in a variety of ways. As data scientists, we tend to prefer to isolate and formalize equity problems to make them amenable to narrow technical solutions. However, this reductionist approach is inadequate in practice. In this article, we attempt to address data equity broadly, identify different ways in which it is manifest in data-driven systems, and propose a research agenda.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "145557773",
                    "name": "B. Howe"
                }
            ]
        },
        {
            "paperId": "14bcda21f06e0ea91ccd157788dd9e06bd234e3d",
            "title": "Principles of Query Visualization",
            "abstract": "Query Visualization (QV) is the problem of transforming a given query into a graphical representation that helps humans understand its meaning. This task is notably different from designing a Visual Query Language (VQL) that helps a user compose a query. This article discusses the principles of relational query visualization and its potential for simplifying user interactions with relational data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2000882",
                    "name": "Wolfgang Gatterbauer"
                },
                {
                    "authorId": "34889063",
                    "name": "Cody Dunne"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                },
                {
                    "authorId": "1722086",
                    "name": "Mirek Riedewald"
                }
            ]
        },
        {
            "paperId": "5fac26dbf6f2bd58ad0ca06dd330f40305405342",
            "title": "Bias analysis and mitigation in data-driven tools using provenance",
            "abstract": "Fairness and bias mitigation in data-driven systems has been extensively studied in recent years. In this paper, we suggest a novel approach towards fairness analysis and bias mitigation utilizing the notion of provenance, which was shown to be useful for similar tasks in the context of data and process analyses. We illustrate the idea using a simple use-case demonstrating a scenario of mitigating bias caused by inadequate minority group representation. We conclude with an outline of opportunities and challenges in developing provenance-based solutions for bias analysis and mitigation in data-driven systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2142943278",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                }
            ]
        }
    ]
}