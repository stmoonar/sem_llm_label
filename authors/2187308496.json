{
    "authorId": "2187308496",
    "papers": [
        {
            "paperId": "b639dd92cf2639f3d584e5e5bfd15ace594e0650",
            "title": "PRO-Face C: Privacy-Preserving Recognition of Obfuscated Face via Feature Compensation",
            "abstract": "The advancement of face recognition technology has delivered substantial societal advantages. However, it has also raised global privacy concerns due to the ubiquitous collection and potential misuse of individuals\u2019 facial data. This presents a notable paradox: while there is a societal demand for a robust face recognition ecosystem to ensure public security and convenience, an increasing number of individuals are hesitant to release their facial data. Numerous studies have endeavored to find such a utility-privacy trade-off, yet many struggle with the dilemma of prioritizing one at the expense of the other. In response to this challenge, this paper proposes PRO-Face C, a novel paradigm for privacy-preserving recognition of obfuscated faces via a dedicated feature compensation mechanism, aimed at optimizing the equilibrium between privacy preservation and utility maximization. The proposed approach is characterized by a specialized client-server architecture: the client transmits only obfuscated images to the server, which then performs identity recognition using a pre-trained model in conjunction with a suite of privacy-free complementary features. This framework facilitates accurate face identification while safeguarding the original facial appearance from explicit disclosure. Furthermore, the obfuscated image retains its visualization capability, crucial for image preview functionalities. To ensure the desired properties, we have developed an identity-guided feature compensation mechanism, complemented by several privacy-enhancing techniques. Extensive experiments conducted across multiple face datasets underscore the effectiveness of the proposed approach in diverse scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275542434",
                    "name": "Lin Yuan"
                },
                {
                    "authorId": "2297051288",
                    "name": "Wu Chen"
                },
                {
                    "authorId": "2187308496",
                    "name": "Xiao Pu"
                },
                {
                    "authorId": "2275853709",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2283974850",
                    "name": "Hongbo Li"
                },
                {
                    "authorId": "2145039781",
                    "name": "Yushu Zhang"
                },
                {
                    "authorId": "2239964615",
                    "name": "Xinbo Gao"
                },
                {
                    "authorId": "2254300831",
                    "name": "Touradj Ebrahimi"
                }
            ]
        },
        {
            "paperId": "26509bc3fbd4c9f5cd89f3cd6b65f84d09f0250d",
            "title": "PRO-Face S: Privacy-preserving Reversible Obfuscation of Face Images via Secure Flow",
            "abstract": "This paper proposes a novel paradigm for facial privacy protection that unifies multiple characteristics including anonymity, diversity, reversibility and security within a single lightweight framework. We name it PRO-Face S, short for Privacy-preserving Reversible Obfuscation of Face images via Secure flow-based model. In the framework, an Invertible Neural Network (INN) is utilized to process the input image along with its pre-obfuscated form, and generate the privacy protected image that visually approximates to the pre-obfuscated one, thus ensuring privacy. The pre-obfuscation applied can be in diversified form with different strengths and styles specified by users. Along protection, a secret key is injected into the network such that the original image can only be recovered from the protection image via the same model given the correct key provided. Two modes of image recovery are devised to deal with malicious recovery attempts in different scenarios. Finally, extensive experiments conducted on three public image datasets demonstrate the superiority of the proposed framework over multiple state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152192126",
                    "name": "Lin Yuan"
                },
                {
                    "authorId": "2068639486",
                    "name": "Kai Liang"
                },
                {
                    "authorId": "2187308496",
                    "name": "Xiao Pu"
                },
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "40939264",
                    "name": "Jiaxu Leng"
                },
                {
                    "authorId": "2112377430",
                    "name": "Tao Wu"
                },
                {
                    "authorId": "144050302",
                    "name": "Nannan Wang"
                },
                {
                    "authorId": "2164214077",
                    "name": "Xinbo Gao"
                }
            ]
        },
        {
            "paperId": "340a2513a7d807361c1b122092f16d04e9aa8fab",
            "title": "DecomFormer: Decompose Self-Attention Via Fourier Transform for VHR Aerial Image Scene Classification",
            "abstract": "Very high-resolution (VHR) aerial image scene classification is an essential task for aerial image understanding. Although transformer-based models have demonstrated strong ability in natural image classification, transformer-based methods on VHR aerial image tasks are still lack of concern because the complexity of self-attention in the transformer grows quadratically with the image resolution. To address this issue, we decompose the self-attention via Fourier Transform and propose a novel Fourier self-attention (FSA) mechanism. Based on FSA, we design a highly efficient network named DecomFormer, which learns contextual relationships in the real part and imaginary part of the Fourier field, respectively. Theoretically, the DecomFormer reduces the complexity of the naive self-attention mechanism from O(n2) to O(nlog(n)). Universal experiments on public VHR aerial image classification benchmarks demonstrated the DecomFormer\u2019s efficiency, especially on images with very high-resolution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2172078823",
                    "name": "Xiyuan Gao"
                },
                {
                    "authorId": "2187308496",
                    "name": "Xiao Pu"
                },
                {
                    "authorId": "41154933",
                    "name": "Tao Wang"
                },
                {
                    "authorId": "2164214077",
                    "name": "Xinbo Gao"
                }
            ]
        },
        {
            "paperId": "0fcfc3c0d13facbfec603cccbee9eec40a73aea8",
            "title": "Contextual Learning in Fourier Complex Field for VHR Remote Sensing Images",
            "abstract": "Very high-resolution (VHR) remote sensing (RS) image classification is the fundamental task for RS image analysis and understanding. Recently, Transformer-based models demonstrated outstanding potential for learning high-order contextual relationships from natural images with general resolution ( \u2248 224 \u00d7 224 pixels) and achieved remarkable results on general image classification tasks. However, the complexity of the naive Transformer grows quadratically with the increase in image size, which prevents Transformer-based models from VHR RS image ( \u2265 500 \u00d7 500 pixels) classification and other computationally expensive downstream tasks. To this end, we propose to decompose the expensive self-attention (SA) into real and imaginary parts via discrete Fourier transform (DFT) and, therefore, propose an efficient complex SA (CSA) mechanism. Benefiting from the conjugated symmetric property of DFT, CSA is capable to model the high-order contextual information with less than half computations of naive SA. To overcome the gradient explosion in Fourier complex field, we replace the Softmax function with the carefully designed Logmax function to normalize the attention map of CSA and stabilize the gradient propagation. By stacking various layers of CSA blocks, we propose the Fourier complex Transformer (FCT) model to learn global contextual information from VHR aerial images following the hierarchical manners. Universal experiments conducted on commonly used RS classification datasets demonstrate the effectiveness and efficiency of FCT, especially on VHR RS images. The source code of FCT will be available at https://github.com/Gao-xiyuan/FCT.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2172078823",
                    "name": "Xiyuan Gao"
                },
                {
                    "authorId": "3440080",
                    "name": "Qingyan Duan"
                },
                {
                    "authorId": "40939264",
                    "name": "Jiaxu Leng"
                },
                {
                    "authorId": "2187308496",
                    "name": "Xiao Pu"
                },
                {
                    "authorId": "2164214077",
                    "name": "Xinbo Gao"
                }
            ]
        },
        {
            "paperId": "766b686a53abb65892c00d81ac241f890ca8d2d6",
            "title": "PRO-Face: A Generic Framework for Privacy-preserving Recognizable Obfuscation of Face Images",
            "abstract": "A number of applications (e.g., video surveillance and authentication) rely on automated face recognition to guarantee functioning of secure services, and meanwhile, have to take into account the privacy of individuals exposed under camera systems. This is the so-called Privacy-Utility trade-off. However, most existing approaches to facial privacy protection focus on removing identifiable visual information from images, leaving protected face unrecognizable to machine, which sacrifice utility for privacy. To tackle the privacy-utility challenge, we propose a novel, generic, effective, yet lightweight framework for Privacy-preserving Recognizable Obfuscation of Face images (named as PRO-Face). The framework allows one to first process a face image using any preferred obfuscation, such as image blur, pixelate and face morphing. It then leverages a Siamese network to fuse the original image with its obfuscated form, generating the final protected image visually similar to the obfuscated one from human perception (for privacy) but still recognized as the original identity by machine (for utility). The framework supports various obfuscations for facial anonymization. The face recognition can be performed accurately not only across anonymized images but also between plain and anonymized ones, based on only pre-trained recognizers. Those feature the \"generic\" merit of the proposed framework. In-depth objective and subjective evaluations demonstrate the effectiveness of the proposed framework in both privacy protection and utility preservation under distinct scenarios. Our source code, models and any supplementary materials are made publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152192126",
                    "name": "Lin Yuan"
                },
                {
                    "authorId": "2187314838",
                    "name": "Linguo Liu"
                },
                {
                    "authorId": "2187308496",
                    "name": "Xiao Pu"
                },
                {
                    "authorId": "2187420398",
                    "name": "Zhao Li"
                },
                {
                    "authorId": "2167226346",
                    "name": "Hongbo Li"
                },
                {
                    "authorId": "2164214077",
                    "name": "Xinbo Gao"
                }
            ]
        }
    ]
}