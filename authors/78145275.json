{
    "authorId": "78145275",
    "papers": [
        {
            "paperId": "653578a9044e198c86dcc254d45bbecded0ab267",
            "title": "Contrastive Graph Pooling for Explainable Classification of Brain Networks",
            "abstract": "Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson\u2019s, Alzheimer\u2019s, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literature, and disclose direct and interesting insights. Our contributions underscore the potential of ContrastPool for advancing the understanding of brain networks and neurodegenerative conditions. The source code is available at https://github.com/AngusMonroe/ContrastPool.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2157763562",
                    "name": "Jiaxing Xu"
                },
                {
                    "authorId": "2218561112",
                    "name": "Qingtian Bian"
                },
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2219061979",
                    "name": "Aihu Zhang"
                },
                {
                    "authorId": "2636068",
                    "name": "Yiping Ke"
                },
                {
                    "authorId": "2191678370",
                    "name": "Miao Qiao"
                },
                {
                    "authorId": "48902278",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2055633824",
                    "name": "W. K. Sim"
                },
                {
                    "authorId": "2064386104",
                    "name": "Bal'azs Guly'as"
                }
            ]
        },
        {
            "paperId": "338b61463f5d77ca12c7651952ceb5af95e1de69",
            "title": "OpenSiteRec: An Open Dataset for Site Recommendation",
            "abstract": "As a representative information retrieval task, site recommendation, which aims at predicting the optimal sites for a brand or an institution to open new branches in an automatic data-driven way, is beneficial and crucial for brand development in modern business. However, there is no publicly available dataset so far and most existing approaches are limited to an extremely small scope of brands, which seriously hinders the research on site recommendation. Therefore, we collect, construct and release an open comprehensive dataset, namely OpenSiteRec, to facilitate and promote the research on site recommendation. Specifically, OpenSiteRec leverages a heterogeneous graph schema to represent various types of real-world entities and relations in four international metropolises. To evaluate the performance of the existing general methods on the site recommendation task, we conduct benchmarking experiments of several representative recommendation models on OpenSiteRec. Furthermore, we also highlight the potential application directions to demonstrate the wide applicability of OpenSiteRec. We believe that our OpenSiteRec dataset is significant and anticipated to encourage the development of advanced methods for site recommendation. OpenSiteRec is available online at https://OpenSiteRec.github.io/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2146400187",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "2154405613",
                    "name": "Yong Li"
                },
                {
                    "authorId": "2221009794",
                    "name": "Cheng Long"
                },
                {
                    "authorId": "33603226",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                }
            ]
        },
        {
            "paperId": "607d9eb8ceab0533bcfc65e8aced69aee4e40976",
            "title": "IMF: Interactive Multimodal Fusion Model for Link Prediction",
            "abstract": "Link prediction aims to identify potential missing triples in knowledge graphs. To get better results, some recent studies have introduced multimodal information to link prediction. However, these methods utilize multimodal information separately and neglect the complicated interaction between different modalities. In this paper, we aim at better modeling the inter-modality information and thus introduce a novel Interactive Multimodal Fusion (IMF) model to integrate knowledge from different modalities. To this end, we propose a two-stage multimodal fusion framework to preserve modality-specific knowledge as well as take advantage of the complementarity between different modalities. Instead of directly projecting different modalities into a unified space, our multimodal fusion module limits the representations of different modalities independent while leverages bilinear pooling for fusion and incorporates contrastive learning as additional constraints. Furthermore, the decision fusion module delivers the learned weighted average over the predictions of all modalities to better incorporate the complementarity of different modalities. Our approach has been demonstrated to be effective through empirical evaluations on several real-world datasets. The implementation code is available online at https://github.com/HestiaSky/IMF-Pytorch.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2197532318",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2157763562",
                    "name": "Jiaxing Xu"
                },
                {
                    "authorId": "33603226",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                }
            ]
        },
        {
            "paperId": "84557e06b971ff71acef88d5c94a274dee71e304",
            "title": "Conditional Cross-Platform User Engagement Prediction",
            "abstract": "The bursting of media sharing platforms like TikTok, YouTube, and Kwai enables normal users to create and share content with worldwide audiences. The most popular YouTuber can attract up to 100 million followers. Since there are multiple popular platforms, it\u2019s quite common that a YouTuber publishes the same media to multiple platforms, or replicates all media from one platform to another. However, the users of different platforms have different tastes. The media that is popular on one platform may not be a great vogue on other platforms. Observing such cross-platform variance, we propose a new task: estimating the user engagement score of a media on one platform given its popularity on other platforms. This task can benefit both the YouTubers and the platform. On one hand, YouTubers can use the predicted engagement to guide the media reworking; on the other hand, the platform can use the predicted engagement to establish promotion and advertising plans. Therefore, this task is of great practical value. To tackle this task, we propose a disentangled neural network that can separate the general media adorability from platform inclinations. In this manner, by substituting the inclination from the source platform to the target platform, we are able to predict the user engagement in the target platform. To validate the proposed model, we manage to build a dataset of micro-videos which are published on four platforms TikTok, Kwai, Bilibili, and WESEE. The experimental results prove the effectiveness of the proposed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2382872",
                    "name": "Zhaopeng Qiu"
                },
                {
                    "authorId": "2212137234",
                    "name": "Jiacheng Jiang"
                },
                {
                    "authorId": "33603226",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                },
                {
                    "authorId": "144620591",
                    "name": "X. Wu"
                }
            ]
        },
        {
            "paperId": "cf659af952ee98182f9dc7cd6173bad55aa57daa",
            "title": "E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation",
            "abstract": "The recent advancements in Large Language Models (LLMs) have sparked interest in harnessing their potential within recommender systems. Since LLMs are designed for natural language tasks, existing recommendation approaches have predominantly transformed recommendation tasks into open-domain natural language generation tasks. However, this approach necessitates items to possess rich semantic information, often generates out-of-range results, and suffers from notably low efficiency and limited extensibility. Furthermore, practical ID-based recommendation strategies, reliant on a huge number of unique identities (IDs) to represent users and items, have gained prominence in real-world recommender systems due to their effectiveness and efficiency. Nevertheless, the incapacity of LLMs to model IDs presents a formidable challenge when seeking to leverage LLMs for personalized recommendations. In this paper, we introduce an Elegant Effective Efficient Extensible solution for large language models for Sequential Recommendation (E4SRec), which seamlessly integrates LLMs with traditional recommender systems that exclusively utilize IDs to represent items. Specifically, E4SRec takes ID sequences as inputs, ensuring that the generated outputs fall within the candidate lists. Furthermore, E4SRec possesses the capability to generate the entire ranking list in a single forward process, and demands only a minimal set of pluggable parameters, which are trained for each dataset while keeping the entire LLM frozen. We substantiate the effectiveness, efficiency, and extensibility of our proposed E4SRec through comprehensive experiments conducted on four widely-used real-world datasets. The implementation code is accessible at https://github.com/HestiaSky/E4SRec/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2269755998",
                    "name": "Chong Chen"
                },
                {
                    "authorId": "2269779369",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2144287948",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                }
            ]
        },
        {
            "paperId": "d0111516fa5b32157bcbae322476b489a0b77d7b",
            "title": "REST: Drug-Drug Interaction Prediction via Reinforced Student-Teacher Curriculum Learning",
            "abstract": "Accurate prediction of drug-drug interaction (DDI) is crucial to achieving effective decision-making in medical treatment for both doctors and patients. Recently, many deep learning based methods have been proposed to learn from drug-related features and conduct DDI prediction. These works have achieved promising results. However, the extreme imbalance of medical data poses a serious problem to DDI prediction, where a small fraction of DDI types occupy the majority training data. A straightforward way is to develop an appropriate policy to sample the data. Due to the high complexity and speciality of medical science, a dynamic learnable policy is required instead of a heuristic, uniform or static one. Therefore, we propose a REinforced Student-Teacher curriculum learning model (REST) for effective sampling to tackle this imbalance problem. Specifically, REST consists of two interactive parts, which are a heterogeneous graph neural network as the student and a reinforced sampler as the teacher. In each interaction, the teacher model takes action to sample an appropriate batch to train the student model according to the student model state while the cumulated improvement in performance of the student model is treated as the reward for policy gradient of the teacher model. The experimental results on two benchmarking datasets have demonstrated the significant effectiveness of our proposed model in DDI prediction, especially for the DDI types with low frequency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2382872",
                    "name": "Zhaopeng Qiu"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2144287948",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                },
                {
                    "authorId": "2261065257",
                    "name": "Xian Wu"
                }
            ]
        },
        {
            "paperId": "f5fa16684a34aa992ef24a5836108608c10d35ab",
            "title": "Towards Automatic ICD Coding via Knowledge Enhanced Multi-Task Learning",
            "abstract": "The aim of ICD coding is to assign International Classification of Diseases (ICD) codes to unstructured clinical notes or discharge summaries. Numerous methods have been proposed for automatic ICD coding in an effort to reduce human labor and errors. However, existing works disregard the data imbalance problem of clinical notes. In addition, the noisy clinical note issue has not been thoroughly investigated. To address such issues, we propose a knowledge enhanced Graph Attention Network (GAT) under multi-task learning setting. Specifically, multi-level information transitions and interactions have been implemented. On the one hand, a large heterogeneous text graph is constructed to capture both intra- and inter-note correlations between various semantic concepts, thereby alleviating the data imbalance issue. On the other hand, two auxiliary healthcare tasks have been proposed to facilitate the sharing of information across tasks. Moreover, to tackle the issue of noisy clinical notes, we propose to utilize the rich structured knowledge facts and information provided by medical domain knowledge, thereby encouraging the model to focus on the clinical notes' noteworthy portion and valuable information. The experimental results on the widely-used medical dataset, MIMIC-III, demonstrate the advantages of our proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2144287948",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                }
            ]
        },
        {
            "paperId": "6fb37ff73153d891867cd275e47a285a0cc8de22",
            "title": "Gromov-Wasserstein Guided Representation Learning for Cross-Domain Recommendation",
            "abstract": "Cross-Domain Recommendation (CDR) has attracted increasing attention in recent years as a solution to the data sparsity issue. The fundamental paradigm of prior efforts is to train a mapping function based on the overlapping users/items and then apply it to the knowledge transfer. However, due to the commercial privacy policy and the sensitivity of user data, it is unrealistic to explicitly share the user mapping relations and behavior data. Therefore, in this paper, we consider a more practical cross-domain scenario, where there is no explicit overlap between the source and target domains in terms of users/items. Since the user sets of both domains are drawn from the entire population, there may be commonalities between their user characteristics, resulting in comparable user preference distributions. Thus, without the mapping relations at user level, it is feasible to model this distribution-level relation to transfer knowledge between domains. To this end, we propose a novel framework that improves the effect of representation learning on the target domain by aligning the representation distributions between the source and target domains. In addition, GWCDR can be easily integrated with existing single-domain collaborative filtering methods to achieve cross-domain recommendation. Extensive experiments on two pairs of public bidirectional datasets demonstrate the effectiveness of our proposed framework in enhancing the recommendation performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2382872",
                    "name": "Zhaopeng Qiu"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "1390878075",
                    "name": "Zihao Wang"
                },
                {
                    "authorId": "33603226",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                },
                {
                    "authorId": "144620591",
                    "name": "X. Wu"
                }
            ]
        },
        {
            "paperId": "93d9da4cf14daf5ccff9f82f0d9440b19609fae6",
            "title": "Jointly Learning Knowledge Embedding and Neighborhood Consensus with Relational Knowledge Distillation for Entity Alignment",
            "abstract": "Entity alignment aims at integrating heterogeneous knowledge from different knowledge graphs. Recent studies employ embedding-based methods by first learning the representation of Knowledge Graphs and then performing entity alignment via measuring the similarity between entity embeddings. However, they failed to make good use of the relation semantic information due to the trade-off problem caused by the different objectives of learning knowledge embedding and neighborhood consensus. To address this problem, we propose Relational Knowledge Distillation for Entity Alignment (RKDEA), a Graph Convolutional Network (GCN) based model equipped with knowledge distillation for entity alignment. We adopt GCN-based models to learn the representation of entities by considering the graph structure and incorporating the relation semantic information into GCN via knowledge distillation. Then, we introduce a novel adaptive mechanism to transfer relational knowledge so as to jointly learn entity embedding and neighborhood consensus. Experimental results on several benchmarking datasets demonstrate the effectiveness of our proposed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "33603226",
                    "name": "Yong Zhang"
                },
                {
                    "authorId": "1838264",
                    "name": "Chunxiao Xing"
                }
            ]
        },
        {
            "paperId": "f66bfb81b05996f14010094e9717545a07e5186e",
            "title": "The Emotion Recognition System Based on Support Vector Machines",
            "abstract": "Now speech recognition plays an important role in the filed of human-computer interaction. As the main way to communicate with each other in daily life, voice carries a wealth of emotional information. It is necessary for artificial intelligence to process these information to reach better interaction. In this article, we aim to study a speech emotion recognition system based on support vector machines(SVM), which can recognize different emotions through people\u2019s voice to help people manage their emotions by analysing changes of their emotions. To achieve this goal, we have built a small Chinese voice database including four emotions, each from six different people. We wrote the Matlab program to complete speech feature parameters extraction, model training and emotion recognition, thus realizing the emotion classification of the speech signal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2156252391",
                    "name": "Yuwei Wei"
                },
                {
                    "authorId": "2152007796",
                    "name": "Linghao Kong"
                },
                {
                    "authorId": "78145275",
                    "name": "Xinhang Li"
                },
                {
                    "authorId": "2061164023",
                    "name": "Ming Pan"
                },
                {
                    "authorId": "3087469",
                    "name": "Chengke Tang"
                },
                {
                    "authorId": "2149912655",
                    "name": "Shicong Sun"
                }
            ]
        }
    ]
}