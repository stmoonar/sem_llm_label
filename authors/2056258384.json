{
    "authorId": "2056258384",
    "papers": [
        {
            "paperId": "098be01c95b4c18e2c7e8b4164d29dbb0903e71f",
            "title": "Can a Multichoice Dataset be Repurposed for Extractive Question Answering?",
            "abstract": "The rapid evolution of Natural Language Processing (NLP) has favored major languages such as English, leaving a significant gap for many others due to limited resources. This is especially evident in the context of data annotation, a task whose importance cannot be underestimated, but which is time-consuming and costly. Thus, any dataset for resource-poor languages is precious, in particular when it is task-specific. Here, we explore the feasibility of repurposing existing datasets for a new NLP task: we repurposed the Belebele dataset (Bandarkar et al., 2023), which was designed for multiple-choice question answering (MCQA), to enable extractive QA (EQA) in the style of machine reading comprehension. We present annotation guidelines and a parallel EQA dataset for English and Modern Standard Arabic (MSA). We also present QA evaluation results for several monolingual and cross-lingual QA pairs including English, MSA, and five Arabic dialects. Our aim is to enable others to adapt our approach for the 120+ other language variants in Belebele, many of which are deemed under-resourced. We also conduct a thorough analysis and share our insights from the process, which we hope will contribute to a deeper understanding of the challenges and the opportunities associated with task reformulation in NLP research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298756162",
                    "name": "Teresa Lynn"
                },
                {
                    "authorId": "51935928",
                    "name": "Malik H. Altakrori"
                },
                {
                    "authorId": "148087360",
                    "name": "S. Magdy"
                },
                {
                    "authorId": "2211732585",
                    "name": "Rocktim Jyoti Das"
                },
                {
                    "authorId": "2266387313",
                    "name": "Chenyang Lyu"
                },
                {
                    "authorId": "2056258384",
                    "name": "Mohamed Nasr"
                },
                {
                    "authorId": "2282523149",
                    "name": "Younes Samih"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "1781292",
                    "name": "S. Roukos"
                },
                {
                    "authorId": "2261287685",
                    "name": "Radu Florian"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                }
            ]
        },
        {
            "paperId": "366669ad13ba9cc7c01796739196e34dc4eb5563",
            "title": "The TechQA Dataset",
            "abstract": "We introduce TECHQA, a domain-adaptation question answering dataset for the technical support domain. The TECHQA corpus highlights two real-world issues from the automated customer support domain. First, it contains actual questions posed by users on a technical forum, rather than questions generated specifically for a competition or a task. Second, it has a real-world size \u2013 600 training, 310 dev, and 490 evaluation question/answer pairs \u2013 thus reflecting the cost of creating large labeled datasets with actual data. Hence, TECHQA is meant to stimulate research in domain adaptation rather than as a resource to build QA systems from scratch. TECHQA was obtained by crawling the IBMDeveloper and DeveloperWorks forums for questions with accepted answers provided in an IBM Technote\u2014a technical document that addresses a specific technical issue. We also release a collection of the 801,998 Technotes available on the web as of April 4, 2019 as a companion resource that can be used to learn representations of the IT domain language.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2879453",
                    "name": "Vittorio Castelli"
                },
                {
                    "authorId": "38725355",
                    "name": "Rishav Chakravarti"
                },
                {
                    "authorId": "2066641453",
                    "name": "Saswati Dana"
                },
                {
                    "authorId": "1388016369",
                    "name": "Anthony Ferritto"
                },
                {
                    "authorId": "1707117",
                    "name": "Radu Florian"
                },
                {
                    "authorId": "39038065",
                    "name": "M. Franz"
                },
                {
                    "authorId": "50252087",
                    "name": "Dinesh Garg"
                },
                {
                    "authorId": "50564082",
                    "name": "Dinesh Khandelwal"
                },
                {
                    "authorId": "40454673",
                    "name": "J. Scott McCarley"
                },
                {
                    "authorId": "1404350473",
                    "name": "Mike McCawley"
                },
                {
                    "authorId": "2056258384",
                    "name": "Mohamed Nasr"
                },
                {
                    "authorId": "2101328894",
                    "name": "Lin Pan"
                },
                {
                    "authorId": "1999108",
                    "name": "Cezar Pendus"
                },
                {
                    "authorId": "1993357",
                    "name": "J. Pitrelli"
                },
                {
                    "authorId": "1403641392",
                    "name": "Saurabh Pujar"
                },
                {
                    "authorId": "1781292",
                    "name": "S. Roukos"
                },
                {
                    "authorId": "1389541398",
                    "name": "Andrzej Sakrajda"
                },
                {
                    "authorId": "2707234",
                    "name": "Avirup Sil"
                },
                {
                    "authorId": "1400349389",
                    "name": "Rosario A. Uceda-Sosa"
                },
                {
                    "authorId": "144582029",
                    "name": "T. Ward"
                },
                {
                    "authorId": "2119062987",
                    "name": "Rong Zhang"
                }
            ]
        }
    ]
}