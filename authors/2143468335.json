{
    "authorId": "2143468335",
    "papers": [
        {
            "paperId": "61d134b99099b21cc88b700229140023507ce848",
            "title": "Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels",
            "abstract": "Large language models (LLMs) have shown remarkable performance across various natural language processing (NLP) tasks, indicating their significant potential as data annotators. Although LLM-generated annotations are more cost-effective and efficient to obtain, they are often erroneous for complex or domain-specific tasks and may introduce bias when compared to human annotations. Therefore, instead of completely replacing human annotators with LLMs, we need to leverage the strengths of both LLMs and humans to ensure the accuracy and reliability of annotations. This paper presents a multi-step human-LLM collaborative approach where (1) LLMs generate labels and provide explanations, (2) a verifier assesses the quality of LLM-generated labels, and (3) human annotators re-annotate a subset of labels with lower verification scores. To facilitate human-LLM collaboration, we make use of LLM\u2019s ability to rationalize its decisions. LLM-generated explanations can provide additional information to the verifier model as well as help humans better understand LLM labels. We demonstrate that our verifier is able to identify potentially incorrect LLM labels for human re-annotation. Furthermore, we investigate the impact of presenting LLM labels and explanations on human re-annotation through crowdsourced studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2295486007",
                    "name": "Xinru Wang"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2265753908",
                    "name": "Kushan Mitra"
                },
                {
                    "authorId": "2273964572",
                    "name": "Zhengjie Miao"
                }
            ]
        },
        {
            "paperId": "69069bea10deaa4b6b95450420cb5564a4890aa6",
            "title": "A Blueprint Architecture of Compound AI Systems for Enterprise",
            "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities surpassing conventional NLP challenges, creating opportunities for use in production use cases. Towards this goal, there is a notable shift to building compound AI systems, wherein LLMs are integrated into an expansive software infrastructure with many components like models, retrievers, databases and tools. In this paper, we introduce a blueprint architecture for compound AI systems to operate in enterprise settings cost-effectively and feasibly. Our proposed architecture aims for seamless integration with existing compute and data infrastructure, with ``stream'' serving as the key orchestration concept to coordinate data and instructions among agents and other components. Task and data planners, respectively, break down, map, and optimize tasks and data to available agents and data sources defined in respective registries, given production constraints such as accuracy and latency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2284869489",
                    "name": "Nikita Bhutani"
                },
                {
                    "authorId": "2188417102",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2199811208",
                    "name": "Rafael Li Chen"
                },
                {
                    "authorId": "2265753908",
                    "name": "Kushan Mitra"
                },
                {
                    "authorId": "2121386026",
                    "name": "Sairam Gurajada"
                },
                {
                    "authorId": "1713436",
                    "name": "Pouya Pezeshkpour"
                },
                {
                    "authorId": "7782351",
                    "name": "Hayate Iso"
                },
                {
                    "authorId": "2304573633",
                    "name": "Yanlin Feng"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2305077543",
                    "name": "Chen Shen"
                },
                {
                    "authorId": "2305332661",
                    "name": "Jin Wang"
                },
                {
                    "authorId": "2265753807",
                    "name": "Estevam R. Hruschka"
                }
            ]
        },
        {
            "paperId": "95b5672a7b473b239342948c67c150750efc5e59",
            "title": "Knowledge Acquisition and Integration with Expert-in-the-loop",
            "abstract": "Constructing and serving knowledge graphs (KGs) is an iterative and human-centered process involving on-demand programming and analysis. In this paper, we present Kyurem, a programmable and interactive widget library that facilitates human-in-the-loop knowledge acquisition and integration to enable continuous curation a knowledge graph (KG). Kyurem provides a seamless environment within computational notebooks where data scientists explore a KG to identify opportunities for acquiring new knowledge and verify recommendations provided by AI agents for integrating the acquired knowledge in the KG. We refined Kyurem through participatory design and conducted case studies in a real-world setting for evaluation. The case-studies show that introduction of Kyurem within an existing HR knowledge graph construction and serving platform improved the user experience of the experts and helped eradicate inefficiencies related to knowledge acquisition and integration tasks",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2282535504",
                    "name": "Frederick Choi"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2188417102",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2265753807",
                    "name": "Estevam R. Hruschka"
                }
            ]
        },
        {
            "paperId": "ff9d264896b540f1f4609deb90b6e544038fef3e",
            "title": "MEGAnno+: A Human-LLM Collaborative Annotation System",
            "abstract": "Large language models (LLMs) can label data faster and cheaper than humans for various NLP tasks. Despite their prowess, LLMs may fall short in understanding of complex, sociocultural, or domain-specific context, potentially leading to incorrect annotations. Therefore, we advocate a collaborative approach where humans and LLMs work together to produce reliable and high-quality labels. We present MEGAnno+, a human-LLM collaborative annotation system that offers effective LLM agent and annotation management, convenient and robust LLM annotation, and exploratory verification of LLM labels by humans.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2265753908",
                    "name": "Kushan Mitra"
                },
                {
                    "authorId": "2199811208",
                    "name": "Rafael Li Chen"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2188417102",
                    "name": "Dan Zhang"
                }
            ]
        },
        {
            "paperId": "1312318ae9b8a60ddb2ccfe37c00a4b1b36f1fb8",
            "title": "Towards Multifaceted Human-Centered AI",
            "abstract": "Human-centered AI workflows involve stakeholders with multiple roles interacting with each other and automated agents to accomplish diverse tasks. In this paper, we call for a holistic view when designing support mechanisms, such as interaction paradigms, interfaces, and systems, for these multifaceted workflows.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2188417102",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                }
            ]
        },
        {
            "paperId": "37f4718ccf2ee93eab4a55d281c72d79c270f6ed",
            "title": "MEGAnno: Exploratory Labeling for NLP in Computational Notebooks",
            "abstract": "We present MEGAnno, a novel exploratory annotation framework designed for NLP researchers and practitioners. Unlike existing labeling tools that focus on data labeling only, our framework aims to support a broader, iterative ML workflow including data exploration and model development. With MEGAnno\u2019s API, users can programmatically explore the data through sophisticated search and automated suggestion functions and incrementally update task schema as their project evolve. Combined with our widget, the users can interactively sort, filter, and assign labels to multiple items simultaneously in the same notebook where the rest of the NLP project resides. We demonstrate MEGAnno\u2019s flexible, exploratory, efficient, and seamless labeling experience through a sentiment analysis use case.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145909538",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2199811208",
                    "name": "Rafael Li Chen"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                }
            ]
        },
        {
            "paperId": "d3b5705d6ea1b8ec25504f46d9ff99a65a294e7c",
            "title": "Characterizing Large Language Models as Rationalizers of Knowledge-intensive Tasks",
            "abstract": "Large language models (LLMs) are proficient at generating fluent text with minimal task-specific supervision. Yet, their ability to provide well-grounded rationalizations for knowledge-intensive tasks remains under-explored. Such tasks, like commonsense multiple-choice questions, require rationales based on world knowledge to support predictions and refute alternate options. We consider the task of generating knowledge-guided rationalization in natural language by using expert-written examples in a few-shot manner. Surprisingly, crowd-workers preferred knowledge-grounded rationales over crowdsourced rationalizations, citing their factuality, sufficiency, and comprehensive refutations. Although LLMs-generated rationales were preferable, further improvements in conciseness and novelty are required. In another study, we show how rationalization of incorrect model predictions erodes humans' trust in LLM-generated rationales. Motivated by these observations, we create a two-stage pipeline to review task predictions and eliminate potential incorrect decisions before rationalization, enabling trustworthy rationale generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266166126",
                    "name": "Aditi Mishra"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2265753908",
                    "name": "Kushan Mitra"
                },
                {
                    "authorId": "2265753807",
                    "name": "Estevam R. Hruschka"
                }
            ]
        },
        {
            "paperId": "e1c8f0ba6be57e37ab4fe1759ffecf3b633a97ce",
            "title": "Weedle: Composable Dashboard for Data-Centric NLP in Computational Notebooks",
            "abstract": "Data-centric NLP is a highly iterative process requiring careful exploration of text data throughout entire model development lifecycle. Unfortunately, existing data exploration tools are not suitable to support data-centric NLP because of workflow discontinuity and lack of support for unstructured text. In response, we propose Weedle, a seamless and customizable exploratory text analysis system for data-centric NLP. Weedle is equipped with built-in text transformation operations and a suite of visual analysis features. With its widget, users can compose customizable dashboards interactively and programmatically in computational notebooks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33659517",
                    "name": "Nahyun Kwon"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2188417102",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                }
            ]
        },
        {
            "paperId": "e51ae31d0d0798276bd9c8e3ea28df809e816fc8",
            "title": "Towards Transparent, Reusable, and Customizable Data Science in Computational Notebooks",
            "abstract": "Data science workflows are human-centered processes involving on-demand programming and analysis. While programmable and interactive interfaces such as widgets embedded within computational notebooks are suitable for these workflows, they lack robust state management capabilities and do not support user-defined customization of the interactive components. The absence of such capabilities hinders workflow reusability and transparency while limiting the scope of exploration of the end-users. In response, we developed Magneton, a framework for authoring interactive widgets within computational notebooks that enables transparent, reusable, and customizable data science workflows. The framework enhances existing widgets to support fine-grained interaction history management, reusable states, and user-defined customizations. We conducted three case studies in a real-world knowledge graph construction and serving platform to evaluate the effectiveness of these widgets. Based on the observations, we discuss future implications of employing Magneton widgets for general-purpose data science workflows.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111720780",
                    "name": "Frederick Choi"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2212200534",
                    "name": "Daz Zhang"
                }
            ]
        },
        {
            "paperId": "1ca1a371f8cbfb714126350afd5225eafe7f65ce",
            "title": "Low-resource Interactive Active Labeling for Fine-tuning Language Models",
            "abstract": "Recently, active learning (AL) methods have been used to effectively fine-tune pre-trained language models for various NLP tasks such as sentiment analysis and document classification. However, given the task of fine-tuning language models, understanding the impact of different aspects on AL methods such as labeling cost, sample acquisition latency, and the diversity of the datasets necessitates a deeper investigation. This paper examines the performance of existing AL methods within a low-resource, interactive labeling setting. We observe that existing methods often underperform in such a setting while exhibiting higher latency and a lack of generalizability. To overcome these challenges, we propose a novel active learning method T YROGUE that employs a hybrid sampling strategy to minimize labeling cost and acquisition latency while providing a framework for adapting to dataset diversity via user guidance. Through our experiments, we observe that compared to SOTA methods, T Y - ROGUE reduces the labeling cost by up to 43% and the acquisition latency by as much as 11 X , while achieving comparable accuracy. Finally, we discuss the strengths and weaknesses of T YROGUE by exploring the impact of dataset characteristics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "83776034",
                    "name": "Seiji Maekawa"
                },
                {
                    "authorId": "2145909936",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                }
            ]
        }
    ]
}