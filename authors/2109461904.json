{
    "authorId": "2109461904",
    "papers": [
        {
            "paperId": "06b7a5e3f9487def152d032575867ceca143f4f7",
            "title": "Generalizing Graph ODE for Learning Complex System Dynamics across Environments",
            "abstract": "Learning multi-agent system dynamics have been extensively studied for various real-world applications, such as molecular dynamics in biology, multi-body system prediction in physics, and particle dynamics in material science. Most of the existing models are built to learn single system dynamics, which learn the dynamics from observed historical data and predict the future trajectory. In practice, however, we might observe multiple systems that are generated across different environments, which differ in latent exogenous factors such as temperature and gravity. One simple solution is to learn multiple environment-specific models, but it fails to exploit the potential commonalities among the dynamics across environments and offers poor prediction results where per-environment data is sparse or limited. Here, we present GG-ODE (Generalized Graph Ordinary Differential Equations), a machine learning framework for learning continuous multi-agent system dynamics across environments. Our model learns system dynamics using neural ordinary differential equations (ODE) parameterized by Graph Neural Networks (GNNs) to capture the continuous interaction among agents. We achieve the model generalization by assuming the dynamics across different environments are governed by common physics laws that can be captured via learning a shared ODE function. The distinct latent exogenous factors learned for each environment are incorporated into the ODE function to account for their differences. To improve model performance, we additionally design two regularization losses to (1) enforce the orthogonality between the learned initial states and exogenous factors via mutual information minimization; and (2) reduce the temporal variance of learned exogenous factors within the same system via contrastive learning. Experiments over various physical simulations show that our model can accurately predict system dynamics, especially in the long range, and can generalize well to new systems with few observations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "1ea7006bbc0c0ed2a4172caa2cfe0ff00a4646e6",
            "title": "ProgSG: Cross-Modality Representation Learning for Programs in Electronic Design Automation",
            "abstract": "Recent years have witnessed the growing popularity of domain-specific accelerators (DSAs), such as Google's TPUs, for accelerating various applications such as deep learning, search, autonomous driving, etc. To facilitate DSA designs, high-level synthesis (HLS) is used, which allows a developer to compile a high-level description in the form of software code in C and C++ into a design in low-level hardware description languages (such as VHDL or Verilog) and eventually synthesized into a DSA on an ASIC (application-specific integrated circuit) or FPGA (field-programmable gate arrays). However, existing HLS tools still require microarchitecture decisions, expressed in terms of pragmas (such as directives for parallelization and pipelining). To enable more people to design DSAs, it is desirable to automate such decisions with the help of deep learning for predicting the quality of HLS designs. This requires us a deeper understanding of the program, which is a combination of original code and pragmas. Naturally, these programs can be considered as sequence data, for which large language models (LLM) can help. In addition, these programs can be compiled and converted into a control data flow graph (CDFG), and the compiler also provides fine-grained alignment between the code tokens and the CDFG nodes. However, existing works either fail to leverage both modalities or combine the two in shallow or coarse ways. We propose ProgSG allowing the source code sequence modality and the graph modalities to interact with each other in a deep and fine-grained way. To alleviate the scarcity of labeled designs, a pre-training method is proposed based on a suite of compiler's data flow analysis tasks. Experimental results on two benchmark datasets show the superiority of ProgSG over baseline methods that either only consider one modality or combine the two without utilizing the alignment information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51228791",
                    "name": "Yunsheng Bai"
                },
                {
                    "authorId": "1508161146",
                    "name": "Atefeh Sohrabizadeh"
                },
                {
                    "authorId": "1419556433",
                    "name": "Zongyue Qin"
                },
                {
                    "authorId": "3407296",
                    "name": "Ziniu Hu"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2259796",
                    "name": "J. Cong"
                }
            ]
        },
        {
            "paperId": "4008f607e29cfe6c0cce0b5ae119827380b99031",
            "title": "PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous Link Prediction",
            "abstract": "Transparency and accountability have become major concerns for black-box machine learning (ML) models. Proper explanations for the model behavior increase model transparency and help researchers develop more accountable models. Graph neural networks (GNN) have recently shown superior performance in many graph ML problems than traditional methods, and explaining them has attracted increased interest. However, GNN explanation for link prediction (LP) is lacking in the literature. LP is an essential GNN task and corresponds to web applications like recommendation and sponsored search on web. Given existing GNN explanation methods only address node/graph-level tasks, we propose Path-based GNN Explanation for heterogeneous Link prediction (PaGE-Link) that generates explanations with connection interpretability, enjoys model scalability, and handles graph heterogeneity. Qualitatively, PaGE-Link can generate explanations as paths connecting a node pair, which naturally captures connections between the two nodes and easily transfer to human-interpretable explanations. Quantitatively, explanations generated by PaGE-Link improve AUC for recommendation on citation and user-item graphs by 9 - 35% and are chosen as better by 78.79% of responses in human evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145408511",
                    "name": "Shichang Zhang"
                },
                {
                    "authorId": "73329314",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2118943843",
                    "name": "Xiang Song"
                },
                {
                    "authorId": "2121390172",
                    "name": "Soji Adeshina"
                },
                {
                    "authorId": "122579067",
                    "name": "Da Zheng"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "45a6f7ca23944aa2050c2bc6d6a580058d032b30",
            "title": "Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation",
            "abstract": "Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks. To test the potential of the dataset, we introduce three tasks in this work: (1) next-product recommendation, (2) next-product recommendation with domain shifts, and (3) next-product title generation. With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice. In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 2023 and have attracted thousands of users and submissions. The winning solutions and the associated workshop can be accessed at our website https://kddcup23.github.io/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "5795999",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2149891871",
                    "name": "Hanqing Lu"
                },
                {
                    "authorId": "8492168",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "47370334",
                    "name": "Ruirui Li"
                },
                {
                    "authorId": "1700892",
                    "name": "Z. Li"
                },
                {
                    "authorId": "2072995251",
                    "name": "Mo Cheng"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2893721",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "48784944",
                    "name": "Xianfeng Tang"
                }
            ]
        },
        {
            "paperId": "4993258852711c4e3d0011325ac3db680eae84f4",
            "title": "SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models",
            "abstract": "Most of the existing Large Language Model (LLM) benchmarks on scientific problem reasoning focus on problems grounded in high-school subjects and are confined to elementary algebraic operations. To systematically examine the reasoning capabilities required for solving complex scientific problems, we introduce an expansive benchmark suite SciBench for LLMs. SciBench contains a carefully curated dataset featuring a range of collegiate-level scientific problems from mathematics, chemistry, and physics domains. Based on the dataset, we conduct an in-depth benchmarking study of representative open-source and proprietary LLMs with various prompting strategies. The results reveal that the current LLMs fall short of delivering satisfactory performance, with the best overall score of merely 43.22%. Furthermore, through a detailed user study, we categorize the errors made by LLMs into ten problem-solving abilities. Our analysis indicates that no single prompting strategy significantly outperforms the others and some strategies that demonstrate improvements in certain problem-solving skills could result in declines in other skills. We envision that SciBench will catalyze further developments in the reasoning abilities of LLMs, thereby ultimately contributing to scientific research and discovery.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2224092326",
                    "name": "Xiaoxuan Wang"
                },
                {
                    "authorId": "3407296",
                    "name": "Ziniu Hu"
                },
                {
                    "authorId": "2887562",
                    "name": "Pan Lu"
                },
                {
                    "authorId": "2653121",
                    "name": "Yanqiao Zhu"
                },
                {
                    "authorId": "47540245",
                    "name": "Jieyu Zhang"
                },
                {
                    "authorId": "2224018745",
                    "name": "Satyen Subramaniam"
                },
                {
                    "authorId": "2224017080",
                    "name": "Arjun R. Loomba"
                },
                {
                    "authorId": "2145408511",
                    "name": "Shichang Zhang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "55b8ad6068cd9a5dd9e5109778ac84bc4bdbaa6e",
            "title": "HOPE: High-order Graph ODE For Modeling Interacting Dynamics",
            "abstract": "Leading graph ordinary differential equation (ODE) models have offered generalized strategies to model interacting multi-agent dynamical systems in a data-driven approach. They typically consist of a temporal graph encoder to get the initial states and a neural ODE-based generative model to model the evolution of dynamical systems. However, existing methods have severe deficiencies in capacity and efficiency due to the failure to model high-order correlations in long-term temporal trends. To tackle this, in this paper, we propose a novel model named High-Order graPh ODE (HOPE) for learning from dynamic interaction data, which can be naturally represented as a graph. It first adopts a twin graph encoder to initialize the latent state representations of nodes and edges, which consists of two branches to capture spatio-temporal correlations in complementary manners. More importantly, our HOPE utilizes a second-order graph ODE function which models the dynamics for both nodes and edges in the latent space respectively, which enables efficient learning of long-term dependencies from complex dynamical systems. Experiment results on a variety of datasets demonstrate both the effectiveness and efficiency of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145263905",
                    "name": "Xiao Luo"
                },
                {
                    "authorId": "2214118441",
                    "name": "Jingyang Yuan"
                },
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "2229011998",
                    "name": "Huiyu Jiang"
                },
                {
                    "authorId": "2420154",
                    "name": "Yifang Qin"
                },
                {
                    "authorId": "2154453854",
                    "name": "Wei Ju"
                },
                {
                    "authorId": "1596795872",
                    "name": "Ming Zhang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "58820d7d68e12d2a531e771a5fcb7e461c25f5c6",
            "title": "Neural Compositional Rule Learning for Knowledge Graph Reasoning",
            "abstract": "Learning logical rules is critical to improving reasoning in KGs. This is due to their ability to provide logical and interpretable explanations when used for predictions, as well as their ability to generalize to other tasks, domains, and data. While recent methods have been proposed to learn logical rules, the majority of these methods are either restricted by their computational complexity and can not handle the large search space of large-scale KGs, or show poor generalization when exposed to data outside the training set. In this paper, we propose an end-to-end neural model for learning compositional logical rules called NCRL. NCRL detects the best compositional structure of a rule body, and breaks it into small compositions in order to infer the rule head. By recurrently merging compositions in the rule body with a recurrent attention unit, NCRL finally predicts a single rule head. Experimental results show that NCRL learns high-quality rules, as well as being generalizable. Specifically, we show that NCRL is scalable, efficient, and yields state-of-the-art results for knowledge graph completion on large-scale KGs. Moreover, we test NCRL for systematic generalization by learning to reason on small-scale observed graphs and evaluating on larger unseen ones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3161399",
                    "name": "Kewei Cheng"
                },
                {
                    "authorId": "47699955",
                    "name": "Nesreen Ahmed"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "77f2c139ce2abaeed0bc6feda721fea7eaf62277",
            "title": "Trustworthy Recommendation and Search: Introduction to the Special Issue - Part 1",
            "abstract": "\u2022",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "1747560",
                    "name": "Guandong Xu"
                },
                {
                    "authorId": "1713134",
                    "name": "E. Kanoulas"
                }
            ]
        },
        {
            "paperId": "7b3bc0c8e9597f2b0e733fc3728c5caf6647213f",
            "title": "CF-GODE: Continuous-Time Causal Inference for Multi-Agent Dynamical Systems",
            "abstract": "Multi-agent dynamical systems refer to scenarios where multiple units (aka agents) interact with each other and evolve collectively over time. For instance, people's health conditions are mutually influenced. Receiving vaccinations not only strengthens the long-term health status of one unit but also provides protection for those in their immediate surroundings. To make informed decisions in multi-agent dynamical systems, such as determining the optimal vaccine distribution plan, it is essential for decision-makers to estimate the continuous-time counterfactual outcomes. However, existing studies of causal inference over time rely on the assumption that units are mutually independent, which is not valid for multi-agent dynamical systems. In this paper, we aim to bridge this gap and study how to estimate counterfactual outcomes in multi-agent dynamical systems. Causal inference in a multi-agent dynamical system has unique challenges: 1) Confounders are time-varying and are present in both individual unit covariates and those of other units; 2) Units are affected by not only their own but also others' treatments; 3) The treatments are naturally dynamic, such as receiving vaccines and boosters in a seasonal manner. To this end, we model a multi-agent dynamical system as a graph and propose a novel model called CF-GODE (C ounterFactual Graph Ordinary Differential Equations). CF-GODE is a causal model that estimates continuous-time counterfactual outcomes in the presence of inter-dependencies between units. To facilitate continuous-time estimation, we propose Treatment-Induced GraphODE, a novel ordinary differential equation based on graph neural networks (GNNs), which can incorporate dynamical treatments as additional inputs to predict potential outcomes over time. To remove confounding bias, we propose two domain adversarial learning based objectives that learn balanced continuous representation trajectories, which are not predictive of treatments and interference. We further provide theoretical justification to prove their effectiveness. Experiments on two semi-synthetic datasets confirm that CF-GODE outperforms baselines on counterfactual estimation. We also provide extensive analyses to understand how our model works.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2108719385",
                    "name": "Song Jiang"
                },
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "2220669584",
                    "name": "Xiao Luo"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "894d61c709ec6f61899703458d90b09c663d7b11",
            "title": "A Survey on Graph Neural Network Acceleration: Algorithms, Systems, and Customized Hardware",
            "abstract": "Graph neural networks (GNNs) are emerging for machine learning research on graph-structured data. GNNs achieve state-of-the-art performance on many tasks, but they face scalability challenges when it comes to real-world applications that have numerous data and strict latency requirements. Many studies have been conducted on how to accelerate GNNs in an effort to address these challenges. These acceleration techniques touch on various aspects of the GNN pipeline, from smart training and inference algorithms to efficient systems and customized hardware. As the amount of research on GNN acceleration has grown rapidly, there lacks a systematic treatment to provide a unified view and address the complexity of relevant works. In this survey, we provide a taxonomy of GNN acceleration, review the existing approaches, and suggest future research directions. Our taxonomic treatment of GNN acceleration connects the existing works and sets the stage for further development in this area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145408511",
                    "name": "Shichang Zhang"
                },
                {
                    "authorId": "2242000525",
                    "name": "Atefeh Sohrabizadeh"
                },
                {
                    "authorId": "2158998114",
                    "name": "Cheng Wan"
                },
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "3407296",
                    "name": "Ziniu Hu"
                },
                {
                    "authorId": "27035995",
                    "name": "Yewen Wang"
                },
                {
                    "authorId": "3138925",
                    "name": "Yingyan Lin"
                },
                {
                    "authorId": "2066032921",
                    "name": "J. Cong"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        }
    ]
}