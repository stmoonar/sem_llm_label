{
    "authorId": "2266472645",
    "papers": [
        {
            "paperId": "0872173a4358b11f1fdbed18a432aa9cbe8bf67d",
            "title": "Lq Lower Bounds on Distributed Estimation via Fisher Information",
            "abstract": "Van Trees inequality, also known as the Bayesian Cram\u00e9r- Rao lower bound, is a powerful tool for establishing lower bounds for minimax estimation through Fisher information. It easily adapts to different statistical models and often yields tight bounds. Recently, its application has been extended to distributed estimation with privacy and communication constraints where it yields order-wise optimal minimax lower bounds for various parametric tasks under squared $L_{2}$ loss. However, a widely perceived drawback of the van Trees inequality is that it is limited to squared $L_{2}$ loss. The goal of this paper is to dispel that perception by introducing a strengthened version of the van Trees inequality that applies to general $L_{q}$ loss functions by building on the Efroimovich's inequality - a lesser-known entropic inequality dating back to the $1970\\mathrm{s}$. We then apply the generalized van Trees inequality to lower bound $L_{q}$ loss in distributed minimax estimation under communication and local differential privacy constraints. This leads to lower bounds for $L_{q}$ loss that apply to sequentially interactive and blackboard communication protocols. Additionally, we show how the generalized van Trees inequality can be used to obtain local and non-asymptotic minimax results that capture the hardness of estimating each instance at finite sample sizes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109085368",
                    "name": "Wei-Ning Chen"
                },
                {
                    "authorId": "2266472645",
                    "name": "Ayfer \u00d6zg\u00fcr"
                }
            ]
        },
        {
            "paperId": "282b3f1e3fec0ad906bc7369de6b3eab30226e53",
            "title": "Over-the-Air Histogram Estimation",
            "abstract": "We consider the problem of secure histogram es-timation, where $n$ users hold private items xi from a size-d domain and a server aims to estimate the histogram of the user items. Previous results utilizing orthogonal communication schemes have shown that this problem can be solved securely with a total communication cost of O(n2log(d)) bits by hiding each item xi with a mask. In this paper, we offer a different approach to achieving secure aggregation. Instead of masking the data, our scheme protects individuals by aggregating their messages via a multiple-access channel. A naive communication scheme over the multiple-access channel requires $d$ channel uses, which is generally worse than the O(n21og(d)) bits communication cost of the prior art in the most relevant regime $d$ >> $n$. Instead, we propose a new scheme that we call Over-the-Air Group Testing (AirG T) which uses group testing codes to solve the histogram estimation problem in O(n log(d)) channel uses. AirGT reconstructs the histogram exactly with a vanishing probability of error Perror= O(d-T) that drops exponentially in the number of channel uses $T$.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065817189",
                    "name": "Henrik Hellstr\u00f6m"
                },
                {
                    "authorId": "2316834141",
                    "name": "Jiwon Jeong"
                },
                {
                    "authorId": "2109085368",
                    "name": "Wei-Ning Chen"
                },
                {
                    "authorId": "2266472645",
                    "name": "Ayfer \u00d6zg\u00fcr"
                },
                {
                    "authorId": "2248167519",
                    "name": "Viktoria Fodor"
                },
                {
                    "authorId": "2285059879",
                    "name": "Carlo Fischione"
                }
            ]
        },
        {
            "paperId": "934d295b01d8fc5b039491e9b8745950b690a221",
            "title": "Universal Exact Compression of Differentially Private Mechanisms",
            "abstract": "To reduce the communication cost of differential privacy mechanisms, we introduce a novel construction, called Poisson private representation (PPR), designed to compress and simulate any local randomizer while ensuring local differential privacy. Unlike previous simulation-based local differential privacy mechanisms, PPR exactly preserves the joint distribution of the data and the output of the original local randomizer. Hence, the PPR-compressed privacy mechanism retains all desirable statistical properties of the original privacy mechanism such as unbiasedness and Gaussianity. Moreover, PPR achieves a compression size within a logarithmic gap from the theoretical lower bound. Using the PPR, we give a new order-wise trade-off between communication, accuracy, central and local differential privacy for distributed mean estimation. Experiment results on distributed mean estimation show that PPR consistently gives a better trade-off between communication, accuracy and central differential privacy compared to the coordinate subsampled Gaussian mechanism, while also providing local differential privacy.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2283783294",
                    "name": "Yanxiao Liu"
                },
                {
                    "authorId": "2109085368",
                    "name": "Wei-Ning Chen"
                },
                {
                    "authorId": "2266472645",
                    "name": "Ayfer \u00d6zg\u00fcr"
                },
                {
                    "authorId": "2281716099",
                    "name": "Cheuk Ting Li"
                }
            ]
        },
        {
            "paperId": "5e7c0f64a0f228362c69951c2157245ff227258d",
            "title": "Federated Experiment Design under Distributed Differential Privacy",
            "abstract": "Experiment design has a rich history dating back over a century and has found many critical applications across various fields since then. The use and collection of users' data in experiments often involve sensitive personal information, so additional measures to protect individual privacy are required during data collection, storage, and usage. In this work, we focus on the rigorous protection of users' privacy (under the notion of differential privacy (DP)) while minimizing the trust toward service providers. Specifically, we consider the estimation of the average treatment effect (ATE) under DP, while only allowing the analyst to collect population-level statistics via secure aggregation, a distributed protocol enabling a service provider to aggregate information without accessing individual data. Although a vital component in modern A/B testing workflows, private distributed experimentation has not previously been studied. To achieve DP, we design local privatization mechanisms that are compatible with secure aggregation and analyze the utility, in terms of the width of confidence intervals, both asymptotically and non-asymptotically. We show how these mechanisms can be scaled up to handle the very large number of participants commonly found in practice. In addition, when introducing DP noise, it is imperative to cleverly split privacy budgets to estimate both the mean and variance of the outcomes and carefully calibrate the confidence intervals according to the DP noise. Last, we present comprehensive experimental evaluations of our proposed schemes and show the privacy-utility trade-offs in experiment design.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2109085368",
                    "name": "Wei-Ning Chen"
                },
                {
                    "authorId": "2254587151",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "2528900",
                    "name": "Akash Bharadwaj"
                },
                {
                    "authorId": "2265647990",
                    "name": "Peter Romov"
                },
                {
                    "authorId": "2266472645",
                    "name": "Ayfer \u00d6zg\u00fcr"
                }
            ]
        },
        {
            "paperId": "14e6dc9ed789ee8dfe4a8b8cc085119968f99547",
            "title": "Sparse Combinatorial Group Testing for Low-Energy Massive Random Access",
            "abstract": "We present random access schemes for machine-type communication where a massive number of low-energy wireless devices want to occasionally transmit short information packets. We focus on the device discovery problem, with extensions to joint discovery and data transmission as well as data transmission without communicating device identities. We formulate this problem as a combinatorial group testing one, where the goal is to exactly identify the set of at most $d$ defective items from a pool of $n$ items. We translate the energy constraint at the physical layer to a constraint on the number of tests each item can participate in, and study the resulting \"sparse\" combinatorial group testing problem. \nIn our sparse setting, we restrict the number of tests each item can participate in by $w_{\\max}$. It is easy to observe that if $w_{\\max} \\leq d$, then we must have $t=n$; i.e., testing every item individually is optimal. We show that if $w_{\\max}=d+1$, the number of tests decreases suddenly from $t=n$ to $t = (d+1)\\sqrt{n}$. More generally, if $w_{\\max}=ld+1$ for any positive integer $l$ such that $ld+1 \\leq \\sqrt[l+1]{n}$, we can achieve $t=(ld+1)n^{1/(l+1)}$ using Kautz and Singleton's construction with a particular choice of field size. We also prove a nearly matching lower bound which shows that $t = \\Omega(d^{2/l+1}n^{1/(l+1)})$. This shows that in the sparse setting $t$ is a fractional power of $n$, rather than logarithmic in $n$ as in the classical setting. \nSince encoding and decoding efficiency can be just as important as energy efficiency, we demonstrate that our construction can be decoded in (poly$(d) + O(t)$)-time and each entry in any codeword can be computed in space poly$(\\log n)$. This shows that our construction not only (nearly) achieves the fundamental lower bound, but also does that with a favorable encoding and decoding complexity.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3058104",
                    "name": "Huseyin A. Inan"
                },
                {
                    "authorId": "3115341",
                    "name": "P. Kairouz"
                },
                {
                    "authorId": "2266472645",
                    "name": "Ayfer \u00d6zg\u00fcr"
                }
            ]
        }
    ]
}