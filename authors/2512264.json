{
    "authorId": "2512264",
    "papers": [
        {
            "paperId": "b7be6a4ccdcd854538c9cd6de296e3136b7627a5",
            "title": "Identifying and Consolidating Knowledge Engineering Requirements",
            "abstract": "Knowledge engineering is the process of creating and maintaining knowledge-producing systems. Throughout the history of computer science and AI, knowledge engineering workflows have been widely used because high-quality knowledge is assumed to be crucial for reliable intelligent agents. However, the landscape of knowledge engineering has changed, presenting four challenges: unaddressed stakeholder requirements, mismatched technologies, adoption barriers for new organizations, and misalignment with software engineering practices. In this paper, we propose to address these challenges by developing a reference architecture using a mainstream software methodology. By studying the requirements of different stakeholders and eras, we identify 23 essential quality attributes for evaluating reference architectures. We assess three candidate architectures from recent literature based on these attributes. Finally, we discuss the next steps towards a comprehensive reference architecture, including prioritizing quality attributes, integrating components with complementary strengths, and supporting missing socio-technical requirements. As this endeavor requires a collaborative effort, we invite all knowledge engineering researchers and practitioners to join us.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39460142",
                    "name": "Bradley Paul Allen"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2206282787",
                    "name": "Saurav Joshi"
                }
            ]
        },
        {
            "paperId": "d9dd13e33a77f298746ba77908423df0cfb13c3c",
            "title": "Where Does Bias in Common Sense Knowledge Models Come From?",
            "abstract": "Common Sense knowledge bases and models have been shown to embed bias. We investigate the source of such bias in a knowledge model called common sense transformer (COMET) by training it on various combinations of language models and knowledge bases. We experiment with three language models of different sizes and architectures, and two knowledge bases with different modeling principles. We use sentiment and regard as proxy measures of bias and analyze bias using three methods: overgeneralization and disparity, keyword outliers, and relational dimensions. Our results show that larger models tend to be more nuanced in their biases but are more biased than smaller models in certain categories (e.g., utility of religions), which can be attributed to the larger knowledge accumulated during pretraining. We also observe that training on a larger set of common sense knowledge typically leads to more bias, and that models generally have stronger negative regard than positive.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "70716913",
                    "name": "S. Melotte"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2145417960",
                    "name": "Linglan Zhang"
                },
                {
                    "authorId": "1379948038",
                    "name": "Aditya Malte"
                },
                {
                    "authorId": "2100925684",
                    "name": "Namita Mutha"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "51997673",
                    "name": "Ninareh Mehrabi"
                }
            ]
        },
        {
            "paperId": "dc4abd75cb5e9a07b2533cf588bc5da41c131981",
            "title": "A Study of Slang Representation Methods",
            "abstract": "Considering the large amount of content created online by the minute, slang-aware automatic tools are critically needed to promote social good, and assist policymakers and moder- ators in restricting the spread of offensive language, abuse, and hate speech. Despite the success of large language mod- els and the spontaneous emergence of slang dictionaries, it is unclear how far their combination goes in terms of slang un- derstanding for downstream social good tasks. In this paper, we provide a framework to study different combinations of representation learning models and knowledge resources for a variety of downstream tasks that rely on slang understanding. Our experiments show the superiority of models that have been pre-trained on social media data, while the impact of dictionaries is positive only for static word embeddings. Our error analysis identi\ufb01es core challenges for slang representa- tion learning, including out-of-vocabulary words, polysemy, variance, and annotation disagreements, which can be traced to characteristics of slang as a quickly evolving and highly subjective language.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196140253",
                    "name": "Aravinda Kolla"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "0f21f87dc9460356627d6ac7c53cc92d19233d4d",
            "title": "User-friendly Comparison of Similarity Algorithms on Wikidata",
            "abstract": "While the similarity between two concept words has been evaluated and studied for decades, much less attention has been devoted to algorithms that can compute the similarity of nodes in very large knowledge graphs, like Wikidata. To facilitate investigations and head-to-head comparisons of similarity algorithms on Wikidata, we present a user-friendly interface that allows flexible computation of similarity between Qnodes in Wikidata. At present, the similarity interface supports four algorithms, based on: graph embeddings (TransE, ComplEx), text embeddings (BERT), and class-based similarity. We demonstrate the behavior of the algorithms on representative examples about semantically similar, related, and entirely unrelated entity pairs. To support anticipated applications that require efficient similarity computations, like entity linking and recommendation, we also provide a REST API that can compute most similar neighbors for any Qnode in Wikidata.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "144171096",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "1840215",
                    "name": "Gleb Satyukov"
                },
                {
                    "authorId": "2116288277",
                    "name": "Amandeep Singh"
                }
            ]
        },
        {
            "paperId": "28a5a53dafacebad8a7c47773079caeffb9a5baa",
            "title": "Representing Numbers in NLP: a Survey and a Vision",
            "abstract": "NLP systems rarely give special consideration to numbers found in text. This starkly contrasts with the consensus in neuroscience that, in the brain, numbers are represented differently from words. We arrange recent NLP work on numeracy into a comprehensive taxonomy of tasks and methods. We break down the subjective notion of numeracy into 7 subtasks, arranged along two dimensions: granularity (exact vs approximate) and units (abstract vs grounded). We analyze the myriad representational choices made by over a dozen previously published number encoders and decoders. We synthesize best practices for representing numbers in text and articulate a vision for holistic numeracy in NLP, comprised of design trade-offs and a unified evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37574242",
                    "name": "Avijit Thawani"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "144171096",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                }
            ]
        },
        {
            "paperId": "572b9183d3eaf45a31c9308f20e420c5f922588e",
            "title": "Do Language Models Perform Generalizable Commonsense Inference?",
            "abstract": "Inspired by evidence that pretrained language models (LMs) encode commonsense knowledge, recent work has applied LMs to automatically populate commonsense knowledge graphs (CKGs). However, there is a lack of understanding on their generalization to multiple CKGs, unseen relations, and novel entities. This paper analyzes the ability of LMs to perform generalizable commonsense inference, in terms of knowledge capacity, transferability, and induction. Our experiments with these three aspects show that: (1) LMs can adapt to different schemas defined by multiple CKGs but fail to reuse the knowledge to generalize to new relations. (2) Adapted LMs generalize well to unseen subjects, but less so on novel objects. Future work should investigate how to improve the transferability and induction of commonsense mining from LMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118952190",
                    "name": "Peifeng Wang"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "1998918",
                    "name": "Muhao Chen"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "5b34ec04d92c391800dbd5094559eec143638acd",
            "title": "Demo: Knowledge Graph-Based Housing Market Analysis",
            "abstract": "The housing market is complex and multi-faceted, which makes its analysis challenging for users and professionals. We develop a four-step knowledge graph-based knowledge extraction approach for the housing market for efficient and accurate data analysis, consisting of data acquisition and cleaning, entity linking, ontology mapping, and question answering. The proposed system allows one to summarize the housing information for a selected geographical area, analyze the surroundings by collecting census data, understand the medical safety based on COVID-19 data, and the area attractiveness based on celebrities data from DBpedia. Our system can provide personalized recommendations given keywords and information about the market over time. A user-based evaluation demonstrates the utility of our system. Copyright \u00a9 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2454959",
                    "name": "Ziping Hu"
                },
                {
                    "authorId": "2116254135",
                    "name": "Zepei Zhao"
                },
                {
                    "authorId": "144023926",
                    "name": "Mohammad Rostami"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "1720805839",
                    "name": "Basel Shbita"
                }
            ]
        },
        {
            "paperId": "6c7d9b1e9d11e9ca0da5cfadaed75b3071c02922",
            "title": "Open Drug Knowledge Graph",
            "abstract": ". Automatic knowledge-based systems can assist medical professionals to make more informed recommendations and decisions. Unfortunately, as no comprehensive knowledge base (with both medical and non-medical) knowledge exists today, much manual e\ufb00ort is required to consolidate knowledge across sources, that are heterogeneous in content and formats. In this paper, we propose a knowledge-based method that aims to harmonize four such heterogeneous sources into a single drug-centric knowledge graph. The graph is based on the drugs found in Wiki-data, and extended with specialized sources through an extraction and transformation pipeline, including data acquisition, entity resolution, and semantic modeling. Our analyses show that the resulting graph and its embeddings can capture drug similarity through their associated symptoms, and thus address common, knowledge-intensive medical search scenarios. As such, it holds the promise to be adapted for drug recommendation in the future. Given the modular setup of our method, new sources can be included to accommodate healthcare object use cases, relating to diagnoses and claims. We make the resulting knowledge source available in both relational database and property graph format.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "11402954",
                    "name": "M. Mann"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "144023926",
                    "name": "Mohammad Rostami"
                },
                {
                    "authorId": "1720805839",
                    "name": "Basel Shbita"
                }
            ]
        },
        {
            "paperId": "99998cf5d23b0edff5c2061119d2e06a9a4e4d0f",
            "title": "Analyzing Race and Country of Citizenship Bias in Wikidata",
            "abstract": "As an open and collaborative knowledge graph created by users and bots, it is possible that the knowledge in Wikidata is biased in regards to multiple factors such as gender, race, and country of citizenship. Previous work has mostly studied the representativeness of Wikidata knowledge in terms of genders of people. In this paper, we examine the race and citizenship bias in general and in regards to STEM representation for scientists, software developers, and engineers. By comparing Wikidata queries to real-world datasets, we identify the differences in representation to characterize the biases present in Wikidata. Through this analysis, we discovered that there is an overrepresentation of white individuals and those with citizenship in Europe and North America; the rest of the groups are generally underrepresented. Based on these findings, we have found and linked to Wikidata additional data about STEM scientists from the minorities. This data is ready to be inserted into Wikidata with a bot. Increasing representation of minority race and country of citizenship groups can create a more accurate portrayal of individuals in STEM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123038942",
                    "name": "Zaina Shaik"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                }
            ]
        },
        {
            "paperId": "ad34afb13e054e281b20a85e93f90cc9573ec636",
            "title": "CoreQuisite: Circumstantial Preconditions of Common Sense Knowledge",
            "abstract": "The task of identifying and reasoning with circumstantial preconditions associated with everyday facts is natural to humans. It is unclear whether state-of-the-art language models (LMs) understand the implicit preconditions that enable or invalidate commonsense facts, such as \"A glass is used for drinking water\", Despite their impressive accuracy on existing commonsense tasks. In this paper, we propose a new problem of reasoning with circumstantial preconditions, and present a dataset, called CoreQuisite, which annotates commonsense facts with preconditions expressed in natural language. Based on this resource, we create three canonical evaluation tasks and use them to examine the capability of existing LMs to understand situational pre-conditions. Our results show that there is a 10-30%gap between machine and human performance on our tasks. We make all resources and software publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064322437",
                    "name": "Ehsan Qasemi"
                },
                {
                    "authorId": "2512264",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "1998918",
                    "name": "Muhao Chen"
                },
                {
                    "authorId": "144171096",
                    "name": "Pedro A. Szekely"
                }
            ]
        }
    ]
}