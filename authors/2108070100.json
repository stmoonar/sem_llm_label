{
    "authorId": "2108070100",
    "papers": [
        {
            "paperId": "0553ff6d10a8dd377d6d0c171f8612231b7211a2",
            "title": "DriveLLM: Charting the Path Toward Full Autonomous Driving With Large Language Models",
            "abstract": "Human drivers instinctively reason with commonsense knowledge to predict hazards in unfamiliar scenarios and to understand the intentions of other road users. However, this essential capability is entirely missing from traditional decision-making systems in autonomous driving. In response, this paper presents DriveLLM, a decision-making framework that integrates large language models (LLMs) with existing autonomous driving stacks. This integration allows for commonsense reasoning in decision-making. DriveLLM also features a unique cyber-physical feedback system, allowing it to learn and improve from its mistakes. In real-world case studies, the proposed framework outperforms traditional decision-making methods in complex scenarios, including difficult edge cases. Furthermore, we propose a novel approach that allows the decision-making system to interact with human inputs while guarding against adversarial attacks. Empirical evaluations demonstrate that this framework responds correctly to complex human instructions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240267661",
                    "name": "Yaodong Cui"
                },
                {
                    "authorId": "2262083909",
                    "name": "Shucheng Huang"
                },
                {
                    "authorId": "2262085909",
                    "name": "Jiaming Zhong"
                },
                {
                    "authorId": "2262078747",
                    "name": "Zhenan Liu"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2118831257",
                    "name": "Chen Sun"
                },
                {
                    "authorId": "2118424373",
                    "name": "Bai Li"
                },
                {
                    "authorId": "2198887839",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2240033250",
                    "name": "A. Khajepour"
                }
            ]
        },
        {
            "paperId": "18c4a235641e482016c94d6bdc8172fec212645d",
            "title": "The Emerging Intelligent Vehicles and Intelligent Vehicle Carriers Collaborative Systems",
            "abstract": "In this paper, we propose the innovative use of Intelligent Vehicle Carriers (IVCs) as a key solution to address the energy constraints of small-scale unmanned Intelligent Vehicles (IVs). IVCs function as both transporters and charging stations, significantly boosting the operational range and efficiency of IVs. Our research delves into the IV-IVC collaborative framework, highlighting the existing challenges, exploring potential solutions, and examining a range of applications. This study offers a visionary approach to revolutionizing intelligent transportation systems by leveraging the synergistic relationship between IVs and IVCs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243374479",
                    "name": "Zhipeng Shen"
                },
                {
                    "authorId": "2299911464",
                    "name": "Chao Huang"
                },
                {
                    "authorId": "2243332823",
                    "name": "Hailong Huang"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2302792308",
                    "name": "Fei-Yue Wang"
                },
                {
                    "authorId": "2311592221",
                    "name": "Abbas Jamalipour"
                },
                {
                    "authorId": "143842530",
                    "name": "D. Pham"
                },
                {
                    "authorId": "2290231759",
                    "name": "Ljubo B. Vlacic"
                },
                {
                    "authorId": "2311590004",
                    "name": "Andrey V. Savkin"
                }
            ]
        },
        {
            "paperId": "191e0be027f3aad00ed3e4cdc0ccdc85004207ca",
            "title": "eVTOL Performance Analysis: A Review From Control Perspectives",
            "abstract": "Electric Vertical Takeoff and Landing (eVTOL) aircraft has gained significant attention as a basic element of urban air mobility (UAM), a potential solution for urban transportation challenges using low-altitude urban airspace. Ensuring the safe operation of eVTOL is crucial for UAM applications, which are related to various professional fields such as aerodynamics, control, structures, and power systems. This article systematically analyzes the characteristics of different design configurations, including multi-rotor, lift+cruise, and tilt-rotor types of eVTOL. The advantages and limitations of each type of eVTOL are analyzed. After that, the overall design problems are analyzed, and challenges of eVTOL control system design are discussed from aspects of overall control structure and subsystems, such as controller, sensors, actuators, and command generator. This article tries to fill the gap in the eVTOL design from a control perspective and provides some resolutions for the eVTOL application.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296745050",
                    "name": "Jiangcheng Su"
                },
                {
                    "authorId": "2243332823",
                    "name": "Hailong Huang"
                },
                {
                    "authorId": "2296573331",
                    "name": "Hong Zhang"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "1de62628b8723d09ade7b9e57bde0675c647366d",
            "title": "Sora-Based Parallel Vision for Smart Sensing of Intelligent Vehicles: From Foundation Models to Foundation Intelligence",
            "abstract": "There are a large number of functional sensors installed on the modern intelligent vehicles. Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268703418",
                    "name": "Hongkai Yu"
                },
                {
                    "authorId": "2282086298",
                    "name": "Xinyu Liu"
                },
                {
                    "authorId": "32847052",
                    "name": "Yonglin Tian"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2266597382",
                    "name": "Chao Gou"
                },
                {
                    "authorId": "2281911263",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "4b220012ed1de257d530f22c9e65ec48699580a9",
            "title": "Parameter Identification and Refinement for Parallel PCB Inspection in Cyber\u2013Physical\u2013Social Systems",
            "abstract": "Replacing manual inspection, automated optical inspection (AOI) equipment is widely used in printed circuit board (PCB) factories for automatic PCB defect segmentation. However, parameter refinement of AOI devices has gradually become an efficiency bottleneck in AOI usage, posing a highly challenging task. Since a large number of AOI parameters and different types of inspected objects make timely proper parameter refinement for clear images quite difficult. Considering this, we propose the concept of parallel PCB inspection in cyber\u2013physical\u2013social systems (CPSSs). Based on artificial systems, computational experiments, and parallel execution (ACP) theory with automatic parameter identification and refinement, we perform descriptive intelligence to build an artificial imaging system, obtain knowledge about the mapping relationships of parameter settings and imaging results, and realize automatic parameter identification given image input; conduct predictive intelligence to obtain image quality assessment results and maximize quality score for refinement strategies; and carry out prescriptive intelligence to guide parameter refinement for better imaging. This system could guide engineers proactively with constructive suggestions on parameter refinement when imaging failures occur, greatly reducing the training cost of engineers while improving work efficiency and work quality. To validate that our parallel PCB inspection could perform automatic AOI results evaluation without human participation, we evaluate it on distortion-free and different distortion images and confirm image quality score is positively associated with segmentation accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2141058721",
                    "name": "Yansong Cao"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "48094230",
                    "name": "Jiangong Wang"
                },
                {
                    "authorId": "32847052",
                    "name": "Yonglin Tian"
                },
                {
                    "authorId": "2198887839",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "4d44384b0f044a0088564b846bbd3cc16b3b7c63",
            "title": "VistaRAG: Toward Safe and Trustworthy Autonomous Driving Through Retrieval-Augmented Generation",
            "abstract": "Autonomous driving based on foundation models has recently garnered widespread attention. However, the risk of hallucinations inherent in foundation models could compromise the safety and reliability of autonomous driving systems. This letter, as part of a series of reports from the Distributed/Decentralized Hybrid Workshop on Foundation/Infrastructure Intelligence (DHW-FII), aims to tackle these issues. We introduce VistaRAG, which integrates retrieval-augmented generation (RAG) technologies into autonomous driving systems based on foundation models, to address the inherent reliability challenges in decision-making. VistaRAG employs a dynamic retrieval mechanism to access highly relevant driving experience, real-time road network status, and other contextual information from external databases. This aids foundation models in informed reasoning and decision-making, thereby enhancing the safety and trustworthiness of foundation-model-based autonomous driving systems under complex traffic scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22200602",
                    "name": "Xingyuan Dai"
                },
                {
                    "authorId": "2110227121",
                    "name": "Chao Guo"
                },
                {
                    "authorId": "2300130446",
                    "name": "Yun Tang"
                },
                {
                    "authorId": "2299907772",
                    "name": "Haichuan Li"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2274729221",
                    "name": "Jun Huang"
                },
                {
                    "authorId": "32847052",
                    "name": "Yonglin Tian"
                },
                {
                    "authorId": "2150058228",
                    "name": "Xin Xia"
                },
                {
                    "authorId": "2237937820",
                    "name": "Yisheng Lv"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "52726f082b9f9b3341b508ab22175bccf2d6b5ad",
            "title": "4D mmWave Radar for Autonomous Driving Perception: A Comprehensive Survey",
            "abstract": "The rapid development of autonomous driving technology has driven continuous innovation in perception systems, with 4D millimeter-wave (mmWave) radar being one of the key sensing devices. Leveraging its all-weather operational characteristics and robust perception capabilities in challenging environments, 4D mmWave radar plays a crucial role in achieving highly automated driving. This review systematically summarizes the latest advancements and key applications of 4D mmWave radar in the field of autonomous driving. To begin with, we introduce the fundamental principles and technical features of 4D mmWave radar, delving into its comprehensive perception capabilities across distance, speed, angle, and time dimensions. Subsequently, we provide a detailed analysis of the performance advantages of 4D mmWave radar compared to other sensors in complex environments. We then discuss the latest developments in target detection and tracking using 4D mmWave radar, along with existing datasets in this domain. Finally, we explore the current technological challenges and future directions. This review offers researchers and engineers a comprehensive understanding of the cutting-edge technology and future development directions of 4D mmWave radar in the context of autonomous driving perception.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186633108",
                    "name": "Lili Fan"
                },
                {
                    "authorId": "2260821542",
                    "name": "Junhao Wang"
                },
                {
                    "authorId": "2292930985",
                    "name": "Yuanmeng Chang"
                },
                {
                    "authorId": "2274463497",
                    "name": "Yuke Li"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2180645056",
                    "name": "Dongpu Cao"
                }
            ]
        },
        {
            "paperId": "719fcf882a9f36899d4bc6c5af4c7de0380e0298",
            "title": "Sustainability Opportunities and Ethical Challenges of AI-Enabled Connected Autonomous Vehicles Routing in Urban Areas",
            "abstract": "The advent of Connected Autonomous Vehicles (CAVs) paves the way to a new era of urban traffic control and management, driven by Artificial Intelligence (AI)-enabled strategies. This advancement promises significant improvements in infrastructure use optimization, traffic delay reduction, and overall sustainability. The autonomous driving capabilities of CAVs, coupled with the communication technology, allow vehicles to play an active role in urban traffic control: they can follow tailored instructions and can act as highly accurate moving sensors for traffic authorities. However, such improved capabilities come at the cost of unprecedented vulnerabilities to cyber exploitation, and with the concrete potential to increase social and economic disparities. As an extension of TIV-DHW (Distributed/Decentralized Hybrid Workshop) on ERS (Ethics, Responsibility, and Sustainability), this letter explores how the AI-enabled routing methodology can enhance urban transportation sustainability while also discussing its ethical implications and challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "75044926",
                    "name": "Rongge Guo"
                },
                {
                    "authorId": "2270414980",
                    "name": "Mauro Vallati"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2265930588",
                    "name": "Hui Zhang"
                },
                {
                    "authorId": "2261953274",
                    "name": "Yuanyuan Chen"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "86711213574f519544ae44c358832e72a30c34cf",
            "title": "Sora for Senarios Engineering of Intelligent Vehicles: V&V, C&C, and Beyonds",
            "abstract": "The advent of Scenarios Engineering (SE) paves the way to a new era of intelligent vehicles (IVs), driven by Artificial Intelligence (AI)-enabled strategies. It aims at shaping the IVs to be a form that is more relevant to the underlying scenario, thereby accomplishing validation, verification (V&V), and calibration, certification (C&C) of each vehicle. However, such improved capabilities relies on the accumulation and analysis of an unprecedented volume of scenarios. Recently, Sora and other video generation models have opened up new horizons for Imaginative Intelligence. As an extension of TIV-DHW (Distributed/Decentralized Hybrid Workshop) on SE, this letter discusses the potential of Sora to change the scenario generation process by reducing physical shooting, increasing extreme scenario generation, thereby enabling more comprehensive training and testing of IVs. This letter also analyzes the limitations of Sora in accurately model physics and understand cause and effect, which may affect its effectiveness in SE applications. Last, through a comprehensive outlook, this letter aims to provide a potential direction for the development of Sora-like AI technology, thereby promoting the safety, efficiency, reliability, and sustainability of IVs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108263715",
                    "name": "Xuan Li"
                },
                {
                    "authorId": "3071596",
                    "name": "Q. Miao"
                },
                {
                    "authorId": "2240418173",
                    "name": "Lingxi Li"
                },
                {
                    "authorId": "2248826737",
                    "name": "Qinghua Ni"
                },
                {
                    "authorId": "2186633108",
                    "name": "Lili Fan"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "32847052",
                    "name": "Yonglin Tian"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "8bceecfb03341053deb2a67905d1c9469958682c",
            "title": "SynerFill: A Synergistic RGB-D Image Inpainting Network via Fast Fourier Convolutions",
            "abstract": "Map inpainting is an important technology in the production of maps for autonomous driving vehicles. In recent years, scholars have often used methods such as point cloud inpainting, RGB image inpainting, and depth inpainting to repair maps. However, these methods require high computational power and result in longer algorithmic processing times. To address this issue, we propose SynerFill, a synergistic RGB-D images inpainting method that can simultaneously inpaint RGB and depth images. We design its network architecture and loss functions, which include a generator, an RGB image discriminator, a depth image discriminator, and an edge image discriminator. Second, we collect real-world data and build a large-scale, multi-scene, multi-weather dataset called the Synthetic City RGB-D (SCRGB-D) Dataset based on 3ds Max, CARLA, and Unreal Engine 4. To verify SynerFill, we conduct experiments on the SCRGB-D dataset, DynaFill dataset, and SceneNet dataset. The experimental results show that SynerFill achieves state-of-the-art (SOTA) performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144862980",
                    "name": "Kunhua Liu"
                },
                {
                    "authorId": "2118002474",
                    "name": "Yunqing Zhang"
                },
                {
                    "authorId": "2261079284",
                    "name": "Yuting Xie"
                },
                {
                    "authorId": "2188466678",
                    "name": "Leixin Li"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "2164975031",
                    "name": "Long Chen"
                }
            ]
        }
    ]
}