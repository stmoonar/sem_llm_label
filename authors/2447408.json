{
    "authorId": "2447408",
    "papers": [
        {
            "paperId": "4d5326408cc5b894fd4e2cc36e3aa5ee4bb2f1c2",
            "title": "Learning Entity Linking Features for Emerging Entities",
            "abstract": "Entity linking (EL) is the process of linking entity mentions appearing in text with their corresponding entities in a knowledge base. EL features of entities (e.g., prior probability, relatedness score, and entity embedding) are usually estimated based on Wikipedia. However, for newly emerging entities (EEs) which have just been discovered in news, they may still not be included in Wikipedia yet. As a consequence, it is unable to obtain required EL features for those EEs from Wikipedia and EL models will always fail to link ambiguous mentions with those EEs correctly as the absence of their EL features. To deal with this problem, in this paper we focus on a new task of learning EL features for emerging entities in a general way. We propose a novel approach called STAMO to learn high-quality EL features for EEs automatically, which needs just a small number of labeled documents for each EE collected from the Web, as it could further leverage the knowledge hidden in the unlabeled data. STAMO is mainly based on self-training, which makes it flexibly integrated with any EL feature or EL model, but also makes it easily suffer from the error reinforcement problem caused by the mislabeled data. Instead of some common self-training strategies that try to throw the mislabeled data away explicitly, we regard self-training as a multiple optimization process with respect to the EL features of EEs, and propose both intra-slot and inter-slot optimizations to alleviate the error reinforcement problem implicitly. We construct two EL datasets involving selected EEs to evaluate the quality of obtained EL features for EEs, and the experimental results show that our approach significantly outperforms other baseline methods of learning EL features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3011549",
                    "name": "Chenwei Ran"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1810902946",
                    "name": "Jianbo Gao"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2861442",
                    "name": "Yantao Jia"
                }
            ]
        },
        {
            "paperId": "6159ea65a6dab3499c82bc90c0b70cff4a80941c",
            "title": "Neuro-Symbolic Interpretable Collaborative Filtering for Attribute-based Recommendation",
            "abstract": "Recommender System (RS) is ubiquitous on today\u2019s Internet to provide multifaceted personalized information services. While an enormous success has been made in pushing forward high-accuracy recommendations, the other side of the coin \u2014 the recommendation explainability \u2014 needs to be better handled for pursuing persuasiveness, especially for the era of deep learning based recommendation. A few research efforts investigate interpretable recommendation from the feature and result levels. Compared with them, model-level explanation, which unfolds the reasoning process of recommendation through transparent models, still remains underexplored and deserves more attention. In this paper, we propose a model-based explainable recommendation approach, i.e., NS-ICF, which stands for Neuro-Symbolic Interpretable Collaborative Filtering. Thanks to the recent advance on neuro-symbolic computation for automatic rule learning, NS-ICF learns interpretable recommendation rules (consisting of user and item attributes) based on neural networks with two innovations: (1) a three-tower architecture tailored for the user and item sides in the RS domain; (2) fusing the powerful personalized representations of users and items to achieve adaptive rule weights and without sacrificing interpretability. Comprehensive experiments on public datasets demonstrate NS-ICF is comparable to state-of-the-art deep recommendation models and is transparent for its unique neuro-symbolic architecture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40538912",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2112593769",
                    "name": "Junbing Yan"
                },
                {
                    "authorId": "101279813",
                    "name": "Zhuo Wang"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "ffeb482b80aa8ed0df595ffc6f17508b2672b808",
            "title": "Toward Tweet Entity Linking With Heterogeneous Information Networks",
            "abstract": "Twitter, a microblogging platform, has developed into an increasingly invaluable information source, where millions of users post a great quantity of tweets with various topics per day. Heterogeneous information networks consisting of multi-type objects and relations are becoming more and more prevalent as an organization form of knowledge and information. The task of linking an entity mention in a tweet with its corresponding entity in a heterogeneous information network is of great importance, for the purpose of enriching heterogeneous information networks with the abundant and fresh knowledge embedded in tweets. However, the entity mention is ambiguous. Additionally, tweets are short and informal, making it difficult to mine enough information from a single tweet for entity linking. In this paper, we propose an unsupervised iterative clustering framework TELHIN to link multiple similar tweets with a heterogeneous information network jointly. Our framework takes three dimensions of tweet similarity into consideration: (1) content similarity, (2) temporal similarity, and (3) user similarity. The appropriate weights of different similarity dimensions for each entity mention are learned iteratively based on the metric learning algorithm by leveraging the pairwise constraints generated automatically. Experiments on real data demonstrate the effectiveness of our framework in comparison with the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": null,
                    "name": "Yuwei Yin"
                },
                {
                    "authorId": "2152920501",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "18981e60887244d898f00ef60738eaeae1453f76",
            "title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA",
            "abstract": "In community-based question answering (CQA) platforms, automatic answer ranking for a given question is critical for finding potentially popular answers in early times. The mainstream approaches learn to generate answer ranking scores based on the matching degree between question and answer representations as well as the influence of respondents. However, they encounter two main limitations: (1) Correlations between answers in the same question are often overlooked. (2) Question and respondent representations are built independently of specific answers before affecting answer representations. To address the limitations, we devise a novel graph-based tri-attention network, namely GTAN, which has two innovations. First, GTAN proposes to construct a graph for each question and learn answer correlations from each graph through graph neural networks (GNNs). Second, based on the representations learned from GNNs, an alternating tri-attention method is developed to alternatively build target-aware respondent representations, answer-specific question representations, and context-aware answer representations by attention computation. GTAN finally integrates the above representations to generate answer ranking scores. Experiments on three real-world CQA datasets demonstrate GTAN significantly outperforms state-of-the-art answer ranking methods, validating the rationality of the network architecture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155468861",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "5478513",
                    "name": "Zeyuan Chen"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2108908267",
                    "name": "Wen Wang"
                },
                {
                    "authorId": "145203884",
                    "name": "H. Zha"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "446b38131e1f9605a8e43c81571e4d64a826084e",
            "title": "Named Entity Location Prediction Combining Twitter and Web",
            "abstract": "Knowledge bases are critical to many applications. However, they are greatly incomplete. Enriching knowledge bases with new entities and new location attributes becomes increasingly important. Given a named entity with tweets and Web documents where the entity appears, we aim to predict the entity city-level location combining the geographical location knowledge embedded in both Twitter and Web. This task is helpful for knowledge base enrichment and tweet location prediction. In this paper we propose NELPTW, the first unsupervised framework for <underline><bold>N</bold></underline>amed <underline><bold>E</bold></underline>ntity <underline><bold>L</bold></underline>ocation <underline><bold>P</bold></underline>rediction by leveraging the knowledge from <underline><bold>T</bold></underline>witter and <underline><bold>W</bold></underline>eb. Based on each data source, NELPTW utilizes a linear function ranking model to generate several rankings to the candidate location set for each entity. To combine the knowledge from two sources which have different reliability and importance for the location prediction, an unsupervised rank aggregation algorithm is developed to aggregate multiple rankings for each entity to obtain a better ranking. A learning algorithm based on the EM method is proposed to automatically learn the parameters of the ranking model without requiring any training labels. The experimental results over a real world Twitter and Web data set show that our framework significantly outperforms the baselines in terms of accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "2117226472",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1576489304",
                    "name": "Zonghai Yao"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "8af73fbe9f9b11c2820674dbbf7a208f7cadc2a6",
            "title": "Entity Linking Meets Deep Learning: Techniques and Solutions",
            "abstract": "Entity linking (EL) is the process of linking entity mentions appearing in web text with their corresponding entities in a knowledge base. EL plays an important role in the fields of knowledge engineering and data mining, underlying a variety of downstream applications such as knowledge base population, content analysis, relation extraction, and question answering. In recent years, deep learning (DL), which has achieved tremendous success in various domains, has also been leveraged in EL methods to surpass traditional machine learning based methods and yield the state-of-the-art performance. In this survey, we present a comprehensive review and analysis of existing DL based EL methods. First of all, we propose a new taxonomy, which organizes existing DL based EL methods using three axes: embedding, feature, and algorithm. Then we systematically survey the representative EL methods along the three axes of the taxonomy. Later, we introduce ten commonly used EL data sets and give a quantitative performance analysis of DL based EL methods over these data sets. Finally, we discuss the remaining limitations of existing methods and highlight some promising future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117226472",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "bacf302e7ec26bddb17d1d84f1b107279423fd00",
            "title": "Learning Dual Dynamic Representations on Time-Sliced User-Item Interaction Graphs for Sequential Recommendation",
            "abstract": "Sequential Recommendation aims to recommend items that a target user will interact with in the near future based on the historically interacted items. While modeling temporal dynamics is crucial for sequential recommendation, most of the existing studies concentrate solely on the user side while overlooking the sequential patterns existing in the counterpart, i.e., the item side. Although a few studies investigate the dynamics involved in the dual sides, the complex user-item interactions are not fully exploited from a global perspective to derive dynamic user and item representations. In this paper, we devise a novel Dynamic Representation Learning model for Sequential Recommendation (DRL-SRe). To better model the user-item interactions for characterizing the dynamics from both sides, the proposed model builds a global user-item interaction graph for each time slice and exploit time-sliced graph neural networks to learn user and item representations. Moreover, to enable the model to capture fine-grained temporal information, we propose an auxiliary temporal prediction task over consecutive time slices based on temporal point process. Comprehensive experiments on three public real-world datasets demonstrate DRL-SRe outperforms the state-of-the-art sequential recommendation models with a large margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "5478513",
                    "name": "Zeyuan Chen"
                },
                {
                    "authorId": "2155468861",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "3063894",
                    "name": "Junchi Yan"
                },
                {
                    "authorId": "2117909851",
                    "name": "Gang Wang"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "c24cbe99bfde5bea6adda58edaf4471794f2852c",
            "title": "Joint Open Knowledge Base Canonicalization and Linking",
            "abstract": "Open Information Extraction (OIE) methods extract a large number of OIE triples (noun phrase, relation phrase, noun phrase) from text, which compose large Open Knowledge Bases (OKBs). However, noun phrases (NPs) and relation phrases (RPs) in OKBs are not canonicalized and often appear in different paraphrased textual variants, which leads to redundant and ambiguous facts. To address this problem, there are two related tasks: OKB canonicalization (i.e., convert NPs and RPs to canonicalized form) and OKB linking (i.e., link NPs and RPs with their corresponding entities and relations in a curated Knowledge Base (e.g., DBPedia). These two tasks are tightly coupled, and one task can benefit significantly from the other. However, they have been studied in isolation so far. In this paper, we explore the task of joint OKB canonicalization and linking for the first time, and propose a novel framework JOCL based on factor graph model to make them reinforce each other. JOCL is flexible enough to combine different signals from both tasks, and able to extend to fit any new signals. A thorough experimental study over two large scale OIE triple data sets shows that our framework outperforms all the baseline methods for the task of OKB canonicalization (OKB linking) in terms of average F1 (accuracy).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2146017601",
                    "name": "Yuanfei Wang"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2149231521",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "d69e2356d469139eced650bce41ab2073cf559f8",
            "title": "Scalable Rule-Based Representation Learning for Interpretable Classification",
            "abstract": "Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacrifice the model interpretability. To obtain both good scalability and interpretability, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classification. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Exhaustive experiments on nine small and four large data sets show that RRL outperforms the competitive interpretable approaches and can be easily adjusted to obtain a trade-off between classification accuracy and model complexity for different scenarios. Our code is available at: https://github.com/12wang3/rrl.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "101279813",
                    "name": "Zhuo Wang"
                },
                {
                    "authorId": "2155468861",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2152354910",
                    "name": "Ning Liu"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "5d68aed491c0235ac20e85b64312b43097c4f87e",
            "title": "Social Link Inference via Multiview Matching Network From Spatiotemporal Trajectories",
            "abstract": "In this article, we investigate the problem of social link inference in a target location-aware social network (LSN), which aims at predicting the unobserved links between users within the network. This problem is critical for downstream applications, including network completion and friend recommendation. In addition to the network structures commonly used in general link prediction, the studies tailored for social link inference in an LSN leverage user trajectories from the spatial aspect. However, the temporal factor lying in user trajectories is largely overlooked by most of the prior studies, limiting the capabilities of capturing the temporal relevance between users. Moreover, effective user matching by fusing different views, i.e., social, spatial, and temporal factors, remains unresolved, which hinders the potential improvement of link inference. To this end, this article devises a novel multiview matching network (MVMN) by regarding each of the three factors as one view of any target user pair. MVMN enjoys the flexibility and completeness of modeling each factor by developing its suitable matching module: 1) location matching module; 2) time-series matching module; and 3) relation matching module. Each module learns a view-specific representation for matching, and MVMN fuses them for final link inference. Extensive experiments on two real-world data sets demonstrate the superiority of our approach against several competitive baselines for link prediction and sequence matching, validating the contribution of its key components.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2111718094",
                    "name": "Xin Lai"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        }
    ]
}