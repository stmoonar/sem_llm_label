{
    "authorId": "2118697460",
    "papers": [
        {
            "paperId": "92b6a2b38810f4dcb1a2778f5d5a4975bb63885c",
            "title": "D2Match: Leveraging Deep Learning and Degeneracy for Subgraph Matching",
            "abstract": "Subgraph matching is a fundamental building block for graph-based applications and is challenging due to its high-order combinatorial nature. Existing studies usually tackle it by combinatorial optimization or learning-based methods. However, they suffer from exponential computational costs or searching the matching without theoretical guarantees. In this paper, we develop D2Match by leveraging the efficiency of Deep learning and Degeneracy for subgraph matching. More specifically, we first prove that subgraph matching can degenerate to subtree matching, and subsequently is equivalent to finding a perfect matching on a bipartite graph. We can then yield an implementation of linear time complexity by the built-in tree-structured aggregation mechanism on graph neural networks. Moreover, circle structures and node attributes can be easily incorporated in D2Match to boost the matching performance. Finally, we conduct extensive experiments to show the superior performance of our D2Match and confirm that our D2Match indeed exploits the subtrees and differs from existing GNNs-based subgraph matching methods that depend on memorizing the data distribution divergence",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "26966619",
                    "name": "Xuan Liu"
                },
                {
                    "authorId": "2217098681",
                    "name": "Lin Zhang"
                },
                {
                    "authorId": "2188389873",
                    "name": "Jiaqi Sun"
                },
                {
                    "authorId": "3001727",
                    "name": "Yujiu Yang"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                }
            ]
        },
        {
            "paperId": "c5e3a26d2e929aee2ace9bc08b28c580006439f2",
            "title": "A Diffusion Model for Event Skeleton Generation",
            "abstract": "Event skeleton generation, aiming to induce an event schema skeleton graph with abstracted event nodes and their temporal relations from a set of event instance graphs, is a critical step in the temporal complex event schema induction task. Existing methods effectively address this task from a graph generation perspective but suffer from noise-sensitive and error accumulation, e.g., the inability to correct errors while generating schema. We, therefore, propose a novel Diffusion Event Graph Model~(DEGM) to address these issues. Our DEGM is the first workable diffusion model for event skeleton generation, where the embedding and rounding techniques with a custom edge-based loss are introduced to transform a discrete event graph into learnable latent representation. Furthermore, we propose a denoising training process to maintain the model's robustness. Consequently, DEGM derives the final schema, where error correction is guaranteed by iteratively refining the latent representation during the schema generation process. Experimental results on three IED bombing datasets demonstrate that our DEGM achieves better results than other state-of-the-art baselines. Our code and data are available at https://github.com/zhufq00/EventSkeletonGeneration.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2075369995",
                    "name": "Fangqi Zhu"
                },
                {
                    "authorId": "2143837504",
                    "name": "Lin Zhang"
                },
                {
                    "authorId": "2111016840",
                    "name": "Junfeng Gao"
                },
                {
                    "authorId": "152277111",
                    "name": "Bing Qin"
                },
                {
                    "authorId": "2115804042",
                    "name": "Ruifeng Xu"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                }
            ]
        },
        {
            "paperId": "66ee488cf3dad5bb83804124367460edddd3c271",
            "title": "Vision-and-Language Pretrained Models: A Survey",
            "abstract": "Pretrained models have produced great success in both Computer Vision (CV) and Natural Language Processing (NLP). This progress leads to learning joint representations of vision and language pretraining by feeding visual and linguistic contents into a multi-layer transformer, Visual-Language Pretrained Models (VLPMs). In this paper, we present an overview of the major advances achieved in VLPMs for producing joint representations of vision and language. As the preliminaries, we briefly describe the general task definition and genetic architecture of VLPMs. We first discuss the language and vision data encoding methods and then present the mainstream VLPM structure as the core content. We further summarise several essential pretraining and fine-tuning strategies. Finally, we highlight three future directions for both CV and NLP researchers to provide insightful guidance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "2162737605",
                    "name": "Feiqi Cao"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                }
            ]
        },
        {
            "paperId": "7b5fa4de7ade60f87f70930b3d5d920170c81e78",
            "title": "Trigger-free Event Detection via Derangement Reading Comprehension",
            "abstract": "Event detection (ED), aiming to detect events from texts and categorize them, is vital to understanding actual happenings in real life. However, mainstream event detection models require high-quality expert human annotations of triggers, which are often costly and thus deter the application of ED to new domains. Therefore, in this paper, we focus on low-resource ED without triggers and aim to tackle the following formidable challenges: multi-label classi\ufb01cation, insuf\ufb01cient clues, and imbalanced events distribution. We propose a novel trigger-free ED method via Derangement mechanism on a machine Reading Comprehension (DRC) framework. More speci\ufb01-cally, we treat the input text as Context and concatenate it with all event type tokens that are deemed as Answers with an omitted default question. So we can leverage the self-attention in pre-trained language models to absorb semantic relations between input text and the event types. Moreover, we design a simple yet effective event derangement module (EDM) to prevent major events from being excessively learned so as to yield a more balanced training process. The experiment results show that our proposed trigger-free ED model is remarkably competitive to mainstream trigger-based models, showing its strong performance on low-source event detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46508951",
                    "name": "Jiachen Zhao"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                }
            ]
        },
        {
            "paperId": "0468f9995b896885a778f45a2e87b5afc5c85b1a",
            "title": "PALI at SemEval-2021 Task 2: Fine-Tune XLM-RoBERTa for Word in Context Disambiguation",
            "abstract": "This paper presents the PALI team\u2019s winning system for SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation. We fine-tune XLM-RoBERTa model to solve the task of word in context disambiguation, i.e., to determine whether the target word in the two contexts contains the same meaning or not. In implementation, we first specifically design an input tag to emphasize the target word in the contexts. Second, we construct a new vector on the fine-tuned embeddings from XLM-RoBERTa and feed it to a fully-connected network to output the probability of whether the target word in the context has the same meaning or not. The new vector is attained by concatenating the embedding of the [CLS] token and the embeddings of the target word in the contexts. In training, we explore several tricks, such as the Ranger optimizer, data augmentation, and adversarial training, to improve the model prediction. Consequently, we attain the first place in all four cross-lingual tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2005412253",
                    "name": "Shu-Yi Xie"
                },
                {
                    "authorId": "2027486994",
                    "name": "Jian Ma"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                },
                {
                    "authorId": "21833875",
                    "name": "Lian-Xin Jiang"
                },
                {
                    "authorId": "115656171",
                    "name": "Yang Mo"
                },
                {
                    "authorId": "49927294",
                    "name": "Jianping Shen"
                }
            ]
        },
        {
            "paperId": "276c0dc230883a2db07c4849e0b74cc21be310b2",
            "title": "Automatic Intent-Slot Induction for Dialogue Systems",
            "abstract": "Automatically and accurately identifying user intents and filling the associated slots from their spoken language are critical to the success of dialogue systems. Traditional methods require manually defining the DOMAIN-INTENT-SLOT schema and asking many domain experts to annotate the corresponding utterances, upon which neural models are trained. This procedure brings the challenges of information sharing hindering, out-of-schema, or data sparsity in open domain dialogue systems. To tackle these challenges, we explore a new task of automatic intent-slot induction and propose a novel domain-independent tool. That is, we design a coarse-to-fine three-step procedure including Role-labeling, Concept-mining, And Pattern-mining (RCAP): (1) role-labeling: extracting key phrases from users\u2019 utterances and classifying them into a quadruple of coarsely-defined intent-roles via sequence labeling; (2) concept-mining: clustering the extracted intent-role mentions and naming them into abstract fine-grained concepts; (3) pattern-mining: applying the Apriori algorithm to mine intent-role patterns and automatically inferring the intent-slot using these coarse-grained intent-role labels and fine-grained concepts. Empirical evaluations on both real-world in-domain and out-of-domain datasets show that: (1) our RCAP can generate satisfactory SLU schema and outperforms the state-of-the-art supervised learning method; (2) our RCAP can be directly applied to out-of-domain datasets and gain at least 76% improvement of F1-score on intent detection and 41% improvement of F1-score on slot filling; (3) our RCAP exhibits its power in generic intent-slot extractions with less manual effort, which opens pathways for schema induction on new domains and unseen intent-slot discovery for generalizable dialogue systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2075414035",
                    "name": "Zengfeng Zeng"
                },
                {
                    "authorId": "2113510067",
                    "name": "Dan Ma"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                },
                {
                    "authorId": "3305938",
                    "name": "Zhen Gou"
                },
                {
                    "authorId": "49927294",
                    "name": "Jianping Shen"
                }
            ]
        },
        {
            "paperId": "45a7d3cbb38168d8d605725aae26044b251614e6",
            "title": "MagicPai at SemEval-2021 Task 7: Method for Detecting and Rating Humor Based on Multi-Task Adversarial Training",
            "abstract": "This paper describes MagicPai\u2019s system for SemEval 2021 Task 7, HaHackathon: Detecting and Rating Humor and Offense. This task aims to detect whether the text is humorous and how humorous it is. There are four subtasks in the competition. In this paper, we mainly present our solution, a multi-task learning model based on adversarial examples, for task 1a and 1b. More specifically, we first vectorize the cleaned dataset and add the perturbation to obtain more robust embedding representations. We then correct the loss via the confidence level. Finally, we perform interactive joint learning on multiple tasks to capture the relationship between whether the text is humorous and how humorous it is. The final result shows the effectiveness of our system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2027486994",
                    "name": "Jian Ma"
                },
                {
                    "authorId": "2005412253",
                    "name": "Shu-Yi Xie"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                },
                {
                    "authorId": "21833875",
                    "name": "Lian-Xin Jiang"
                },
                {
                    "authorId": "2109138287",
                    "name": "Mengyuan Zhou"
                },
                {
                    "authorId": "2080027477",
                    "name": "Xiaoyi Ruan"
                },
                {
                    "authorId": "115656171",
                    "name": "Yang Mo"
                }
            ]
        },
        {
            "paperId": "8cd6d209fe4c701bd47675f91001a75e990a226e",
            "title": "Sequential Attention Module for Natural Language Processing",
            "abstract": "Recently, large pre-trained neural language models have attained remarkable performance on many downstream natural language processing (NLP) applications via fine-tuning. In this paper, we target at how to further improve the token representations on the language models. We, therefore, propose a simple yet effective plug-and-play module, Sequential Attention Module (SAM), on the token embeddings learned from a pre-trained language model. Our proposed SAM consists of two main attention modules deployed sequentially: Feature-wise Attention Module (FAM) and Token-wise Attention Module (TAM). More specifically, FAM can effectively identify the importance of features at each dimension and promote the effect via dot-product on the original token embeddings for downstream NLP applications. Meanwhile, TAM can further re-weight the features at the token-wise level. Moreover, we propose an adaptive filter on FAM to prevent noise impact and increase information absorption. Finally, we conduct extensive experiments to demonstrate the advantages and properties of our proposed SAM. We first show how SAM plays a primary role in the champion solution of two subtasks of SemEval'21 Task 7. After that, we apply SAM on sentiment analysis and three popular NLP tasks and demonstrate that SAM consistently outperforms the state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109138287",
                    "name": "Mengyuan Zhou"
                },
                {
                    "authorId": "2027486994",
                    "name": "Jian Ma"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                },
                {
                    "authorId": "21833875",
                    "name": "Lian-Xin Jiang"
                },
                {
                    "authorId": "115656171",
                    "name": "Yang Mo"
                }
            ]
        },
        {
            "paperId": "a61d0fc235b86897ce32435591c822ecb280d63c",
            "title": "RefBERT: Compressing BERT by Referencing to Pre-computed Representations",
            "abstract": "Recently developed large pre-trained language models, e.g., BERT, have achieved remarkable performance in many downstream natural language processing applications. These pre-trained language models often contain hundreds of millions of parameters and suffer from high computation and latency in real-world applications. It is desirable to reduce the computation overhead of the models for fast training and inference while keeping the model performance in downstream applications. Several lines of work utilize knowledge distillation to compress the teacher model to a smaller student model. However, they usually discard the teacher's knowledge when in inference. Differently, in this paper, we propose RemERT to leverage the knowledge learned from the teacher, i.e., facilitating the pre-computed BERT representation on the reference sample and compressing BERT into a smaller student model. To guarantee our proposal, we provide theoretical justification on the loss function and the usage of reference samples. Significantly, the theoretical result shows that including the pre-computed teacher's representations on the reference samples indeed increases the mutual information in learning the student model. Finally, we conduct the empirical evaluation and show that our RemERT can beat the vanilla TinyBERT over 8.1 % and achieves more than 94% of the performance of $\\mathbf{BERT}_{\\mathbf{BASE}}$ on the GLUE benchmark. Meanwhile, RemERT is $\\mathbf{7.4x}$ smaller and $\\mathbf{9.5x}$ faster on inference than $\\mathbf{BERT}_{\\mathbf{BASE}}$.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115553132",
                    "name": "Xinyi Wang"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                },
                {
                    "authorId": "2116735843",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "115656171",
                    "name": "Yang Mo"
                },
                {
                    "authorId": "49927294",
                    "name": "Jianping Shen"
                }
            ]
        },
        {
            "paperId": "b9c8e25195282cf7698017da2ea2c2d86a3de19d",
            "title": "Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables",
            "abstract": "Question answering from semi-structured tables can be seen as a semantic parsing task and is significant and practical for pushing the boundary of natural language understanding. Existing research mainly focuses on understanding contents from unstructured evidence, e.g., news, natural language sentences and documents. The task of verification from structured evidence, such as tables, charts, and databases, is still less-explored. This paper describes sattiy team\u2019s system in SemEval-2021 task 9: Statement Verification and Evidence Finding with Tables (SEM-TAB-FACT)(CITATION). This competition aims to verify statements and to find evidence from tables for scientific articles and to promote proper interpretation of the surrounding article. In this paper we exploited ensemble models of pre-trained language models over tables, TaPas and TaBERT, for Task A and adjust the result based on some rules extracted for Task B. Finally, in the leadboard, we attain the F1 scores of 0.8496 and 0.7732 in Task A for the 2-way and 3-way evaluation, respectively, and the F1 score of 0.4856 in Task B.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080027477",
                    "name": "Xiaoyi Ruan"
                },
                {
                    "authorId": "2029667024",
                    "name": "Meizhi Jin"
                },
                {
                    "authorId": "2027486994",
                    "name": "Jian Ma"
                },
                {
                    "authorId": "2118697460",
                    "name": "Haiqing Yang"
                },
                {
                    "authorId": "21833875",
                    "name": "Lian-Xin Jiang"
                },
                {
                    "authorId": "115656171",
                    "name": "Yang Mo"
                },
                {
                    "authorId": "2109138287",
                    "name": "Mengyuan Zhou"
                }
            ]
        }
    ]
}