{
    "authorId": "2152862795",
    "papers": [
        {
            "paperId": "ef00e8f46708f0345270e19b24dc03aee32c5a3e",
            "title": "DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting",
            "abstract": "Coherence in writing, an aspect that second-language (L2) English learners often struggle with, is crucial in assessing L2 English writing. Existing automated writing evaluation systems primarily use basic surface linguistic features to detect coherence in writing. However, little effort has been made to correct the detected incoherence, which could significantly benefit L2 language learners seeking to improve their writing. To bridge this gap, we introduce DECOR, a novel benchmark that includes expert annotations for detecting incoherence in L2 English writing, identifying the underlying reasons, and rewriting the incoherent sentences. To our knowledge, DECOR is the first coherence assessment dataset specifically designed for improving L2 English writing, featuring pairs of original incoherent sentences alongside their expert-rewritten counterparts. Additionally, we fine-tuned models to automatically detect and rewrite incoherence in student essays. We find that incorporating specific reasons for incoherence during fine-tuning consistently improves the quality of the rewrites, achieving a result that is favored in both automatic and human evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2308225745",
                    "name": "Xuanming Zhang"
                },
                {
                    "authorId": "2309114589",
                    "name": "Anthony Diaz"
                },
                {
                    "authorId": "2281415319",
                    "name": "Zixun Chen"
                },
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "2308102293",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2309007293",
                    "name": "Erik Voss"
                },
                {
                    "authorId": "2280289629",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "a120e3583f37495b10e3fa831a5087a0471638ca",
            "title": "Using Textual Interface to Align External Knowledge for End-to-End Task-Oriented Dialogue Systems",
            "abstract": "Traditional end-to-end task-oriented dialogue systems have been built with a modularized design. However, such design often causes misalignment between the agent response and external knowledge, due to inadequate representation of information. Furthermore, its evaluation metrics emphasize assessing the agent's pre-lexicalization response, neglecting the quality of the completed response. In this work, we propose a novel paradigm that uses a textual interface to align external knowledge and eliminate redundant processes. We demonstrate our paradigm in practice through MultiWOZ-Remake, including an interactive textual interface built for the MultiWOZ database and a correspondingly re-processed dataset. We train an end-to-end dialogue system to evaluate this new dataset. The experimental results show that our approach generates more natural final responses and achieves a greater task success rate compared to the previous models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "2428276",
                    "name": "Deema Alnuhait"
                },
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "d40958116341901c07cac4654d9329cd35c1fad3",
            "title": "DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems",
            "abstract": "Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "2684382",
                    "name": "James Gung"
                },
                {
                    "authorId": "7412686",
                    "name": "Raphael Shu"
                },
                {
                    "authorId": null,
                    "name": "Yi Zhang"
                }
            ]
        },
        {
            "paperId": "1660de28d9f1121e7f0116b92ed9e21e17eb30aa",
            "title": "KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning",
            "abstract": "In task-oriented dialogs (TOD), reinforcement learning (RL) algorithms train a model to directly optimize response for task-related metrics. However, RL needs to perform exploration, which can be time-consuming due to the slow auto-regressive sequence generation process. We investigate an approach to create a more efficient RL-based algorithm to improve TOD performance in an offline setting. First, we use a faster generation procedure that samples from independent next-word distributions after training the language model (LM) with supervised learning. We then introduce a fine-grained reward function to help the model focus on learning key information in a dialog, by measuring the importance and semantic closeness of each generated token. Experiments on the MultiWoZ dataset show our new training algorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), achieves state-of-the-art performance on the end-to-end response generation task, with a 15% training time reduction compared to a standard RL algorithm using auto-regressive generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "ab27a41e10d2362a58db2465073f2b8a4a29312a",
            "title": "Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling",
            "abstract": "Transformer models have achieved great performance in dialogue generation tasks. However, their inability to process long dialogue history often leads to truncation of the context. To address this problem, we propose a novel memory-augmented transformer that is compatible with existing pre-trained encoder-decoder models and enables efficient preservation of the dialogue history information. The new model incorporates a separate memory module alongside the pre-trained transformer, which can effectively interchange information between the memory states and the current input context. We evaluate the efficiency of our model on three dialogue datasets and two language modeling datasets. Experimental results show that our method has achieved superior efficiency and performance compared to other pre-trained Transformer baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "c6304247f04870393d56579cdd5e093a25c121ee",
            "title": "On the Generation of Medical Dialogs for COVID-19",
            "abstract": "Under the pandemic of COVID-19, people experiencing COVID19-related symptoms have a pressing need to consult doctors. Because of the shortage of medical professionals, many people cannot receive online consultations timely. To address this problem, we aim to develop a medical dialog system that can provide COVID19-related consultations. We collected two dialog datasets \u2013 CovidDialog \u2013 (in English and Chinese respectively) containing conversations between doctors and patients about COVID-19. While the largest of their kind, these two datasets are still relatively small compared with general-domain dialog datasets. Training complex dialog generation models on small datasets bears high risk of overfitting. To alleviate overfitting, we develop a multi-task learning approach, which regularizes the data-deficient dialog generation task with a masked token prediction task. Experiments on the CovidDialog datasets demonstrate the effectiveness of our approach. We perform both human evaluation and automatic evaluation of dialogs generated by our method. Results show that the generated responses are promising in being doctor-like, relevant to conversation history, clinically informative and correct. The code and the data are available at https://github.com/UCSD-AI4H/COVID-Dialogue.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112494296",
                    "name": "Meng Zhou"
                },
                {
                    "authorId": "2003804697",
                    "name": "Zechen Li"
                },
                {
                    "authorId": "10918587",
                    "name": "Bowen Tan"
                },
                {
                    "authorId": "2061248094",
                    "name": "Guangtao Zeng"
                },
                {
                    "authorId": "32412901",
                    "name": "Wenmian Yang"
                },
                {
                    "authorId": "2149253469",
                    "name": "Xuehai He"
                },
                {
                    "authorId": "1613055688",
                    "name": "Zeqian Ju"
                },
                {
                    "authorId": "79952429",
                    "name": "Subrato Chakravorty"
                },
                {
                    "authorId": "2107976513",
                    "name": "Shu Chen"
                },
                {
                    "authorId": "48520402",
                    "name": "Xingyi Yang"
                },
                {
                    "authorId": "2129513945",
                    "name": "Yichen Zhang"
                },
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "1564034697",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "2113451979",
                    "name": "Kun Xu"
                },
                {
                    "authorId": "143977260",
                    "name": "E. Xing"
                },
                {
                    "authorId": "40526720",
                    "name": "P. Xie"
                }
            ]
        },
        {
            "paperId": "e13bee68e7c2de3aed873cb8d411143a16bb2f51",
            "title": "DG2: Data Augmentation Through Document Grounded Dialogue Generation",
            "abstract": "Collecting data for training dialog systems can be extremely expensive due to the involvement of human participants and the need for extensive annotation. Especially in document-grounded dialog systems, human experts need to carefully read the unstructured documents to answer the users\u2019 questions. As a result, existing document-grounded dialog datasets are relatively small-scale and obstruct the effective training of dialogue systems. In this paper, we propose an automatic data augmentation technique grounded on documents through a generative dialogue model. The dialogue model consists of a user bot and agent bot that can synthesize diverse dialogues given an input document, which is then used to train a downstream model. When supplementing the original dataset, our method achieves significant improvement over traditional data augmentation methods. We also achieve great performance in the low-resource setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "145480864",
                    "name": "Song Feng"
                },
                {
                    "authorId": "2111900571",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "1703799",
                    "name": "Sachindra Joshi"
                },
                {
                    "authorId": "8390140",
                    "name": "L. Lastras"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        }
    ]
}