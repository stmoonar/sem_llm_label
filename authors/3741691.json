{
    "authorId": "3741691",
    "papers": [
        {
            "paperId": "85722b13631d9846866d45ff2bfc2a2fe1026ac8",
            "title": "LLMRec: Benchmarking Large Language Models on Recommendation Task",
            "abstract": "Recently, the fast development of Large Language Models (LLMs) such as ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. However, the application of LLMs in the recommendation domain has not been thoroughly investigated. To bridge this gap, we propose LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks. Specifically, we benchmark several popular off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. Furthermore, we investigate the effectiveness of supervised finetuning to improve LLMs' instruction compliance ability. The benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation. However, they demonstrated comparable performance to state-of-the-art methods in explainability-based tasks. We also conduct qualitative evaluations to further evaluate the quality of contents generated by different models, and the results show that LLMs can truly understand the provided information and generate clearer and more reasonable results. We aspire that this benchmark will serve as an inspiration for researchers to delve deeper into the potential of LLMs in enhancing recommendation performance. Our codes, processed data and benchmark results are available at https://github.com/williamliujl/LLMRec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218869839",
                    "name": "Junling Liu"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "1800462890",
                    "name": "Peilin Zhou"
                },
                {
                    "authorId": "2190432576",
                    "name": "Qichen Ye"
                },
                {
                    "authorId": "52290752",
                    "name": "Dading Chong"
                },
                {
                    "authorId": "2165702320",
                    "name": "Kangan Zhou"
                },
                {
                    "authorId": "2154871075",
                    "name": "Yueqi Xie"
                },
                {
                    "authorId": "150346771",
                    "name": "Yuwei Cao"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2061592207",
                    "name": "Chenyu You"
                },
                {
                    "authorId": "2233087809",
                    "name": "Philip S.Yu"
                }
            ]
        },
        {
            "paperId": "ccdedf5f4fd06b7b247a07ed75c456bd12450c91",
            "title": "Findings of the LoResMT 2021 Shared Task on COVID and Sign Language for Low-resource Languages",
            "abstract": "We present the findings of the LoResMT 2021 shared task which focuses on machine translation (MT) of COVID-19 data for both low-resource spoken and sign languages. The organization of this task was conducted as part of the fourth workshop on technologies for machine translation of low resource languages (LoResMT). Parallel corpora is presented and publicly available which includes the following directions: English$\\leftrightarrow$Irish, English$\\leftrightarrow$Marathi, and Taiwanese Sign language$\\leftrightarrow$Traditional Chinese. Training data consists of 8112, 20933 and 128608 segments, respectively. There are additional monolingual data sets for Marathi and English that consist of 21901 segments. The results presented here are based on entries from a total of eight teams. Three teams submitted systems for English$\\leftrightarrow$Irish while five teams submitted systems for English$\\leftrightarrow$Marathi. Unfortunately, there were no systems submissions for the Taiwanese Sign language$\\leftrightarrow$Traditional Chinese task. Maximum system performance was computed using BLEU and follow as 36.0 for English--Irish, 34.6 for Irish--English, 24.2 for English--Marathi, and 31.3 for Marathi--English.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40894258",
                    "name": "Atul Kr. Ojha"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "3422953",
                    "name": "Katharina Kann"
                },
                {
                    "authorId": "2056819421",
                    "name": "John E. Ortega"
                },
                {
                    "authorId": "2123317392",
                    "name": "Sheetal Shatam"
                },
                {
                    "authorId": "1515519789",
                    "name": "Theodorus Fransen"
                }
            ]
        },
        {
            "paperId": "1d7a7b894dcd8418d7278cd8ad234542380bafd8",
            "title": "Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages",
            "abstract": "This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages. This task was organised as part of the 3rd Workshop on Technologies for MT of Low Resource Languages (LoResMT) at AACL-IJCNLP 2020. The focus was on the zero-shot approach as a notable development in Neural Machine Translation to build MT systems for language pairs where parallel corpora are small or even non-existent. The shared task experience suggests that back-translation and domain adaptation methods result in better accuracy for small-size datasets. We further noted that, although translation between similar languages is no cakewalk, linguistically distinct languages require more data to give better results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112187419",
                    "name": "Atul Kr. Ojha"
                },
                {
                    "authorId": "47815719",
                    "name": "Valentin Malykh"
                },
                {
                    "authorId": "3456929",
                    "name": "Alina Karakanta"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                }
            ]
        },
        {
            "paperId": "63fae79b921e50d182d7a8cdfceab1fbf21c1d7f",
            "title": "Multiple Segmentations of Thai Sentences for Neural Machine Translation",
            "abstract": "Thai is a low-resource language, so it is often the case that data is not available in sufficient quantities to train an Neural Machine Translation (NMT) model which perform to a high level of quality. In addition, the Thai script does not use white spaces to delimit the boundaries between words, which adds more complexity when building sequence to sequence models. In this work, we explore how to augment a set of English\u2013Thai parallel data by replicating sentence-pairs with different word segmentation methods on Thai, as training data for NMT model training. Using different merge operations of Byte Pair Encoding, different segmentations of Thai sentences can be obtained. The experiments show that combining these datasets, performance is improved for NMT models trained with a dataset that has been split using a supervised splitting tool.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27731932",
                    "name": "Alberto Poncelas"
                },
                {
                    "authorId": "1656712155",
                    "name": "Wichaya Pidchamook"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "145630054",
                    "name": "J. Hadley"
                },
                {
                    "authorId": "144315616",
                    "name": "Andy Way"
                }
            ]
        },
        {
            "paperId": "ae83632de305219194dab935143cbcb27acabb3c",
            "title": "Pivot Machine Translation in INTERACT Project",
            "abstract": "The INTERnAtional network on Crisis Translation (INTERACT) project under EU Marie Sk\u0142odowska-Curie Actions (MSCA) Research and Innovation Staff Exchange (RISE) Programme aimed at researching translation in crisis scenarios. In this extended abstract, we present the work on Pivot Machine Translation under the INTERACT project.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "144315616",
                    "name": "Andy Way"
                },
                {
                    "authorId": "153712278",
                    "name": "C. Silva"
                },
                {
                    "authorId": "2069905347",
                    "name": "Andr\u00e9 Martins"
                }
            ]
        },
        {
            "paperId": "17c574c7ceb13b291a5114dac690094923539556",
            "title": "Understanding Meanings in Multilingual Customer Feedback",
            "abstract": "Understanding and being able to react to customer feedback is the most fundamental task in providing good customer service. However, there are two major obstacles for international companies to automatically detect the meaning of customer feedback in a global multilingual environment. Firstly, there is no widely acknowledged categorisation (classes) of meaning for customer feedback. Secondly, the applicability of one meaning categorisation, if it exists, to customer feedback in multiple languages is questionable. In this paper, we extracted representative real world samples of customer feedback from Microsoft Office customers in multiple languages, English, Spanish and Japanese,and concluded a five-class categorisation(comment, request, bug, complaint and meaningless) for meaning classification that could be used across languages in the realm of customer feedback analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "39366957",
                    "name": "Declan Groves"
                },
                {
                    "authorId": "2831538",
                    "name": "Hayakawa Akira"
                },
                {
                    "authorId": "27731932",
                    "name": "Alberto Poncelas"
                },
                {
                    "authorId": "1688015",
                    "name": "Qun Liu"
                }
            ]
        },
        {
            "paperId": "1875cb708437318f1bc5b2f5b7152de457879c77",
            "title": "Extracting In-domain Training Corpora for Neural Machine Translation Using Data Selection Methods",
            "abstract": "Data selection is a process used in selecting a subset of parallel data for the training of machine translation (MT) systems, so that 1) resources for training might be reduced, 2) trained models could perform better than those trained with the whole corpus, and/or 3) trained models are more tailored to specific domains. It has been shown that for statistical MT (SMT), the use of data selection helps improve the MT performance significantly. In this study, we reviewed three data selection approaches for MT, namely Term Frequency\u2013 Inverse Document Frequency, Cross-Entropy Difference and Feature Decay Algorithm, and conducted experiments on Neural Machine Translation (NMT) with the selected data using the three approaches. The results showed that for NMT systems, using data selection also improved the performance, though the gain is not as much as for SMT systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153712278",
                    "name": "C. Silva"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "27731932",
                    "name": "Alberto Poncelas"
                },
                {
                    "authorId": "144315616",
                    "name": "Andy Way"
                }
            ]
        },
        {
            "paperId": "687caea03c0ae4ed8006690fe39138d226ac0ce5",
            "title": "Chinese-Portuguese Machine Translation: A Study on Building Parallel Corpora from Comparable Texts",
            "abstract": "Although there are increasing and significant ties between China and Portuguese-speaking countries, there is not much parallel corpora in the Chinese-Portuguese language pair. Both languages are very populous, with 1.2 billion native Chinese speakers and 279 million native Portuguese speakers, the language pair, however, could be considered as low-resource in terms of available parallel corpora. In this paper, we describe our methods to curate Chinese-Portuguese parallel corpora and evaluate their quality. We extracted bilingual data from Macao government websites and proposed a hierarchical strategy to build a large parallel corpus. Experiments are conducted on existing and our corpora using both Phrased-Based Machine Translation (PBMT) and the state-of-the-art Neural Machine Translation (NMT) models. The results of this work can be used as a benchmark for future Chinese-Portuguese MT systems. The approach we used in this paper also shows a good example on how to boost performance of MT systems for low-resource language pairs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3417566",
                    "name": "Siyou Liu"
                },
                {
                    "authorId": "1800190",
                    "name": "Longyue Wang"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                }
            ]
        },
        {
            "paperId": "8352af90d534e2fd52b2a3da0a6cc03cdc6e8f5e",
            "title": "The RGNLP Machine Translation Systems for WAT 2018",
            "abstract": "This paper presents the system description of Machine Translation (MT) system(s) for Indic Languages Multilingual Task for the 2018 edition of the WAT Shared Task. In our experiments, we (the RGNLP team) explore both statistical and neural methods across all language pairs. (We further present an extensive comparison of language-related problems for both the approaches in the context of low-resourced settings.) Our PBSMT models were highest score on all automatic evaluation metrics in the English into Telugu, Hindi, Bengali, Tamil portion of the shared task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40894258",
                    "name": "Atul Kr. Ojha"
                },
                {
                    "authorId": "24870762",
                    "name": "Koel Dutta Chowdhury"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "9393246",
                    "name": "Karan Saxena"
                }
            ]
        },
        {
            "paperId": "0ee4aad344e03ba68267199652946d1260b0fd93",
            "title": "Ethical Considerations in NLP Shared Tasks",
            "abstract": "Shared tasks are increasingly common in our field, and new challenges are suggested at almost every conference and workshop. However, as this has become an established way of pushing research forward, it is important to discuss how we researchers organise and participate in shared tasks, and make that information available to the community to allow further research improvements. In this paper, we present a number of ethical issues along with other areas of concern that are related to the competitive nature of shared tasks. As such issues could potentially impact on research ethics in the Natural Language Processing community, we also propose the development of a framework for the organisation of and participation in shared tasks that can help mitigate against these issues arising.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2969658",
                    "name": "Carla Parra Escart\u00edn"
                },
                {
                    "authorId": "3373845",
                    "name": "Wessel Reijers"
                },
                {
                    "authorId": "143617906",
                    "name": "Teresa Lynn"
                },
                {
                    "authorId": "2243988",
                    "name": "Joss Moorkens"
                },
                {
                    "authorId": "144315616",
                    "name": "Andy Way"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                }
            ]
        }
    ]
}