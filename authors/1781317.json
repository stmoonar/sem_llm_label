{
    "authorId": "1781317",
    "papers": [
        {
            "paperId": "40d751dc26261f24d9cc8ba119052f5a7b2cd631",
            "title": "CMDBench: A Benchmark for Coarse-to-fine Multimodal Data Discovery in Compound AI Systems",
            "abstract": "Compound AI systems (CASs) that employ LLMs as agents to accomplish knowledge-intensive tasks via interactions with tools and data retrievers have garnered significant interest within database and AI communities. While these systems have the potential to supplement typical analysis workflows of data analysts in enterprise data platforms, unfortunately, CASs are subject to the same data discovery challenges that analysts have encountered over the years \u2014 silos of multimodal data sources, created across teams and departments within an organization, make it difficult to identify appropriate data sources for accomplishing the task at hand. Existing data discovery benchmarks do not model such multimodality and multiplicity of data sources. Moreover, benchmarks of CASs prioritize only evaluating end-to-end task performance. To catalyze research on evaluating the data discovery performance of multimodal data retrievers in CASs within a real-world setting, we propose CMDBench, a benchmark modeling the complexity of enterprise data platforms. We adapt existing datasets and benchmarks in open-domain \u2014 from question answering and complex reasoning tasks to natural language querying over structured data \u2014 to evaluate coarse- and fine-grained data discovery and task execution performance. Our experiments reveal the impact of data retriever design on downstream task performance \u2014 46% drop in task accuracy on average \u2014 across various modalities, data sources, and task difficulty. The results indicate the need to develop optimization strategies to identify appropriate LLM agents and retrievers for efficient execution of CASs over enterprise data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2304573633",
                    "name": "Yanlin Feng"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2304498651",
                    "name": "Aaron Feng"
                },
                {
                    "authorId": "2304499557",
                    "name": "Vincent Chen"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                }
            ]
        },
        {
            "paperId": "54644dfa759ca210e6c00dfe8943e37bca8a0ff0",
            "title": "Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions",
            "abstract": "Remarkable performance of large language models (LLMs) in a variety of tasks brings forth many opportunities as well as challenges of utilizing them in production settings. Towards practical adoption of LLMs, multi-agent systems hold great promise to augment, integrate, and orchestrate LLMs in the larger context of enterprise platforms that use existing proprietary data and models to tackle complex real-world tasks. Despite the tremendous success of these systems, current approaches rely on narrow, single-focus objectives for optimization and evaluation, often overlooking potential constraints in real-world scenarios, including restricted budgets, resources and time. Furthermore, interpreting, analyzing, and debugging these systems requires different components to be evaluated in relation to one another. This demand is currently not feasible with existing methodologies. In this postion paper, we introduce the concept of reasoning capacity as a unifying criterion to enable integration of constraints during optimization and establish connections among different components within the system, which also enable a more holistic and comprehensive approach to evaluation. We present a formal definition of reasoning capacity and illustrate its utility in identifying limitations within each component of the system. We then argue how these limitations can be addressed with a self-reflective process wherein human-feedback is used to alleviate shortcomings in reasoning and enhance overall consistency of the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1713436",
                    "name": "Pouya Pezeshkpour"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "29995869",
                    "name": "Nikita Bhutani"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2282472829",
                    "name": "Tom Mitchell"
                },
                {
                    "authorId": "2265753807",
                    "name": "Estevam R. Hruschka"
                }
            ]
        },
        {
            "paperId": "69069bea10deaa4b6b95450420cb5564a4890aa6",
            "title": "A Blueprint Architecture of Compound AI Systems for Enterprise",
            "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities surpassing conventional NLP challenges, creating opportunities for use in production use cases. Towards this goal, there is a notable shift to building compound AI systems, wherein LLMs are integrated into an expansive software infrastructure with many components like models, retrievers, databases and tools. In this paper, we introduce a blueprint architecture for compound AI systems to operate in enterprise settings cost-effectively and feasibly. Our proposed architecture aims for seamless integration with existing compute and data infrastructure, with ``stream'' serving as the key orchestration concept to coordinate data and instructions among agents and other components. Task and data planners, respectively, break down, map, and optimize tasks and data to available agents and data sources defined in respective registries, given production constraints such as accuracy and latency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "2284869489",
                    "name": "Nikita Bhutani"
                },
                {
                    "authorId": "2188417102",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2199811208",
                    "name": "Rafael Li Chen"
                },
                {
                    "authorId": "2265753908",
                    "name": "Kushan Mitra"
                },
                {
                    "authorId": "2121386026",
                    "name": "Sairam Gurajada"
                },
                {
                    "authorId": "1713436",
                    "name": "Pouya Pezeshkpour"
                },
                {
                    "authorId": "7782351",
                    "name": "Hayate Iso"
                },
                {
                    "authorId": "2304573633",
                    "name": "Yanlin Feng"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2305077543",
                    "name": "Chen Shen"
                },
                {
                    "authorId": "2305332661",
                    "name": "Jin Wang"
                },
                {
                    "authorId": "2265753807",
                    "name": "Estevam R. Hruschka"
                }
            ]
        },
        {
            "paperId": "37f4718ccf2ee93eab4a55d281c72d79c270f6ed",
            "title": "MEGAnno: Exploratory Labeling for NLP in Computational Notebooks",
            "abstract": "We present MEGAnno, a novel exploratory annotation framework designed for NLP researchers and practitioners. Unlike existing labeling tools that focus on data labeling only, our framework aims to support a broader, iterative ML workflow including data exploration and model development. With MEGAnno\u2019s API, users can programmatically explore the data through sophisticated search and automated suggestion functions and incrementally update task schema as their project evolve. Combined with our widget, the users can interactively sort, filter, and assign labels to multiple items simultaneously in the same notebook where the rest of the NLP project resides. We demonstrate MEGAnno\u2019s flexible, exploratory, efficient, and seamless labeling experience through a sentiment analysis use case.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145909538",
                    "name": "Dan Zhang"
                },
                {
                    "authorId": "2143468335",
                    "name": "H. Kim"
                },
                {
                    "authorId": "2199811208",
                    "name": "Rafael Li Chen"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                }
            ]
        },
        {
            "paperId": "d704f65e140de9140e28a5662ecbfcdaa36fa823",
            "title": "Machop: an end-to-end generalized entity matching framework",
            "abstract": "Real-world applications frequently seek to solve a general form of the Entity Matching (EM) problem to find associated entities. Such scenarios include matching jobs to candidates in job targeting, matching students with courses in online education, matching products with user reviews on e-commercial websites, and beyond. These tasks impose new requirements such as matching data entries with diverse formats or having a flexible and semantics-rich matching definition, which are beyond the current EM task formulation or approaches. In this paper, we introduce the problem of Generalized Entity Matching (GEM) that satisfies these practical requirements and presents an end-to-end pipeline Machop as the solution. Machop allows end users to define new matching tasks from scratch and apply them to new domains in a step-by-step manner. Machop casts the GEM problem as sequence pair classification so as to utilize the language understanding capability of Transformers-based language models (LMs) such as BERT. Moreover, it features a novel external knowledge injection approach with structure-aware pooling methods that allow domain experts to guide the LM to focus on the key matching information thus further contributing to the overall performance. Our experiments and case studies on real-world datasets from a popular recruiting platform show a significant 17.1% gain in F1 score against state-of-the-art methods along with meaningful matching results that are human understandable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143720808",
                    "name": "Jin Wang"
                },
                {
                    "authorId": "47001493",
                    "name": "Yuliang Li"
                },
                {
                    "authorId": "66536732",
                    "name": "Wataru Hirota"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                }
            ]
        },
        {
            "paperId": "eaf3352609c99271bfb905e2598e1f4bd0e3b84a",
            "title": "Characterizing Practices, Limitations, and Opportunities Related to Text Information Extraction Workflows: A Human-in-the-loop Perspective",
            "abstract": "Information extraction (IE) approaches often play a pivotal role in text analysis and require significant human intervention. Therefore, a deeper understanding of existing IE practices and related challenges from a human-in-the-loop perspective is warranted. In this work, we conducted semi-structured interviews in an industrial environment and analyzed the reported IE approaches and limitations. We observed that data science workers often follow an iterative task model consisting of information foraging and sensemaking loops across all the phases of an IE workflow. The task model is generalizable and captures diverse goals across these phases (e.g., data preparation, modeling, evaluation.) We found several limitations in both foraging (e.g., data exploration) and sensemaking (e.g., qualitative debugging) loops stemming from a lack of adherence to existing cognitive engineering principles. Moreover, we identified that due to the iterative nature of an IE workflow, the requirement of provenance is often implied but rarely supported by existing systems. Based on these findings, we discuss design implications for supporting IE workflows and future research directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37455401",
                    "name": "Sajjadur Rahman"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                }
            ]
        },
        {
            "paperId": "1e8c695035fb161158042c960f716cb938d261d9",
            "title": "Boomerang: Proactive Insight-Based Recommendations for Guiding Conversational Data Analysis",
            "abstract": "Natural-language interfaces are gaining popularity due to their potential to democratize access to data and insights by making the interaction with data more natural and accessible for a wide range of business users. To fully embrace the goal of democratization, it is also necessary to provide effective and continuous guidance support for data exploration. Conversational interfaces enable exploration of the data and insights search space in small incremental steps as the conversation with the data progresses. In this demo, we describe Boomerang, a system that recommends data-driven insights to guide exploration of datasets through a conversational interface. Boomerang aggregates recommendations from a variety of statistical, collaborative, and content-based recommenders, and selects insights that match closely to the user's current state of data exploration, represented as the \\em conversational context. Boomerang combines various metrics, such as \\em relevance, \\em interestingness and \\em timeliness, to rank the insights and recommends the insights based on current conversational context. In the demo, we will show how Boomerang enables guided data exploration on a sales dataset, containing information about products, retailers, sales, orders, inventory levels and regions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159905",
                    "name": "D. Lee"
                },
                {
                    "authorId": "1949818",
                    "name": "A. Quamar"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "143972996",
                    "name": "Fatma \u00d6zcan"
                }
            ]
        },
        {
            "paperId": "03a4544caed21760df30f0e4f417bbe361c29c9e",
            "title": "A Study on Interaction in Human-in-the-Loop Machine Learning for Text Analytics",
            "abstract": "Machine learning (ML) models are often considered \u201cblackboxes\u201d as their internal representations fail to align with human understanding. While recent work attempted to expose the inner workings of ML models they do not allow users to interact directly with the model. This is especially problematic in domains where labeled data is limited as such the generalizability of ML models becomes questionable. We argue that the fundamental problem of generalizibility could be addressed by making ML models explainable in abstractions and expressions that make sense to users and by allowing them to interact with the model to assess, select, and build on. By involving humans in the process this way, we argue that the cocreated models will be more generalizable as they extrapolate what ML learns from few data when expressed in higher level abstractions that humans can verify, update, and expand based on their domain expertise. In this paper, we introduce RulesLearner that expresses MLmodel as rules on top of semantic linguistic structures in disjunctive normal form. RulesLearner allows users to interact with the patterns learned by the ML model, e.g. add and remove predicates, examine precision and recall, and construct a trusted set of rules.We conducted a preliminary user study which suggests that (1) rules learned by ML are explainable and (2) co-created model is more generalizable (3) providing rules to experts improves overall productivity, with fewer people involved, with less expertise. Our findings link explainability and interactivity to generalizability, as such suggest that hybrid intelligence (human-AI) methods offer great potential.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108756362",
                    "name": "Yiwei Yang"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "40655309",
                    "name": "Prithviraj Sen"
                },
                {
                    "authorId": "2598433",
                    "name": "Walter S. Lasecki"
                }
            ]
        },
        {
            "paperId": "3bb3a018bf8c0defd7eec3d98001aa9103fcb24a",
            "title": "HEIDL: Learning Linguistic Expressions with Deep Learning and Human-in-the-Loop",
            "abstract": "While the role of humans is increasingly recognized in machine learning community, representation of and interaction with models in current human-in-the-loop machine learning (HITL-ML) approaches are too low-level and far-removed from human\u2019s conceptual models. We demonstrate HEIDL, a prototype HITL-ML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text. In HEIDL, human\u2019s role is elevated from simply evaluating model predictions to interpreting and even updating the model logic directly by enabling interaction with rule predicates themselves. Raising the currency of interaction to such semantic levels calls for new interaction paradigms between humans and machines that result in improved productivity for text analytics model development process. Moreover, by involving humans in the process, the human-machine co-created models generalize better to unseen data as domain experts are able to instill their expertise by extrapolating from what has been learned by automated algorithms from few labelled data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108756362",
                    "name": "Yiwei Yang"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2598433",
                    "name": "Walter S. Lasecki"
                },
                {
                    "authorId": "40655309",
                    "name": "Prithviraj Sen"
                }
            ]
        },
        {
            "paperId": "8720fcac310f4da940dbc3a067cb4bc3835d4c85",
            "title": "OMXWare, A Cloud-Based Platform for Studying Microbial Life at Scale",
            "abstract": "The rapid growth in biological sequence data is revolutionizing our understanding of genotypic diversity and challenging conventional approaches to informatics. Due to increasing availability of genomic data, traditional bioinformatic tools require substantial computational time and creation of ever larger indices each time a researcher seeks to gain insight from the data. To address these challenges, we pre-compute important relationships between biological entities and capture this information in a relational database.The database can be queried across millions of entities and returns results in a fraction of the time required by traditional methods. In this paper, we describeOMXWare, a comprehensive database relating genotype to phenotype for bacterial life. Continually updated,OMXWare today contains data derived from 200,000 curated, self-consistently assembled genomes. The database stores functional data for over 68 million genes, 52 million proteins, and 239 million domains with associated biological activity annotations from GeneOntology, KEGG, MetaCyc, and Reactome. OMXWare maps connections between each biological entity including the originating genome, gene, protein, and protein domain. Various microbial studies, from infectious disease to environmental health, can benefit from the rich data and relationships within OMXWare. We describe the data selection, the pipeline to create and update OMXWare, and developer tools (Python SDK and Rest APIs) which allow researchers to efficiently study microbial life at scale.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "41158906",
                    "name": "Ed Seabolt"
                },
                {
                    "authorId": "2123783689",
                    "name": "Gowri Nayar"
                },
                {
                    "authorId": "51045818",
                    "name": "Harsha Krishnareddy"
                },
                {
                    "authorId": "143914394",
                    "name": "Akshay Agarwal"
                },
                {
                    "authorId": "1380315035",
                    "name": "Kristen L. Beck"
                },
                {
                    "authorId": "2899326",
                    "name": "Ignacio G. Terrizzano"
                },
                {
                    "authorId": "1781317",
                    "name": "Eser Kandogan"
                },
                {
                    "authorId": "11571384",
                    "name": "M. Roth"
                },
                {
                    "authorId": "80257800",
                    "name": "Vandana V. Mukherjee"
                },
                {
                    "authorId": "34517474",
                    "name": "J. Kaufman"
                }
            ]
        }
    ]
}