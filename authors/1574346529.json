{
    "authorId": "1574346529",
    "papers": [
        {
            "paperId": "d7f29f1d6a7ad4a612c17282ac17645085f81d20",
            "title": "Pixel- And Patch-Wise Context-Aware Learning with CNN and GCN Collaboration for Hyperspectral Image Classification",
            "abstract": "Graph convolutional network (GCN) gains increasing attention in the hyperspectral image (HSI) classification by the ability to flexibly capture arbitrarily irregular objects. However, due to expensive computation, the graph construction is usually based on superpixel-wise nodes, which ignore the subtle pixel-wise features. In contrast, the convolution neural network (CNN) can mine pixel-wise spectral-spatial features but is limited to capturing local features in small square windows. In this paper, we design a new CNN and GCN collaborative network to simultaneously introduce pixel- and patch-wise contextual information. Concretely, we use the depthwise separable convolution to perform pixel-wise local feature extraction. To further mine the long-range contextual information between land covers, we concatenate a GCN. Finally, we further fuse the complementary features and decode them to obtain the classification map. Extensive experiments reveal that our method achieves competitive performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "8fc2548ae8f31a148b29281e359ea3151d2115ed",
            "title": "Triplet-Metric-Guided Multi-Scale Attention for Remote Sensing Image Scene Classification with a Convolutional Neural Network",
            "abstract": "Remote sensing image scene classification (RSISC) plays a vital role in remote sensing applications. Recent methods based on convolutional neural networks (CNNs) have driven the development of RSISC. However, these approaches are not adequate considering the contributions of different features to the global decision. In this paper, triplet-metric-guided multi-scale attention (TMGMA) is proposed to enhance task-related salient features and suppress task-unrelated salient and redundant features. Firstly, we design the multi-scale attention module (MAM) guided by multi-scale feature maps to adaptively emphasize salient features and simultaneously fuse multi-scale and contextual information. Secondly, to capture task-related salient features, we use the triplet metric (TM) to optimize the learning of MAM under the constraint that the distance of the negative pair is supposed to be larger than the distance of the positive pair. Notably, the MAM and TM collaboration can enforce learning a more discriminative model. As such, our TMGMA can avoid the classification confusion caused by only using the attention mechanism and the excessive correction of features caused by only using the metric learning. Extensive experiments demonstrate that our TMGMA outperforms the ResNet50 baseline by 0.47% on the UC Merced, 1.46% on the AID, and 1.55% on the NWPU-RESISC45 dataset, respectively, and achieves performance that is competitive with other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "1787c87af9407810b3d549de27313ce3dd559190",
            "title": "An improved kernelized-correlation-filter spatial target tracking method using variable regularization and spatio-temporal context model",
            "abstract": "The dim target tracking is essential for the spatial surveillance system. Considering that the starry image sequences acquired by imaging sensors often has low Signal-to-Noise Ratio (SNR), the brightness of a spatial target is often susceptible to the background interferences, such as the night clouds and the atmospheric turbulence, etc, and become dim and instable, its shape and profile is also blurred and lack of texture information. In order to extract the target from background, Spatio-Temporal Context Model (STCM) based filtering theory is applied in this paper and used to improve the traditional Kernelized-Correlation-Filter (KCF) target tracking method. It introduces a spatial weighting function that can pre-enhance the point target and suppresses the background interferences. So the tracking drift phenomenon is relieved when the moving object being obstructed temporarily. Considering that L1 regularization is easier to obtain sparse solutions and L2 regularization has smoothness property, the regularization function of the regressive classifiers in KCF target tracking method is renewed by using variable L1 or L2 regularization instead. The index of regularization in the improved regression model is a piecewise function, which is determined by the cost function during learning period that can distinguish the target star point from the background point by using the characteristics of points (such as brightness, etc.)The numeral simulation and actual processing results show that, comparing with the traditional Kernelized- Correlation-Filter (KCF) methods, the proposed method owns more robustness and precision in the starry images with low signal-to-noise ratio and complex background.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "50615889",
                    "name": "Tinghua Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                }
            ]
        },
        {
            "paperId": "87f03bc740c224217f7b4e6c0d2a1c998555898a",
            "title": "Starry image matching method based on the description of multi-scale geometric invariant features",
            "abstract": "In the spatial target surveillance and astronomical observation applications, image matching processing is the key procedure for the multi-temporal starry images or the multi-channel starry images acquired by different imaging sensors. However, the starry images obtained often have low Signal-to-Noise Ratios (SNR), the light intensities of the target stars or spacecrafts in them are vulnerable to background interferences, such as the atmospheric turbulence and the night clouds, etc., and become dim and instable. With the weak texture information of the target stars, all the influences make the feature point extraction quite difficult. In this paper, a new type of image matching method based on the description of Multi-scale Geometric Invariant Features (MGIF) is proposed, which uses the Rolling Guidance Filter (RGF) to perform preprocessing for the input images. By virtue of the excellent edge-preserving performance of the Joint Bilateral Filter in RGF, the integrities of contour profile of the star points are guaranteed effectively while the interference and other noise in the background are suppressed. Then the segmented and morphology methods are applied to extract star points and get the centroid of star points to form the feature point constellation. Considering the cross ratio of two lines in projection transformation model of image matching is a geometric invariant, a multi-scale geometric invariants based function, which uses the scaling of RGF as a reference to describe the relative spatial positions of matching points more accurately, is constructed to evaluate the level of similarity between star points according to the relative position of each points in the constellation. Subsequently, Random Sample Consensus\uff08RANSAC\uff09method is adopted to remove the mismatching star points and calculate the rigid transform matrix and other registration parameters. Digital simulation and practical processing results demonstrate that the proposed method can achieve higher matching accuracy and robustness for the starry images with low SNR and complex backgrounds.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "50615889",
                    "name": "Tinghua Zhang"
                }
            ]
        },
        {
            "paperId": "be84165c8f8924941defc5dc912c2b64d94ed5d6",
            "title": "A method of posture monitoring and falling detection based on physiological and behavioral characteristics of the elderly",
            "abstract": "At present, the problem of population aging has become a hot spot of international concern, especially in China, and the international community urgently needs a universally applicable health care system for the elderly. Recent research shows that falling is the biggest threat to the health of the elderly. Based on thihe physiological and behavioral characteristics of the elderly, the paper discusses an algorithm for the recognition of motion state and fall detection of elderly applied to wearable devices to ensure timely rescue after a fall. The algorithm continuously acquires acceleration information during the movement of the elderly through a six-axis acceleration sensor. Firstly, the acceleration data is filtered, then the combined acceleration is calculated, and multiple features of the continuous data are extracted, and then the softmax method is used to classify the different motion states to realize the alarm of the fall. The algorithm extracts the feature vector by the magnitude of the combined acceleration, which solves the problem that the single acceleration in the traditional algorithm must solves the coordinate axis, which may waste much calculating time. The algorithm is validated by using the existing data set, and the accuracy of the algorithm is up to 89%. It is an effective way to detect falls.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2210199951",
                    "name": "Shiyun Zhou"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "1575167527",
                    "name": "Haisong Tang"
                },
                {
                    "authorId": "2108082593",
                    "name": "Yanchen Liu"
                },
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "32693617",
                    "name": "Liquan Dong"
                }
            ]
        },
        {
            "paperId": "c4af35a3c200207a200fbf72d38ceeee75a39214",
            "title": "A mosaic method for multichannel sequence starry images via multiscale edge-preserving spatio-temporal context filtering",
            "abstract": "Astronomical observation and spatial target surveillance applications often require mosaic processing of starry images acquired by multiple image sensors to expand the Fields of View (FOV) or improve the resolutions. Due to the low SNR (Signal-to-Noise Ratio), lack of star point texture information and vulnerability of atmospheric turbulence of the starry image properties, traditional mosaic methods are prone to failures during feature point extraction. In this paper, Spatio-Temporal Context (STC) filtering is introduced as the preprocessing procedure to suppress the background interferences. We have improved the classical STC filtering and expands it into multi-scale space combining with Rolling-Guidance Filtering Algorithm (RGFA). Making full use of the fine edge-preserving feature of RGFA, the time-variant or spatial variant interference and noise in the background, such as glimmer stars, night clouds, sensor response noise, etc, are suppressed while the profiles of the target star points are enhanced and easy to extract their centroids. Then, we produced the feature description of the star-point sets via threshold segmentation and morphological algorithms based on geometric invariant cost function for the input image pairs to be stitched. After Random Sample Consensus (RANSAC) processing, the mismatched feature point pairs in the star-point sets are excluded. The subsequent procedures of the registration parameter calculation, image fusion and parallax correction processing are adopted to complete the mosaic processing. The results of digital simulation and practical processing show that the proposed method for the multichannel sequence starry images with the low SNR and complex backgrounds can extract feature points more precisely and more robustly comparing with the traditional methods. So, it is suitable for the large FOV spatial observation or surveillance applications.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "50615889",
                    "name": "Tinghua Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                }
            ]
        }
    ]
}