{
    "authorId": "1403679857",
    "papers": [
        {
            "paperId": "0bd01c2028eedfb3e6cd6c0505416783f6615a51",
            "title": "Finding Convincing Views to Endorse a Claim",
            "abstract": "Recent studies investigated the challenge of assessing the strength of a given claim extracted from a dataset, particularly the claim's potential of being misleading and cherry-picked. We focus on claims that compare answers to an aggregate query posed on a view that selects tuples. The strength of a claim amounts to the question of how likely it is that the view is carefully chosen to support the claim, whereas less careful choices would lead to contradictory claims. We embark on the study of the reverse task that offers a complementary angle in the critical assessment of data-based claims: given a claim, find useful supporting views. The goal of this task is twofold. On the one hand, we aim to assist users in finding significant evidence of phenomena of interest. On the other hand, we wish to provide them with machinery to criticize or counter given claims by extracting evidence of opposing statements. To be effective, the supporting sub-population should be significant and defined by a ``natural'' view. We discuss several measures of naturalness and propose ways of extracting the best views under each measure (and combinations thereof). The main challenge is the computational cost, as na\\\"ive search is infeasible. We devise anytime algorithms that deploy two main steps: (1) a preliminary construction of a ranked list of attribute combinations that are assessed using fast-to-compute features, and (2) an efficient search for the actual views based on each attribute combination. We present a thorough experimental study that shows the effectiveness of our algorithms in terms of quality and execution cost. We also present a user study to assess the usefulness of the naturalness measures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50821849",
                    "name": "Shunit Agmon"
                },
                {
                    "authorId": "2302860063",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "2317008532",
                    "name": "Shahar Zoarets"
                },
                {
                    "authorId": "2317004035",
                    "name": "Benny Kimelfeld Technion - Israel Institute of Technology"
                },
                {
                    "authorId": "2317011213",
                    "name": "Hebrew University"
                }
            ]
        },
        {
            "paperId": "3e74d29604b82810a9c8cf5193c1a6a280c3dd2c",
            "title": "Sawmill: From Logs to Causal Diagnosis of Large Systems",
            "abstract": "Causal analysis is an essential lens for understanding complex system dynamics in domains as varied as medicine, economics and law. Computer systems are often similarly complex, but much of the information about them is only available in long, messy, semi-structured log files. This demo presents Sawmill, an open-source system that makes it possible to extract causal conclusions from log files. Sawmill employs methods drawn from the areas of data transformation, cleaning, and extraction in order to transform logs into a representation amenable to causal analysis. It gives log-derived variables human-understandable names and distills the information present in a log file around a user's chosen causal units (e.g. users or machines), generating appropriate aggregated variables for each causal unit. It then leverages original algorithms to efficiently use this representation for the novel process of Exploration-based Causal Discovery - the task of constructing a sufficient causal model of the system from available data. Users can engage with this process via an interactive interface, ultimately making causal inference possible using off-the-shelf tools. SIGMOD'24 participants will be able to use Sawmill to efficiently answer causal questions about logs. We will guide attendees through the process of quantifying the impact of parameter tuning on query latency using real-world PostgreSQL server logs, before letting them test Sawmill on additional logs with known causal effects but varying difficulty. A companion video for this submission is available online.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2094294894",
                    "name": "Markos Markakis"
                },
                {
                    "authorId": "2294344485",
                    "name": "An Bo Chen"
                },
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "2294214747",
                    "name": "Trinity Gao"
                },
                {
                    "authorId": "41017226",
                    "name": "Rana Shahout"
                },
                {
                    "authorId": "2302770964",
                    "name": "Peter Baille Chen"
                },
                {
                    "authorId": "1726050553",
                    "name": "Chunwei Liu"
                },
                {
                    "authorId": "2294212476",
                    "name": "Ibrahim Sabek"
                },
                {
                    "authorId": "2273946249",
                    "name": "Michael Cafarella"
                },
                {
                    "authorId": "2294305826",
                    "name": "Ziyu Zhang"
                }
            ]
        },
        {
            "paperId": "a331ec868921c440c1794f7b23f899ae403a1f11",
            "title": "First Workshop on Governance, Understanding and Integration of Data for Effective and Responsible AI (GUIDE-AI)",
            "abstract": "With the recent advancements in artificial intelligence (AI) and Machine Learning (ML), data-driven automated systems are being deployed in numerous high-stakes applications. Central to AI's effectiveness is its foundation in data. This workshop aims to bring together researchers from academia and industry to discuss the role of data management to guide the trustworthy design of AI-based applications. We plan the first edition of the workshop to include invited talks and a panel discussion with researchers from neighboring communities like ML, FAccT, HCI and Theoretical Computer science. The workshop aims to create a collaborative platform for these diverse communities to contribute to the evolving narrative of responsible AI development.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302859830",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "2663974",
                    "name": "Sainyam Galhotra"
                },
                {
                    "authorId": "2302860063",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "2124624117",
                    "name": "Babak Salimi"
                },
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                }
            ]
        },
        {
            "paperId": "d53a0f75aa12181e49e1ddc687356655f16ed387",
            "title": "Summarized Causal Explanations For Aggregate Views",
            "abstract": "SQL queries with group-by and average are frequently used and plotted as bar charts in several data analysis applications. Understanding the reasons behind the results in such an aggregate view may be a highly nontrivial and time-consuming task, especially for large datasets with multiple attributes. Hence, generating automated explanations for aggregate views can allow users to gain better insights into the results while saving time in data analysis. When providing explanations for such views, it is paramount to ensure that they are succinct yet comprehensive, reveal different types of insights that hold for different aggregate answers in the view, and, most importantly, they reflect reality and arm users to make informed data-driven decisions, i.e., the explanations do not only consider correlations but are causal. In this paper, we present CauSumX, a framework for generating summarized causal explanations for the entire aggregate view. Using background knowledge captured in a causal DAG, CauSumX finds the most effective causal treatments for different groups in the view. We formally define the framework and the optimization problem, study its complexity, and devise an efficient algorithm using the Apriori algorithm, LP rounding, and several optimizations. We experimentally show that our system generates useful summarized causal explanations compared to prior work and scales well for large high-dimensional data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "2273946249",
                    "name": "Michael Cafarella"
                },
                {
                    "authorId": "32466098",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "2243940951",
                    "name": "Sudeepa Roy"
                }
            ]
        },
        {
            "paperId": "5cbc8b933654248f3461881772ad70a418bf72ff",
            "title": "Causal Data Integration",
            "abstract": "Causal inference is fundamental to empirical scientific discoveries in natural and social sciences; however, in the process of conducting causal inference, data management problems can lead to false discoveries. Two such problems are (i) not having all attributes required for analysis, and (ii) misidentifying which attributes are to be included in the analysis. Analysts often only have access to partial data, and they critically rely on (often unavailable or incomplete) domain knowledge to identify attributes to include for analysis, which is often given in the form of a causal DAG. We argue that data management techniques can surmount both of these challenges. In this work, we introduce the Causal Data Integration (CDI) problem, in which unobserved attributes are mined from external sources and a corresponding causal DAG is automatically built. We identify key challenges and research opportunities in designing a CDI system, and present a system architecture for solving the CDI problem. Our preliminary experimental results demonstrate that solving CDI is achievable and pave the way for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1725561",
                    "name": "Michael J. Cafarella"
                },
                {
                    "authorId": "145674068",
                    "name": "Babak Salimi"
                },
                {
                    "authorId": "2162674366",
                    "name": "Anna Zeng"
                }
            ]
        },
        {
            "paperId": "8b88b37ba32ecde69901a9bdd6e63ffa21a5d339",
            "title": "NEXUS: On Explaining Confounding Bias",
            "abstract": "When analyzing large datasets, analysts are often interested in the explanations for unexpected results produced by their queries. In this work, we focus on aggregate SQL queries that expose correlations in the data. A major challenge that hinders the interpretation of such queries is confounding bias, which can lead to an unexpected association between variables. For example, a SQL query computes the average Covid-19 death rate in each country, may expose a puzzling correlation between the country and the death rate. In this work, we demonstrate NEXUS, a system that generates explanations in terms of a set of potential confounding variables that explain the unexpected correlation observed in a query. NEXUS mines candidate confounding variables from external sources since, in many real-life scenarios, the explanations are not solely contained in the input data. For instance, NEXUS might extract data about factors explaining the association between countries and the Covid-19 death rate, such as information about countries' economies and health outcomes. We will demonstrate the utility of NEXUS for investigating unexpected query results by interacting with the SIGMOD'23 participants, who will act as data analysts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1725561",
                    "name": "Michael J. Cafarella"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2124624117",
                    "name": "Babak Salimi"
                }
            ]
        },
        {
            "paperId": "17d5adafa8a151d2d906abf206f380fae40fc72c",
            "title": "EDA4SUM: Guided Exploration of Data Summaries",
            "abstract": "\n We demonstrate EDA4Sum, a framework dedicated to generating guided multi-step data summarization pipelines for very large datasets. Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. EDA4Sum leverages Exploratory Data Analysis (EDA) to produce connected summaries in multiple steps, with the goal of maximizing their cumulative utility. A useful summary contains\n k individually uniform\n sets that are\n collectively diverse\n to be representative of the input data. EDA4Sum accommodates datasets with different characteristics by providing the ability to tune the weights of uniformity, diversity and novelty when generating multi-step summaries. We demonstrate the superiority of multi-step EDA summarization over single-step summarization for summarizing very large data, and the need to provide guidance to domain experts, by interacting with the VLDB'22 participants who will act as data analysts. The application is avilable at https://bit.ly/eda4sum_application.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2072259106",
                    "name": "Aur\u00e9lien Personnaz"
                },
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "34eaec9643c1025065589f5513249431168a2ace",
            "title": "On Explaining Confounding Bias",
            "abstract": "When analyzing large datasets, analysts are often interested in the explanations for unexpected results produced by their queries. In this work, we focus on aggregate SQL queries that expose correlations in the data. A major challenge that hinders the interpretation of such queries is confounding bias, which can lead to an unexpected correlation. We generate explanations in terms of a set of potential confounding variables that explain the unexpected correlation observed in a query. We propose to mine candidate confounding variables from external sources since, in many real-life scenarios, the explanations are not solely contained in the input data. We present an efficient algorithm that finds a concise subset of attributes (mined from external sources and the input dataset) that explain the unexpected correlation. This algorithm is embodied in a system called MESA. We demonstrate experimentally over multiple real-life datasets and through a user study that our approach generates insightful explanations, outperforming existing methods even when are given with the extracted attributes. We further demonstrate the robustness of our system to missing data and the ability of MESA to handle input datasets containing millions of tuples and an extensive search space of candidate confounding attributes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1725561",
                    "name": "Michael J. Cafarella"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "2124624117",
                    "name": "Babak Salimi"
                }
            ]
        },
        {
            "paperId": "5d809ae3499f10c73eba96dc5c1bbb55a56fb1c0",
            "title": "Guided Exploration of Data Summaries",
            "abstract": "\n Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains\n k individually uniform\n sets that are\n collectively diverse\n to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of Exploratory Data Analysis (EDA) to data summarization and formalize Eda4Sum, the problem of guided exploration of data summaries that seeks to sequentially produce connected summaries with the goal of maximizing their cumulative utility. Eda4Sum generalizes one-shot summarization. We propose to solve it with one of two approaches: (i) Top1Sum that chooses the most useful summary at each step; (ii) RLSum that trains a policy with Deep Reinforcement Learning that rewards an agent for finding a diverse and new collection of uniform sets at each step. We compare these approaches with one-shot summarization and top-performing EDA solutions. We run extensive experiments on three large datasets. Our results demonstrate the superiority of our approaches for summarizing very large data, and the need to provide guidance to domain experts.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2072259106",
                    "name": "Aur\u00e9lien Personnaz"
                }
            ]
        },
        {
            "paperId": "b3333559178dc9247ab2f103abf60518dd234d3e",
            "title": "OREO: Detection of Cherry-picked Generalizations",
            "abstract": "Data analytics often make sense of large data sets by generalization: aggregating from the detailed data to a more general context. Given a dataset, misleading generalizations can sometimes be drawn from a cherry-picked level of aggregation to obscure substantial subgroups that oppose the generalization. Our goal is to detect and explain cherry-picked generalizations by refining the corresponding aggregate queries. We demonstrate OREO, a system to compute a support score of the given statement to quantify the quality of the generalization; that is, whether the aggregated result is an accurate reflection of the data. To better understand the resulting score, our system also identifies significant counterexamples and alternative statements that better represent the data at hand. We will demonstrate the utility of OREO for investigating generalizations, by interacting with the VLDB'22 participants who will use the OREO interface for statement validation and explanation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117033724",
                    "name": "Yin Lin"
                },
                {
                    "authorId": "1403679857",
                    "name": "Brit Youngmann"
                },
                {
                    "authorId": "2330778",
                    "name": "Y. Moskovitch"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                },
                {
                    "authorId": "1702212",
                    "name": "Tova Milo"
                }
            ]
        }
    ]
}