{
    "authorId": "145071799",
    "papers": [
        {
            "paperId": "1607ee857e7fd5bcd16581859f4049cd61fc909a",
            "title": "Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning",
            "abstract": "Methods for carefully selecting or generating a small set of training data to learn from, i.e., data pruning, coreset selection, and data distillation, have been shown to be effective in reducing the ever-increasing cost of training neural networks. Behind this success are rigorously designed strategies for identifying informative training examples out of large datasets. However, these strategies come with additional computational costs associated with subset selection or data distillation before training begins, and furthermore, many are shown to even under-perform random sampling in high data compression regimes. As such, many data pruning, coreset selection, or distillation methods may not reduce 'time-to-accuracy', which has become a critical efficiency measure of training deep neural networks over large datasets. In this work, we revisit a powerful yet overlooked random sampling strategy to address these challenges and introduce an approach called Repeated Sampling of Random Subsets (RSRS or RS2), where we randomly sample the subset of training data for each epoch of model training. We test RS2 against thirty state-of-the-art data pruning and data distillation methods across four datasets including ImageNet. Our results demonstrate that RS2 significantly reduces time-to-accuracy compared to existing techniques. For example, when training on ImageNet in the high-compression regime (using less than 10% of the dataset each epoch), RS2 yields accuracy improvements up to 29% compared to competing pruning methods while offering a runtime reduction of 7x. Beyond the above meta-study, we provide a convergence analysis for RS2 and discuss its generalization capability. The primary goal of our work is to establish RS2 as a competitive baseline for future data selection or distillation techniques aimed at efficient training.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2173711120",
                    "name": "Patrik Okanovic"
                },
                {
                    "authorId": "103967638",
                    "name": "R. Waleffe"
                },
                {
                    "authorId": "2148975767",
                    "name": "Vasilis Mageirakos"
                },
                {
                    "authorId": "52210145",
                    "name": "Konstantinos E. Nikolakakis"
                },
                {
                    "authorId": "1697131",
                    "name": "Amin Karbasi"
                },
                {
                    "authorId": "2215926645",
                    "name": "Dionysis Kalogerias"
                },
                {
                    "authorId": "51274710",
                    "name": "Nezihe Merve Gurel"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "231b753ae413964f279db551795da7965366450c",
            "title": "Co-design Hardware and Algorithm for Vector Search",
            "abstract": "Vector search has emerged as the foundation for large-scale information retrieval and machine learning systems, with search engines like Google and Bing processing tens of thousands of queries per second on petabyte-scale document datasets by evaluating vector similarities between encoded query texts and web documents. As performance demands for vector search systems surge, accelerated hardware offers a promising solution in the post-Moore's Law era. We introduce FANNS, an end-to-end and scalable vector search framework on FPGAs. Given a user-provided recall requirement on a dataset and a hardware resource budget, FANNS automatically co-designs hardware and algorithm, subsequently generating the corresponding accelerator. The framework also supports scale-out by incorporating a hardware TCP/IP stack in the accelerator. FANNS attains up to 23.0\u00d7 and 37.2\u00d7 speedup compared to FPGA and CPU baselines, respectively, and demonstrates superior scalability to GPUs, achieving 5.5\u00d7 and 7.6\u00d7 speedup in median and 95th per-centile (P95) latency within an eight-accelerator configuration. The remarkable performance of FANNS lays a robust groundwork for future FPGA integration in data centers and AI supercomputers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38818042",
                    "name": "Wenqi Jiang"
                },
                {
                    "authorId": "2298884755",
                    "name": "Shigang Li"
                },
                {
                    "authorId": "2109388499",
                    "name": "Yu Zhu"
                },
                {
                    "authorId": "35608738",
                    "name": "J. D. F. Licht"
                },
                {
                    "authorId": "72181587",
                    "name": "Zhenhao He"
                },
                {
                    "authorId": "2834680",
                    "name": "Runbin Shi"
                },
                {
                    "authorId": "37833666",
                    "name": "C\u00e9dric Renggli"
                },
                {
                    "authorId": "1583098764",
                    "name": "Shuai Zhang"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                },
                {
                    "authorId": "1713648",
                    "name": "T. Hoefler"
                },
                {
                    "authorId": "144641551",
                    "name": "G. Alonso"
                }
            ]
        },
        {
            "paperId": "2b054eb2be8fbb261503370323e4442602eddeed",
            "title": "Fact Ranking over Large-Scale Knowledge Graphs with Reasoning Embedding Models",
            "abstract": "Knowledge graphs (KGs) serve as the backbone of many applications such as recommendation systems and question answering. All these applications require reasoning about the relevance of facts in a KG to downstream applications. In this work, we describe our efforts in building a solution to reason about the importance of facts over continuously updated industry-scale KGs. We focus on the problem of fact ranking and evaluate to what extent modern knowledge graph embedding (KGE) models provide a representation for addressing this problem. To this end, we discuss unique challenges associated with solving this task in industrial settings and evaluate how accurately different KGE models and text-based embedding models can solve the problem of fact ranking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "143661472",
                    "name": "A. Mousavi"
                },
                {
                    "authorId": "4047075",
                    "name": "Anil Pacaci"
                },
                {
                    "authorId": "2087061163",
                    "name": "S. R. Chowdhury"
                },
                {
                    "authorId": "2047146404",
                    "name": "J. Mohoney"
                },
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "4f662c42b2bd52422b70d8f44175f33cec4f8969",
            "title": "High-Throughput Vector Similarity Search in Knowledge Graphs",
            "abstract": "There is an increasing adoption of machine learning for encoding data into vectors to serve online recommendation and search use cases. As a result, recent data management systems propose augmenting query processing with online vector similarity search. In this work, we explore vector similarity search in the context of Knowledge Graphs (KGs). Motivated by the tasks of finding related KG queries and entities for past KG query workloads, we focus on hybrid vector similarity search (hybrid queries for short) where part of the query corresponds to vector similarity search and part of the query corresponds to predicates over relational attributes associated with the underlying data vectors. For example, given past KG queries for a song entity, we want to construct new queries for new song entities whose vector representations are close to the vector representation of the entity in the past KG query. But entities in a KG also have non-vector attributes such as a song associated with an artist, a genre, and a release date. Therefore, suggested entities must also satisfy query predicates over non-vector attributes beyond a vector-based similarity predicate. While these tasks are central to KGs, our contributions are generally applicable to hybrid queries. In contrast to prior works that optimize online queries, we focus on enabling efficient batch processing of past hybrid query workloads. We present our system, HQI, for high-throughput batch processing of hybrid queries. We introduce a workload-aware vector data partitioning scheme to tailor the vector index layout to the given workload and describe a multi-query optimization technique to reduce the overhead of vector similarity computations. We evaluate our methods on industrial workloads and demonstrate that HQI yields a 31\u00d7 improvement in throughput for finding related KG queries compared to existing hybrid query processing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047146404",
                    "name": "J. Mohoney"
                },
                {
                    "authorId": "4047075",
                    "name": "Anil Pacaci"
                },
                {
                    "authorId": "2087061163",
                    "name": "S. R. Chowdhury"
                },
                {
                    "authorId": "143661472",
                    "name": "A. Mousavi"
                },
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "1856878",
                    "name": "U. F. Minhas"
                },
                {
                    "authorId": "32546616",
                    "name": "Jeffrey Pound"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "b6f229681cf0a3ba38884d281d89b2d498a853a8",
            "title": "Growing and Serving Large Open-domain Knowledge Graphs",
            "abstract": "Applications of large open-domain knowledge graphs (KGs) to real-world problems pose many unique challenges. In this paper, we present extensions to Saga our platform for continuous construction and serving of knowledge at scale. In particular, we describe a pipeline for training knowledge graph embeddings that powers key capabilities such as fact ranking, fact verification, a related entities service, and support for entity linking. We then describe how our platform, including graph embeddings, can be leveraged to create a Semantic Annotation service that links unstructured Web documents to entities in our KG. Semantic annotation of the Web effectively expands our knowledge graph with edges to open-domain Web content which can be used in various search and ranking problems. Finally, we leverage annotated Web documents to drive Open-domain Knowledge Extraction. This targeted extraction framework identifies important coverage issues in the KG, then finds relevant data sources for target entities on the Web and extracts missing information to enrich the KG. Finally, we describe adaptations to our knowledge platform needed to construct and serve private personal knowledge on-device. This includes private incremental KG construction, cross- device knowledge sync, and global knowledge enrichment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "2217340760",
                    "name": "JP Lacerda"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "1856878",
                    "name": "U. F. Minhas"
                },
                {
                    "authorId": "143661472",
                    "name": "A. Mousavi"
                },
                {
                    "authorId": "32546616",
                    "name": "Jeffrey Pound"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                },
                {
                    "authorId": "3308088",
                    "name": "C. Sumanth"
                }
            ]
        },
        {
            "paperId": "d278692e07e0d13f88e199f451723d37209b10e5",
            "title": "EnergAt: Fine-Grained Energy Attribution for Multi-Tenancy",
            "abstract": "In the post-Moore's Law era, relying solely on hardware advancements for automatic performance gains is no longer feasible without increased energy consumption, due to the end of Dennard scaling. Consequently, computing accounts for an increasing amount of global energy usage, contradicting the objective of sustainable computing. The lack of hardware support and the absence of a standardized, software-centric method for the precise tracing of energy provenance exacerbates the issue. Aiming to overcome this challenge, we argue that fine-grained software energy attribution is attainable, even with limited hardware support. To support our position, we present a thread-level, NUMA-aware energy attribution method for CPU and DRAM in multi-tenant environments. The evaluation of our prototype implementation, EnergAt, demonstrates the validity, effectiveness, and robustness of our theoretical model, even in the presence of the noisy-neighbor effect. We envisage a sustainable cloud environment and emphasize the importance of collective efforts to improve software energy efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145911458",
                    "name": "Hongyu H\u00e8"
                },
                {
                    "authorId": "145722011",
                    "name": "Michal Friedman"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "f7e14a3b43377dea6f7258b1933aaa8c9156c7fe",
            "title": "Simple Adaptive Query Processing vs. Learned Query Optimizers: Observations and Analysis",
            "abstract": "\n There have been many decades of work on optimizing query processing in database management systems. Recently, modern machine learning (ML), and specifically reinforcement learning (RL), has gained increased attention as a means to develop a query optimizer (QO). In this work, we take a closer look at two recent state-of-the-art (SOTA) RL-based QO methods to better understand their behavior. We find that these RL-based methods do not generalize as well as it seems at first glance. Thus, we ask a simple question:\n How do SOTA RL-based QOs compare to a simple, modern, adaptive query processing approach?\n To answer this question, we choose two simple adaptive query processing techniques and implemented them in PostgreSQL. The first adapts an individual join operation on-the-fly and switches between a Nested Loop Join algorithm and a Hash Join algorithm to avoid sub-optimal join algorithm decisions. The second is a technique called\n Lookahead Information Passing\n (LIP), in which adaptive semijoin techniques are used to make a pipeline of join operations execute efficiently. To our surprise, we find that this simple adaptive query processing approach is not only competitive to the SOTA RL-based approaches but, in some cases, outperforms the RL-based approaches. The adaptive approach is also appealing because it does not require an expensive training step, and it is fully interpretable compared to the RL-based QO approaches. Further, the adaptive method works across complex query constructs that RL-based QO methods currently cannot optimize.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145049376",
                    "name": "Yunjia Zhang"
                },
                {
                    "authorId": "3388236",
                    "name": "Yannis Chronis"
                },
                {
                    "authorId": "49111633",
                    "name": "J. Patel"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "0ab2ecf1748b62c9c00861e21248fb6d483a542a",
            "title": "Saga: A Platform for Continuous Construction and Serving of Knowledge at Scale",
            "abstract": "We introduce Saga, a next-generation knowledge construction and serving platform for powering knowledge-based applications at industrial scale. Saga follows a hybrid batch-incremental design to continuously integrate billions of facts about real-world entities and construct a central knowledge graph that supports multiple production use cases with diverse requirements around data freshness, accuracy, and availability. In this paper, we discuss the unique challenges associated with knowledge graph construction at industrial scale, and review the main components of Saga and how they address these challenges. Finally, we share lessons-learned from a wide array of production use cases powered by Saga.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                },
                {
                    "authorId": "40064471",
                    "name": "V. Konda"
                },
                {
                    "authorId": "32546616",
                    "name": "Jeffrey Pound"
                },
                {
                    "authorId": "2162773856",
                    "name": "Xiaoguang Qi"
                },
                {
                    "authorId": "144018773",
                    "name": "Mohamed A. Soliman"
                }
            ]
        },
        {
            "paperId": "36b7419166e470d65a84dad4ce4aa7857d7573fe",
            "title": "MariusGNN: Resource-Efficient Out-of-Core Training of Graph Neural Networks",
            "abstract": "We study training of Graph Neural Networks (GNNs) for large-scale graphs. We revisit the premise of using distributed training for billion-scale graphs and show that for graphs that fit in main memory or the SSD of a single machine, out-of-core pipelined training with a single GPU can outperform state-of-the-art (SoTA) multi-GPU solutions. We introduce MariusGNN, the first system that utilizes the entire storage hierarchy---including disk---for GNN training. MariusGNN introduces a series of data organization and algorithmic contributions that 1) minimize the end-to-end time required for training and 2) ensure that models learned with disk-based training exhibit accuracy similar to those fully trained in memory. We evaluate MariusGNN against SoTA systems for learning GNN models and find that single-GPU training in MariusGNN achieves the same level of accuracy up to 8\u00d7 faster than multi-GPU training in these systems, thus, introducing an order of magnitude monetary cost reduction. MariusGNN is open-sourced at www.marius-project.org.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103967638",
                    "name": "R. Waleffe"
                },
                {
                    "authorId": "2047146404",
                    "name": "J. Mohoney"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                },
                {
                    "authorId": "2697906",
                    "name": "S. Venkataraman"
                }
            ]
        },
        {
            "paperId": "983d2d7d71c5243737368702c02019709d601369",
            "title": "Machine Learning and Data Cleaning: Which Serves the Other?",
            "abstract": "The last few years witnessed significant advances in building automated or semi-automated data quality, data cleaning and data integration systems powered by machine learning (ML). In parallel, large deployment of ML systems in business, science, environment and various other areas started to realize the strong dependency on the quality of the input data to these ML models to get reliable predictions or insights. That dual relationship between ML and data cleaning has been addressed by many recent research works under terms such as \u201cData cleaning for ML\u201d and \u201cML for automating data cleaning and data preparation\u201d. In this article, we highlight this symbiotic relationship between ML and data cleaning and discuss few challenges that require collaborative efforts of multiple research communities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        }
    ]
}