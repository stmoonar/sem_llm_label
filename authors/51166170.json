{
    "authorId": "51166170",
    "papers": [
        {
            "paperId": "2023cc4dafd7ec46b7c7b7b95af455f27dbd1ce5",
            "title": "Item Recommendation Using User Feedback Data and Item Profile",
            "abstract": ". Matrix factorization (MS) is a collaborative filtering (CF) based approach, which is widely used for recommendation systems (RS). In this research work, we deal with the content recommendation problem for users in a content management system (CMS) based on users\u2019 feedback data. The CMS is applied for publishing and pushing curated content to the employees of a company or an organization. Here, we have used the users\u2019 feedback data and content data to solve the content recommendation problem. We prepare individual user-profiles and then generate recommendation results based on different categories, including Direct Interaction, Social Share and Reading Statistics, of user\u2019s feedback data. Subsequently, we analyze the effect of the different categories on the recommendation results. The results have shown that different categories of feedback data have different impacts on recommendation accuracy. The best performance achieves if we include all types of data for the recommendation task. We also incorporate content similarity as a regularization term into an MF model for designing a hybrid model. Experimental results have shown that the proposed hybrid model demonstrates better performance compared with the traditional MF-based models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115059044",
                    "name": "Debashish Roy"
                },
                {
                    "authorId": "69938484",
                    "name": "R. Chowdhury"
                },
                {
                    "authorId": "3411002",
                    "name": "Abdullah B. Nasser"
                },
                {
                    "authorId": "100792991",
                    "name": "Afdhal Azmi"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                }
            ]
        },
        {
            "paperId": "2d3ca953e2efb2e6b09d851e1649681ac549ae89",
            "title": "Partisan US News Media Representations of Syrian Refugees",
            "abstract": "We investigate how representations of Syrian refugees (2011-2021) differ across US partisan news outlets. We analyze 47,388 articles from the online US media about Syrian refugees to detail differences in reporting between left- and right-leaning media. We use various NLP techniques to understand these differences. Our polarization and question answering results indicated that left-leaning media tended to represent refugees as child victims, welcome in the US, and right-leaning media cast refugees as Islamic terrorists. We noted similar results with our sentiment and offensive speech scores over time, which detail possibly unfavorable representations of refugees in right-leaning media. A strength of our work is how the different techniques we have applied validate each other. Based on our results, we provide several recommendations. Stakeholders may utilize our findings to intervene around refugee representations, and design communications campaigns that improve the way society sees refugees and possibly aid refugee outcomes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152955806",
                    "name": "Keyu Chen"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "2170852517",
                    "name": "Yiwen Shi"
                },
                {
                    "authorId": "1645061254",
                    "name": "Kamila Janmohamed"
                },
                {
                    "authorId": "2056781644",
                    "name": "Rupak Sarkar"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "2054378953",
                    "name": "Thomas Davidson"
                },
                {
                    "authorId": "2583473",
                    "name": "M. Choudhury"
                },
                {
                    "authorId": "2171736559",
                    "name": "Jonathan Y Huang"
                },
                {
                    "authorId": "46782621",
                    "name": "S. Yadav"
                },
                {
                    "authorId": "2170539086",
                    "name": "Ashique Khudabukhsh"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2736592",
                    "name": "C. Bauch"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "50417026",
                    "name": "K. Khoshnood"
                },
                {
                    "authorId": "50325647",
                    "name": "Navin Kumar"
                }
            ]
        },
        {
            "paperId": "61d66f019232723bb7901a0cd5775ed5f73d3693",
            "title": "How is Vaping Framed on Online Knowledge Dissemination Platforms?",
            "abstract": "We analyze 1,888 articles and 1,119,453 vaping posts to study how vaping is framed across multiple knowledge dissemination platforms (Wikipedia, Quora, Medium, Reddit, Stack Exchange, wikiHow). We use various NLP techniques to understand these differences. For example, n-grams, emotion recognition, and question answering results indicate that Medium, Quora, and Stack Exchange are appropriate venues for those looking to transition from smoking to vaping. Other platforms (Reddit, wikiHow) are more for vaping hobbyists and may not sufficiently dissuade youth vaping. Conversely, Wikipedia may exaggerate vaping harms, dissuading smokers from transitioning. A strength of our work is how the different techniques we have applied validate each other. Based on our results, we provide several recommendations. Stakeholders may utilize our findings to design informational tools to reinforce or mitigate vaping (mis)perceptions online.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152955806",
                    "name": "Keyu Chen"
                },
                {
                    "authorId": "2170852517",
                    "name": "Yiwen Shi"
                },
                {
                    "authorId": "2172063859",
                    "name": "Jun Luo"
                },
                {
                    "authorId": "144159599",
                    "name": "Joyce Jiang"
                },
                {
                    "authorId": "46782621",
                    "name": "S. Yadav"
                },
                {
                    "authorId": "2583473",
                    "name": "M. Choudhury"
                },
                {
                    "authorId": "2856003",
                    "name": "Ashiqur R. KhudaBukhsh"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "145635300",
                    "name": "F. Altice"
                },
                {
                    "authorId": "50325647",
                    "name": "Navin Kumar"
                }
            ]
        },
        {
            "paperId": "7781169bac759836365c719279af46607a0b5989",
            "title": "US News and Social Media Framing around Vaping",
            "abstract": "In this paper, we investigate how vaping is framed differently (2008-2021) between US news and social media. We analyze 15,711 news articles and 1,231,379 Facebook posts about vaping to study the differences in framing between media varieties. We use word embeddings to provide two-dimensional visualizations of the semantic changes around vaping for news and for social media. We detail that news media framing of vaping shifted over time in line with emergent regulatory trends, such as; flavored vaping bans, with little discussion around vaping as a smoking cessation tool. We found that social media discussions were far more varied, with transitions toward vaping both as a public health harm and as a smoking cessation tool. Our cloze test, dynamic topic model, and question answering showed similar patterns, where social media, but not news media, characterizes vaping as combustible cigarette substitute. We use n-grams to detail that social media data first centered on vaping as a smoking cessation tool, and in 2019 moved toward narratives around vaping regulation, similar to news media frames. Overall, social media tracks the evolution of vaping as a social practice, while news media reflects more risk based concerns. A strength of our work is how the different techniques we have applied validate each other. Stakeholders may utilize our findings to intervene around the framing of vaping, and may design communications campaigns that improve the way society sees vaping, thus possibly aiding smoking cessation; and reducing youth vaping.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152955806",
                    "name": "Keyu Chen"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "2170852517",
                    "name": "Yiwen Shi"
                },
                {
                    "authorId": "2122753736",
                    "name": "R. Aanegola"
                },
                {
                    "authorId": "2170538811",
                    "name": "Lam Yin Cheung"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "46782621",
                    "name": "S. Yadav"
                },
                {
                    "authorId": "33891668",
                    "name": "A. Bancroft"
                },
                {
                    "authorId": "2170539086",
                    "name": "Ashique Khudabukhsh"
                },
                {
                    "authorId": "2583473",
                    "name": "M. Choudhury"
                },
                {
                    "authorId": "145635300",
                    "name": "F. Altice"
                },
                {
                    "authorId": "50325647",
                    "name": "Navin Kumar"
                }
            ]
        },
        {
            "paperId": "1635e0e963111b0dface5843b68d94419b152c12",
            "title": "Studying Political Bias via Word Embeddings",
            "abstract": "Machine Learning systems learn bias in addition to other patterns from input data on which they are trained. Bolukbasi et al. pioneered a method for quantifying gender bias learned from a corpus of text. Specifically, they compute a gender subspace into which words, represented as word vectors, can be placed and compared with one another. In this paper, we apply a similar methodology to a different type of bias, political bias. Unlike with gender bias, it is not obvious how to choose a set of definitional word pairs to compute a political bias subspace. We propose a methodology for doing so that could be used for modeling other types of bias as well. We collect and examine a 26 GB corpus of tweets from Republican and Democratic politicians in the United States (presidential candidates and members of Congress). With our definition of a political bias subspace, we observe several interesting and intuitive trends including that tweets from presidential candidates, both Republican and Democratic, show more political bias than tweets from other politicians of the same party. This work models political bias as a binary choice along one axis, as Bolukbasi et al. did for gender. However, most kinds of bias - political, racial and even gender bias itself - are much more complicated than two binary extremes along one axis. In this paper, we also discuss what might be required to model bias along multiple axes (e.g. liberal/conservative and authoritarian/libertarian for political bias) or as a range of points along a single axis (e.g. a gender spectrum).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070864094",
                    "name": "Joshua Gordon"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "34756128",
                    "name": "Jeanna Neefe Matthews"
                }
            ]
        },
        {
            "paperId": "1d29e42bda72365f4eea9522f769d9aa83281d32",
            "title": "Quantifying Gender Bias in Different Corpora",
            "abstract": "Word embedding models have been shown to be effective in performing a wide variety of Natural Language Processing (NLP) tasks such as identifying audiences for web advertisements, parsing resum\u00e9s to select promising job candidates, and translating documents from one language to another. However, it has been demonstrated that NLP systems learn gender bias from the corpora of documents on which they are trained. It is increasingly common for pre-trained models to be used as a starting point for building applications in a wide range of areas including critical decision making applications. It is also very easy to use a pre-trained model as the basis for a new application without careful consideration of the original nature of the training set. In this paper, we quantify the degree to which gender bias differs with the corpora used for training. We look especially at the impact of starting with a pre-trained model and fine-tuning with additional data. Specifically, we calculate a measure of direct gender bias on several pre-trained models including BERT\u2019s Wikipedia and Book corpus models as well as on several fine-tuned General Language Understanding Evaluation (GLUE) benchmarks. In addition, we evaluate the bias from several more extreme corpora including the Jigsaw identity toxic dataset that includes toxic speech biased against race, gender, religion, and disability and the RtGender dataset that includes speech specifically labelled by gender. Our results reveal that the direct gender bias of the Jigsaw toxic identity dataset is surprisingly close to that of the base pre-trained Google model, but the RtGender dataset has significantly higher direct gender bias than the base model. When the bias learned by an NLP system can vary significantly with the corpora used for training, it becomes important to consider and report these details, especially for use in critical decision-making applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "2052293851",
                    "name": "Stephen Lorenz"
                },
                {
                    "authorId": "2070864094",
                    "name": "Joshua Gordon"
                },
                {
                    "authorId": "34756128",
                    "name": "Jeanna Neefe Matthews"
                },
                {
                    "authorId": "2064199373",
                    "name": "Evan Freitag"
                }
            ]
        },
        {
            "paperId": "4a5aaf79a52a6988a3c29fef8fc50691dc2d61da",
            "title": "Is Machine Learning Speaking my Language? A Critical Look at the NLP-Pipeline Across 8 Human Languages",
            "abstract": "Natural Language Processing (NLP) is increasingly used as a key ingredient in critical decision-making systems such as resume parsers used in sorting a list of job candidates. NLP systems often ingest large corpora of human text, attempting to learn from past human behavior and decisions in order to produce systems that will make recommendations about our future world. Over 7000 human languages are being spoken today and the typical NLP pipeline underrepresents speakers of most of them while amplifying the voices of speakers of other languages. In this paper, a team including speakers of 8 languages - English, Chinese, Urdu, Farsi, Arabic, French, Spanish, and Wolof - takes a critical look at the typical NLP pipeline and how even when a language is technically supported, substantial caveats remain to prevent full participation. Despite huge and admirable investments in multilingual support in many tools and resources, we are still making NLP-guided decisions that systematically and dramatically underrepresent the voices of much of the world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1811110925",
                    "name": "Esma Wali"
                },
                {
                    "authorId": "2155492559",
                    "name": "Yan Chen"
                },
                {
                    "authorId": "2057590117",
                    "name": "Christopher Mahoney"
                },
                {
                    "authorId": "2066570175",
                    "name": "Thomas Middleton"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "96015707",
                    "name": "Mariama Njie"
                },
                {
                    "authorId": "34756128",
                    "name": "Jeanna Neefe Matthews"
                }
            ]
        },
        {
            "paperId": "c1fcd2f51127b5f568de4c384ead42e02415283b",
            "title": "When Trusted Black Boxes Don't Agree: Incentivizing Iterative Improvement and Accountability in Critical Software Systems",
            "abstract": "Software increasingly plays a key role in regulated areas like housing, hiring, and credit, as well as major public functions such as criminal justice and elections. It is easy for there to be unintended defects with a large impact on the lives of individuals and society as a whole. Preventing, finding, and fixing software defects is a key focus of both industrial software development efforts as well as academic research in software engineering. In this paper, we discuss flaws in the larger socio-technical decision-making processes in which critical black-box software systems are developed, deployed, and trusted. We use criminal justice software, specifically probabilistic genotyping (PG) software, as a concrete example. We describe how PG software systems, designed to do the same job, produce different results. We highlight the under-appreciated impact of changes in key parameters and the disparate impact that one such parameter can have on different racial/ethnic groups. We propose concrete changes to the socio-technical decision-making processes surrounding the use of PG software that could be used to incentivize iterative improvements in the accuracy, fairness, reliability, and accountability of these systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34756128",
                    "name": "Jeanna Neefe Matthews"
                },
                {
                    "authorId": "1491521519",
                    "name": "G. Northup"
                },
                {
                    "authorId": "1491521785",
                    "name": "Isabella Grasso"
                },
                {
                    "authorId": "2052293851",
                    "name": "Stephen Lorenz"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "1491522208",
                    "name": "Hunter Bashaw"
                },
                {
                    "authorId": "3135009",
                    "name": "Sumona Mondal"
                },
                {
                    "authorId": "121721438",
                    "name": "Abigail V. Matthews"
                },
                {
                    "authorId": "96015707",
                    "name": "Mariama Njie"
                },
                {
                    "authorId": "151049572",
                    "name": "Jessica Goldthwaite"
                }
            ]
        },
        {
            "paperId": "1577bf434b6c6ad3994a54ffd5ac2b226161daf8",
            "title": "The Right To Confront Your Accusers: Opening the Black Box of Forensic DNA Software",
            "abstract": "The results of forensic DNA software systems are regularly introduced as compelling evidence in criminal trials, but requests by defendants to evaluate how these results are generated are often denied. Furthermore, there is mounting evidence of problems such as failures to disclose substantial changes in methodology to oversight bodies and substantial differences in the results generated by different software systems. In a society that purports to guarantee defendants the right to face their accusers and confront the evidence against them, what then is the role of black-box forensic software systems in moral decision making in criminal justice? In this paper, we examine the case of the Forensic Statistical Tool (FST), a forensic DNA system developed in 2010 by New York City's Office of Chief Medical Examiner (OCME). For over 5 years, expert witness review requested by defense teams was denied, even under protective order, while the system was used in over 1300 criminal cases. When the first expert review was finally permitted in 2016, many problems were identified including an undisclosed function capable of dropping evidence that could be beneficial to the defense. Overall, the findings were so substantial that a motion to release the full source code of FST publicly was granted. In this paper, we quantify the impact of this undisclosed function on samples from OCME's own validation study and discuss the potential impact on individual defendants. Specifically, we find that 104 of the 439 samples (23.7%) triggered the undisclosed data-dropping behavior and that the change skewed results toward false inclusion for individuals whose DNA was not present in an evidence sample. Beyond this, we consider what changes in the criminal justice system could prevent problems like this from going unresolved in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34756128",
                    "name": "Jeanna Neefe Matthews"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "2052293851",
                    "name": "Stephen Lorenz"
                },
                {
                    "authorId": "121721438",
                    "name": "Abigail V. Matthews"
                },
                {
                    "authorId": "96015707",
                    "name": "Mariama Njie"
                },
                {
                    "authorId": "2055551012",
                    "name": "Nathaniel Adams"
                },
                {
                    "authorId": "3315398",
                    "name": "D. Krane"
                },
                {
                    "authorId": "151049572",
                    "name": "Jessica Goldthwaite"
                },
                {
                    "authorId": "100477251",
                    "name": "Clinton Hughes"
                }
            ]
        },
        {
            "paperId": "d0eba574dbde8de3a412111e6f628589f07c15db",
            "title": "Performance Evaluation of NDN Applications in Low-Interference Mobile Ad Hoc Environments",
            "abstract": "A mobile ad hoc network (MANET) is an infrastructure-free network where mobile devices are connected wirelessly and can move in arbitrary directions. Mobile ad hoc networks can be utilized in many applications, ranging from sensor networks, autonomous vehicles, battlefield communication, to disaster rescue operations, etc. However, existing TCP/IP based Internet architecture that supports MANET has many limitations, such as dependency on end-to-end IP address-based communication and out-of-band security mechanisms, to enable it to work in an efficient and secured manner. The emerging Named Data Networking (NDN) architecture can help address many such problems fundamentally. NDN is a new information centric network architecture that features name-based data, in-network caching, and built-in security. To test and verify the features of this new paradigm, in this paper, we set up several real and low-interference mobile ad hoc environments using Raspberry Pi-based mini cars and built NDN applications on top of the infrastructure. We examined the performance of the NDN applications with various network settings in both static and mobile modes and demonstrated the effectiveness of NDN architecture in terms of in-network caching and information centric features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144468697",
                    "name": "Anthony Dowling"
                },
                {
                    "authorId": "51166170",
                    "name": "M. Babaeianjelodar"
                },
                {
                    "authorId": "47910176",
                    "name": "Yaoqing Liu"
                },
                {
                    "authorId": "3240144",
                    "name": "Kang-Peng Chen"
                }
            ]
        }
    ]
}