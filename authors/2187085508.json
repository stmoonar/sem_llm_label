{
    "authorId": "2187085508",
    "papers": [
        {
            "paperId": "f282fa85469cc789c2f3b62e57e3446a49528afa",
            "title": "Hybrid Attention Network for Epileptic EEG Classification",
            "abstract": "Automatic seizure detection from electroencephalography (EEG) based on deep learning has been significantly improved. However, existing works have not adequately excavate the spatial-temporal information between EEG channels. Besides, most works mainly focus on patient-specific scenarios while cross-patient seizure detection is more challenging and meaningful. Regarding the above problems, we propose a hybrid attention network (HAN) for automatic seizure detection. Specifically, the graph attention network (GAT) extracts spatial features at the front end, and Transformer gets time features as the back end. HAN leverages the attention mechanism and fully extracts the spatial-temporal correlation of EEG signals. The focal loss function is introduced to HAN to deal with the imbalance of the dataset accompanied by seizure detection based on EEG. Both patient-specific and patient-independent experiments are carried out on the public CHB-MIT database. Experimental results demonstrate the efficacy of HAN in both experimental settings.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "2153102948",
                    "name": "Jiatong He"
                },
                {
                    "authorId": "2171218625",
                    "name": "Fenglin Zhu"
                },
                {
                    "authorId": "2174196178",
                    "name": "Tiantian Xiao"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2243360852",
                    "name": "Ziwei Wang"
                },
                {
                    "authorId": "2534225",
                    "name": "Fangzhou Xu"
                },
                {
                    "authorId": "2056579945",
                    "name": "Yi Niu"
                }
            ]
        },
        {
            "paperId": "12487aca90a94ea7ade0f6162899cba3a7bee524",
            "title": "Automatic Seizure Identification from EEG Signals Based on Brain Connectivity Learning",
            "abstract": "Epilepsy is a neurological disorder caused by brain dysfunction, which could cause uncontrolled behavior, loss of consciousness and other hazards. Electroencephalography (EEG) is an indispensable auxiliary tool for clinical diagnosis. Great progress has been made by current seizure identification methods. However, the performance of the methods on different patients varies a lot. In order to deal with this problem, we propose an automatic seizure identification method based on brain connectivity learning. The connectivity of different brain regions is modeled by a graph. Different from the manually defined graph structure, our method can extract the optimal graph structure and EEG features in an end-to-end manner. Combined with the popular graph attention neural network (GAT), this method achieves high performance and stability on different patients from the CHB-MIT dataset. The average values of accuracy, sensitivity, specificity, F1-score and AUC of the proposed model are 98.90[Formula: see text], 98.33[Formula: see text], 98.48[Formula: see text], 97.72% and 98.54%, respectively. The standard deviations of the above five indicators are 0.0049, 0.0125, 0.0116 and 0.0094, respectively. Compared with the existing seizure identification methods, the stability of the proposed model is improved by 78-95%.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "9718228",
                    "name": "Mingrui Xue"
                },
                {
                    "authorId": "2094059110",
                    "name": "Changxu Dong"
                },
                {
                    "authorId": "2153102948",
                    "name": "Jiatong He"
                },
                {
                    "authorId": "2147383425",
                    "name": "Dengyu Chu"
                },
                {
                    "authorId": "2118526355",
                    "name": "Gaobo Zhang"
                },
                {
                    "authorId": "2534225",
                    "name": "Fangzhou Xu"
                },
                {
                    "authorId": "2078523007",
                    "name": "Xinting Ge"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                }
            ]
        },
        {
            "paperId": "76603da46e5da7ef3c37c57ed5b8319f00d7b2e4",
            "title": "Deep Learning for Logo Detection: A Survey",
            "abstract": "Logo detection has gradually become a research hotspot in the field of computer vision and multimedia for its various applications, such as social media monitoring, intelligent transportation, and video advertising recommendation. Recent advances in this area are dominated by deep learning-based solutions, where many datasets, learning strategies, network architectures, and loss functions have been employed. This article reviews the advance in applying deep learning techniques to logo detection. First, we discuss a comprehensive account of public datasets designed to facilitate performance evaluation of logo detection algorithms, which tend to be more diverse, more challenging, and more reflective of real life. Next, we perform an in-depth analysis of the existing logo detection strategies and their strengths and weaknesses of each learning strategy. Subsequently, we summarize the applications of logo detection in various fields, from intelligent transportation and brand monitoring to copyright and trademark compliance. Finally, we analyze the potential challenges and present the future directions for the development of logo detection. This study aims better to inform readers about the current state of logo detection and encourage more researchers to get involved in logo detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1801481",
                    "name": "Sujuan Hou"
                },
                {
                    "authorId": "2144485931",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2366119",
                    "name": "Weiqing Min"
                },
                {
                    "authorId": "2061437098",
                    "name": "Qiang Hou"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "1696610",
                    "name": "Shuqiang Jiang"
                }
            ]
        },
        {
            "paperId": "fda49dbfc3f293ac0f9add316c6577155325c610",
            "title": "Deep Convolution Generative Adversarial Network-Based Electroencephalogram Data Augmentation for Post-Stroke Rehabilitation with Motor Imagery",
            "abstract": "The motor imagery brain-computer interface (MI-BCI) system is currently one of the most advanced rehabilitation technologies, and it can be used to restore the motor function of stroke patients. The deep learning algorithms in the MI-BCI system require lots of training samples, but the electroencephalogram (EEG) data of stroke patients is quite scarce. Therefore, the expansion of EEG data has become an important part of stroke clinical rehabilitation research. In this paper, a deep convolution generative adversarial network (DCGAN) model is proposed to generate artificial EEG data and further expand the scale of the stroke dataset. First, multichannel one-dimensional EEG data is converted into a two-dimensional EEG spectrogram using EEG2Image based on the modified S-transform. Then, DCGAN is used to artificially generate EEG data based on MI. Finally, the validity of the generated artificial EEG data is proved. This paper preliminarily indicates that generating artificial stroke data is a promising strategy, which contributes to the further development of stroke clinical rehabilitation.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2534225",
                    "name": "Fangzhou Xu"
                },
                {
                    "authorId": "2090489012",
                    "name": "Gege Dong"
                },
                {
                    "authorId": "2155309489",
                    "name": "Jincheng Li"
                },
                {
                    "authorId": "2158478272",
                    "name": "Qingbo Yang"
                },
                {
                    "authorId": "2152507853",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "148417672",
                    "name": "Yihao Yan"
                },
                {
                    "authorId": "2171112627",
                    "name": "Jinzhao Zhao"
                },
                {
                    "authorId": "93142538",
                    "name": "Shaopeng Pang"
                },
                {
                    "authorId": "2149263574",
                    "name": "Dongju Guo"
                },
                {
                    "authorId": "2145954350",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "1814313",
                    "name": "Jiancai Leng"
                }
            ]
        },
        {
            "paperId": "29b33152c1ae8940ecfcbd1ec8efa1dd8444f9fa",
            "title": "Graph Attention Network with Focal Loss for Seizure Detection on Electroencephalography Signals",
            "abstract": "Automatic seizure detection from electroencephalogram (EEG) plays a vital role in accelerating epilepsy diagnosis. Previous researches on seizure detection mainly focused on extracting time-domain and frequency-domain features from single electrodes, while paying little attention to the positional correlations between different EEG channels of the same subject. Moreover, data imbalance is common in seizure detection scenarios where the duration of nonseizure periods is much longer than the duration of seizures. To cope with the two challenges, a novel seizure detection method based on graph attention network (GAT) is presented. The approach acts on graph-structured data and takes the raw EEG data as input. The positional relationship between different EEG signals is exploited by GAT. The loss function of the GAT model is redefined using the focal loss to tackle data imbalance problem. Experiments are conducted on the CHB-MIT dataset. The accuracy, sensitivity and specificity of the proposed method are 98.89[Formula: see text], 97.10[Formula: see text] and 99.63[Formula: see text], respectively.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "2118526355",
                    "name": "Gaobo Zhang"
                },
                {
                    "authorId": "2094059110",
                    "name": "Changxu Dong"
                },
                {
                    "authorId": "145964230",
                    "name": "Qi Yuan"
                },
                {
                    "authorId": "2534225",
                    "name": "Fangzhou Xu"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                }
            ]
        },
        {
            "paperId": "a4d794bbf4fe4cadb207597363023dbe288e0cee",
            "title": "Attention-based Graph ResNet with focal loss for epileptic seizure detection",
            "abstract": "Epilepsy is a chronic brain disease resulted from the central nervous system lesion, which leads to repeated seizure occurs for the patients. Automatic seizure detection with Electroencephalogram (EEG) has witnessed great progress. However, existing methods paid little attention to the topological relationships of different EEG electrodes. Latest neuroscience researches have demonstrated the connectivity between different brain regions. Besides, class-imbalance is a common problem in EEG based seizure detection. The duration of epileptic EEG signals is much shorter than that of normal signals. In order to deal with the above mentioned two challenges, we propose to model the multi-channel EEG data using the Attention-based Graph ResNet (AGRN). In particular, each channel of the EEG signal represents a node of the graph and the inter-channel relations are modeled via the adjacency matrix in the graph. The loss function of the ARGN model is re-designed using focal loss to cope with the class-imbalance problem. The proposed ARGN with focal model could learn discriminative features from the raw EEG data. Experiments are carried out on the CHB-MIT dataset. The proposed model achieves an average accuracy of 98.70%, a sensitivity of 97.94%, a specificity of 98.66% and a precision of 98.62%. The Area Under the ROC Curve (AUC) is 98.69%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2094059110",
                    "name": "Changxu Dong"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "2118526355",
                    "name": "Gaobo Zhang"
                },
                {
                    "authorId": "9718228",
                    "name": "Mingrui Xue"
                },
                {
                    "authorId": "2147383425",
                    "name": "Dengyu Chu"
                },
                {
                    "authorId": "2153102948",
                    "name": "Jiatong He"
                },
                {
                    "authorId": "2078523007",
                    "name": "Xinting Ge"
                }
            ]
        },
        {
            "paperId": "37ab6f44db0d5a68073c55b08483e5de4a8eb149",
            "title": "Face Identification With Top-Push Constrained Generalized Low-Rank Approximation of Matrices",
            "abstract": "We present a novel top-push constrained feature learning (TFL) method for face identification. The idea is to learn low-rank approximations from raw intensity face images such that the squared distance between all faces of the same identity should be smaller than that of different identities by a margin. To this end, we formulate the learning process under the framework of generalized low-rank approximation of matrices (GLRAM) supervised with a top-push constraint. GLRAM operates on the matrix representation of images to seek low-dimensional and compact features, which improves the discriminative power of the features while reducing the time and space costs. The top-push constraint aims to optimize the face identification accuracy of the top-rank matching list, which makes the learned features more discriminative and compact, thus reducing the variability and ambiguity. Once the optimization is finished, the features are vectorized and used for similarity measurement. The effectiveness of TFL is verified on four publicly available face datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1519075513",
                    "name": "Yuanjian Chen"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "2119287708",
                    "name": "Yunlong He"
                },
                {
                    "authorId": "2534225",
                    "name": "Fangzhou Xu"
                },
                {
                    "authorId": "1783497",
                    "name": "Weikuan Jia"
                },
                {
                    "authorId": "144563421",
                    "name": "Jian Lian"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                }
            ]
        },
        {
            "paperId": "84fe95ae2b0befd2e551ee672a1580220d64686f",
            "title": "Drusen Segmentation From Retinal Images via Supervised Feature Learning",
            "abstract": "This paper presents a supervised feature learning method to learn discriminative and compact descriptors for drusen segmentation from retinal images. This method combines generalized low rank approximation of matrices with supervised manifold regularization to learn new features from image patches sampled from retinal images. The learned features are closely related to drusen and potentially free from information that is redundant in distinguishing drusen from background. The learned feature representations are then vectorized and used to train a support vector machine (SVM) classifier. Finally, the obtained SVM classifier is employed to classify the pixels in the test images as drusen or non-drusen. The performance of the proposed method is validated on the STARE and DRIVE databases, where it achieves an average sensitivity/specificity/accuracy of 90.03%/97.06%/96.92% and of 87.41%/94.93%/94.81%, respectively. We also experimentally compare the proposed method with the several representative state-of-the-art drusen segmentation techniques and find that it generates superior accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153457261",
                    "name": "Xiuxiu Ren"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "2112751183",
                    "name": "Chao Luo"
                },
                {
                    "authorId": "2144273396",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "144563421",
                    "name": "Jian Lian"
                },
                {
                    "authorId": "2119287708",
                    "name": "Yunlong He"
                }
            ]
        },
        {
            "paperId": "bd649ce25ce90058ff288433701cdc624b3624b7",
            "title": "Retinal Image Denoising via Bilateral Filter with a Spatial Kernel of Optimally Oriented Line Spread Function",
            "abstract": "Filtering belongs to the most fundamental operations of retinal image processing and for which the value of the filtered image at a given location is a function of the values in a local window centered at this location. However, preserving thin retinal vessels during the filtering process is challenging due to vessels' small area and weak contrast compared to background, caused by the limited resolution of imaging and less blood flow in the vessel. In this paper, we present a novel retinal image denoising approach which is able to preserve the details of retinal vessels while effectively eliminating image noise. Specifically, our approach is carried out by determining an optimal spatial kernel for the bilateral filter, which is represented by a line spread function with an orientation and scale adjusted adaptively to the local vessel structure. Moreover, this approach can also be served as a preprocessing tool for improving the accuracy of the vessel detection technique. Experimental results show the superiority of our approach over state-of-the-art image denoising techniques such as the bilateral filter.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2119287708",
                    "name": "Yunlong He"
                },
                {
                    "authorId": "1746086",
                    "name": "Yuanjie Zheng"
                },
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "46300670",
                    "name": "Yanju Ren"
                },
                {
                    "authorId": "144563421",
                    "name": "Jian Lian"
                },
                {
                    "authorId": "144716639",
                    "name": "J. Gee"
                }
            ]
        },
        {
            "paperId": "1c0489e0126fdb21ff8a4e0dae43ed16eb653371",
            "title": "Multiple-Shot Person Re-identification by Features Learned from Third-party Image Sets",
            "abstract": "Person re-identification is an important and challenging task in computer vision with numerous real world applications. Despite significant progress has been made in the past few years, person re-identification remains an unsolved problem. This paper presents a novel appearance-based approach to person re-identification. The approach exploits region covariance matrix and color histograms to capture the statistical properties and chromatic information of each object. Robustness against low resolution, viewpoint changes and pose variations is achieved by a novel signature, that is, the combination of Log Covariance Matrix feature and HSV histogram (LCMH). In order to further improve re-identification performance, third-party image sets are utilized as a common reference to sufficiently represent any image set with the same type. Distinctive and reliable features for a given image set are extracted through decision boundary between the specific set and a third-party image set supervised by max-margin criteria. This method enables the usage of an existing dataset to represent new image data without time-consuming data collection and annotation. Comparisons with state-of-the-art methods carried out on benchmark datasets demonstrate promising performance of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187085508",
                    "name": "Yanna Zhao"
                },
                {
                    "authorId": "1819473829",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "1390869207",
                    "name": "Xu Zhao"
                },
                {
                    "authorId": "2117416965",
                    "name": "Yuncai Liu"
                }
            ]
        }
    ]
}