{
    "authorId": "70053552",
    "papers": [
        {
            "paperId": "27b9f7b653b79b65d78db0ceb1688a270316331a",
            "title": "Depicting Vocabulary Summaries with Devos",
            "abstract": "Communicating ontologies to potential users is still a difficult and time-consuming task. Even for small ones, users need to invest time to determine whether to reuse them. Providing diagrams together with the ontologies facilitates the task of understanding the model from a user perspective. While some tools are available for depicting ontologies, and the code could also be inspected using ontology editors\u2019 graphical interfaces, in many cases, the diagrams are too big or complex. The main objective of this demo is to present Devos, a system to generate ontology diagrams based on different strategies for summarizing the ontology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2691947",
                    "name": "Ahmad Alobaid"
                },
                {
                    "authorId": "2056266963",
                    "name": "Jhon Toledo"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "1403446235",
                    "name": "M. Poveda-Villal\u00f3n"
                }
            ]
        },
        {
            "paperId": "5845fed63bf8c04f2fc6abc1c416c12c99f7e763",
            "title": "Interoperability of Heterogeneous Systems of Systems: Review of Challenges, Emerging Requirements and Options",
            "abstract": "Interoperability is one of the critical challenges in the construction and management of distributed and collaborative systems. Hence, a deep understanding of the fundamental barriers to interoperability and of the key requirements that systems must meet to be interoperable is essential. In this direction, in the first part of this research, we conducted a questionnaire survey of stakeholders and practitioners of distributed and collaborative systems. As a result, we identified eight essential interoperability requirements and corresponding challenges. Then, in the second part of our study, we performed a critical literature survey of the building blocks of interoperability to understand the ability of current conceptual approaches---and related technologies---to address the identified requirements. The results of our research can significantly impact the software engineering of interoperable systems by introducing their fundamental requirements and the best practices to address them.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51486610",
                    "name": "Mersedeh Sadeghi"
                },
                {
                    "authorId": "36152762",
                    "name": "A. Carenini"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "1585607534",
                    "name": "Matteo G. Rossi"
                },
                {
                    "authorId": "2071032397",
                    "name": "R. Santoro"
                },
                {
                    "authorId": "1859607",
                    "name": "Andreas Vogelsang"
                }
            ]
        },
        {
            "paperId": "ae1c342af395175e6bb7d51541a0c2f90f158134",
            "title": "Boosting Knowledge Graph Generation from Tabular Data with RML Views",
            "abstract": ". A large amount of data is available in tabular form. RML is commonly used to declare how such data can be transformed into RDF. However, RML presents limitations that lead, in many cases, to the need for additional preprocessing using scripting. Although some proposed extensions (e.g., FnO or RML fields) address some of these limitations, they are verbose, unfamiliar to most data engineers, and implemented in systems that do not scale up when large volumes of data need to be processed. In this work, we expand RML views to tabular sources so as to address the limitations of this mapping language. In this way, transformation functions, complex joins, or mixed syntax can be defined directly in SQL queries. We present our extension of Morph-KGC to efficiently support RML views for tabular sources. We validate our implementation adapting R2RML test cases with views and compare it against state-of-the-art RML+FnO systems showing that our system is significantly more scalable. Moreover, we present specific examples of a real use case in the public procurement domain where basic RML mappings could not be used without additional preprocessing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107052011",
                    "name": "Juli\u00e1n Arenas-Guerrero"
                },
                {
                    "authorId": "2691947",
                    "name": "Ahmad Alobaid"
                },
                {
                    "authorId": "1404303309",
                    "name": "Mar\u00eda Navas-Loro"
                },
                {
                    "authorId": "145002690",
                    "name": "Mar\u00eda S. P\u00e9rez"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "fb264b14f2c2df8229358d58f98bacb82a9813b8",
            "title": "FAIR Research Object Assessment: A landscape analysis",
            "abstract": ". Research Objects (ROs) are becoming a popular means to capture the context and research artefacts associated with a research investigation in both human-readable and machine-readable formats. However, it is unclear how well ROs themselves adhere to the FAIR (find-able, accessible, interoperable, and reusable) principles. In this work, we describe a comprehensive analysis of the FAIR assessment of more than 2500 ROs across multiple disciplines. Our work integrates FAIROs, our existing RO evaluation service, in the ROHub platform. We discuss the challenges of calculating the FAIR assessment of aggregations of resources, and how we supplement the FAIROs tests with information from the RO-Crate descriptor file generated by ROHub.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112433218",
                    "name": "E. Gonz\u00e1lez"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "144027454",
                    "name": "Ra\u00fal Palma"
                },
                {
                    "authorId": "1767371",
                    "name": "Malgorzata Wolniewicz"
                },
                {
                    "authorId": "2221055775",
                    "name": "Aron Rynkiewicz"
                }
            ]
        },
        {
            "paperId": "030f55f134e911c5ee331888ae8875b2f9263136",
            "title": "Devising Mapping Interoperability With Mapping Translation",
            "abstract": "Nowadays, KnowledgeGraphs are extensively created using very different techniques, mapping languages among them. The wide variety of use cases, data peculiarities, and potential uses has had a substantial impact in how these languages have been created, extended, and applied. This situation is closely related to the global adoption of these languages and their associated tools. The large number of languages, compliant tools, and usually the lack of information of the combination of both leads users to use other techniques to construct Knowledge Graphs. Often, users choose to create their own ad hoc programming scripts that suit their needs. This choice is normally less reproducible and maintainable, what ultimately affects the quality of the generated RDF data, particularly in long-term scenarios. We devise with mapping translation an enhancement to the interoperability of existing mapping languages. This position paper analyses the possible language translation approaches, presents the scenarios in which it is being applied and discusses how it can be implemented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1485497099",
                    "name": "Ana Iglesias-Molina"
                },
                {
                    "authorId": "3413290",
                    "name": "Andrea Cimmino"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "2739f6ed43bc5ed80ea8e5542882a9d54aa36c52",
            "title": "Systematic Construction of Knowledge Graphs for Research-Performing Organizations",
            "abstract": "Research-Performing Organizations (e.g., research centers, universities) usually accumulate a wealth of data related to their researchers, the generated scientific results and research outputs, and publicly and privately-funded projects that support their activities, etc. Even though the types of data handled may look similar across organizations, it is common to see that each institution has developed its own data model to provide support for many of their administrative activities (project reporting, curriculum management, personnel management, etc.). This creates obstacles to the integration and linking of knowledge across organizations, as well as difficulties when researchers move from one institution to another. In this paper, we take advantage of the ontology network created by the Spanish HERCULES initiative to facilitate the construction of knowledge graphs from existing information systems, such as the one managed by the company Universitas XXI, which provides support to more than 100 Spanish-speaking research-performing organizations worldwide. Our effort is not just focused on following the modeling choices from that ontology, but also on demonstrating how the use of standard declarative mapping rules (i.e., R2RML) guarantees a systematic and sustainable workflow for constructing and maintaining a KG. We also present several real-world use cases in which the proposed workflow is adopted together with a set of lessons learned and general recommendations that may also apply to other domains. The next steps include researching in the automation of the creation of the mapping rules, the enrichment of the KG with external sources, and its exploitation though distributed environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "2193319632",
                    "name": "Francisco Yedro"
                },
                {
                    "authorId": "2192933420",
                    "name": "Roberto Moreno"
                },
                {
                    "authorId": "47469584",
                    "name": "J. Ol\u00edas"
                },
                {
                    "authorId": "13082627",
                    "name": "A. Azuela"
                }
            ]
        },
        {
            "paperId": "47e618a27c3d43318038c71f8928c630b1be1a73",
            "title": "Data Quality Barriers for Transparency in Public Procurement",
            "abstract": "Governments need to be accountable and transparent for their public spending decisions in order to prevent losses through fraud and corruption as well as to build healthy and sustainable economies. Open data act as a major instrument in this respect by enabling public administrations, service providers, data journalists, transparency activists, and regular citizens to identify fraud or uncompetitive markets through connecting related, heterogeneous, and originally unconnected data sources. To this end, in this article, we present our experience in the case of Slovenia, where we successfully applied a number of anomaly detection techniques over a set of open disparate data sets integrated into a Knowledge Graph, including procurement, company, and spending data, through a linked data-based platform called TheyBuyForYou. We then report a set of guidelines for publishing high quality procurement data for better procurement analytics, since our experience has shown us that there are significant shortcomings in the quality of data being published. This article contributes to enhanced policy making by guiding public administrations at local, regional, and national levels on how to improve the way they publish and use procurement-related data; developing technologies and solutions that buyers in the public and private sectors can use and adapt to become more transparent, make markets more competitive, and reduce waste and fraud; and providing a Knowledge Graph, which is a data resource that is designed to facilitate integration across multiple data silos by showing how it adds context and domain knowledge to machine-learning-based procurement analytics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153750193",
                    "name": "A. Soylu"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "3170752",
                    "name": "B. Elves\u00e6ter"
                },
                {
                    "authorId": "2134990618",
                    "name": "Carlos Badenes-Olmedo"
                },
                {
                    "authorId": "2155715210",
                    "name": "Francisco Yedro-Mart\u00ednez"
                },
                {
                    "authorId": "101029936",
                    "name": "Matej Kovacic"
                },
                {
                    "authorId": "2007932882",
                    "name": "Matej Posinkovic"
                },
                {
                    "authorId": "2155714185",
                    "name": "Mitja Medve\u0161\u010dek"
                },
                {
                    "authorId": "52208399",
                    "name": "Ian Makgill"
                },
                {
                    "authorId": "31951006",
                    "name": "C. Taggart"
                },
                {
                    "authorId": "2927032",
                    "name": "E. Simperl"
                },
                {
                    "authorId": "143759957",
                    "name": "T. C. Lech"
                },
                {
                    "authorId": "66215591",
                    "name": "D. Roman"
                }
            ]
        },
        {
            "paperId": "6d702da5dea94d0b0a9302ae579ce995357dd960",
            "title": "An ontological approach for representing declarative mapping languages",
            "abstract": "Knowledge Graphs are currently created using an assortment of techniques and tools: ad hoc code in a programming language, database export scripts, OpenRefine transformations, mapping languages, etc. Focusing on the latter, the wide variety of use cases, data peculiarities, and potential uses has had a substantial impact in how mappings have been created, extended, and applied. As a result, a large number of languages and their associated tools have been created. In this paper, we present the Conceptual Mapping ontology, that is designed to represent the features and characteristics of existing declarative mapping languages to construct Knowledge Graphs. This ontology is built upon the requirements extracted from experts experience, a thorough analysis of the features and capabilities of current mapping languages presented as a comparative framework; and the languages\u2019 limitations discussed by the community and denoted as Mapping Challenges. The ontology is evaluated to ensure that it meets these requirements and has no inconsistencies, pitfalls or modelling errors, and is publicly available online along with its documentation and related resources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1485497099",
                    "name": "Ana Iglesias-Molina"
                },
                {
                    "authorId": "3413290",
                    "name": "Andrea Cimmino"
                },
                {
                    "authorId": "1792630",
                    "name": "E. Ruckhaus"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1398854351",
                    "name": "R. Garc\u00eda-Castro"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "80313ba1f12e4525b941ba29f8e020cf5ae8b835",
            "title": "An Overview of Drugs, Diseases, Genes and Proteins in the CORD-19 Corpus",
            "abstract": "Several initiatives have emerged during the COVID-19 pandemic to gather scientific publications related to coronaviruses. Among them, the COVID-19 Open Research Dataset (CORD-19) has proven to be a valuable resource that provides full-text articles from the PubMed Central, bioRxiv and medRxiv repositories. Such a large amount of biomedical literature needs to be properly managed to facilitate and promote its use by health professionals, for example by tagging documents with the biomedical entities that appear on them. We created a biomedical named entity recognizer (NER) that normalizes (NEN) the drugs, diseases, genes and proteins mentioned in texts with the codes of the main standardization systems such as MeSH, ICD-10, ATC, SNOMED, ChEBI, GARD and NCBI. It is based on fine-tuning the BioBERT language model independently for each entity type using domain-specific datasets and an inverse index search to normalize the references. We have used the resultant BioNER+BioNEN system to process the CORD-19 corpus and offer an overview of the drugs, diseases, genes and proteins related to coronaviruses in the last fifty years.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134990618",
                    "name": "Carlos Badenes-Olmedo"
                },
                {
                    "authorId": "2072861538",
                    "name": "\u00c1lvaro Alonso"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "aac2642bac6e5cd7c295033cbd6b20b168d185db",
            "title": "Multi-label Text Classification for Public Procurement in Spanish",
            "abstract": ": Public procurement accounts for a 14% of the annual budget of the different governments of the European Union. In Europe, contracting processes are classified using Common Procurement Vocabulary codes (CPVs), a taxonomy designed to facilitate statistical reporting, search and the creation of alerts that can be used by potential bidders. CPVs are commonly assigned manually by public employees in charge of contracting processes. However, CPV classification is not a trivial task, as there are more than 9,000 different CPV categories, which are often assigned following heterogeneous criteria. In this paper we have created a CPV classifier that uses as an input the textual description of the contracting process, and assigns CPVs from the 45 top-level CPV categories. We work only with texts in Spanish, although our approach may be easily extended to other languages. Our results improve the state of the art (10% F1-score improvement) and are available online.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404303309",
                    "name": "Mar\u00eda Navas-Loro"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        }
    ]
}