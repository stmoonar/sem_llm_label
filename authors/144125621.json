{
    "authorId": "144125621",
    "papers": [
        {
            "paperId": "03627e32a048ba71ad6ed632df2f3669464a7dae",
            "title": "Domain Information Control at Inference Time for Acoustic Scene Classification",
            "abstract": "Domain shift is considered a challenge in machine learning as it causes significant degradation of model performance. In the Acoustic Scene Classification task (ASC), domain shift is mainly caused by different recording devices. Several studies have already targeted domain generalization to improve the performance of ASC models on unseen domains, such as new devices. Recently, the Controllable Gate Adapter (CONGATER) has been proposed in Natural Language Processing to address the biased training data problem. CONGATER allows controlling the debiasing process at inference time. CONGATER's main advantage is the continuous and selective debiasing of a trained model, during inference. In this work, we adapt CONGATER to the audio spectrogram transformer for an acoustic scene classification task. We show that CONGATER can be used to selectively adapt the learned representations to be invariant to device domain shifts such as recording devices. Our analysis shows that CONGATER can progressively remove device information from the learned representations and improve the model generalization, especially under domain shift conditions (e.g. unseen devices). We show that information removal can be extended to both device and location domain. Finally, we demonstrate CONGATER's ability to enhance specific device performance without further training11Source Code: https://github.com/ShawMaskldcase22_CONGATER.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "28921847",
                    "name": "Khaled Koutini"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "145964711",
                    "name": "G. Widmer"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "06ac71d6ca5ce375ca0dbe4ada89fff9eca98056",
            "title": "Integrating the ACT-R Framework with Collaborative Filtering for Explainable Sequential Music Recommendation",
            "abstract": "Music listening sessions often consist of sequences including repeating tracks. Modeling such relistening behavior with models of human memory has been proven effective in predicting the next track of a session. However, these models intrinsically lack the capability of recommending novel tracks that the target user has not listened to in the past. Collaborative filtering strategies, on the contrary, provide novel recommendations by leveraging past collective behaviors but are often limited in their ability to provide explanations. To narrow this gap, we propose four hybrid algorithms that integrate collaborative filtering with the cognitive architecture ACT-R. We compare their performance in terms of accuracy, novelty, diversity, and popularity bias, to baselines of different types, including pure ACT-R, kNN-based, and neural-networks-based approaches. We show that the proposed algorithms are able to achieve the best performances in terms of novelty and diversity, and simultaneously achieve a higher accuracy of recommendation with respect to pure ACT-R models. Furthermore, we illustrate how the proposed models can provide explainable recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "90762292",
                    "name": "Marta Moscati"
                },
                {
                    "authorId": "2240544649",
                    "name": "Christian Wallmann"
                },
                {
                    "authorId": "1405284505",
                    "name": "Markus Reiter-Haas"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "2cbadfa44dd2818738943c0be4a4cbd69aac9b95",
            "title": "Computational Versus Perceived Popularity Miscalibration in Recommender Systems",
            "abstract": "Popularity bias in recommendation lists refers to over-representation of popular content and is a challenge for many recommendation algorithms. Previous research has suggested several offline metrics to quantify popularity bias, which commonly relate the popularity of items in users' recommendation lists to the popularity of items in their interaction history. Discrepancies between these two factors are referred to as popularity miscalibration. While popularity metrics provide a straightforward and well-defined means to measure popularity bias, it is unknown whether they actually reflect users' perception of popularity bias. To address this research gap, we conduct a crowd-sourced user study on Prolific, involving 56 participants, to (1) investigate whether the level of perceived popularity miscalibration differs between common recommendation algorithms, (2) assess the correlation between perceived popularity miscalibration and its corresponding quantification according to a common offline metric. We conduct our study in a well-defined and important domain, namely music recommendation using the standardized LFM-2b dataset, and quantify popularity miscalibration of five recommendation algorithms by utilizing Jensen-Shannon distance (JSD). Challenging the findings of previous studies, we observe that users generally do perceive significant differences in terms of popularity bias between algorithms if this bias is framed as popularity miscalibration. In addition, JSD correlates moderately with users' perception of popularity, but not with their perception of unpopularity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "2223770106",
                    "name": "Gustavo Escobedo"
                },
                {
                    "authorId": "2614755",
                    "name": "Yashar Deldjoo"
                },
                {
                    "authorId": "3001795",
                    "name": "B. Ferwerda"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "2cd17e31308dc783d45cfd26d64d5c1a96461adc",
            "title": "Trustworthy Recommender Systems: Technical, Ethical, Legal, and Regulatory Perspectives",
            "abstract": "This tutorial provides an interdisciplinary overview about the topics of fairness, non-discrimination, transparency, privacy, and security in the context of recommender systems. These are important dimensions of trustworthy AI systems according to European policies, but also extend to the global debate on regulating AI technology. Since we strongly believe that the aforementioned aspects require more than merely technical considerations, we discuss these topics also from ethical, legal, and regulatory points of views, intertwining different perspectives. The main focus of the tutorial is still on presenting technical solutions that aim at addressing the mentioned topics of trustworthiness. In addition, the tutorial equips the mostly technical audience of RecSys with the necessary understanding of the social and ethical implications of their research and development, and of recent ethical guidelines and regulatory frameworks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2431124",
                    "name": "V. W. Anelli"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                }
            ]
        },
        {
            "paperId": "452070cc57a0430baed36bc34b623dd7d31b69b2",
            "title": "Predicting the Price of Bitcoin Using Sentiment-Enriched Time Series Forecasting",
            "abstract": "Recently, various methods to predict the future price of financial assets have emerged. One promising approach is to combine the historic price with sentiment scores derived via sentiment analysis techniques. In this article, we focus on predicting the future price of Bitcoin, which is currently the most popular cryptocurrency. More precisely, we propose a hybrid approach, combining time series forecasting and sentiment prediction from microblogs, to predict the intraday price of Bitcoin. Moreover, in addition to standard sentiment analysis methods, we are the first to employ a fine-tuned BERT model for this task. We also introduce a novel weighting scheme in which the weight of the sentiment of each tweet depends on the number of its creator\u2019s followers. For evaluation, we consider periods with strongly varying ranges of Bitcoin prices. This enables us to assess the models w.r.t. robustness and generalization to varied market conditions. Our experiments demonstrate that BERT-based sentiment analysis and the proposed weighting scheme improve upon previous methods. Specifically, our hybrid models that use linear regression as the underlying forecasting algorithm perform best in terms of the mean absolute error (MAE of 2.67) and root mean squared error (RMSE of 3.28). However, more complicated models, particularly long short-term memory networks and temporal convolutional networks, tend to have generalization and overfitting issues, resulting in considerably higher MAE and RMSE scores.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2226600284",
                    "name": "Markus Frohmann"
                },
                {
                    "authorId": "2226599065",
                    "name": "Manuel Karner"
                },
                {
                    "authorId": "2226604035",
                    "name": "Said Khudoyan"
                },
                {
                    "authorId": "2226495439",
                    "name": "Robert Wagner"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "605755564694f22a63ad5f17116704077182cdbd",
            "title": "Show me a \"Male Nurse\"! How Gender Bias is Reflected in the Query Formulation of Search Engine Users",
            "abstract": "Biases in algorithmic systems have led to discrimination against historically disadvantaged groups, including the reinforcement of outdated gender stereotypes. While a substantial body of research addresses biases in algorithms and underlying data, in this work, we study if and how users themselves reflect these biases in their interactions with systems, which expectedly leads to the further manifestation of biases. More specifically, we investigate the replication of stereotypical gender representations by users in formulating online search queries. Following prototype theory, we define the disproportionate mention of the gender that does not conform to the prototypical representative of a searched domain (e.g., \u201cmale nurse\u201d) as an indication of bias. In a pilot study with 224 US participants and a main study with 400 UK participants, we find clear evidence of gender biases in formulating search queries. We also report the effects of an educative text on user behaviour and highlight the wish of users to learn about bias-mitigating strategies in their interactions with search engines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "2424581",
                    "name": "Martina Mara"
                },
                {
                    "authorId": "2214759238",
                    "name": "Linda Ratz"
                },
                {
                    "authorId": "2150483265",
                    "name": "Klara Krieg"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "67c38930249ef08f950849850cacd060713f4d86",
            "title": "Multiobjective Hyperparameter Optimization of Recommender Systems",
            "abstract": "The quality of recommendations can be evaluated in terms of accuracy and beyond-accuracy metrics; this renders recommendation a multiobjective task. Several works apply multiobjective optimization techniques for training recommender systems (RSs) or for late fusion of recommendations. However, for the hyperparameter selection, only accuracy is considered. In this paper, we include metrics for accuracy, coverage, novelty, and fairness of recommendations towards groups of users of different activity, and items of different popularity, in the hyperparameter optimization of RSs. We apply the concept of Pareto dominance to select the optimal hyperparameter configurations. Then, by performing multiple univariate linear regressions of the values of beyond-accuracy metrics on the values of NDCG for the optimal hyperparameter configurations, we quantify the interplay of accuracy and beyond-accuracy metrics in terms of the the slope of the lines of best fit. Furthermore, by performing experiments in the domains of movie rating, music streaming, and food and household delivery and with four recommendation algorithms we provide insight in the generalizability of the interplay between accuracy and beyond-accuracy metrics. Our analysis shows that for 8 out of 12 combinations of algorithms and domains, the line of best fit for at least one beyond-accuracy metric has a negative slope, indicating a trade-off relationship and supporting the multiobjective hyperparameter optimization. Our analysis further shows that both the sign and the absolute value of the slope of the line of best fit depend on the recommendation algorithm as well as the recommendation domain, indicating the non-generalizability of the interplay between accuracy and beyond-accuracy metrics in the hyperparameter optimization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "90762292",
                    "name": "Marta Moscati"
                },
                {
                    "authorId": "2614755",
                    "name": "Yashar Deldjoo"
                },
                {
                    "authorId": "2239542737",
                    "name": "Giulio Davide Carparelli"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "8149e3c13afbfd7f8b7d85cc042f2db177444d51",
            "title": "I Don\u2019t Care How Popular You Are! Investigating Popularity Bias in Music Recommendations from a User\u2019s Perspective",
            "abstract": "Recommender systems are designed to help us navigate through an abundance of online content. Collaborative filtering (CF) approaches are commonly used to leverage behaviors of others with a similar taste to make predictions for the target user. However, CF is prone to introduce or amplify popularity bias in which popular (often consumed or highly ranked) items are prioritized over less popular items. Many computational metrics of popularity biases \u2014 and resulting algorithmic (un)fairness \u2014 have been presented. However, it is largely unclear whether these metrics reflect human perception of bias and fairness. We conducted a user study with 170 participants to explore how users perceive recommendation lists created by algorithms with different degrees of popularity bias. Our results show \u2014 surprisingly \u2014 that popularity biases in recommendation lists are barely observed by users, even when corresponding bias/fairness metrics clearly indicate them.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3001795",
                    "name": "B. Ferwerda"
                },
                {
                    "authorId": "2212030196",
                    "name": "Eveline Ingesson"
                },
                {
                    "authorId": "2212030203",
                    "name": "Michaela Berndl"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "e180519d43f740af0e4b1341f37974f5033f08f6",
            "title": "Travel Bird: A Personalized Destination Recommender with TourBERT and Airbnb Experiences",
            "abstract": "We present Travel Bird, a novel personalized destination recommendation and exploration interface which allows its users to find their next tourist destination by describing their specific preferences in a narrative form. Unlike other solutions, Travel Bird is based on TourBERT, a novel NLP model we developed, specifically tailored to the tourism domain. Travel Bird creates a two-dimensional personalized destination exploration space from TourBERT embeddings of social media content and the users' textual description of the experience they are looking for. In this demo, we will showcase several use cases for Travel Bird, which are beneficial for consumers and destination management organizations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087407096",
                    "name": "Veronika Arefieva"
                },
                {
                    "authorId": "12805888",
                    "name": "R. Egger"
                },
                {
                    "authorId": "1723099",
                    "name": "M. Schrefl"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "e92d26ca27a6e51c1c0460ea29f89b72dffc5c5d",
            "title": "Trustworthy Algorithmic Ranking Systems",
            "abstract": "This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency as relevant dimensions of trustworthy AI systems, tailored to algorithmic ranking systems such as search engines and recommender systems. We will equip the mostly technical audience of WSDM with the necessary understanding of the social and ethical implications of their research and development on the one hand, and of recent ethical guidelines and regulatory frameworks addressing the aforementioned dimensions on the other hand. While the tutorial foremost takes a European perspective, starting from the concept of trustworthy AI and discussing EU regulation in this area currently in the implementation stages, we also consider related initiatives worldwide. Since ensuring non-discrimination, diversity, and transparency in retrieval and recommendation systems is an endeavor in which academic institutions and companies in different parts of the world should collaborate, this tutorial is relevant for researchers and practitioners interested in the ethical, social, and legal impact of their work. The tutorial, therefore, targets both academic scholars and practitioners around the globe, by reviewing recent research and providing practical examples addressing these particular trustworthiness aspects, and showcasing how new regulations affect the audience's daily work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "1740615089",
                    "name": "Emilia G\u00f3mez"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                }
            ]
        }
    ]
}