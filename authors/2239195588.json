{
    "authorId": "2239195588",
    "papers": [
        {
            "paperId": "5cc558d112cf90f4e67484fa92c9175f600268b8",
            "title": "ShaRP: Explaining Rankings with Shapley Values",
            "abstract": "Algorithmic decisions in critical domains such as hiring, college admissions, and lending are often based on rankings. Because of the impact these decisions have on individuals, organizations, and population groups, there is a need to understand them: to know whether the decisions are abiding by the law, to help individuals improve their rankings, and to design better ranking procedures. In this paper, we present ShaRP (Shapley for Rankings and Preferences), a framework that explains the contributions of features to different aspects of a ranked outcome, and is based on Shapley values. Using ShaRP, we show that even when the scoring function used by an algorithmic ranker is known and linear, the weight of each feature does not correspond to its Shapley value contribution. The contributions instead depend on the feature distributions, and on the subtle local interactions between the scoring features. ShaRP builds on the Quantitative Input Influence framework, and can compute the contributions of features for multiple Quantities of Interest, including score, rank, pair-wise preference, and top-k. Because it relies on black-box access to the ranker, ShaRP can be used to explain both score-based and learned ranking models. We show results of an extensive experimental validation of ShaRP using real and synthetic datasets, showcasing its usefulness for qualitative analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3444610",
                    "name": "Venetia Pliatsika"
                },
                {
                    "authorId": "2239195588",
                    "name": "Jo\u00e3o Fonseca"
                },
                {
                    "authorId": "2281905611",
                    "name": "Tilun Wang"
                },
                {
                    "authorId": "2281825322",
                    "name": "Julia Stoyanovich"
                }
            ]
        },
        {
            "paperId": "83de6482f1a6f5429c03697eb9e90713e4f2d238",
            "title": "The Game Of Recourse: Simulating Algorithmic Recourse over Time to Improve Its Reliability and Fairness",
            "abstract": "Algorithmic recourse, or providing recommendations to individuals who receive an unfavorable outcome from an algorithmic system on how they can take action and change that outcome, is an important tool for giving individuals agency against algorithmic decision systems. Unfortunately, research on algorithmic recourse faces a fundamental challenge: there are no publicly available datasets on algorithmic recourse. In this work, we begin to explore a solution to this challenge by creating an agent-based simulation called The Game of Recourse (an homage to Conway's Game of Life) to synthesize realistic algorithmic recourse data. We designed The Game of Recourse with a focus on reliability and fairness, two areas of critical importance in socio-technical systems. You can access the application at https://game-of-recourse.streamlit.app.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239195821",
                    "name": "Andrew Bell"
                },
                {
                    "authorId": "2239195588",
                    "name": "Jo\u00e3o Fonseca"
                },
                {
                    "authorId": "2281825322",
                    "name": "Julia Stoyanovich"
                }
            ]
        },
        {
            "paperId": "ba1a77c3a93854461be2fe642b1952eaf3e27bd7",
            "title": "Fairness in Algorithmic Recourse Through the Lens of Substantive Equality of Opportunity",
            "abstract": "Algorithmic recourse -- providing recommendations to those affected negatively by the outcome of an algorithmic system on how they can take action and change that outcome -- has gained attention as a means of giving persons agency in their interactions with artificial intelligence (AI) systems. Recent work has shown that even if an AI decision-making classifier is ``fair'' (according to some reasonable criteria), recourse itself may be unfair due to differences in the initial circumstances of individuals, compounding disparities for marginalized populations and requiring them to exert more effort than others. There is a need to define more methods and metrics for evaluating fairness in recourse that span a range of normative views of the world, and specifically those that take into account time. Time is a critical element in recourse because the longer it takes an individual to act, the more the setting may change due to model or data drift. This paper seeks to close this research gap by proposing two notions of fairness in recourse that are in normative alignment with substantive equality of opportunity, and that consider time. The first considers the (often repeated) effort individuals exert per successful recourse event, and the second considers time per successful recourse event. Building upon an agent-based framework for simulating recourse, this paper demonstrates how much effort is needed to overcome disparities in initial circumstances. We then proposes an intervention to improve the fairness of recourse by rewarding effort, and compare it to existing strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239195821",
                    "name": "Andrew Bell"
                },
                {
                    "authorId": "2239195588",
                    "name": "Jo\u00e3o Fonseca"
                },
                {
                    "authorId": "89449460",
                    "name": "Carlo Abrate"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                }
            ]
        },
        {
            "paperId": "e91410e3346b7b65afa4459fcbf189632d6a9739",
            "title": "Setting the Right Expectations: Algorithmic Recourse Over Time",
            "abstract": "Algorithmic systems are often called upon to assist in high-stakes decision making. In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention. The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context. Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date \u2014 when the context might have changed. This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals. In this work we propose an agent-based simulation framework for studying the effects of a continuously changing environment on algorithmic recourse. In particular, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment. Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time. Consequently, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents\u2019 effort.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239195588",
                    "name": "Jo\u00e3o Fonseca"
                },
                {
                    "authorId": "2239195821",
                    "name": "Andrew Bell"
                },
                {
                    "authorId": "89449460",
                    "name": "Carlo Abrate"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                }
            ]
        }
    ]
}