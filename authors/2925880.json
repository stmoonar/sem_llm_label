{
    "authorId": "2925880",
    "papers": [
        {
            "paperId": "36d916c261e18b91577730d10d5cd23a0464f046",
            "title": "Efficient and Effective Multi-Modal Queries through Heterogeneous Network Embedding (Extended Abstract)",
            "abstract": "Recent information retrieval (IR) systems answer a multi-modal query by considering it as a set of separate uni-modal queries. However, depending on the chosen operationalisation, such an approach is inefficient or ineffective. It either requires multiple passes over the data or leads to inaccuracies since the relations between data modalities are neglected in the relevance assessment. To mitigate these challenges, we present an IR system that has been designed to answer genuine multi-modal queries. It relies on a heterogeneous network embedding, so that features from diverse modalities can be incorporated when representing both, a query and the data over which it shall be evaluated. An experimental evaluation using diverse real-world and synthetic datasets illustrates that our approach returns twice the amount of relevant information compared to baseline techniques, while scaling to large multi-modal databases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "39822639",
                    "name": "Chi Thang Duong"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2315762",
                    "name": "M. Weidlich"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "9f2e2aeba6396d522bb53899d77887a0b18cda12",
            "title": "Streamflow Prediction in the Mekong River Basin Using Deep Neural Networks",
            "abstract": "In recent years, the Mekong River Basin (MRB), one of the largest river basins in Southeast Asia, has experienced severe impacts from extreme droughts and floods. Streamflow forecasting has become crucial for effective risk management strategies in the region. However, this task presents significant challenges due to rapid climate changes and the presence of numerous newly constructed upstream dams, which disrupt the natural flow. In this paper, we develop multiple deep learning models (incl. Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), Long short-term Memory (LSTM), and Transformer) to predict streamflow with different lead time forecasts based on observed meteorological variables and climatic indices (i.e., discharge, water level, precipitation, and temperature) from 1979 to 2019. The results indicate that LSTM obtains high performance for streamflow prediction in both dry and wet seasons while Transformer is not recommended for long-term prediction, especially in the dry season. The proposed deep learning models capture well the fluctuation of river flow in the MRB during the period of high-dam development, especially LSTM (NSE \u2265 0.8). The models\u2019 performances are enhanced with the adding of temperature for short-term prediction while precipitation was the most sensitive variable for long-term one. Such proposed models are essential for government agencies to plan mitigation and adaptation strategies at different periods, which can range from days to years.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2227878786",
                    "name": "Thi-Thu-Ha Nguyen"
                },
                {
                    "authorId": "1557269992",
                    "name": "Duc-Quang Vu"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "49474047",
                    "name": "T Dang"
                }
            ]
        },
        {
            "paperId": "afd6a3afc42af8aa601e0e8f103f2927364f842b",
            "title": "Dengue Fever: From Extreme Climates to Outbreak Prediction",
            "abstract": "Dengue Fever (DF) is an emerging mosquito-borne infectious disease that affects hundred of millions of people each year with considerable morbidity and mortality rates, especially for children. Together with global climate changes, it is continuously increasing in terms of number of cases and new locations. Thus, having effective early warning systems becomes an urgent need to improve disease controls and prevention. In this paper, we introduce a novel framework, called Proximity Time Ensemble, to predict DF outbreaks for multiple areas (provinces) and multiple time steps ahead, and to study the effects of climate data on DF outbreaks. PT-Ensem consists of 6 key components: (1) an event-to-event probabilistic framework to study links among extreme climate events and DF outbreaks; (2) a proximity graph that connects similar provinces; (3) an ensemble prediction technique that combines many different advanced machine learning (ML) methods to predict outbreaks within t time steps in the future using extreme climate events as model inputs; (4) a data aggregate scheme to enrich training data for each province via its neighbors in the proximity graph; (5) a proximity propagation step that propagates predicted results among similar provinces via the proximity graph until maximal agreements are reached among provinces; and (6) a time propagation step to propagate results via different predicted time steps in each province. We use PT-Ensem to predict DF outbreaks for all provinces in Vietnam using data collected from 1997-2016. Experiments show that PT-Ensem acquires significant performance boost compared to many highly-rated ML models like XGBoost, LightGBM and Catboost in the outbreak prediction task. Compared to most recent deep learning approaches like LSTM-ATT, LSTM, CNN and Transformer for predicting DF incidence, PT-Ensem also dominates in both prediction accuracy and computation times.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "2203812261",
                    "name": "Ha T. Phi"
                },
                {
                    "authorId": "88061212",
                    "name": "A. Abubakar"
                },
                {
                    "authorId": "2057915031",
                    "name": "Peter Kilpatrick"
                },
                {
                    "authorId": "2203933455",
                    "name": "Hung Q. V. Nguyen"
                },
                {
                    "authorId": "144114375",
                    "name": "Hans Vandierendonck"
                }
            ]
        },
        {
            "paperId": "dbfd3c70174e24a37f7d4134194fe51a237e493e",
            "title": "Diarrhoea incidence prediction using climate data: Machine Learning approaches",
            "abstract": "Diarrhoea disease pose significant threats to national morbidity and mortality in Vietnam, especially on children below 5 years old. Being a climate sensitive disease, it has strong links to various meteorological factors like rainfall. Together with global climate changes, these meteorological factors have contributed the increasing of Diarrhoea incidence in Vietnam. Thus, having an effective early warning system is becoming an urgent need. However, it has not been paid enough attention with very few research works, mainly focusing on quantilizing the relationships among climate and diarrhoea incidence using linear regressions. Exploring more sophisticated machine learning techniques is therefore an interesting work towards more efficient and effective warning systems. In this paper, different types of prediction models from traditional to deep learning methods are studied for predicting Diarrhoea rate in six provinces in Vietnam in both long- and short-terms. Experiments show that LSTM-ATT acquires better performance compared to all other approaches like SARIMA, CNN, LSTM, Transformer, and Prophet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2201678523",
                    "name": "T. Do"
                },
                {
                    "authorId": "117717258",
                    "name": "James Mulhall"
                },
                {
                    "authorId": "2201925266",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2201750074",
                    "name": "Quang T.M. Nguyen"
                },
                {
                    "authorId": "9728788",
                    "name": "D. Phan"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                }
            ]
        },
        {
            "paperId": "69e4ac52275312b1b26d53a6d78b29f83b9489ec",
            "title": "Efficient and Effective Multi-Modal Queries Through Heterogeneous Network Embedding",
            "abstract": "The heterogeneity of today\u2019s Web sources requires information retrieval (IR) systems to handle multi-modal queries. Such queries define a user\u2019s information needs by different data modalities, such as keywords, hashtags, user profiles, and other media. Recent IR systems answer such a multi-modal query by considering it as a set of separate uni-modal queries. However, depending on the chosen operationalisation, such an approach is inefficient or ineffective. It either requires multiple passes over the data or leads to inaccuracies since the relations between data modalities are neglected in the relevance assessment. To mitigate these challenges, we present an IR system that has been designed to answer genuine multi-modal queries. It relies on a heterogeneous network embedding, so that features from diverse modalities can be incorporated when representing both, a query and the data over which it shall be evaluated. By embedding a query and the data in the same vector space, the relations across modalities are made explicit and exploited for more accurate query evaluation. At the same time, multi-modal queries are answered with a single pass over the data. An experimental evaluation using diverse real-world and synthetic datasets illustrates that our approach returns twice the amount of relevant information compared to baseline techniques, while scaling to large multi-modal databases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39822639",
                    "name": "Chi Thang Duong"
                },
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2315762",
                    "name": "M. Weidlich"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "903c6471bdd34cbcc36743d3608fc64b36b72d02",
            "title": "Advanced Machine Learning Techniques for Predicting Nha Trang Shorelines",
            "abstract": "Nha Trang Coast is located in the South Central Vietnam and the coastal erosion has occurred rapidly in recent years. Hence it is crucial to accurately monitor the shoreline changes for better coastal management and reduction of risks for communities. In this paper, we explored a statistical forecasting model, Seasonal Auto-regressive Integrated Moving Average (SARIMA), and two Machine Learning (ML) models, Neural Network Auto-Regression (NNAR) and Long Short-Term Memory (LSTM), to predict the shoreline variations from surveillance camera images. Compared to the Empirical Orthogonal Function (EOF), the most common method used for predicting shoreline changes from cameras, we demonstrate that the SARIMA, NNAR and LSTM models outperform the EOF model significantly in terms of prediction accuracy. The forecasting performance of the SARIMA model, NNAR model and LSTM model is comparable in both long and short-term predictions. The results suggest that these models are highly effective in detecting shoreline changes from video cameras under extreme weather conditions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144424644",
                    "name": "Cheng Yin"
                },
                {
                    "authorId": "145513280",
                    "name": "L. Binh"
                },
                {
                    "authorId": "107606140",
                    "name": "Duong Tran Anh"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1818249934",
                    "name": "Anh Le"
                },
                {
                    "authorId": "2196642410",
                    "name": "Van-Hau Nguyen"
                },
                {
                    "authorId": "2038468909",
                    "name": "Van-Chien Nguyen"
                },
                {
                    "authorId": "72913001",
                    "name": "N. X. Tinh"
                },
                {
                    "authorId": "2109478307",
                    "name": "Hitoshi Tanaka"
                },
                {
                    "authorId": "92441622",
                    "name": "N. Viet"
                },
                {
                    "authorId": "2150604072",
                    "name": "L. Nguyen"
                },
                {
                    "authorId": "2288487325",
                    "name": "T. Duong"
                }
            ]
        },
        {
            "paperId": "e47a2d3ac58458e49618274b3b02ce6136750c1a",
            "title": "Spectrum-Sharing UAV-Assisted Mission-Critical Communication: Learning-Aided Real-Time Optimisation",
            "abstract": "We propose an unmanned aerial vehicle (UAV) communications scheme with spectrum-sharing mechanism to provide mission-critical services such as disaster recovery and public safety. Specifically, the UAVs can serve as flying base stations to provide extended network coverage for the affected area under spectrum-sharing cognitive radio networks (CRNs). To cope with the effects of network destruction in a disaster, we propose a real-time optimisation framework for resource allocation (e.g., power and number of UAVs) for CRNs assisted by UAV relays. The proposed optimisation scheme aims at optimising the network throughput of primary and secondary networks under the stringent constraint of maximum tolerable interference impinged on the primary users. We also propose a deep neural network (DNN) model to significantly reduce the execution time under real-time solution of mixed-integer UAV deployment problems. For both primary and secondary networks, our real-time optimisation algorithms impose low computational complexity, hence, have a low execution time in solving throughput optimisation problems, which demonstrates the benefit of our approached proposed for spectrum-sharing UAV-assisted mission-critical services.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1789308",
                    "name": "Minh Le Nguyen"
                },
                {
                    "authorId": "1398182306",
                    "name": "E. Garcia-Palacios"
                },
                {
                    "authorId": "1411489504",
                    "name": "Tan do-Duy"
                },
                {
                    "authorId": "2150604072",
                    "name": "L. Nguyen"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "2288487325",
                    "name": "T. Duong"
                }
            ]
        },
        {
            "paperId": "1be51d323ce7c52587053c6aaffca9f92673e713",
            "title": "Incremental Density-Based Clustering on Multicore Processors",
            "abstract": "The density-based clustering algorithm is a fundamental data clustering technique with many real-world applications. However, when the database is frequently changed, how to effectively update clustering results rather than reclustering from scratch remains a challenging task. In this work, we introduce IncAnyDBC, a unique parallel incremental data clustering approach to deal with this problem. First, IncAnyDBC can process changes in bulks rather than batches like state-of-the-art methods for reducing update overheads. Second, it keeps an underlying cluster structure called the object node graph during the clustering process and uses it as a basis for incrementally updating clusters wrt. inserted or deleted objects in the database by propagating changes around affected nodes only. In additional, IncAnyDBC actively and iteratively examines the graph and chooses only a small set of most meaningful objects to produce exact clustering results of DBSCAN or to approximate results under arbitrary time constraints. This makes it more efficient than other existing methods. Third, by processing objects in blocks, IncAnyDBC can be efficiently parallelized on multicore CPUs, thus creating a work-efficient method. It runs much faster than existing techniques using one thread while still scaling well with multiple threads. Experiments are conducted on various large real datasets for demonstrating the performance of IncAnyDBC.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "144891660",
                    "name": "Jon Jacobsen"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "39657876",
                    "name": "I. Spence"
                },
                {
                    "authorId": "1500614044",
                    "name": "N. Tran"
                },
                {
                    "authorId": "1713664",
                    "name": "I. Assent"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "d953bc72887d3bfbdfce6ec2c01b29c707071812",
            "title": "Scalable Interactive Dynamic Graph Clustering on Multicore CPUs",
            "abstract": "The structural graph clustering algorithm SCAN is a fundamental technique for managing and analyzing graph data. However, its high runtime remains a computational bottleneck, which limits its applicability. In this paper, we propose a novel interactive approach for tackling this problem on multicore CPUs. Our algorithm, called anySCAN, iteratively processes vertices in blocks. The acquired results are merged into an underlying cluster structure consisting of the so-called super-nodes for building clusters. During its runtime, anySCAN can be suspended for examining intermediate results and resumed for finding better results at arbitrary time points, making it an anytime algorithm which is capable of handling very large graphs in an interactive way and under arbitrary time constraints. Moreover, its block processing scheme allows the design of a scalable parallel algorithm on shared memory architectures such as multicore CPUs for speeding up the algorithm further at each iteration. Consequently, anySCAN uniquely is a both interactive and work-efficient parallel algorithm. We further introduce danySCAN an efficient bulk update scheme for anySCAN on dynamic graphs in which the clusters are updated in bulks and in a parallel interactive scheme. Experiments are conducted on very large real graph datasets for demonstrating the performance of anySCAN. They show its ability to acquire very good approximate results early, leading to orders of magnitude speedup compared to SCAN and its variants. Moreover, it scales very well with the number of threads when dealing with both static and dynamic graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1713664",
                    "name": "I. Assent"
                },
                {
                    "authorId": "31468535",
                    "name": "Mathias Skovgaard Birk"
                },
                {
                    "authorId": "40899464",
                    "name": "Martin Storgaard Dieu"
                },
                {
                    "authorId": "144891660",
                    "name": "Jon Jacobsen"
                },
                {
                    "authorId": "2065384360",
                    "name": "Jesper Kristensen"
                }
            ]
        },
        {
            "paperId": "2a3eeee82919fb8394342d9bb1d59bc9a63c7717",
            "title": "Scalable Active Temporal Constrained Clustering",
            "abstract": "We introduce a novel interactive framework to handle both instance-level and temporal smoothness constraints for clustering large temporal data. It consists of a constrained clustering algorithm which optimizes the clustering quality, constraint violation and the historical cost between consecutive data snapshots. At the center of our framework is a simple yet effective active learning technique for iteratively selecting the most informative pairs of objects to query users about, and updating the clustering with new constraints. Those constraints are then propagated inside each snapshot and between snapshots via constraint inheritance and propagation to further enhance the results. Experiments show better or comparable clustering results than existing techniques as well as high scalability for large datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1765141",
                    "name": "A. Chouakria"
                }
            ]
        },
        {
            "paperId": "4fdab84b9806555936d46c9f536672391c4ce854",
            "title": "Scalable and Interactive Graph Clustering Algorithm on Multicore CPUs",
            "abstract": "The structural graph clustering algorithm SCAN is a fundamental technique for managing and analyzing graph data. However, its high runtime remains a computational bottleneck, which limits its applicability. In this paper, we propose a novel interactive approach for tackling this problem on multicore CPUs. Our algorithm, called anySCAN, iteratively processes vertices in blocks. The acquired results are merged into an underlying cluster structures consisting of the so-called supernodes for building clusters. During its runtime, anySCAN can be suppressed for examining intermediate results and resumed for finding better result at arbitrary time points, making it an anytime algorithm which is capable to deal with very large graphs in an interactive way and under arbitrary time constraints. Moreover, its block processing scheme allows the design of a scalable parallel algorithm on shared memory architectures such as multicore CPUs for further speeding up the algorithm at each iteration. Consequently, anySCAN uniquely is an interactive and parallel algorithm at the same time. Experiments are conducted on very large real graph datasets for demonstrating the performance of anySCAN. It acquires very good approximate results early, leading to orders of magnitude speedup factor compared to SCAN and its variants. Using 16 threads, the acquired speed up factors are up to 13.5 times over its sequential version.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "40899464",
                    "name": "Martin Storgaard Dieu"
                },
                {
                    "authorId": "1713664",
                    "name": "I. Assent"
                },
                {
                    "authorId": "144891660",
                    "name": "Jon Jacobsen"
                },
                {
                    "authorId": "2065384360",
                    "name": "Jesper Kristensen"
                },
                {
                    "authorId": "31468535",
                    "name": "Mathias Skovgaard Birk"
                }
            ]
        },
        {
            "paperId": "13c47ed140cc36191678a48b3115939cd0aa8314",
            "title": "AnyDBC: An Efficient Anytime Density-based Clustering Algorithm for Very Large Complex Datasets",
            "abstract": "The density-based clustering algorithm DBSCAN is a state-of-the-art data clustering technique with numerous applications in many fields. However, its O(n2) time complexity still remains a severe weakness. In this paper, we propose a novel anytime approach to cope with this problem by reducing both the range query and the label propagation time of DBSCAN. Our algorithm, called AnyDBC, compresses the data into smaller density-connected subsets called primitive clusters and labels objects based on connected components of these primitive clusters for reducing the label propagation time. Moreover, instead of passively performing the range query for all objects like existing techniques, AnyDBC iteratively and actively learns the current cluster structure of the data and selects a few most promising objects for refining clusters at each iteration. Thus, in the end, it performs substantially fewer range queries compared to DBSCAN while still guaranteeing the exact final result of DBSCAN. Experiments show speedup factors of orders of magnitude compared to DBSCAN and its fastest variants on very large real and synthetic complex datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1713664",
                    "name": "I. Assent"
                },
                {
                    "authorId": "31894642",
                    "name": "Martin Storgaard"
                }
            ]
        },
        {
            "paperId": "c5c92d217b6f0bcdc537e891c8cd9f7d7ef0db5b",
            "title": "Health Monitoring on Social Media over Time",
            "abstract": "Social media has become a major source for analyzing all aspects of daily life. Thanks to dedicated latent topic analysis methods such as the Ailment Topic Aspect Model (ATAM), public health can now be observed on Twitter. In this work, we are interested in using social media to monitor people\u2019s health over time. The use of tweets has several benefits including instantaneous data availability at virtually no cost. Early monitoring of health data is complementary to post-factum studies and enables a range of applications such as measuring behavioral risk factors and triggering health campaigns. We formulate two problems: health transition detection and  health transition prediction. We first propose the Temporal Ailment Topic Aspect Model (TM\u2013ATAM), a new latent model dedicated to solving the first problem by capturing transitions that involve health-related topics. TM\u2013ATAM is a non-obvious extension to ATAM that was designed to extract health-related topics. It learns health-related topic transitions by minimizing the prediction error on topic distributions between consecutive posts at different time and geographic granularities. To solve the second problem, we develop T\u2013ATAM, a Temporal Ailment Topic Aspect Model where time is treated as a random variable natively inside ATAM. Our experiments on an 8-month corpus of tweets show that TM\u2013ATAM outperforms TM\u2013LDA in estimating health-related transitions from tweets for different geographic populations. We examine the ability of TM\u2013ATAM to detect transitions due to climate conditions in different geographic regions. We then show how T\u2013ATAM can be used to predict the most important transition and additionally compare T\u2013ATAM with CDC (Center for Disease Control) data and Google Flu Trends.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3430051",
                    "name": "Sumit Sidana"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                },
                {
                    "authorId": "1412139901",
                    "name": "Majdeddine Rebai"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "9956ee15d2576d516abb7a7bcc8a5528c04b348b",
            "title": "A New Method to Encode the At-Most-One Constraint into SAT",
            "abstract": "One of the most widely used constraints during the process of translating a practical problem into a propositional satisfiability (SAT) instance is the at-most-one (AMO) constraint. This paper proposes a new encoding for the AMO constraint, the so-called AMO bimander encoding which can be easily extended to encode cardinality constraints, which are often used in constraint programming. Experimental results reveal that the new encoding is very competitive compared with all other state-of-the-art encodings. Furthermore, we will prove that the new encoding allows unit propagation to achieve arc consistency - an important technique in constraint programming. We also show that a special case of the AMO bimander encoding outperforms the AMO binary encoding, a widely used encoding, in all our experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9520450",
                    "name": "Van-Hau Nguyen"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                }
            ]
        },
        {
            "paperId": "83e3c224d73f4e98116f2dba5435b88e8249618c",
            "title": "Relevant overlapping subspace clusters on categorical data",
            "abstract": "Clustering categorical data poses some unique challenges: Due to missing order and spacing among the categories, selecting a suitable similarity measure is a difficult task. Many existing techniques require the user to specify input parameters which are difficult to estimate. Moreover, many techniques are limited to detect clusters in the full-dimensional data space. Only few methods exist for subspace clustering and they produce highly redundant results. Therefore, we propose ROCAT (Relevant Overlapping Subspace Clusters on Categorical Data), a novel technique based on the idea of data compression. Following the Minimum Description Length principle, ROCAT automatically detects the most relevant subspace clusters without any input parameter. The relevance of each cluster is validated by its contribution to compress the data. Optimizing the trade-off between goodness-of-fit and model complexity, ROCAT automatically determines a meaningful number of clusters to represent the data. ROCAT is especially designed to detect subspace clusters on categorical data which may overlap in objects and/or attributes; i.e. objects can be assigned to different clusters in different subspaces and attributes may contribute to different subspaces containing clusters. ROCAT naturally avoids undesired redundancy in clusters and subspaces by allowing overlap only if it improves the compression rate. Extensive experiments demonstrate the effectiveness and efficiency of our approach.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193088956",
                    "name": "Xiao He"
                },
                {
                    "authorId": "2108686610",
                    "name": "Jing Feng"
                },
                {
                    "authorId": "2780488",
                    "name": "B. Konte"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "144372623",
                    "name": "C. Plant"
                }
            ]
        },
        {
            "paperId": "b3257a1637f8c0f49b900b129d141765f88a15f4",
            "title": "Density-based algorithms for active and anytime clustering",
            "abstract": "Data intensive applications like biology, medicine, and neuroscience require effective and efficient data mining technologies. Advanced data acquisition methods produce a constantly increasing volume and complexity. As a consequence, the need of new data mining technologies to deal with complex data has emerged during the last decades. In this thesis, we focus on the data mining task of clustering in which objects are separated in different groups (clusters) such that objects inside a cluster are more similar than objects in different clusters. Particularly, we consider density-based clustering algorithms and their applications in biomedicine. \n \nThe core idea of the density-based clustering algorithm DBSCAN is that each object within a cluster must have a certain number of other objects inside its neighborhood. Compared with other clustering algorithms, DBSCAN has many attractive benefits, e.g., it can detect clusters with arbitrary shape and is robust to outliers, etc. Thus, DBSCAN has attracted a lot of research interest during the last decades with many extensions and applications. In the first part of this thesis, we aim at developing new algorithms based on the DBSCAN paradigm to deal with the new challenges of complex data, particularly expensive distance measures and incomplete availability of the distance matrix. \n \nLike many other clustering algorithms, DBSCAN suffers from poor performance when facing expensive distance measures for complex data. To tackle this problem, we propose a new algorithm based on the DBSCAN paradigm, called Anytime Density-based Clustering (A-DBSCAN), that works in an anytime scheme: in contrast to the original batch scheme of DBSCAN, the algorithm A-DBSCAN first produces a quick approximation of the clustering result and then continuously refines the result during the further run. Experts can interrupt the algorithm, examine the results, and choose between (1) stopping the algorithm at any time whenever they are satisfied with the result to save runtime and (2) continuing the algorithm to achieve better results. Such kind of anytime scheme has been proven in the literature as a very useful technique when dealing with time consuming problems. We also introduced an extended version of A-DBSCAN called A-DBSCAN-XS which is more efficient and effective than A-DBSCAN when dealing with expensive distance measures. \n \nSince DBSCAN relies on the cardinality of the neighborhood of objects, it requires the full distance matrix to perform. For complex data, these distances are usually expensive, time consuming or even impossible to acquire due to high cost, high time complexity, noisy and missing data, etc. Motivated by these potential difficulties of acquiring the distances among objects, we propose another approach for DBSCAN, called Active Density-based Clustering (Act-DBSCAN). Given a budget limitation B, Act-DBSCAN is only allowed to use up to B pairwise distances ideally to produce the same result as if it has the entire distance matrix at hand. The general idea of Act-DBSCAN is that it actively selects the most promising pairs of objects to calculate the distances between them and tries to approximate as much as possible the desired clustering result with each distance calculation. This scheme provides an efficient way to reduce the total cost needed to perform the clustering. Thus it limits the potential weakness of DBSCAN when dealing with the distance sparseness problem of complex data. \n \nAs a fundamental data clustering algorithm, density-based clustering has many applications in diverse fields. In the second part of this thesis, we focus on an application of density-based clustering in neuroscience: the segmentation of the white matter fiber tracts in human brain acquired from Diffusion Tensor Imaging (DTI). We propose a model to evaluate the similarity between two fibers as a combination of structural similarity and connectivity-related similarity of fiber tracts. Various distance measure techniques from fields like time-sequence mining are adapted to calculate the structural similarity of fibers. Density-based clustering is used as the segmentation algorithm. We show how A-DBSCAN and A-DBSCAN-XS are used as novel solutions for the segmentation of massive fiber datasets and provide unique features to assist experts during the fiber segmentation process.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                }
            ]
        },
        {
            "paperId": "fc8c632284cbf4fe0d8434fc088ee3c2f485b16e",
            "title": "Solving the all-interval series problem: SAT vs CP",
            "abstract": "Although Boolean satisfiability (abbreviated as SAT) is a sub-field of constraint programming (CP), the former states and solves problems as a black-box approach, whereas the latter aims at being tunable and programmable. Although many researches bridging SAT and CP have been provided, surprisingly, only few researchers have compared the SAT and CP approaches on a particular problem. This paper studies how to solve the all-interval series problem through both approaches. We will show that by using a state-of-the-art SAT solver and an appropriate SAT encoding the SAT approach obtains a significantly higher performance over the CP approach. Furthermore, we also provide the state-of-the-art result for several all-interval series instances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9520450",
                    "name": "Van-Hau Nguyen"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                }
            ]
        },
        {
            "paperId": "57812e6a4e8ca15ecf9f60bcb9d9082e09e23e4e",
            "title": "Active Density-Based Clustering",
            "abstract": "The density-based clustering algorithm DBSCAN is a fundamental technique for data clustering with many attractive properties and applications. However, DBSCAN requires specifying all pair wise (dis)similarities among objects that can be non-trivial to obtain in many applications. To tackle this problem, in this paper, we propose a novel active density-based clustering algorithm, named Act-DBSCAN, which works under a restricted number of used pair wise similarities. Act-DBSCAN exploits the pair wise lower-bounding (LB) similarities to initialize the cluster structure. Then, it adaptively selects the most informative pair wise LB similarities to update with the real ones in order to reconstruct the result until the budget limitation is reached. The goal is to approximate as much as possible the true clustering result with each update. Our Act-DBSCAN framework is built upon a proposed probabilistic model to score the impact of the update of each pair wise LB similarity on the change of the intermediate clustering structure. Deriving from this scoring system and the monotonicity and reduction property of our active clustering process, we propose the two efficient algorithms to iteratively select and update pair wise similarities and cluster structure. Experiments on real datasets show that Act-DBSCAN acquires good clustering results with only a few pair wise similarities, and requires only a small fraction of all pair wise similarities to reach the DBSCAN results. Act-DBSCAN also outperforms other related techniques such as active spectral clustering.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "2193088956",
                    "name": "Xiao He"
                },
                {
                    "authorId": "1999324",
                    "name": "Nina C. Hubig"
                },
                {
                    "authorId": "144372623",
                    "name": "C. Plant"
                },
                {
                    "authorId": "145913175",
                    "name": "C. B\u00f6hm"
                }
            ]
        },
        {
            "paperId": "dd07544de945344f71b2b4594fafae4e0ebd845c",
            "title": "Efficient Anytime Density-based Clustering",
            "abstract": "Many clustering algorithms suffer from scalability problems on massive datasets and do not support any user interaction during runtime. To tackle these problems, anytime clustering algorithms are proposed. They produce a fast approximate result which is continuously refined during the further run. Also, they can be stopped or suspended anytime and provide an answer. In this paper, we propose a novel anytime clustering algorithm based on the density-based clustering paradigm. Our algorithm called A-DBSCAN is applicable to very high dimensional databases such as time series, trajectory, medical data, etc. The general idea of our algorithm is to use a sequence of lower-bounding functions (LBs) of the true similarity measure to produce multiple approximate results of the true density-based clusters. ADBSCAN operates in multiple levels w.r.t. the LBs and is mainly based on two algorithmic schemes: (1) an efficient distance upgrade scheme which restricts distance calculations to core-objects at each level of the LBs; (2) a local reclustering scheme which restricts update operations to the relevant objects only. Extensive experiments demonstrate that A-DBSCAN acquires very good clustering results at very early stages of execution thus saves a large amount of computational time. Even if it runs to the end, A-DBSCAN is still orders of magnitude faster than DBSCAN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145913175",
                    "name": "C. B\u00f6hm"
                },
                {
                    "authorId": "2108686610",
                    "name": "Jing Feng"
                },
                {
                    "authorId": "2193088956",
                    "name": "Xiao He"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                }
            ]
        },
        {
            "paperId": "07e587ca667701bf22ba37b2175762cd8108fd36",
            "title": "A Similarity Model and Segmentation Algorithm for White Matter Fiber Tracts",
            "abstract": "Recently, fiber segmentation has become an emerging technique in neuroscience. Grouping fiber tracts into anatomical meaningful bundles allows to study the structure of the brain and to investigate onset and progression of neurodegenerative and mental diseases. In this paper, we propose a novel technique for fiber tracts based on shape similarity and connection similarity. For shape similarity, we propose some new techniques adapted from existing similarity measures for trajectory data. We also propose a new technique called Warped Longest Common Subsequence (WLCS) for which we additionally developed a lower-bounding distance function to speed up the segmentation process. Our segmentation is based on an outlier-robust density-based clustering algorithm. Extensive experiments on diffusion tensor images demonstrate the efficiency and effectiveness of our technique.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "3256912",
                    "name": "Sebastian Goebl"
                },
                {
                    "authorId": "144372623",
                    "name": "C. Plant"
                }
            ]
        },
        {
            "paperId": "d0356ae053d348f514949f8bd2296c9e95916ba2",
            "title": "Measuring Non-Gaussianity by Phi-Transformed and Fuzzy Histograms",
            "abstract": "Independent component analysis (ICA) is an essential building block for data analysis in many applications. Selecting the truly meaningful components from the result of an ICA algorithm, or comparing the results of different algorithms, however, is nontrivial problems. We introduce a very general technique for evaluating ICA results rooted in information-theoretic model selection. The basic idea is to exploit the natural link between non-Gaussianity and data compression: the better the data transformation represented by one or several ICs improves the effectiveness of data compression, the higher is the relevance of the ICs. We propose two different methods which allow an efficient data compression of non-Gaussian signals: Phi-transformed histograms and fuzzy histograms. In an extensive experimental evaluation, we demonstrate that our novel information-theoretic measures robustly select non-Gaussian components from data in a fully automatic way, that is, without requiring any restrictive assumptions or thresholds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144372623",
                    "name": "C. Plant"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "40161233",
                    "name": "Junming Shao"
                },
                {
                    "authorId": "2958299",
                    "name": "Fabian J Theis"
                },
                {
                    "authorId": "1398348342",
                    "name": "A. Meyer-B\u00e4se"
                },
                {
                    "authorId": "2057274375",
                    "name": "Christian B\u00f6hm"
                }
            ]
        },
        {
            "paperId": "4c7c514ebb62fd1a79ff0c682ed23fc950e2a1a7",
            "title": "EWAT+: Finding Time Series Discords Based on New Discord Measure Functions",
            "abstract": "In this paper, we introduce a new method, called EWAT+, for finding discords in time series databases. The proposed method takes full advantages of WAT, the discord discovery algorithm proposed by Fu et al., with major improvements based on new discord measure functions which help to set up a range of alternative good orderings for the outer loop of the discord discovery algorithm. In addition, we employ a branch-and-bound search mechanism on augmented trie that is carried out in the inner loop of the algorithm. Our experiments show that EWAT+ is highly effective in terms of running time.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1728515",
                    "name": "D. T. Anh"
                }
            ]
        }
    ]
}