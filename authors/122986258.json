{
    "authorId": "122986258",
    "papers": [
        {
            "paperId": "8861c32368d4c30732c6c57d1ca188149b631567",
            "title": "Measuring Technological Convergence in Encryption Technologies with Proximity Indices: A Text Mining and Bibliometric Analysis using OpenAlex",
            "abstract": "Identifying technological convergence among emerging technologies in cybersecurity is crucial for advancing science and fostering innovation. Unlike previous studies focusing on the binary relationship between a paper and the concept it attributes to technology, our approach utilizes attribution scores to enhance the relationships between research papers, combining keywords, citation rates, and collaboration status with specific technological concepts. The proposed method integrates text mining and bibliometric analyses to formulate and predict technological proximity indices for encryption technologies using the\"OpenAlex\"catalog. Our case study findings highlight a significant convergence between blockchain and public-key cryptography, evidenced by the increasing proximity indices. These results offer valuable strategic insights for those contemplating investments in these domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290022464",
                    "name": "Alessandro Tavazzi"
                },
                {
                    "authorId": "29898269",
                    "name": "Dimitri Percia David"
                },
                {
                    "authorId": "1402808377",
                    "name": "Julian Jang-Jaccard"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "160762eaab73ef24bc15668e13fcf836735fe45e",
            "title": "Explainable Classification of Internet Memes",
            "abstract": "Nowadays, the integrity of online conversations is faced with a variety of threats, ranging from hateful content to manufactured media. In such a context, Internet Memes make the scalable automation of moderation interventions increasingly more challenging, given their inherently complex and multimodal nature. Existing work on Internet Meme classification has focused on black-box methods that do not explicitly consider the semantics of the memes or the context of their creation. This paper proposes a modular and explainable architecture for Internet Meme classification and understanding. We design and implement multimodal classification methods that perform exampleand prototype-based reasoning over training cases, while leveraging both textual and visual SOTA models to represent the individual cases. We study the relevance of our modular and explainable models in detecting harmful memes on two existing tasks: Hate Speech Detection and Misogyny Classification. We compare the performance between exampleand prototype-based methods, and between text, vision, and multimodal models, across different categories of harmfulness (e.g., stereotype and objectification). We devise a user-friendly interface that facilitates the comparative analysis of examples retrieved by all of our models for any given meme, informing the community about the strengths and limitations of these explainable methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070336022",
                    "name": "A. Thakur"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2282974137",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "1ce5b255c7304d708b48bdd2172e0cf632b2a7cd",
            "title": "Modeling 5G Threat Scenarios for Critical Infrastructure Protection",
            "abstract": "Fifth-generation cellular networks (5G) are currently being deployed by mobile operators around the globe. 5G is an enabler for many use cases and improves security and privacy over 4G and previous network generations. However, as recent security research has revealed, the 5G standard still has technical security weaknesses for attackers to exploit. In addition, the migration from 4G to 5G systems takes place by first deploying 5G solutions in a non-standalone (NSA) manner, where the first step of the 5G deployment is restricted to the new radio aspects of 5G. At the same time, the control of user equipment is still based on 4G protocols; that is, the core network is still the legacy 4G evolved packet core (EPC) network. As a result, many security vulnerabilities of 4G networks are still present in current 5G deployments. To stimulate the discussion about the security risks in current 5G networks, particularly regarding critical infrastructures, we model possible threats according to the STRIDE threat classification model. We derive a risk matrix based on the likelihood and impact of eleven threat scenarios (TS) that affect the radio access and the network core. We estimate that malware or software vulnerabilities on the 5G base station constitute the most impactful threat scenario, though not the most probable. In contrast, a scenario where compromised cryptographic keys threaten communications between network functions is both highly probable and highly impactful. To improve the 5G security posture, we discuss possible mitigations and security controls. Our analysis is generalizable and does not depend on the specifics of any particular 5G network vendor or operator.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "98755607",
                    "name": "G. Holtrup"
                },
                {
                    "authorId": "2223955825",
                    "name": "William Blonay"
                },
                {
                    "authorId": "2666160",
                    "name": "Martin Strohmeier"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                },
                {
                    "authorId": "2086180399",
                    "name": "Jean-Pascal Chavanne"
                },
                {
                    "authorId": "2143889977",
                    "name": "Vincent Lenders"
                }
            ]
        },
        {
            "paperId": "285dae5c2f2ef55c70971094a1ddd45afe720eee",
            "title": "Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense",
            "abstract": "Generative Language Models gained significant attention in late 2022 / early 2023, notably with the introduction of models refined to act consistently with users' expectations of interactions with AI (conversational models). Arguably the focal point of public attention has been such a refinement of the GPT3 model -- the ChatGPT and its subsequent integration with auxiliary capabilities, including search as part of Microsoft Bing. Despite extensive prior research invested in their development, their performance and applicability to a range of daily tasks remained unclear and niche. However, their wider utilization without a requirement for technical expertise, made in large part possible through conversational fine-tuning, revealed the extent of their true capabilities in a real-world environment. This has garnered both public excitement for their potential applications and concerns about their capabilities and potential malicious uses. This review aims to provide a brief overview of the history, state of the art, and implications of Generative Language Models in terms of their principles, abilities, limitations, and future prospects -- especially in the context of cyber-defense, with a focus on the Swiss operational environment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2319814657",
                    "name": "Andrei Kucharavy"
                },
                {
                    "authorId": "104207674",
                    "name": "Z. Schillaci"
                },
                {
                    "authorId": "2187874510",
                    "name": "Loic Mar'echal"
                },
                {
                    "authorId": "2212459901",
                    "name": "Maxime Wursch"
                },
                {
                    "authorId": "2094810509",
                    "name": "Ljiljana Dolamic"
                },
                {
                    "authorId": "2212460386",
                    "name": "Remi Sabonnadiere"
                },
                {
                    "authorId": "29898269",
                    "name": "Dimitri Percia David"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                },
                {
                    "authorId": "2143889977",
                    "name": "Vincent Lenders"
                }
            ]
        },
        {
            "paperId": "31c782e852e134025864394a69dbd618ed59d6dd",
            "title": "Case-Based Reasoning with Language Models for Classification of Logical Fallacies",
            "abstract": "The ease and speed of spreading misinformation and propaganda on the Web motivate the need to develop trustworthy technology for detecting fallacies in natural language arguments. However, state-of-the-art language modeling methods exhibit a lack of robustness on tasks like logical fallacy classification that require complex reasoning. In this paper, we propose a Case-Based Reasoning method that classifies new cases of logical fallacy by language-modeling-driven retrieval and adaptation of historical cases. We design four complementary strategies to enrich input representation for our model, based on external information about goals, explanations, counterarguments, and argument structure. Our experiments in in-domain and out-of-domain settings indicate that Case-Based Reasoning improves the accuracy and generalizability of language models. Our ablation studies suggest that representations of similar cases have a strong impact on the model performance, that models perform well with fewer retrieved cases, and that the size of the case database has a negligible effect on the performance. Finally, we dive deeper into the relationship between the properties of the retrieved cases and the model performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "be615ca215872b7c5bade919ec4307f12d8fe3ca",
            "title": "LLMs Perform Poorly at Concept Extraction in Cyber-security Research Literature",
            "abstract": "The cybersecurity landscape evolves rapidly and poses threats to organizations. To enhance resilience, one needs to track the latest developments and trends in the domain. It has been demonstrated that standard bibliometrics approaches show their limits in such a fast-evolving domain. For this purpose, we use large language models (LLMs) to extract relevant knowledge entities from cybersecurity-related texts. We use a subset of arXiv preprints on cybersecurity as our data and compare different LLMs in terms of entity recognition (ER) and relevance. The results suggest that LLMs do not produce good knowledge entities that reflect the cybersecurity context, but our results show some potential for noun extractors. For this reason, we developed a noun extractor boosted with some statistical analysis to extract specific and relevant compound nouns from the domain. Later, we tested our model to identify trends in the LLM domain. We observe some limitations, but it offers promising results to monitor the evolution of emergent trends.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2212459901",
                    "name": "Maxime Wursch"
                },
                {
                    "authorId": "2319814657",
                    "name": "Andrei Kucharavy"
                },
                {
                    "authorId": "29898269",
                    "name": "Dimitri Percia David"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "21326ddf1ec175b82b3d6f5ecdc3be56a4ca62da",
            "title": "Identifying Emerging Technologies and Leading Companies using Network Dynamics of Patent Clusters: a Cybersecurity Case Study",
            "abstract": "Strategic decisions rely heavily on non-scientific instrumentation to forecast emerging technologies and leading companies. Instead, we build a fast quantitative system with a small computational footprint to discover the most important technologies and companies in a given field, using generalisable methods applicable to any industry. With the help of patent data from the US Patent and Trademark Office, we first assign a value to each patent thanks to automated machine learning tools. We then apply network science to track the interaction and evolution of companies and clusters of patents (i.e. technologies) to create rankings for both sets that highlight important or emerging network nodes thanks to five network centrality indices. Finally, we illustrate our system with a case study based on the cybersecurity industry. Our results produce useful insights, for instance by highlighting (i) emerging technologies with a growing mean patent value and cluster size, (ii) the most influential companies in the field and (iii) attractive startups with few but impactful patents. Complementary analysis also provides evidence of decreasing marginal returns of research and development in larger companies in the cybersecurity industry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144863673",
                    "name": "Michael Tsesmelis"
                },
                {
                    "authorId": "2094810509",
                    "name": "Ljiljana Dolamic"
                },
                {
                    "authorId": "2615970",
                    "name": "Marcus M. Keupp"
                },
                {
                    "authorId": "29898269",
                    "name": "Dimitri Percia David"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "290cb5f3d1b9442f77924c2bd155b5a4ddef38dd",
            "title": "Efficient Collective Action for Tackling Time-Critical Cybersecurity Threats",
            "abstract": "\n The latency reduction between the discovery of vulnerabilities, the build-up, and the dissemination of cyberattacks has put significant pressure on cybersecurity professionals. For that, security researchers have increasingly resorted to collective action in order to reduce the time needed to characterize and tame outstanding threats. Here, we investigate how joining and contribution dynamics on Malware Information Sharing Platform (MISP), an open-source threat intelligence sharing platform, influence the time needed to collectively complete threat descriptions. We find that performance, defined as the capacity to characterize quickly a threat event, is influenced by (i) its own complexity (negatively), by (ii) collective action (positively), and by (iii) learning, information integration, and modularity (positively). Our results inform on how collective action can be organized at scale and in a modular way to overcome a large number of time-critical tasks, such as cybersecurity threats.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2464924",
                    "name": "S\u00e9bastien Gillard"
                },
                {
                    "authorId": "29898269",
                    "name": "Dimitri Percia David"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                },
                {
                    "authorId": "2450475",
                    "name": "T. Maillart"
                }
            ]
        },
        {
            "paperId": "4cea7fb4cbaf819760aed95654f645d4fce4602b",
            "title": "Beyond S-curves: Recurrent Neural Networks for Technology Forecasting",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1642188369",
                    "name": "Alexander Glavackij"
                },
                {
                    "authorId": "29898269",
                    "name": "Dimitri Percia David"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                },
                {
                    "authorId": "1910588458",
                    "name": "Angelika Romanou"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                }
            ]
        },
        {
            "paperId": "db7a69f36a792b2d642da7f0b3260e3c155b248e",
            "title": "Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments",
            "abstract": "The spread of misinformation, propaganda, and flawed argumentation has been amplified in the Internet era. Given the volume of data and the subtlety of identifying violations of argumentation norms, supporting information analytics tasks, like content moderation, with trustworthy methods that can identify logical fallacies is essential. In this paper, we formalize prior theoretical work on logical fallacies into a comprehensive three-stage evaluation framework of detection, coarse-grained, and fine-grained classification. We adapt existing evaluation datasets for each stage of the evaluation. We employ three families of robust and explainable methods based on prototype reasoning, instance-based reasoning, and knowledge injection. The methods combine language models with background knowledge and explainable mechanisms. Moreover, we address data sparsity with strategies for data augmentation and curriculum learning. Our three-stage framework natively consolidates prior datasets and methods from existing tasks, like propaganda detection, serving as an overarching evaluation testbed. We extensively evaluate these methods on our datasets, focusing on their robustness and explainability. Our results provide insight into the strengths and weaknesses of the methods on different components and fallacy classes, indicating that fallacy identification is a challenging task that may require specialized forms of reasoning to capture various classes. We share our open-source code and data on GitHub to support further work on logical fallacy identification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "1931556395",
                    "name": "Vishnu Priya Prasanna Venkatesh"
                },
                {
                    "authorId": "2069729843",
                    "name": "D. Deshpande"
                },
                {
                    "authorId": "2197068504",
                    "name": "Himanshu Rawlani"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        }
    ]
}