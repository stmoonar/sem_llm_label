{
    "authorId": "2242112674",
    "papers": [
        {
            "paperId": "3dfc034c4072da049f03f595dcc8841dd61b4562",
            "title": "FlowerFormer: Empowering Neural Architecture Encoding Using a Flow-Aware Graph Transformer",
            "abstract": "The success of a specific neural network architecture is closely tied to the dataset and task it tackles; there is no one-size-fits-all solution. Thus, considerable efforts have been made to quickly and accurately estimate the performances of neural architectures, without full training or evaluation, for given tasks and datasets. Neural architecture encoding has played a crucial role in the estimation, and graph-based methods, which treat an architecture as a graph, have shown prominent performance. For enhanced representation learning of neural architectures, we introduce FLOWERFORMER, a powerful graph transformer that in-corporates the information flows within a neural architecture. FLOWERFORMER consists of two key components: (a) bidirectional asynchronous message passing, inspired by the flows; (b) global attention built on flow-based masking. Our extensive experiments demonstrate the superiority of FLOWERFORMER over existing neural encoding methods, and its effectiveness extends beyond computer vision models to include graph neural networks and auto speech recognition models. Our code is available at h ttp://git hub. com/yOngjaenius/cvpR2024_FLOWERFormer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2292160236",
                    "name": "Dongyeong Hwang"
                },
                {
                    "authorId": "2261669977",
                    "name": "Hyunju Kim"
                },
                {
                    "authorId": "2268372451",
                    "name": "Sunwoo Kim"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "7791e09dfca5e0a1f94f2e31a39f799d92c4328e",
            "title": "Representative and Back-In-Time Sampling from Real-world Hypergraphs",
            "abstract": "Graphs are widely used for representing pairwise interactions in complex systems. Since such real-world graphs are large and often evergrowing, sampling subgraphs is useful for various purposes, including simulation, visualization, stream processing, representation learning, and crawling. However, many complex systems consist of group interactions (e.g., collaborations of researchers and discussions on online Q&A platforms) and thus are represented more naturally and accurately by hypergraphs than by ordinary graphs. Motivated by the prevalence of large-scale hypergraphs, we study the problem of sampling from real-world hypergraphs, aiming at answering (Q1) how can we measure the goodness of sub-hypergraphs, and (Q2) how can we efficiently find a \u201cgood\u201d sub-hypergraph. Regarding Q1, we distinguish between two goals: (a) representative sampling, which aims at capturing the characteristics of the input hypergraph, and (b) back-in-time sampling, which aims at closely approximating a past snapshot of the input time-evolving hypergraph. To evaluate the similarity of the sampled sub-hypergraph to the target (i.e., the input hypergraph or its past snapshot), we consider 10 graph-level, hyperedge-level, and node-level statistics. Regarding Q2, we first conduct a thorough analysis of various intuitive approaches using 11 real-world hypergraphs. Then, based on this analysis, we propose MiDaS and MiDaS-B, designed for representative sampling and back-in-time sampling, respectively. Regarding representative sampling, we demonstrate through extensive experiments that MiDaS, which employs a sampling bias toward high-degree nodes in hyperedge selection, is (a) Representative: finding overall the most representative samples among 15 considered approaches, (b) Fast: several orders of magnitude faster than the strongest competitors, and (c) Automatic: automatically tuning the degree of sampling bias. Regarding back-in-time sampling, we demonstrate that MiDaS-B inherits the strengths of MiDaS despite an additional challenge\u2014the unavailability of the target (i.e., past snapshot). It effectively handles this challenge by focusing on replicating universal evolutionary patterns, rather than directly replicating the target.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047035591",
                    "name": "Minyoung Choe"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2261454328",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "2292531478",
                    "name": "Woonsung Baek"
                },
                {
                    "authorId": "2292600102",
                    "name": "U. Kang"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "b528b5184b6191c6867d28e3d034645ec723274d",
            "title": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide",
            "abstract": "Higher-order interactions (HOIs) are ubiquitous in real-world complex systems and applications. Investigation of deep learning for HOIs, thus, has become a valuable agenda for the data mining and machine learning communities. As networks of HOIs are expressed mathematically as hypergraphs, hypergraph neural networks (HNNs) have emerged as a powerful tool for representation learning on hypergraphs. Given the emerging trend, we present the first survey dedicated to HNNs, with an in-depth and step-by-step guide. Broadly, the present survey overviews HNN architectures, training strategies, and applications. First, we break existing HNNs down into four design components: (i) input features, (ii) input structures, (iii) message-passing schemes, and (iv) training strategies. Second, we examine how HNNs address and learn HOIs with each of their components. Third, we overview the recent applications of HNNs in recommendation, bioinformatics and medical science, time series analysis, and computer vision. Lastly, we conclude with a discussion on limitations and future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268372451",
                    "name": "Sunwoo Kim"
                },
                {
                    "authorId": "2218932858",
                    "name": "Soo Yong Lee"
                },
                {
                    "authorId": "2294807430",
                    "name": "Yue Gao"
                },
                {
                    "authorId": "31736099",
                    "name": "Alessia Antelmi"
                },
                {
                    "authorId": "2294361631",
                    "name": "Mirko Polato"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "b6b8e083c42d6be3c80f59b33b380143b4800648",
            "title": "VilLain: Self-Supervised Learning on Homogeneous Hypergraphs without Features via Virtual Label Propagation",
            "abstract": "Group interactions arise in various scenarios in real-world systems: collaborations of researchers, co-purchases of products, and discussions in online Q&A sites, to name a few. Such higher-order relations are naturally modeled as hypergraphs, which consist of hyperedges (i.e., any-sized subsets of nodes). For hypergraphs, the challenge to learn node representation when features or labels are not available is imminent, given that (a) most real-world hypergraphs are not equipped with external features while (b) most existing approaches for hypergraph learning resort to additional information. Thus, in this work, we propose VilLain, a novel self-supervised hypergraph representation learning method based on the propagation of virtual labels (v-labels). Specifically, we learn for each node a sparse probability distribution over v-labels as its feature vector, and we propagate the vectors to construct the final node embeddings. Inspired by higher-order label homogeneity, which we discover in real-world hypergraphs, we design novel self-supervised loss functions for the v-labels to reproduce the higher-order structure-label pattern. We demonstrate that VilLain is: (a) Requirement-free: learning node embeddings without relying on node labels and features, (b) Versatile: giving embeddings that are not specialized to specific tasks but generalizable to diverse downstream tasks, and (c) Accurate: more accurate than its competitors for node classification, hyperedge prediction, node clustering, and node retrieval tasks. Our code and dataset are available at https://github.com/geon0325/VilLain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261454328",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "2218932858",
                    "name": "Soo Yong Lee"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "c5f4db49031cfdd5d71967ab0b66a44342c3e2c4",
            "title": "Feature Distribution on Graph Topology Mediates the Effect of Graph Convolution: Homophily Perspective",
            "abstract": "How would randomly shuffling feature vectors among nodes from the same class affect graph neural networks (GNNs)? The feature shuffle, intuitively, perturbs the dependence between graph topology and features (A-X dependence) for GNNs to learn from. Surprisingly, we observe a consistent and significant improvement in GNN performance following the feature shuffle. Having overlooked the impact of A-X dependence on GNNs, the prior literature does not provide a satisfactory understanding of the phenomenon. Thus, we raise two research questions. First, how should A-X dependence be measured, while controlling for potential confounds? Second, how does A-X dependence affect GNNs? In response, we (i) propose a principled measure for A-X dependence, (ii) design a random graph model that controls A-X dependence, (iii) establish a theory on how A-X dependence relates to graph convolution, and (iv) present empirical analysis on real-world graphs that align with the theory. We conclude that A-X dependence mediates the effect of graph convolution, such that smaller dependence improves GNN-based node classification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218932858",
                    "name": "Soo Yong Lee"
                },
                {
                    "authorId": "2268372451",
                    "name": "Sunwoo Kim"
                },
                {
                    "authorId": "2065674134",
                    "name": "Fanchen Bu"
                },
                {
                    "authorId": "2257360769",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2283301820",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "d3891e1d85ad3b4461b7beb423ad95ddeaaf7604",
            "title": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators",
            "abstract": "Hypergraphs are a natural and powerful choice for modeling group interactions in the real world, which are often referred to as higher-order networks. For example, when modeling collaboration networks, where collaborations can involve not just two but three or more people, employing hypergraphs allows us to explore beyond pairwise (dyadic) patterns and capture groupwise (polyadic) patterns. The mathematical complexity of hypergraphs offers both opportunities and challenges for learning and mining on hypergraphs, and hypergraph mining, which seeks to enhance our understanding of underlying systems through hypergraph modeling, gained increasing attention in research. Researchers have discovered various structural patterns in real-world hypergraphs, leading to the development of mining tools. Moreover, they have designed generators with the aim of reproducing and thereby shedding light on these patterns. In this survey, we provide a comprehensive overview of the current landscape of hypergraph mining, covering patterns, tools, and generators. We provide comprehensive taxonomies for them, and we also provide in-depth discussions to provide insights into future research on hypergraph mining.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2261454328",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "2065674134",
                    "name": "Fanchen Bu"
                },
                {
                    "authorId": "2279755955",
                    "name": "Tina Eliassi-Rad"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "e5ac87e2be84bac70247d031578c96331a559f2e",
            "title": "SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning",
            "abstract": "To detect anomalies in real-world graphs, such as social, email, and financial networks, various approaches have been developed. While they typically assume static input graphs, most real-world graphs grow over time, naturally represented as edge streams. In this context, we aim to achieve three goals: (a) instantly detecting anomalies as they occur, (b) adapting to dynamically changing states, and (c) handling the scarcity of dynamic anomaly labels. In this paper, we propose SLADE (Self-supervised Learning for Anomaly Detection in Edge Streams) for rapid detection of dynamic anomalies in edge streams, without relying on labels. SLADE detects the shifts of nodes into abnormal states by observing deviations in their interaction patterns over time. To this end, it trains a deep neural network to perform two self-supervised tasks: (a) minimizing drift in node representations and (b) generating long-term interaction patterns from short-term ones. Failure in these tasks for a node signals its deviation from the norm. Notably, the neural network and tasks are carefully designed so that all required operations can be performed in constant time (w.r.t. the graph size) in response to each new edge in the input stream. In dynamic anomaly detection across four real-world datasets, SLADE outperforms nine competing methods, even those leveraging label supervision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284689477",
                    "name": "Jongha Lee"
                },
                {
                    "authorId": "2268372451",
                    "name": "Sunwoo Kim"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "e7009b097d5c1aa18831c638717fbe21fa34afe8",
            "title": "Exploring Edge Probability Graph Models Beyond Edge Independency: Concepts, Analyses, and Algorithms",
            "abstract": "Desirable random graph models (RGMs) should (i) be tractable so that we can compute and control graph statistics, and (ii) generate realistic structures such as high clustering (i.e., high subgraph densities). A popular category of RGMs (e.g., Erdos-Renyi and stochastic Kronecker) outputs edge probabilities, and we need to realize (i.e., sample from) the edge probabilities to generate graphs. Typically, each edge (in)existence is assumed to be determined independently. However, with edge independency, RGMs theoretically cannot produce high subgraph densities unless they\"replicate\"input graphs. In this work, we explore realization beyond edge independence that can produce more realistic structures while ensuring high tractability. Specifically, we propose edge-dependent realization schemes called binding and derive closed-form tractability results on subgraph (e.g., triangle) densities in graphs generated with binding. We propose algorithms for graph generation with binding and parameter fitting of binding. We empirically validate that binding exhibits high tractability and generates realistic graphs with high clustering, significantly improving upon existing RGMs assuming edge independency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065674134",
                    "name": "Fanchen Bu"
                },
                {
                    "authorId": "2303612514",
                    "name": "Ruochen Yang"
                },
                {
                    "authorId": "2303402323",
                    "name": "Paul Bogdan"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "eed6cac597a7993767f78d0f55419f7e6b23fced",
            "title": "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs",
            "abstract": "Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple nodes with hyperedges, and better capturing the topology is essential for effective representation learning. Recent advances in generative self-supervised learning (SSL) suggest that hypergraph neural networks learned from generative self supervision have the potential to effectively encode the complex hypergraph topology. Designing a generative SSL strategy for hypergraphs, however, is not straightforward. Questions remain with regard to its generative SSL task, connection to downstream tasks, and empirical properties of learned representations. In light of the promises and challenges, we propose a novel generative SSL strategy for hypergraphs. We first formulate a generative SSL task on hypergraphs, hyperedge filling, and highlight its theoretical connection to node classification. Based on the generative SSL task, we propose a hypergraph SSL method, HypeBoy. HypeBoy learns effective general-purpose hypergraph representations, outperforming 16 baseline methods across 11 benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268372451",
                    "name": "Sunwoo Kim"
                },
                {
                    "authorId": "2160698854",
                    "name": "Shinhwan Kang"
                },
                {
                    "authorId": "2065674134",
                    "name": "Fanchen Bu"
                },
                {
                    "authorId": "2218932858",
                    "name": "Soo Yong Lee"
                },
                {
                    "authorId": "2257360769",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                }
            ]
        },
        {
            "paperId": "f012baef9f44b83d0b28b1843247004146e128e5",
            "title": "Sign is Not a Remedy: Multiset-to-Multiset Message Passing for Learning on Heterophilic Graphs",
            "abstract": "Graph Neural Networks (GNNs) have gained significant attention as a powerful modeling and inference method, especially for homophilic graph-structured data. To empower GNNs in heterophilic graphs, where adjacent nodes exhibit dissimilar labels or features, Signed Message Passing (SMP) has been widely adopted. However, there is a lack of theoretical and empirical analysis regarding the limitations of SMP. In this work, we unveil some potential pitfalls of SMP and their remedies. We first identify two limitations of SMP: undesirable representation update for multi-hop neighbors and vulnerability against oversmoothing issues. To overcome these challenges, we propose a novel message passing function called Multiset to Multiset GNN(M2M-GNN). Our theoretical analyses and extensive experiments demonstrate that M2M-GNN effectively alleviates the aforementioned limitations of SMP, yielding superior performance in comparison",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155276820",
                    "name": "Langzhang Liang"
                },
                {
                    "authorId": "2268372451",
                    "name": "Sunwoo Kim"
                },
                {
                    "authorId": "2242112674",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2298925809",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "2304445964",
                    "name": "Shirui Pan"
                },
                {
                    "authorId": "2237862935",
                    "name": "Yuan Qi"
                }
            ]
        }
    ]
}