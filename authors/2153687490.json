{
    "authorId": "2153687490",
    "papers": [
        {
            "paperId": "0b18bb8858a6e437b007cadea507a09946061383",
            "title": "Multimodal Graph Neural Architecture Search under Distribution Shifts",
            "abstract": "Multimodal graph neural architecture search (MGNAS) has shown great success for automatically designing the optimal multimodal graph neural network (MGNN) architecture by leveraging multimodal representation, crossmodal information and graph structure in one unified framework. However, existing MGNAS fails to handle distribution shifts that naturally exist in multimodal graph data, since the searched architectures inevitably capture spurious statistical correlations under distribution shifts. To solve this problem, we propose a novel Out-of-distribution Generalized Multimodal Graph Neural Architecture Search (OMG-NAS) method which optimizes the MGNN architecture with respect to its performance on decorrelated OOD data. Specifically, we propose a multimodal graph representation decorrelation strategy, which encourages the searched MGNN model to output representations that eliminate spurious correlations through iteratively optimizing the feature weights and controller. In addition, we propose a global sample weight estimator that facilitates the sharing of optimal sample weights learned from existing architectures. This design promotes the effective estimation of the sample weights for candidate MGNN architectures to generate decorrelated multimodal graph representations, concentrating more on the truly predictive relations between invariant features and ground-truth labels. Extensive experiments on real-world multimodal graph datasets demonstrate the superiority of our proposed method over SOTA baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293898555",
                    "name": "Jie Cai"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "1e80802a2fef00f2e10dfd4ab0ecce18ee2af82b",
            "title": "Exploring the Potential of Large Language Models in Graph Generation",
            "abstract": "Large language models (LLMs) have achieved great success in many fields, and recent works have studied exploring LLMs for graph discriminative tasks such as node classification. However, the abilities of LLMs for graph generation remain unexplored in the literature. Graph generation requires the LLM to generate graphs with given properties, which has valuable real-world applications such as drug discovery, while tends to be more challenging. In this paper, we propose LLM4GraphGen to explore the ability of LLMs for graph generation with systematical task designs and extensive experiments. Specifically, we propose several tasks tailored with comprehensive experiments to address key questions regarding LLMs' understanding of different graph structure rules, their ability to capture structural type distributions, and their utilization of domain knowledge for property-based graph generation. Our evaluations demonstrate that LLMs, particularly GPT-4, exhibit preliminary abilities in graph generation tasks, including rule-based and distribution-based generation. We also observe that popular prompting methods, such as few-shot and chain-of-thought prompting, do not consistently enhance performance. Besides, LLMs show potential in generating molecules with specific properties. These findings may serve as foundations for designing good LLMs based models for graph generation and provide valuable insights and further research.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2292399289",
                    "name": "Xu Chu"
                },
                {
                    "authorId": "2292430960",
                    "name": "Yuekui Yang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "35c07f14c5edd6dc87d0ad9ab9849bb6ab6055aa",
            "title": "Unsupervised Graph Neural Architecture Search with Disentangled Self-Supervision",
            "abstract": "The existing graph neural architecture search (GNAS) methods heavily rely on supervised labels during the search process, failing to handle ubiquitous scenarios where supervisions are not available. In this paper, we study the problem of unsupervised graph neural architecture search, which remains unexplored in the literature. The key problem is to discover the latent graph factors that drive the formation of graph data as well as the underlying relations between the factors and the optimal neural architectures. Handling this problem is challenging given that the latent graph factors together with architectures are highly entangled due to the nature of the graph and the complexity of the neural architecture search process. To address the challenge, we propose a novel Disentangled Self-supervised Graph Neural Architecture Search (DSGAS) model, which is able to discover the optimal architectures capturing various latent graph factors in a self-supervised fashion based on unlabeled graph data. Specifically, we first design a disentangled graph super-network capable of incorporating multiple architectures with factor-wise disentanglement, which are optimized simultaneously. Then, we estimate the performance of architectures under different factors by our proposed self-supervised training with joint architecture-graph disentanglement. Finally, we propose a contrastive search with architecture augmentations to discover architectures with factor-specific expertise. Extensive experiments on 11 real-world datasets demonstrate that the proposed model is able to achieve state-of-the-art performance against several baseline methods in an unsupervised manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "1993657377",
                    "name": "Guangyao Shen"
                },
                {
                    "authorId": "2279330465",
                    "name": "Shiqi Shen"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "7448e270ccfab5a2b4838129f78136731c496ab6",
            "title": "Data-Augmented Curriculum Graph Neural Architecture Search under Distribution Shifts",
            "abstract": "Graph neural architecture search (NAS) has achieved great success in designing architectures for graph data processing.However, distribution shifts pose great challenges for graph NAS, since the optimal searched architectures for the training graph data may fail to generalize to the unseen test graph data. The sole prior work tackles this problem by customizing architectures for each graph instance through learning graph structural information, but failed to consider data augmentation during training, which has been proven by existing works to be able to improve generalization.In this paper, we propose Data-augmented Curriculum Graph Neural Architecture Search (DCGAS), which learns an architecture customizer with good generalizability to data under distribution shifts. Specifically, we design an embedding-guided data generator, which can generate sufficient graphs for training to help the model better capture graph structural information. In addition, we design a two-factor uncertainty-based curriculum weighting strategy, which can evaluate the importance of data in enabling the model to learn key information in real-world distribution and reweight them during training. Experimental results on synthetic datasets and real datasets with distribution shifts demonstrate that our proposed method learns generalizable mappings and outperforms existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "9a0e9ee432acf902c297916622778f1e3cd18261",
            "title": "OOD-GNN: Out-of-Distribution Generalized Graph Neural Network: (Extended Abstract)",
            "abstract": "Graph neural networks (GNNs) have achieved impressive performance when testing and training graph data come from identical distribution. However, existing GNNs lack out-of-distribution generalization abilities so that their performance substantially degrades when there exist distribution shifts between testing and training graph data. To solve this problem, we propose an out-of-distribution generalized graph neural network (OOD-GNN) for achieving satisfactory performance on unseen testing graphs that have different distributions with training graphs. OOD-GNN employs a novel nonlinear graph representation decorrelation method utilizing random Fourier features, which encourages the model to eliminate the statistical dependence between relevant and irrelevant graph representations through iteratively optimizing the sample graph weights and graph encoder. The learned weights help the graph encoder to get rid of spurious correlations and, in turn, concentrate more on the true connection between learned discriminative graph representations and their ground-truth labels. We conduct extensive experiments to validate the out-of-distribution generalization abilities on two synthetic and 12 real-world datasets with distribution shifts. The results demonstrate that our proposed OOD-GNN significantly outperforms state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "b2e2e808181be431bcfeef57bd30cdf93dadfd30",
            "title": "Customized Cross-device Neural Architecture Search with Images",
            "abstract": "Cross-device scenarios have become increasingly common, where non-independently and identically distributed (non-IID) data is generated and stored in different devices. However, the existing cross-device NAS methods only search for a fixed architecture for different devices, neglecting that different devices have varying hardware characteristics and data distributions. In this paper, we propose a novel NAS framework that can customize the most suitable architecture for each device and its associated dataset. Specifically, we propose a decoupled data feature extractor and a device feature extractor to characterize the complex distributions of the different datasets and diverse hardware features. Then, we propose a prototype matcher to customize the operators and shape selection parameters of architectures. Experiments on ImageNet and CIFAR-10 show that our method can discover more efficient and effective architectures in cross-device scenarios than the existing approaches. To the best of our knowledge, this is the first exploration on customized cross-device NAS problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "b9d5e237ca163c719aed189d3fc8efc3748bc509",
            "title": "Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts",
            "abstract": "Dynamic graph neural networks (DyGNNs) currently struggle with handling distribution shifts that are inherent in dynamic graphs. Existing work on DyGNNs with out-of-distribution settings only focuses on the time domain, failing to handle cases involving distribution shifts in the spectral domain. In this paper, we discover that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain, and propose to study distribution shifts on dynamic graphs in the spectral domain for the first time. However, this investigation poses two key challenges: i) it is non-trivial to capture different graph patterns that are driven by various frequency components entangled in the spectral domain; and ii) it remains unclear how to handle distribution shifts with the discovered spectral patterns. To address these challenges, we propose Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts (SILD), which can handle distribution shifts on dynamic graphs by capturing and utilizing invariant and variant spectral patterns. Specifically, we first design a DyGNN with Fourier transform to obtain the ego-graph trajectory spectrums, allowing the mixed dynamic graph patterns to be transformed into separate frequency components. We then develop a disentangled spectrum mask to filter graph dynamics from various frequency components and discover the invariant and variant spectral patterns. Finally, we propose invariant spectral filtering, which encourages the model to rely on invariant patterns for generalization under distribution shifts. Experimental results on synthetic and real-world dynamic graph datasets demonstrate the superiority of our method for both node classification and link prediction tasks under distribution shifts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2273698217",
                    "name": "Zhou Qin"
                },
                {
                    "authorId": "2070076938",
                    "name": "Weigao Wen"
                },
                {
                    "authorId": "2273682025",
                    "name": "Hui Xue"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "235d6337eeb067042eb90c957a4380506a78c7b7",
            "title": "Curriculum Multi-Negative Augmentation for Debiased Video Grounding",
            "abstract": "Video Grounding (VG) aims to locate the desired segment from a video given a sentence query. Recent studies have found that current VG models are prone to over-rely the groundtruth moment annotation distribution biases in the training set. To discourage the standard VG model's behavior of exploiting such temporal annotation biases and improve the model generalization ability, we propose multiple negative augmentations in a hierarchical way, including cross-video augmentations from clip-/video-level, and self-shuffled augmentations with masks. These augmentations can effectively diversify the data distribution so that the model can make more reasonable predictions instead of merely fitting the temporal biases. However, directly adopting such data augmentation strategy may inevitably carry some noise shown in our cases, since not all of the handcrafted augmentations are semantically irrelevant to the groundtruth video. To further denoise and improve the grounding accuracy, we design a multi-stage curriculum strategy to adaptively train the standard VG model from easy to hard negative augmentations. Experiments on newly collected Charades-CD and ActivityNet-CD datasets demonstrate our proposed strategy can improve the performance of the base model on both i.i.d and o.o.d scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "82105675",
                    "name": "Xiaohan Lan"
                },
                {
                    "authorId": "48009996",
                    "name": "Yitian Yuan"
                },
                {
                    "authorId": "2191043236",
                    "name": "Hong Chen"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2750647",
                    "name": "Zequn Jie"
                },
                {
                    "authorId": "2152343776",
                    "name": "Lin Ma"
                },
                {
                    "authorId": "2135451624",
                    "name": "Zhi Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "240d132dac839eb2762ccf6f0b601885c7b33118",
            "title": "Adaptive Disentangled Transformer for Sequential Recommendation",
            "abstract": "Sequential recommendation aims at mining time-aware user interests through modeling sequential behaviors. Transformer, as an effective architecture designed to process sequential input data, has shown its superiority in capturing sequential relations for recommendation. Nevertheless, existing Transformer architectures lack explicit regularization for layer-wise disentanglement, which fails to take advantage of disentangled representation in recommendation and leads to suboptimal performance. In this paper, we study the problem of layer-wise disentanglement for Transformer architectures and propose the Adaptive Disentangled Transformer (ADT) framework, which is able to adaptively determine the optimal degree of disentanglement of attention heads within different layers. Concretely, we propose to encourage disentanglement by requiring the independence constraint via mutual information estimation over attention heads and employing auxiliary objectives to prevent the information from collapsing into useless noise. We further propose a progressive scheduler to adaptively adjust the weights controlling the degree of disentanglement via an evolutionary process. Extensive experiments on various real-world datasets demonstrate the effectiveness of our proposed ADT framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Yipeng Zhang"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2191043236",
                    "name": "Hong Chen"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "36edaddefa086075cdfab67a4916d27dbb6f4eea",
            "title": "Cross-domain Recommendation with Behavioral Importance Perception",
            "abstract": "Cross-domain recommendation (CDR) aims to leverage the source domain information to provide better recommendation for the target domain, which is widely adopted in recommender systems to alleviate the data sparsity and cold-start problems. However, existing CDR methods mostly focus on designing effective model architectures to transfer the source domain knowledge, ignoring the behavior-level effect during the loss optimization process, where behaviors regarding different aspects in the source domain may have different importance for the CDR model optimization. The ignorance of the behavior-level effect will cause the carefully designed model architectures ending up with sub-optimal parameters, which limits the recommendation performance. To tackle the problem, we propose a generic behavioral importance-aware optimization framework for cross-domain recommendation (BIAO). Specifically, we propose a behavioral perceptron which predicts the importance of each source behavior according to the corresponding item\u2019s global impact and local user-specific impact. The joint optimization process of the CDR model and the behavioral perceptron is formulated as a bi-level optimization problem. In the lower optimization, only the CDR model is updated with weighted source behavior loss and the target domain loss, while in the upper optimization, the behavioral perceptron is updated with implicit gradient from a developing dataset obtained through the proposed reorder-and-reuse strategy. Extensive experiments show that our proposed optimization framework consistently improves the performance of different cross-domain recommendation models in 7 cross-domain scenarios, demonstrating that our method can serve as a generic and powerful tool for cross-domain recommendation1.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191043236",
                    "name": "Hong Chen"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "3360722",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "2110219508",
                    "name": "Yuwei Zhou"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        }
    ]
}