{
    "authorId": "2121394809",
    "papers": [
        {
            "paperId": "0f84514e42c080efbc94f4aa2b2261e81d08ca24",
            "title": "Curricular Object Manipulation in LiDAR-based Object Detection",
            "abstract": "This paper explores the potential of curriculum learning in LiDAR-based 3D object detection by proposing a curricular object manipulation (COM) framework. The framework embeds the curricular training strategy into both the loss design and the augmentation process. For the loss design, we propose the COMLoss to dynamically predict object-level difficulties and emphasize objects of different difficulties based on training stages. On top of the widely-used augmentation technique called GT-Aug in Li-DAR detection tasks, we propose a novel COMAug strategy which first clusters objects in ground-truth database based on well-designed heuristics. Group-level difficulties rather than individual ones are then predicted and updated during training for stable results. Model performance and generalization capabilities can be improved by sampling and augmenting progressively more difficult objects into the training samples. Extensive experiments and ablation studies reveal the superior and generality of the proposed framework. The code is available at https://github.com/ZZY816/COM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121394809",
                    "name": "Ziyue Zhu"
                },
                {
                    "authorId": "2112721678",
                    "name": "Q. Meng"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2133842786",
                    "name": "Ke Wang"
                },
                {
                    "authorId": "2218779354",
                    "name": "Liujiang Yan"
                },
                {
                    "authorId": "2119197417",
                    "name": "Jian Yang"
                }
            ]
        },
        {
            "paperId": "2c816397fa1bb2848f65ec18f27a5ca89acfab72",
            "title": "Co-Salient Object Detection With Co-Representation Purification",
            "abstract": "Co-salient object detection (Co-SOD) aims at discovering the common objects in a group of relevant images. Mining a co-representation is essential for locating co-salient objects. Unfortunately, the current Co-SOD method does not pay enough attention that the information not related to the co-salient object is included in the co-representation. Such irrelevant information in the co-representation interferes with its locating of co-salient objects. In this paper, we propose a Co-Representation Purification (CoRP) method aiming at searching noise-free co-representation. We search a few pixel-wise embeddings probably belonging to co-salient regions. These embeddings constitute our co-representation and guide our prediction. For obtaining purer co-representation, we use the prediction to iteratively reduce irrelevant embeddings in our co-representation. Experiments on three datasets demonstrate that our CoRP achieves state-of-the-art performances on the benchmark datasets. Our source code is available at https://github.com/ZZY816/CoRP.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2121394809",
                    "name": "Ziyue Zhu"
                },
                {
                    "authorId": "2156122174",
                    "name": "Zhao Zhang"
                },
                {
                    "authorId": "2112752933",
                    "name": "Zheng Lin"
                },
                {
                    "authorId": "143900241",
                    "name": "Xing Sun"
                },
                {
                    "authorId": "1557350184",
                    "name": "Mingg-Ming Cheng"
                }
            ]
        },
        {
            "paperId": "d57dce722a76c3babce458d4fbdde62858cb2f80",
            "title": "Image Harmonization by Matching Regional References",
            "abstract": "To achieve visual consistency in composite images, recent image harmonization methods typically summarize the appearance pattern of global background and apply it to the global foreground without location discrepancy. However, for a real image, the appearances (illumination, color temperature, saturation, hue, texture, etc) of different regions can vary significantly. So previous methods, which transfer the appearance globally, are not optimal. Trying to solve this issue, we firstly match the contents between the foreground and background and then adaptively adjust every foreground location according to the appearance of its content-related background regions. Further, we design a residual reconstruction strategy, that uses the predicted residual to adjust the appearance, and the composite foreground to reserve the image details. Extensive experiments demonstrate the effectiveness of our method. The source code will be available publicly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121394809",
                    "name": "Ziyue Zhu"
                },
                {
                    "authorId": "2156122174",
                    "name": "Zhao Zhang"
                },
                {
                    "authorId": "2112752933",
                    "name": "Zheng Lin"
                },
                {
                    "authorId": "48967199",
                    "name": "Ruiqi Wu"
                },
                {
                    "authorId": "2070809958",
                    "name": "Zhi Chai"
                },
                {
                    "authorId": "18158517",
                    "name": "Chunle Guo"
                }
            ]
        }
    ]
}