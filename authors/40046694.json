{
    "authorId": "40046694",
    "papers": [
        {
            "paperId": "7f0f99b2863dc64f606f3d9c636452834478ccdb",
            "title": "TimeGraphs: Graph-based Temporal Reasoning",
            "abstract": "Many real-world systems exhibit temporal, dynamic behaviors, which are captured as time series of complex agent interactions. To perform temporal reasoning, current methods primarily encode temporal dynamics through simple sequence-based models. However, in general these models fail to efficiently capture the full spectrum of rich dynamics in the input, since the dynamics is not uniformly distributed. In particular, relevant information might be harder to extract and computing power is wasted for processing all individual timesteps, even if they contain no significant changes or no new information. Here we propose TimeGraphs, a novel approach that characterizes dynamic interactions as a hierarchical temporal graph, diverging from traditional sequential representations. Our approach models the interactions using a compact graph-based representation, enabling adaptive reasoning across diverse time scales. Adopting a self-supervised method, TimeGraphs constructs a multi-level event hierarchy from a temporal input, which is then used to efficiently reason about the unevenly distributed dynamics. This construction process is scalable and incremental to accommodate streaming data. We evaluate TimeGraphs on multiple datasets with complex, dynamic agent interactions, including a football simulator, the Resistance game, and the MOMA human activity dataset. The results demonstrate both robustness and efficiency of TimeGraphs on a range of temporal reasoning tasks. Our approach obtains state-of-the-art performance and leads to a performance increase of up to 12.2% on event prediction and recognition tasks over current approaches. Our experiments further demonstrate a wide array of capabilities including zero-shot generalization, robustness in case of data sparsity, and adaptability to streaming data flow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278426663",
                    "name": "Paridhi Maheshwari"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2257348997",
                    "name": "Yanan Wang"
                },
                {
                    "authorId": "48523334",
                    "name": "R. Sosi\u010d"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "0088c9f4d50706c7ab71efa13bcb4b42cf2058e2",
            "title": "PRODIGY: Enabling In-context Learning Over Graphs",
            "abstract": "In-context learning is the ability of a pretrained model to adapt to novel and diverse downstream tasks by conditioning on prompt examples, without optimizing any parameters. While large language models have demonstrated this ability, how in-context learning could be performed over graphs is unexplored. In this paper, we develop \\textbf{Pr}etraining \\textbf{O}ver \\textbf{D}iverse \\textbf{I}n-Context \\textbf{G}raph S\\textbf{y}stems (PRODIGY), the first pretraining framework that enables in-context learning over graphs. The key idea of our framework is to formulate in-context learning over graphs with a novel \\emph{prompt graph} representation, which connects prompt examples and queries. We then propose a graph neural network architecture over the prompt graph and a corresponding family of in-context pretraining objectives. With PRODIGY, the pretrained model can directly perform novel downstream classification tasks on unseen graphs via in-context learning. We provide empirical evidence of the effectiveness of our framework by showcasing its strong in-context learning performance on tasks involving citation networks and knowledge graphs. Our approach outperforms the in-context learning accuracy of contrastive pretraining baselines with hard-coded adaptation by 18\\% on average across all setups. Moreover, it also outperforms standard finetuning with limited data by 33\\% on average with in-context learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144862341",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2158172225",
                    "name": "Peng Chen"
                },
                {
                    "authorId": "2218033487",
                    "name": "Gregor Krvzmanc"
                },
                {
                    "authorId": "2106064673",
                    "name": "D. Zeng"
                },
                {
                    "authorId": "145419642",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "033275ccc2c7c5c38592ae893da0b5923cf90717",
            "title": "Neural Graph Reasoning: Complex Logical Query Answering Meets Graph Databases",
            "abstract": "Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves a far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs in a latent space. The task received a significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications. Refining the CLQA task, we introduce the concept of Neural Graph Databases (NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we design a graph store, a feature store, and further embed information in a latent embedding store using an encoder. Given a query, Neural Query Engine learns how to perform query planning and execution in order to efficiently retrieve the correct results by interacting with the Neural Graph Storage. Compared with traditional graph DBs, NGDBs allow for a flexible and unified modeling of features in diverse modalities using the embedding store. Moreover, when the graph is incomplete, they can provide robust retrieval of answers which a normal graph DB cannot recover. Finally, we point out promising directions, unsolved problems and applications of NGDB for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2066369448",
                    "name": "Mikhail Galkin"
                },
                {
                    "authorId": "1708906",
                    "name": "Michael Cochez"
                },
                {
                    "authorId": "9031926",
                    "name": "Zhaocheng Zhu"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "2b054eb2be8fbb261503370323e4442602eddeed",
            "title": "Fact Ranking over Large-Scale Knowledge Graphs with Reasoning Embedding Models",
            "abstract": "Knowledge graphs (KGs) serve as the backbone of many applications such as recommendation systems and question answering. All these applications require reasoning about the relevance of facts in a KG to downstream applications. In this work, we describe our efforts in building a solution to reason about the importance of facts over continuously updated industry-scale KGs. We focus on the problem of fact ranking and evaluate to what extent modern knowledge graph embedding (KGE) models provide a representation for addressing this problem. To this end, we discuss unique challenges associated with solving this task in industrial settings and evaluate how accurately different KGE models and text-based embedding models can solve the problem of fact ranking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "143661472",
                    "name": "A. Mousavi"
                },
                {
                    "authorId": "4047075",
                    "name": "Anil Pacaci"
                },
                {
                    "authorId": "2087061163",
                    "name": "S. R. Chowdhury"
                },
                {
                    "authorId": "2047146404",
                    "name": "J. Mohoney"
                },
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "730bab13c468df82c0f44d738dcdb3ac00410861",
            "title": "High dimensional, tabular deep learning with an auxiliary knowledge graph",
            "abstract": "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high d -dimensional features but limited n samples (i.e. d \u226b n ), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose P LATO , a method that achieves strong performance on tabular data with d \u226b n by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In P LATO , each input feature corresponds to a node in the auxiliary KG. In the MLP\u2019s first layer, each input feature also corresponds to a weight vector. P LATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP\u2019s first layer. P LATO captures this inductive bias by inferring the weight vector for each input feature from its corresponding node in the KG via a trainable message-passing function. Across 6 d \u226b n datasets, P LATO outperforms 13 state-of-the-art baselines by up to 10.19%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243501205",
                    "name": "Camilo Ruiz"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "8c769ef4f7dc800c16a29f249f8c4edac11284b1",
            "title": "Approximate Answering of Graph Queries",
            "abstract": "Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1708906",
                    "name": "Michael Cochez"
                },
                {
                    "authorId": "133811740",
                    "name": "Dimitrios Alivanistos"
                },
                {
                    "authorId": "2159004",
                    "name": "Erik Arakelyan"
                },
                {
                    "authorId": "65881464",
                    "name": "M. Berrendorf"
                },
                {
                    "authorId": "2064551388",
                    "name": "Daniel Daza"
                },
                {
                    "authorId": "2066369448",
                    "name": "Mikhail Galkin"
                },
                {
                    "authorId": "3051815",
                    "name": "Pasquale Minervini"
                },
                {
                    "authorId": "2780262",
                    "name": "Mathias Niepert"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                }
            ]
        },
        {
            "paperId": "c779710db42fa7dc0ebc6bf98a5d019cb9e8737c",
            "title": "Enabling tabular deep learning when d \u226b n with an auxiliary knowledge graph",
            "abstract": "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high $d$-dimensional features but limited $n$ samples (i.e. $d \\gg n$), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves strong performance on tabular data with $d \\gg n$ by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In PLATO, each input feature corresponds to a node in the auxiliary KG. In the MLP's first layer, each input feature also corresponds to a weight vector. PLATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP's first layer. PLATO captures this inductive bias by inferring the weight vector for each input feature from its corresponding node in the KG via a trainable message-passing function. Across 6 $d \\gg n$ datasets, PLATO outperforms 13 state-of-the-art baselines by up to 10.19%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123463839",
                    "name": "Camilo Ruiz"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "49454094",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "ce913026f693101e54d3ab9152e107034d81fce1",
            "title": "Holistic Evaluation of Language Models",
            "abstract": "Language models (LMs) like GPT\u20103, PaLM, and ChatGPT are the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of LMs. LMs can serve many purposes and their behavior should satisfy many desiderata. To navigate the vast space of potential scenarios and metrics, we taxonomize the space and select representative subsets. We evaluate models on 16 core scenarios and 7 metrics, exposing important trade\u2010offs. We supplement our core evaluation with seven targeted evaluations to deeply analyze specific aspects (including world knowledge, reasoning, regurgitation of copyrighted content, and generation of disinformation). We benchmark 30 LMs, from OpenAI, Microsoft, Google, Meta, Cohere, AI21 Labs, and others. Prior to HELM, models were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: all 30 models are now benchmarked under the same standardized conditions. Our evaluation surfaces 25 top\u2010level findings. For full transparency, we release all raw model prompts and completions publicly. HELM is a living benchmark for the community, continuously updated with new scenarios, metrics, and models https://crfm.stanford.edu/helm/latest/.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "145419642",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "150272855",
                    "name": "Rishi Bommasani"
                },
                {
                    "authorId": "2110585783",
                    "name": "Tony Lee"
                },
                {
                    "authorId": "2754804",
                    "name": "Dimitris Tsipras"
                },
                {
                    "authorId": "1914569491",
                    "name": "Dilara Soylu"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "9227100",
                    "name": "Yian Zhang"
                },
                {
                    "authorId": "22252150",
                    "name": "D. Narayanan"
                },
                {
                    "authorId": "3374063",
                    "name": "Yuhuai Wu"
                },
                {
                    "authorId": "32423266",
                    "name": "Ananya Kumar"
                },
                {
                    "authorId": "51149693",
                    "name": "Benjamin Newman"
                },
                {
                    "authorId": "2833699",
                    "name": "Binhang Yuan"
                },
                {
                    "authorId": "1748871792",
                    "name": "Bobby Yan"
                },
                {
                    "authorId": "2146064162",
                    "name": "Ce Zhang"
                },
                {
                    "authorId": "133749287",
                    "name": "Christian Cosgrove"
                },
                {
                    "authorId": "144783904",
                    "name": "Christopher D. Manning"
                },
                {
                    "authorId": "2061444681",
                    "name": "Christopher R'e"
                },
                {
                    "authorId": "1413421064",
                    "name": "Diana Acosta-Navas"
                },
                {
                    "authorId": "152951058",
                    "name": "Drew A. Hudson"
                },
                {
                    "authorId": "49456763",
                    "name": "E. Zelikman"
                },
                {
                    "authorId": "41152329",
                    "name": "Esin Durmus"
                },
                {
                    "authorId": "8759332",
                    "name": "Faisal Ladhak"
                },
                {
                    "authorId": "2047004093",
                    "name": "Frieda Rong"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "18307037",
                    "name": "Huaxiu Yao"
                },
                {
                    "authorId": "39597242",
                    "name": "Jue Wang"
                },
                {
                    "authorId": "50818255",
                    "name": "Keshav Santhanam"
                },
                {
                    "authorId": "4773175",
                    "name": "Laurel J. Orr"
                },
                {
                    "authorId": "2118604716",
                    "name": "Lucia Zheng"
                },
                {
                    "authorId": "2186981598",
                    "name": "Mert Yuksekgonul"
                },
                {
                    "authorId": "51903517",
                    "name": "Mirac Suzgun"
                },
                {
                    "authorId": "2182172863",
                    "name": "Nathan S. Kim"
                },
                {
                    "authorId": "2820009",
                    "name": "Neel Guha"
                },
                {
                    "authorId": "22193324",
                    "name": "Niladri S. Chatterji"
                },
                {
                    "authorId": "144112155",
                    "name": "O. Khattab"
                },
                {
                    "authorId": "2071773966",
                    "name": "Peter Henderson"
                },
                {
                    "authorId": "144862341",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "2121293578",
                    "name": "Ryan Chi"
                },
                {
                    "authorId": "46215055",
                    "name": "Sang Michael Xie"
                },
                {
                    "authorId": "2852106",
                    "name": "Shibani Santurkar"
                },
                {
                    "authorId": "25769960",
                    "name": "S. Ganguli"
                },
                {
                    "authorId": "2117567142",
                    "name": "Tatsunori Hashimoto"
                },
                {
                    "authorId": "8938047",
                    "name": "Thomas F. Icard"
                },
                {
                    "authorId": "123437034",
                    "name": "Tianyi Zhang"
                },
                {
                    "authorId": "113810201",
                    "name": "Vishrav Chaudhary"
                },
                {
                    "authorId": "2127971344",
                    "name": "William Wang"
                },
                {
                    "authorId": "2145429039",
                    "name": "Xuechen Li"
                },
                {
                    "authorId": "2054708905",
                    "name": "Yifan Mai"
                },
                {
                    "authorId": "49889860",
                    "name": "Yuhui Zhang"
                },
                {
                    "authorId": "2740047",
                    "name": "Yuta Koreeda"
                }
            ]
        },
        {
            "paperId": "06f3827ff5fd27d72390ae28532402d53ba69582",
            "title": "Prediction of Pedestrian Crossing Behavior Based on Surveillance Video",
            "abstract": "Prediction of pedestrian crossing behavior is an important issue faced by the realization of autonomous driving. The current research on pedestrian crossing behavior prediction is mainly based on vehicle camera. However, the sight line of vehicle camera may be blocked by other vehicles or the road environment, making it difficult to obtain key information in the scene. Pedestrian crossing behavior prediction based on surveillance video can be used in key road sections or accident-prone areas to provide supplementary information for vehicle decision-making, thereby reducing the risk of accidents. To this end, we propose a pedestrian crossing behavior prediction network for surveillance video. The network integrates pedestrian posture, local context and global context features through a new cross-stacked gated recurrence unit (GRU) structure to achieve accurate prediction of pedestrian crossing behavior. Applied onto the surveillance video dataset from the University of California, Berkeley to predict the pedestrian crossing behavior, our model achieves the best results regarding accuracy, F1 parameter, etc. In addition, we conducted experiments to study the effects of time to prediction and pedestrian speed on the prediction accuracy. This paper proves the feasibility of pedestrian crossing behavior prediction based on surveillance video. It provides a reference for the application of edge computing in the safety guarantee of automatic driving.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2109126619",
                    "name": "Xiao Zhou"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2146321698",
                    "name": "Tingting Zhang"
                },
                {
                    "authorId": "9211482",
                    "name": "Xingang Mou"
                },
                {
                    "authorId": "2156156836",
                    "name": "Yi He"
                },
                {
                    "authorId": "39063641",
                    "name": "Ching-yao Chan"
                }
            ]
        },
        {
            "paperId": "29abcf865613287c661385c39401424f709a3fda",
            "title": "Holistic Evaluation of Language Models",
            "abstract": "Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what's missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios when possible (87.5% of the time). This ensures metrics beyond accuracy don't fall to the wayside, and that trade-offs are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to analyze specific aspects (e.g. reasoning, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, 21 of which were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: now all 30 models have been densely benchmarked on the same core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2249641250",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "2223138553",
                    "name": "Rishi Bommasani"
                },
                {
                    "authorId": "2110585783",
                    "name": "Tony Lee"
                },
                {
                    "authorId": "2754804",
                    "name": "Dimitris Tsipras"
                },
                {
                    "authorId": "1914569491",
                    "name": "Dilara Soylu"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2250923503",
                    "name": "Yian Zhang"
                },
                {
                    "authorId": "2251007290",
                    "name": "Deepak Narayanan"
                },
                {
                    "authorId": "2250015839",
                    "name": "Yuhuai Wu"
                },
                {
                    "authorId": "32423266",
                    "name": "Ananya Kumar"
                },
                {
                    "authorId": "2250557275",
                    "name": "Benjamin Newman"
                },
                {
                    "authorId": "2250117174",
                    "name": "Binhang Yuan"
                },
                {
                    "authorId": "1748871792",
                    "name": "Bobby Yan"
                },
                {
                    "authorId": "2262511796",
                    "name": "Ce Zhang"
                },
                {
                    "authorId": "2251005170",
                    "name": "Christian Cosgrove"
                },
                {
                    "authorId": "2250402802",
                    "name": "Christopher D. Manning"
                },
                {
                    "authorId": "2250761261",
                    "name": "Christopher R\u00e9"
                },
                {
                    "authorId": "1413421064",
                    "name": "Diana Acosta-Navas"
                },
                {
                    "authorId": "152951058",
                    "name": "Drew A. Hudson"
                },
                {
                    "authorId": "49456763",
                    "name": "E. Zelikman"
                },
                {
                    "authorId": "41152329",
                    "name": "Esin Durmus"
                },
                {
                    "authorId": "8759332",
                    "name": "Faisal Ladhak"
                },
                {
                    "authorId": "2047004093",
                    "name": "Frieda Rong"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2250097082",
                    "name": "Huaxiu Yao"
                },
                {
                    "authorId": "2252087284",
                    "name": "Jue Wang"
                },
                {
                    "authorId": "50818255",
                    "name": "Keshav Santhanam"
                },
                {
                    "authorId": "2250741832",
                    "name": "Laurel J. Orr"
                },
                {
                    "authorId": "2118604716",
                    "name": "Lucia Zheng"
                },
                {
                    "authorId": "1387987315",
                    "name": "Mert Y\u00fcksekg\u00f6n\u00fcl"
                },
                {
                    "authorId": "51903517",
                    "name": "Mirac Suzgun"
                },
                {
                    "authorId": "2252992164",
                    "name": "Nathan Kim"
                },
                {
                    "authorId": "2820009",
                    "name": "Neel Guha"
                },
                {
                    "authorId": "22193324",
                    "name": "Niladri S. Chatterji"
                },
                {
                    "authorId": "144112155",
                    "name": "O. Khattab"
                },
                {
                    "authorId": "2250986700",
                    "name": "Peter Henderson"
                },
                {
                    "authorId": "144862341",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "2121293578",
                    "name": "Ryan Chi"
                },
                {
                    "authorId": "2114080615",
                    "name": "Sang Michael Xie"
                },
                {
                    "authorId": "2852106",
                    "name": "Shibani Santurkar"
                },
                {
                    "authorId": "2242939863",
                    "name": "Surya Ganguli"
                },
                {
                    "authorId": "2117567142",
                    "name": "Tatsunori Hashimoto"
                },
                {
                    "authorId": "2251009433",
                    "name": "Thomas Icard"
                },
                {
                    "authorId": "2256233130",
                    "name": "Tianyi Zhang"
                },
                {
                    "authorId": "113810201",
                    "name": "Vishrav Chaudhary"
                },
                {
                    "authorId": "2127971344",
                    "name": "William Wang"
                },
                {
                    "authorId": "2250724754",
                    "name": "Xuechen Li"
                },
                {
                    "authorId": "2054708905",
                    "name": "Yifan Mai"
                },
                {
                    "authorId": "2273913293",
                    "name": "Yuhui Zhang"
                },
                {
                    "authorId": "2740047",
                    "name": "Yuta Koreeda"
                }
            ]
        }
    ]
}