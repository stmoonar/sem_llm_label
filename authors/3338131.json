{
    "authorId": "3338131",
    "papers": [
        {
            "paperId": "8d12b3065af0873503bc70c4c54b856cf493dd4a",
            "title": "Cross-lingual Transfer and Multilingual Learning for Detecting Harmful Behaviour in African Under-Resourced Language Dialogue",
            "abstract": "Most harmful dialogue detection models are developed for high-resourced languages. Consequently, users who speak under-resourced languages cannot fully benefit from these models in terms of usage, development, detection and mitigation of harmful dialogue utterances. Our work aims at detecting harmful utterances in under-resourced African languages. We leverage transfer learning using pretrained models trained with multilingual embeddings to develop a cross-lingual model capable of detecting harmful content across various African languages. We first fine-tune a harmful dialogue detection model on a selected African dialogue dataset. Additionally, we fine-tune a model on a combined dataset in some African languages to develop a multilingual harmful dialogue detection model. We then evaluate the cross-lingual model\u2019s ability to generalise to an unseen African language by performing harmful dialogue detection in an under-resourced language not present during pretraining or fine-tuning. We evaluate our models on the test datasets. We show that our best performing models achieve impressive results in terms of F1 score. Finally, we discuss the results and limitations of our work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "98725872",
                    "name": "T. Ajayi"
                },
                {
                    "authorId": "2061752049",
                    "name": "Mihael Arcan"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "ea23b1f298b5b50ffc105bb71adad53f65255be0",
            "title": "A Hybrid Approach to Aspect Based Sentiment Analysis Using Transfer Learning",
            "abstract": "Aspect-Based Sentiment Analysis ( ABSA) aims to identify terms or multiword expressions (MWEs) on which sentiments are expressed and the sentiment polarities associated with them. The development of supervised models has been at the forefront of research in this area. However, training these models requires the availability of manually annotated datasets which is both expensive and time-consuming. Furthermore, the available annotated datasets are tailored to a specific domain, language, and text type. In this work, we address this notable challenge in current state-of-the-art ABSA research. We propose a hybrid approach for Aspect Based Sentiment Analysis using transfer learning. The approach focuses on generating weakly-supervised annotations by exploiting the strengths of both large language models (LLM) and traditional syntactic dependencies. We utilise syntactic dependency structures of sentences to complement the annotations generated by LLMs, as they may overlook domain-specific aspect terms. Extensive experimentation on multiple datasets is performed to demonstrate the efficacy of our hybrid method for the tasks of aspect term extraction and aspect sentiment classification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293395635",
                    "name": "Gaurav Negi"
                },
                {
                    "authorId": "2293396085",
                    "name": "Rajdeep Sarkar"
                },
                {
                    "authorId": "3203390",
                    "name": "Omnia Zayed"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "0872a3880b471580c1676f25d96c323ffeb2dff1",
            "title": "Empowering recommender systems using automatically generated Knowledge Graphs and Reinforcement Learning",
            "abstract": "Personalized recommendations have a growing importance in direct marketing, which motivates research to enhance customer experiences by knowledge graph (KG) applications. For example, in financial services, companies may benefit from providing relevant financial articles to their customers to cultivate relationships, foster client engagement and promote informed financial decisions. While several approaches center on KG-based recommender systems for improved content, in this study we focus on interpretable KG-based recommender systems for decision making.To this end, we present two knowledge graph-based approaches for personalized article recommendations for a set of customers of a large multinational financial services company. The first approach employs Reinforcement Learning and the second approach uses the XGBoost algorithm for recommending articles to the customers. Both approaches make use of a KG generated from both structured (tabular data) and unstructured data (a large body of text data).Using the Reinforcement Learning-based recommender system we could leverage the graph traversal path leading to the recommendation as a way to generate interpretations (Path Directed Reasoning (PDR)). In the XGBoost-based approach, one can also provide explainable results using post-hoc methods such as SHAP (SHapley Additive exPlanations) and ELI5 (Explain Like I am Five).Importantly, our approach offers explainable results, promoting better decision-making. This study underscores the potential of combining advanced machine learning techniques with KG-driven insights to bolster experience in customer relationship management.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059684744",
                    "name": "Ghanshyam Verma"
                },
                {
                    "authorId": "2057928346",
                    "name": "Shovon Sengupta"
                },
                {
                    "authorId": "2222829873",
                    "name": "Simon Simanta"
                },
                {
                    "authorId": "2145302130",
                    "name": "Huan Chen"
                },
                {
                    "authorId": "6654428",
                    "name": "J. Perge"
                },
                {
                    "authorId": "70992470",
                    "name": "Devishree Pillai"
                },
                {
                    "authorId": "1689974",
                    "name": "John P. McCrae"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "0fc6c37c01f789b8acd83d9d35a1ff843ebb9ab7",
            "title": "Identifying FrameNet Lexical Semantic Structures for Knowledge Graph Extraction from Financial Customer Interactions",
            "abstract": "We explore the use of the well established lexical resource and theory of the Berkeley FrameNet project to support the creation of a domain-specific knowledge graph in the financial domain, more precisely from financial customer interactions. We introduce a domain independent and unsupervised method that can be used across multiple applications, and test our experiments on the financial domain. We use an existing tool for term extraction and taxonomy generation in combination with information taken from FrameNet. By using principles from frame semantic theory, we show that we can connect domain-specific terms with their semantic concepts (semantic frames) and their properties (frame elements) to enrich knowledge about these terms, in order to improve the customer experience in customer-agent dialogue settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49740832",
                    "name": "C\u00e9cile Robin"
                },
                {
                    "authorId": "2265495881",
                    "name": "Atharva Kulkarni"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "1c355e5e0a5825e40cacb82a94000d89ca884e5d",
            "title": "CURED4NLG: A Dataset for Table-to-Text Generation",
            "abstract": "We introduce CURED 4 NLG , a dataset for the task of table-to-text generation focusing on the public health domain. The dataset consists of 280 pairs of tables and documents extracted from weekly epidemiological reports published by the World Health Organisation (WHO). The tables report the number of cases and deaths from COVID-19, while the documents describe global and regional updates in English text. Along with the releasing the dataset, we present outputs from three different baselines for the task of table-to-text generation. The first is based on a manually defined template and the other two on end-to-end transformer-based models. Our results suggest that end-to-end models can learn a template-like structure of the reports to produce fluent sentences, but may contain many factual errors especially related to numerical values.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1379775644",
                    "name": "Nivranshu Pasricha"
                },
                {
                    "authorId": "2061752049",
                    "name": "Mihael Arcan"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "458e17d2c67c8a7474ea5a6375d4a5d56273170c",
            "title": "CALM-Bench: A Multi-task Benchmark for Evaluating Causality-Aware Language Models",
            "abstract": "Causal reasoning is a critical component of human cognition and is required across a range of question-answering (QA) tasks (such as abductive reasoning, commonsense QA, and procedural reasoning). Research on causal QA has been underdefined, task-specific, and limited in complexity. Recent advances in foundation language models (such as BERT, ERNIE, and T5) have shown the efficacy of pre-trained models across diverse QA tasks. However, there is limited research exploring the causal reasoning capabilities of those language models and no standard evaluation benchmark. To unify causal QA research, we propose CALM-Bench, a multi-task benchmark for evaluating causality-aware language models (CALM). We present a standardized definition of causal QA tasks and show empirically that causal reasoning can be generalized and transferred across different QA tasks. Additionally, we share a strong multi-task baseline model which outperforms single-task fine-tuned models on the CALM-Bench tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1491746798",
                    "name": "Dhairya Dalal"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                },
                {
                    "authorId": "1951431",
                    "name": "Mihael Arcan"
                }
            ]
        },
        {
            "paperId": "9fb06a59b33240cd4e5574a02a0eb3782c342b1b",
            "title": "Multimodal Offensive Meme Classification with Natural Language Inference",
            "abstract": "Multimodal offensive meme classification is a challenging classification task, where a multi-modal meme needs to be classified as offensive or not offensive based on the provided text and image. A well-known approach to solving this problem is to fuse the text and image features captured either by the text and image encoder or by a transformer architecture to form a multimodal meme representation. In our work, we argue that the image features captured by the image encoder are unable to capture the abstract representation like language. Hence, we propose to transform the multimodal offensive meme classification task into an unimodal of-fensive text classification task for which we leverage the Natural Language Inference (NLI) task. Firstly, we carefully generate image cap-tions using an off-the-shelf image captioner and automatically transcribed the meme as if it was explained to a visually impaired individual. Later, these meme transcriptions and labels (image-text-label) have been transformed into NLI format (premise-hypothesis-label). To evaluate our approach, we run benchmark analysis on Memotion, Hateful memes and Multi-OFF datasets (in their NLI format) using four baselines finetuned on Emotion Analysis, Sentiment Analysis, Offensive tweet Classification, and NLI task. We achieve state-of-the-art (SOTA) results for the MultiOFF dataset and close to SOTA results for Memotion while achieving competent evaluation scores on the Hateful Memes dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1654096445",
                    "name": "Shardul Suryawanshi"
                },
                {
                    "authorId": "2061752049",
                    "name": "Mihael Arcan"
                },
                {
                    "authorId": "2261397149",
                    "name": "Suzanne Little"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "b811f895b3093b3d6716ecf99c94e295259c3bfa",
            "title": "Intent Classification by the Use of Automatically Generated Knowledge Graphs",
            "abstract": "Intent classification is an essential task for goal-oriented dialogue systems for automatically identifying customers\u2019 goals. Although intent classification performs well in general settings, domain-specific user goals can still present a challenge for this task. To address this challenge, we automatically generate knowledge graphs for targeted data sets to capture domain-specific knowledge and leverage embeddings trained on these knowledge graphs for the intent classification task. As existing knowledge graphs might not be suitable for a targeted domain of interest, our automatic generation of knowledge graphs can extract the semantic information of any domain, which can be incorporated within the classification process. We compare our results with state-of-the-art pre-trained sentence embeddings and our evaluation of three data sets shows improvement in the intent classification task in terms of precision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951431",
                    "name": "Mihael Arcan"
                },
                {
                    "authorId": "2124980567",
                    "name": "Sampritha H. Manjunath"
                },
                {
                    "authorId": "49740832",
                    "name": "C\u00e9cile Robin"
                },
                {
                    "authorId": "2059684744",
                    "name": "Ghanshyam Verma"
                },
                {
                    "authorId": "70992470",
                    "name": "Devishree Pillai"
                },
                {
                    "authorId": "2217080114",
                    "name": "Simon Sarkar"
                },
                {
                    "authorId": "2106345977",
                    "name": "Sourav Dutta"
                },
                {
                    "authorId": "3068079",
                    "name": "H. Assem"
                },
                {
                    "authorId": "1738599770",
                    "name": "John P. Mccrae"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "3c097927b457e2f89252978732e144fec7e52288",
            "title": "Linghub2: Language Resource Discovery Tool for Language Technologies",
            "abstract": "Language resources are a key component of natural language processing and related research and applications. Users of language resources have different needs in terms of format, language, topics, etc. for the data they need to use. Linghub (McCrae and Cimiano, 2015) was first developed for this purpose, using the capabilities of linked data to represent metadata, and tackling the heterogeneous metadata issue. Linghub aimed at helping language resources and technology users to easily find and retrieve relevant data, and identify important information on access, topics, etc. This work describes a rejuvenation and modernisation of the 2015 platform into using a popular open source data management system, DSpace, as foundation. The new platform, Linghub2, contains updated and extended resources, more languages offered, and continues the work towards homogenisation of metadata through conversions, through linkage to standardisation strategies and community groups, such as the Open Digital Rights Language (ODRL) community group.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49740832",
                    "name": "C\u00e9cile Robin"
                },
                {
                    "authorId": "2065863314",
                    "name": "G. V. Suresh"
                },
                {
                    "authorId": "69466430",
                    "name": "V\u00edctor Rodr\u00edguez Doncel"
                },
                {
                    "authorId": "1689974",
                    "name": "John P. McCrae"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                }
            ]
        },
        {
            "paperId": "656665216d18440e9908e4be8684983bff192981",
            "title": "Toward an Integrative Approach for Making Sense Distinctions",
            "abstract": "Word senses are the fundamental unit of description in lexicography, yet it is rarely the case that different dictionaries reach any agreement on the number and definition of senses in a language. With the recent rise in natural language processing and other computational approaches there is an increasing demand for quantitatively validated sense catalogues of words, yet no consensus methodology exists. In this paper, we look at four main approaches to making sense distinctions: formal, cognitive, distributional, and intercultural and examine the strengths and weaknesses of each approach. We then consider how these may be combined into a single sound methodology. We illustrate this by examining two English words, \u201cwing\u201d and \u201cfish,\u201d using existing resources for each of these four approaches and illustrate the weaknesses of each. We then look at the impact of such an integrated method and provide some future perspectives on the research that is necessary to reach a principled method for making sense distinctions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1689974",
                    "name": "John P. McCrae"
                },
                {
                    "authorId": "1515519789",
                    "name": "Theodorus Fransen"
                },
                {
                    "authorId": "35183492",
                    "name": "Sina Ahmadi"
                },
                {
                    "authorId": "3338131",
                    "name": "P. Buitelaar"
                },
                {
                    "authorId": "120873790",
                    "name": "Koustava Goswami"
                }
            ]
        }
    ]
}