{
    "authorId": "2179558887",
    "papers": [
        {
            "paperId": "773bb2a832db8eb52aa91df313af192dfa55dffd",
            "title": "A True-to-the-model Axiomatic Benchmark for Graph-based Explainers",
            "abstract": "Regulators, researchers, and practitioners recognize the urgency of explainability in artificial intelligence systems, including the ones based on machine learning for graph-structured data. Despite the large number of proposals, however, a common understanding of what constitutes a good explanation is still lacking: different explainers often arrive at different conclusions on the same problem instance, making it hard for practitioners to choose among them. Furthermore, explainers often produce explanations through opaque logic hard to understand and assess \u2013 ironically mirroring the black box nature they aim to elucidate. Recent proposals in the literature for benchmarking graph-based explainers typically involve embedding specific logic into data, training a black-box model, and then empirically assessing how well the explanation matches the embedded logic, i.e., they test truthfulness to the data . In contrast, we propose a true-to-the-model axiomatic framework for auditing explainers in the task of node classification on graphs. Our proposal hinges on the fundamental idea that an explainer should discern if a model relies on a particular feature for classifying a node. Building on this concept, we develop three types of white-box classifiers, with clear internal logic, that are relevant in real-world applications. We then formally prove that the set of features that can induce a change in the classification correctly corresponds to a ground-truth set of predefined important features. This property allows us to use the white-box classifiers to build a testing framework. We apply this framework to both synthetic and real data and evaluate various state-of-the-art explainers, thus characterizing their behavior. Our findings highlight how explainers often react in a rather counter-intuitive fashion to technical details that might be easily overlooked. Our approach offers valuable insights and recommended practices for selecting the right explainer given the task at hand, and for developing new methods for explaining graph-learning models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47286020",
                    "name": "Corrado Monti"
                },
                {
                    "authorId": "46726748",
                    "name": "P. Bajardi"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "2735649",
                    "name": "A. Panisson"
                },
                {
                    "authorId": "2305344957",
                    "name": "Alan Perotti"
                }
            ]
        },
        {
            "paperId": "abbdafcdff1a980173f565138c0f9069280f2424",
            "title": "Fair Representation in Submodular Subset Selection: A Pareto Optimization Approach",
            "abstract": "Many machine learning applications, such as feature selection, recommendation, and social advertising, require the joint optimization of the global utility and the representativeness for different groups of items or users. To meet such requirements, we propose a novel multi-objective combinatorial optimization problem called Submodular Maximization with Fair Representation ( SMFR ), which selects subsets from a ground set, subject to a knapsack or matroid constraint, to maximize a submodular ( utility ) function f as well as a set of d submodular ( representativeness ) functions g 1 , . . . , g d . We show that the maximization of f might conflict with the maximization of g 1 , . . . , g d , so that no single solution can optimize all these objectives at the same time. Therefore, we propose a Pareto optimization approach to SMFR , which finds a set of solutions to approximate all Pareto-optimal solutions with different trade-offs between the objectives. Our method converts an instance of SMFR into several submodular cover instances by adjusting the weights of the objective functions; then it computes a set of solutions by running the greedy algorithm on each submodular cover instance. We prove that our method provides approximation guarantees for SMFR under knapsack or matroid constraints. Finally, we demonstrate the effectiveness of SMFR and our proposed approach in two real-world problems: maximum coverage and recommendation .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2314165264",
                    "name": "Adriano Fazzone"
                },
                {
                    "authorId": "2314335097",
                    "name": "Yanhao Wang"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                }
            ]
        },
        {
            "paperId": "ba1a77c3a93854461be2fe642b1952eaf3e27bd7",
            "title": "Fairness in Algorithmic Recourse Through the Lens of Substantive Equality of Opportunity",
            "abstract": "Algorithmic recourse -- providing recommendations to those affected negatively by the outcome of an algorithmic system on how they can take action and change that outcome -- has gained attention as a means of giving persons agency in their interactions with artificial intelligence (AI) systems. Recent work has shown that even if an AI decision-making classifier is ``fair'' (according to some reasonable criteria), recourse itself may be unfair due to differences in the initial circumstances of individuals, compounding disparities for marginalized populations and requiring them to exert more effort than others. There is a need to define more methods and metrics for evaluating fairness in recourse that span a range of normative views of the world, and specifically those that take into account time. Time is a critical element in recourse because the longer it takes an individual to act, the more the setting may change due to model or data drift. This paper seeks to close this research gap by proposing two notions of fairness in recourse that are in normative alignment with substantive equality of opportunity, and that consider time. The first considers the (often repeated) effort individuals exert per successful recourse event, and the second considers time per successful recourse event. Building upon an agent-based framework for simulating recourse, this paper demonstrates how much effort is needed to overcome disparities in initial circumstances. We then proposes an intervention to improve the fairness of recourse by rewarding effort, and compare it to existing strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239195821",
                    "name": "Andrew Bell"
                },
                {
                    "authorId": "2239195588",
                    "name": "Jo\u00e3o Fonseca"
                },
                {
                    "authorId": "89449460",
                    "name": "Carlo Abrate"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                }
            ]
        },
        {
            "paperId": "6a5741e39a3c0b9ba1eaab2c890bbc471e40395e",
            "title": "Counterfactual Explanations for Graph Classification Through the Lenses of Density",
            "abstract": "Counterfactual examples have emerged as an effective approach to produce simple and understandable post-hoc explanations. In the context of graph classification, previous work has focused on generating counterfactual explanations by manipulating the most elementary units of a graph, i.e., removing an existing edge, or adding a non-existing one. In this paper, we claim that such language of explanation might be too fine-grained, and turn our attention to some of the main characterizing features of real-world complex networks, such as the tendency to close triangles, the existence of recurring motifs, and the organization into dense modules. We thus define a general density-based counterfactual search framework to generate instance-level counterfactual explanations for graph classifiers, which can be instantiated with different notions of dense substructures. In particular, we show two specific instantiations of this general framework: a method that searches for counterfactual graphs by opening or closing triangles, and a method driven by maximal cliques. We also discuss how the general method can be instantiated to exploit any other notion of dense substructures, including, for instance, a given taxonomy of nodes. We evaluate the effectiveness of our approaches in 7 brain network datasets and compare the counterfactual statements generated according to several widely-used metrics. Results confirm that adopting a semantic-relevant unit of change like density is essential to define versatile and interpretable counterfactual explanation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "89449460",
                    "name": "Carlo Abrate"
                },
                {
                    "authorId": "39046274",
                    "name": "Giulia Preti"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                }
            ]
        },
        {
            "paperId": "ada4eca39f9a2bf6b944bb7ba6d1322a71e1bff2",
            "title": "Fast and Effective GNN Training with Linearized Random Spanning Trees",
            "abstract": "We present a new effective and scalable framework for training GNNs in node classification tasks, based on the effective resistance, a powerful tool solidly rooted in graph theory. Our approach progressively refines the GNN weights on an extensive sequence of random spanning trees, suitably transformed into path graphs that retain essential topological and node information of the original graph. The sparse nature of these path graphs substantially lightens the computational burden of GNN training. This not only enhances scalability but also effectively addresses common issues like over-squashing, over-smoothing, and performance deterioration caused by overfitting in small training set regimes. We carry out an extensive experimental investigation on a number of real-world graph benchmarks, where we apply our framework to graph convolutional networks, showing simultaneous improvement of both training speed and test accuracy over a wide pool of representative baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "1895207",
                    "name": "C. Gentile"
                },
                {
                    "authorId": "2735649",
                    "name": "A. Panisson"
                },
                {
                    "authorId": "2823120",
                    "name": "Fabio Vitale"
                }
            ]
        },
        {
            "paperId": "c521a86db8ec9da3f2c68e3a44c65856cf902b75",
            "title": "A Survey on the Densest Subgraph Problem and its Variants",
            "abstract": "The Densest Subgraph Problem requires us to find, in a given graph, a subset of vertices whose induced subgraph maximizes a measure of density. The problem has received a great deal of attention in the algorithmic literature since the early 1970s, with many variants proposed and many applications built on top of this basic definition. Recent years have witnessed a revival of research interest in this problem with several important contributions, including some groundbreaking results, published in 2022 and 2023. This survey provides a deep overview of the fundamental results and an exhaustive coverage of the many variants proposed in the literature, with a special attention to the most recent results. The survey also presents a comprehensive overview of applications and discusses some interesting open problems for this evergreen research topic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52523225",
                    "name": "Tommaso Lanciano"
                },
                {
                    "authorId": "2594516",
                    "name": "Atsushi Miyauchi"
                },
                {
                    "authorId": "2716427",
                    "name": "Adriano Fazzone"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                }
            ]
        },
        {
            "paperId": "e91410e3346b7b65afa4459fcbf189632d6a9739",
            "title": "Setting the Right Expectations: Algorithmic Recourse Over Time",
            "abstract": "Algorithmic systems are often called upon to assist in high-stakes decision making. In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention. The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context. Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date \u2014 when the context might have changed. This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals. In this work we propose an agent-based simulation framework for studying the effects of a continuously changing environment on algorithmic recourse. In particular, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment. Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time. Consequently, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents\u2019 effort.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239195588",
                    "name": "Jo\u00e3o Fonseca"
                },
                {
                    "authorId": "2239195821",
                    "name": "Andrew Bell"
                },
                {
                    "authorId": "89449460",
                    "name": "Carlo Abrate"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                }
            ]
        },
        {
            "paperId": "24b407c217e1465b4eb152ddc103a920f1d6cf62",
            "title": "Discovering Polarization Niches via Dense Subgraphs with Attractors and Repulsers",
            "abstract": "\n Detecting niches of polarization in social media is a first step towards deploying mitigation strategies and avoiding radicalization. In this paper, we model polarization niches as close-knit dense communities of users, which are under the influence of some well-known sources of misinformation, and isolated from authoritative information sources. Based on this intuition we define the problem of finding a subgraph that maximizes a combination of (\n i\n ) density, (\n ii\n ) proximity to a small set of nodes\n A\n (named\n Attractors\n ), and (\n iii\n ) distance from another small set of nodes\n R\n (named\n Repulsers\n ).\n \n \n Deviating from the bulk of the literature on detecting polarization, we do not exploit text mining or sentiment analysis, nor we track the propagation of information: we only exploit the network structure and the background knowledge about the sets\n A\n and\n R\n , which are given as input. We build on recent algorithmic advances in supermodular maximization to provide an iterative greedy algorithm, dubbed\n Down in the Hollow\n (dith), that converges fast to a near-optimal solution. Thanks to a novel theoretical upper bound, we are able to equip dith with a practical device that allows to terminate as soon as a solution with a user-specified approximation factor is found, making our algorithm very efficient in practice. Our experiments on very large networks confirm that our algorithm always returns a solution with an approximation factor better or equal to the one specified by the user, and it is scalable. Our case-studies in polarized settings, confirm the usefulness of our algorithmic primitive in detecting polarization niches.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2716427",
                    "name": "Adriano Fazzone"
                },
                {
                    "authorId": "52523225",
                    "name": "Tommaso Lanciano"
                },
                {
                    "authorId": "2061150134",
                    "name": "R. Denni"
                },
                {
                    "authorId": "2023899",
                    "name": "Charalampos E. Tsourakakis"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                }
            ]
        },
        {
            "paperId": "72e41c76bfb8b2c1e42b4a5297a84e7e259debbc",
            "title": "Explaining Identity-aware Graph Classifiers through the Language of Motifs",
            "abstract": "Most methods for explaining black-box classifiers (e.g., on tabular data, images, or time series) rely on measuring the impact that removing/perturbing features has on the model output. This forces the explanation language to match the classifier's feature space. However, when dealing with graph data, in which the basic features correspond to the edges describing the graph structure, this matching between features space and explanation language might not be appropriate. Decoupling the feature space (edges) from a desired high-lever explanation language (such as motifs) is thus a major challenge towards developing actionable explanations for graph classification tasks. In this paper we introduce Graphshap, a Shapley-based approach able to provide motif-based explanations for identityaware graph classifiers, assuming no knowledge whatsoever about the model or its training data: the only requirement is that the classifier can be queried as a black-box at will. For the sake of computational efficiency we explore a progressive approximation strategy and show how a simple kernel can efficiently approximate explanation scores, thus allowing Graphshap to scale on scenarios with a large explanation space (i.e., large number of motifs). We showcase Graphshap on a real-world brain-network dataset consisting of patients affected by Autism Spectrum Disorder and a control group. Our experiments highlight how the classification provided by a black-box model can be effectively explained by few connectomics patterns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "26582424",
                    "name": "A. Perotti"
                },
                {
                    "authorId": "46726748",
                    "name": "P. Bajardi"
                },
                {
                    "authorId": "2179558887",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "2735649",
                    "name": "A. Panisson"
                }
            ]
        }
    ]
}