{
    "authorId": "2117800368",
    "papers": [
        {
            "paperId": "1d6ba7435383ab645a8b6d02c48a95a863eeda2c",
            "title": "Unified Contextual Query Rewriting",
            "abstract": "Query rewriting (QR) is an important technique for user friction (i.e. recovering ASR error or system error) reduction and contextual carryover (i.e. ellipsis and co-reference) in conversational AI systems. Recently, generation-based QR models have achieved promising results on these two tasks separately. Although these two tasks have many similarities such as they both use the previous dialogue along with the current request as model input, there is no unified model to solve them jointly. To this end, we propose a unified contextual query rewriting model that unifies QR for both reducing friction and contextual carryover purpose. Moreover, we involve multiple auxiliary tasks such as trigger prediction and NLU interpretation tasks to boost the performance of the rewrite. We leverage the text-to-text unified framework which uses independent tasks with weighted loss to account for task importance. Then we propose new unified multitask learning strategies including a sequential model which outputs one sentence for multi-tasks, and a hybrid model where some tasks are independent and some tasks are sequentially generated. Our experimental results demonstrate the effectiveness of the proposed unified learning methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118861187",
                    "name": "Yingxue Zhou"
                },
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "35315626",
                    "name": "Mukund Rungta"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2220668748",
                    "name": "Yanbin Lu"
                },
                {
                    "authorId": "7159482",
                    "name": "V. Vasudevan"
                },
                {
                    "authorId": "39312387",
                    "name": "Kellen Gillespie"
                },
                {
                    "authorId": "3274284",
                    "name": "Zeynab Raeesy"
                }
            ]
        },
        {
            "paperId": "26059f871eea2ef9aeeda228ebd40a69b61ab65c",
            "title": "RecMind: Large Language Model Powered Agent For Recommendation",
            "abstract": "While the recommendation system (RS) has advanced significantly through deep learning, current RS approaches usually train and fine-tune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an LLM-powered autonomous recommender agent, RecMind, which is capable of leveraging external knowledge, utilizing tools with careful planning to provide zero-shot personalized recommendations. We propose a Self-Inspiring algorithm to improve the planning ability. At each intermediate step, the LLM self-inspires to consider all previously explored states to plan for the next step. This mechanism greatly improves the model's ability to comprehend and utilize historical information in planning for recommendation. We evaluate RecMind's performance in various recommendation scenarios. Our experiment shows that RecMind outperforms existing zero/few-shot LLM-based recommendation baseline methods in various tasks and achieves comparable performance to a fully trained recommendation model P5.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115944576",
                    "name": "Yancheng Wang"
                },
                {
                    "authorId": "2112347577",
                    "name": "Ziyan Jiang"
                },
                {
                    "authorId": "2141144864",
                    "name": "Zheng Chen"
                },
                {
                    "authorId": "47829900",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2118861187",
                    "name": "Yingxue Zhou"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1794577",
                    "name": "Xiaojiang Huang"
                },
                {
                    "authorId": "2220668748",
                    "name": "Yanbin Lu"
                },
                {
                    "authorId": "2193639833",
                    "name": "Yingzhen Yang"
                }
            ]
        },
        {
            "paperId": "89db8566a928f9267efbf2ad93d8c8d54c41d58b",
            "title": "Multi-Task Knowledge Enhancement for Zero-Shot and Multi-Domain Recommendation in an AI Assistant Application",
            "abstract": "Recommender systems have found significant commercial success but still struggle with integrating new users. Since users often interact with content in different domains, it is possible to leverage a user's interactions in previous domains to improve that user's recommendations in a new one (multi-domain recommendation). A separate research thread on knowledge graph enhancement uses external knowledge graphs to improve single domain recommendations (knowledge graph enhancement). Both research threads incorporate related information to improve predictions in a new domain. We propose in this work to unify these approaches: Using information from interactions in other domains as well as external knowledge graphs to make predictions in a new domain that would be impossible with either information source alone. We apply these ideas to a dataset derived from millions of users' requests for content across three domains (videos, music, and books) in a live virtual assistant application. We demonstrate the advantage of combining knowledge graph enhancement with previous multi-domain recommendation techniques to provide better overall recommendations as well as for better recommendations on new users of a domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2083006949",
                    "name": "Elan Markowitz"
                },
                {
                    "authorId": "2112347577",
                    "name": "Ziyan Jiang"
                },
                {
                    "authorId": "145338224",
                    "name": "F. Yang"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2110558005",
                    "name": "Tony Chen"
                },
                {
                    "authorId": "1719898",
                    "name": "G. V. Steeg"
                },
                {
                    "authorId": "143728483",
                    "name": "A. Galstyan"
                }
            ]
        },
        {
            "paperId": "a33d1b24ff14a4e4559eea16387072a81d40b6be",
            "title": "KG-ECO: Knowledge Graph Enhanced Entity Correction For Query Rewriting",
            "abstract": "Query Rewriting (QR) plays a critical role in large-scale dialogue systems for reducing frictions. When there is an entity error, it imposes extra challenges for a dialogue system to produce satisfactory responses. In this work, we propose KG-ECO: Knowledge Graph enhanced Entity COrrection for query rewriting, an entity correction system with corrupt entity span detection and entity retrieval/re-ranking functionalities.To boost the model performance, we incorporate Knowledge Graph (KG) to provide entity structural information (neighboring entities encoded by graph neural networks) and textual information (KG entity descriptions encoded by RoBERTa). Experimental results show that our approach yields a clear performance gain over two baselines: utterance level QR and entity correction without utilizing KG information. The proposed system is particularly effective for few-shot learning cases where target entities are rarely seen in training or there is a KG relation between the target entity and other contextual entities in the query.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115670967",
                    "name": "Jason (Jinglun) Cai"
                },
                {
                    "authorId": "47628976",
                    "name": "Mingda Li"
                },
                {
                    "authorId": "2112347577",
                    "name": "Ziyan Jiang"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "2141144864",
                    "name": "Zheng Chen"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "53871ac59c687d312dfdd89f0dde82f79c5faf76",
            "title": "PAIGE: Personalized Adaptive Interactions Graph Encoder for Query Rewriting in Dialogue Systems",
            "abstract": "Unexpected responses or repeated clarification questions from conversational agents detract from the users\u2019 experience with technology meant to streamline their daily tasks. To reduce these frictions, Query Rewriting ( QR ) techniques replace transcripts of faulty queries with alternatives that lead to responses that satisfy the users\u2019 needs. Despite their successes, existing QR approaches are limited in their ability to fix queries that require considering users\u2019 personal preferences. We improve QR by proposing P ersonalized A daptive I nteractions G raph E ncoder (PAIGE). PAIGE is the first QR architecture that jointly models user\u2019s affinities and query semantics end-to-end. The core idea is to represent previous user-agent interactions and world knowledge in a structured form \u2014 a heterogeneous graph \u2014 and apply message passing to propagate latent representations of users\u2019 affinities to refine utterance embeddings. Using these embeddings, PAIGE can potentially provide different rewrites given the same query for users with different preferences. Our model, trained without any human-annotated data, improves the rewrite retrieval precision of state-of-the-art baselines by 12.5\u201317.5% while having nearly ten times fewer parameters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65987423",
                    "name": "Daniel Bis"
                },
                {
                    "authorId": "2118973203",
                    "name": "Saurabh Gupta"
                },
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "c8525b6119a6ec89bd64a97a6ee5d7d377f8841c",
            "title": "CGF: Constrained Generation Framework for Query Rewriting in Conversational AI",
            "abstract": "In conversational AI agents, Query Rewriting 001 (QR) plays a crucial role in reducing users fric- 002 tions and satisfying their daily demands. Users 003 frictions are caused by various reasons, such 004 as errors in the spoken dialogue system, users\u2019 005 accent or their abridged language. In this work, 006 we present a novel Constrained Generation 007 Framework (CGF) for query rewriting at both 008 global and personalized level. The proposed 009 framework is based on the encoder-decoder 010 framework and consists of a context-enhanced 011 encoding and constrained generation decoding 012 phrases. The model takes the query and its 013 previous dialogue context information as the 014 encoder input, then the decoder relies on the 015 pre-defined global or personalized constrained 016 decoding space to generate the rewrites. Ex- 017 tensive offline and online A/B experimental re- 018 sults show that the proposed CGF significantly 019 boosts the query rewriting performance. 020",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2118973203",
                    "name": "Saurabh Gupta"
                },
                {
                    "authorId": "2805456",
                    "name": "Saleh Soltan"
                },
                {
                    "authorId": "147887099",
                    "name": "Rakesh Chada"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                },
                {
                    "authorId": "1748051",
                    "name": "G\u00f6khan T\u00fcr"
                }
            ]
        },
        {
            "paperId": "dde0be499b277f52dc3a730e90005c6c19a049cb",
            "title": "Overcoming Catastrophic Forgetting During Domain Adaptation of Seq2seq Language Generation",
            "abstract": "Seq2seq language generation models that are trained offline with multiple domains in a sequential fashion often suffer from catastrophic forgetting. Lifelong learning has been proposed to handle this problem. However, existing work such as experience replay or elastic weighted consolidation requires incremental memory space. In this work, we propose an innovative framework, RMR_DSEthat leverages a recall optimization mechanism to selectively memorize important parameters of previous tasks via regularization, and uses a domain drift estimation algorithm to compensate the drift between different do-mains in the embedding space. These designs enable the model to be trained on the current task while keep-ing the memory of previous tasks, and avoid much additional data storage. Furthermore, RMR_DSE can be combined with existing lifelong learning approaches. Our experiments on two seq2seq language generation tasks, paraphrase and dialog response generation, show thatRMR_DSE outperforms SOTA models by a considerable margin and reduces forgetting greatly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34377382",
                    "name": "Dingcheng Li"
                },
                {
                    "authorId": "2141144864",
                    "name": "Zheng Chen"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "8015600",
                    "name": "Xiaohu Liu"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "ecdee4c3e7c6a5ce0c25c4d24bbfa363e1bbb5aa",
            "title": "PENTATRON: PErsonalized coNText-Aware Transformer for Retrieval-based cOnversational uNderstanding",
            "abstract": "Conversational understanding is an integral part of modern intelligent devices. In a large fraction of the global traffic from customers using smart digital assistants, frictions in dialogues may be attributed to incorrect understanding of the entities in a customer's query due to factors including ambiguous mentions, mispronunciation, background noise and faulty on-device signal processing. Such errors are compounded by two common deficiencies from intelligent devices namely, (1) the device not being tailored to individual customers, and (2) the device responses being unaware of the context in the conversation session. Viewing this problem via the lens of retrieval-based search engines, we build and evaluate a scalable entity correction system, PENTATRON. The system leverages a parametric transformer-based language model to learn patterns from in-session customer-device interactions coupled with a non-parametric personalized entity index to compute the correct query, which aids downstream components in reasoning about the best response. In addition to establishing baselines and demonstrating the value of personalized and context-aware systems, we use multitasking to learn the domain of the correct entity. We also investigate the utility of language model prompts. Through extensive experiments, we show a significant upward movement of the key metric (Exact Match) by up to 500.97% (relative to the baseline).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143795841",
                    "name": "Niranjan Uma Naresh"
                },
                {
                    "authorId": "2112347577",
                    "name": "Ziyan Jiang"
                },
                {
                    "authorId": "2128405653",
                    "name": "Ankit"
                },
                {
                    "authorId": "2108230831",
                    "name": "Sungjin Lee"
                },
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "f654052033d2b4f83124ae7d46705906b785f007",
            "title": "Research on Chinese short text semantic matching based on lightweight ERNIE",
            "abstract": "Semantic matching of short texts is a hot research problem in the field of natural language processing, which has a wide range of application needs in information retrieval, dialogue system, text paraphrase questions, and question answering system etc. Short texts have the characteristics of less information and lack of contextual background. The existing semantic matching methods for short texts also generally have the problem of low matching accuracy. With the speedy development of deep learning technology, various models of deep learning have been extensively used in natural language processing and achieved good results. In this paper, we design a FERNIE model based on a lightweight pre-training model ERNIE3.0-medium of BERT architecture, which integrates low-level features and high-level features. Experiments on several datasets show that the FERNIE model has good results in short text semantic matching, and the accuracy is further improved compared to ERNIE3.0-medium.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2075362797",
                    "name": "W. Pan"
                },
                {
                    "authorId": "2111526781",
                    "name": "Qingqing Huang"
                }
            ]
        },
        {
            "paperId": "2d27fc841823364561a6c8afae27b246bec9c6d9",
            "title": "Graph Enhanced Query Rewriting for Spoken Language Understanding System",
            "abstract": "Query rewriting (QR) is an increasingly important component in voice assistant systems to reduce customer friction caused by errors in a spoken language understanding pipeline. These errors originate from various sources such as Automatic Speech Recognition (ASR) and Natural Language Understanding (NLU) modules. In this work, we construct a user interaction graph from their queries using data mined from a Markov Chain Model [1], and introduce a self-supervised pre-training process for learning query embeddings by leveraging the recent developments in Graph Representation Learning (GRL). We then fine-tune these embeddings with weak supervised data for the query rewriting task, and observe improvement over the neural retrieval baseline system, demonstrating the effectiveness of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087092426",
                    "name": "Siyang Yuan"
                },
                {
                    "authorId": "2118973203",
                    "name": "Saurabh Gupta"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2146063081",
                    "name": "Derek Liu"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        }
    ]
}