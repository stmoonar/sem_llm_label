{
    "authorId": "39677946",
    "papers": [
        {
            "paperId": "637eaef19e86b6f0025e56ea066ea82835ea3b86",
            "title": "Adaptive Search-based Repair of Deep Neural Networks",
            "abstract": "Deep Neural Networks (DNNs) are finding a place at the heart of more and more critical systems, and it is necessary to ensure they perform in as correct a way as possible. Search-based repair methods, that search for new values for target neuron weights in the network to better process fault-inducing inputs, have shown promising results. These methods rely on fault localisation to determine what weights the search should target. However, as the search progresses and the network evolves, the weights responsible for the faults in the system will change, and the search will lose in effectiveness. In this work, we propose an adaptive search method for DNN repair that adaptively updates the target weights during the search by performing fault localisation on the current state of the model. We propose and implement two methods to decide when to update the target weights, based on the progress of the search's fitness value or on the evolution of fault localisation results. We apply our technique to two image classification DNN architectures against a dataset of autonomous driving images, and compare it with a state-of-the art search-based DNN repair approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223100545",
                    "name": "Davide Li Calsi"
                },
                {
                    "authorId": "2154328998",
                    "name": "Matias Duran"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2109108964",
                    "name": "Xiaoyi Zhang"
                },
                {
                    "authorId": "2122951953",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                }
            ]
        },
        {
            "paperId": "dc53420bca08064841bb00e635705856efa35a93",
            "title": "Modelling Android applications through static analysis and systematic exploratory testing",
            "abstract": "Mobile application development is a fast paced industry with frequent releases. While the development pace increases, so too does the need for automated test generation. Model-based test generation is one of the most common and successful approaches to support this need. Understanding and modelling the application under test is integral to producing comprehensive, dependable and effective tests. Unfortunately, mobile platforms such as Android, introduce a host of difficulties. Static analysis struggles with Android\u2019s event-based nature and the growing variety of mechanisms available for developers to implement different features. Additionally, dynamic analysis, implemented by popular random test generators, is slow, inefficient, and limited by a lack of application knowledge.This paper introduces DroidGraph, a framework to generate a comprehensive control flow model of Android applications using traditional static analysis and efficient systematic exploratory tests. DroidGraph provides a detailed model of an Android application, from low level method statements to high level user interface structures. This model can be used to support automated test generation. We apply DroidGraph to 19 diverse apps and show that our efficient exploratory tests, on average, interact with 18% more of the app than commonly used random exploration in 345 less interactions. Integrating the dynamic analysis results provided by these tests complements our static analysis, and uncovers on average 51 more components and 49% more interface callback links in the application code.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106225625",
                    "name": "Jordan Doyle"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "19b2889a44107d230d43086a4aadc63307726697",
            "title": "Parameter Coverage for Testing of Autonomous Driving Systems under Uncertainty",
            "abstract": "Autonomous Driving Systems (ADSs) are promising, but must show they are secure and trustworthy before adoption. Simulation-based testing is a widely adopted approach, where the ADS is run in a simulated environment over specific scenarios. Coverage criteria specify what needs to be covered to consider the ADS sufficiently tested. However, existing criteria do not guarantee to exercise the different decisions that the ADS can make, which is essential to assess its correctness. ADSs usually compute their decisions using parameterised rule-based systems and cost functions, such as cost components or decision thresholds. In this article, we argue that the parameters characterise the decision process, as their values affect the ADS\u2019s final decisions. Therefore, we propose parameter coverage, a criterion requiring to cover the ADS\u2019s parameters. A scenario covers a parameter if changing its value leads to different simulation results, meaning it is relevant for the driving decisions made in the scenario. Since ADS simulators are slightly uncertain, we employ statistical methods to assess multiple simulation runs for execution difference and coverage. Experiments using the Autonomoose ADS show that the criterion discriminates between different scenarios and that the cost of computing coverage can be managed with suitable heuristics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "3198077",
                    "name": "Stefan Klikovits"
                },
                {
                    "authorId": "2122951953",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "54bd9494f83d42fc3e013e33cf1166376c502363",
            "title": "The case for grammatical evolution in test generation",
            "abstract": "Generating tests for software is an important, but difficult, task. Search-based test generation is promising, as it reduces the time required from human experts, but suffers from many problems and limitations. Namely, the inability to fully incorporate a tester's domain knowledge into the search, its difficulty in creating very complex objects, and the problems associated with variable length tests. This paper illustrates how Grammatical Evolution could address and provide a possible solution to each of these concerns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2005218887",
                    "name": "Aidan Murphy"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "87c0f3559853373033ae35b304cbf1936c9f0aee",
            "title": "The Forgotten Margins of AI Ethics",
            "abstract": "How has recent AI Ethics literature addressed topics such as fairness and justice in the context of continued social and structural power asymmetries? We trace both the historical roots and current landmark work that have been shaping the field and categorize these works under three broad umbrellas: (i) those grounded in Western canonical philosophy, (ii) mathematical and statistical methods, and (iii) those emerging from critical data/algorithm/information studies. We also survey the field and explore emerging trends by examining the rapidly growing body of literature that falls under the broad umbrella of AI Ethics. To that end, we read and annotated peer-reviewed papers published over the past four years in two premier conferences: FAccT and AIES. We organize the literature based on an annotation scheme we developed according to three main dimensions: whether the paper deals with concrete applications, use-cases, and/or people\u2019s lived experience; to what extent it addresses harmed, threatened, or otherwise marginalized groups; and if so, whether it explicitly names such groups. We note that although the goals of the majority of FAccT and AIES papers were often commendable, their consideration of the negative impacts of AI on traditionally marginalized groups remained shallow. Taken together, our conceptual analysis and the data from annotated papers indicate that the field would benefit from an increased focus on ethical analysis grounded in concrete use-cases, people\u2019s experiences, and applications as well as from approaches that are sensitive to structural and historical power asymmetries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8318698",
                    "name": "Abeba Birhane"
                },
                {
                    "authorId": "36136648",
                    "name": "Elayne Ruane"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2216835593",
                    "name": "Matthew S. Brown"
                },
                {
                    "authorId": "1484559720",
                    "name": "John F. Flowers"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                },
                {
                    "authorId": "2961640",
                    "name": "Christopher L. Dancy"
                }
            ]
        },
        {
            "paperId": "b0fe8e18e29a5ecb5b3d1010849349b1d611887e",
            "title": "JSIMutate: understanding performance results through mutations",
            "abstract": "Understanding the performance characteristics of software systems is particular relevant when looking at design alternatives. However, it is a very challenging problem, due to the complexity of interpreting the role and incidence of the different system elements on performance metrics of interest, such as system response time or resources utilisation. This work introduces JSIMutate, a tool that makes use of queueing network performance models and enables the analysis of mutations of a model reflecting possible design changes to support designers in identifying the model elements that contribute to improving or worsening the system's performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2122951953",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1808957",
                    "name": "Catia Trubiani"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "e665824b9467e9f2458a5ca3bc333bf0a6476398",
            "title": "Re-visiting the coupling between mutants and real faults with Defects4J 2.0",
            "abstract": "Mutation analysis is a well-known testing criterion that involves seeding changes in the system under test, i.e. creating mutants, to simulate faults, and measuring the capacity of the test suite to detect these changes. The question of whether real faults are coupled with the mutants is central, as it determines whether tests that detect the mutants will also detect faults that actually occur in code, making the mutants reasonable test requirements. Prior work has explored this question, notably using the Defects4J dataset in Java. As the dataset and the mutation tools used in these prior works have evolved, this work re-visits this question using the newest available versions in order to strengthen and extend prior results. In this work we use 337 real faults from 15 different projects in the Defects4J 2.0.0 dataset, 2,828 test suites, and two well-known Java mutation testing tools (Major and Pitest) to explore (i) to what extent real faults are coupled with mutants, (ii) how both tools compare in terms of producing mutants coupled with faults, (iii) the characteristics of the mutants that are coupled with real faults, and (iv) the characteristics of faults not coupled with the mutants. Most (80.7%) of the faults used were coupled with at least one mutant created by Pitest or Major, most often with mutants created by both tools. All operators used produced a low (<4%) proportion of coupled mutants, although some operators are exclusively coupled to more faults, i.e. coupled to faults where no other operator produces coupled mutants. Finally, faults not coupled with any mutants usually had small fix patches, and although the code related to these faults was mostly affected by the mutation operators used the mutants produces were still not coupled. Results confirm previous findings showing that the coupling effect mostly holds but that additional mutation operators are needed to capture all faults.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "123895839",
                    "name": "Stephen Gaffney"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "0f17d26a4623f36c9e977935eca6c7958b5652e8",
            "title": "Shake Those System Parameters! On the Need for Parameter Coverage for Decision Systems",
            "abstract": "Decision systems such as Multiple-Criteria Decision Analysis systems formulate a decision process in terms of a mathematical function that takes into consideration different aspects of a problem. Testing such systems is crucial, as they are usually employed in safety-critical systems. A good test suite for these systems should be able to exercise all the possible types of decisions that can be taken by the system. Classic structural coverage criteria do not provide good test suites in this sense, as they can be fulfilled by simple tests that only cover one possible type of decision. Thus, in this paper we discuss the need for tailored coverage criteria for this class of systems, and we propose a criterion based on the perturbation of the decision systems\u2019 parameters. We demonstrate the effectiveness of the criterion, compared to classic structural coverage criteria, on a path planner system for autonomous driving. We also discuss other benefits, such as the criterion helping explain why a decision was made during a test.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2122951953",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "0f970c96d3a8c2c5c1e140571e98fc29ea644f71",
            "title": "Achieving weight coverage for an autonomous driving system with search-based test generation (HOP track at GECCO 2021)",
            "abstract": "Autonomous Driving Systems (ADSs) are complex critical systems that must be thoroughly tested. Still, assessing the strength of tests for ADSs is an open and complex problem. Weight Coverage is a test criterion targeting ADSs which are based on a weighted cost function. It measures how much each weight, related to different aspects of the ADS's decision process, is involved in the decisions taken in a test scenario. All weights/aspects should be involved for a strong test suite. Although weight coverage can measure the quality of a test suite, it does not provide clear guidance for test generation. This work proposes weight coverage-driven search-based test generation for ADSs. It describes and compares three designs of the search process: a single-objective search aiming at generating a test covering a single weight; a multi-objective search where each objective targets a different weight; and a single-objective search where the fitness function is an aggregate function representing the coverage over multiple weights. Experiments using an ADS system provided by our industry partner show the validity of the method and provide insights into the benefits of each search design. This Hot-off-the-Press paper summarises the paper [2]: T. Laurent, P. Arcaini, F. Ishikawa and A. Ventresque, \"Achieving Weight Coverage for an Autonomous Driving System with Search-based Test Generation\", 25th International Conference on Engineering of Complex Computer Systems (ICECCS 2020).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2846414",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "9de1591bc2b3db04d0432140767d88980ee8bebd",
            "title": "Parameter-Based Testing and Debugging of Autonomous Driving Systems",
            "abstract": "Testing of Autonomous Driving Systems (ADSs) is of paramount importance. However, ADS testing raises several challenges specific to the domain. Typical testing (coverage criteria, test generation, and oracle definition) and debugging activities performed for software programs are not directly applicable to ADSs, because of the lack of proper test oracles, and the difficulty of specifying the desired, correct ADS behavior. We tackle these challenges by extending and combining existing approaches to the domain of testing ADS. The approach is demonstrated on an industrial path planner. The path planner decides which path to follow through a cost function that uses parameters to assign a cost to the driving characteristics (e.g., lateral acceleration or speed) that must be applied in the path. These parameters implicitly describe the behavior of the ADS. We exploit this idea for defining a coverage criterion, for automatically specifying an oracle, and for debugging the path planner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122951953",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "2078401000",
                    "name": "Alessandro Cal\u00f2"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2109108964",
                    "name": "Xiaoyi Zhang"
                },
                {
                    "authorId": "47495965",
                    "name": "Sajid Ali"
                },
                {
                    "authorId": "2287987",
                    "name": "Florian Hauer"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "08a8e17b471582467b21c21bea72ffeee6026b98",
            "title": "Commit-Aware Mutation Testing",
            "abstract": "In Continuous Integration, developers want to know how well they have tested their changes. Unfortunately, in these cases, the use of mutation testing is suboptimal since mutants affect the entire set of program behaviours and not the changed ones. Thus, the extent to which mutation testing can be used to test committed changes is questionable. To deal with this issue, we define commit-relevant mutants; a set of mutants that affect the changed program behaviours and represent the commit-relevant test requirements. We identify such mutants in a controlled way, and check their relationship with traditional mutation score (score based on the entire set of mutants or on the mutants located on the commits). We conduct experiments in both C and Java, using 83 commits, 2,253,610 mutants from 25 projects. Our findings reveal that there is a relatively weak correlation (Kendall/Pearson 0.15-0.4) between the sought (commit-relevant) and traditional mutation scores, indicating the need for a commit-aware test assessment metric. Our analysis also shows that traditional mutation is far from the envisioned case as it loses approximately 50%-60% of the commit-relevant mutants when analysing 5-25 mutants. More importantly, our results demonstrate that traditional mutation has approximately 30% lower chances of revealing commit-introducing faults than commit-aware mutation testing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111665481",
                    "name": "Wei Ma"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "1397172963",
                    "name": "Milo\u0161 Ojdani\u0107"
                },
                {
                    "authorId": "3433689",
                    "name": "T. Chekam"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                },
                {
                    "authorId": "37766916",
                    "name": "Mike Papadakis"
                }
            ]
        },
        {
            "paperId": "1b2f280acd9c9ac96d5b05146b8378aa9a19a588",
            "title": "Achieving Weight Coverage for an Autonomous Driving System with Search-based Test Generation",
            "abstract": "Autonomous Driving Systems (ADS) are complex critical systems that need to be thoroughly tested. Still, assessing the strength of tests for such systems is an open and complex problem. A central component of an ADS is the Path Planner, which is in charge of computing the trajectory of the autonomous vehicle. It bases its decisions on several aspects such as safety, traffic regulations, comfort, etc. These aspects can be linked to weights in a weighted cost function that ranks potential trajectories to be followed. Weight coverage has been proposed as a test criterion for tests of this type of path planner. Weight coverage measures how much the different weights (and thus the aspects they are linked to) are involved in the decisions taken by the path planner in a test scenario. All weights should be involved in at least one test. Although weight coverage has shown to be a reasonable criterion, it does not provide a clear way to drive the generation of new scenarios. In this paper, we propose a search-based approach for generating scenarios for achieving weight coverage. We introduce two variants of the approach; the first one tries to generate a scenario covering a given single weight, while the second one tries to generate scenarios covering as many weights as possible at the same time. We experimented with these approaches using the path planner provided by our industry partner, and we show that they are able to generate scenarios that cover all the weights.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2846414",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "dd9793052988f4be30223955997857fc6fa61111",
            "title": "On the impact of timeouts and JVM crashes in Pitest",
            "abstract": "Mutation analysis is a strong, well studied, faultbased testing criterion that has been shown to lead to strong test suites. Still, when using mutation analysis to compare test suites, previous work has shown that its results can be skewed because of redundant mutants. This problem is avoided by using minimal mutants, a set of representative mutants that is computed from a full matrix of all test results against all mutants. Pitest is a state of the art mutation analysis tool for Java and the JVM that can produce the matrix needed to compute minimal mutants.When a mutant leads to a JVM crash, because of a timeout or a memory error for example, Pitest does not record the full information about a mutant, leading to an incomplete matrix. In this work, we update Pitest in order to obtain the complete matrix, and make our updated version available. We then study the impact of the incomplete matrix on both minimal mutant computation and test selection, using both open source projects and developer-made test suites as well as a set of well tested methods. Finally, using the data collected, we see whether particular characteristics of a mutant or a test can help predict whether a test run against a mutant will lead to a JVM crash.Our experiments show that the missing information in Pitest\u2019s matrix has little impact on the computed set of minimal mutants and the tests it selects. We also find no indication that particular mutation operator or test systematically leads to JVM crashes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "1874480542",
                    "name": "Fionnuala Wall"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "3590de10d385c5e39e69e04efdff070e7a167ced",
            "title": "PIT-HOM: an Extension of Pitest for Higher Order Mutation Analysis",
            "abstract": "Mutation testing is a well-known, effective, fault-based testing criterion. First order mutation introduces defects in the form of a single small syntactic change. While the technique has been shown to be effective, it has some limits. Higher order mutation, where the faults introduced include multiple changes, has been proposed as a way to address some of these limits. Although the technique has shown promising results, there is no practical tool available for the application and study of higher order mutation on Java programs. In this paper we present PIT-HOM, an extension of Pitest (PIT) for higher order mutation. Pitest is a practical mutation analysis tool for Java, applicable on real-world codebases. PIT-HOM combines mutants in a same class to create higher order mutants of user-defined orders, it runs the mutants and reports the results in an easy to process format. We validate PIT-HOM using two small Java programs and report its performance as well as some characteristics of the mutants it creates.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "67a8c6de7af2464e89bd90d4e511977f01625cb9",
            "title": "A Mutation-Based Approach for Assessing Weight Coverage of a Path Planner",
            "abstract": "Autonomous cars are subjected to several different kind of inputs (other cars, road structure, etc.) and, therefore, testing the car under all possible conditions is impossible. To tackle this problem, scenario-based testing for automated driving defines categories of different scenarios that should be covered. Although this kind of coverage is a necessary condition, it still does not guarantee that any possible behaviour of the autonomous car is tested. In this paper, we consider the path planner of an autonomous car that decides, at each timestep, the short-term path to follow in the next few seconds; such decision is done by using a weighted cost function that considers different aspects (safety, comfort, etc.). In order to assess whether all the possible decisions that can be taken by the path planner are covered by a given test suite T, we propose a mutation-based approach that mutates the weights of the cost function and then checks if at least one scenario of T kills the mutant. Preliminary experiments on a manually designed test suite show that some weights are easier to cover as they consider aspects that more likely occur in a scenario, and that more complicated scenarios (that generate more complex paths) are those that allow to cover more weights.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2846414",
                    "name": "Paolo Arcaini"
                },
                {
                    "authorId": "1679182",
                    "name": "F. Ishikawa"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "662311bdb0391f3e6f164ef1ce2bb57fb8a08ded",
            "title": "Fairness and Transparency in Crowdsourcing",
            "abstract": "Despite the success of crowdsourcing, the question of ethics has not yet been addressed in its entirety. Existing e\ufb00orts have studied fairness in worker compensation and in helping requesters detect malevolent workers. In this paper, we propose fairness axioms that generalize existing work and pave the way to studying fairness for task assignment, task completion, and worker compensation. Transparency on the other hand, has been addressed with the development of plug-ins and forums to track workers\u2019 performance and rate requesters. Similarly to fairness, we de\ufb01ne transparency axioms and advocate the need to address it in a holistic manner by providing declarative speci\ufb01cations. We also discuss how fairness and transparency could be enforced and evaluated in a crowdsourcing platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "48449806",
                    "name": "Motomichi Toyama"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "9c2b6e6ce39ea0f54da71743275dfd6c08f72e89",
            "title": "Towards a Gamified Equivalent Mutants Detection Platform",
            "abstract": "This poster presents a gamified system for equivalent mutants detection. This system can be used as a standalone tool for developers and testing teams alike - but we plan to use this system on a crowdsourcing platform to evaluate the various parameters involved in the detection of equivalent mutants, such as, expertise (coding and testing), familiarity with the code base, complexity of the code and tests, measured likelihood of equivalent mutants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "32702807",
                    "name": "L. Guillot"
                },
                {
                    "authorId": "48449806",
                    "name": "Motomichi Toyama"
                },
                {
                    "authorId": "2109379776",
                    "name": "Ross Smith"
                },
                {
                    "authorId": "37216714",
                    "name": "Dan Bean"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "dcd6e59e7d59d577adb725bbd87b83c422d5358e",
            "title": "RTA: A Framework for the Integration of Local and Relational Open Data",
            "abstract": "There are currently massive amounts of public data, also refereed to as open data, for example stock price data or weather data. However, such data is distributed in a variety of ways, such as downloadable files like CSV or XML files, or through API calls to web services. Each data source thus requires a specific workflow, making it a burden for the users to process and use this data. This barrier to use diminishes the openness of this data We thus propose the Remote Table Access (RTA) system, a simple and safe architecture for publishing, i.e. giving open read only access to relational data, and easily integrating it with the user's local data. RTA enables the user to query relational open data and their own local data seamlessly through a single SQL query. To allow this, we designed a three parties architecture featuring a client-side application, an optional server-side module and a \"Public Table Library\" (PTL). The client side application processes the RTA query and fetches the necessary data, the server side system acts as an agent between the remote database and the client, offering added security as well as scalability in terms of connections, and the PTL list all the published data and stores its access information. We implemented an early prototype of this architecture as a proof of concept. We validated it against two datasets, including data from the TPC-C benchmark and make it available1. Our results show the feasability of RTA and possible significant reduction of query processing time mainly because of the reduction on transmission volume by condition pushing and semijoin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3082733",
                    "name": "Yusuke Kosaka"
                },
                {
                    "authorId": "23208946",
                    "name": "Shu Murakami"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "143838907",
                    "name": "Kento Goto"
                },
                {
                    "authorId": "48449806",
                    "name": "Motomichi Toyama"
                }
            ]
        },
        {
            "paperId": "1c0bd22f0807bd4545ca6d1cd99a983fee64b6a8",
            "title": "Assessing and Improving the Mutation Testing Practice of PIT",
            "abstract": "Mutation testing is extensively used in software testing studies. However, popular mutation testing tools use a restrictive set of mutants which does not conform to the community standards and mutation testing literature. This can be problematic since the effectiveness of mutation strongly depends on the used mutants. To investigate this issue we form an extended set of mutants and implement it on a popular mutation testing tool named PIT. We then show that in real-world projects the original mutants of PIT are easier to kill and lead to tests that score statistically lower than those of the extended set of mutants for a range of 35% to 70% of the studied classes. These results raise serious concerns regarding the validity of mutation-based experiments that use PIT. To further show the strengths of the extended mutants we also performed an analysis using a benchmark with mutation-adequate test cases and identified equivalent mutants. Our results confirmed that the extended mutants are more effective than a) the original version of PIT and b) two other popular mutation testing tools (major and muJava). In particular, our results demonstrate that the extended mutants are more effective by 23%, 12% and 7% than the mutants of the original PIT, major and muJava. They also show that the extended mutants are at least as strong as the mutants of all the other three tools together. To support future research, we make the new version of PIT, which is equipped with the extended mutants, publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                },
                {
                    "authorId": "37766916",
                    "name": "Mike Papadakis"
                },
                {
                    "authorId": "2390837",
                    "name": "Christopher Henard"
                },
                {
                    "authorId": "47681863",
                    "name": "Y. L. Traon"
                }
            ]
        },
        {
            "paperId": "6238b044500719c559bd0adcd42c1792704c7f31",
            "title": "PIT a Practical Mutation Testing Tool for Java",
            "abstract": "Mutation testing introduces artificial defects to measure the adequacy of testing. In case candidate tests can distinguish the behaviour of mutants from that of the original program, they are considered of good quality \u2013 otherwise developers need to design new tests. While, this method has been shown to be effective, industry-scale code challenges its applicability due to the sheer number of mutants and test executions it requires. In this paper we present PIT, a practical mutation testing tool for Java, applicable on real-world codebases. PIT is fast since it operates on bytecode and optimises mutant executions. It is also robust and well integrated with development tools, as it can be invoked through a command line interface, Ant or Maven. PIT is also open source and hence, publicly available at http://pitest.org/ CCS Concepts \u2022Software and its engineering \u2192 Software testing and debugging;",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2241676060",
                    "name": "Henry Coles"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2390837",
                    "name": "Christopher Henard"
                },
                {
                    "authorId": "37766916",
                    "name": "Mike Papadakis"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "816eb7ebf34907ff4a27fe647ade46e50df4ca87",
            "title": "PIT: a practical mutation testing tool for Java (demo)",
            "abstract": "Mutation testing introduces artificial defects to measure the adequacy of testing. In case candidate tests can distinguish the behaviour of mutants from that of the original program, they are considered of good quality -- otherwise developers need to design new tests. While, this method has been shown to be effective, industry-scale code challenges its applicability due to the sheer number of mutants and test executions it requires. In this paper we present PIT, a practical mutation testing tool for Java, applicable on real-world codebases. PIT is fast since it operates on bytecode and optimises mutant executions. It is also robust and well integrated with development tools, as it can be invoked through a command line interface, Ant or Maven. PIT is also open source and hence, publicly available at \\url{http://pitest.org/}",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2241676060",
                    "name": "Henry Coles"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "2390837",
                    "name": "Christopher Henard"
                },
                {
                    "authorId": "37766916",
                    "name": "Mike Papadakis"
                },
                {
                    "authorId": "2796694",
                    "name": "Anthony Ventresque"
                }
            ]
        },
        {
            "paperId": "c333dbe6837059995a2e5e9df3313a3cd668cc16",
            "title": "The Influence of Crowd Type and Task Complexity on Crowdsourced Work Quality",
            "abstract": "As the use of crowdsourcing spreads, the need to ensure the quality of crowdsourced work is magnified. While quality control in crowdsourcing has been widely studied, established mechanisms may still be improved to take into account other factors that affect quality. However, since crowdsourcing relies on humans, it is difficult to identify and consider all factors affecting quality. In this study, we conduct an initial investigation on the effect of crowd type and task complexity on work quality by crowdsourcing a simple and more complex version of a data extraction task to paid and unpaid crowds. We then measure the quality of the results in terms of its similarity to a gold standard data set. Our experiments show that the unpaid crowd produces results of high quality regardless of the type of task while the paid crowd yields better results in simple tasks. We intend to extend our work to integrate existing quality control mechanisms and perform more experiments with more varied crowd members.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "39677946",
                    "name": "Thomas Laurent"
                },
                {
                    "authorId": "48449806",
                    "name": "Motomichi Toyama"
                }
            ]
        }
    ]
}