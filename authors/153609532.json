{
    "authorId": "153609532",
    "papers": [
        {
            "paperId": "dd4f872c22a6b7c28a81b9ea1f803f1b34bb29e1",
            "title": "Personalization for Robust Voice Pathology Detection in Sound Waves",
            "abstract": "Automatic voice pathology detection is promising for non-invasive screening and early intervention using sound signals. Nevertheless, existing methods are susceptible to covariate shifts due to background noises, human voice variations, and data selection biases leading to severe performance degradation in real-world scenarios. Hence, we propose a non-invasive framework that contrastively learns personalization from sound waves as a pre-train and predicts latent-spaced profile features through semi-supervised learning. It allows all subjects from various distributions (e.g., regionality, gender, age) to benefit from personalized predictions for robust voice pathology in a privacy-fulfilled manner. We extensively evaluate the framework on four real-world respiratory illnesses datasets, including Coswara, COUGHVID, ICBHI, and our private dataset - ASound under multiple covariate shift settings (i.e., cross-dataset), improving up to 4.12% in overall performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2230079907",
                    "name": "Khanh-Tung Tran"
                },
                {
                    "authorId": "46208719",
                    "name": "Hoang Van Truong"
                },
                {
                    "authorId": "2230323525",
                    "name": "D. Nguyen"
                },
                {
                    "authorId": "153609532",
                    "name": "H. D. Nguyen"
                },
                {
                    "authorId": "2399573",
                    "name": "Xuan-Son Vu"
                }
            ]
        },
        {
            "paperId": "d0099abc45435a45fe95672c46fb78e611d5af75",
            "title": "A Novel Approach for Pill-Prescription Matching with GNN Assistance and Contrastive Learning",
            "abstract": "Medication mistaking is one of the risks that can result in unpredictable consequences for patients. To mitigate this risk, we develop an automatic system that correctly identifies pill-prescription from mobile images. Specifically, we define a so-called pill-prescription matching task, which attempts to match the images of the pills taken with the pills' names in the prescription. We then propose PIMA, a novel approach using Graph Neural Network (GNN) and contrastive learning to address the targeted problem. In particular, GNN is used to learn the spatial correlation between the text boxes in the prescription and thereby highlight the text boxes carrying the pill names. In addition, contrastive learning is employed to facilitate the modeling of cross-modal similarity between textual representations of pill names and visual representations of pill images. We conducted extensive experiments and demonstrated that PIMA outperforms baseline models on a real-world dataset of pill and prescription images that we constructed. Specifically, PIMA improves the accuracy from 19.09% to 46.95% compared to other baselines. We believe our work can open up new opportunities to build new clinical applications and improve medication safety and patient care.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2156262398",
                    "name": "Trung Thanh Nguyen"
                },
                {
                    "authorId": "153609532",
                    "name": "H. D. Nguyen"
                },
                {
                    "authorId": "2117823930",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "143635391",
                    "name": "H. Pham"
                },
                {
                    "authorId": "1679187",
                    "name": "I. Ide"
                },
                {
                    "authorId": "2143967163",
                    "name": "Phi-Le Nguyen"
                }
            ]
        },
        {
            "paperId": "69a1943e13863b3273d6d8b37fcf4ac066ae0866",
            "title": "Modular Graph Transformer Networks for Multi-Label Image Classification",
            "abstract": "With the recent advances in graph neural networks, there is a rising number of studies on graph-based multi-label classification with the consideration of object dependencies within visual data. Nevertheless, graph representations can become indistinguishable due to the complex nature of label relationships. We propose a multi-label image classification framework based on graph transformer networks to fully exploit inter-label interactions. The paper presents a modular learning scheme to enhance the classification performance by segregating the computational graph into multiple sub-graphs based on modularity. The proposed approach, named Modular Graph Transformer Networks (MGTN), is capable of employing multiple backbones for better information propagation over different sub-graphs guided by graph transformers and convolutions. We validate our framework on MS-COCO and Fashion550K datasets to demonstrate improvements for multi-label image classification. The source code is available at https://github.com/ReML-AI/MGTN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153609532",
                    "name": "H. D. Nguyen"
                },
                {
                    "authorId": "2399573",
                    "name": "Xuan-Son Vu"
                },
                {
                    "authorId": "40140266",
                    "name": "Duc-Trong Le"
                }
            ]
        },
        {
            "paperId": "574d90a9a74e75fefb005e3d55aad9258c608d93",
            "title": "Reinforced Data Sampling for Model Diversification",
            "abstract": "With the rising number of machine learning competitions, the world has witnessed an exciting race for the best algorithms. However, the involved data selection process may fundamentally suffer from evidence ambiguity and concept drift issues, thereby possibly leading to deleterious effects on the performance of various models. This paper proposes a new Reinforced Data Sampling (RDS) method to learn how to sample data adequately on the search for useful models and insights. We formulate the optimisation problem of model diversification $\\delta{-div}$ in data sampling to maximise learning potentials and optimum allocation by injecting model diversity. This work advocates the employment of diverse base learners as value functions such as neural networks, decision trees, or logistic regressions to reinforce the selection process of data subsets with multi-modal belief. We introduce different ensemble reward mechanisms, including soft voting and stochastic choice to approximate optimal sampling policy. The evaluation conducted on four datasets evidently highlights the benefits of using RDS method over traditional sampling approaches. Our experimental results suggest that the trainable sampling for model diversification is useful for competition organisers, researchers, or even starters to pursue full potentials of various machine learning tasks such as classification and regression. The source code is available at this https URL.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "153609532",
                    "name": "H. D. Nguyen"
                },
                {
                    "authorId": "2399573",
                    "name": "Xuan-Son Vu"
                },
                {
                    "authorId": "39603708",
                    "name": "Quoc-Tuan Truong"
                },
                {
                    "authorId": "40140266",
                    "name": "Duc-Trong Le"
                }
            ]
        },
        {
            "paperId": "97cd65764e8314defcdc52c392b3907c958414ea",
            "title": "Privacy-Preserving Visual Content Tagging using Graph Transformer Networks",
            "abstract": "With the rapid growth of Internet media, content tagging has become an important topic with many multimedia understanding applications, including efficient organisation and search. Nevertheless, existing visual tagging approaches are susceptible to inherent privacy risks in which private information may be exposed unintentionally. The use of anonymisation and privacy-protection methods is desirable, but with the expense of task performance. Therefore, this paper proposes an end-to-end framework (SGTN) using Graph Transformer and Convolutional Networks to significantly improve classification and privacy preservation of visual data. Especially, we employ several mechanisms such as differential privacy based graph construction and noise-induced graph transformation to protect the privacy of knowledge graphs. Our approach unveils new state-of-the-art on MS-COCO dataset in various semi-supervised settings. In addition, we showcase a real experiment in the education domain to address the automation of sensitive document tagging. Experimental results show that our approach achieves an excellent balance of model accuracy and privacy preservation on both public and private datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2399573",
                    "name": "Xuan-Son Vu"
                },
                {
                    "authorId": "40140266",
                    "name": "Duc-Trong Le"
                },
                {
                    "authorId": "2079623218",
                    "name": "Christoffer Edlund"
                },
                {
                    "authorId": "1630481449",
                    "name": "Lili Jiang"
                },
                {
                    "authorId": "153609532",
                    "name": "H. D. Nguyen"
                }
            ]
        },
        {
            "paperId": "f6da6519ab8e37cbe7ede0cf8f370bcaf590d9c4",
            "title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites",
            "abstract": "This paper reports on the ReINTEL Shared Task for Responsible Information Identification on social network sites, which is hosted at the seventh annual workshop on Vietnamese Language and Speech Processing (VLSP 2020). Given a piece of news with respective textual, visual content and metadata, participants are required to classify whether the news is `reliable' or `unreliable'. In order to generate a fair benchmark, we introduce a novel human-annotated dataset of over 10,000 news collected from a social network in Vietnam. All models will be evaluated in terms of AUC-ROC score, a typical evaluation metric for classification. The competition was run on the Codalab platform. Within two months, the challenge has attracted over 60 participants and recorded nearly 1,000 submission entries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40140266",
                    "name": "Duc-Trong Le"
                },
                {
                    "authorId": "2399573",
                    "name": "Xuan-Son Vu"
                },
                {
                    "authorId": "2037851165",
                    "name": "Nhu-Dung To"
                },
                {
                    "authorId": "2214587659",
                    "name": "Huu Nguyen"
                },
                {
                    "authorId": "2116085393",
                    "name": "Thuy-Trinh Nguyen"
                },
                {
                    "authorId": "2056343948",
                    "name": "Linh Le"
                },
                {
                    "authorId": "1398541475",
                    "name": "A. Nguyen"
                },
                {
                    "authorId": "1388547137",
                    "name": "Minh-Duc Hoang"
                },
                {
                    "authorId": "2057194447",
                    "name": "Nghia T. Le"
                },
                {
                    "authorId": "51405065",
                    "name": "Huyen Thi Minh Nguyen"
                },
                {
                    "authorId": "153609532",
                    "name": "H. D. Nguyen"
                }
            ]
        }
    ]
}