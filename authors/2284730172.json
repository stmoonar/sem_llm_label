{
    "authorId": "2284730172",
    "papers": [
        {
            "paperId": "37741a9e9a2cb964ca3c7ab034c3e077baf66c8c",
            "title": "BiVRec: Bidirectional View-based Multimodal Sequential Recommendation",
            "abstract": "The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we first construct structured user interest representations and then learn the synergistic relationship between them. Specifically, BivRec comprises three modules: Multi-scale Interest Embedding, comprehensively modeling user interests by expanding user interaction sequences with multi-scale patching; Intra-View Interest Decomposition, constructing highly structured interest representations using carefully designed Gaussian attention and Cluster attention; and Cross-View Interest Learning, learning the synergistic relationship between the two recommendation views through coarse-grained overall semantic similarity and fine-grained interest allocation similarity BiVRec achieves state-of-the-art performance on five datasets and showcases various practical advantages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2284735864",
                    "name": "Yuehong Hu"
                },
                {
                    "authorId": "2289093854",
                    "name": "Yuxuan Liang"
                },
                {
                    "authorId": "2282243915",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2287901729",
                    "name": "Ming He"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2282271789",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "7357961c1f068f6b56e5513c4887ef00d28113ba",
            "title": "TwinS: Revisiting Non-Stationarity in Multivariate Time Series Forecasting",
            "abstract": "Recently, multivariate time series forecasting tasks have garnered increasing attention due to their significant practical applications, leading to the emergence of various deep forecasting models. However, real-world time series exhibit pronounced non-stationary distribution characteristics. These characteristics are not solely limited to time-varying statistical properties highlighted by non-stationary Transformer but also encompass three key aspects: nested periodicity, absence of periodic distributions, and hysteresis among time variables. In this paper, we begin by validating this theory through wavelet analysis and propose the Transformer-based TwinS model, which consists of three modules to address the non-stationary periodic distributions: Wavelet Convolution, Period-Aware Attention, and Channel-Temporal Mixed MLP. Specifically, The Wavelet Convolution models nested periods by scaling the convolution kernel size like wavelet transform. The Period-Aware Attention guides attention computation by generating period relevance scores through a convolutional sub-network. The Channel-Temporal Mixed MLP captures the overall relationships between time series through channel-time mixing learning. TwinS achieves SOTA performance compared to mainstream TS models, with a maximum improvement in MSE of 25.8\\% over PatchTST.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "2253561592",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2297769202",
                    "name": "Sijie Ruan"
                },
                {
                    "authorId": "2293451547",
                    "name": "Li Liu"
                },
                {
                    "authorId": "2253824408",
                    "name": "Yuxuan Liang"
                }
            ]
        },
        {
            "paperId": "de7f235452bec5304290f6faa54b9ff36a27e592",
            "title": "Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting",
            "abstract": "State Space Models (SSMs) have emerged as a potent tool in sequence modeling tasks in recent years. These models approximate continuous systems using a set of basis functions and discretize them to handle input data, making them well-suited for modeling time series data collected at specific frequencies from continuous systems. Despite its potential, the application of SSMs in time series forecasting remains underexplored, with most existing models treating SSMs as a black box for capturing temporal or channel dependencies. To address this gap, this paper proposes a novel theoretical framework termed Dynamic Spectral Operator, offering more intuitive and general guidance on applying SSMs to time series data. Building upon our theory, we introduce Time-SSM, a novel SSM-based foundation model with only one-seventh of the parameters compared to Mamba. Various experiments validate both our theoretical framework and the superior performance of Time-SSM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "2303407868",
                    "name": "Disen Lan"
                },
                {
                    "authorId": "2303418753",
                    "name": "Ziyu Zhou"
                },
                {
                    "authorId": "2253561592",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2253824408",
                    "name": "Yuxuan Liang"
                }
            ]
        },
        {
            "paperId": "f3ca1515d610ec8811d3b4f9a209eae099523048",
            "title": "Attractor Memory for Long-Term Time Series Forecasting: A Chaos Perspective",
            "abstract": "In long-term time series forecasting (LTSF) tasks, an increasing number of models have acknowledged that discrete time series originate from continuous dynamic systems and have attempted to model their dynamical structures. Recognizing the chaotic nature of real-world data, our model, \\textbf{\\textit{Attraos}}, incorporates chaos theory into LTSF, perceiving real-world time series as observations from unknown high-dimensional chaotic dynamic systems. Under the concept of attractor invariance, Attraos utilizes non-parametric Phase Space Reconstruction embedding and the proposed multi-scale dynamic memory unit to memorize historical dynamics structure and predicts by a frequency-enhanced local evolution strategy. Detailed theoretical analysis and abundant empirical evidence consistently show that Attraos outperforms various LTSF methods on mainstream LTSF datasets and chaotic datasets with only one-twelfth of the parameters compared to PatchTST.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "2284735864",
                    "name": "Yuehong Hu"
                },
                {
                    "authorId": "2262453292",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2254096428",
                    "name": "Ming Jin"
                },
                {
                    "authorId": "2254047333",
                    "name": "Shirui Pan"
                },
                {
                    "authorId": "2253561592",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2253824408",
                    "name": "Yuxuan Liang"
                }
            ]
        },
        {
            "paperId": "43674b7c8d4858ef560794fc5c0c9add42fd4cf4",
            "title": "Multimodal Recommender Systems: A Survey",
            "abstract": "\n The recommender system (RS) has been an integral toolkit of online services. They are equipped with various deep learning techniques to model user preference based on identifier and attribute information. With the emergence of multimedia services, such as short videos, news and\n etc.\n , understanding these contents while recommending becomes critical. Besides, multimodal features are also helpful in alleviating the problem of data sparsity in RS. Thus,\n M\n ultimodal\n R\n ecommender\n S\n ystem (MRS) has attracted much attention from both academia and industry recently. In this paper, we will give a comprehensive survey of the MRS models, mainly from technical views. First, we conclude the general procedures and major challenges for MRS. Then, we introduce the existing MRS models according to four categories,\n i.e.,\n Modality Encoder\n ,\n Feature Interaction\n ,\n Feature Enhancement\n and\n Model Optimization\n . Besides, to make it convenient for those who want to research this field, we also summarize the dataset and code resources. Finally, we discuss some promising future directions of MRS and conclude this paper. To access more details of the surveyed papers, such as implementation code, we open source a repository.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112246463",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "150352978",
                    "name": "Yutian Xiao"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                }
            ]
        }
    ]
}