{
    "authorId": "2246897295",
    "papers": [
        {
            "paperId": "42d2e852d9f3d7bcc499584fe0a8e5ad8a2df11e",
            "title": "Structural Knowledge Informed Continual Multivariate Time Series Forecasting",
            "abstract": "Recent studies in multivariate time series (MTS) forecasting reveal that explicitly modeling the hidden dependencies among different time series can yield promising forecasting performance and reliable explanations. However, modeling variable dependencies remains underexplored when MTS is continuously accumulated under different regimes (stages). Due to the potential distribution and dependency disparities, the underlying model may encounter the catastrophic forgetting problem, i.e., it is challenging to memorize and infer different types of variable dependencies across different regimes while maintaining forecasting performance. To address this issue, we propose a novel Structural Knowledge Informed Continual Learning (SKI-CL) framework to perform MTS forecasting within a continual learning paradigm, which leverages structural knowledge to steer the forecasting model toward identifying and adapting to different regimes, and selects representative MTS samples from each regime for memory replay. Specifically, we develop a forecasting model based on graph structure learning, where a consistency regularization scheme is imposed between the learned variable dependencies and the structural knowledge while optimizing the forecasting objective over the MTS data. As such, MTS representations learned in each regime are associated with distinct structural knowledge, which helps the model memorize a variety of conceivable scenarios and results in accurate forecasts in the continual learning context. Meanwhile, we develop a representation-matching memory replay scheme that maximizes the temporal coverage of MTS data to efficiently preserve the underlying temporal dynamics and dependency structures of each regime. Thorough empirical studies on synthetic and real-world benchmarks validate SKI-CL's efficacy and advantages over the state-of-the-art for continual MTS forecasting tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2281612988",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2257349440",
                    "name": "Sahil Garg"
                },
                {
                    "authorId": "4565995",
                    "name": "Kashif Rasul"
                },
                {
                    "authorId": "2257349988",
                    "name": "Anderson Schneider"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                }
            ]
        },
        {
            "paperId": "44f6cea2aa05620fef00d8dc9e566918dc6771c9",
            "title": "Empowering Time Series Analysis with Large Language Models: A Survey",
            "abstract": "Recently, remarkable progress has been made over large language models (LLMs), demonstrating their unprecedented capability in varieties of natural language tasks. However, completely training a large general-purpose model from the scratch is challenging for time series analysis, due to the large volumes and varieties of time series data, as well as the non-stationarity that leads to concept drift impeding continuous model adaptation and re-training. Recent advances have shown that pre-trained LLMs can be exploited to capture complex dependencies in time series data and facilitate various applications. In this survey, we provide a systematic overview of existing methods that leverage LLMs for time series analysis. Specifically, we first state the challenges and motivations of applying language models in the context of time series as well as brief preliminaries of LLMs. Next, we summarize the general pipeline for LLM-based time series analysis, categorize existing methods into different groups (\\textit{i.e.}, direct query, tokenization, prompt design, fine-tune, and model integration), and highlight the key ideas within each group. We also discuss the applications of LLMs for both general and spatial-temporal time series data, tailored to specific domains. Finally, we thoroughly discuss future research opportunities to empower time series analysis with LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "2281612988",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2257349440",
                    "name": "Sahil Garg"
                },
                {
                    "authorId": "2257349988",
                    "name": "Anderson Schneider"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "a0e7f328781eda3e3dc919c77bd1eedb99b99612",
            "title": "S2IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting",
            "abstract": "Recently, there has been a growing interest in leveraging pre-trained large language models (LLMs) for various time series applications. However, the semantic space of LLMs, established through the pre-training, is still underexplored and may help yield more distinctive and informative representations to facilitate time series forecasting. To this end, we propose Semantic Space Informed Prompt learning with LLM ($S^2$IP-LLM) to align the pre-trained semantic space with time series embeddings space and perform time series forecasting based on learned prompts from the joint space. We first design a tokenization module tailored for cross-modality alignment, which explicitly concatenates patches of decomposed time series components to create embeddings that effectively encode the temporal dynamics. Next, we leverage the pre-trained word token embeddings to derive semantic anchors and align selected anchors with time series embeddings by maximizing the cosine similarity in the joint space. This way, $S^2$IP-LLM can retrieve relevant semantic anchors as prompts to provide strong indicators (context) for time series that exhibit different temporal dynamics. With thorough empirical studies on multiple benchmark datasets, we demonstrate that the proposed $S^2$IP-LLM can achieve superior forecasting performance over state-of-the-art baselines. Furthermore, our ablation studies and visualizations verify the necessity of prompt learning informed by semantic space.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2281612988",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "2257349440",
                    "name": "Sahil Garg"
                },
                {
                    "authorId": "2257349988",
                    "name": "Anderson Schneider"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "4bdb8888b106bd45a785d6a3afe6dac222fedb25",
            "title": "The 9th SIGKDD International Workshop on Mining and Learning from Time Series",
            "abstract": "Time series data has become pervasive across domains such as finance, transportation, retail, entertainment, and healthcare. This shift towards continuous monitoring and recording, fueled by advancements in sensing technologies, necessitates the development of new tools and solutions. Despite extensive study, the importance of time series analysis continues to increase. However, modern time series data present challenges to existing techniques, including irregular sampling and spatiotemporal structures. Time series mining research is both challenging and rewarding as it connects diverse disciplines and requires interdisciplinary solutions. The goals of this workshop are to (1) highlight the significant challenges that underpin learning and mining from time series data (e.g., irregular sampling, spatiotemporal structure, uncertainty quantification), (2) discuss recent algorithmic, theoretical, statistical, or systems-based developments for tackling these problems, and (3) to synergize the research activities and discuss both new and open problems in time series analysis and mining. In summary, our workshop will focus on both the theoretical and practical aspects of time series data analysis and will provide a platform for researchers and practitioners from academia and industry to discuss potential research directions and critical technical issues and present solutions to tackle related issues in practical applications. We will invite researchers and practitioners from the related areas of AI, machine learning, data science, statistics, and many others to contribute to this workshop.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2181310178",
                    "name": "Jun Huan"
                },
                {
                    "authorId": "2113392954",
                    "name": "Cong Shen"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                }
            ]
        },
        {
            "paperId": "f005889b7d85558f978d40506196e9a853b5ed15",
            "title": "Lag-Llama: Towards Foundation Models for Time Series Forecasting",
            "abstract": "Aiming to build foundation models for time-series forecasting and study their scaling behavior, we present here our work-in-progress on Lag-Llama , a general-purpose univariate probabilistic time-series forecasting model trained on a large collection of time-series data. The model shows good zero-shot prediction capabilities on unseen \u201cout-of-distribution\u201d time-series datasets, outperforming supervised baselines. We use smoothly broken power-laws [7] to fit and predict model scaling behavior. The open source code is made available at https://github",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4565995",
                    "name": "Kashif Rasul"
                },
                {
                    "authorId": "2253400055",
                    "name": "Arjun Ashok"
                },
                {
                    "authorId": "2258310022",
                    "name": "Andrew Robert Williams"
                },
                {
                    "authorId": "2257347656",
                    "name": "Arian Khorasani"
                },
                {
                    "authorId": "2257347183",
                    "name": "George Adamopoulos"
                },
                {
                    "authorId": "2052115032",
                    "name": "Rishika Bhagwatkar"
                },
                {
                    "authorId": "1388111489",
                    "name": "Marin Bilos"
                },
                {
                    "authorId": "2257348423",
                    "name": "Hena Ghonia"
                },
                {
                    "authorId": "2124982378",
                    "name": "N. Hassen"
                },
                {
                    "authorId": "2257349988",
                    "name": "Anderson Schneider"
                },
                {
                    "authorId": "2257349440",
                    "name": "Sahil Garg"
                },
                {
                    "authorId": "2253399166",
                    "name": "Alexandre Drouin"
                },
                {
                    "authorId": "2748188",
                    "name": "Nicolas Chapados"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                },
                {
                    "authorId": "2239232896",
                    "name": "Irina Rish"
                }
            ]
        },
        {
            "paperId": "aae275290596b3e721cd32dfad5635d4c6f6132f",
            "title": "8th SIGKDD International Workshop on Mining and Learning from Time Series -- Deep Forecasting: Models, Interpretability, and Applications",
            "abstract": "Time series data are ubiquitous, and is one of the fastest growing and richest types of data. Recent advances in sensing technologies has resulted in a rapid growth in the size and complexity of time series archives. This demands development of new tools and solutions. The goals of this workshop are to: (1) highlight the significant challenges that underpin learning and mining from time series data (e.g. irregular sampling, spatiotemporal structure, uncertainty quantification), (2) discuss recent algorithmic, theoretical, statistical, or systems-based developments for tackling these problems, and (3) exploring new frontiers in time series analysis and their connections with important topics such as knowledge representation, reasoning, control, and business intelligence. In summary, our workshop will focus on both the theoretical and practical aspects of time series data analysis and will provide a platform for researchers and practitioners from both academia and industry to discuss potential research directions, key technical issues, and present solutions to tackle related issues in practical applications. We will invite researchers and practitioners from the related areas of AI, machine learning, data science, statistics, and many others to contribute to this workshop.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2181310178",
                    "name": "Jun Huan"
                },
                {
                    "authorId": "2113392954",
                    "name": "Cong Shen"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "49416149",
                    "name": "Bernie Wang"
                },
                {
                    "authorId": "2113062",
                    "name": "Jan Gasthaus"
                },
                {
                    "authorId": "31743390",
                    "name": "Hilaf Hasson"
                },
                {
                    "authorId": "1845861038",
                    "name": "Youngsuk Park"
                },
                {
                    "authorId": "145260557",
                    "name": "Sungyong Seo"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                }
            ]
        }
    ]
}