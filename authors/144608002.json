{
    "authorId": "144608002",
    "papers": [
        {
            "paperId": "00a458bc40016d10d3a4d640d4fc985328fa198b",
            "title": "FARSEC: A Reproducible Framework for Automatic Real-Time Vehicle Speed Estimation Using Traffic Cameras",
            "abstract": "Estimating the speed of vehicles using traffic cameras is a crucial task for traffic surveillance and management, enabling more optimal traffic flow, improved road safety, and lower environmental impact. Transportation-dependent systems, such as for navigation and logistics, have great potential to benefit from reliable speed estimation. While there is prior research in this area reporting competitive accuracy levels, their solutions lack reproducibility and robustness across different datasets. To address this, we provide a novel framework for automatic real-time vehicle speed calculation, which copes with more diverse data from publicly available traffic cameras to achieve greater robustness. Our model employs novel techniques to estimate the length of road segments via depth map prediction. Additionally, our framework is capable of handling realistic conditions such as camera movements and different video stream inputs automatically. We compare our model to three well-known models in the field using their benchmark datasets. While our model does not set a new state of the art regarding prediction performance, the results are competitive on realistic CCTV videos. At the same time, our end-to-end pipeline offers more consistent results, an easier implementation, and better compatibility. Its modular structure facilitates reproducibility and future improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2246882460",
                    "name": "Lucas Liebe"
                },
                {
                    "authorId": "2246892999",
                    "name": "Franz Sauerwald"
                },
                {
                    "authorId": "2246885213",
                    "name": "Sylwester Sawicki"
                },
                {
                    "authorId": "47486112",
                    "name": "M. Schneider"
                },
                {
                    "authorId": "2246882456",
                    "name": "Leo Schuhmann"
                },
                {
                    "authorId": "3361431",
                    "name": "Tolga Buz"
                },
                {
                    "authorId": "2246882839",
                    "name": "Paul Boes"
                },
                {
                    "authorId": "2246884674",
                    "name": "Ahmad Ahmadov"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                }
            ]
        },
        {
            "paperId": "3a9ee1824f5a37e24bdc518417b530619e654921",
            "title": "Temporal Ordinance Mining for Event-Driven Social Media Reaction Analytics",
            "abstract": "As a growing number of policies are adopted to address the substantial rise in urbanization, there is a significant push for smart governance, endowing transparency in decision-making and enabling greater public involvement. The thriving concept of smart governance goes beyond just cities, ultimately aiming at a smart planet. Ordinances (local laws) affect our life with regard to health, business, etc. This is particularly notable during major events such as the recent pandemic, which may lead to rapid changes in ordinances, pertaining for instance to public safety, disaster management, and recovery phases. However, many citizens view ordinances as impervious and complex. This position paper proposes a research agenda enabling novel forms of ordinance content analysis over time and temporal web question answering (QA) for both legislators and the broader public. Along with this, we aim to analyze social media posts so as to track the public opinion before and after the introduction of ordinances. Challenges include addressing concepts changing over time and infusing subtle human reasoning in mining, which we aim to address by harnessing terminology evolution methods and commonsense knowledge sources, respectively. We aim to make the results of the historical ordinance mining and event-driven analysis seamlessly accessible, relying on a robust semantic understanding framework to flexibly support web QA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154252",
                    "name": "A. Varde"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "2138845",
                    "name": "Boxiang Dong"
                }
            ]
        },
        {
            "paperId": "a5bc3c0bce8d105a6b95f999fed4ea59c342cb1d",
            "title": "Multi-Modal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision\u2013Language Models",
            "abstract": "Recent breakthroughs in self-supervised training have led to a new class of pretrained vision\u2013language models. While there have been investigations of bias in multimodal models, they have mostly focused on gender and racial bias, giving much less attention to other relevant groups, such as minorities with regard to religion, nationality, sexual orientation, or disabilities. This is mainly due to lack of suitable benchmarks for such groups. We seek to address this gap by providing a visual and textual bias benchmark called MMBias, consisting of around 3,800 images and phrases covering 14 population subgroups. We utilize this dataset to assess bias in several prominent self-supervised multimodal models, including CLIP, ALBEF, and ViLT. Our results show that these models demonstrate meaningful bias favoring certain groups. Finally, we introduce a debiasing method designed specifically for such large pretrained models that can be applied as a post-processing step to mitigate bias, while preserving the remaining accuracy of the model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51057369",
                    "name": "Sepehr Janghorbani"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                }
            ]
        },
        {
            "paperId": "b826c9318686f6e51a2f25484ea995b709283639",
            "title": "Disentangled CVAEs with Contrastive Learning for Explainable Recommendation",
            "abstract": "Modern recommender systems are increasingly expected to provide informative explanations that enable users to understand the reason for particular recommendations. However, previous methods struggle to interpret the input IDs of user--item pairs in real-world datasets, failing to extract adequate characteristics for controllable generation. To address this issue, we propose disentangled conditional variational autoencoders (CVAEs) for explainable recommendation, which leverage disentangled latent preference factors and guide the explanation generation with the refined condition of CVAEs via a self-regularization contrastive learning loss. Extensive experiments demonstrate that our method generates high-quality explanations and achieves new state-of-the-art results in diverse domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124862106",
                    "name": "Linlin Wang"
                },
                {
                    "authorId": "2113442256",
                    "name": "Zefeng Cai"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "2113997977",
                    "name": "Zhu Cao"
                },
                {
                    "authorId": "2148951260",
                    "name": "Liang He"
                }
            ]
        },
        {
            "paperId": "cd37a330aca9fbdb54716e4e43710ba4b125fc2c",
            "title": "Model-Agnostic Bias Measurement in Link Prediction",
            "abstract": "Link prediction models based on factual knowledge graphs are commonly used in applications such as search and question answering. However, work investigating social bias in these models has been limited. Previous work focused on knowledge graph embeddings, so more recent classes of models achieving superior results by fine-tuning Transformers have not yet been investigated. We therefore present a model-agnostic approach for bias measurement leveraging fairness metrics to compare bias in knowledge graph embedding-based predictions (KG only) with models that use pre-trained, Transformer-based language models (KG+LM). We further create a dataset to measure gender bias in occupation predictions and assess whether the KG+LM models are more or less biased than KG only models. We find that gender bias tends to be higher for the KG+LM models and analyze potential connections to the accuracy of the models and the data bias inherent in our dataset.Finally, we discuss the limitations and ethical considerations of our work. The repository containing the source code and the data set is publicly available at https://github.com/lena-schwert/comparing-bias-in-KG-models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "83138891",
                    "name": "Lena Schwertmann"
                },
                {
                    "authorId": "31405335",
                    "name": "M. Ravi"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                }
            ]
        },
        {
            "paperId": "d25f8c388677d287d00ca67d44ef02da2b45f2d9",
            "title": "Large Language Models and Knowledge Graphs: Opportunities and Challenges",
            "abstract": "Large Language Models (LLMs) have taken Knowledge Representation -- and the world -- by storm. This inflection point marks a shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge. In this position paper, we will discuss some of the common debate points within the community on LLMs (parametric knowledge) and Knowledge Graphs (explicit knowledge) and speculate on opportunities and visions that the renewed focus brings, as well as related research topics and challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9416872",
                    "name": "Jeff Z. Pan"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "3245041",
                    "name": "Jan-Christoph Kalo"
                },
                {
                    "authorId": "29001552",
                    "name": "Sneha Singhania"
                },
                {
                    "authorId": "1731892",
                    "name": "Jiaoyan Chen"
                },
                {
                    "authorId": "3081683",
                    "name": "S. Dietze"
                },
                {
                    "authorId": "2362078",
                    "name": "Hajira Jabeen"
                },
                {
                    "authorId": "2008000176",
                    "name": "Janna Omeliyanenko"
                },
                {
                    "authorId": "2155281129",
                    "name": "Wen Zhang"
                },
                {
                    "authorId": "2574504",
                    "name": "Matteo Lissandrini"
                },
                {
                    "authorId": "51119656",
                    "name": "Russa Biswas"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "1699192",
                    "name": "A. Bonifati"
                },
                {
                    "authorId": "2007891598",
                    "name": "Edlira Vakaj"
                },
                {
                    "authorId": "2346796",
                    "name": "M. Dragoni"
                },
                {
                    "authorId": "2235966",
                    "name": "D. Graux"
                }
            ]
        },
        {
            "paperId": "dcc2dd6221a00a0b469551fd313b95b6cc870123",
            "title": "Robust NLP for Finance (RobustFin)",
            "abstract": "Natural language processing (NLP) technologies have been widely applied in business domains such as e-commerce and customer service, but their adoption in the financial sector has been constrained by industry-specific performance standards and regulatory restrictions. This challenge has created new opportunities for core research in related areas. Recent advancements in NLP, such as the advent of large language models, has encouraged adoption in the finance sector. However, compared to other domains, finance has stricter requirements for robustness, explainability, and generalizability. Given this background, we propose to organize the first Robust NLP for Finance (RobustFin) workshop at KDD '23 to encourage the study of and research on robustness and explainability technologies with regard to financial NLP. The goal of the workshop is to extend the applications of NLP in finance, while motivating further research in robust NLP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36532736",
                    "name": "Sameena Shah"
                },
                {
                    "authorId": "1854999",
                    "name": "Xiao-Dan Zhu"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "2144369",
                    "name": "Armineh Nourbakhsh"
                },
                {
                    "authorId": "2108959746",
                    "name": "Xiaomo Liu"
                },
                {
                    "authorId": "2223933086",
                    "name": "Zhiqiang Ma"
                },
                {
                    "authorId": "37722032",
                    "name": "Charese Smiley"
                },
                {
                    "authorId": "2142370346",
                    "name": "Zhiyu Chen"
                }
            ]
        },
        {
            "paperId": "f02872dc8707cb9e0ed78c85eec4b73ff1bd4edb",
            "title": "Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?",
            "abstract": "Given the success of Graph Neural Networks (GNNs) for structure-aware machine learning, numerous studies have explored their application to text classification, as an alternative to traditional feature representation models. However, most studies considered just a specific domain and validated on data with particular characteristics. This work presents an extensive empirical investigation of graph-based text representation methods proposed for text classification, identifying practical implications and open challenges in the field. We compare several GNN architectures as well as BERT across five datasets, encompassing short and also long documents. The results show that: i) graph performance is highly related to the textual input features and domain, ii) despite its outstanding performance, BERT has difficulties converging when dealing with short texts, iii) graph methods are particularly beneficial for longer documents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72840732",
                    "name": "M. Bugue\u00f1o"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                }
            ]
        },
        {
            "paperId": "f9e307b8c48c6ce27c993f017f5e951e35a59734",
            "title": "Harnessing Neighborhood Modeling and Asymmetry Preservation for Digraph Representation Learning",
            "abstract": "Digraph Representation Learning aims to learn representations for directed homogeneous graphs (digraphs). Prior work is largely constrained or has poor generalizability across tasks. Most Graph Neural Networks exhibit poor performance on digraphs due to the neglect of modeling neighborhoods and preserving asymmetry. In this paper, we address these notable challenges by leveraging hyperbolic collaborative learning from multi-ordered partitioned neighborhoods and asymmetry-preserving regularizers. Our resulting formalism, Digraph Hyperbolic Networks (D-HYPR), is versatile for multiple tasks including node classification, link presence prediction, and link property prediction. The efficacy of D-HYPR was meticulously examined against 21 previous techniques, using 8 real-world digraph datasets. D-HYPR statistically significantly outperforms the current state of the art. We release our code at https://github. com/hongluzhou/dhypr.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157475030",
                    "name": "Honglu Zhou"
                },
                {
                    "authorId": "2146693355",
                    "name": "Advith Chegu"
                },
                {
                    "authorId": "51118484",
                    "name": "Samuel S. Sohn"
                },
                {
                    "authorId": "2011378",
                    "name": "Zuohui Fu"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "143980997",
                    "name": "M. Kapadia"
                }
            ]
        },
        {
            "paperId": "0242e25ffb7fe83351ec06d286d7effceca4eb44",
            "title": "ViLPAct: A Benchmark for Compositional Generalization on Multimodal Human Activities",
            "abstract": "We introduce {dataset, a novel vision-language benchmark for human activity planning. It is designed for a task where embodied AI agents can reason and forecast future actions of humans based on video clips about their initial activities and intents in text. The dataset consists of 2.9k videos from {charades extended with intents via crowdsourcing, a multi-choice question test set, and four strong baselines. One of the baselines implements a neurosymbolic approach based on a multi-modal knowledge base (MKB), while the other ones are deep generative models adapted from recent state-of-the-art (SOTA) methods. According to our extensive experiments, the key challenges are compositional generalization and effective use of information from both modalities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080123731",
                    "name": "Terry Yue Zhuo"
                },
                {
                    "authorId": "2114122093",
                    "name": "Yaqing Liao"
                },
                {
                    "authorId": "2187557239",
                    "name": "Yuecheng Lei"
                },
                {
                    "authorId": "14564042",
                    "name": "Lizhen Qu"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "144950946",
                    "name": "Xiaojun Chang"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1683510",
                    "name": "Zenglin Xu"
                }
            ]
        }
    ]
}