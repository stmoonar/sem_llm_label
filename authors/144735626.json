{
    "authorId": "144735626",
    "papers": [
        {
            "paperId": "3646de39a9ef976ddef7d5249d4f066c8a0cf7de",
            "title": "Vista-Morph: Unsupervised Image Registration of Visible-Thermal Facial Pairs",
            "abstract": "For a variety of biometric cross-spectral tasks, Visible-Thermal (VT) facial pairs are used. However, due to a lack of calibration in the lab, photographic capture between two different sensors leads to severely misaligned pairs that can lead to poor results for person re-identification and generative AI. To solve this problem, we introduce our approach for VT image registration called Vista Morph. Unlike existing VT facial registration that requires manual, hand-crafted features for pixel matching and/or a supervised thermal reference, Vista Morph is completely unsupervised without the need for a reference. By learning the affine matrix through a Vision Transformer (ViT)-based Spatial Transformer Network (STN) and Generative Adversarial Networks (GAN), Vista Morph successfully aligns facial and non-facial VT images. Our approach learns warps in Hard, No, and Low-light visual settings and is robust to geometric perturbations and erasure at test time. We conduct a downstream generative AI task to show that registering training data with Vista Morph improves subject identity of generated thermal faces when performing V2T image translation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6138190",
                    "name": "Catherine Ordun"
                },
                {
                    "authorId": "34885007",
                    "name": "Edward Raff"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                }
            ]
        },
        {
            "paperId": "4bdb8888b106bd45a785d6a3afe6dac222fedb25",
            "title": "The 9th SIGKDD International Workshop on Mining and Learning from Time Series",
            "abstract": "Time series data has become pervasive across domains such as finance, transportation, retail, entertainment, and healthcare. This shift towards continuous monitoring and recording, fueled by advancements in sensing technologies, necessitates the development of new tools and solutions. Despite extensive study, the importance of time series analysis continues to increase. However, modern time series data present challenges to existing techniques, including irregular sampling and spatiotemporal structures. Time series mining research is both challenging and rewarding as it connects diverse disciplines and requires interdisciplinary solutions. The goals of this workshop are to (1) highlight the significant challenges that underpin learning and mining from time series data (e.g., irregular sampling, spatiotemporal structure, uncertainty quantification), (2) discuss recent algorithmic, theoretical, statistical, or systems-based developments for tackling these problems, and (3) to synergize the research activities and discuss both new and open problems in time series analysis and mining. In summary, our workshop will focus on both the theoretical and practical aspects of time series data analysis and will provide a platform for researchers and practitioners from academia and industry to discuss potential research directions and critical technical issues and present solutions to tackle related issues in practical applications. We will invite researchers and practitioners from the related areas of AI, machine learning, data science, statistics, and many others to contribute to this workshop.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2181310178",
                    "name": "Jun Huan"
                },
                {
                    "authorId": "2113392954",
                    "name": "Cong Shen"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                }
            ]
        },
        {
            "paperId": "4e5da7c5c9c9a333afd8d2a53baf5fdd2d1a6040",
            "title": "An Online Continuous Semantic Segmentation Framework With Minimal Labeling Efforts",
            "abstract": "The annotation load for a new dataset has been greatly decreased using domain adaptation based semantic segmentation, which iteratively constructs pseudo labels on unlabeled target data and retrains the network. However, realistic segmentation datasets are often imbalanced, with pseudo-labels tending to favor certain \"head\" classes while neglecting other \"tail\" classes. This can lead to an inaccurate and noisy mask. To address this issue, we propose a novel hard sample mining strategy for an active domain adaptation based semantic segmentation network, with the aim of automatically selecting a small subset of labeled target data to fine-tune the network. By calculating class-wise entropy, we are able to rank the difficulty level of different samples. We use a fusion of focal loss and regional mutual information loss instead of cross-entropy loss for the domain adaptation based semantic segmentation network. Our entire framework has been implemented in real-time using the Robotics Operating System (ROS) with a server PC and a small Unmanned Ground Vehicle (UGV) known as the ROSbot2.0 Pro. This implementation allows ROSbot2.0 Pro to access any type of data at any time, enabling it to perform a variety of tasks with ease. Our approach has been thoroughly evaluated through a series of extensive experiments, which demonstrate its superior performance compared to existing state-of-the-art methods. Remarkably, by using just 20% of hard samples for fine-tuning, our network has achieved a level of performance that is comparable (\u224888%) to that of a fully supervised approach, with mIOU scores of 60.51% in the In-house dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145354488",
                    "name": "Masud Ahmed"
                },
                {
                    "authorId": "2067241490",
                    "name": "Zahid Hasan"
                },
                {
                    "authorId": "2230577775",
                    "name": "Tim Yingling"
                },
                {
                    "authorId": "2229491577",
                    "name": "Eric O'Leary"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2190321104",
                    "name": "Suya You"
                },
                {
                    "authorId": "47705715",
                    "name": "Nirmalya Roy"
                }
            ]
        },
        {
            "paperId": "63e8f0e96c21cff7cf5ca1f4910b483c980a6261",
            "title": "Novel Categories Discovery Via Constraints on Empirical Prediction Statistics",
            "abstract": "Novel Categories Discovery (NCD) aims to cluster novel data based on the class semantics of known classes using the open-world partial class space annotated dataset. As an alternative to the traditional pseudo-labeling-based approaches, we leverage the connection between the data sampling and the provided multinoulli (categorical) distribution of novel classes. We introduce constraints on individual and collective statistics of predicted novel class probabilities to implicitly achieve semantic-based clustering. More specifically, we align the class neuron activation distributions under Monte-Carlo sampling of novel classes in large batches by matching their empirical first-order (mean) and second-order (covariance) statistics with the multinoulli distribution of the labels while applying instance information constraints and prediction consistency under label-preserving augmentations. We then explore a directional statistics-based probability formation that learns the mixture of Von Mises-Fisher distribution of class labels in a unit hypersphere. We demonstrate the discriminative ability of our approach to realize semantic clustering of novel samples in image, video, and time-series modalities. We perform extensive ablation studies regarding data, networks, and framework components to provide better insights. Our approach maintains 94%, 93%, 85%, and 93% (approx.) classification accuracy in labeled data while achieving 90%, 84%, 72%, and 75% (approx.) clustering accuracy for novel categories in Cifar10, UCF101, MPSC-ARL, and SHAR datasets that match state-of-the-art approaches without any external clustering.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067241490",
                    "name": "Zahid Hasan"
                },
                {
                    "authorId": "35613119",
                    "name": "A. Faridee"
                },
                {
                    "authorId": "145354488",
                    "name": "Masud Ahmed"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "1688527",
                    "name": "H. Kwon"
                },
                {
                    "authorId": "2445131",
                    "name": "Hyungtae Lee"
                },
                {
                    "authorId": "1515122607",
                    "name": "Nirmalya Roy"
                }
            ]
        },
        {
            "paperId": "83b0df1971581ad09e47a3097ce930a16446f576",
            "title": "FedPseudo: Privacy-Preserving Pseudo Value-Based Deep Learning Models for Federated Survival Analysis",
            "abstract": "Survival analysis, aka time-to-event analysis, has a wide-ranging impact on patient care. Federated Survival Analysis (FSA) is an emerging Federated Learning (FL) paradigm for performing survival analysis on distributed decentralized data available at multiple medical institutions. FSA enables individual medical institutions, referred to as clients, to improve their survival predictions while ensuring privacy. However, FSA faces challenges due to non-linear and non-IID data distributions among clients, as well as bias caused by censoring. Although recent studies have adapted Cox Proportional Hazards (CoxPH) survival models for FSA, a systematic exploration of these challenges is currently lacking. In this paper, we address these critical challenges by introducing FedPseudo, a pseudo value-based deep learning framework for FSA. FedPseudo uses deep learning models to learn robust representations from non-linear survival data, leverages the power of pseudo values to handle non-uniform censoring, and employs FL algorithms such as FedAvg to learn model parameters. We propose a novel and simple approach for estimating pseudo values for FSA. We provide theoretical proof that the estimated pseudo values, referred to as Federated Pseudo Values, are consistent. Moreover, our empirical results demonstrate that they can be computed faster than traditional methods of deriving pseudo values. To ensure and enhance the privacy of both the estimated pseudo values and the shared model parameters, we systematically investigate the application of differential privacy (DP) on both the federated pseudo values and local model updates. Furthermore, we adapt V -Usable Information metric to quantify the informativeness of a client's data for training a survival model and utilize this metric to show the advantages of participating in FSA. We conducted extensive experiments on synthetic and real-world survival datasets to demonstrate that our FedPseudo framework achieves better performance than other FSA approaches and performs similarly to the best centrally trained deep survival model. Moreover, FedPseudo consistently achieves superior results across different censoring settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145557612",
                    "name": "Md Mahmudur Rahman"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                }
            ]
        },
        {
            "paperId": "b4e3f0c14dbd39e6c858b4a538b8c31f6c055872",
            "title": "A Generative Approach for Image Registration of Visible-Thermal (VT) Cancer Faces",
            "abstract": "Since thermal imagery offers a unique modality to investigate pain, the U.S. National Institutes of Health (NIH) has collected a large and diverse set of cancer patient facial thermograms for AI-based pain research. However, differing angles from camera capture between thermal and visible sensors has led to misalignment between Visible-Thermal (VT) images. We modernize the classic computer vision task of image registration by applying and modifying a generative alignment algorithm to register VT cancer faces, without the need for a reference or alignment parameters. By registering VT faces, we demonstrate that the quality of thermal images produced in the generative AI downstream task of Visible-to-Thermal (V2T) image translation significantly improves up to 52.5\\%, than without registration. Images in this paper have been approved by the NIH NCI for public dissemination.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6138190",
                    "name": "Catherine Ordun"
                },
                {
                    "authorId": "2145080136",
                    "name": "Alexandra N. Cha"
                },
                {
                    "authorId": "34885007",
                    "name": "Edward Raff"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2233143108",
                    "name": "Karen Kwok"
                },
                {
                    "authorId": "2143161409",
                    "name": "Mason Rule"
                },
                {
                    "authorId": "10144346",
                    "name": "J. Gulley"
                }
            ]
        },
        {
            "paperId": "ce4bd9543f53294ebeb05fd4e14e3bc5d0fe3545",
            "title": "When Visible-to-Thermal Facial GAN Beats Conditional Diffusion",
            "abstract": "Thermal facial imagery offers valuable insight into physiological states such as inflammation and stress by detecting emitted radiation in the infrared spectrum, which is unseen in the visible spectra. Telemedicine applications could benefit from thermal imagery, but conventional computers are reliant on RGB cameras and lack thermal sensors. As a result, we propose the Visible-to-Thermal Facial GAN (VTF-GAN) that is specifically designed to generate high-resolution thermal faces by learning both the spatial and frequency domains of facial regions, across spectra. We compare VTF-GAN against several popular GAN baselines and the first conditional DDPM for VT face translation (VTF-Diff). Results show that VTF-GAN achieves high quality, crisp, and perceptually realistic thermal faces using a combined set of patch, temperature, perceptual, and Fourier Transform losses, compared to all baselines including diffusion.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "6138190",
                    "name": "Catherine Ordun"
                },
                {
                    "authorId": "34885007",
                    "name": "Edward Raff"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                }
            ]
        },
        {
            "paperId": "d90f049644c32a8be00f024bb9edd8f936ca1477",
            "title": "NEV-NCD: Negative Learning, Entropy, and Variance Regularization Based Novel Action Categories Discovery",
            "abstract": "Novel Categories Discovery (NCD) facilitates learning from a partially annotated label space and enables deep learning (DL) models to operate in an open-world setting by identifying and differentiating instances of novel classes based on the labeled data notions. One of the primary assumptions of NCD is that the novel label space is perfectly disjoint and can be equipartitioned, but it is rarely realized by most NCD approaches in practice. To better align with this assumption, we propose a novel single-stage joint optimization-based NCD method, Negative learning, Entropy, and Variance regularization NCD (NEV-NCD). We demonstrate the efficacy of NEV-NCD in previously unexplored NCD applications of video action recognition (VAR) with the public UCF101 dataset and a curated in-house partial action-space annotated multi-view video dataset. Further, we perform a thorough ablation study by varying the composition of final joint loss and associated hyper-parameters. During our experiments with UCF101 and multi-view action dataset, NEV-NCD achieves \u2248 83% classification accuracy in test instances of labeled data. NEV-NCD achieves \u2248 70% clustering accuracy over unlabeled data outperforming both naive baselines and state-of-the-art pseudo-labeling-based approaches by \u2248 40% and \u2248 3.5% over both datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067241490",
                    "name": "Zahid Hasan"
                },
                {
                    "authorId": "145354488",
                    "name": "Masud Ahmed"
                },
                {
                    "authorId": "35613119",
                    "name": "A. Faridee"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "1688527",
                    "name": "H. Kwon"
                },
                {
                    "authorId": "2445131",
                    "name": "Hyungtae Lee"
                },
                {
                    "authorId": "1515122607",
                    "name": "Nirmalya Roy"
                }
            ]
        },
        {
            "paperId": "3b03addb5592ab2388726380c9b05e93c89e323f",
            "title": "Intelligent Sight and Sound: A Chronic Cancer Pain Dataset",
            "abstract": "Cancer patients experience high rates of chronic pain throughout the treatment process. Assessing pain for this patient population is a vital component of psychological and functional well-being, as it can cause a rapid deterioration of quality of life. Existing work in facial pain detection often have deficiencies in labeling or methodology that prevent them from being clinically relevant. This paper introduces the first chronic cancer pain dataset, collected as part of the Intelligent Sight and Sound (ISS) clinical trial, guided by clinicians to help ensure that model findings yield clinically relevant results. The data collected to date consists of 29 patients, 509 smartphone videos, 189,999 frames, and self-reported affective and activity pain scores adopted from the Brief Pain Inventory (BPI). Using static images and multi-modal data to predict self-reported pain levels, early models show significant gaps between current methods available to predict pain today, with room for improvement. Due to the especially sensitive nature of the inherent Personally Identifiable Information (PII) of facial images, the dataset will be released under the guidance and control of the National Institutes of Health (NIH).",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6138190",
                    "name": "Catherine Ordun"
                },
                {
                    "authorId": "2145080136",
                    "name": "Alexandra N. Cha"
                },
                {
                    "authorId": "34885007",
                    "name": "Edward Raff"
                },
                {
                    "authorId": "4582400",
                    "name": "Byron Gaskin"
                },
                {
                    "authorId": null,
                    "name": "Alex Hanson"
                },
                {
                    "authorId": "2143161409",
                    "name": "Mason Rule"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "10144346",
                    "name": "J. Gulley"
                }
            ]
        },
        {
            "paperId": "4f06fc29817275e55adb2935d9c4892a3b9baed9",
            "title": "Atmospheric Gravity Wave Detection Using Transfer Learning Techniques",
            "abstract": "Atmospheric gravity waves are produced when gravity attempts to restore disturbances through stable layers in the atmosphere. They have a visible effect on many atmospheric phenomena such as global circulation and air turbulence. Despite their importance, however, little research has been conducted on how to detect gravity waves using machine learning algorithms. We faced two major challenges in our research: our raw data had a lot of noise and the labeled dataset was extremely small. In this study, we explored various methods of preprocessing and transfer learning in order to address those challenges. We pre-trained an autoencoder on unlabeled data before training it to classify labeled data. We also created a custom CNN by combining certain pre-trained layers from the InceptionV3 Model trained on ImageNet with custom layers and a custom learning rate scheduler. Experiments show that our best model outperformed the best performing baseline model by 6.36% in terms of test accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185046349",
                    "name": "Jorge L. Gonzalez"
                },
                {
                    "authorId": "2211525704",
                    "name": "Theodore Chapman"
                },
                {
                    "authorId": "2211597120",
                    "name": "Kathryn Chen"
                },
                {
                    "authorId": "2000365324",
                    "name": "Hannah M. Nguyen"
                },
                {
                    "authorId": "2211574169",
                    "name": "Logan Chambers"
                },
                {
                    "authorId": "2615449",
                    "name": "S. A. Mostafa"
                },
                {
                    "authorId": "2110238311",
                    "name": "Jianwu Wang"
                },
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2280529429",
                    "name": "Chenxi Wang"
                },
                {
                    "authorId": "2113661187",
                    "name": "J. Yue"
                }
            ]
        }
    ]
}