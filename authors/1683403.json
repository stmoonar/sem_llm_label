{
    "authorId": "1683403",
    "papers": [
        {
            "paperId": "9f879b5df015b8393e45647825a18b9734df9c5f",
            "title": "Towards Generalization of Machine Learning Models: A Case Study of Arabic Sentiment Analysis",
            "abstract": "The abundance of social media data in the Arab world, specifically on Twitter, enabled companies and entities to exploit such rich and beneficial data that could be mined and used to extract important information, including sentiments and opinions of people towards a topic or a merchandise. However, with this plenitude comes the issue of producing models that are able to deliver consistent outcomes when tested within various contexts. Although model generalization has been thoroughly investigated in many fields, it has not been heavily investigated in the Arabic context. To address this gap, we investigate the generalization of models and data in Arabic with application to sentiment analysis, by performing a battery of experiments and building different models that are tested on five independent test sets to understand their performance when presented with unseen data. In doing so, we detail different techniques that improve the generalization of machine learning models in Arabic sentiment analysis, and share a large versatile dataset consisting of approximately 1.64M Arabic tweets and their corresponding sentiment to be used for future research. Our experiments concluded that the most consistent model is trained using a dataset labelled by a cascaded approach of two models, one that labels neutral tweets and another that identifies positive/negative tweets based on the Arabic emoji lexicon after class balancing. Both the BERT and the SVM models trained using the refined data achieve an average F-1 score of 0.62 and 0.60, and standard deviation of 0.06 and 0.04 respectively, when evaluated on five diverse test sets, outperforming other models by at least 17% relative gain in F-1. Based on our experiments, we share recommendations to improve model generalization for classification tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2249672254",
                    "name": "Samir Abdaljalil"
                },
                {
                    "authorId": "83760265",
                    "name": "S. Hassanein"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                }
            ]
        },
        {
            "paperId": "9f87c8e27a10d71500314e7e21853f5a23efce59",
            "title": "LAraBench: Benchmarking Arabic AI with Large Language Models",
            "abstract": "Recent advancements in Large Language Models (LLMs) have significantly influenced the landscape of language and speech research. Despite this progress, these models lack specific benchmarking against state-of-the-art (SOTA) models tailored to particular languages and tasks. LAraBench addresses this gap for Arabic Natural Language Processing (NLP) and Speech Processing tasks, including sequence tagging and content classification across different domains. We utilized models such as GPT-3.5-turbo, GPT-4, BLOOMZ, Jais-13b-chat, Whisper, and USM, employing zero and few-shot learning techniques to tackle 33 distinct tasks across 61 publicly available datasets. This involved 98 experimental setups, encompassing ~296K data points, ~46 hours of speech, and 30 sentences for Text-to-Speech (TTS). This effort resulted in 330+ sets of experiments. Our analysis focused on measuring the performance gap between SOTA models and LLMs. The overarching trend observed was that SOTA models generally outperformed LLMs in zero-shot learning, with a few exceptions. Notably, larger computational models with few-shot learning techniques managed to reduce these performance gaps. Our findings provide valuable insights into the applicability of LLMs for Arabic NLP and speech processing tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "1725417821",
                    "name": "Shammur A. Chowdhury"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2171367840",
                    "name": "Basel Mousi"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2189476655",
                    "name": "Yassine El Kheir"
                },
                {
                    "authorId": "2177436744",
                    "name": "Daniel Izham"
                },
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                },
                {
                    "authorId": "2218353460",
                    "name": "Nizi Nazar"
                },
                {
                    "authorId": "2218145245",
                    "name": "Yousseif Elshahawy"
                },
                {
                    "authorId": "2109102523",
                    "name": "Ahmed M. Ali"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "1398136050",
                    "name": "Natasa Milic-Frayling"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "c60116a51bf66bc363d11b797d97eba84b13cfd7",
            "title": "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking",
            "abstract": "The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework, which can be seamlessly customized to evaluate LLMs for any NLP task, regardless of language. The framework features generic dataset loaders, several model providers, and pre-implements most standard evaluation metrics. It supports in-context learning with zero- and few-shot settings. A specific dataset and task can be evaluated for a given LLM in less than 20 lines of code while allowing full flexibility to extend the framework for custom datasets, models, or tasks. The framework has been tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We open-sourced LLMeBench for the community (https://github.com/qcri/LLMeBench/) and a video demonstrating the framework is available online (https://youtu.be/9cC2m_abk3A).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2466162",
                    "name": "Sabri Boughorbel"
                },
                {
                    "authorId": "2171367840",
                    "name": "Basel Mousi"
                },
                {
                    "authorId": "2249672254",
                    "name": "Samir Abdaljalil"
                },
                {
                    "authorId": "2218353460",
                    "name": "Nizi Nazar"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "1725417821",
                    "name": "Shammur A. Chowdhury"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "2109102523",
                    "name": "Ahmed M. Ali"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "3c00e6cc82b49f046b5f36e5d5f8aa4af68cad5a",
            "title": "Textual Data Augmentation for Arabic-English Code-Switching Speech Recognition",
            "abstract": "The pervasiveness of intra-utterance code-switching (CS) in spoken content requires that speech recognition (ASR) systems handle mixed language. Designing a CS-ASR system has many challenges, mainly due to data scarcity, grammatical structure complexity, and domain mismatch. The most common method for addressing CS is to train an ASR system with the available transcribed CS speech, along with monolingual data. In this work, we propose a zero-shot learning methodology for CS-ASR by augmenting the monolingual data with artificially generating CS text. We based our approach on random lexical replacements and Equivalence Constraint (EC) while exploiting aligned translation pairs to generate random and grammatically valid CS content. Our empirical results show a 65.5% relative reduction in language model perplexity, and 7.7% in ASR WER on two ecologically valid CS test sets. The human evaluation of the generated text using EC suggests that more than 80% is of adequate quality.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "152885017",
                    "name": "A. Hussein"
                },
                {
                    "authorId": "143996866",
                    "name": "S. A. Chowdhury"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "3135554",
                    "name": "N. Dehak"
                },
                {
                    "authorId": "2109102523",
                    "name": "Ahmed M. Ali"
                },
                {
                    "authorId": "2803071",
                    "name": "S. Khudanpur"
                }
            ]
        },
        {
            "paperId": "82070c57e5bca1b6217c87638df53b029c2bac9a",
            "title": "Interpreting Arabic Transformer Models",
            "abstract": "Arabic is a Semitic language which is widely spoken with many dialects. Given the success of pre-trained language models, many transformer models trained on Arabic and its dialects have surfaced. While these models have been compared with respect to downstream NLP tasks, no evaluation has been carried out to directly compare the internal representations. We probe how linguistic information is encoded in Arabic pretrained models, trained on different varieties of Arabic language. We perform a layer and neuron analysis on the models using three intrinsic tasks: two morphological tagging tasks based on MSA (modern standard Arabic) and dialectal POS-tagging and a dialectal identification task. Our analysis enlightens interesting findings such as: i) word morphology is learned at the lower and middle layers ii) dialectal identification necessitate more knowledge and hence preserved even in the final layers, iii) despite a large overlap in their vocabulary, the MSA-based models fail to capture the nuances of Arabic dialects, iv) we found that neurons in embedding layers are polysemous in nature, while the neurons in middle layers are exclusive to specific properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "145775792",
                    "name": "Hassan Sajjad"
                }
            ]
        },
        {
            "paperId": "9a9eff68eacc844b6495779d404faa7251a8cd07",
            "title": "Post-hoc analysis of Arabic transformer models",
            "abstract": "Arabic is a Semitic language which is widely spoken with many dialects. Given the success of pre-trained language models, many transformer models trained on Arabic and its dialects have surfaced. While there have been an extrinsic evaluation of these models with respect to downstream NLP tasks, no work has been carried out to analyze and compare their internal representations. We probe how linguistic information is encoded in the transformer models, trained on different Arabic dialects. We perform a layer and neuron analysis on the models using morphological tagging tasks for different dialects of Arabic and a dialectal identification task. Our analysis enlightens interesting findings such as: i) word morphology is learned at the lower and middle layers, ii) while syntactic dependencies are predominantly captured at the higher layers, iii) despite a large overlap in their vocabulary, the MSA-based models fail to capture the nuances of Arabic dialects, iv) we found that neurons in embedding layers are polysemous in nature, while the neurons in middle layers are exclusive to specific properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "145775792",
                    "name": "Hassan Sajjad"
                }
            ]
        },
        {
            "paperId": "be5074a85ef8166fc173cb51971a2e3f79685134",
            "title": "Code-Switching Text Augmentation for Multilingual Speech Processing",
            "abstract": "The pervasiveness of intra-utterance Code-switching (CS) in spoken content has enforced ASR systems to handle mixed input. Yet, designing a CS-ASR has many challenges, mainly due to the data scarcity, grammatical structure complexity and mismatch along with unbalanced language usage distribution. Recent ASR studies showed the predominance of E2E-ASR using multilingual data to handle CS phenomena with little CS data. However, the dependency on the CS data still remains. In this work, we propose a methodology to augment the monolingual data for arti\ufb01cially generating spoken CS text to improve different speech modules. We based our approach on Equivalence Constraint theory while exploiting aligned translation pairs, to generate grammatically valid CS content. Our empirical results show a relative gain of 29-34% in perplexity and \u2248 2% in WER for two ecological and noisy CS test sets. Finally, the human evaluation suggests that 83.8% of the generated data is acceptable to humans.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152885017",
                    "name": "A. Hussein"
                },
                {
                    "authorId": "143996866",
                    "name": "S. A. Chowdhury"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "3135554",
                    "name": "N. Dehak"
                },
                {
                    "authorId": "2109102523",
                    "name": "Ahmed M. Ali"
                }
            ]
        },
        {
            "paperId": "ef15bdd870e9a9107c1fa2c542272da50829de83",
            "title": "NatiQ: An End-to-end Text-to-Speech System for Arabic",
            "abstract": "NatiQ is end-to-end text-to-speech system for Arabic. Our speech synthesizer uses an encoder-decoder architecture with attention. We used both tacotron-based models (tacotron- 1 and tacotron-2) and the faster transformer model for generating mel-spectrograms from characters. We concatenated Tacotron1 with the WaveRNN vocoder, Tacotron2 with the WaveGlow vocoder and ESPnet transformer with the parallel wavegan vocoder to synthesize waveforms from the spectrograms. We used in-house speech data for two voices: 1) neu- tral male \u201cHamza\u201d- narrating general content and news, and 2) expressive female \u201cAmina\u201d- narrating children story books to train our models. Our best systems achieve an aver- age Mean Opinion Score (MOS) of 4.21 and 4.40 for Amina and Hamza respectively.The objective evaluation of the systems using word and character error rate (WER and CER) as well as the response time measured by real- time factor favored the end-to-end architecture ESPnet. NatiQ demo is available online at https://tts.qcri.org.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "145938140",
                    "name": "Nadir Durrani"
                },
                {
                    "authorId": "47977236",
                    "name": "C. Demiro\u011flu"
                },
                {
                    "authorId": "6415321",
                    "name": "Fahim Dalvi"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "143758717",
                    "name": "Kareem Darwish"
                }
            ]
        },
        {
            "paperId": "5d2756cc8f3fabe75940f561ed71a5e14981cd37",
            "title": "Automatic Expansion and Retargeting of Arabic Offensive Language Training",
            "abstract": "Rampant use of offensive language on social media led to recent efforts on automatic identification of such language. Though offensive language has general characteristics, attacks on specific entities may exhibit distinct phenomena such as malicious alterations in the spelling of names. In this paper, we present a method for identifying entity specific offensive language. We employ two key insights, namely that replies on Twitter often imply opposition and some accounts are persistent in their offensiveness towards specific targets. Using our methodology, we are able to collect thousands of targeted offensive tweets. We show the efficacy of the approach on Arabic tweets with 13% and 79% relative F1-measure improvement in entity specific offensive language detection when using deep-learning based and support vector machine based classifiers respectively. Further, expanding the training set with automatically identified offensive tweets directed at multiple entities can improve F1-measure by 48%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                },
                {
                    "authorId": "143758717",
                    "name": "Kareem Darwish"
                },
                {
                    "authorId": "3103210",
                    "name": "Younes Samih"
                }
            ]
        },
        {
            "paperId": "5e10dcde03dce0d8dab85b909a449a1bab44b49e",
            "title": "Bert Transformer model for Detecting Arabic GPT2 Auto-Generated Tweets",
            "abstract": "During the last two decades, we have progressively turned to the Internet and social media to find news, entertain conversations and share opinion. Recently, OpenAI has developed a machine learning system called GPT-2 for Generative Pre-trained Transformer-2, which can produce deepfake texts. It can generate blocks of text based on brief writing prompts that look like they were written by humans, facilitating the spread false or auto-generated text. In line with this progress, and in order to counteract potential dangers, several methods have been proposed for detecting text written by these language models. In this paper, we propose a transfer learning based model that will be able to detect if an Arabic sentence is written by humans or automatically generated by bots. Our dataset is based on tweets from a previous work, which we have crawled and extended using the Twitter API. We used GPT2-Small-Arabic to generate fake Arabic Sentences. For evaluation, we compared different recurrent neural network (RNN) word embeddings based baseline models, namely: LSTM, BI-LSTM, GRU and BI-GRU, with a transformer-based model. Our new transfer-learning model has obtained an accuracy up to 98%. To the best of our knowledge, this work is the first study where ARABERT and GPT2 were combined to detect and classify the Arabic auto-generated texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2624126",
                    "name": "Fouzi Harrag"
                },
                {
                    "authorId": "2029646889",
                    "name": "Maria Dabbah"
                },
                {
                    "authorId": "143758717",
                    "name": "Kareem Darwish"
                },
                {
                    "authorId": "1683403",
                    "name": "Ahmed Abdelali"
                }
            ]
        }
    ]
}