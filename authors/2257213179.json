{
    "authorId": "2257213179",
    "papers": [
        {
            "paperId": "c29aa2e58d91e733685914b40eadb83d719c59dd",
            "title": "STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases",
            "abstract": "Answering real-world complex queries, such as complex product search, often requires accurate retrieval from semi-structured knowledge bases that involve blend of unstructured (e.g., textual descriptions of products) and structured (e.g., entity relations of products) information. However, previous works have mostly studied textual and relational retrieval tasks as separate topics. To address the gap, we develop STARK, a large-scale Semi-structure retrieval benchmark on Textual and Relational K nowledge Bases. Our benchmark covers three domains/datasets: product search, academic paper search, and queries in precision medicine. We design a novel pipeline to synthesize realistic user queries that integrate diverse relational information and complex textual properties, together with their ground-truth answers (items). We conduct rigorous human evaluation to validate the quality of our synthesized queries. We further enhance the benchmark with high-quality human-generated queries to provide an authentic reference. STARK serves as a comprehensive testbed for evaluating the performance of retrieval systems driven by large language models (LLMs). Our experiments suggest that STARK presents significant challenges to the current retrieval and LLM systems, indicating the demand for building more capable retrieval systems. The benchmark data and code are available on https://github.com/snap-stanford/stark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774538",
                    "name": "Shirley Wu"
                },
                {
                    "authorId": "2297830746",
                    "name": "Shiyu Zhao"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "48865984",
                    "name": "Kaidi Cao"
                },
                {
                    "authorId": "2302855404",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2265619476",
                    "name": "James Zou"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "db22b645cb9d213095089a9ba88d02d18e6543a6",
            "title": "AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval",
            "abstract": "Large language model (LLM) agents have demonstrated impressive capability in utilizing external tools and knowledge to boost accuracy and reduce hallucinations. However, developing the prompting techniques that make LLM agents able to effectively use external tools and knowledge is a heuristic and laborious task. Here, we introduce AvaTaR, a novel and automatic framework that optimizes an LLM agent to effectively use the provided tools and improve its performance on a given task/domain. During optimization, we design a comparator module to iteratively provide insightful and holistic prompts to the LLM agent via reasoning between positive and negative examples sampled from training data. We demonstrate AvaTaR on four complex multimodal retrieval datasets featuring textual, visual, and relational information. We find AvaTaR consistently outperforms state-of-the-art approaches across all four challenging tasks and exhibits strong generalization ability when applied to novel cases, achieving an average relative improvement of 14% on the Hit@1 metric. Code and dataset are available at https://github.com/zou-group/avatar.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774538",
                    "name": "Shirley Wu"
                },
                {
                    "authorId": "2297830746",
                    "name": "Shiyu Zhao"
                },
                {
                    "authorId": "2302855404",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "2265619476",
                    "name": "James Zou"
                }
            ]
        },
        {
            "paperId": "17a6213e30895fb7e5d0b368236ea8beeb94ee86",
            "title": "Relational Deep Learning: Graph Representation Learning on Relational Databases",
            "abstract": "Much of the world's most valued data is stored in relational databases and data warehouses, where the data is organized into many tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming. The core problem is that no machine learning method is capable of learning on multiple tables interconnected by primary-foreign key relations. Current methods can only learn from a single table, so the data must first be manually joined and aggregated into a single training table, the process known as feature engineering. Feature engineering is slow, error prone and leads to suboptimal models. Here we introduce an end-to-end deep representation learning approach to directly learn on data laid out across multiple tables. We name our approach Relational Deep Learning (RDL). The core idea is to view relational databases as a temporal, heterogeneous graph, with a node for each row in each table, and edges specified by primary-foreign key links. Message Passing Graph Neural Networks can then automatically learn across the graph to extract representations that leverage all input data, without any manual feature engineering. Relational Deep Learning leads to more accurate models that can be built much faster. To facilitate research in this area, we develop RelBench, a set of benchmark datasets and an implementation of Relational Deep Learning. The data covers a wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon Product Catalog. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability to a wide set of AI use cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3410500",
                    "name": "Matthias Fey"
                },
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "9572099",
                    "name": "J. E. Lenssen"
                },
                {
                    "authorId": "2268710645",
                    "name": "Rishabh Ranjan"
                },
                {
                    "authorId": "2268728614",
                    "name": "Joshua Robinson"
                },
                {
                    "authorId": "83539859",
                    "name": "Rex Ying"
                },
                {
                    "authorId": "145829303",
                    "name": "Jiaxuan You"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "730bab13c468df82c0f44d738dcdb3ac00410861",
            "title": "High dimensional, tabular deep learning with an auxiliary knowledge graph",
            "abstract": "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high d -dimensional features but limited n samples (i.e. d \u226b n ), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose P LATO , a method that achieves strong performance on tabular data with d \u226b n by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In P LATO , each input feature corresponds to a node in the auxiliary KG. In the MLP\u2019s first layer, each input feature also corresponds to a weight vector. P LATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP\u2019s first layer. P LATO captures this inductive bias by inferring the weight vector for each input feature from its corresponding node in the KG via a trainable message-passing function. Across 6 d \u226b n datasets, P LATO outperforms 13 state-of-the-art baselines by up to 10.19%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243501205",
                    "name": "Camilo Ruiz"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "c1aace95593ead7fe452cb845a60876d39578c21",
            "title": "TuneUp: A Training Strategy for Improving Generalization of Graph Neural Networks",
            "abstract": "Despite many advances in Graph Neural Networks (GNNs), their training strategies simply focus on minimizing a loss over nodes in a graph. However, such simplistic training strategies may be sub-optimal as they neglect that certain nodes are much harder to make accurate predictions on than others. Here we present TUNEUP, a curriculum learning strategy for better training GNNs. Crucially, TUNEUP trains a GNN in two stages. The first stage aims to produce a strong base GNN. Such base GNNs tend to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). So, the second stage of TUNEUP specifically focuses on improving prediction on tail nodes. Concretely, TUNEUP synthesizes many additional supervised tail node data by dropping edges from head nodes and reusing the supervision on the original head nodes. TUNEUP then minimizes the loss over the synthetic tail nodes to finetune the base GNN. TUNEUP is a general training strategy that can be used with any GNN architecture and any loss, making TUNEUP applicable to a wide range of prediction tasks. Extensive evaluation of TUNEUP on two GNN architectures, three types of prediction tasks, and both inductive and transductive settings shows that TUNEUP significantly improves the performance of the base GNN on tail nodes, while often even improving the performance on head nodes, which together leads up to 58.5% relative improvement in GNN predictive performance. Moreover, TUNEUP significantly outperforms its variants without the two-stage curriculum learning, existing graph data augmentation techniques, as well as other specialized methods for tail nodes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "48865984",
                    "name": "Kaidi Cao"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "2057479333",
                    "name": "E-Wen Huang"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                }
            ]
        }
    ]
}