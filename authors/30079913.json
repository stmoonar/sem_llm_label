{
    "authorId": "30079913",
    "papers": [
        {
            "paperId": "08b877e527f8cc55e6527fa7a1b1f7265783a72c",
            "title": "MAINDZ at SemEval-2024 Task 5: CLUEDO - Choosing Legal oUtcome by Explaining Decision through Oversight",
            "abstract": "Large language models (LLMs) have recently obtained strong performance on complex reasoning tasks. However, their capabilities in specialized domains like law remain relatively unexplored. We present CLUEDO, a system to tackle a novel legal reasoning task that involves determining if a provided answer correctly addresses a legal question derived from U.S. civil procedure cases. CLUEDO utilizes multiple collaborator models that are trained using multiple-choice prompting to choose the right label and generate explanations. These collaborators are overseen by a final \u201cdetective\u201d model that identifies the most accurate answer in a zero-shot manner. Our approach achieves an F1 macro score of 0.74 on the development set and 0.76 on the test set, outperforming individual models. Unlike the powerful GPT-4, CLUEDO provides more stable predictions thanks to the ensemble approach. Our results showcase the promise of tailored frameworks to enhance legal reasoning capabilities in LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181131869",
                    "name": "Irene Benedetto"
                },
                {
                    "authorId": "1909140421",
                    "name": "Alkis Koudounas"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "51209710",
                    "name": "Eliana Pastor"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                },
                {
                    "authorId": "29829627",
                    "name": "Francesco Tarasconi"
                }
            ]
        },
        {
            "paperId": "0f54fab8f05f8bea99ac5edb3572717fa591715f",
            "title": "On Leveraging Multi-Page Element Relations in Visually-Rich Documents",
            "abstract": "Thanks to the rapid progress of the digitalization process, Visually-Rich Documents (VRDs) such as PDF files or scanned documents have become among the most widespread sources of knowledge. However, Question Answering on VRDs is challenged by the presence of multi-page relationships between document elements such as tables, figures, sections. This paper addresses a specific Visual Question Answering subtask from VDRs where answer generation leverages pairwise element relations in multi-page documents. We explore the performance of text-only and multimodal Transformer-based architectures as well as open-source Large Language Models. The results show that multimodal Transformers outperform the other tested methods, particularly when training samples contain explicit textual references to the elements in the document layout.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237785478",
                    "name": "Davide Napolitano"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                }
            ]
        },
        {
            "paperId": "3a55568a1d1a7e37faad1ca4e259a98e3f97027f",
            "title": "3MVRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding",
            "abstract": "This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation between token and entity representations, addressing the complexities inherent in form documents. Additionally, we introduce new inter-grained and cross-grained loss functions to further refine diverse multi-teacher knowledge distillation transfer process, presenting distribution gaps and a harmonised understanding of form documents. Through a comprehensive evaluation across publicly available form document understanding datasets, our proposed model consistently outperforms existing baselines, showcasing its efficacy in handling the intricate structures and content of visually complex form documents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166956722",
                    "name": "Yihao Ding"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "1712027",
                    "name": "P. Garza"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                }
            ]
        },
        {
            "paperId": "3cf241bfb4d5ec6a744f4c455fc5ed1431a761a4",
            "title": "Benchmarking Representations for Speech, Music, and Acoustic Events",
            "abstract": "Limited diversity in standardized benchmarks for evaluating audio representation learning (ARL) methods may hinder systematic comparison of current methods\u2019 capabilities. We present ARCH, a comprehensive benchmark for evaluating ARL methods on diverse audio classification domains, covering acoustic events, music, and speech. ARCH comprises 12 datasets, that allow us to thoroughly assess pre-trained SSL models of different sizes. ARCH streamlines benchmarking of ARL techniques through its unified access to a wide range of domains and its ability to readily incorporate new datasets and models. To address the current lack of open-source, pre-trained models for non-speech audio, we also release new pre-trained models that demonstrate strong performance on non-speech datasets. We argue that the presented wide-ranging evaluation provides valuable insights into state-of-the-art ARL methods, and is useful to pinpoint promising research directions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2220099062",
                    "name": "Moreno La Quatra"
                },
                {
                    "authorId": "1909140421",
                    "name": "Alkis Koudounas"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2292282200",
                    "name": "Elena Baralis"
                },
                {
                    "authorId": "2287930712",
                    "name": "Luca Cagliero"
                },
                {
                    "authorId": "2292447799",
                    "name": "Paolo Garza"
                },
                {
                    "authorId": "1709878",
                    "name": "Sabato Marco Siniscalchi"
                }
            ]
        },
        {
            "paperId": "9c7e9acca0ad8aba3a284c997fbbc7cbe9319eff",
            "title": "Emotion Recognition from Videos Using Multimodal Large Language Models",
            "abstract": "The diffusion of Multimodal Large Language Models (MLLMs) has opened new research directions in the context of video content understanding and classification. Emotion recognition from videos aims to automatically detect human emotions such as anxiety and fear. It requires deeply elaborating multiple data modalities, including acoustic and visual streams. State-of-the-art approaches leverage transformer-based architectures to combine multimodal sources. However, the impressive performance of MLLMs in content retrieval and generation offers new opportunities to extend the capabilities of existing emotion recognizers. This paper explores the performance of MLLMs in the emotion recognition task in a zero-shot learning setting. Furthermore, it presents a state-of-the-art architecture extension based on MLLM content reformulation. The performance achieved on the Hume-Reaction benchmark shows that MLLMs are still unable to outperform the state-of-the-art average performance but, notably, are more effective than traditional transformers in recognizing emotions with an intensity that deviates from the average of the samples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                },
                {
                    "authorId": "2292447799",
                    "name": "Paolo Garza"
                }
            ]
        },
        {
            "paperId": "2fe1ef43257d994a12f39f277a00484a2f08ae6b",
            "title": "Learning Confidence Intervals for Feature Importance: A Fast Shapley-based Approach",
            "abstract": "Inferring feature importance is a well-known machine learning problem. Giving importance scores to the input data features is particularly helpful for explaining black-box models. Existing approaches rely on either statistical or Neural Network-based methods. Among them, Shapley Value estimates are among the mostly used scores to explain individual classification models or ensemble methods. As a drawback, state-of-the-art neural network-based approaches neglects the uncertainty of the input predictions while computing the confidence intervals of the feature importance scores. The paper extends a state-of-the-art neural method for Shapley Value estimation to handle uncertain predictions made by ensemble methods and to estimate a confidence interval for the feature importances. The results show that (1) The estimated confidence intervals are coherent with the expectation and more reliable than baseline methods; (2) The efficiency of the Shapley value estimator is comparable to those of traditional models; (3) The level of uncertainty of the Shapley value estimates decreases while producing ensembles of larger numbers of predictors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "146524996",
                    "name": "D.P.H. Napolitano"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "1692878",
                    "name": "Luca Cagliero"
                }
            ]
        },
        {
            "paperId": "462855d1fbb474ce0d6a8bd1177a875a64714041",
            "title": "Enhancing BERT-Based Visual Question Answering through Keyword-Driven Sentence Selection",
            "abstract": "The Document-based Visual Question Answering competition addresses the automatic detection of parent-child relationships between elements in multi-page documents. The goal is to identify the document elements that answer a specific question posed in natural language. This paper describes the PoliTo's approach to addressing this task, in particular, our best solution explores a text-only approach, leveraging an ad hoc sampling strategy. Specifically, our approach leverages the Masked Language Modeling technique to fine-tune a BERT model, focusing on sentences containing sensitive keywords that also occur in the questions, such as references to tables or images. Thanks to the effectiveness of this approach, we are able to achieve high performance compared to baselines, demonstrating how our solution contributes positively to this task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237785478",
                    "name": "Davide Napolitano"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                }
            ]
        },
        {
            "paperId": "7d8ce3eefbddeb72c1a1c78cc8a775d96426c81c",
            "title": "ITALIC: An Italian Intent Classification Dataset",
            "abstract": "Recent large-scale Spoken Language Understanding datasets focus predominantly on English and do not account for language-specific phenomena such as particular phonemes or words in different lects. We introduce ITALIC, the first large-scale speech dataset designed for intent classification in Italian. The dataset comprises 16,521 crowdsourced audio samples recorded by 70 speakers from various Italian regions and annotated with intent labels and additional metadata. We explore the versatility of ITALIC by evaluating current state-of-the-art speech and text models. Results on intent classification suggest that increasing scale and running language adaptation yield better speech models, monolingual text models outscore multilingual ones, and that speech recognition on ITALIC is more challenging than on existing Italian benchmarks. We release both the dataset and the annotation scheme to streamline the development of new Italian SLU models and language-specific datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1909140421",
                    "name": "Alkis Koudounas"
                },
                {
                    "authorId": "2220099062",
                    "name": "Moreno La Quatra"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2006458457",
                    "name": "Luca Colomba"
                },
                {
                    "authorId": "1481857041",
                    "name": "Giuseppe Attanasio"
                },
                {
                    "authorId": "51209710",
                    "name": "Eliana Pastor"
                },
                {
                    "authorId": "1692878",
                    "name": "Luca Cagliero"
                },
                {
                    "authorId": "1750105",
                    "name": "Elena Baralis"
                }
            ]
        },
        {
            "paperId": "afdc659c7a58cfa9f0513ac274da797d7881953e",
            "title": "PoliTo at MULTI-Fake-DetectiVE: Improving FND-CLIP for Multimodal Italian Fake News Detection",
            "abstract": "The MULTI-Fake-DetectiVE challenge addresses the automatic detection of Italian fake news in a multimodal setting, where both textual and visual components contribute as potential sources of fake content. This paper describes the PoliTO approach to the tasks of fake news detection and analysis of the modality contributions. Our solution turns out to be the best performer on both tasks. It leverages the established FND-CLIP multimodal architecture and proposes ad hoc extensions including sentiment-based text encoding, image transformation in the frequency domain, and data augmentation via back-translation. Thanks to its effectiveness in combining visual and textual content, our solution contributes to fighting the spread of disinformation in the Italian news flow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237790629",
                    "name": "Lorenzo D'Amico"
                },
                {
                    "authorId": "2237785478",
                    "name": "Davide Napolitano"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                }
            ]
        },
        {
            "paperId": "bad8e497646c576c48a0c8112e3be0a167d7bafc",
            "title": "PoliToHFI at SemEval-2023 Task 6: Leveraging Entity-Aware and Hierarchical Transformers For Legal Entity Recognition and Court Judgment Prediction",
            "abstract": "The use of Natural Language Processing techniques in the legal domain has become established for supporting attorneys and domain experts in content retrieval and decision-making. However, understanding the legal text poses relevant challenges in the recognition of domain-specific entities and the adaptation and explanation of predictive models. This paper addresses the Legal Entity Name Recognition (L-NER) and Court judgment Prediction (CPJ) and Explanation (CJPE) tasks. The L-NER solution explores the use of various transformer-based models, including an entity-aware method attending domain-specific entities. The CJPE proposed method relies on hierarchical BERT-based classifiers combined with local input attribution explainers. We propose a broad comparison of eXplainable AI methodologies along with a novel approach based on NER. For the L-NER task, the experimental results remark on the importance of domain-specific pre-training. For CJP our lightweight solution shows performance in line with existing approaches, and our NER-boosted explanations show promising CJPE results in terms of the conciseness of the prediction explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181131869",
                    "name": "Irene Benedetto"
                },
                {
                    "authorId": "1909140421",
                    "name": "Alkis Koudounas"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "51209710",
                    "name": "Eliana Pastor"
                },
                {
                    "authorId": "1750105",
                    "name": "Elena Baralis"
                },
                {
                    "authorId": "1692878",
                    "name": "Luca Cagliero"
                },
                {
                    "authorId": "29829627",
                    "name": "Francesco Tarasconi"
                }
            ]
        }
    ]
}