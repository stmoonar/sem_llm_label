{
    "authorId": "2064767378",
    "papers": [
        {
            "paperId": "278927c0bdc11c778dcd2d9f91667d1f1db005b2",
            "title": "\u2018Eyes of a Hawk and Ears of a Fox\u2019: Part Prototype Network for Generalized Zero-Shot Learning",
            "abstract": "Many approaches in Generalized Zero-Shot Learning (GZSL) are built upon base models which consider only a single class attribute vector representation over the entire image. This is an oversimplification of the process of novel category recognition, where different regions of the image may have properties from different seen classes and thus have different predominant attributes. With this in mind, we take a fundamentally different approach: a pre-trained Vision-Language detector (VINVL) sensitive to attribute information is employed to efficiently obtain region features. A learned function maps the region features to region-specific attribute attention used to construct class part prototypes. We conduct experiments on a popular GZSL benchmark consisting of the CUB, SUN, and AWA2 datasets where our proposed Part Prototype Network (PPN) achieves promising results when compared with other popular base models. Corresponding ablation studies and analysis show that our approach is highly practical and has a distinct advantage over global attribute attention when localized proposals are available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150143507",
                    "name": "Joshua Forster Feinglass"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2292179537",
                    "name": "T. S. Jayram"
                },
                {
                    "authorId": "2237606621",
                    "name": "Yezhou Yang"
                }
            ]
        },
        {
            "paperId": "39c4fd8948dabc28868af5efdb1d28f2cb433a1f",
            "title": "On The Role of Prompt Construction In Enhancing Efficacy and Efficiency of LLM-Based Tabular Data Generation",
            "abstract": "LLM-based data generation for real-world tabular data can be challenged by the lack of sufficient semantic context in feature names used to describe columns. We hypothesize that enriching prompts with domain-specific insights can improve both the quality and efficiency of data generation. To test this hypothesis, we explore three prompt construction protocols: Expert-guided, LLM-guided, and Novel-Mapping. Through empirical studies with the recently proposed GReaT framework, we find that context-enriched prompts lead to significantly improved data generation quality and training efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2317109659",
                    "name": "Banooqa H. Banday"
                },
                {
                    "authorId": "2123725394",
                    "name": "Kowshik Thopalli"
                },
                {
                    "authorId": "2219526",
                    "name": "T. Islam"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "4ca5824933d2c7b44dbfce0418ef40c4774ec78f",
            "title": "DECIDER: Leveraging Foundation Model Priors for Improved Model Failure Detection and Explanation",
            "abstract": "Reliably detecting when a deployed machine learning model is likely to fail on a given input is crucial for ensuring safe operation. In this work, we propose DECIDER (Debiasing Classifiers to Identify Errors Reliably), a novel approach that leverages priors from large language models (LLMs) and vision-language models (VLMs) to detect failures in image classification models. DECIDER utilizes LLMs to specify task-relevant core attributes and constructs a ``debiased'' version of the classifier by aligning its visual features to these core attributes using a VLM, and detects potential failure by measuring disagreement between the original and debiased models. In addition to proactively identifying samples on which the model would fail, DECIDER also provides human-interpretable explanations for failure through a novel attribute-ablation strategy. Through extensive experiments across diverse benchmarks spanning subpopulation shifts (spurious correlations, class imbalance) and covariate shifts (synthetic corruptions, domain shifts), DECIDER consistently achieves state-of-the-art failure detection performance, significantly outperforming baselines in terms of the overall Matthews correlation coefficient as well as failure and success recall. Our codes can be accessed at~\\url{https://github.com/kowshikthopalli/DECIDER/}",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175280217",
                    "name": "Rakshith Subramanyam"
                },
                {
                    "authorId": "2123725394",
                    "name": "Kowshik Thopalli"
                },
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "7954ab2cc4984b71467049ac6713f30645fbd2e3",
            "title": "On the Use of Anchoring for Training Vision Models",
            "abstract": "Anchoring is a recent, architecture-agnostic principle for training deep neural networks that has been shown to significantly improve uncertainty estimation, calibration, and extrapolation capabilities. In this paper, we systematically explore anchoring as a general protocol for training vision models, providing fundamental insights into its training and inference processes and their implications for generalization and safety. Despite its promise, we identify a critical problem in anchored training that can lead to an increased risk of learning undesirable shortcuts, thereby limiting its generalization capabilities. To address this, we introduce a new anchored training protocol that employs a simple regularizer to mitigate this issue and significantly enhances generalization. We empirically evaluate our proposed approach across datasets and architectures of varying scales and complexities, demonstrating substantial performance gains in generalization and safety metrics compared to the standard training protocol.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2123725394",
                    "name": "Kowshik Thopalli"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2121317308",
                    "name": "Yamen Mubarka"
                },
                {
                    "authorId": "3178630",
                    "name": "W. Sakla"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "8ef2d0e0b3c50e300bac94a7438368c901a4ff67",
            "title": "On Estimating Link Prediction Uncertainty Using Stochastic Centering",
            "abstract": "Accurate confidence estimates are crucial for safe graph neural network (GNN) deployment, yet link prediction (LP) calibration is understudied. We provide novel insights into LP calibration by highlighting the importance of meaningful node-level uncertainties. In response, we propose E-\u0394UQ, an architecture-agnostic framework leveraging stochastic centering to incorporate epistemic uncertainty into GNNs. Our work provides principles and three E-\u0394UQ variants to improve trust in LP models, while introducing minimal overhead. Key results demonstrate properly handling node-level uncertainty improves edge calibration. We evaluate E-\u0394UQ variants on citation networks and find that intermediate stochastic layers outperform alternatives by producing better node uncertainties. E-\u0394UQ reduces calibration error by 15-50% and maintains comparable prediction fidelity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "9962ea51df04ca28df40f102575ea72770b93dfd",
            "title": "The Double-Edged Sword Of Ai Safety: Balancing Anomaly Detection and OOD Generalization Via Model Anchoring",
            "abstract": "Safe deployment of AI systems requires models to accurately flag anomalous or semantically unrelated data, while also generalizing to unseen shifts in the data distribution. While both these problems have been extensively studied, there is a risk for undesirable trade-off when exclusively optimizing for one of the objectives. In this paper, we systematically study this trade-off under the lens of model anchoring. Anchoring is a recently proposed training methodology that involves reparameterizing input data into anchor-residual pairs (anchors are drawn from the training data itself), thus establishing a combinatorial relationship with other samples in the training data. We make a surprising finding that the dual objectives of generalization and anomaly detection can be controlled by independently regularizing the model\u2019s dependency on the distribution of anchors and residuals respectively. This enables, for the first time, a finer control of the detection-generalization trade-off without requiring any additional data (e.g., outlier exposure) or computationally intensive modeling strategies (e.g., deep ensembling).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "c926ec72004270a38e7f8c121a9d4fff0f54cdfb",
            "title": "Speeding Up Image Classifiers with Little Companions",
            "abstract": "Scaling up neural networks has been a key recipe to the success of large language and vision models. However, in practice, up-scaled models can be disproportionately costly in terms of computations, providing only marginal improvements in performance; for example, EfficientViT-L3-384 achieves<2% improvement on ImageNet-1K accuracy over the base L1-224 model, while requiring $14\\times$ more multiply-accumulate operations (MACs). In this paper, we investigate scaling properties of popular families of neural networks for image classification, and find that scaled-up models mostly help with\"difficult\"samples. Decomposing the samples by difficulty, we develop a simple model-agnostic two-pass Little-Big algorithm that first uses a light-weight\"little\"model to make predictions of all samples, and only passes the difficult ones for the\"big\"model to solve. Good little companion achieve drastic MACs reduction for a wide variety of model families and scales. Without loss of accuracy or modification of existing models, our Little-Big models achieve MACs reductions of 76% for EfficientViT-L3-384, 81% for EfficientNet-B7-600, 71% for DeiT3-L-384 on ImageNet-1K. Little-Big also speeds up the InternImage-G-512 model by 62% while achieving 90% ImageNet-1K top-1 accuracy, serving both as a strong baseline and as a simple practical method for large model compression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2308108803",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2123725394",
                    "name": "Kowshik Thopalli"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "e8c784ed09e1cdc546a281b541316a5b29813bd5",
            "title": "Exploring the Utility of Clip Priors for Visual Relationship Prediction",
            "abstract": "This work explores the challenges of leveraging large-scale vision language models, such as CLIP, for visual relationship prediction (VRP), a task vital in understanding the relations between objects in a scene based on both image features and text descriptors. Despite its potential, we find that CLIP\u2019s language priors are restrictive in effectively differentiating between various predicates for VRP. Towards this, we present CREPE (CLIP Representation Enhanced Predicate Estimation), which utilizes learnable prompts and a unique contrastive training strategy to derive reliable CLIP representations suited for VRP. CREPE can be seamlessly integrated into any VRP method. Our evaluations on the Visual Genome benchmark illustrate that using representations from CREPE significantly enhances the performance of vanilla VRP methods, such as UVTransE and VCTree. This enhancement is notable as CREPE can be seamlessly integrated into any VRP method, even without the need for additional calibration techniques, showcasing its efficacy as a powerful solution to VRP. CREPE\u2019s performance on the Unrel benchmark reveals strong generalization to diverse and previously unseen predicate occurrences, despite lacking explicit training on such examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175280217",
                    "name": "Rakshith Subramanyam"
                },
                {
                    "authorId": "2292179537",
                    "name": "T. S. Jayram"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "f3bff001a75081a1ee3344828a815c5d5094ccd4",
            "title": "Enhancing Accuracy and Parameter-Efficiency of Neural Representations for Network Parameterization",
            "abstract": "In this work, we investigate the fundamental trade-off regarding accuracy and parameter efficiency in the parameterization of neural network weights using predictor networks. We present a surprising finding that, when recovering the original model accuracy is the sole objective, it can be achieved effectively through the weight reconstruction objective alone. Additionally, we explore the underlying factors for improving weight reconstruction under parameter-efficiency constraints, and propose a novel training scheme that decouples the reconstruction objective from auxiliary objectives such as knowledge distillation that leads to significant improvements compared to state-of-the-art approaches. Finally, these results pave way for more practical scenarios, where one needs to achieve improvements on both model accuracy and predictor network parameter-efficiency simultaneously.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294811926",
                    "name": "Hongjun Choi"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                },
                {
                    "authorId": "2294720741",
                    "name": "Ruben Glatt"
                },
                {
                    "authorId": "2294810557",
                    "name": "Shusen Liu"
                }
            ]
        },
        {
            "paperId": "0254468083ed3c8f079dfaf9f7fae3009b981f53",
            "title": "Exploring Inlier and Outlier Specification for Improved Medical OOD Detection",
            "abstract": "We address the crucial task of developing well-calibrated out-of-distribution (OOD) detectors, in order to enable safe deployment of medical image classifiers. Calibration enables deep networks to protect against trivial decision rules and controls over-generalization, thereby supporting model reliability. Given the challenges involved in curating appropriate calibration datasets, synthetic augmentations have gained significant popularity for inlier/outlier specification. Despite the rapid progress in data augmentation techniques, our study reveals a remarkable finding: the synthesis space and augmentation type play a pivotal role in effectively calibrating OOD detectors. Using the popular energy-based OOD detection framework, we find that the optimal protocol is to synthesize latent-space inliers along with diverse pixel-space outliers. Through extensive empirical studies conducted on multiple medical imaging benchmarks, we consistently demonstrate the superiority of our approach, achieving substantial improvements of 15% - 35% in AUROC compared to the state-of-the-art across various open-set recognition settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2121317308",
                    "name": "Yamen Mubarka"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "145882781",
                    "name": "Deepta Rajan"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        }
    ]
}