{
    "authorId": "2266387781",
    "papers": [
        {
            "paperId": "64c8edfd8db83a893eaf0e2d137acb23eb698fd3",
            "title": "SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages",
            "abstract": "Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader phenomenon of semantic relatedness. In this paper, we present \\textit{SemRel}, a new semantic relatedness dataset collection annotated by native speakers across 13 languages: \\textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Spanish,} and \\textit{Telugu}. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia -- regions characterised by a relatively limited availability of NLP resources. Each instance in the SemRel datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. The scores are obtained using a comparative annotation framework. We describe the data collection and annotation processes, challenges when building the datasets, baseline experiments, and their impact and utility in NLP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3056500",
                    "name": "N. Ousidhoum"
                },
                {
                    "authorId": "7744881",
                    "name": "Shamsuddeen Hassan Muhammad"
                },
                {
                    "authorId": "2283931971",
                    "name": "Mohamed Abdalla"
                },
                {
                    "authorId": "2260237439",
                    "name": "Idris Abdulmumin"
                },
                {
                    "authorId": "153795444",
                    "name": "I. Ahmad"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "71323208",
                    "name": "A. Ayele"
                },
                {
                    "authorId": "2269468034",
                    "name": "Pavan Baswani"
                },
                {
                    "authorId": "2604621",
                    "name": "Meriem Beloucif"
                },
                {
                    "authorId": "1829342",
                    "name": "Christian Biemann"
                },
                {
                    "authorId": "2266839087",
                    "name": "Sofia Bourhim"
                },
                {
                    "authorId": "2047358683",
                    "name": "Christine de Kock"
                },
                {
                    "authorId": "2283935559",
                    "name": "Genet Shanko Dekebo"
                },
                {
                    "authorId": "23245535",
                    "name": "Oumaima Hourrane"
                },
                {
                    "authorId": "2268675106",
                    "name": "Gopichand Kanumolu"
                },
                {
                    "authorId": "2268674912",
                    "name": "Lokesh Madasu"
                },
                {
                    "authorId": "30571646",
                    "name": "Samuel Rutunda"
                },
                {
                    "authorId": "2280905799",
                    "name": "Manish Shrivastava"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "2104748735",
                    "name": "Nirmal Surange"
                },
                {
                    "authorId": "2283932533",
                    "name": "Hailegnaw Getaneh Tilaye"
                },
                {
                    "authorId": "51172231",
                    "name": "Krishnapriya Vishnubhotla"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "3084761",
                    "name": "Seid Muhie Yimam"
                },
                {
                    "authorId": "2261458500",
                    "name": "Saif Mohammad"
                }
            ]
        },
        {
            "paperId": "926b8fa0f6afe07d8ef4cb921377db672a6ebba7",
            "title": "sPhinX: Sample Efficient Multilingual Instruction Fine-Tuning Through N-shot Guided Prompting",
            "abstract": "Despite the remarkable success of LLMs in English, there is a significant gap in performance in non-English languages. In order to address this, we introduce a novel recipe for creating a multilingual synthetic instruction tuning dataset, sPhinX, which is created by selectively translating instruction response pairs from English into 50 languages. We test the effectiveness of sPhinX by using it to fine-tune two state-of-the-art models, Phi-3-small and Mistral-7B and then evaluating them across a comprehensive suite of multilingual benchmarks that test reasoning, question answering, and reading comprehension. Our results show that Phi-3-small and Mistral-7B fine-tuned with sPhinX perform better on an average by 4.2%pt and 5%pt respectively as compared to the baselines. We also devise a strategy to incorporate N-shot examples in each fine-tuning sample which further boosts the performance of these models by 3%pt and 10%pt respectively. Additionally, sPhinX also outperforms other multilingual instruction tuning datasets on the same benchmarks along with being sample efficient and diverse, thereby reducing dataset creation costs. Additionally, instruction tuning with sPhinX does not lead to regression on most standard LLM benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "123587511",
                    "name": "K. Tanmay"
                },
                {
                    "authorId": "2262218438",
                    "name": "Hardik Hansrajbhai Chauhan"
                },
                {
                    "authorId": "27419446",
                    "name": "Barun Patra"
                },
                {
                    "authorId": "2277742254",
                    "name": "Kriti Aggarwal"
                },
                {
                    "authorId": "2952437",
                    "name": "Tejas I. Dhamecha"
                },
                {
                    "authorId": "2159712911",
                    "name": "Monojit Choudhary"
                },
                {
                    "authorId": "113810201",
                    "name": "Vishrav Chaudhary"
                },
                {
                    "authorId": "2256989615",
                    "name": "Sunayana Sitaram"
                }
            ]
        },
        {
            "paperId": "92940bf82f8163976c0615a97b271b1af71a5b35",
            "title": "SemEval Task 1: Semantic Textual Relatedness for African and Asian Languages",
            "abstract": "We present the first shared task on Semantic Textual Relatedness (STR). While earlier shared tasks primarily focused on semantic similarity, we instead investigate the broader phenomenon of semantic relatedness across 14 languages: Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Punjabi, Spanish, and Telugu. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia \u2013 regions characterised by the relatively limited availability of NLP resources. Each instance in the datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. Participating systems were asked to rank sentence pairs by their closeness in meaning (i.e., their degree of semantic relatedness) in the 14 languages in three main tracks: (a) supervised, (b) unsupervised, and (c) crosslingual. The task attracted 163 participants. We received 70 submissions in total (across all tasks) from 51 different teams, and 38 system description papers. We report on the best-performing systems as well as the most common and the most effective approaches for the three different tracks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3056500",
                    "name": "N. Ousidhoum"
                },
                {
                    "authorId": "7744881",
                    "name": "Shamsuddeen Hassan Muhammad"
                },
                {
                    "authorId": "2283931971",
                    "name": "Mohamed Abdalla"
                },
                {
                    "authorId": "2260237439",
                    "name": "Idris Abdulmumin"
                },
                {
                    "authorId": "153795444",
                    "name": "I. Ahmad"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "2604621",
                    "name": "Meriem Beloucif"
                },
                {
                    "authorId": "2047358683",
                    "name": "Christine de Kock"
                },
                {
                    "authorId": "23245535",
                    "name": "Oumaima Hourrane"
                },
                {
                    "authorId": "2280905799",
                    "name": "Manish Shrivastava"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "2104748735",
                    "name": "Nirmal Surange"
                },
                {
                    "authorId": "2293724273",
                    "name": "Krishnapriya Vishnubhotla"
                },
                {
                    "authorId": "3084761",
                    "name": "Seid Muhie Yimam"
                },
                {
                    "authorId": "2261458500",
                    "name": "Saif Mohammad"
                }
            ]
        },
        {
            "paperId": "ca60cb73d770f7093100cdea12b19881e7610df1",
            "title": "DOSA: A Dataset of Social Artifacts from Different Indian Geographical Subcultures",
            "abstract": "Generative models are increasingly being used in various applications, such as text generation, commonsense reasoning, and question-answering. To be effective globally, these models must be aware of and account for local socio-cultural contexts, making it necessary to have benchmarks to evaluate the models for their cultural familiarity. Since the training data for LLMs is web-based and the Web is limited in its representation of information, it does not capture knowledge present within communities that are not on the Web. Thus, these models exacerbate the inequities, semantic misalignment, and stereotypes from the Web. There has been a growing call for community-centered participatory research methods in NLP. In this work, we respond to this call by using participatory research methods to introduce DOSA, the first community-generated Dataset of 615 Social Artifacts, by engaging with 260 participants from 19 different Indian geographic subcultures. We use a gamified framework that relies on collective sensemaking to collect the names and descriptions of these artifacts such that the descriptions semantically align with the shared sensibilities of the individuals from those cultures. Next, we benchmark four popular LLMs and find that they show significant variation across regional sub-cultures in their ability to infer the artifacts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261734475",
                    "name": "Agrima Seth"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "3086996",
                    "name": "Kalika Bali"
                },
                {
                    "authorId": "2256989615",
                    "name": "Sunayana Sitaram"
                }
            ]
        },
        {
            "paperId": "fb034ba01f7de7760a400cc6956002717314dda8",
            "title": "SemEval Task 1: Semantic Textual Relatedness for African and Asian Languages",
            "abstract": "We present the first shared task on Semantic Textual Relatedness (STR). While earlier shared tasks primarily focused on semantic similarity, we instead investigate the broader phenomenon of semantic relatedness across 14 languages: Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Punjabi, Spanish, and Telugu . These languages originate from five distinct language families and are predominantly spoken in Africa and Asia \u2013 regions characterised by the relatively limited availability of NLP resources. Each instance in the datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. Participating systems were asked to rank sentence pairs by their closeness in meaning (i.e., their degree of semantic relatedness) in the 14 languages in three main tracks: (a) supervised, (b) unsupervised, and (c) crosslingual. The task attracted 163 participants. We received 70 submissions in total (across all tasks) from 51 different teams, and 38 system description papers. We report on the best-performing systems as well as the most common and the most effective approaches for the three different tracks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3056500",
                    "name": "N. Ousidhoum"
                },
                {
                    "authorId": "7744881",
                    "name": "Shamsuddeen Hassan Muhammad"
                },
                {
                    "authorId": "2283931971",
                    "name": "Mohamed Abdalla"
                },
                {
                    "authorId": "2260237439",
                    "name": "Idris Abdulmumin"
                },
                {
                    "authorId": "153795444",
                    "name": "I. Ahmad"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "2604621",
                    "name": "Meriem Beloucif"
                },
                {
                    "authorId": "2047358683",
                    "name": "Christine de Kock"
                },
                {
                    "authorId": "23245535",
                    "name": "Oumaima Hourrane"
                },
                {
                    "authorId": "2280905799",
                    "name": "Manish Shrivastava"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "2104748735",
                    "name": "Nirmal Surange"
                },
                {
                    "authorId": "2293724273",
                    "name": "Krishnapriya Vishnubhotla"
                },
                {
                    "authorId": "2295375069",
                    "name": "Seid Muhie Yimam"
                },
                {
                    "authorId": "2261458500",
                    "name": "Saif Mohammad"
                }
            ]
        },
        {
            "paperId": "71c3c3c262239adb89b41d4c80e342cd24f11ef3",
            "title": "MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks",
            "abstract": "There has been a surge in LLM evaluation research to understand LLM capabilities and limitations. However, much of this research has been confined to English, leaving LLM building and evaluation for non-English languages relatively unexplored. Several new LLMs have been introduced recently, necessitating their evaluation on non-English languages. This study aims to perform a thorough evaluation of the non-English capabilities of SoTA LLMs (GPT-3.5-Turbo, GPT-4, PaLM2, Gemini-Pro, Mistral, Llama2, and Gemma) by comparing them on the same set of multilingual datasets. Our benchmark comprises 22 datasets covering 83 languages, including low-resource African languages. We also include two multimodal datasets in the benchmark and compare the performance of LLaVA models, GPT-4-Vision and Gemini-Pro-Vision. Our experiments show that larger models such as GPT-4, Gemini-Pro and PaLM2 outperform smaller models on various tasks, notably on low-resource languages, with GPT-4 outperforming PaLM2 and Gemini-Pro on more datasets. We also perform a study on data contamination and find that several models are likely to be contaminated with multilingual evaluation benchmarks, necessitating approaches to detect and handle contamination while assessing the multilingual performance of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "27543974",
                    "name": "Divyanshu Aggarwal"
                },
                {
                    "authorId": "2140408530",
                    "name": "Varun Gumma"
                },
                {
                    "authorId": "2297767230",
                    "name": "Ishaan Watts"
                },
                {
                    "authorId": "2266397701",
                    "name": "Ashutosh Sathe"
                },
                {
                    "authorId": "104014275",
                    "name": "Millicent Ochieng"
                },
                {
                    "authorId": "35831406",
                    "name": "Rishav Hada"
                },
                {
                    "authorId": "3094662",
                    "name": "Prachi Jain"
                },
                {
                    "authorId": "2212463954",
                    "name": "Maxamed Axmed"
                },
                {
                    "authorId": "3086996",
                    "name": "Kalika Bali"
                },
                {
                    "authorId": "2256989615",
                    "name": "Sunayana Sitaram"
                }
            ]
        },
        {
            "paperId": "62fbd22c74502f49a90027ddb7640ddb43afe4ec",
            "title": "HYPHEN: Hyperbolic Hawkes Attention For Text Streams",
            "abstract": "Analyzing the temporal sequence of texts from sources such as social media, news, and parliamentary debates is a challenging problem as it exhibits time-varying scale-free properties and fine-grained timing irregularities. We propose a Hyperbolic Hawkes Attention Network (HYPHEN), which learns a data-driven hyperbolic space and models irregular powerlaw excitations using a hyperbolic Hawkes process. Through quantitative and exploratory experiments over financial NLP, suicide ideation detection, and political debate analysis we demonstrate HYPHEN\u2019s practical applicability for modeling online text sequences in a geometry agnostic manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "2161000447",
                    "name": "Ritesh Soun"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        }
    ]
}