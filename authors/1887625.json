{
    "authorId": "1887625",
    "papers": [
        {
            "paperId": "816ab414e9820f1bb550bceaa8065b10f55de42e",
            "title": "Federated Split Learning With Data and Label Privacy Preservation in Vehicular Networks",
            "abstract": "Federatedlearning (FL) is an emerging distributed learning paradigm widely used in vehicular networks, where vehicles are enabled to train the deep model for the server while keeping private data locally. However, the annotation of private data by vehicular users is very difficult since the high costs and professional needs, and one solution is that roadside infrastructures could provide label mapping to the data according to the geographical coordinates. In this scenario where vehicles and roadside infrastructures hold the data and labels, respectively, traditional FL is not applicable since it needs each participant to have both data and labels. In this article, we propose a federated split learning (FSL) paradigm that split the deep model into two submodels which are trained separately in the vehicles and the roadside infrastructures. The vehicles and the roadside infrastructures exchange the intermediate data (i.e., smashed data and cut layer gradients) in training local submodels and upload the local gradients to the global server for aggregation into the global model. Specifically, we first adopt three types of privacy attacks to demonstrate that attackers could recover the private data and labels according to the shared intermediate data and uploaded local gradients. We then propose a differential privacy (DP)-based defense mechanism to defend the privacy attacks by perturbing the intermediate data. Furthermore, we design a contract-based incentive mechanism that encourages vehicles and roadside infrastructures to enhance training performance by adjusting their privacy strategies. The simulation results illustrated that the proposed defense mechanism can remarkably emasculate the performance of attacks and the proposed incentive mechanism is efficient in the FSL paradigm for vehicular networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3427682",
                    "name": "Maoqiang Wu"
                },
                {
                    "authorId": "2153217492",
                    "name": "Guoliang Cheng"
                },
                {
                    "authorId": "2192785",
                    "name": "Dongdong Ye"
                },
                {
                    "authorId": "145993626",
                    "name": "Jiawen Kang"
                },
                {
                    "authorId": "143791274",
                    "name": "Rong Yu"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2147192788",
                    "name": "Miao Pan"
                }
            ]
        },
        {
            "paperId": "c31ed7fb2091d665debca82cdedcec5cd0f148a3",
            "title": "Smart Fiber-Optic Distributed Acoustic Sensing (sDAS) With Multitask Learning for Time-Efficient Ground Listening Applications",
            "abstract": "In recent years, fiber-optical distributed acoustic sensing (DAS) has been applied to various large-scale infrastructure monitoring areas in smart cities, leading to a new generation of fiber-optic IoT for ground listening. However, its single-task-focused postprocessing methods cannot achieve real-time efficient ground event recognition and localization concurrently. In this article, a two-level multitask learning (MTL) enhanced smart fiber-optical DAS (sDAS) system is proposed, for the first time, to simultaneously realize ground event recognition and localization. Performances and efficiency of both tasks are significantly improved by sharing knowledge across them. Besides, the imbalanced incremental learning ability for new events is also enhanced in the proposed MTL network. The total computation time for the two tasks is greatly shortened to 0.3 ms for a spatial-temporal sample with 129-m fiber length and 5-s time frame, which equals to a processing time of 0.04 s over a total fiber length of 18.7-km with a spatial sampling interval of 1.29 m, and is even better than the fastest single recognition reported to date. In the field test, such an MTL-enhanced sDAS system indicates excellent feature extraction performance with classification accuracy of up to 99.46% for five events and location error of \u00b11 m for two core-events at 8/16 different radial distances, which are much better than the DAS systems with multiclassifier and the combined single-task learning methods. Also, the MTL-enhanced sDAS shows strong robustness against environmental noises. Hence, it provides a breakthrough technology for time-efficient multitask processing in smart distributed sensors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47987652",
                    "name": "Huijuan Wu"
                },
                {
                    "authorId": "2143696580",
                    "name": "Yufeng Wang"
                },
                {
                    "authorId": "48032577",
                    "name": "Xinyu Liu"
                },
                {
                    "authorId": "2109026354",
                    "name": "Yuwen Sun"
                },
                {
                    "authorId": "2185902911",
                    "name": "Guofeng Yan"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2237220210",
                    "name": "Yunjiang Rao"
                }
            ]
        },
        {
            "paperId": "f5216aa94b28eb7e5d9ab5f2d295c34147ec013d",
            "title": "Railway Track Online Detection Based on Optical Fiber Distributed Large-Range Acoustic Sensing",
            "abstract": "An optical fiber distributed acoustic sensing (DAS) system for large infrastructure vibration monitoring is proposed in this work. To meet the requirements of measurement range, spatial resolution, and real-time performance of the monitoring network, the acrlong RE algorithm is proposed to optimize the recovery of large signals for the DAS monitoring of large-scale infrastructure structure monitoring networks. Furthermore, the technology is applied to heavy rail track defect detection, where existing track-side communication cables are used to directly monitored vibration signals with the DAS system. Multiple characteristic parameters are combined to form a multidimensional eigenvector, and then combined with the acrlong ML algorithm to enable the recognition of typical track defects along the heavy-haul railway. The experimental results demonstrate that the recognition and classification of typical track defects, such as acrlong RCF, corrugation, and unsupported sleepers. The real-time detection of track defects in this work can be used as a crucial basis for workers to maintain and repair the railway. Finally, a long-term real-time online monitoring method is proposed in this work for vibration monitoring of large-scale infrastructures with large-amplitude/low-SNR signals using existing track-side communication cables, without any additional sensor arrangement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237394352",
                    "name": "Lang Xie"
                },
                {
                    "authorId": "2237402329",
                    "name": "Zhaojie Li"
                },
                {
                    "authorId": "2237408935",
                    "name": "Yiwei Zhou"
                },
                {
                    "authorId": "2237218709",
                    "name": "Weiming Xiang"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2237220210",
                    "name": "Yunjiang Rao"
                }
            ]
        },
        {
            "paperId": "1747a3db25788889da32a9e92d8a08edb50d1d7a",
            "title": "1st Place Solution for PVUW Challenge 2023: Video Panoptic Segmentation",
            "abstract": "Video panoptic segmentation is a challenging task that serves as the cornerstone of numerous downstream applications, including video editing and autonomous driving. We believe that the decoupling strategy proposed by DVIS enables more effective utilization of temporal information for both\"thing\"and\"stuff\"objects. In this report, we successfully validated the effectiveness of the decoupling strategy in video panoptic segmentation. Finally, our method achieved a VPQ score of 51.4 and 53.7 in the development and test phases, respectively, and ultimately ranked 1st in the VPS track of the 2nd PVUW Challenge. The code is available at https://github.com/zhang-tao-whu/DVIS",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689115",
                    "name": "Zhang Tao"
                },
                {
                    "authorId": "2218999030",
                    "name": "Xingye Tian"
                },
                {
                    "authorId": "151030320",
                    "name": "Haoran Wei"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2862986",
                    "name": "Shunping Ji"
                },
                {
                    "authorId": "2218913596",
                    "name": "Xuebo Wang"
                },
                {
                    "authorId": "2202356639",
                    "name": "Yuanhui Zhang"
                },
                {
                    "authorId": "37124370",
                    "name": "Pengfei Wan"
                }
            ]
        },
        {
            "paperId": "1e06ebbcecf93f4a333b701100ac5ef1982ee072",
            "title": "Communication-Efficient Federated Learning on Non-IID Data Using Two-Step Knowledge Distillation",
            "abstract": "Federated learning (FL) has shown its great potential for achieving distributed intelligence in privacy-sensitive IoT. However, popular FL approaches, such as FedAvg and its variants share model parameters among clients during the training process and thus cause significant communication overhead in IoT. Moreover, nonindependent and identically distributed (non-IID) data across learning devices severely affect the convergence and speed of FL. To address these challenges, we propose a communication-efficient FL framework based on Two-step Knowledge Distillation, Fed2KD, which boosts the classification accuracy through privacy-preserving data generation while improving communication efficiency through a new knowledge distillation scheme empowered by an attention mechanism and metric learning. The generalization ability of Fed2KD is analyzed from the view of domain adaption. Extensive simulation experiments are conducted on Fashion-MNIST, CIFAR-10, and ImageNet data sets with various non-IID data distributions. The performance results show that Fed2KD can reduce the communication overhead and improve classification accuracy compared to FedAvg and its latest variants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152697641",
                    "name": "Hancong Duan"
                },
                {
                    "authorId": "2244050770",
                    "name": "Geyong"
                },
                {
                    "authorId": "1482590379",
                    "name": "Hui Wen"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2245067689",
                    "name": "Jia Hu"
                },
                {
                    "authorId": "1687515",
                    "name": "Z. Wang"
                },
                {
                    "authorId": "2237139342",
                    "name": "Geyong Min"
                }
            ]
        },
        {
            "paperId": "4008cdf1fce3310c4a6b338c1332e38e3753489f",
            "title": "DVIS: Decoupled Video Instance Segmentation Framework",
            "abstract": "Video instance segmentation (VIS) is a critical task with diverse applications, including autonomous driving and video editing. Existing methods often underperform on complex and long videos in real world, primarily due to two factors. Firstly, offline methods are limited by the tightly-coupled modeling paradigm, which treats all frames equally and disregards the interdependencies between adjacent frames. Consequently, this leads to the introduction of excessive noise during long-term temporal alignment. Secondly, online methods suffer from inadequate utilization of temporal information. To tackle these challenges, we propose a decoupling strategy for VIS by dividing it into three independent sub-tasks: segmentation, tracking, and refinement. The efficacy of the decoupling strategy relies on two crucial elements: 1) attaining precise long-term alignment outcomes via frame-by-frame association during tracking, and 2) the effective utilization of temporal information predicated on the aforementioned accurate alignment outcomes during refinement. We introduce a novel referring tracker and temporal refiner to construct the Decoupled VIS framework (DVIS). DVIS achieves new SOTA performance in both VIS and VPS, surpassing the current SOTA methods by 7.3 AP and 9.6 VPQ on the OVIS and VIPSeg datasets, which are the most challenging and realistic benchmarks. Moreover, thanks to the decoupling strategy, the referring tracker and temporal refiner are super light-weight (only 1.69% of the segmenter FLOPs), allowing for efficient training and inference on a single GPU with 11G memory. The code is available at https://github.com/zhang-tao-whu/DVIS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146343742",
                    "name": "Tao Zhang"
                },
                {
                    "authorId": "2218999030",
                    "name": "Xingye Tian"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2862986",
                    "name": "Shunping Ji"
                },
                {
                    "authorId": "2218913596",
                    "name": "Xuebo Wang"
                },
                {
                    "authorId": "2156008389",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "37124370",
                    "name": "Pengfei Wan"
                }
            ]
        },
        {
            "paperId": "408b1e1e3c1ffaf8f14aae3a9b4a5d14057a5efb",
            "title": "1st Place Solution for the 5th LSVOS Challenge: Video Instance Segmentation",
            "abstract": "Video instance segmentation is a challenging task that serves as the cornerstone of numerous downstream applications, including video editing and autonomous driving. In this report, we present further improvements to the SOTA VIS method, DVIS. First, we introduce a denoising training strategy for the trainable tracker, allowing it to achieve more stable and accurate object tracking in complex and long videos. Additionally, we explore the role of visual foundation models in video instance segmentation. By utilizing a frozen VIT-L model pre-trained by DINO v2, DVIS demonstrates remarkable performance improvements. With these enhancements, our method achieves 57.9 AP and 56.0 AP in the development and test phases, respectively, and ultimately ranked 1st in the VIS track of the 5th LSVOS Challenge. The code will be available at https://github.com/zhang-tao-whu/DVIS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "101643752",
                    "name": "Tao Zhang"
                },
                {
                    "authorId": "2218999030",
                    "name": "Xingye Tian"
                },
                {
                    "authorId": "2235153275",
                    "name": "Yikang Zhou"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2862986",
                    "name": "Shunping Ji"
                },
                {
                    "authorId": "2148776897",
                    "name": "Cilin Yan"
                },
                {
                    "authorId": "2218913596",
                    "name": "Xuebo Wang"
                },
                {
                    "authorId": "49902634",
                    "name": "Xin Tao"
                },
                {
                    "authorId": "2202356639",
                    "name": "Yuanhui Zhang"
                },
                {
                    "authorId": "37124370",
                    "name": "Pengfei Wan"
                }
            ]
        },
        {
            "paperId": "4fff82435192ea9bc75bbdbbe413effc35084938",
            "title": "Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World",
            "abstract": "Scene Graph Generation (SGG) aims to extract relationships in images for vision understanding. Although recent works have made steady progress on SGG, they still suffer long-tail distribution issues that tail-predicates are more costly to train and hard to distinguish due to a small amount of annotated data compared to frequent predicates. Existing re-balancing strategies try to handle it via prior rules but are still confined to pre-defined conditions, which are not scalable for various models and datasets. In this paper, we propose a Cross-modal prediCate boosting (CaCao) framework, where a visually-prompted language model is learned to generate diverse fine-grained predicates in a low-resource way. The proposed CaCao can be applied in a plug-and-play fashion and automatically strengthen existing SGG to tackle the long-tailed problem. Based on that, we further introduce a novel Entangled cross-modal prompt approach for open-world predicate scene graph generation (Epic), where models can generalize to unseen predicates in a zero-shot manner. Comprehensive experiments on three benchmark datasets show that CaCao consistently boosts the performance of multiple scene graph generation models in a model-agnostic way. Moreover, our Epic achieves competitive performance on open-world predicate prediction. The data and code for this paper are publicly available.1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2206456553",
                    "name": "Qifan Yu"
                },
                {
                    "authorId": "2108998895",
                    "name": "Juncheng Li"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "2118071462",
                    "name": "Siliang Tang"
                },
                {
                    "authorId": "144540018",
                    "name": "Wei Ji"
                },
                {
                    "authorId": "2125211",
                    "name": "Yueting Zhuang"
                }
            ]
        },
        {
            "paperId": "7062f69a56f2f9be1324b4f395080a067d0a7987",
            "title": "Federated Learning-Empowered AI-Generated Content in Wireless Networks",
            "abstract": "Artificial intelligence generated content (AIGC) has emerged as a promising technology to improve the efficiency, quality, diversity and flexibility of the content creation process by adopting a variety of generative AI models. Deploying AIGC services in wireless networks has been expected to enhance the user experience. However, the existing AIGC service provision suffers from several limitations, e.g., the centralized training in the pre-training, fine-tuning, and inference processes, especially their implementations in wireless networks with privacy preservation. Federated learning (FL), as a collaborative learning framework where the model training is distributed to cooperative data owners without the need for data sharing, can be leveraged to simultaneously improve learning efficiency and achieve privacy protection for AIGC. To this end, we present FL-based techniques for empowering AIGC, and aim to enable users to generate diverse, personalized, and high-quality content. Furthermore, we conduct a case study of FL-aided AIGC fine-tuning by using the state-of-the-art AIGC model, i.e., stable diffusion model. Numerical results show that our scheme achieves advantages in effectively reducing the communication cost and training latency, and providing privacy protection. Finally, we highlight several major research directions and open issues for the convergence of FL and AIGC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3116552",
                    "name": "Xumin Huang"
                },
                {
                    "authorId": "47471151",
                    "name": "Peichun Li"
                },
                {
                    "authorId": "2175043468",
                    "name": "Hongyang Du"
                },
                {
                    "authorId": "145993626",
                    "name": "Jiawen Kang"
                },
                {
                    "authorId": "1713586",
                    "name": "D. Niyato"
                },
                {
                    "authorId": "34841193",
                    "name": "Dong In Kim"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                }
            ]
        },
        {
            "paperId": "729a08bd933beb22b94025dc2f184a8d9f96155f",
            "title": "A Computationally Efficient Airborne Forward-Looking Super-Resolution Imaging Method Based on Sparse Bayesian Learning",
            "abstract": "In airborne forward-looking imaging, the azimuth resolution and the imaging efficiency are important. In this article, we propose a low-dimensional sparse Bayesian learning with Doppler compensation (LDSBL-DC) method to improve the azimuth resolution with low computational complexity in airborne forward-looking imaging. First, since the variant pitching angle causes the space variant of the Doppler centroid, the Doppler convolution matrix needs to be constructed in each range cell. We construct a Doppler compensation matrix to eliminate the space variant of the Doppler centroid. After the Doppler centroid compensation, the Doppler convolution matrix only needs to be constructed once. Second, we propose a low-dimensional projection model based on the singular value decomposition. In the low-dimensional projection model, the high-dimensional echo data is compressed to low-dimensional data. Finally, combining Doppler centroid compensation and low-dimensional projection model, a new forward-looking imaging model is created, and we introduce sparse Bayesian learning (SBL) to estimate the imaging parameters. In the estimation of the targets\u2019 scattering coefficient, we reduce the computational complexity by the matrix transformation. Several simulations are designed to evaluate the performance of the efficient forward-looking imaging method. The simulation results show that the LDSBL-DC method can improve the azimuth resolution with a low computational complexity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139288739",
                    "name": "Weixin Li"
                },
                {
                    "authorId": "35834541",
                    "name": "Ming Li"
                },
                {
                    "authorId": "2054756261",
                    "name": "Lei Zuo"
                },
                {
                    "authorId": "118164182",
                    "name": "Hongmeng Chen"
                },
                {
                    "authorId": "1887625",
                    "name": "Yuehua Wu"
                },
                {
                    "authorId": "32820581",
                    "name": "Zhenyu Zhuo"
                }
            ]
        }
    ]
}