{
    "authorId": "145800151",
    "papers": [
        {
            "paperId": "05c8caf9a5c992eb047f7baf23957a33c1caa60a",
            "title": "TAP: A Comprehensive Data Repository for Traffic Accident Prediction in Road Networks",
            "abstract": "Road safety is a major global public health concern, and effective prediction of traffic accidents at a fine-grained spatial scale plays a critical role in reducing roadway deaths and serious injuries. However, previous studies have either overlooked implicit spatial correlations or inadequately simulated road structures due to the lack of graph-structured datasets. To bridge this gap, we introduce a graph-based Traffic Accident Prediction (TAP) data repository, along with two representative tasks: accident occurrence and severity prediction. With its real-world graph structures, comprehensive geographical coverage, and rich geospatial features, this repository has considerable potential to facilitate various traffic-related tasks. We extensively evaluate eleven Graph Neural Network (GNN) baselines using the constructed datasets. We also develop a novel GNN-based model, which can capture additional angular and directional information from road networks. We demonstrate that the proposed model consistently outperforms the baselines. The data and code are available at https://github.com/baixianghuang/travel.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51164501",
                    "name": "Baixiang Huang"
                },
                {
                    "authorId": "2019961",
                    "name": "Bryan Hooi"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        },
        {
            "paperId": "1664ded356e6aa8fefbdcd50509e9d1d91ef3cb9",
            "title": "Data Augmentation for Seizure Prediction with Generative Diffusion Model",
            "abstract": "Objective: Seizure prediction is of great importance to improve the life of patients. The focal point is to distinguish preictal states from interictal ones. With the development of machine learning, seizure prediction methods have achieved significant progress. However, the severe imbalance problem between preictal and interictal data still poses a great challenge, restricting the performance of classifiers. Data augmentation is an intuitive way to solve this problem. Existing data augmentation methods generate samples by overlapping or recombining data. The distribution of generated samples is limited by original data, because such transformations cannot fully explore the feature space and offer new information. As the epileptic EEG representation varies among seizures, these generated samples cannot provide enough diversity to achieve high performance on a new seizure. As a consequence, we propose a novel data augmentation method with diffusion model called DiffEEG. Methods: Diffusion models are a class of generative models that consist of two processes. Specifically, in the diffusion process, the model adds noise to the input EEG sample step by step and converts the noisy sample into output random noise, exploring the distribution of data by minimizing the loss between the output and the noise added. In the denoised process, the model samples the synthetic data by removing the noise gradually, diffusing the data distribution to outward areas and narrowing the distance between different clusters. Results: We compared DiffEEG with existing methods, and integrated them into three representative classifiers. The experiments indicate that DiffEEG could further improve the performance and shows superiority to existing methods. Conclusion: This paper proposes a novel and effective method to solve the imbalanced problem and demonstrates the effectiveness and generality of our method.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                },
                {
                    "authorId": "2167879070",
                    "name": "Yuchang Zhao"
                },
                {
                    "authorId": "152318056",
                    "name": "Le Wu"
                },
                {
                    "authorId": "145341848",
                    "name": "Aiping Liu"
                },
                {
                    "authorId": "2061001769",
                    "name": "Ruobing Qian"
                },
                {
                    "authorId": "2160953865",
                    "name": "Xun Chen"
                }
            ]
        },
        {
            "paperId": "1a8771d67690158c5ca06c9e6429a8fc5dce8ae4",
            "title": "Investigating Gender Euphoria and Dysphoria on TikTok: Characterization and Comparison",
            "abstract": "With the emergence of short video-sharing platforms, engagement with social media sites devoted to opinion and knowledge dissemination has rapidly increased. Among the short video platforms, TikTok is one of the most popular globally and has become the platform of choice for transgender and nonbinary individuals, who have formed a large community to mobilize personal experience and exchange information. The knowledge produced in online spaces can influence the ways in which people understand and experience their own gender and transitions, as they hear about others and weigh that experiential and medical knowledge against their own. This paper extends current research and past interview methods on gender euphoria and gender dysphoria to analyze what and how online communities on TikTok discuss these two types of gender experiences. Our findings indicate that gender euphoria and gender dysphoria are differently described in online TikTok spaces. These findings indicate that there are wide similarities in the words used to describe gender dysphoria as well as gender euphoria in both the comments of videos and content creators' hashtags. Finally, our results show that gender euphoria is described in more similar terms between transfeminine and transmasculine experiences than gender dysphoria, which appears to be more differentiated by gendering experience and transition goals. We hope this paper can provide insights for future research on understanding transgender and nonbinary individuals in online communities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218577331",
                    "name": "SJ Dillon"
                },
                {
                    "authorId": "2152485663",
                    "name": "Yueqing Liang"
                },
                {
                    "authorId": "2013947833",
                    "name": "H. Bernard"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        },
        {
            "paperId": "1c1a728b26b1aff8c839aa76093c23eddd921598",
            "title": "MUSER: A MUlti-Step Evidence Retrieval Enhancement Framework for Fake News Detection",
            "abstract": "The ease of spreading false information online enables individuals with malicious intent to manipulate public opinion and destabilize social stability. Recently, fake news detection based on evidence retrieval has gained popularity in an effort to identify fake news reliably and reduce its impact. Evidence retrieval-based methods can improve the reliability of fake news detection by computing the textual consistency between the evidence and the claim in the news. In this paper, we propose a framework for fake news detection based on MUlti- Step Evidence Retrieval enhancement (MUSER), which simulates the steps of human beings in the process of reading news, summarizing, consulting materials, and inferring whether the news is true or fake. Our model can explicitly model dependencies among multiple pieces of evidence, and perform multi-step associations for the evidence required for news verification through multi-step retrieval. In addition, our model is able to automatically collect existing evidence through paragraph retrieval and key evidence selection, which can save the tedious process of manual evidence collection. We conducted extensive experiments on real-world datasets in different languages, and the results demonstrate that our proposed model outperforms state-of-the-art baseline methods for detecting fake news by at least 3% in F1-Macro and 4% in F1-Micro. Furthermore, it provides interpretable evidence for end users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067746794",
                    "name": "Hao Liao"
                },
                {
                    "authorId": "2220698421",
                    "name": "Jiaohao Peng"
                },
                {
                    "authorId": "2220510482",
                    "name": "Zhanyi Huang"
                },
                {
                    "authorId": "47527881",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2151298654",
                    "name": "Guang\u2010hua Li"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                },
                {
                    "authorId": "2110971999",
                    "name": "Xingyu Xie"
                }
            ]
        },
        {
            "paperId": "353fa5d2fca52153cbafecf8e03b39a0fb9a7b97",
            "title": "Emulating Reader Behaviors for Fake News Detection",
            "abstract": "The wide dissemination of fake news has affected our lives in many aspects, making fake news detection important and attracting increasing attention. Existing approaches make substantial contributions in this field by modeling news from a single-modal or multi-modal perspective. However, these modal-based methods can result in sub-optimal outcomes as they ignore reader behaviors in news consumption and authenticity verification. For instance, they haven't taken into consideration the component-by-component reading process: from the headline, images, comments, to the body, which is essential for modeling news with more granularity. To this end, we propose an approach of Emulating the behaviors of readers (Ember) for fake news detection on social media, incorporating readers' reading and verificating process to model news from the component perspective thoroughly. Specifically, we first construct intra-component feature extractors to emulate the behaviors of semantic analyzing on each component. Then, we design a module that comprises inter-component feature extractors and a sequence-based aggregator. This module mimics the process of verifying the correlation between components and the overall reading and verification sequence. Thus, Ember can handle the news with various components by emulating corresponding sequences. We conduct extensive experiments on nine real-world datasets, and the results demonstrate the superiority of Ember.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2205050612",
                    "name": "Junwei Yin"
                },
                {
                    "authorId": "2147415949",
                    "name": "Min Gao"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                },
                {
                    "authorId": "1806179723",
                    "name": "Zehua Zhao"
                },
                {
                    "authorId": "2145497020",
                    "name": "Yinqiu Huang"
                },
                {
                    "authorId": "2144547802",
                    "name": "Jia Wang"
                }
            ]
        },
        {
            "paperId": "6f75e8b61f13562237851d8119cb2f9d49e073fb",
            "title": "Can LLM-Generated Misinformation Be Detected?",
            "abstract": "The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery on combating misinformation in the age of LLMs and the countermeasures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2163546329",
                    "name": "Canyu Chen"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        },
        {
            "paperId": "946981a998d7782d55fdf356a5e4423c0c1e7a52",
            "title": "Attacking Fake News Detectors via Manipulating News Social Engagement",
            "abstract": "Social media is one of the main sources for news consumption, especially among the younger generation. With the increasing popularity of news consumption on various social media platforms, there has been a surge of misinformation which includes false information or unfounded claims. As various text- and social context-based fake news detectors are proposed to detect misinformation on social media, recent works start to focus on the vulnerabilities of fake news detectors. In this paper, we present the first adversarial attack framework against Graph Neural Network (GNN)-based fake news detectors to probe their robustness. Specifically, we leverage a multi-agent reinforcement learning (MARL) framework to simulate the adversarial behavior of fraudsters on social media. Research has shown that in real-world settings, fraudsters coordinate with each other to share different news in order to evade the detection of fake news detectors. Therefore, we modeled our MARL framework as a Markov Game with bot, cyborg, and crowd worker agents, which have their own distinctive cost, budget, and influence. We then use deep Q-learning to search for the optimal policy that maximizes the rewards. Extensive experimental results on two real-world fake news propagation datasets demonstrate that our proposed framework can effectively sabotage the GNN-based fake news detector performance. We hope this paper can provide insights for future research on fake news detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256769280",
                    "name": "Haoran Wang"
                },
                {
                    "authorId": "8729899",
                    "name": "Yingtong Dou"
                },
                {
                    "authorId": "2163546329",
                    "name": "Canyu Chen"
                },
                {
                    "authorId": "46732871",
                    "name": "Lichao Sun"
                },
                {
                    "authorId": "144019071",
                    "name": "Philip S. Yu"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        },
        {
            "paperId": "c1e8377cc5f8b959f3c66000d1ceeef2dc658729",
            "title": "MetaGAD: Meta Representation Adaptation for Few-Shot Graph Anomaly Detection",
            "abstract": "Graph anomaly detection has long been an important problem in various domains pertaining to information security such as financial fraud, social spam and network intrusion. The majority of existing methods are performed in an unsupervised manner, as labeled anomalies in a large scale are often too expensive to acquire. However, the identified anomalies may turn out to be uninteresting data instances due to the lack of prior knowledge. In real-world scenarios, it is often feasible to obtain limited labeled anomalies, which have great potential to advance graph anomaly detection. However, the work exploring limited labeled anomalies and a large amount of unlabeled nodes in graphs to detect anomalies is relatively limited. Therefore, in this paper, we study an important problem of few-shot graph anomaly detection. Nonetheless, it is challenging to fully leverage the information of few-shot anomalous nodes due to the irregularity of anomalies and the overfitting issue in the few-shot learning. To tackle the above challenges, we propose a novel meta-learning based framework, MetaGAD, that learns to adapt the knowledge from self-supervised learning to few-shot supervised learning for graph anomaly detection. In specific, we formulate the problem as a bi-level optimization, ensuring MetaGAD converging to minimizing the validation loss, thus enhancing the generalization capacity. The comprehensive experiments on six real-world datasets with synthetic anomalies and\"organic\"anomalies (available in the datasets) demonstrate the effectiveness of MetaGAD in detecting anomalies with few-shot anomalies. The code is available at https://github.com/XiongxiaoXu/MetaGAD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2140517981",
                    "name": "Xiongxiao Xu"
                },
                {
                    "authorId": "66807781",
                    "name": "Kaize Ding"
                },
                {
                    "authorId": "2163546329",
                    "name": "Canyu Chen"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        },
        {
            "paperId": "c4de5bca13d9afc5ae5094e7bb2f3d6b1c13f88c",
            "title": "Combating Disinformation on Social Media and Its Challenges: A Computational Perspective",
            "abstract": "The use of social media has accelerated information sharing and instantaneous communications. The low barrier to entering social media enables more users to participate and keeps them engaged longer, incentivizing individuals with a hidden agenda to spread disinformation online to manipulate information and sway opinion. Disinformation, such as fake news, hoaxes, and conspiracy theories, has increasingly become a hindrance to the functioning of online social media as an effective channel for trustworthy information. Therefore, it is imperative to understand disinformation and systematically investigate how to improve resistance against it. This article highlights relevant theories and recent advancements of detecting disinformation from a computational perspective, and urges the need for future interdisciplinary research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        },
        {
            "paperId": "1665291a60f6c8b80eac4c9c720a08f1b7bb2efa",
            "title": "When Fairness Meets Privacy: Fair Classification with Semi-Private Sensitive Attributes",
            "abstract": "Machine learning models have demonstrated promising performance in many areas. However, the concerns that they can be biased against specific demographic groups hinder their adoption in high-stake applications. Thus, it is essential to ensure fairness in machine learning models. Most previous efforts require direct access to sensitive attributes for mitigating bias. Nonetheless, it is often infeasible to obtain large-scale users' sensitive attributes considering users' concerns about privacy in the data collection process. Privacy mechanisms such as local differential privacy (LDP) are widely enforced on sensitive information in the data collection stage due to legal compliance and people's increasing awareness of privacy. Therefore, a critical problem is how to make fair predictions under privacy. We study a novel and practical problem of fair classification in a semi-private setting, where most of the sensitive attributes are private and only a small amount of clean ones are available. To this end, we propose a novel framework FairSP that can achieve Fair prediction under the Semi-Private setting. First, FairSP learns to correct the noise-protected sensitive attributes by exploiting the limited clean sensitive attributes. Then, it jointly models the corrected and clean data in an adversarial way for debiasing and prediction. Theoretical analysis shows that the proposed model can ensure fairness under mild assumptions in the semi-private setting. Extensive experimental results on real-world datasets demonstrate the effectiveness of our method for making fair predictions under privacy and maintaining high accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2163546329",
                    "name": "Canyu Chen"
                },
                {
                    "authorId": "2152485663",
                    "name": "Yueqing Liang"
                },
                {
                    "authorId": "2140517981",
                    "name": "Xiongxiao Xu"
                },
                {
                    "authorId": "12009223",
                    "name": "Shangyu Xie"
                },
                {
                    "authorId": "1897202",
                    "name": "A. Kundu"
                },
                {
                    "authorId": "3443416",
                    "name": "Ali Payani"
                },
                {
                    "authorId": "50569535",
                    "name": "Yuan Hong"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                }
            ]
        }
    ]
}