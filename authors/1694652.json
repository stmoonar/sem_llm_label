{
    "authorId": "1694652",
    "papers": [
        {
            "paperId": "21b4777948797377deedf4a9f1f58ad13f6b8b5d",
            "title": "Overview of the Tenth Dialog System Technology Challenge: DSTC10",
            "abstract": "This article introduces the Tenth Dialog System Technology Challenge (DSTC-10). This edition of the DSTC focuses on applying end-to-end dialog technologies for five distinct tasks in dialog systems, namely 1. Incorporation of Meme images into open domain dialogs, 2. Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations, 3. Situated Interactive Multimodal dialogs, 4. Reasoning for Audio Visual Scene-Aware Dialog, and 5. Automatic Evaluation and Moderation of Open-domainDialogue Systems. This article describes the task definition, provided datasets, baselines, and evaluation setup for each track. We also summarize the results of the submitted systems to highlight the general trends of the state-of-the-art technologies for the tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237192",
                    "name": "Koichiro Yoshino"
                },
                {
                    "authorId": "1725643",
                    "name": "Yun-Nung (Vivian) Chen"
                },
                {
                    "authorId": "34963487",
                    "name": "Paul A. Crook"
                },
                {
                    "authorId": "2150275",
                    "name": "Satwik Kottur"
                },
                {
                    "authorId": "2887412",
                    "name": "Jinchao Li"
                },
                {
                    "authorId": "2127328167",
                    "name": "Behnam Hedayatnia"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "2066415714",
                    "name": "Zhengcong Fei"
                },
                {
                    "authorId": "2109965103",
                    "name": "Zekang Li"
                },
                {
                    "authorId": "27672597",
                    "name": "Jinchao Zhang"
                },
                {
                    "authorId": "2257374643",
                    "name": "Yang Feng"
                },
                {
                    "authorId": "2116575668",
                    "name": "Jie Zhou"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2152284471",
                    "name": "Di Jin"
                },
                {
                    "authorId": "1710287",
                    "name": "A. Papangelis"
                },
                {
                    "authorId": "145916630",
                    "name": "Karthik Gopalakrishnan"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "3057557",
                    "name": "Babak Damavandi"
                },
                {
                    "authorId": "1979505",
                    "name": "A. Geramifard"
                },
                {
                    "authorId": "1765212",
                    "name": "Chiori Hori"
                },
                {
                    "authorId": "31017418",
                    "name": "Ankit Shah"
                },
                {
                    "authorId": "2111574800",
                    "name": "Chen Zhang"
                },
                {
                    "authorId": "1711271",
                    "name": "Haizhou Li"
                },
                {
                    "authorId": "2319137716",
                    "name": "Jo\u00e3o Sedoc"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "5cf42d26583d2b083262451e9005e6ed273badca",
            "title": "Automatic Evaluation and Moderation of Open-domain Dialogue Systems",
            "abstract": "The development of Open-Domain Dialogue Systems (ODS)is a trending topic due to the large number of research challenges, large societal and business impact, and advances in the underlying technology. However, the development of these kinds of systems requires two important characteristics:1) automatic evaluation mechanisms that show high correlations with human judgements across multiple dialogue evaluation aspects (with explainable features for providing constructive and explicit feedback on the quality of generative models' responses for quick development and deployment)and 2) mechanisms that can help to control chatbot responses,while avoiding toxicity and employing intelligent ways to handle toxic user comments and keeping interaction flow and engagement. This track at the 10th Dialogue System Technology Challenge (DSTC10) is part of the ongoing effort to promote scalable and toxic-free ODS. This paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111574800",
                    "name": "Chen Zhang"
                },
                {
                    "authorId": "2319137716",
                    "name": "Jo\u00e3o Sedoc"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "8628d8b0ec02559c43947ff559c58eef79ffd47f",
            "title": "Joint Learning of Word and Label Embeddings for Sequence Labelling in Spoken Language Understanding",
            "abstract": "We propose an architecture to jointly learn word and label embeddings for slot filling in spoken language understanding. The proposed approach encodes labels using a combination of word embeddings and straightforward word-label association from the training data. Compared to the state-of-the-art methods, our approach does not require label embed-dings as part of the input and therefore lends itself nicely to a wide range of model architectures. In addition, our architecture computes contextual distances between words and labels to avoid adding contextual windows, thus reducing memory footprint. We validate the approach on established spoken dialogue datasets and show that it can achieve state-of-the-art performance with much fewer trainable parameters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39365627",
                    "name": "Jiewen Wu"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "2185019",
                    "name": "Nancy F. Chen"
                },
                {
                    "authorId": "33428484",
                    "name": "Pavitra Krishnaswamy"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                }
            ]
        },
        {
            "paperId": "35ca0e30ba5882b76eaa200dfb9f7cf697dc2ad8",
            "title": "NEWS 2018 Whitepaper",
            "abstract": "Transliteration is defined as phonetic translation of names across languages. Transliteration of Named Entities (NEs) is necessary in many applications, such as machine translation, corpus alignment, cross-language IR, information extraction and automatic lexicon acquisition. All such systems call for high-performance transliteration, which is the focus of shared task in the NEWS 2018 workshop. The objective of the shared task is to promote machine transliteration research by providing a common benchmarking platform for the community to evaluate the state-of-the-art technologies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185019",
                    "name": "Nancy F. Chen"
                },
                {
                    "authorId": "2109002",
                    "name": "Xiangyu Duan"
                },
                {
                    "authorId": "5432151",
                    "name": "Min Zhang"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1711271",
                    "name": "Haizhou Li"
                }
            ]
        },
        {
            "paperId": "51506274b8d193668fe9f1e9ffcf602f1ab583e9",
            "title": "Multi-Modal Robot Apprenticeship: Imitation Learning Using Linearly Decayed DMP+ in a Human-Robot Dialogue System",
            "abstract": "Robot learning by demonstration gives robots the ability to learn tasks which they have not been programmed to do before. The paradigm allows robots to work in a greater range of real-world applications in our daily life. However, this paradigm has traditionally been applied to learn tasks from a single demonstration modality. This restricts the approach to be scaled to learn and execute a series of tasks in a real-life environment. In this paper, we propose a multi-modal learning approach using DMP+ with linear decay integrated in a dialogue system with speech and ontology for the robot to learn seamlessly through natural interaction modalities (like an apprentice) while learning or re-learning is done on the fly to allow partial updates to a learned task to reduce potential user fatigue and operational downtime in teaching. The performance of new DMP+ with linear decay system is statistically benchmarked against state-of-the-art DMP implementations. A gluing demonstration is also conducted to show how the system provides seamless learning of multiple tasks in a flexible manufacturing set-up.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47096695",
                    "name": "Yan Wu"
                },
                {
                    "authorId": "3368222",
                    "name": "Ruohan Wang"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "98141158",
                    "name": "K. P. Tee"
                }
            ]
        },
        {
            "paperId": "5f1b926adf2a2943fe2139e922689ddb7128abf9",
            "title": "Attention-based Semantic Priming for Slot-filling",
            "abstract": "The problem of sequence labelling in language understanding would benefit from approaches inspired by semantic priming phenomena. We propose that an attention-based RNN architecture can be used to simulate semantic priming for sequence labelling. Specifically, we employ pre-trained word embeddings to characterize the semantic relationship between utterances and labels. We validate the approach using varying sizes of the ATIS and MEDIA datasets, and show up to 1.4-1.9% improvement in F1 score. The developed framework can enable more explainable and generalizable spoken language understanding systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39365627",
                    "name": "Jiewen Wu"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "33428484",
                    "name": "Pavitra Krishnaswamy"
                },
                {
                    "authorId": "2185019",
                    "name": "Nancy F. Chen"
                }
            ]
        },
        {
            "paperId": "6e9b26f1049566f6e1e31477e7de27e30ea3557a",
            "title": "Report of NEWS 2018 Named Entity Transliteration Shared Task",
            "abstract": "This report presents the results from the Named Entity Transliteration Shared Task conducted as part of The Seventh Named Entities Workshop (NEWS 2018) held at ACL 2018 in Melbourne, Australia. Similar to previous editions of NEWS, the Shared Task featured 19 tasks on proper name transliteration, including 13 different languages and two different Japanese scripts. A total of 6 teams from 8 different institutions participated in the evaluation, submitting 424 runs, involving different transliteration methodologies. Four performance metrics were used to report the evaluation results. The NEWS shared task on machine transliteration has successfully achieved its objectives by providing a common ground for the research community to conduct comparative evaluations of state-of-the-art technologies that will benefit the future research and development in this area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185019",
                    "name": "Nancy F. Chen"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "5432151",
                    "name": "Min Zhang"
                },
                {
                    "authorId": "2109002",
                    "name": "Xiangyu Duan"
                },
                {
                    "authorId": "1711271",
                    "name": "Haizhou Li"
                }
            ]
        },
        {
            "paperId": "11d00193f64586234fc28810cd326896ed7b0c7d",
            "title": "Punctuation prediction using a bidirectional recurrent neural network with part-of-speech tagging",
            "abstract": "Most automatic speech recognition (ASR) systems are incapable of generating punctuation, making it difficult to read the transcribed output and less appropriate for tasks such as dictation. This paper introduces a procedure to automatically insert punctuation into unpunctuated sentences by using a bidirectional recurrent neural network with attention mechanism and Part-of-Speech (POS) Tags. Using the WikiText Long Term Dependency Language Modelling Dataset and handling 11 different punctuation symbols, the model managed to achieve a punctuation error rate of 31.4% and an F1 score of 78.5%. When the system was trained on consecutive sentences and a smaller dataset using the Europarl v7 corpus, the model still managed to achieve a punctuation error rate of 48.1% and an F1 score of 64.7%. In both cases, our proposed system outperforms previous state-of-the-art systems trained on the same datasets, showing the advantage of using POS tags information and an encoderdecoder network.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1410923997",
                    "name": "Chin Char Juin"
                },
                {
                    "authorId": "2055788333",
                    "name": "Richard Xiong Jun Wei"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                }
            ]
        },
        {
            "paperId": "9caa4ba33b08fa401723646e9aab68d59ad776a8",
            "title": "Automatic labelling of touristic pictures using CNNs and metadata information",
            "abstract": "In this paper, we present a system that automatically recognizes pictures of landmarks in Singapore and combine the output with metadata information extracted from the picture if available in order to provide tourists with information about the recognized places. In detail, the system combines GPS information from the image metadata with a Convolutional Neural Network (CNN) based image recognition system to caption the image, where the GPS information is used to verify the caption given by the CNN, making the system more robust. For the training of the CNN, a total of \u223c67000 images were automatically downloaded from different search engines including Google, Flickr and Bing which were then filtered down to \u223c330 images per landmark to preserve the quality of the training dataset (e.g. removing repeated or confusing images), and then artificially augmented. After optimization, our CNN achieves a F1 score of 81% over a set of 6 different but very challenging locations, with each being a popular landmark in Singapore. With this combined system, the system can accurately tell the user where the image was taken and what the landmark in the image is. In addition, we created a database that provides background information for many landmarks (including, but not limited to the 6 landmarks used for training), such as their historic al or cultural significance. In order to make the system ac cessible and intuitive, it was integrated into a website where a Google Map is generated showing the results of the recognition and metadata information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1409239124",
                    "name": "Chan Kah Leong"
                },
                {
                    "authorId": "1414627485",
                    "name": "Lim Guan Mao Daven"
                },
                {
                    "authorId": "1409424493",
                    "name": "Neoh Tzeh Yuan"
                }
            ]
        },
        {
            "paperId": "a9c2a7ebb579ebfa11c63bd6c83c96453752d7c3",
            "title": "On the construction of more human-like chatbots: Affect and emotion analysis of movie dialogue data",
            "abstract": "Affect and emotion are inherent properties of human-human communication and interaction. Recent research interest in chatbots and conversational agents aims at making human-machine interaction more human-like in both behavioral and attitudinal terms. This paper intends to present some baby steps in this direction by analyzing a large dialogue dataset in terms of tonal, affective and emotional bias, with the objective of providing a valuable resource for developing and training datadriven conversational agents with discriminative power across such dimensions. Preliminary results of the conducted analysis demonstrate that only a relative small, although not negligible, percentage of the dialogue turns present clear orientation in any of the considered dimensions. Future research is still needed to determine whether this proportion is enough for biasing system responses in order to create different personality trends in conversational agents that are perceptible by humans when interacting with them.",
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                }
            ]
        }
    ]
}