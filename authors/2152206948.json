{
    "authorId": "2152206948",
    "papers": [
        {
            "paperId": "3a755f8dcc9af9304c2cbd3a00e42e66feec1d5d",
            "title": "Patton: Language Model Pretraining on Text-Rich Networks",
            "abstract": "A real-world text corpus sometimes comprises not only text documents, but also semantic links between them (e.g., academic papers in a bibliographic network are linked by citations and co-authorships).Text documents and semantic connections form a text-rich network, which empowers a wide range of downstream tasks such as classification and retrieval.However, pretraining methods for such structures are still lacking, making it difficult to build one generic model that can be adapted to various tasks on text-rich networks.Current pretraining objectives, such as masked language modeling, purely model texts and do not take inter-document structure information into consideration.To this end, we propose our PretrAining on TexT-Rich NetwOrk framework Patton.Patton includes two pretraining strategies: network-contextualized masked language modeling and masked node prediction, to capture the inherent dependency between textual attributes and network structure.We conduct experiments on four downstream tasks in five datasets from both academic and e-commerce domains, where Patton outperforms baselines significantly and consistently.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057050247",
                    "name": "Bowen Jin"
                },
                {
                    "authorId": "2204634891",
                    "name": "Wentao Zhang"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "e7dcdfb7734d59b97f825cce8b3105a2d9b14d10",
            "title": "The Effect of Metadata on Scientific Literature Tagging: A Cross-Field Cross-Model Study",
            "abstract": "Due to the exponential growth of scientific publications on the Web, there is a pressing need to tag each paper with fine-grained topics so that researchers can track their interested fields of study rather than drowning in the whole literature. Scientific literature tagging is beyond a pure multi-label text classification task because papers on the Web are prevalently accompanied by metadata information such as venues, authors, and references, which may serve as additional signals to infer relevant tags. Although there have been studies making use of metadata in academic paper classification, their focus is often restricted to one or two scientific fields (e.g., computer science and biomedicine) and to one specific model. In this work, we systematically study the effect of metadata on scientific literature tagging across 19 fields. We select three representative multi-label classifiers (i.e., a bag-of-words model, a sequence-based model, and a pre-trained language model) and explore their performance change in scientific literature tagging when metadata are fed to the classifiers as additional features. We observe some ubiquitous patterns of metadata\u2019s effects across all fields (e.g., venues are consistently beneficial to paper tagging in almost all cases), as well as some unique patterns in fields other than computer science and biomedicine, which are not explored in previous studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2057050247",
                    "name": "Bowen Jin"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "5445c21f471938a495ba7459fc8e3662d9a4b1eb",
            "title": "Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks",
            "abstract": "Representation learning on networks aims to derive a meaningful vector representation for each node, thereby facilitating downstream tasks such as link prediction, node classification, and node clustering. In heterogeneous text-rich networks, this task is more challenging due to (1) presence or absence of text: Some nodes are associated with rich textual information, while others are not; (2) diversity of types: Nodes and edges of multiple types form a heterogeneous network structure. As pretrained language models (PLMs) have demonstrated their effectiveness in obtaining widely generalizable text representations, a substantial amount of effort has been made to incorporate PLMs into representation learning on text-rich networks. However, few of them can jointly consider heterogeneous structure (network) information as well as rich textual semantic information of each node effectively. In this paper, we propose Heterformer, a Heterogeneous Network-Empowered Transformer that performs contextualized text encoding and heterogeneous structure encoding in a unified model. Specifically, we inject heterogeneous structure information into each Transformer layer when encoding node texts. Meanwhile, Heterformer is capable of characterizing node/edge type heterogeneity and encoding nodes with or without texts. We conduct comprehensive experiments on three tasks (i.e., link prediction, node classification, and node clustering) on three large-scale datasets from different domains, where Heterformer outperforms competitive baselines significantly and consistently. The code can be found at https://github.com/PeterGriffinJin/Heterformer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057050247",
                    "name": "Bowen Jin"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "2363de7a4282e405f337e8855463f906ba111ff9",
            "title": "Facet-Aware Evaluation for Extractive Text Summarization",
            "abstract": "Commonly adopted metrics for extractive text summarization like ROUGE focus on the lexical similarity and are facet-agnostic. In this paper, we present a facet-aware evaluation procedure for better assessment of the information coverage in extracted summaries while still supporting automatic evaluation once annotated. Speci\ufb01cally, we treat facet instead of token as the basic unit for evaluation, manually annotate the support sentences for each facet, and directly evaluate extractive methods by comparing the indices of extracted sentences with support sentences. We demonstrate the bene\ufb01ts of the proposed setup by performing a thorough quantitative investigation on the CNN/Daily Mail dataset, which in the mean-time reveals useful insights of state-of-the-art summarization methods. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3375249",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "4079cfe12460f3b77291e3f14a49198e0b322413",
            "title": "Facet-Aware Evaluation for Extractive Summarization",
            "abstract": "Commonly adopted metrics for extractive summarization focus on lexical overlap at the token level. In this paper, we present a facet-aware evaluation setup for better assessment of the information coverage in extracted summaries. Specifically, we treat each sentence in the reference summary as a facet, identify the sentences in the document that express the semantics of each facet as support sentences of the facet, and automatically evaluate extractive summarization methods by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary. To facilitate this new evaluation setup, we construct an extractive version of the CNN/Daily Mail dataset and perform a thorough quantitative investigation, through which we demonstrate that facet-aware evaluation manifests better correlation with human judgment than ROUGE, enables fine-grained evaluation as well as comparative analysis, and reveals valuable insights of state-of-the-art summarization methods. Data can be found at https://github.com/morningmoni/FAR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3375249",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "46458310",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "48c959d81e13612b0451583a45033e6cc93a23ed",
            "title": "Discovering Hypernymy in Text-Rich Heterogeneous Information Network by Exploiting Context Granularity",
            "abstract": "Text-rich heterogeneous information networks (text-rich HINs) are ubiquitous in real-world applications. Hypernymy, also known as is-a relation or subclass-of relation, lays in the core of many knowledge graphs and benefits many downstream applications. Existing methods of hypernymy discovery either leverage textual patterns to extract explicitly mentioned hypernym-hyponym pairs, or learn a distributional representation for each term of interest based its context. These approaches rely on statistical signals from the textual corpus, and their effectiveness would therefore be hindered when the signals from the corpus are not sufficient for all terms of interest. In this work, we propose to discover hypernymy in text-rich HINs, which can introduce additional high-quality signals. We develop a new framework, named HyperMine, that exploits multi-granular contexts and combines signals from both text and network without human labeled data. HyperMine extends the definition of \"context\" to the scenario of text-rich HIN. For example, we can define typed nodes and communities as contexts. These contexts encode signals of different granularities and we feed them into a hypernymy inference model. HyperMine learns this model using weak supervision acquired based on high-precision textual patterns. Extensive experiments on two large real-world datasets demonstrate the effectiveness of HyperMine and the utility of modeling context granularity. We further show a case study that a high-quality taxonomy can be generated solely based on the hypernymy discovered by HyperMine.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145814855",
                    "name": "Yu Shi"
                },
                {
                    "authorId": "3363642",
                    "name": "Jiaming Shen"
                },
                {
                    "authorId": "1823512389",
                    "name": "Yuchen Li"
                },
                {
                    "authorId": "2296885",
                    "name": "Naijing Zhang"
                },
                {
                    "authorId": "144603000",
                    "name": "Xinwei He"
                },
                {
                    "authorId": "2141805204",
                    "name": "Zhengzhi Lou"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2116449611",
                    "name": "Matthew Walker"
                },
                {
                    "authorId": "39345585",
                    "name": "Myunghwan Kim"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "e02b2751ec3e09d5066801ea19d019b24f26f6c5",
            "title": "Task-Guided Pair Embedding in Heterogeneous Network",
            "abstract": "Many real-world tasks solved by heterogeneous network embedding methods can be cast as modeling the likelihood of a pairwise relationship between two nodes. For example, the goal of author identification task is to model the likelihood of a paper being written by an author (paper-author pairwise relationship). Existing taskguided embedding methods are node-centric in that they simply measure the similarity between the node embeddings to compute the likelihood of a pairwise relationship between two nodes. However, we claim that for task-guided embeddings, it is crucial to focus on directly modeling the pairwise relationship. In this paper, we propose a novel task-guided pair embedding framework in heterogeneous network, called TaPEm, that directly models the relationship between a pair of nodes that are related to a specific task (e.g., paper-author relationship in author identification). To this end, we 1) propose to learn a pair embedding under the guidance of its associated context path, i.e., a sequence of nodes between the pair, and 2) devise the pair validity classifier to distinguish whether the pair is valid with respect to the specific task at hand. By introducing pair embeddings that capture the semantics behind the pairwise relationships, we are able to learn the fine-grained pairwise relationship between two nodes, which is paramount for task-guided embedding methods. Extensive experiments on author identification task demonstrate that TaPEm outperforms the state-of-the-art methods, especially for authors with few publication records.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109120259",
                    "name": "Chanyoung Park"
                },
                {
                    "authorId": "2145183039",
                    "name": "Donghyun Kim"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "1723357",
                    "name": "Hwanjo Yu"
                }
            ]
        },
        {
            "paperId": "3bc3ef2e0e693c30a458dad6ec2f827fba58d259",
            "title": "AspEm: Embedding Learning by Aspects in Heterogeneous Information Networks",
            "abstract": "Heterogeneous information networks (HINs) are ubiquitous in real-world applications. Due to the heterogeneity in HINs, the typed edges may not fully align with each other. In order to capture the semantic subtlety, we propose the concept of aspects with each aspect being a unit representing one underlying semantic facet. Meanwhile, network embedding has emerged as a powerful method for learning network representation, where the learned embedding can be used as features in various downstream applications. Therefore, we are motivated to propose a novel embedding learning framework-ASPEM-to preserve the semantic information in HINs based on multiple aspects. Instead of preserving information of the network in one semantic space, ASPEM encapsulates information regarding each aspect individually. In order to select aspects for embedding purpose, we further devise a solution for ASPEM based on dataset-wide statistics. To corroborate the efficacy of ASPEM, we conducted experiments on two real-words datasets with two types of applications-classification and link prediction. Experiment results demonstrate that ASPEM can outperform baseline network embedding learning methods by considering multiple aspects, where the aspects can be selected from the given HIN in an unsupervised manner.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "145814855",
                    "name": "Yu Shi"
                },
                {
                    "authorId": "2286096",
                    "name": "Huan Gui"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "a8aa8c562007c2ac1256bf3f6b7837580f6292f6",
            "title": "Open Information Extraction with Global Structure Constraints",
            "abstract": "Extracting entities and their relations from text is an important task for understanding massive text corpora. Open information extraction (IE) systems mine relation tuples (i.e., entity arguments and a predicate string to describe their relation) from sentences. However, current open IE systems ignore the fact that global statistics in a large corpus can be collectively leveraged to identify high-quality sentence-level extractions. In this paper, we propose a novel open IE system, called ReMine, which integrates local context signal and global structural signal in a unified framework with distant supervision. The new system can be efficiently applied to different domains as it uses facts from external knowledge bases as supervision; and can effectively score sentence-level tuple extractions based on corpus-level statistics. Specifically, we design a joint optimization problem to unify (1) segmenting entity/relation phrases in individual sentences based on local context; and (2) measuring the quality of sentence-level extractions with a translating-based objective. Experiments on real-world corpora from different domains demonstrate the effectiveness and robustness of ReMine when compared to other open IE systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2288429643",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2266006837",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2153637649",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2286653487",
                    "name": "Frank F. Xu"
                },
                {
                    "authorId": "2257136881",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "bb012bea9e71175299d6af2417b87c4047ae4984",
            "title": "Expert Finding in Heterogeneous Bibliographic Networks with Locally-trained Embeddings",
            "abstract": "Expert finding is an important task in both industry and academia. It is challenging to rank candidates with appropriate expertise for various queries. In addition, different types of objects interact with one another, which naturally forms heterogeneous information networks. We study the task of expert finding in heterogeneous bibliographical networks based on two aspects: textual content analysis and authority ranking. Regarding the textual content analysis, we propose a new method for query expansion via locally-trained embedding learning with concept hierarchy as guidance, which is particularly tailored for specific queries with narrow semantic meanings. Compared with global embedding learning, locally-trained embedding learning projects the terms into a latent semantic space constrained on relevant topics, therefore it preserves more precise and subtle information for specific queries. Considering the candidate ranking, the heterogeneous information network structure, while being largely ignored in the previous studies of expert finding, provides additional information. Specifically, different types of interactions among objects play different roles. We propose a ranking algorithm to estimate the authority of objects in the network, treating each strongly-typed edge type individually. To demonstrate the effectiveness of the proposed framework, we apply the proposed method to a large-scale bibliographical dataset with over two million entries and one million researcher candidates. The experiment results show that the proposed framework outperforms existing methods for both general and specific queries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2286096",
                    "name": "Huan Gui"
                },
                {
                    "authorId": "2152206948",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "2085709",
                    "name": "Aston Zhang"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                }
            ]
        }
    ]
}