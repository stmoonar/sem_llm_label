{
    "authorId": "2112481185",
    "papers": [
        {
            "paperId": "1e80802a2fef00f2e10dfd4ab0ecce18ee2af82b",
            "title": "Exploring the Potential of Large Language Models in Graph Generation",
            "abstract": "Large language models (LLMs) have achieved great success in many fields, and recent works have studied exploring LLMs for graph discriminative tasks such as node classification. However, the abilities of LLMs for graph generation remain unexplored in the literature. Graph generation requires the LLM to generate graphs with given properties, which has valuable real-world applications such as drug discovery, while tends to be more challenging. In this paper, we propose LLM4GraphGen to explore the ability of LLMs for graph generation with systematical task designs and extensive experiments. Specifically, we propose several tasks tailored with comprehensive experiments to address key questions regarding LLMs' understanding of different graph structure rules, their ability to capture structural type distributions, and their utilization of domain knowledge for property-based graph generation. Our evaluations demonstrate that LLMs, particularly GPT-4, exhibit preliminary abilities in graph generation tasks, including rule-based and distribution-based generation. We also observe that popular prompting methods, such as few-shot and chain-of-thought prompting, do not consistently enhance performance. Besides, LLMs show potential in generating molecules with specific properties. These findings may serve as foundations for designing good LLMs based models for graph generation and provide valuable insights and further research.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2292399289",
                    "name": "Xu Chu"
                },
                {
                    "authorId": "2292430960",
                    "name": "Yuekui Yang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "7448e270ccfab5a2b4838129f78136731c496ab6",
            "title": "Data-Augmented Curriculum Graph Neural Architecture Search under Distribution Shifts",
            "abstract": "Graph neural architecture search (NAS) has achieved great success in designing architectures for graph data processing.However, distribution shifts pose great challenges for graph NAS, since the optimal searched architectures for the training graph data may fail to generalize to the unseen test graph data. The sole prior work tackles this problem by customizing architectures for each graph instance through learning graph structural information, but failed to consider data augmentation during training, which has been proven by existing works to be able to improve generalization.In this paper, we propose Data-augmented Curriculum Graph Neural Architecture Search (DCGAS), which learns an architecture customizer with good generalizability to data under distribution shifts. Specifically, we design an embedding-guided data generator, which can generate sufficient graphs for training to help the model better capture graph structural information. In addition, we design a two-factor uncertainty-based curriculum weighting strategy, which can evaluate the importance of data in enabling the model to learn key information in real-world distribution and reweight them during training. Experimental results on synthetic datasets and real datasets with distribution shifts demonstrate that our proposed method learns generalizable mappings and outperforms existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "854b58d5126fd536e9e512069452370641e346a2",
            "title": "Causal-Aware Graph Neural Architecture Search under Distribution Shifts",
            "abstract": "Graph NAS has emerged as a promising approach for autonomously designing GNN architectures by leveraging the correlations between graphs and architectures. Existing methods fail to generalize under distribution shifts that are ubiquitous in real-world graph scenarios, mainly because the graph-architecture correlations they exploit might be spurious and varying across distributions. We propose to handle the distribution shifts in the graph architecture search process by discovering and exploiting the causal relationship between graphs and architectures to search for the optimal architectures that can generalize under distribution shifts. The problem remains unexplored with following challenges: how to discover the causal graph-architecture relationship that has stable predictive abilities across distributions, and how to handle distribution shifts with the discovered causal graph-architecture relationship to search the generalized graph architectures. To address these challenges, we propose Causal-aware Graph Neural Architecture Search (CARNAS), which is able to capture the causal graph-architecture relationship during the architecture search process and discover the generalized graph architecture under distribution shifts. Specifically, we propose Disentangled Causal Subgraph Identification to capture the causal subgraphs that have stable prediction abilities across distributions. Then, we propose Graph Embedding Intervention to intervene on causal subgraphs within the latent space, ensuring that these subgraphs encapsulate essential features for prediction while excluding non-causal elements. Additionally, we propose Invariant Architecture Customization to reinforce the causal invariant nature of the causal subgraphs, which are utilized to tailor generalized graph architectures. Extensive experiments demonstrate that CARNAS achieves advanced out-of-distribution generalization ability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260834123",
                    "name": "Peiwen Li"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2249121211",
                    "name": "Jialong Wang"
                },
                {
                    "authorId": "2298224490",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "b2e2e808181be431bcfeef57bd30cdf93dadfd30",
            "title": "Customized Cross-device Neural Architecture Search with Images",
            "abstract": "Cross-device scenarios have become increasingly common, where non-independently and identically distributed (non-IID) data is generated and stored in different devices. However, the existing cross-device NAS methods only search for a fixed architecture for different devices, neglecting that different devices have varying hardware characteristics and data distributions. In this paper, we propose a novel NAS framework that can customize the most suitable architecture for each device and its associated dataset. Specifically, we propose a decoupled data feature extractor and a device feature extractor to characterize the complex distributions of the different datasets and diverse hardware features. Then, we propose a prototype matcher to customize the operators and shape selection parameters of architectures. Experiments on ImageNet and CIFAR-10 show that our method can discover more efficient and effective architectures in cross-device scenarios than the existing approaches. To the best of our knowledge, this is the first exploration on customized cross-device NAS problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186253494",
                    "name": "Yang Yao"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                },
                {
                    "authorId": "2292410833",
                    "name": "Hong Mei"
                }
            ]
        },
        {
            "paperId": "0e87f4c721c2a5302e9cf7e2b3a6ceacfaceb469",
            "title": "LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?",
            "abstract": "In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs\u2019 capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs\u2019 competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs\u2019 spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts ( DST2 ) for LLMs on dynamic graphs to enhance LLMs\u2019 spatial-temporal understanding abilities. Our main observations are: 1) LLMs have prelim-inary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs\u2019 spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes will be open-sourced at publication time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2308044035",
                    "name": "Simin Wu"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "7a922abcda328f9333c5a3819ade8917b98f08c9",
            "title": "Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs",
            "abstract": "Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs such as citation networks, e-commerce networks and social networks has attracted considerable attention in the web community. Recently, large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks. However, the existing works focus on harnessing the potential of LLMs solely relying on prompts to convey graph structure information to LLMs, thus suffering from insufficient understanding of the complex structural relationships within TAGs. To address this problem, in this paper we present the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model incorporates graph structure information through tailored disentangled graph neural network (GNN) layers, enabling LLMs to capture the intricate relationships hidden in text-attributed graphs from multiple structural factors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing computational costs and allowing much more flexibility in combining with different LLM models. Experimental evaluations demonstrate the effectiveness of the proposed DGTL model on achieving superior or comparable performance over state-of-the-art baselines. Additionally, we also demonstrate that our DGTL model can offer natural language explanations for predictions, thereby significantly enhancing model interpretability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "8dd0869fd671682fa2d8e5f5f0ef14ecef04df0d",
            "title": "Dynamic Heterogeneous Graph Attention Neural Architecture Search",
            "abstract": "Dynamic heterogeneous graph neural networks (DHGNNs) have been shown to be effective in handling the ubiquitous dynamic heterogeneous graphs. However, the existing DHGNNs are hand-designed, requiring extensive human efforts and failing to adapt to diverse dynamic heterogeneous graph scenarios. In this paper, we propose to automate the design of DHGNN, which faces two major challenges: 1) how to design the search space to jointly consider the spatial-temporal dependencies and heterogeneous interactions in graphs; 2) how to design an efficient search algorithm in the potentially large and complex search space. To tackle these challenges, we propose a novel Dynamic Heterogeneous Graph Attention Search (DHGAS) method. Our proposed method can automatically discover the optimal DHGNN architecture and adapt to various dynamic heterogeneous graph scenarios without human guidance. In particular, we first propose a unified dynamic heterogeneous graph attention (DHGA) framework, which enables each node to jointly attend its heterogeneous and dynamic neighbors. Based on the framework, we design a localization space to determine where the attention should be applied and a parameterization space to determine how the attention should be parameterized. Lastly, we design a multi-stage differentiable search algorithm to efficiently explore the search space. Extensive experiments on real-world dynamic heterogeneous graph datasets demonstrate that our proposed method significantly outperforms state-of-the-art baselines for tasks including link prediction, node classification and node regression. To the best of our knowledge, DHGAS is the first dynamic heterogeneous graph neural architecture search method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2099587015",
                    "name": "Zhou Qin"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "a5cec58c2525b6f5b011d2170bf37a67b42d1fbb",
            "title": "Large Graph Models: A Perspective",
            "abstract": ".",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2118689973",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "2298094088",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "b4646815d5107489e7660d71e83c6584a926d280",
            "title": "Graph Meets LLMs: Towards Large Graph Models",
            "abstract": "Large models have emerged as the most recent groundbreaking achievements in artificial intelligence, and particularly machine learning. However, when it comes to graphs, large models have not achieved the same level of success as in other fields, such as natural language processing and computer vision. In order to promote applying large models for graphs forward, we present a perspective paper to discuss the challenges and opportunities associated with developing large graph models. First, we discuss the desired characteristics of large graph models. Then, we present detailed discussions from three key perspectives: representation basis, graph data, and graph models. In each category, we provide a brief overview of recent advances and highlight the remaining challenges together with our visions. Finally, we discuss valuable applications of large graph models. We believe this perspective can encourage further investigations into large graph models, ultimately pushing us one step closer towards artificial general intelligence (AGI). We are the first to comprehensively study large graph models, to the best of our knowledge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116460208",
                    "name": "Ziwei Zhang"
                },
                {
                    "authorId": "2145538097",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2118690469",
                    "name": "Zeyang Zhang"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "153316152",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "d11e6fd847bdeb1b76121dccc7ecdae8f8bffb13",
            "title": "Joint Data-Task Generation for Auxiliary Learning",
            "abstract": "Current auxiliary learning methods mainly adopt the methodology of reweighing losses for the manually collected auxiliary data and tasks. However, these methods heavily rely on domain knowledge during data collection, which may be hardly available in reality. Therefore, current methods will become less effective and even do harm to the primary task when unhelpful auxiliary data and tasks are employed. To tackle the problem, we propose a joint data-task generation framework for auxiliary learning (DTG-AuxL), which can bring benefits to the primary task by generating the new auxiliary data and task in a joint manner. The proposed DTG-AuxL framework contains a joint generator and a bi-level optimization strategy. Specifically, the joint generator contains a feature generator and a label generator, which are designed to be applicable and expressive for various auxiliary learning scenarios. The bi-level optimization strategy optimizes the joint generator and the task learning model, where the joint generator is effectively optimized in the upper level via the implicit gradient from the primary loss and the explicit gradient of our proposed instance regularization, while the task learning model is optimized in the lower level by the generated data and task. Extensive experiments show that our proposed DTG-AuxL framework consistently outperforms existing methods in various auxiliary learning scenarios, particularly when the manually collected auxiliary data and tasks are unhelpful.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191043236",
                    "name": "Hong Chen"
                },
                {
                    "authorId": "2153687490",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2261888564",
                    "name": "Yuwei Zhou"
                },
                {
                    "authorId": "2112481185",
                    "name": "Yi Qin"
                },
                {
                    "authorId": "133761917",
                    "name": "Chaoyu Guan"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        }
    ]
}