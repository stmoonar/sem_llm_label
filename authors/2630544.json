{
    "authorId": "2630544",
    "papers": [
        {
            "paperId": "0fe861147ea756d271d33121ac48519ea3a11811",
            "title": "Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework",
            "abstract": "With the proliferation of short video applications, the significance of short video recommendations has vastly increased. Unlike other recommendation scenarios, short video recommendation systems heavily rely on feedback from watch time. Existing approaches simply treat watch time as a direct label, failing to effectively harness its extensive semantics and introduce bias, thereby limiting the potential for modeling user interests based on watch time. To overcome this challenge, we propose a framework named Debiased Multiple-semantics-extracting Labeling (DML). DML constructs labels that encompass various semantics by utilizing quantiles derived from the distribution of watch time, prioritizing relative order rather than absolute label values. This approach facilitates easier model learning while aligning with the ranking objective of recommendations. Furthermore, we introduce a method inspired by causal adjustment to refine label definitions, thereby directly mitigating bias at the label level. We substantiate the effectiveness of our DML framework through both online and offline experiments. Extensive results demonstrate that our DML could effectively leverage watch time to discover users' real interests, enhancing their engagement in our application.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "1456009564",
                    "name": "Yimeng Bai"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2220987794",
                    "name": "Song Lu"
                },
                {
                    "authorId": "2115404510",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                }
            ]
        },
        {
            "paperId": "1b2740ab1d21afb2bb1176c50344cf428f213e2b",
            "title": "Understanding and Modeling Passive-Negative Feedback for Short-video Sequential Recommendation",
            "abstract": "Sequential recommendation is one of the most important tasks in recommender systems, which aims to recommend the next interacted item with historical behaviors as input. Traditional sequential recommendation always mainly considers the collected positive feedback such as click, purchase, etc. However, in short-video platforms such as TikTok, video viewing behavior may not always represent positive feedback. Specifically, the videos are played automatically, and users passively receive the recommended videos. In this new scenario, users passively express negative feedback by skipping over videos they do not like, which provides valuable information about their preferences. Different from the negative feedback studied in traditional recommender systems, this passive-negative feedback can reflect users\u2019 interests and serve as an important supervision signal in extracting users\u2019 preferences. Therefore, it is essential to carefully design and utilize it in this novel recommendation scenario. In this work, we first conduct analyses based on a large-scale real-world short-video behavior dataset and illustrate the significance of leveraging passive feedback. We then propose a novel method that deploys the sub-interest encoder, which incorporates positive feedback and passive-negative feedback as supervision signals to learn the user\u2019s current active sub-interest. Moreover, we introduce an adaptive fusion layer to integrate various sub-interests effectively. To enhance the robustness of our model, we then introduce a multi-task learning module to simultaneously optimize two kinds of feedback \u2013 passive-negative feedback and traditional randomly-sampled negative feedback. The experiments on two large-scale datasets verify that the proposed method can significantly outperform state-of-the-art approaches. The code is released at https://github.com/tsinghua-fib-lab/RecSys2023-SINE to benefit the community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111417074",
                    "name": "Yunzhu Pan"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "31687d5dd4d97b69a3143560729f00cdc76c4b7f",
            "title": "Inverse Learning with Extremely Sparse Feedback for Recommendation",
            "abstract": "Modern personalized recommendation services often rely on user feedback, either explicit or implicit, to improve the quality of services. Explicit feedback refers to behaviors like ratings, while implicit feedback refers to behaviors like user clicks. However, in the scenario of full-screen video viewing experiences like Tiktok and Reels, the click action is absent, resulting in unclear feedback from users, hence introducing noises in modeling training. Existing approaches on de-noising recommendation mainly focus on positive instances while ignoring the noise in a large amount of sampled negative feedback. In this paper, we propose a meta-learning method to annotate the unlabeled data from loss and gradient perspectives, which considers the noises in both positive and negative instances. Specifically, we first propose anInverse Dual Loss (IDL) to boost the true label learning and prevent the false label learning. Then we further propose anInverse Gradient (IG) method to explore the correct updating gradient and adjust the updating based on meta-learning. Finally, we conduct extensive experiments on both benchmark and industrial datasets where our proposed method can significantly improve AUC by 9.25% against state-of-the-art methods. Further analysis verifies the proposed inverse learning framework is model-agnostic and can improve a variety of recommendation backbones. The source code, along with the best hyper-parameter settings, is available at this link: https://github.com/Guanyu-Lin/InverseLearning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257446689",
                    "name": "Guanyu Lin"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "118961885",
                    "name": "Y. Zheng"
                },
                {
                    "authorId": "2129445960",
                    "name": "Yinfeng Li"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2266777606",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2266467527",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "2257351656",
                    "name": "Zhiheng Li"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "7fcc1c7bc9d1f763022b7a46eb916d2d6c36af36",
            "title": "Mixed Attention Network for Cross-domain Sequential Recommendation",
            "abstract": "In modern recommender systems, sequential recommendation leverages chronological user behaviors to make effective next-item suggestions, which suffers from data sparsity issues, especially for new users. One promising line of work is the cross-domain recommendation, which trains models with data across multiple domains to improve the performance in data-scarce domains. Recent proposed cross-domain sequential recommendation models such as PiNet and DASL have a common drawback relying heavily on overlapped users in different domains, which limits their usage in practical recommender systems. In this paper, we propose a M ixed A ttention N etwork (MAN) with local and global attention modules to extract the domain-specific and cross-domain information. Firstly, we propose a local/global encoding layer to capture the domain-specific/cross-domain sequential pattern. Then we propose a mixed attention layer with item similarity attention, sequence-fusion attention, and group-prototype attention to capture the local/global item similarity, fuse the local/global item sequence, and extract the user groups across different domains, respectively. Finally, we propose a local/global prediction layer to further evolve and combine the domain-specific and cross-domain interests. Experimental results on two real-world datasets (each with two domains) demonstrate the superiority of our proposed model. Further study also illustrates that our proposed method and components are model-agnostic and effective, respectively. The code and data are available at https://github.com/Guanyu-Lin/MAN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257446689",
                    "name": "Guanyu Lin"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "118961885",
                    "name": "Y. Zheng"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2266777606",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2266467527",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "2257351656",
                    "name": "Zhiheng Li"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                },
                {
                    "authorId": "2284377864",
                    "name": "Meng Wang"
                }
            ]
        },
        {
            "paperId": "926157ec82a606939b1535cd52b1fb9a69643833",
            "title": "LabelCraft: Empowering Short Video Recommendations with Automated Label Crafting",
            "abstract": "Short video recommendations often face limitations due to the quality of user feedback, which may not accurately depict user interests. To tackle this challenge, a new task has emerged: generating more dependable labels from original feedback. Existing label generation methods rely on manual rules, demanding substantial human effort and potentially misaligning with the desired objectives of the platform. To transcend these constraints, we introduce LabelCraft, a novel automated label generation method explicitly optimizing pivotal operational metrics for platform success. By formulating label generation as a higher-level optimization problem above recommender model optimization, LabelCraft introduces a trainable labeling model for automatic label mechanism modeling. Through meta-learning techniques, LabelCraft effectively addresses the bi-level optimization hurdle posed by the recommender and labeling models, enabling the automatic acquisition of intricate label generation mechanisms. Extensive experiments on real-world datasets corroborate LabelCraft's excellence across varied operational metrics, encompassing usage time, user engagement, and retention. Codes are available at https://github.com/baiyimeng/LabelCraft.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275528388",
                    "name": "Yimeng Bai"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2275773462",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2266777606",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                }
            ]
        },
        {
            "paperId": "985a47671c30e2d059c568ba8eb8e2813bab9423",
            "title": "Bundle Recommendation and Generation With Graph Neural Networks",
            "abstract": "Bundle recommendation aims to recommend a bundle of items for a user to consume as a whole. Related work can be divided into two categories: 1) to recommend the platform's prebuilt bundles to users; 2) generate personalized bundles for users. In this work, we propose two graph neural network models, a BGCN model (short for <italic/><italic>Bundle</italic> <italic>Graph</italic> <italic>Convolutional</italic> <italic>Network</italic>) for prebuilt bundle recommendation, and a BGGN model (short for <italic/><italic>Bundle</italic> <italic>Graph</italic> <italic>Generation</italic> <italic>Network</italic>) for personalized bundle generation. First, BGCN unifies the user-item interaction, the user-bundle interaction and the bundle-item affiliation into a heterogeneous graph. With item nodes as the bridge, graph convolutional propagation between user and bundle nodes makes the learned representations capture the item-level semantics. Second, BGGN re-constructs bundles into graphs based on the item co-occurrence pattern and the user's supervision signal. The complex and high-order item-item relationships in the bundle graph are explicitly modeled through graph generation. Empirical results demonstrate the substantial performance gains of BGCN and BGGN, which outperforms the state-of-the-art baselines by 10.77% to 23.18% and 20.90% to 64.52%, respectively. We have released the datasets and codes at this link: <uri>https://github.com/cjx0525/BGCN</uri>.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "39948674",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "a33c6bd9bcdc3b99b5fec66edea6bd334163cc74",
            "title": "Dual-interest Factorization-heads Attention for Sequential Recommendation",
            "abstract": "Accurate user interest modeling is vital for recommendation scenarios. One of the effective solutions is the sequential recommendation that relies on click behaviors, but this is not elegant in the video feed recommendation where users are passive in receiving the streaming contents and return skip or no-skip behaviors. Here skip and no-skip behaviors can be treated as negative and positive feedback, respectively. With the mixture of positive and negative feedback, it is challenging to capture the transition pattern of behavioral sequence. To do so, FeedRec has exploited a shared vanilla Transformer, which may be inelegant because head interaction of multi-heads attention does not consider different types of feedback. In this paper, we propose Dual-interest Factorization-heads Attention for Sequential Recommendation (short for DFAR) consisting of feedback-aware encoding layer, dual-interest disentangling layer and prediction layer. In the feedback-aware encoding layer, we first suppose each head of multi-heads attention can capture specific feedback relations. Then we further propose factorization-heads attention which can mask specific head interaction and inject feedback information so as to factorize the relation between different types of feedback. Additionally, we propose a dual-interest disentangling layer to decouple positive and negative interests before performing disentanglement on their representations. Finally, we evolve the positive and negative interests by corresponding towers whose outputs are contrastive by BPR loss. Experiments on two real-world datasets show the superiority of our proposed method against state-of-the-art baselines. Further ablation study and visualization also sustain its effectiveness. We release the source code here: https://github.com/tsinghua-fib-lab/WWW2023-DFAR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9277993",
                    "name": "Guanyu Lin"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "118961885",
                    "name": "Y. Zheng"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": null,
                    "name": "Zhiheng Li"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "a6d06a4503b15604f51132c771cf8ea8cfdd244c",
            "title": "PEPNet: Parameter and Embedding Personalized Network for Infusing with Personalized Prior Information",
            "abstract": "With the increase of content pages and interactive buttons in online services such as online-shopping and video-watching websites, industrial-scale recommender systems face challenges in multi-domain and multi-task recommendations. The core of multi-task and multi-domain recommendation is to accurately capture user interests in multiple scenarios given multiple user behaviors. In this paper, we propose a plug-and-play Parameter and Embedding Personalized Network (PEPNet) for multi-domain and multi-task recommendation. PEPNet takes personalized prior information as input and dynamically scales the bottom-level Embedding and top-level DNN hidden units through gate mechanisms. Embedding Personalized Network (EPNet) performs personalized selection on Embedding to fuse features with different importance for different users in multiple domains. Parameter Personalized Network (PPNet) executes personalized modification on DNN parameters to balance targets with different sparsity for different users in multiple tasks. We have made a series of special engineering optimizations combining the Kuaishou training framework and the online deployment environment. By infusing personalized selection of Embedding and personalized modification of DNN parameters, PEPNet tailored to the interests of each individual obtains significant performance gains, with online improvements exceeding 1% in multiple task metrics across multiple domains. We have deployed PEPNet in Kuaishou apps, serving over 300 million users every day.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2125752970",
                    "name": "Chenbin Zhang"
                },
                {
                    "authorId": "2115330531",
                    "name": "Yiqun Hui"
                },
                {
                    "authorId": "2203912362",
                    "name": "Dewei Leng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "d12dbe90e767b299de644de41ae47a5733634e58",
            "title": "TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou",
            "abstract": "Life-long user behavior modeling, i.e., extracting a user's hidden interests from rich historical behaviors in months or even years, plays a central role in modern CTR prediction systems. Conventional algorithms mostly follow two cascading stages: a simple General Search Unit (GSU) for fast and coarse search over tens of thousands of long-term behaviors and an Exact Search Unit (ESU) for effective Target Attention (TA) over the small number of finalists from GSU. Although efficient, existing algorithms mostly suffer from a crucial limitation: the inconsistent target-behavior relevance metrics between GSU and ESU. As a result, their GSU usually misses highly relevant behaviors but retrieves ones considered irrelevant by ESU. In such case, the TA in ESU, no matter how attention is allocated, mostly deviates from the real user interests and thus degrades the overall CTR prediction accuracy. To address such inconsistency, we propose TWo-stage Interest Network (TWIN), where our Consistency-Preserved GSU (CP-GSU) adopts the identical target-behavior relevance metric as the TA in ESU, making the two stages twins. Specifically, to break TA's computational bottleneck and extend it from ESU to GSU, or namely from behavior length 102 to length 104 - 105, we build a novel attention mechanism by behavior feature splitting. For the video inherent features of a behavior, we calculate their linear projection by efficient pre-computing & caching strategies. And for the user-item cross features, we compress each into a one-dimentional bias term in the attention score calculation to save the computational cost. The consistency between two stages, together with the effective TA-based relevance metric in CP-GSU, contributes to significant performance gain in CTR prediction. Offline experiments on a 46 billion scale real production dataset from Kuaishou and an Online A/B test show that TWIN outperforms all compared SOTA algorithms. With optimized online infrastructure, we reduce the computational bottleneck by 99.3%, which contributes to the successful deployment of TWIN on Kuaishou, serving the main traffic of hundreds of millions of active users everyday.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2125752970",
                    "name": "Chenbin Zhang"
                },
                {
                    "authorId": "2068057294",
                    "name": "Zhiyi Fu"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2203437528",
                    "name": "Lin Guan"
                },
                {
                    "authorId": "2115404510",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2115330531",
                    "name": "Yiqun Hui"
                },
                {
                    "authorId": "2203912362",
                    "name": "Dewei Leng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "e3040d27f357295baee058a54829427488dfee94",
            "title": "Learning and Optimization of Implicit Negative Feedback for Industrial Short-video Recommender System",
            "abstract": "Short-video recommendation is one of the most important recommendation applications in today's industrial information systems. Compared with other recommendation tasks, the enormous amount of feedback is the most typical characteristic. Specifically, in short-video recommendation, the easiest-to-collect user feedback is theskipping behavior, which leads to two critical challenges for the recommendation model. First, the skipping behavior reflects implicit user preferences, and thus, it is challenging for interest extraction. Second, this kind of special feedback involves multiple objectives, such as total watching time and skipping rate, which is also very challenging. In this paper, we present our industrial solution in Kuaishou1, which serves billion-level users every day. Specifically, we deploy a feedback-aware encoding module that extracts user preferences, taking the impact of context into consideration. We further design a multi-objective prediction module which well distinguishes the relation and differences among different model objectives in the short-video recommendation. We conduct extensive online A/B tests, along with detailed and careful analysis, which verify the effectiveness of our solution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111417074",
                    "name": "Yunzhu Pan"
                },
                {
                    "authorId": "2155792599",
                    "name": "Nian Li"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        }
    ]
}