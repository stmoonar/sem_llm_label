{
    "authorId": "2144163813",
    "papers": [
        {
            "paperId": "754afd60e4b1c81cf69e55da4c22022e3fa850b7",
            "title": "Active Explainable Recommendation with Limited Labeling Budgets",
            "abstract": "Explainable recommendation has gained significant attention due to its potential to enhance user trust and system transparency. Previous studies primarily focus on refining model architectures to generate more informative explanations, assuming that the explanation data is sufficient and easy to acquire. However, in practice, obtaining the ground truth for explanations can be costly since individuals may not be inclined to put additional efforts to provide behavior explanations. In this paper, we study a novel problem in the field of explainable recommendation, that is, \u201cgiven a limited budget to incentivize users to provide behavior explanations, how to effectively collect data such that the downstream models can be better optimized?\u201d To solve this problem, we propose an active learning framework for recommender system, which consists of an acquisition function for sample collection and an explainable recommendation model to provide the final results. We consider both uncertainty and influence based strategies to design the acquisition function, which can determine the sample effectiveness from complementary perspectives. To demonstrate the effectiveness of our framework, we conduct extensive experiments based on real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2226446789",
                    "name": "Xiaohe Bo"
                },
                {
                    "authorId": "2292647139",
                    "name": "Chenxi Wang"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "2276747916",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2258445639",
                    "name": "Xu Chen"
                }
            ]
        },
        {
            "paperId": "4d9febdaa93eee8329abed610bf79cba00dc5111",
            "title": "RecAgent: A Novel Simulation Paradigm for Recommender Systems",
            "abstract": "Recommender system has deeply revolutionized people\u2019s daily life and production, bringing a large amount of business value. In the recommendation domain, simulation and real data-based studies are two typical research paradigms, with each having different advantages. Previously, real data-based studies occupy more important positions, since accurately simulating the user preference is quite difficult. Recently, large language models (LLM) have shown great potential to achieve human-like intelligence, which provides new opportunities to overcome the short-comings of simulation-based studies and thus highlight their advantages, such as much more application scenarios and cheaper data acquisition strategies. To shed lights on this direction, in this paper, we introduce an LLM-based recommender simulator called RecAgent. Our simulator is composed of two modules: (1) the user module and (2) the recommender module. The user module can browse the recommendation website, communicate with other users and broadcast messages on the social media. The recommender module is designed to provide search or recommendation lists to the users, and one can design different models to implement the recommender. All the users take actions based on LLMs, and can freely evolve like in the real world. We present several case studies to demonstrate that the users in our simulator can indeed behave in a reasonable manner as expected. Our project has been released at https://github.com/RUC-GSAI/YuLan-Rec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152509786",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2144230136",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2257310922",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "2257175080",
                    "name": "Ruihua Song"
                },
                {
                    "authorId": "2257376413",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "59ef0dbab49b10fec4cb8cca84436d618618852b",
            "title": "Recommendation with Causality enhanced Natural Language Explanations",
            "abstract": "Explainable recommendation has recently attracted increasing attention from both academic and industry communities. Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. Despite the effectiveness, existing models are mostly optimized based on the observed datasets, which can be skewed due to the selection or exposure bias. To alleviate this problem, in this paper, we formulate the task of explainable recommendation with a causal graph, and design a causality enhanced framework to generate unbiased explanations. More specifically, we firstly define an ideal unbiased learning objective, and then derive a tractable loss for the observational data based on the inverse propensity score (IPS), where the key is a sample re-weighting strategy for equalizing the loss and ideal objective in expectation. Considering that the IPS estimated from the sparse and noisy recommendation datasets can be inaccurate, we introduce a fault tolerant mechanism by minimizing the maximum loss induced by the sample weights near the IPS. For more comprehensive modeling, we further analyze and infer the potential latent confounders induced by the complex and diverse user personalities. We conduct extensive experiments by comparing with the state-of-the-art methods based on three real-world datasets to demonstrate the effectiveness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2144230136",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "144010962",
                    "name": "Jiakai Tang"
                },
                {
                    "authorId": "2143609496",
                    "name": "Weiqi Shao"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2163112250",
                    "name": "Rui Zhang"
                }
            ]
        },
        {
            "paperId": "6751d850fff87d02127bb58de1ad899fb1b40f86",
            "title": "When Fairness meets Bias: a Debiased Framework for Fairness aware Top-N Recommendation",
            "abstract": "Fairness in the recommendation domain has recently attracted increasing attention due to more and more concerns about the algorithm discrimination and ethics. While recent years have witnessed many promising fairness aware recommender models, an important problem has been largely ignored, that is, the fairness can be biased due to the user personalized selection tendencies or the non-uniform item exposure probabilities. To study this problem, in this paper, we formally define a novel task named as unbiased fairness aware Top-N recommendation. For solving this task, we firstly define an ideal loss function based on all the user-item pairs. Considering that, in real-world datasets, only a small number of user-item interactions can be observed, we then approximate the above ideal loss with a more tractable objective based on the inverse propensity score (IPS). Since the recommendation datasets can be noisy and quite sparse, which brings difficulties for accurately estimating the IPS, we propose to optimize the objective in an IPS range instead of a specific point, which improves the model fault tolerance capability. In order to make our model more applicable to the commonly studied Top-N recommendation, we soften the ranking metrics such as Precision, Hit-Ratio, and NDCG to derive a fully differentiable framework. We conduct extensive experiments to demonstrate the effectiveness of our model based on four real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144010962",
                    "name": "Jiakai Tang"
                },
                {
                    "authorId": "2241038698",
                    "name": "Shiqi Shen"
                },
                {
                    "authorId": "2163673454",
                    "name": "Zhipeng Wang"
                },
                {
                    "authorId": "2240547021",
                    "name": "Zhi Gong"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2240719271",
                    "name": "Xu Chen"
                }
            ]
        },
        {
            "paperId": "729d4e0db88583d1add8681a34b28d1b1e84eb5d",
            "title": "User Behavior Simulation with Large Language Model based Agents",
            "abstract": "Simulating high quality user behavior data has always been a fundamental problem in human-centered applications, where the major difficulty originates from the intricate mechanism of human decision process. Recently, substantial evidences have suggested that by learning huge amounts of web knowledge, large language models (LLMs) can achieve human-like intelligence. We believe these models can provide significant opportunities to more believable user behavior simulation. To inspire such direction, we propose an LLM-based agent framework and design a sandbox environment to simulate real user behaviors. Based on extensive experiments, we find that the simulated behaviors of our method are very close to the ones of real humans. Concerning potential applications, we simulate and study two social phenomenons including (1) information cocoons and (2) user conformity behaviors. This research provides novel simulation paradigms for human-centered applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152509786",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2257352534",
                    "name": "Hao Yang"
                },
                {
                    "authorId": "2241452075",
                    "name": "Zhiyuan Chen"
                },
                {
                    "authorId": "144010962",
                    "name": "Jiakai Tang"
                },
                {
                    "authorId": "2223760889",
                    "name": "Zeyu Zhang"
                },
                {
                    "authorId": "2144230136",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "35119829",
                    "name": "Ruihua Song"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2241424564",
                    "name": "Jun Xu"
                },
                {
                    "authorId": "1897235",
                    "name": "Zhicheng Dou"
                },
                {
                    "authorId": "2241311153",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "89d7e534faceb84ce76eba18727f2a6a6e95af8b",
            "title": "Recommendation with Dynamic Natural Language Explanations",
            "abstract": "Explaining recommendation with natural languages has shown to be an effective strategy to improve the recommendation pervasiveness and user satisfaction. While recent years have witnessed many promising models, they mostly consider the user-item interactions as independent samples. However, in real-world scenarios, the user preference is always dynamic and evolving, and the current user behaviors may have strong correlations with the previous ones. To bridge this gap, in this paper, we propose to build an explainable recommender model by considering the user dynamic preference. Our general idea is to build a sequential model to capture the user history behaviors, and then the explanations are generated by summarizing all the past interactions. In specific, we firstly deploy two independent components to model the user sequential interactions and reviews separately. Then, we design a duration-aware attention mechanism to discriminate the importance of different items and reviews. For more effectively modeling the history information, we introduce a denoising module to remove the user behaviors which are less important for the current prediction. We conduct extensive experiments to demonstrate the effectiveness of our model based on three real-world datasets, in which the best performance can be improved by about 13.3%, 6.5%, 5.0% and 1.9% on the metrics of BLEU-1, ROUGE-1, ROUGE-2 and MAE, respectively. In addition, we also evaluate the generated explanations from both qualitative and qualitative perspectives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2226690977",
                    "name": "Xi Li"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2226446789",
                    "name": "Xiaohe Bo"
                },
                {
                    "authorId": "2152509786",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "2144230136",
                    "name": "Xu Chen"
                }
            ]
        },
        {
            "paperId": "8a833a5625951a86f13123e972fbee54957cc6ec",
            "title": "REASONER: An Explainable Recommendation Dataset with Multi-aspect Real User Labeled Ground Truths Towards more Measurable Explainable Recommendation",
            "abstract": "Explainable recommendation has attracted much attention from the industry and academic communities. It has shown great potential for improving the recommendation persuasiveness, informativeness and user satisfaction. Despite a lot of promising explainable recommender models have been proposed in the past few years, the evaluation strategies of these models suffer from several limitations. For example, the explanation ground truths are not labeled by real users, the explanations are mostly evaluated based on only one aspect and the evaluation strategies can be hard to unify. To alleviate the above problems, we propose to build an explainable recommendation dataset with multi-aspect real user labeled ground truths. In specific, we firstly develop a video recommendation platform, where a series of questions around the recommendation explainability are carefully designed. Then, we recruit about 3000 users with different backgrounds to use the system, and collect their behaviors and feedback to our questions. In this paper, we detail the construction process of our dataset and also provide extensive analysis on its characteristics. In addition, we develop a library, where ten well-known explainable recommender models are implemented in a unified framework. Based on this library, we build several benchmarks for different explainable recommendation tasks. At last, we present many new opportunities brought by our dataset, which are expected to shed some new lights to the explainable recommendation field. Our dataset, library and the related documents have been released at https://reasoner2023.github.io/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144230136",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2152507359",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2163112250",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "91908628",
                    "name": "Li Chen"
                },
                {
                    "authorId": "2113341875",
                    "name": "Jingxuan Wen"
                }
            ]
        },
        {
            "paperId": "8ed52e4cb13b7b36509573efa65aaa0cd8bc59cc",
            "title": "REASONER: An Explainable Recommendation Dataset with Comprehensive Labeling Ground Truths",
            "abstract": "Explainable recommendation has attracted much attention from the industry and academic communities. It has shown great potential to improve the recommendation persuasiveness, informativeness and user satisfaction. In the past few years, while a lot of promising explainable recommender models have been proposed, the datasets used to evaluate them still suffer from several limitations, for example, the explanation ground truths are not labeled by the real users, the explanations are mostly single-modal and around only one aspect. To bridge these gaps, in this paper, we build a new explainable recommendation dataset, which, to our knowledge, is the \ufb01rst contribution that provides a large amount of real user labeled multi-modal and multi-aspect explanation ground truths. In speci\ufb01c, we \ufb01rstly develop a video recommendation platform, where a series of questions around the recommendation explainability are carefully designed. Then, we recruit about 3000 high-quality labelers with different backgrounds to use the system, and collect their behaviors and feedback to our questions. In this paper, we detail the construction process of our dataset and also provide extensive analysis on its characteristics. In addition, we develop a library, where many well-known explainable recommender models are implemented in a uni\ufb01ed framework. Based on this library, we build several benchmarks for different explainable recommendation tasks. At last, we present many new opportunities brought by our dataset, which are expected to promote the \ufb01eld of explainable recommendation. Our dataset, library and the related documents have been released at https://reasoner2023.github.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258445639",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "2152509786",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "2276747916",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2163112250",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "2287762610",
                    "name": "Li Chen"
                },
                {
                    "authorId": "2288043051",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "2287918455",
                    "name": "Ji-Rong Wen"
                }
            ]
        },
        {
            "paperId": "e726b4a72da8ecddc0d3f3f8d32bf2d43b129fb1",
            "title": "Data Augmented Sequential Recommendation Based on Counterfactual Thinking",
            "abstract": "Sequential recommendation has recently attracted increasing attention from the industry and academic communities. While previous models have achieved remarkable successes, an important problem may still hinder their performances, that is, the sparsity of the real-world data. In this paper, we propose a novel counterfactual data augmentation framework to alleviate the problem of data sparsity. In specific, our framework contains a sampler model and an anchor model. The sampler model aims to generate high-quality user behavior sequences, while the anchor model is trained based on the original and new generated samples, and leveraged to provide the final recommendation list. To implement the sampler model, we first design four types of heuristic methods based on either random or frequency-based strategies. And then, to improve the quality of the generated sequences, we propose two learning-based samplers by discovering the decision boundaries or increasing the sample informativeness. At last, we build an RL based model to automatically determine where to edit the history behaviors and how many items should be replaced. Considering that the sampler model can be imperfect, we, at last, analyze the influence of the noisy information contained in the generated sequences on the anchor model in theory, and design a simple but effective method to better serve the anchor model. We conduct extensive experiments to demonstrate the effectiveness of our model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1734206",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2108231435",
                    "name": "Zhenlei Wang"
                },
                {
                    "authorId": "2146235527",
                    "name": "Hongteng Xu"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "02c7fe8bbae8257305089f6ca9c7ca40bf454f20",
            "title": "RecBole 2.0: Towards a More Up-to-Date Recommendation Library",
            "abstract": "In order to support the study of recent advances in recommender systems, this paper presents an extended recommendation library consisting of eight packages for up-to-date topics and architectures. First of all, from a data perspective, we consider three important topics related to data issues (ie sparsity, bias and distribution shift ), and develop five packages accordingly, including meta-learning, data augmentation, debiasing, fairness and cross-domain recommendation. Furthermore, from a model perspective, we develop two benchmarking packages for Transformer-based and graph neural network~(GNN)-based models, respectively. All the packages (consisting of 65 new models) are developed based on a popular recommendation framework RecBole, ensuring that both the implementation and interface are unified. For each package, we provide complete implementations from data loading, experimental setup, evaluation and algorithm implementation. This library provides a valuable resource to facilitate the up-to-date research in recommender systems. The project is released at the link: \\urlhttps://github.com/RUCAIBox/RecBole2.0.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "151472453",
                    "name": "Yupeng Hou"
                },
                {
                    "authorId": "1471329930",
                    "name": "Xingyu Pan"
                },
                {
                    "authorId": "2154171210",
                    "name": "Chen Yang"
                },
                {
                    "authorId": "2155279878",
                    "name": "Zeyu Zhang"
                },
                {
                    "authorId": "2112304962",
                    "name": "Zihan Lin"
                },
                {
                    "authorId": "2144163813",
                    "name": "Jingsen Zhang"
                },
                {
                    "authorId": "40901446",
                    "name": "Shuqing Bian"
                },
                {
                    "authorId": "144010962",
                    "name": "Jiakai Tang"
                },
                {
                    "authorId": "2111845105",
                    "name": "Wenqi Sun"
                },
                {
                    "authorId": "2109315001",
                    "name": "Yushuo Chen"
                },
                {
                    "authorId": "2167464968",
                    "name": "Lanling Xu"
                },
                {
                    "authorId": "2404181",
                    "name": "Gaowei Zhang"
                },
                {
                    "authorId": "2152251597",
                    "name": "Zhen Tian"
                },
                {
                    "authorId": "2072927117",
                    "name": "Changxin Tian"
                },
                {
                    "authorId": "51396195",
                    "name": "Shanlei Mu"
                },
                {
                    "authorId": "46515856",
                    "name": "Xinyan Fan"
                },
                {
                    "authorId": "1734206",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "2113341875",
                    "name": "Jingxuan Wen"
                }
            ]
        }
    ]
}