{
    "authorId": "1770962",
    "papers": [
        {
            "paperId": "2185ee8fad1b6df98d9214b95b1c693ff32b4376",
            "title": "Personal Manifold: Management of Personal Data in the Age of Large Language Models",
            "abstract": "The recent progress on large language models and their conversational capabilities have rekindled interest in building personal digital assistants that will help us with daily tasks, such as recommending to us which items to purchase, what content to consume, what to eat, and even how to spend our time in the most meaningful way. The recommendations these assistants will provide us will be hyper-personalized, based on detailed knowledge of our past, our preferences, our goals and our current context. Realizing this vision raises novel data management challenges. Today's language models, though they display unprecedented reasoning capabilities, do not have the ability to reliably store data they are presented with and to retrieve it when needed. This paper describes the visionary PERSONAL MANIFOLD system that supports a personal agent based on LLMs, tackles some of the associated data management challenges, and exposes others. PERSONAL MANIFOLD offers an LLM-based interface to the tools they use to manage their personal information. Users interact with PERSONAL MANIFOLD by making notes (or journal entries) and asking for recommendations. In either case, the relevant data from the interaction is also added to the relevant tool (e.g., calendar or to-do list) so it becomes actionable. One of the key aspects of PERSONAL MANIFOLD is the user's timeline, which describes the set of experiences they've had and their plans for the future. The personal timeline is constructed based on digital data that they create in the process of using other applications. The personal timeline can then be mined to extract the user's preferences and their habits, which are then used to power personalized recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2265720997",
                    "name": "Yuliang Li"
                },
                {
                    "authorId": "2313954975",
                    "name": "Wang Chiew Tan"
                }
            ]
        },
        {
            "paperId": "56ace0d9ce5eccf2dfa33d09bd39206b3cfe6ef4",
            "title": "DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study",
            "abstract": "Elicitation diary studies, a type of qualitative, longitudinal research method, involve participants to self-report aspects of events of interest at their occurrences as memory cues for providing details and insights during post-study interviews. However, due to time constraints and lack of motivation, participants\u2019 diary entries may be vague or incomplete, impairing their later recall. To address this challenge, we designed an automatic contextual information recording agent, DiaryHelper, based on the theory of episodic memory. DiaryHelper can predict five dimensions of contextual information and confirm with participants. We evaluated the use of DiaryHelper in both the recording period and the elicitation interview through a within-subject study (N=12) over a period of two weeks. Our results demonstrated that DiaryHelper can assist participants in capturing abundant and accurate contextual information without significant burden, leading to a more detailed recall of recorded events and providing greater insights.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2299106618",
                    "name": "Junze Li"
                },
                {
                    "authorId": "2052592415",
                    "name": "Changyang He"
                },
                {
                    "authorId": "2299184700",
                    "name": "Jiaxiong Hu"
                },
                {
                    "authorId": "2298965898",
                    "name": "Boyang Jia"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2201416366",
                    "name": "Xiaojuan Ma"
                }
            ]
        },
        {
            "paperId": "02dd9ca2145393ac1865dd7c026970a460fafb49",
            "title": "Personal Data for Personal Use: Vision or Reality?",
            "abstract": "The vision of collecting all of one's personal information into one searchable database has been around at least since Vannevar Bush's 1945 paper on the Memex System [2]. In the late 1990's, Gordon Bell and his colleagues at Microsoft Research built MyLifeBits [1, 6], which was the first serious attempt to build such a database. Since then, there has been continued interest in our community to build personal information management systems [3-5, 7, 8, 10]. Recently, the Solid Project proposes a more radical approach to personal information, arguing that all of one's data should reside in their own data pod, and applications should be redesigned to fetch data from the pod [9].",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145867172",
                    "name": "X. Dong"
                },
                {
                    "authorId": "2155883057",
                    "name": "Bo Li"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "1699730",
                    "name": "A. Tung"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2131764025",
                    "name": "Wang-Chiew Tan"
                }
            ]
        },
        {
            "paperId": "20a4b2db20c1f06eab6f26cf8b7bf1748e54e6df",
            "title": "NormBank: A Knowledge Bank of Situational Social Norms",
            "abstract": "We present NormBank, a knowledge bank of 155k situational norms. This resource is designed to ground flexible normative reasoning for interactive, assistive, and collaborative AI systems. Unlike prior commonsense resources, NormBank grounds each inference within a multivalent sociocultural frame, which includes the setting (e.g., restaurant), the agents\u2019 contingent roles (waiter, customer), their attributes (age, gender), and other physical, social, and cultural constraints (e.g., the temperature or the country of operation). In total, NormBank contains 63k unique constraints from a taxonomy that we introduce and iteratively refine here. Constraints then apply in different combinations to frame social norms. Under these manipulations, norms are non-monotonic \u2014 one can cancel an inference by updating its frame even slightly. Still, we find evidence that neural models can help reliably extend the scope and coverage of NormBank. We further demonstrate the utility of this resource with a series of transfer experiments. For data and code, see https://github.com/SALT-NLP/normbank",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1399135100",
                    "name": "Caleb Ziems"
                },
                {
                    "authorId": "2284686652",
                    "name": "Jane Dwivedi-Yu"
                },
                {
                    "authorId": "2116640035",
                    "name": "Yi-Chia Wang"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "2bc5239c7696598ec64ceaa26a859ff6480f6dda",
            "title": "Learnings from Data Integration for Augmented Language Models",
            "abstract": "One of the limitations of large language models is that they do not have access to up-to-date, proprietary or personal data. As a result, there are multiple efforts to extend language models with techniques for accessing external data. In that sense, LLMs share the vision of data integration systems whose goal is to provide seamless access to a large collection of heterogeneous data sources. While the details and the techniques of LLMs differ greatly from those of data integration, this paper shows that some of the lessons learned from research on data integration can elucidate the research path we are conducting today on language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2284686652",
                    "name": "Jane Dwivedi-Yu"
                }
            ]
        },
        {
            "paperId": "82269db50b014b6c3932bea016f163ef8d9b49d1",
            "title": "Using Comments for Predicting the Affective Response to Social Media Posts",
            "abstract": "What people see on social media influences their affective state. Predictions of the affective reaction of an audience to a post could help posters creating content and viewers searching for it. This paper examines the value of both real comments and artificially generated ones in predicting the affective responses of an audience. We built an affect prediction model based on Facebook anonymized public posts to predict affective responses (anger, amusement, and sadness affect) as indicated by three Facebook reaction clicks (Angry, Haha, and Sad). Using the content of the original post can predict reactions well (.71 to.87 F1-scores). Adding the text of real post comments improves F1-score by up to 11%. Surprisingly, generated comments improve predictions as much as real comments. These artificial comments were produced using a pre-trained sequence-to-sequence, BART natural language generation model given a post as input. Using artificial comments means that one can predict affect reactions early in the history of a discussion, before anyone has actually commented on a post.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279773205",
                    "name": "Yi-Chia Wang"
                },
                {
                    "authorId": "2284686652",
                    "name": "Jane Dwivedi-Yu"
                },
                {
                    "authorId": "2131324879",
                    "name": "Robert E. Kraut"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                }
            ]
        },
        {
            "paperId": "953d24f0f81714dd90f59f6fa7ba5d76349601b8",
            "title": "Will LLMs reshape, supercharge, or kill data science?",
            "abstract": "Large language models (LLMs) have recently taken the world by storm, promising potentially game changing opportunities in multiple fields. Naturally, there is significant promise in applying LLMs to the management of structured data, or more generally, to the processes involved in data science. At the very least, LLMs have the potential to provide substantial advancements in long-standing challenges that our community has been tackling for decades. On the other hand, they may introduce completely new capabilities that we have only dreamed of thus far. This panel will bring together a few leading experts who have been thinking about these opportunities from various perspectives and fielding them in research prototypes and even in commercial applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2242456636",
                    "name": "Yejin Choi"
                },
                {
                    "authorId": "2327080",
                    "name": "Avrilia Floratou"
                },
                {
                    "authorId": "2257377251",
                    "name": "Michael J. Franklin"
                },
                {
                    "authorId": "1791431",
                    "name": "Natasha Noy"
                },
                {
                    "authorId": "2242785594",
                    "name": "Haixun Wang"
                }
            ]
        },
        {
            "paperId": "9926fb56a7a3a68ae66dd18f8955c1b096bdb474",
            "title": "Human-Centered Planning",
            "abstract": "LLMs have recently made impressive inroads on tasks whose output is structured, such as coding, robotic planning and querying databases. The vision of creating AI-powered personal assistants also involves creating structured outputs, such as a plan for one's day, or for an overseas trip. Here, since the plan is executed by a human, the output doesn't have to satisfy strict syntactic constraints. A useful assistant should also be able to incorporate vague constraints specified by the user in natural language. This makes LLMs an attractive option for planning. We consider the problem of planning one's day. We develop an LLM-based planner (LLMPlan) extended with the ability to self-reflect on its output and a symbolic planner (SymPlan) with the ability to translate text constraints into a symbolic representation. Despite no formal specification of constraints, we find that LLMPlan performs explicit constraint satisfaction akin to the traditional symbolic planners on average (2% performance difference), while retaining the reasoning of implicit requirements. Consequently, LLM-based planners outperform their symbolic counterparts in user satisfaction (70.5% vs. 40.4%) during interactive evaluation with 40 users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265720997",
                    "name": "Yuliang Li"
                },
                {
                    "authorId": "2935753",
                    "name": "Nitin Kamra"
                },
                {
                    "authorId": "2265650981",
                    "name": "Ruta Desai"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                }
            ]
        },
        {
            "paperId": "a393c5dc8e1f29862ec4e3ef5e7303c210c0c9c1",
            "title": "TimelineQA: A Benchmark for Question Answering over Timelines",
            "abstract": "Lifelogs are descriptions of experiences that a person had during their life. Lifelogs are created by fusing data from the multitude of digital services, such as online photos, maps, shopping and content streaming services. Question answering over lifelogs can offer personal assistants a critical resource when they try to provide advice in context. However, obtaining answers to questions over lifelogs is beyond the current state of the art of question answering techniques for a variety of reasons, the most pronounced of which is that lifelogs combine free text with some degree of structure such as temporal and geographical information. We create and publicly release TimelineQA1, a benchmark for accelerating progress on querying lifelogs. TimelineQA generates lifelogs of imaginary people. The episodes in the lifelog range from major life episodes such as high school graduation to those that occur on a daily basis such as going for a run. We describe a set of experiments on TimelineQA with several state-of-the-art QA models. Our experiments reveal that for atomic queries, an extractive QA system significantly out-performs a state-of-the-art retrieval-augmented QA system. For multi-hop queries involving aggregates, we show that the best result is obtained with a state-of-the-art table QA technique, assuming the ground truth set of episodes for deriving the answer is available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34582619",
                    "name": "W. Tan"
                },
                {
                    "authorId": "2284686652",
                    "name": "Jane Dwivedi-Yu"
                },
                {
                    "authorId": "47001493",
                    "name": "Yuliang Li"
                },
                {
                    "authorId": "36299222",
                    "name": "Lambert Mathias"
                },
                {
                    "authorId": "2073055",
                    "name": "Marzieh Saeidi"
                },
                {
                    "authorId": "2197542594",
                    "name": "J. Yan"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                }
            ]
        },
        {
            "paperId": "b91bcadc6227f7d61e406bb6957850231733442e",
            "title": "Factuality Challenges in the Era of Large Language Models",
            "abstract": "The emergence of tools based on Large Language Models (LLMs), such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard, has garnered immense public attention. These incredibly useful, natural-sounding tools mark significant advances in natural language generation, yet they exhibit a propensity to generate false, erroneous, or misleading content -- commonly referred to as\"hallucinations.\"Moreover, LLMs can be exploited for malicious applications, such as generating false but credible-sounding content and profiles at scale. This poses a significant challenge to society in terms of the potential deception of users and the increasing dissemination of inaccurate information. In light of these risks, we explore the kinds of technological innovations, regulatory reforms, and AI literacy initiatives needed from fact-checkers, news organizations, and the broader research and policy communities. By identifying the risks, the imminent threats, and some viable solutions, we seek to shed light on navigating various aspects of veracity in the era of generative AI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256988818",
                    "name": "Isabelle Augenstein"
                },
                {
                    "authorId": "2256987318",
                    "name": "Timothy Baldwin"
                },
                {
                    "authorId": "2284591948",
                    "name": "Meeyoung Cha"
                },
                {
                    "authorId": "2256999352",
                    "name": "Tanmoy Chakraborty"
                },
                {
                    "authorId": "1683012",
                    "name": "Giovanni Luca Ciampaglia"
                },
                {
                    "authorId": "2256993500",
                    "name": "David Corney"
                },
                {
                    "authorId": "2256999256",
                    "name": "Renee DiResta"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                },
                {
                    "authorId": "2256997151",
                    "name": "Scott Hale"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2256998951",
                    "name": "Eduard H. Hovy"
                },
                {
                    "authorId": "2257003221",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2268194233",
                    "name": "Filippo Menczer"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2994143",
                    "name": "Dietram A. Scheufele"
                },
                {
                    "authorId": "1491627343",
                    "name": "Shivam Sharma"
                },
                {
                    "authorId": "2256998588",
                    "name": "Giovanni Zagni"
                }
            ]
        }
    ]
}