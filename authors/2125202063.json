{
    "authorId": "2125202063",
    "papers": [
        {
            "paperId": "0081c0a8228a3a1efad8cfddf657f09f76d1546a",
            "title": "A Data Generation Perspective to the Mechanism of In-Context Learning",
            "abstract": "In-Context Learning (ICL) empowers Large Language Models (LLMs) with the capacity to learn in context, achieving downstream generalization without gradient updates but with a few in-context examples. Despite the encouraging empirical success, the underlying mechanism of ICL remains unclear, and existing research offers various viewpoints of understanding. These studies propose intuition-driven and ad-hoc technical solutions for interpreting ICL, illustrating an ambiguous road map. In this paper, we leverage a data generation perspective to reinterpret recent efforts and demonstrate the potential broader usage of popular technical solutions, approaching a systematic angle. For a conceptual definition, we rigorously adopt the terms of skill learning and skill recognition. The difference between them is skill learning can learn new data generation functions from in-context data. We also provide a comprehensive study on the merits and weaknesses of different solutions, and highlight the uniformity among them given the perspective of data generation, establishing a technical foundation for future research to incorporate the strengths of different lines of research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2152758698",
                    "name": "Guang-Da Liu"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2258699836",
                    "name": "Rongrong Wang"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "13f81979372850d9ab9d386c35bb00b4cc0e35f1",
            "title": "Position: Graph Foundation Models Are Already Here",
            "abstract": "Graph Foundation Models (GFMs) are emerging as a significant research topic in the graph domain, aiming to develop graph models trained on extensive and diverse data to enhance their applicability across various tasks and domains. Developing GFMs presents unique challenges over traditional Graph Neural Networks (GNNs), which are typically trained from scratch for specific tasks on particular datasets. The primary challenge in constructing GFMs lies in effectively leveraging vast and diverse graph data to achieve positive transfer. Drawing inspiration from existing foundation models in the CV and NLP domains, we propose a novel perspective for the GFM development by advocating for a ``graph vocabulary'', in which the basic transferable units underlying graphs encode the invariance on graphs. We ground the graph vocabulary construction from essential aspects including network analysis, expressiveness, and stability. Such a vocabulary perspective can potentially advance the future GFM design in line with the neural scaling laws. All relevant resources with GFM design can be found here.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2188792890",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "2282988161",
                    "name": "Jianan Zhao"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2256340293",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "2253409421",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "2066369448",
                    "name": "Mikhail Galkin"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "2e4a3a3d3541e87f308b759a6767e03005f498bd",
            "title": "Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis",
            "abstract": "Large Language Models (LLMs) are capable of producing content that perpetuates stereotypes, discrimination, and toxicity. The recently proposed moral self-correction is a computationally efficient method for reducing harmful content in the responses of LLMs. However, the process of how injecting self-correction instructions can modify the behavior of LLMs remains under-explored. In this paper, we explore the effectiveness of moral self-correction by answering three research questions: (1) In what scenarios does moral self-correction work? (2) What are the internal mechanisms of LLMs, e.g., hidden states, that are influenced by moral self-correction instructions? (3) Is intrinsic moral self-correction actually superficial? We argue that self-correction can help LLMs find a shortcut to more morally correct output, rather than truly reducing the immorality stored in hidden states. Through empirical investigation with tasks of language generation and multi-choice question answering, we conclude: (i) LLMs exhibit good performance across both tasks, and self-correction instructions are particularly beneficial when the correct answer is already top-ranked; (ii) The morality levels in intermediate hidden states are strong indicators as to whether one instruction would be more effective than another; (iii) Based on our analysis of intermediate hidden states and task case studies of self-correction behaviors, we are first to propose the hypothesis that intrinsic moral self-correction is in fact superficial.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152758698",
                    "name": "Guang-Da Liu"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2262203039",
                    "name": "K. Johnson"
                }
            ]
        },
        {
            "paperId": "3661028c69324cc7c17b1f61403f353330824217",
            "title": "The 1st International Workshop on Graph Foundation Models (GFM)",
            "abstract": "Foundation models such as GPT-4 for natural language processing (NLP), Flamingo for computer vision (CV), have set new benchmarks in AI by delivering state-of-the-art results across various tasks with minimal task-specific data. Despite their success, the application of these models to the graph domain is challenging due to the relational nature of graph-structured data. To address this gap, we propose the Graph Foundation Model (GFM) Workshop, the first workshop for GFMs, dedicated to exploring the adaptation and development of foundation models specifically designed for graph data. The GFM workshop focuses on two critical questions: (1) How can the underlying capabilities of existing foundation models be effectively applied to graph data? (2) What foundational principles should guide the creation of models tailored to the graph domain? Through a curated set of panel sections, keynote talks, and paper presentations, our workshop intends to catalyze innovative approaches and theoretical frameworks for Graph Foundation Models (GFMs). We target a broad audience, encompassing researchers, practitioners, and students, and aim to lay the groundwork for the next wave of breakthroughs in integrating graph data with foundation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2282988161",
                    "name": "Jianan Zhao"
                },
                {
                    "authorId": "2283895736",
                    "name": "Xiaoxin He"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2301244927",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "9031926",
                    "name": "Zhaocheng Zhu"
                },
                {
                    "authorId": "2255480226",
                    "name": "Jian Tang"
                },
                {
                    "authorId": "2301211397",
                    "name": "Micheal Bronstein"
                },
                {
                    "authorId": "2301211510",
                    "name": "Xavier Bresson"
                },
                {
                    "authorId": "2248230652",
                    "name": "Bryan Hooi"
                },
                {
                    "authorId": "2257092445",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2301317582",
                    "name": "Xianfeng Tang"
                },
                {
                    "authorId": "2301273801",
                    "name": "Luo Chen"
                },
                {
                    "authorId": "2261757006",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "48b139056d2c0c9e634d527622eb25d168647351",
            "title": "Text-space Graph Foundation Models: Comprehensive Benchmarks and New Insights",
            "abstract": "Given the ubiquity of graph data and its applications in diverse domains, building a Graph Foundation Model (GFM) that can work well across different graphs and tasks with a unified backbone has recently garnered significant interests. A major obstacle to achieving this goal stems from the fact that graphs from different domains often exhibit diverse node features. Inspired by multi-modal models that align different modalities with natural language, the text has recently been adopted to provide a unified feature space for diverse graphs. Despite the great potential of these text-space GFMs, current research in this field is hampered by two problems. First, the absence of a comprehensive benchmark with unified problem settings hinders a clear understanding of the comparative effectiveness and practical value of different text-space GFMs. Second, there is a lack of sufficient datasets to thoroughly explore the methods' full potential and verify their effectiveness across diverse settings. To address these issues, we conduct a comprehensive benchmark providing novel text-space datasets and comprehensive evaluation under unified problem settings. Empirical results provide new insights and inspire future research directions. Our code and data are publicly available from \\url{https://github.com/CurryTang/TSGFM}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2282543720",
                    "name": "Jingzhe Liu"
                },
                {
                    "authorId": "2298357027",
                    "name": "Yu Song"
                },
                {
                    "authorId": "2254637024",
                    "name": "Bingheng Li"
                },
                {
                    "authorId": "2112343584",
                    "name": "Wei-dong Jin"
                },
                {
                    "authorId": "3422551",
                    "name": "Bahare Fatemi"
                },
                {
                    "authorId": "40900939",
                    "name": "Anton Tsitsulin"
                },
                {
                    "authorId": "2271808",
                    "name": "Bryan Perozzi"
                },
                {
                    "authorId": "2298005501",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "524da808a711c0b3c63c5eb400097860d6e0dd3a",
            "title": "Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?",
            "abstract": "Self-supervised learning~(SSL) is essential to obtain foundation models in NLP and CV domains via effectively leveraging knowledge in large-scale unlabeled data. The reason for its success is that a suitable SSL design can help the model to follow the neural scaling law, i.e., the performance consistently improves with increasing model and dataset sizes. However, it remains a mystery whether existing SSL in the graph domain can follow the scaling behavior toward building Graph Foundation Models~(GFMs) with large-scale pre-training. In this study, we examine whether existing graph SSL techniques can follow the neural scaling behavior with the potential to serve as the essential component for GFMs. Our benchmark includes comprehensive SSL technique implementations with analysis conducted on both the conventional SSL setting and many new settings adopted in other domains. Surprisingly, despite the SSL loss continuously decreasing, no existing graph SSL techniques follow the neural scaling behavior on the downstream performance. The model performance only merely fluctuates on different data scales and model scales. Instead of the scales, the key factors influencing the performance are the choices of model architecture and pretext task design. This paper examines existing SSL techniques for the feasibility of Graph SSL techniques in developing GFMs and opens a new direction for graph SSL design with the new evaluation prototype. Our code implementation is available online to ease reproducibility on https://github.com/GraphSSLScaling/GraphSSLScaling.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287869318",
                    "name": "Qian Ma"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2282543720",
                    "name": "Jingzhe Liu"
                },
                {
                    "authorId": "2316583887",
                    "name": "Zhehua Zhang"
                },
                {
                    "authorId": "2316586272",
                    "name": "Chunlin Feng"
                },
                {
                    "authorId": "2298357027",
                    "name": "Yu Song"
                },
                {
                    "authorId": "2316855566",
                    "name": "Yihan Shao"
                },
                {
                    "authorId": "2287916169",
                    "name": "Yao Ma"
                }
            ]
        },
        {
            "paperId": "647a42d78e5bd405014a8c878e37fb7b2da8eaa6",
            "title": "Graph Machine Learning in the Era of Large Language Models (LLMs)",
            "abstract": "Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML's generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2291324376",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2266567589",
                    "name": "Shijie Wang"
                },
                {
                    "authorId": "2298085002",
                    "name": "Jiani Huang"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2298357027",
                    "name": "Yu Song"
                },
                {
                    "authorId": "2297995979",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2298005501",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2272987756",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "2297846971",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2297955888",
                    "name": "Qing Li"
                }
            ]
        },
        {
            "paperId": "6b10825701d73925808744c863d2a3df2671701b",
            "title": "Universal Link Predictor By In-Context Learning on Graphs",
            "abstract": "Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph. Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training. Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches. Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs. Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph. In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities of parametric models. UniLP is designed to autonomously identify connectivity patterns across diverse graphs, ready for immediate application to any unseen graph dataset without targeted training. We address the challenge of conflicting connectivity patterns-arising from the unique distributions of different graphs-through the implementation of In-context Learning (ICL). This approach allows UniLP to dynamically adjust to various target graphs based on contextual demonstrations, thereby avoiding negative transfer. Through rigorous experimentation, we demonstrate UniLP's effectiveness in adapting to new, unseen graphs at test time, showcasing its ability to perform comparably or even outperform parametric models that have been finetuned for specific datasets. Our findings highlight UniLP's potential to set a new standard in link prediction, combining the strengths of heuristic and parametric methods in a single, versatile framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124716703",
                    "name": "Kaiwen Dong"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2109411071",
                    "name": "Zhichun Guo"
                },
                {
                    "authorId": "144539424",
                    "name": "N. Chawla"
                }
            ]
        },
        {
            "paperId": "98097c3d23e811717c4a9d958d144a5cb6dafe7c",
            "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
            "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from large-scale data, achieving remarkable successes as evidenced by large models in CV and NLP. However, progress in the graph domain remains limited due to fundamental challenges such as feature heterogeneity and structural heterogeneity. Recently, increasing efforts have been made to enhance node feature quality with Large Language Models (LLMs) on text-attributed graphs (TAGs), demonstrating superiority to traditional bag-of-words or word2vec techniques. These high-quality node features reduce the previously critical role of graph structure, resulting in a modest performance gap between Graph Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs). Motivated by this, we introduce a feature-centric pretraining perspective by treating graph structure as a prior and leveraging the rich, unified feature space to learn refined interaction patterns that generalizes across graphs. Our framework, Graph Sequence Pretraining with Transformer (GSPT), samples node contexts through random walks and employs masked feature reconstruction to capture pairwise proximity in the LLM-unified feature space using a standard Transformer. By utilizing unified text representations rather than varying structures, our framework achieves significantly better transferability among graphs within the same domain. GSPT can be easily adapted to both node classification and link prediction, demonstrating promising empirical success on various datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298357027",
                    "name": "Yu Song"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2307606121",
                    "name": "Jiachen Xiao"
                },
                {
                    "authorId": "2282543720",
                    "name": "Jingzhe Liu"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2112343584",
                    "name": "Wei-dong Jin"
                },
                {
                    "authorId": "2307485020",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2298005501",
                    "name": "Hui Liu"
                }
            ]
        },
        {
            "paperId": "9c6b13096f2c081cb587be22818023b13bb0c763",
            "title": "Addressing Shortcomings in Fair Graph Learning Datasets: Towards a New Benchmark",
            "abstract": "Fair graph learning plays a pivotal role in numerous practical applications. Recently, many fair graph learning methods have been proposed; however, their evaluation often relies on poorly constructed semi-synthetic datasets or substandard real-world datasets. In such cases, even a basic Multilayer Perceptron (MLP) can outperform Graph Neural Networks (GNNs) in both utility and fairness. In this work, we illustrate that many datasets fail to provide meaningful information in the edges, which may challenge the necessity of using graph structures in these problems. To address these issues, we develop and introduce a collection of synthetic, semi-synthetic, and real-world datasets that fulfill a broad spectrum of requirements. These datasets are thoughtfully designed to include relevant graph structures and bias information crucial for the fair evaluation of models. The proposed synthetic and semi-synthetic datasets offer the flexibility to create data with controllable bias parameters, thereby enabling the generation of desired datasets with user-defined bias values with ease. Moreover, we conduct systematic evaluations of these proposed datasets and establish a unified evaluation approach for fair graph learning models. Our extensive experimental results with fair graph learning methods across our datasets demonstrate their effectiveness in benchmarking the performance of these methods. Our datasets and the code for reproducing our experiments are available at https://github.com/XweiQ/Benchmark-GraphFairness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275605174",
                    "name": "Xiaowei Qian"
                },
                {
                    "authorId": "2149465392",
                    "name": "Zhimeng Guo"
                },
                {
                    "authorId": "2257373969",
                    "name": "Jialiang Li"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2254637024",
                    "name": "Bingheng Li"
                },
                {
                    "authorId": "2286977475",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2287916169",
                    "name": "Yao Ma"
                }
            ]
        }
    ]
}