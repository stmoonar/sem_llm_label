{
    "authorId": "2166165505",
    "papers": [
        {
            "paperId": "8e86933e24e247d0c04c6bf7dcbdbed3bfc8b75d",
            "title": "Improving Representation of High-frequency Components for Medical Foundation Models",
            "abstract": "Foundation models have recently attracted significant attention for their impressive generalizability across diverse downstream tasks. However, these models are demonstrated to exhibit great limitations in representing high-frequency components and fine-grained details. In many medical imaging tasks, the precise representation of such information is crucial due to the inherently intricate anatomical structures, sub-visual features, and complex boundaries involved. Consequently, the limited representation of prevalent foundation models can result in significant performance degradation or even failure in these tasks. To address these challenges, we propose a novel pretraining strategy, named Frequency-advanced Representation Autoencoder (Frepa). Through high-frequency masking and low-frequency perturbation combined with adversarial learning, Frepa encourages the encoder to effectively represent and preserve high-frequency components in the image embeddings. Additionally, we introduce an innovative histogram-equalized image masking strategy, extending the Masked Autoencoder approach beyond ViT to other architectures such as Swin Transformer and convolutional networks. We develop Frepa across nine medical modalities and validate it on 32 downstream tasks for both 2D images and 3D volume data. Without fine-tuning, Frepa can outperform other self-supervised pretraining methods and, in some cases, even surpasses task-specific trained models. This improvement is particularly significant for tasks involving fine-grained details, such as achieving up to a +15% increase in DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule detection. Further experiments quantitatively reveal that Frepa enables superior high-frequency representations and preservation in the embeddings, underscoring its potential for developing more generalized and universal medical image foundation models.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2312338401",
                    "name": "Yilan Zhang"
                },
                {
                    "authorId": "2279914462",
                    "name": "Zhongyi Han"
                },
                {
                    "authorId": "2296664618",
                    "name": "Changchun Yang"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2312325938",
                    "name": "Gongning Luo"
                },
                {
                    "authorId": "2254373994",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "d2ce3deb40b4b3099e014c651c33dbe210bfee56",
            "title": "Deep learning-driven pulmonary arteries and veins segmentation reveals demography-associated pulmonary vasculature anatomy",
            "abstract": "Pulmonary artery-vein segmentation is crucial for diagnosing pulmonary diseases and surgical planning, and is traditionally achieved by Computed Tomography Pulmonary Angiography (CTPA). However, concerns regarding adverse health effects from contrast agents used in CTPA have constrained its clinical utility. In contrast, identifying arteries and veins using non-contrast CT, a conventional and low-cost clinical examination routine, has long been considered impossible. Here we propose a High-abundant Pulmonary Artery-vein Segmentation (HiPaS) framework achieving accurate artery-vein segmentation on both non-contrast CT and CTPA across various spatial resolutions. HiPaS first performs spatial normalization on raw CT scans via a super-resolution module, and then iteratively achieves segmentation results at different branch levels by utilizing the low-level vessel segmentation as a prior for high-level vessel segmentation. We trained and validated HiPaS on our established multi-centric dataset comprising 1,073 CT volumes with meticulous manual annotation. Both quantitative experiments and clinical evaluation demonstrated the superior performance of HiPaS, achieving a dice score of 91.8% and a sensitivity of 98.0%. Further experiments demonstrated the non-inferiority of HiPaS segmentation on non-contrast CT compared to segmentation on CTPA. Employing HiPaS, we have conducted an anatomical study of pulmonary vasculature on 10,613 participants in China (five sites), discovering a new association between pulmonary vessel abundance and sex and age: vessel abundance is significantly higher in females than in males, and slightly decreases with age, under the controlling of lung volumes (p<0.0001). HiPaS realizing accurate artery-vein segmentation delineates a promising avenue for clinical diagnosis and understanding pulmonary physiology in a non-invasive manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2918346",
                    "name": "Gongning Luo"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "46179154",
                    "name": "Shaodong Cao"
                },
                {
                    "authorId": "2296138398",
                    "name": "Guolin Ma"
                },
                {
                    "authorId": "2296129078",
                    "name": "Xianglin Meng"
                },
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "2296664618",
                    "name": "Changchun Yang"
                },
                {
                    "authorId": "2269547024",
                    "name": "Dexuan Xie"
                },
                {
                    "authorId": "2295987429",
                    "name": "Ricardo Henao"
                },
                {
                    "authorId": "2296478530",
                    "name": "Xigang Xiao"
                },
                {
                    "authorId": "2296240078",
                    "name": "Lianming Wu"
                },
                {
                    "authorId": "2254314887",
                    "name": "Zhaowen Qiu"
                },
                {
                    "authorId": "2254373994",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "27387572208cf777fb2c55db8880dd5407d0e779",
            "title": "Personalized and privacy-preserving federated heterogeneous medical image analysis with PPPML-HMI",
            "abstract": "Heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging. However, there are few open-source frameworks for federated heterogeneous medical image analysis with personalization and privacy protection without the demand to modify the existing model structures or to share any private data. In this paper, we proposed PPPML-HMI, a novel open-source learning paradigm for personalized and privacy-preserving federated heterogeneous medical image analysis. To our best knowledge, personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the PerFedAvg algorithm and designing the novel cyclic secure aggregation with the homomorphic encryption algorithm. To show the utility of PPPML-HMI, we applied it to a simulated classification task namely the classification of healthy people and patients from the RAD-ChestCT Dataset, and one real-world segmentation task namely the segmentation of lung infections from COVID-19 CT scans. For the real-world task, PPPML-HMI achieved $sim$5% higher Dice score on average compared to conventional FL under the heterogeneous scenario. Meanwhile, we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the strong privacy-preserving capability of PPPML-HMI. By applying PPPML-HMI to both tasks with different neural networks, a varied number of users, and sample sizes, we further demonstrated the strong generalizability of PPPML-HMI.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2161017247",
                    "name": "Di Wang"
                },
                {
                    "authorId": "2142540079",
                    "name": "Xiaopeng Xu"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2028962393",
                    "name": "Wenkai Han"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "27d0d2923a42bd2bced1b100844e232ff87368e3",
            "title": "SkinGPT-4: An Interactive Dermatology Diagnostic System with Visual Large Language Model",
            "abstract": "Skin and subcutaneous diseases rank high among the leading contributors to the global burden of nonfatal diseases, impacting a considerable portion of the population. Nonetheless, the field of dermatology diagnosis faces three significant hurdles. Firstly, there is a shortage of dermatologists accessible to diagnose patients, particularly in rural regions. Secondly, accurately interpreting skin disease images poses a considerable challenge. Lastly, generating patient-friendly diagnostic reports is usually a time-consuming and labor-intensive task for dermatologists. To tackle these challenges, we present SkinGPT-4, which is the world's first interactive dermatology diagnostic system powered by an advanced visual large language model. SkinGPT-4 leverages a fine-tuned version of MiniGPT-4, trained on an extensive collection of skin disease images (comprising 52,929 publicly available and proprietary images) along with clinical concepts and doctors' notes. We designed a two-step training process to allow SkinGPT to express medical features in skin disease images with natural language and make accurate diagnoses of the types of skin diseases. With SkinGPT-4, users could upload their own skin photos for diagnosis, and the system could autonomously evaluate the images, identifies the characteristics and categories of the skin conditions, performs in-depth analysis, and provides interactive treatment recommendations. Meanwhile, SkinGPT-4's local deployment capability and commitment to user privacy also render it an appealing choice for patients in search of a dependable and precise diagnosis of their skin ailments. To demonstrate the robustness of SkinGPT-4, we conducted quantitative evaluations on 150 real-life cases, which were independently reviewed by certified dermatologists, and showed that SkinGPT-4 could provide accurate diagnoses of skin diseases. Though SkinGPT-4 is not a substitute for doctors, it could enhance users' comprehension of their medical conditions, facilitate improve communication between patients and doctors, expedite the diagnostic process for dermatologists, and potentially promote human-centred care and healthcare equity in underdeveloped areas.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "3455313",
                    "name": "Xiao-Zhen He"
                },
                {
                    "authorId": "46732892",
                    "name": "Liyuan Sun"
                },
                {
                    "authorId": "2293560831",
                    "name": "Jiannan Xu"
                },
                {
                    "authorId": "46772896",
                    "name": "Xiuying Chen"
                },
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "51072831",
                    "name": "Xingyu Liao"
                },
                {
                    "authorId": "2119454424",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        }
    ]
}