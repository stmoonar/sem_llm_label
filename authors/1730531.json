{
    "authorId": "1730531",
    "papers": [
        {
            "paperId": "0f900f07158d0abf9d7a419c392e33531f3eebae",
            "title": "Word Embeddings Are Steers for Language Models",
            "abstract": "Language models (LMs) automatically learn word embeddings during pre-training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain underexplored. In this work, we theoretically and empirically revisit output word embeddings and find that their linear transformations are equivalent to steering language model generation styles. We name such steers LM-Steers and find them existing in LMs of all sizes. It requires learning parameters equal to 0.2% of the original LMs' size for steering each style. On tasks such as language model detoxification and sentiment control, LM-Steers can achieve comparable or superior performance compared with state-of-the-art controlled generation methods while maintaining a better balance with generation quality. The learned LM-Steer serves as a lens in text styles: it reveals that word embeddings are interpretable when associated with language model generations and can highlight text spans that most indicate the style differences. An LM-Steer is transferrable between different language models by an explicit form calculation. One can also continuously steer LMs simply by scaling the LM-Steer or compose multiple LM-Steers by adding their transformations. Our codes are publicly available at \\url{https://github.com/Glaciohound/LM-Steer}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118642562",
                    "name": "Chi Han"
                },
                {
                    "authorId": "9097644",
                    "name": "Jialiang Xu"
                },
                {
                    "authorId": "2118482058",
                    "name": "Manling Li"
                },
                {
                    "authorId": "51135899",
                    "name": "Y. Fung"
                },
                {
                    "authorId": "1726046634",
                    "name": "Chenkai Sun"
                },
                {
                    "authorId": "2057958465",
                    "name": "Nan Jiang"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                },
                {
                    "authorId": "2072975661",
                    "name": "Heng Ji"
                }
            ]
        },
        {
            "paperId": "13a6bab8de7a419f994c8fdba0499f14a5e26cda",
            "title": "Scheduling Classifiers for Real-Time Hazard Perception Considering Functional Uncertainty",
            "abstract": "This paper addresses the problem of real-time classification-based machine perception, exemplified by a mobile autonomous system that must continually check that a designated area ahead is free of hazards. Such hazards must be identified within a specified time. In practice, classifiers are imperfect; they exhibit functional uncertainty. In the majority of cases, a given classifier will correctly determine whether there is a hazard or the area ahead is clear. However, in other cases it may produce false positives, i.e. indicate hazard when the area is clear, or false negatives, i.e. indicate clear when there is in fact a hazard. The former are undesirable since they reduce quality of service, whereas the latter are a potential safety concern. A stringent constraint is therefore placed on the maximum permitted probability of false negatives. Since this requirement may not be achievable using a single classifier, one approach is to (logically) OR the outputs of multiple disparate classifiers together, setting the final output to hazard if any of the classifiers indicates hazard. This reduces the probability of false negatives; however, the trade-off is an inevitably increase in the probability of false positives and an increase in the overall execution time required. In this paper, we provide optimal algorithms for the scheduling of classifiers that minimize the probability of false positives, while meeting both a latency constraint and a constraint on the maximum acceptable probability of false negatives. The classifiers may have arbitrary statistical dependences between their functional behaviors (probabilities of correct identification of hazards), as well as variability in their execution times, characterized by typical and worst-case values.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                },
                {
                    "authorId": "144379776",
                    "name": "Sanjoy Baruah"
                },
                {
                    "authorId": "1797635",
                    "name": "I. Bate"
                },
                {
                    "authorId": "2143405924",
                    "name": "Alan Burns"
                },
                {
                    "authorId": "35178750",
                    "name": "Robert I. Davis"
                },
                {
                    "authorId": "31567532",
                    "name": "Yigong Hu"
                }
            ]
        },
        {
            "paperId": "5bba9dfb9b8f12ff105498fd192bb04f95ce6514",
            "title": "Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning",
            "abstract": "This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both \\textit{false negative issue} (i.e., potential true facts being excluded) and \\textit{false positive issue} (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call \\textit{label posterior}) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies missing facts to provide high-quality grounds of reasoning. They are unified in a simple yet effective self-training procedure. Empirically, extensive experiments on three benchmark KG and one Twitter dataset with various degrees of false negative/positive cases demonstrate the effectiveness of nPUGraph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144408471",
                    "name": "Ruijie Wang"
                },
                {
                    "authorId": "2118424577",
                    "name": "Baoyu Li"
                },
                {
                    "authorId": "2156141201",
                    "name": "Yichen Lu"
                },
                {
                    "authorId": "1630209136",
                    "name": "Dachun Sun"
                },
                {
                    "authorId": "2109377974",
                    "name": "Jinning Li"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "1390628682",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "69828bf2eb40d7fbbdc2421d7ee60d838972f505",
            "title": "Unsupervised Image Classification by Ideological Affiliation from User-Content Interaction Patterns",
            "abstract": "The proliferation of political memes in modern information campaigns calls for efficient solutions for image classification by ideological affiliation. While significant advances have recently been made on text classification in modern natural language processing literature, understanding the political insinuation in imagery is less developed due to the hard nature of the problem. Unlike text, where meaning arises from juxtaposition of tokens (words) within some common linguistic structures, image semantics emerge from a much less constrained process of fusion of visual concepts. Thus, training a model to infer visual insinuation is possibly a more challenging problem. In this paper, we explore an alternative unsupervised approach that, instead, infers ideological affiliation from image propagation patterns on social media. The approach is shown to improve the F1-score by over 0.15 (nearly 25%) over previous unsupervised baselines, and then by another 0.05 (around 7%) in the presence of a small amount of supervision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "100683845",
                    "name": "Xinyi Liu"
                },
                {
                    "authorId": "2109377974",
                    "name": "Jinning Li"
                },
                {
                    "authorId": "1630209136",
                    "name": "Dachun Sun"
                },
                {
                    "authorId": "2144408471",
                    "name": "Ruijie Wang"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                },
                {
                    "authorId": "2218438509",
                    "name": "Matt Brown"
                },
                {
                    "authorId": "2218883644",
                    "name": "Anthony Barricelli"
                },
                {
                    "authorId": "2113490",
                    "name": "Matthias Kirchner"
                },
                {
                    "authorId": "32865856",
                    "name": "Arslan Basharat"
                }
            ]
        },
        {
            "paperId": "b2ae6f8b318b2b54baa85fd32b0b75ae8a9abaa4",
            "title": "MOSAIC: Spatially-Multiplexed Edge AI Optimization over Multiple Concurrent Video Sensing Streams",
            "abstract": "Sustaining high fidelity and high throughput of perception tasks over vision sensor streams on edge devices remains a formidable challenge, especially given the continuing increase in image sizes (e.g., generated by 4K cameras) and complexity of DNN models. One promising approach involves criticality-aware processing, where the computation is directed selectively to \"critical\" portions of individual image frames. We introduce MOSAIC, a novel system for such criticality-aware concurrent processing of multiple vision sensing streams that provides a multiplicative increase in the achievable throughput with negligible loss in perception fidelity. MOSAIC determines critical regions from images received from multiple vision sensors and spatially bin-packs these regions using a novel multi-scale Mosaic Across Scales (MoS) tiling strategy into a single `canvas frame', sized such that the edge device can retain sufficiently high processing throughput. Experimental studies using benchmark datasets for two tasks, Automatic License Plate Recognition and Drone-based Pedestrian Detection, shows that MOSAIC, executing on a Jetson TX2 edge device, can provide dramatic gains in the throughput vs. fidelity tradeoff. For instance, for drone-based pedestrian detection, for a batch size of 4, MOSAIC can pack input frames from 6 cameras to achieve (a) 4.75X (475%) higher throughput (23 FPS per camera, cumulatively 138FPS) with \u2264 1% accuracy loss, compared to a First Come First Serve (FCFS) processing paradigm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051293502",
                    "name": "Ila Gokarn"
                },
                {
                    "authorId": "2296336242",
                    "name": "Hemanth Sabbella"
                },
                {
                    "authorId": "31567532",
                    "name": "Yigong Hu"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                },
                {
                    "authorId": "2150552689",
                    "name": "Archan Misra"
                }
            ]
        },
        {
            "paperId": "c983190594d4b39448a43a1307d78c37992c857b",
            "title": "Underprovisioned GPUs: On Sufficient Capacity for Real-Time Mission-Critical Perception",
            "abstract": "Recent work suggests that computing resources, such as GPUs in real-time edge-based perception systems, need not have sufficient capacity to keep up with the input frame rates of all input devices (e.g., cameras) at their full-frame resolution. Rather, they can be under-provisioned because only parts of any given frame need to be inspected (i.e., paid attention to). This paper derives an attention allocation policy, called canvas-based attention scheduling that decides which parts of each frame of each device to inspect, and a corresponding schedulability condition that relates the spatiotemporal properties of surrounding objects to the ability of the edge-based perception subsystem to keep up with the state of the environment in real-time. It provides a quantitative estimate of adequate computing capacity for the expected perception workload. We implement a canvas-based attention scheduler for an object detection application and perform an empirical comparative study based on actual GPU hardware and surveillance videos. Results show that canvas-based attention scheduling keeps up with the environment while using a much smaller GPU capacity, compared with prior approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31567532",
                    "name": "Yigong Hu"
                },
                {
                    "authorId": "2051293502",
                    "name": "Ila Gokarn"
                },
                {
                    "authorId": "2237386361",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "2150552689",
                    "name": "Archan Misra"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "d924833bc352ea42ca91859211e09d5f6f507763",
            "title": "AcTrak: Controlling a Steerable Surveillance Camera using Reinforcement Learning",
            "abstract": "Steerable cameras that can be controlled via a network, to retrieve telemetries of interest have become popular. In this paper, we develop a framework called AcTrak, to automate a camera\u2019s motion to appropriately switch between (a) zoom ins on existing targets in a scene to track their activities, and (b) zoom out to search for new targets arriving to the area of interest. Specifically, we seek to achieve a good trade-off between the two tasks, i.e., we want to ensure that new targets are observed by the camera before they leave the scene, while also zooming in on existing targets frequently enough to monitor their activities. There exist prior control algorithms for steering cameras to optimize certain objectives; however, to the best of our knowledge, none have considered this problem, and do not perform well when target activity tracking is required. AcTrak automatically controls the camera\u2019s PTZ configurations using reinforcement learning (RL), to select the best camera position given the current state. Via simulations using real datasets, we show that AcTrak detects newly arriving targets 30% faster than a non-adaptive baseline and rarely misses targets, unlike the baseline which can miss up to 5% of the targets. We also implement AcTrak to control a real camera and demonstrate that in comparison with the baseline, it acquires about 2\u00d7 more high resolution images of targets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "21728973",
                    "name": "Abdulrahman Fahim"
                },
                {
                    "authorId": "3000659",
                    "name": "E. Papalexakis"
                },
                {
                    "authorId": "38774813",
                    "name": "S. Krishnamurthy"
                },
                {
                    "authorId": "2218882405",
                    "name": "Amit K. Roy Chowdhury"
                },
                {
                    "authorId": "48300748",
                    "name": "L. Kaplan"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "db5e2eddc93601106cb27f1949c56b78fd48e317",
            "title": "Mutually-paced Knowledge Distillation for Cross-lingual Temporal Knowledge Graph Reasoning",
            "abstract": "This paper investigates cross-lingual temporal knowledge graph reasoning problem, which aims to facilitate reasoning on Temporal Knowledge Graphs (TKGs) in low-resource languages by transfering knowledge from TKGs in high-resource ones. The cross-lingual distillation ability across TKGs becomes increasingly crucial, in light of the unsatisfying performance of existing reasoning methods on those severely incomplete TKGs, especially in low-resource languages. However, it poses tremendous challenges in two aspects. First, the cross-lingual alignments, which serve as bridges for knowledge transfer, are usually too scarce to transfer sufficient knowledge between two TKGs. Second, temporal knowledge discrepancy of the aligned entities, especially when alignments are unreliable, can mislead the knowledge distillation process. We correspondingly propose a mutually-paced knowledge distillation model MP-KD, where a teacher network trained on a source TKG can guide the training of a student network on target TKGs with an alignment module. Concretely, to deal with the scarcity issue, MP-KD generates pseudo alignments between TKGs based on the temporal information extracted by our representation module. To maximize the efficacy of knowledge transfer and control the noise caused by the temporal knowledge discrepancy, we enhance MP-KD with a temporal cross-lingual attention mechanism to dynamically estimate the alignment strength. The two procedures are mutually paced along with model training. Extensive experiments on twelve cross-lingual TKG transfer tasks in the EventKG benchmark demonstrate the effectiveness of the proposed MP-KD method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144408488",
                    "name": "Ruijie Wang"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "7788583",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "2151070",
                    "name": "Tianyu Cao"
                },
                {
                    "authorId": "2152738036",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "f53776356e468f002a83a414a431777b156ecf35",
            "title": "TwinSync: A Digital Twin Synchronization Protocol for Bandwidth-Limited IoT Applications",
            "abstract": "Digital Twins are evolving as a key component in modern systems with diverse applications like remote prognostics, optimizing run-time operation, anomaly detection, and more. The essential elements of a digital twin are a virtual representation, a physical asset, and the transfer of data/information between the two. IoT deployments are generally characterized by resource constraints, making synchronization of digital twins with IoT devices more challenging. There is a pressing need to optimize the bandwidth of the data transferred between the system and the twin, while ensuring that the twin is able to capture selected key aspects of the current operational state accurately. In this paper, we present TwinSync, a framework that can be utilized to construct flexible real-time representations of deployed IoT systems and efficiently synchronize relevant system states with the twin, over a communication bottleneck, within a configurable application-specific notion of error (henceforth referred to as approximate synchronization). Our approach is optimized to achieve data transfers utilizing less bandwidth without compromising the ability of the twin to replicate real-time system states within the specified approximate synchronization semantics. We evaluate the efficacy of TwinSync's synchronization by conducting both a synthetic analysis and a case study based on a real-life application prototype. Our evaluation indicates that using TwinSync can provide the same or greater accuracy (in many cases) while sending significantly fewer bytes than a bandwidth-insensitive synchronization approach. The result is attributed to a more judicial selection of data to transmit over bottlenecks, compared to bandwidth-insensitive approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1646595036",
                    "name": "Deepti Kalasapura"
                },
                {
                    "authorId": "2124948781",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "2237386361",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "2237088718",
                    "name": "Yizhuo Chen"
                },
                {
                    "authorId": "2144408471",
                    "name": "Ruijie Wang"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                },
                {
                    "authorId": "2146735124",
                    "name": "Matthew Caesar"
                },
                {
                    "authorId": "2174726260",
                    "name": "Joydeep Bhattacharyya"
                },
                {
                    "authorId": "2184218337",
                    "name": "Jae H. Kim"
                },
                {
                    "authorId": "2155124410",
                    "name": "Guijun Wang"
                },
                {
                    "authorId": "1741819",
                    "name": "Greg Kimberly"
                },
                {
                    "authorId": "2202582720",
                    "name": "Josh D. Eckhardt"
                },
                {
                    "authorId": "9350980",
                    "name": "Denis Osipychev"
                }
            ]
        },
        {
            "paperId": "2565ac67975c2e2745a41857b92dd7d7543e40f4",
            "title": "The Methodological Pitfall of Dataset-Driven Research on Deep Learning: An IoT Example",
            "abstract": "In this paper, we highlight a dangerous pitfall in the state-of-the-art evaluation methodology of deep learning algorithms. It results in deceptively good evaluation outcomes on test datasets, whereas the underlying algorithms remain prone to catastrophic failure in practice. We illustrate the pitfall in the context of an Internet-of-Things (IoT) application example and show that it occurs despite the use of cross-validation that breaks down the data into separate training, validation, and testing sets. The pitfall is illustrated by designing two target detection and classification algorithms. One is based on a recently proposed neural network architecture for embedded AI, and the other is based on a traditional machine learning approach with domain-inspired feature engineering. The neural network approach outperforms the traditional one on test data. Yet, it fails in deployment. The mechanics behind the failure are explained and linked to the way the algorithms are trained. Suggestions are presented to avoid the pitfall. The paper is a \u201ccall to arms\u201d to improve the evaluation methodology of machine learning algorithms for mission-critical systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49981269",
                    "name": "Tianshi Wang"
                },
                {
                    "authorId": "2202568267",
                    "name": "Denizhan Kara"
                },
                {
                    "authorId": "2124948781",
                    "name": "Jinyang Li"
                },
                {
                    "authorId": "1390628682",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                },
                {
                    "authorId": "3116427",
                    "name": "B. Jalaeian"
                }
            ]
        }
    ]
}