{
    "authorId": "3224619",
    "papers": [
        {
            "paperId": "09e06c155aaa0bbf1efd562b1dd85b32e39604b3",
            "title": "Affinity Uncertainty-Based Hard Negative Mining in Graph Contrastive Learning",
            "abstract": "Hard negative mining has shown effective in enhancing self-supervised contrastive learning (CL) on diverse data types, including graph CL (GCL). The existing hardness-aware CL methods typically treat negative instances that are most similar to the anchor instance as hard negatives, which helps improve the CL performance, especially on image data. However, this approach often fails to identify the hard negatives but leads to many false negatives on graph data. This is mainly due to that the learned graph representations are not sufficiently discriminative due to oversmooth representations and/or non-independent and identically distributed (non-i.i.d.) issues in graph data. To tackle this problem, this article proposes a novel approach that builds a discriminative model on collective affinity information (i.e., two sets of pairwise affinities between the negative instances and the anchor instance) to mine hard negatives in GCL. In particular, the proposed approach evaluates how confident/uncertain the discriminative model is about the affinity of each negative instance to an anchor instance to determine its hardness weight relative to the anchor instance. This uncertainty information is then incorporated into the existing GCL loss functions via a weighting term to enhance their performance. The enhanced GCL is theoretically grounded that the resulting GCL loss is equivalent to a triplet loss with an adaptive margin being exponentially proportional to the learned uncertainty of each negative instance. Extensive experiments on ten graph datasets show that our approach does the following: 1) consistently enhances different state-of-the-art (SOTA) GCL methods in both graph and node classification tasks and 2) significantly improves their robustness against adversarial attacks. Code is available at https://github.com/mala-lab/AUGCL.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "79690137",
                    "name": "Chaoxi Niu"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                }
            ]
        },
        {
            "paperId": "16a797ca05165e5a2ae7ee4606cb11691645fc9f",
            "title": "Improving Out-of-Distribution Detection with Disentangled Foreground and Background Features",
            "abstract": "Detecting out-of-distribution (OOD) inputs is a principal task for ensuring the safety of deploying deep-neural-network classifiers in open-set scenarios. OOD samples can be drawn from arbitrary distributions and exhibit deviations from in-distribution (ID) data in various dimensions, such as foreground features (e.g., objects in CIFAR100 images vs. those in CIFAR10 images) and background features (e.g., textural images vs. objects in CIFAR10). Existing methods can confound foreground and background features in training, failing to utilize the background features for OOD detection. This paper considers the importance of feature disentanglement in out-of-distribution detection and proposes the simultaneous exploitation of both foreground and background features to support the detection of OOD inputs in in out-of-distribution detection. To this end, we propose a novel framework that first disentangles foreground and background features from ID training samples via a dense prediction approach, and then learns a new classifier that can evaluate the OOD scores of test images from both foreground and background features. It is a generic framework that allows for a seamless combination with various existing OOD detection methods. Extensive experiments show that our approach 1) can substantially enhance the performance of four different state-of-the-art (SotA) OOD detection methods on multiple widely-used OOD datasets with diverse background features, and 2) achieves new SotA performance on these benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153255258",
                    "name": "Choubo Ding"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                }
            ]
        },
        {
            "paperId": "1725ad1d8cc0e539ac5d0a85657d5c95b4538c5e",
            "title": "Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects",
            "abstract": "Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages and disadvantages. To facilitate the experiments and validation of time series SSL methods, we also summarize datasets commonly used in time series forecasting, classification, anomaly detection, and clustering tasks. Finally, we present the future directions of SSL for time series analysis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2119059780",
                    "name": "Kexin Zhang"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2152737103",
                    "name": "Chaoli Zhang"
                },
                {
                    "authorId": "2136700261",
                    "name": "Rongyao Cai"
                },
                {
                    "authorId": "2072905592",
                    "name": "Ming Jin"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "72322304",
                    "name": "Y. Liang"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2585415",
                    "name": "Shirui Pan"
                }
            ]
        },
        {
            "paperId": "1b395558450aee91551b02ec5f1195e04ee9e7f9",
            "title": "Learning Adversarial Semantic Embeddings for Zero-Shot Recognition in Open Worlds",
            "abstract": "Zero-Shot Learning (ZSL) focuses on classifying samples of unseen classes with only their side semantic information presented during training. It cannot handle real-life, open-world scenarios where there are test samples of unknown classes for which neither samples (e.g., images) nor their side semantic information is known during training. Open-Set Recognition (OSR) is dedicated to addressing the unknown class issue, but existing OSR methods are not designed to model the semantic information of the unseen classes. To tackle this combined ZSL and OSR problem, we consider the case of\"Zero-Shot Open-Set Recognition\"(ZS-OSR), where a model is trained under the ZSL setting but it is required to accurately classify samples from the unseen classes while being able to reject samples from the unknown classes during inference. We perform large experiments on combining existing state-of-the-art ZSL and OSR models for the ZS-OSR task on four widely used datasets adapted from the ZSL task, and reveal that ZS-OSR is a non-trivial task as the simply combined solutions perform badly in distinguishing the unseen-class and unknown-class samples. We further introduce a novel approach specifically designed for ZS-OSR, in which our model learns to generate adversarial semantic embeddings of the unknown classes to train an unknowns-informed ZS-OSR classifier. Extensive empirical results show that our method 1) substantially outperforms the combined solutions in detecting the unknown classes while retaining the classification accuracy on the unseen classes and 2) achieves similar superiority under generalized ZS-OSR settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118909726",
                    "name": "Tianqi Li"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2153645540",
                    "name": "Xiao Bai"
                },
                {
                    "authorId": "2137178769",
                    "name": "Jingyi Zheng"
                },
                {
                    "authorId": "2144764491",
                    "name": "Lei Zhou"
                },
                {
                    "authorId": "2221314293",
                    "name": "Xin Ning"
                }
            ]
        },
        {
            "paperId": "3bcc03012f22eb10e7254123b25f3c28c70c3f31",
            "title": "Graph-level Anomaly Detection via Hierarchical Memory Networks",
            "abstract": "Graph-level anomaly detection aims to identify abnormal graphs that exhibit deviant structures and node attributes compared to the majority in a graph set. One primary challenge is to learn normal patterns manifested in both fine-grained and holistic views of graphs for identifying graphs that are abnormal in part or in whole. To tackle this challenge, we propose a novel approach called Hierarchical Memory Networks (HimNet), which learns hierarchical memory modules -- node and graph memory modules -- via a graph autoencoder network architecture. The node-level memory module is trained to model fine-grained, internal graph interactions among nodes for detecting locally abnormal graphs, while the graph-level memory module is dedicated to the learning of holistic normal patterns for detecting globally abnormal graphs. The two modules are jointly optimized to detect both locally- and globally-anomalous graphs. Extensive empirical results on 16 real-world graph datasets from various domains show that i) HimNet significantly outperforms the state-of-art methods and ii) it is robust to anomaly contamination. Codes are available at: https://github.com/Niuchx/HimNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "79690137",
                    "name": "Chaoxi Niu"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2119323490",
                    "name": "Ling Chen"
                }
            ]
        },
        {
            "paperId": "3e90e30b2e8c11c4c459b32fbbe0cd0dbe95d2c3",
            "title": "Anomaly Detection under Distribution Shift",
            "abstract": "Anomaly detection (AD) is a crucial machine learning task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data. Most existing AD studiesassume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering existing AD methods ineffective in such cases. In this paper, we consider the problem of anomaly detection under distribution shift and establish performance benchmarks on four widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effectively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribution shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. Our extensive empirical results on the four datasets show that our approach substantially outperforms state-of-the-art AD methods and OOD generalization methods on data with various distribution shifts, while maintaining the detection accuracy on in-distribution data. Code and data are available at https://github.com/mala-lab/ADShift.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149281913",
                    "name": "T. Cao"
                },
                {
                    "authorId": "2109445463",
                    "name": "Jiawen Zhu"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                }
            ]
        },
        {
            "paperId": "4312617b8e7e0bcbf80876ebffddb6bd1d6ea7ac",
            "title": "Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection",
            "abstract": "We reveal a one-class homophily phenomenon, which is one prevalent property we find empirically in real-world graph anomaly detection (GAD) datasets, i.e., normal nodes tend to have strong connection/affinity with each other, while the homophily in abnormal nodes is significantly weaker than normal nodes. However, this anomaly-discriminative property is ignored by existing GAD methods that are typically built using a conventional anomaly detection objective, such as data reconstruction. In this work, we explore this property to introduce a novel unsupervised anomaly scoring measure for GAD, local node affinity, that assigns a larger anomaly score to nodes that are less affiliated with their neighbors, with the affinity defined as similarity on node attributes/representations. We further propose Truncated Affinity Maximization (TAM) that learns tailored node representations for our anomaly measure by maximizing the local affinity of nodes to their neighbors. Optimizing on the original graph structure can be biased by nonhomophily edges (i.e., edges connecting normal and abnormal nodes). Thus, TAM is instead optimized on truncated graphs where non-homophily edges are removed iteratively to mitigate this bias. The learned representations result in significantly stronger local affinity for normal nodes than abnormal nodes. Extensive empirical results on 10 real-world GAD datasets show that TAM substantially outperforms seven competing models, achieving over 10% increase in AUROC/AUPRC compared to the best contenders on challenging datasets. Our code is available at https://github.com/mala-lab/TAM-master/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065400224",
                    "name": "H. Qiao"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                }
            ]
        },
        {
            "paperId": "49f2805f478a7ea4372004a11b4533d25eb45e69",
            "title": "HRGCN: Heterogeneous Graph-level Anomaly Detection with Hierarchical Relation-augmented Graph Neural Networks",
            "abstract": "This work considers the problem of heterogeneous graph-level anomaly detection. Heterogeneous graphs are commonly used to represent behaviours between different types of entities in complex industrial systems for capturing as much information about the system operations as possible. Detecting anomalous heterogeneous graphs from a large set of system behaviour graphs is crucial for many real-world applications like online web/mobile service and cloud access control. To address the problem, we propose HRGCN, an unsupervised deep heterogeneous graph neural network, to model complex heterogeneous relations between different entities in the system for effectively identifying these anomalous behaviour graphs. HRGCN trains a hierarchical relation-augmented Heterogeneous Graph Neural Network (HetGNN), which learns better graph representations by modelling the interactions among all the system entities and considering both source-to-destination entity (node) types and their relation (edge) types. Extensive evaluation on two real-world application datasets shows that HRGCN outperforms state-of-the-art competing anomaly detection approaches. We further present a real-world industrial case study to justify the effectiveness of HRGCN in detecting anomalous (e.g., congested) network devices in a mobile communication service. HRGCN is available at https://github.com/jiaxililearn/HRGCN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130143234",
                    "name": "Jiaxi Li"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2119323490",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "1398392460",
                    "name": "Mohammad-Reza Namazi-Rad"
                }
            ]
        },
        {
            "paperId": "5e7fbb632a460db6e77299f9ee58cb282cb30477",
            "title": "Rethinking Homework in the Age of Artificial Intelligence",
            "abstract": "The evolution of natural language processing techniques has led to the development of advanced conversational tools such as ChatGPT, capable of assisting users with a variety of activities. Media attention has centered on ChatGPT\u2019s potential impact, policy implications, and ethical ramifications, particularly in the context of education. As such tools become more accessible, students across the globe may use them to assist with their homework. However, it is still unclear whether ChatGPT\u2019s performance is advanced enough to pose a serious risk of plagiarism. We fill this gap by evaluating ChatGPT on two introductory and two advanced university-level courses. We find that ChatGPT receives near-perfect grades on the majority of questions in the introductory courses but has not yet reached the level of sophistication required to pass in advanced courses. Moreover, adding a few full stops or typos may fool a machine learning algorithm designed to detect ChatGPT-generated text. These findings suggest that, at least for some courses, current artificial intelligence tools pose a real threat that can no longer be overlooked by educational institutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2054762578",
                    "name": "Hazem Ibrahim"
                },
                {
                    "authorId": "2157646582",
                    "name": "Rohail Asim"
                },
                {
                    "authorId": "1685939",
                    "name": "Fareed Zaffar"
                },
                {
                    "authorId": "1775071",
                    "name": "Talal Rahwan"
                },
                {
                    "authorId": "1749350",
                    "name": "Y. Zaki"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                }
            ]
        },
        {
            "paperId": "70672c29c0e48201e9d3e740255242e1a2fb4bf1",
            "title": "Anomaly Heterogeneity Learning for Open-Set Supervised Anomaly Detection",
            "abstract": "Open-set supervised anomaly detection (OSAD) - a recently emerging anomaly detection area - aims at utilizing a few samples of anomaly classes seen during training to de-tect unseen anomalies (i.e., samples from open-set anomaly classes), while effectively identifying the seen anomalies. Benefiting from the prior knowledge illustrated by the seen anomalies, current OSAD methods can often largely reduce false positive errors. However, these methods are trained in a closed-set setting and treat the anomaly examples as from a homogeneous distribution, rendering them less effective in generalizing to unseen anomalies that can be drawn from any distribution. This paper proposes to learn heterogeneous anomaly distributions using the limited anomaly examples to address this issue. To this end, we introduce a novel approach, namely Anomaly Heterogeneity Learning (AHL), that simulates a diverse set of heterogeneous anomaly distributions and then utilizes them to learn a unified heterogeneous abnormality model in surrogate open-set environments. Further, AHL is a generic framework that existing OSAD models can plug and play for enhancing their abnormality modeling. Extensive experiments on nine real-world anomaly detection datasets show that AHL can 1) substantially enhance different state-of-the-art OSAD models in detecting seen and unseen anomalies, and 2) effectively generalize to unseen anomalies in new domains. Code is available at https://github.com/mala-lab/AHL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260429137",
                    "name": "Jiawen Zhu"
                },
                {
                    "authorId": "2153255258",
                    "name": "Choubo Ding"
                },
                {
                    "authorId": "2260838219",
                    "name": "Yu Tian"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                }
            ]
        }
    ]
}