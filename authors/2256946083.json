{
    "authorId": "2256946083",
    "papers": [
        {
            "paperId": "bc78ffe2e9fcf89f7aae2e8b5c0960ae419e919f",
            "title": "Target Detection Adapting to Spectral Variability in Multi-Temporal Hyperspectral Images Using Implicit Contrastive Learning",
            "abstract": "Hyperspectral target detection (HTD) is a crucial aspect of remote sensing applications, aiming to identify targets in hyperspectral images (HSIs) based on their known prior spectral signatures. However, the spectral variability resulting from various imaging conditions in multi-temporal hyperspectral images poses a challenge to both classical and deep learning (DL) methods. To overcome the limitations imposed by spectral variability, an implicit contrastive learning-based target detector (ICLTD) is proposed to exploit in-scene spectra in an unsupervised way. First, only prior spectra are utilized for explicit supervision, while an implicit contrastive learning module (ICLM) is designed to normalize the feature distributions of prior and in-scene spectra. This paper theoretically demonstrates that the ICLM can transfer the gradients from prior spectral features to those of in-scene spectra based on their feature similarities and differences. Because of transferred gradient signals, the ICLTD is regularized to extract similar representations for the prior and in-scene target spectra, while augmenting feature differences between the target and background spectra. Additionally, a local spectral similarity constraint (LSSC) is proposed to enhance the capability of scene adaptation by leveraging the spectral similarities among in-scene targets. To validate the performance of the ICLTD under spectral variability, multi-temporal HSIs captured under various imaging conditions are collected to generate prior spectra and in-scene spectra. Comparative evaluations against several DL detectors and classical methods reveal the superior performance of the ICLTD in achieving a balance between target detectability and background suppressibility under spectral variability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2260820793",
                    "name": "Pengyu Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2051261924",
                    "name": "Xiaobin Zhao"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "d7f29f1d6a7ad4a612c17282ac17645085f81d20",
            "title": "Pixel- And Patch-Wise Context-Aware Learning with CNN and GCN Collaboration for Hyperspectral Image Classification",
            "abstract": "Graph convolutional network (GCN) gains increasing attention in the hyperspectral image (HSI) classification by the ability to flexibly capture arbitrarily irregular objects. However, due to expensive computation, the graph construction is usually based on superpixel-wise nodes, which ignore the subtle pixel-wise features. In contrast, the convolution neural network (CNN) can mine pixel-wise spectral-spatial features but is limited to capturing local features in small square windows. In this paper, we design a new CNN and GCN collaborative network to simultaneously introduce pixel- and patch-wise contextual information. Concretely, we use the depthwise separable convolution to perform pixel-wise local feature extraction. To further mine the long-range contextual information between land covers, we concatenate a GCN. Finally, we further fuse the complementary features and decode them to obtain the classification map. Extensive experiments reveal that our method achieves competitive performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "f74ebbd4860ee84e1e7257994194828cf1308eb6",
            "title": "PM2.5 Estimation in Day/Night-Time from Himawari-8 Infrared Bands via a Deep Learning Neural Network",
            "abstract": "Satellite-based PM2.5 estimation is an effective means to achieve large-scale and long-term PM2.5 monitoring and investigation. Currently, most of methods retrieve PM2.5 from satellite-derived aerosol optical depth (AOD) or top-of-atmosphere reflectance (TOAR) during daytime. A few algorithms are also developed to retrieve nighttime PM2.5 from the satellite day\u2013night band and the accuracy is greatly limited by moonlight and artificial light sources. In this study, we utilize the properties of absorption pollutants in infrared spectrum to estimate PM2.5 concentrations from satellite infrared data, thus achieve the PM2.5 estimation in both day and night. Himawari-8 infrared bands data are used for PM2.5 estimation by a specifically designed neural network and loss function. Quantitative results show the satellite derived PM2.5 concentrations correlates with ground-based data well with R2 of 0.79 and RMSE of 15.43 \u03bcg \u00b7 m\u22123 for hourly PM2.5 estimation. Spatiotemporal distributions of model-estimated PM2.5 over China are also analyzed, and exhibit a highly consistent with ground-based measurements. Dust storms, heavy air pollution and fire smoke events are examined to further demonstrate the efficacy of our model. Our method not only circumvents the intermediate retrievals of AOD, but also enables consistent estimation of PM2.5 concentrations during daytime and nighttime in real-time monitoring.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2256306487",
                    "name": "Xiuqing Hu"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2249665454",
                    "name": "Peng Zhang"
                }
            ]
        }
    ]
}