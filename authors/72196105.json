{
    "authorId": "72196105",
    "papers": [
        {
            "paperId": "6fdc4c963b48115282867b66992aa77aad00b793",
            "title": "\"What else can I do?\" Examining the Impact of Community Data on Adaptation and Quality of Reflection in an Educational Game",
            "abstract": "Adaptation, or ability and willingness to consider an alternative approach, is a critical component of learning through reflection, especially in educational games, where there are often multiple avenues to success. As a domain, educational games have shown increased interest in using retrospective visualizations to promote and support reflection. Such visualizations, which can facilitate comparison with peer data, may also have an impact on adaptation in educational games. This has, however, not been empirically examined within the domain. In this work, we examine how comparison with other players\u2019 data influenced adaptation, a part of reflection, in the context of a game that teaches parallel programming. Our results indicate that comparison with peers does significantly impact willingness to try a different approach, but suggest that there may also be other ways. We discuss what these results mean for future use of retrospective visualizations in educational games and present opportunities for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2252170",
                    "name": "Erica Kleinman"
                },
                {
                    "authorId": "1395852473",
                    "name": "Jennifer Villareale"
                },
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "1410306077",
                    "name": "Zhaoqing Teng"
                },
                {
                    "authorId": "2060005253",
                    "name": "Andy Bryant"
                },
                {
                    "authorId": "35187206",
                    "name": "Jichen Zhu"
                },
                {
                    "authorId": "1381933697",
                    "name": "M. S. El-Nasr"
                }
            ]
        },
        {
            "paperId": "087b7cd2be588e7e26997100261f0b1caf727c64",
            "title": "Kills, Deaths, and (Computational) Assists: Identifying Opportunities for Computational Support in Esport Learning",
            "abstract": "Esports play can cultivate real world skills. However, the path to mastery is not easy, and difficulty progressing can result in discontinuation. In the absence of a human coach, computational tools may provide much-needed guidance. However, the specific improvement activities that players engage in and the exact challenges they face are not well defined in the context of computational support. As such, most tools can only support players based on a high level understanding of their practices. We present the results of an interview study (n=17) that identified four improvement activities: practicing, leveraging the knowledge of others, tracking performance, and reflecting on gameplay and setting goals for the future, and four challenges: coordinating and collaborating with teammates, knowing what to do next, tracking game state, and tracking skill and improvement. We discuss six implications for future design and development based on these results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2252170",
                    "name": "Erica Kleinman"
                },
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "2089406153",
                    "name": "Magy Seif El-Nasr"
                }
            ]
        },
        {
            "paperId": "5148fd8f954c9d5f8f7f56df1cba60f59d6f7f9e",
            "title": "A Human-Centric Perspective on Model Monitoring",
            "abstract": "Predictive models are increasingly used to make various consequential decisions in high-stakes domains such as healthcare, finance, and policy. It becomes critical to ensure that these models make accurate predictions, are robust to shifts in the data, do not rely on spurious features, and do not unduly discriminate against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature. Such approaches need to be human-centered as they cater to the understanding of the models to their users. However, there is little to no research on understanding the needs and challenges in monitoring deployed machine learning (ML) models from a human-centric perspective. To address this gap, we conducted semi-structured interviews with 13 practitioners who are experienced with deploying ML models and engaging with customers spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants. We identified various human-centric challenges and requirements for model monitoring in real-world applications. Specifically, we found that relevant stakeholders would want model monitoring systems to provide clear, unambiguous, and easy-to-understand insights that are readily actionable. Furthermore, our study also revealed that stakeholders desire customization of model monitoring systems to cater to domain-specific use cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                }
            ]
        },
        {
            "paperId": "627eb0a59ecc446c476aa8a4077657d89b984144",
            "title": "Challenges and Research Directions in Crowdsourcing for Engineering Design: An Interview Study With Industry Professionals",
            "abstract": "Crowdsourcing is an emerging paradigm in engineering design for open innovation. It offers various benefits to crucial aspects of design innovation, such as generating diverse design ideas and engaging consumers. However, crowdsourcing initiatives for engineering design are prone to failures if the complex nature of engineering design processes is not accounted for. For example, the initiative can fail if design solutions do not achieve the required quality, which, in turn, is influenced by factors such as domain knowledge, problem complexity, and incentive structures. Thus, there lies a need to systematically design crowdsourcing initiatives. In this article, the authors build on an existing framework for designing crowdsourcing initiatives in an engineering design context. They do so, by conducting an interview study with industry professionals with product design experience. The authors investigate the challenges experienced by these professionals for adopting crowdsourcing initiatives for engineering design. Through the study, research opportunities are identified that expand and aid the adoption of the framework. The authors discuss relevant literature for the identified research directions and frame the research gaps that need to be pursued. The authors conclude by encouraging academic communities to pursue collaborative efforts toward enabling systematic design of crowdsourcing initiatives for engineering design.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "48199607",
                    "name": "H. Forbes"
                },
                {
                    "authorId": "46828166",
                    "name": "D. Schaefer"
                },
                {
                    "authorId": "1742411154",
                    "name": "H. Jitesh"
                },
                {
                    "authorId": "2096894278",
                    "name": "Panchal"
                }
            ]
        },
        {
            "paperId": "dfba12c15cf90d07e10f4f2dcfc2429706e3db30",
            "title": "A Human-Centric Take on Model Monitoring",
            "abstract": "Predictive models are increasingly used to make various consequential decisions in high-stakes domains such as healthcare, \ufb01nance, and policy. It becomes critical to ensure that these models make accurate predictions, are robust to shifts in the data, do not rely on spurious features, and do not unduly discriminate against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature. Such approaches need to be human-centered as they cater to the understanding of the models to their users. However, there is a research gap in understanding the human-centric needs and challenges of monitoring machine learning (ML) models once they are deployed . To \ufb01ll this gap, we conducted an interview study with 13 practitioners who have experience at the intersection of deploying ML models and engaging with customers spanning domains such as \ufb01nancial services, healthcare, hiring, online retail, computational advertising, and conversational assistants. We identi\ufb01ed various human-centric challenges and requirements for model monitoring in real-world applications. Speci\ufb01cally, we found the need and the challenge for the model monitoring systems to clarify the impact of the monitoring observations on outcomes. Further, such insights must be actionable, robust, customizable for domain-speci\ufb01c use cases, and cognitively considerate to avoid information overload.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                }
            ]
        },
        {
            "paperId": "f35790a1339184c13650a351a4596f1ab6dbfe7e",
            "title": "Analyzing Students' Problem-Solving Sequences: A Human-in-the-Loop Approach",
            "abstract": "Educational technology is shifting toward facilitating personalized learning. Such personalization, however, requires a detailed understanding of students\u2019 problem-solving processes. Sequence analysis (SA) is a promising approach to gaining granular insights into student problem solving; however, existing techniques are difficult to interpret because they offer little room for human input in the analysis process. Ultimately, in a learning context, a human stakeholder makes the decisions, so they should be able to drive the analysis process. In this paper, we present a human-in-the-loop approach to SA that uses visualization to allow a stakeholder to better understand both the data and the algorithm. We illustrate the method with a case study in the context of a learning game called Parallel. Results reveal six groups of students organized based on their problem-solving patterns and highlight individual differences within each group. We compare the results to a state-of-the-art method run with the same data and discuss the benefits of our method and the implications of this work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2252170",
                    "name": "Erica Kleinman"
                },
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "2089406153",
                    "name": "Magy Seif El-Nasr"
                },
                {
                    "authorId": "1410306077",
                    "name": "Zhaoqing Teng"
                },
                {
                    "authorId": "1395852473",
                    "name": "Jennifer Villareale"
                },
                {
                    "authorId": "2060005253",
                    "name": "Andy Bryant"
                },
                {
                    "authorId": "35187206",
                    "name": "Jichen Zhu"
                }
            ]
        },
        {
            "paperId": "0741506be2d30467b6ebe9cdb7018ab15a4467c3",
            "title": "Esports Agents with a Theory of Mind: Towards Better Engagement, Education, and Engineering",
            "abstract": "The role of AI in esports is shifting from leveraging games as a testbed for improving AI algorithms to addressing the needs of the esports players such as enhancing their gaming experience, esports skills, and providing coaching. For AI to be able to effectively address such needs in esports, AI agents require a theory of mind, that is, the ability to infer players' tactics and intents. To that end, in this position paper, we argue for human-in-the-loop approaches for the discovery and computational embedding of the theory of mind within behavioral models of esports players. We discuss that such approaches can be enabled by player-centric investigations on situated cognition that will expand our understanding of the cognitive and other unobservable factors that influence esports players' behaviors. We conclude by discussing the implications of such a research direction in esports as well as broader implications in engineering design and design education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "1381933697",
                    "name": "M. S. El-Nasr"
                }
            ]
        },
        {
            "paperId": "8eb2bb5f78b9595526287e78b50daad9134b3668",
            "title": "Can we infer player behavior tendencies from a player's decision-making data? Integrating Theory of Mind to Player Modeling",
            "abstract": "Game AI systems need the theory of mind, which is the humanistic ability to infer others' mental models, preferences, and intent. Such systems would enable inferring players' behavior tendencies that contribute to the variations in their decision-making behaviors. To that end, in this paper, we propose the use of inverse Bayesian inference to infer behavior tendencies given a descriptive cognitive model of a player's decision making. The model embeds behavior tendencies as weight parameters in a player's decision-making. Inferences on such parameters provide intuitive interpretations about a player's cognition while making in-game decisions. We illustrate the use of inverse Bayesian inference with synthetically generated data in a game called \\textit{BoomTown} developed by Gallup. We use the proposed model to infer a player's behavior tendencies for moving decisions on a game map. Our results indicate that our model is able to infer these parameters towards uncovering not only a player's decision making but also their behavior tendencies for making such decisions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "1410306077",
                    "name": "Zhaoqing Teng"
                },
                {
                    "authorId": "1381933697",
                    "name": "M. S. El-Nasr"
                }
            ]
        },
        {
            "paperId": "05b8e64a0e9ab02673558a5e51baab2e57698fb8",
            "title": "Human Inductive Biases in Design Decision Making",
            "abstract": "\n Designers make information acquisition decisions, such as where to search and when to stop the search. Such decisions are typically made sequentially, such that at every search step designers gain information by learning about the design space. However, when designers begin acquiring information, their decisions are primarily based on their prior knowledge. Prior knowledge influences the initial set of assumptions that designers use to learn about the design space. These assumptions are collectively termed as inductive biases. Identifying such biases can help us better understand how designers use their prior knowledge to solve problems in the light of uncertainty. Thus, in this study, we identify inductive biases in humans in sequential information acquisition tasks. To do so, we analyze experimental data from a set of behavioral experiments conducted in the past [1\u20135]. All of these experiments were designed to study various factors that influence sequential information acquisition behaviors. Across these studies, we identify similar decision making behaviors in the participants in their very first decision to \u201cchoose x\u201d. We find that their choices of \u201cx\u201d are not uniformly distributed in the design space. Since such experiments are abstractions of real design scenarios, it implies that further contextualization of such experiments would only increase the influence of these biases. Thus, we highlight the need to study the influence of such biases to better understand designer behaviors. We conclude that in the context of Bayesian modeling of designers\u2019 behaviors, utilizing the identified inductive biases would enable us to better model designer\u2019s priors for design search contexts as compared to using non-informative priors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                },
                {
                    "authorId": "1757039",
                    "name": "Jitesh H. Panchal"
                }
            ]
        },
        {
            "paperId": "77b5f5a1ad5aabfc212c4034da29737605a380fd",
            "title": "SEQUENTIAL INFORMATION ACQUISITION AND DECISION MAKING IN DESIGN CONTESTS: THEORETICAL AND EXPERIMENTAL STUDIES",
            "abstract": "The primary research question of this dissertation is, \\textit{How do contestants make sequential design decisions under the influence of competition?} To address this question, I study the influence of three factors, that can be controlled by the contest organizers, on the contestants' sequential information acquisition and decision-making behaviors. These factors are (i) a contestant's domain knowledge, (ii) framing of a design problem, and (iii) information about historical contests. The \\textit{central hypothesis} is that by conducting controlled behavioral experiments we can acquire data of contestant behaviors that can be used to calibrate computational models of contestants' sequential decision-making behaviors, thereby, enabling predictions about the design outcomes. The behavioral results suggest that (i) contestants better understand problem constraints and generate more feasible design solutions when a design problem is framed in a domain-specific context as compared to a domain-independent context, (ii) contestants' efforts to acquire information about a design artifact to make design improvements are significantly affected by the information provided to them about their opponent who is competing to achieve the same objectives, and (iii) contestants make information acquisition decisions such as when to stop acquiring information, based on various criteria such as the number of resources, the target objective value, and the observed amount of improvement in their design quality. Moreover, the threshold values of such criteria are influenced by the information the contestants have about their opponent. The results imply that (i) by understanding the influence of an individual's domain knowledge and framing of a problem we can provide decision-support tools to the contestants in engineering design contexts to better acquire problem-specific information (ii) we can enable contest designers to decide what information to share to improve the quality of the design outcomes of design contest, and (iii) from an educational standpoint, we can enable instructors to provide students with accurate assessments of their domain knowledge by understanding students' information acquisition and decision making behaviors in their design projects. The \\textit{primary contribution} of this dissertation is the computational models of an individual's sequential decision-making process that incorporate the behavioral results discussed above in competitive design scenarios. Moreover, a framework to conduct factorial investigations of human decision making through a combination of theory and behavioral experimentation is illustrated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72196105",
                    "name": "Murtuza N. Shergadwala"
                }
            ]
        }
    ]
}