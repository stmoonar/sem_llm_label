{
    "authorId": "1998921",
    "papers": [
        {
            "paperId": "d4751612225b6b730671e96228e04d9f4ebb8a2a",
            "title": "Fusion Approaches to Predict Post-stroke Aphasia Severity from Multimodal Neuroimaging Data",
            "abstract": "This paper explores feature selection and fusion methods for predicting the clinical outcome of post-stroke aphasia from medical imaging data. Utilizing a multimodal neu-roimaging dataset derived from 55 individuals with chronic aphasia resulting from left-hemisphere lesions following a stroke, two distinct approaches, namely Early Fusion and Late Fusion, were developed using Support Vector Regression or Random Forest regression models for prognosticating patients\u2019 functional communication skills measured by Western Aphasia Battery (WAB) test scores. A supervised learning method is proposed to reduce the number of features derived from each imaging modality. The fusion approaches were then applied to find combinations of these reduced feature sets that yield the most accurate WAB predictions. The same nested training/validation/test sets were used for the feature selection and fusion methods. Experiments showed that the best model based on the correlation metric is a Late Fusion RF model (r=0.63), while the best model based on the RMSE is an Early Fusion SVR model (RMSE=16.72). Experiments also revealed several feature set combinations that yielded more accurate predictions than both single-modality feature sets and feature sets that combine all modalities, justifying both fusion and reduction of features derived from multimodal neuroimaging data. It was also found that the percentage of tissue in gray matter regions of the brain, spared by the stroke as identified on structural Magnetic Resonance Imaging, is the single feature set that appeared in all highest ranked feature set combinations of both fusion approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189466156",
                    "name": "Saurav Chennuri"
                },
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "1485910247",
                    "name": "Anne Billot"
                },
                {
                    "authorId": "3730107",
                    "name": "M. Varkanitsa"
                },
                {
                    "authorId": "152606129",
                    "name": "Emily J Braun"
                },
                {
                    "authorId": "2242026443",
                    "name": "Swathi Kiran"
                },
                {
                    "authorId": "2242031740",
                    "name": "Archana Venkataraman"
                },
                {
                    "authorId": "2242030160",
                    "name": "Janusz Konrad"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                }
            ]
        },
        {
            "paperId": "c017ca4b90ac06e641269a9e8a29feaa655d4b9d",
            "title": "The Machine Learning for Combinatorial Optimization Competition (ML4CO): Results and Insights",
            "abstract": "Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have focused on solving problem instances in isolation, ignoring that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning as a new approach for solving combinatorial problems, either directly as solvers or by enhancing exact solvers. Based on this context, the ML4CO aims at improving state-of-the-art combinatorial optimization solvers by replacing key heuristic components. The competition featured three challenging tasks: finding the best feasible solution, producing the tightest optimality certificate, and giving an appropriate solver configuration. Three realistic datasets were considered: balanced item placement, workload apportionment, and maritime inventory routing. This last dataset was kept anonymous for the contestants.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2001205298",
                    "name": "Maxime Gasse"
                },
                {
                    "authorId": "1907863",
                    "name": "Quentin Cappart"
                },
                {
                    "authorId": "52039940",
                    "name": "J. Charfreitag"
                },
                {
                    "authorId": "1778839",
                    "name": "Laurent Charlin"
                },
                {
                    "authorId": "2066421682",
                    "name": "Didier Ch'etelat"
                },
                {
                    "authorId": "2055029609",
                    "name": "Antonia Chmiela"
                },
                {
                    "authorId": "2008816156",
                    "name": "Justin Dumouchelle"
                },
                {
                    "authorId": "2082044",
                    "name": "Ambros M. Gleixner"
                },
                {
                    "authorId": "3089515",
                    "name": "Aleksandr M. Kazachkov"
                },
                {
                    "authorId": "35252180",
                    "name": "Elias Boutros Khalil"
                },
                {
                    "authorId": "3064441",
                    "name": "Pawel Lichocki"
                },
                {
                    "authorId": "144390922",
                    "name": "Andrea Lodi"
                },
                {
                    "authorId": "4780977",
                    "name": "Miles Lubin"
                },
                {
                    "authorId": "2772217",
                    "name": "Chris J. Maddison"
                },
                {
                    "authorId": "143622465",
                    "name": "Christopher Morris"
                },
                {
                    "authorId": "2711174",
                    "name": "Dimitri J. Papageorgiou"
                },
                {
                    "authorId": "2113388008",
                    "name": "Augustin Parjadis"
                },
                {
                    "authorId": "145729210",
                    "name": "S. Pokutta"
                },
                {
                    "authorId": "51902590",
                    "name": "Antoine Prouvost"
                },
                {
                    "authorId": "2094332638",
                    "name": "Lara Scavuzzo"
                },
                {
                    "authorId": "46235370",
                    "name": "Giulia Zarpellon"
                },
                {
                    "authorId": "2157429547",
                    "name": "Linxin Yangm"
                },
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "2259607784",
                    "name": "Akang Wang"
                },
                {
                    "authorId": "2115826657",
                    "name": "Xiaodong Luo"
                },
                {
                    "authorId": "2140151616",
                    "name": "Xiang Zhou"
                },
                {
                    "authorId": "153233799",
                    "name": "Haohan Huang"
                },
                {
                    "authorId": "2145876857",
                    "name": "Sheng\u00a0Cheng Shao"
                },
                {
                    "authorId": "2117042163",
                    "name": "Yuanming Zhu"
                },
                {
                    "authorId": "2109797878",
                    "name": "Dong Zhang"
                },
                {
                    "authorId": "2144919868",
                    "name": "T. Quan"
                },
                {
                    "authorId": "145342849",
                    "name": "Zixuan Cao"
                },
                {
                    "authorId": "115986457",
                    "name": "Yang Xu"
                },
                {
                    "authorId": "2151326157",
                    "name": "Zhewei Huang"
                },
                {
                    "authorId": "35132667",
                    "name": "Shuchang Zhou"
                },
                {
                    "authorId": "21172076",
                    "name": "C. Binbin"
                },
                {
                    "authorId": "2157431035",
                    "name": "He Minggui"
                },
                {
                    "authorId": "2065509138",
                    "name": "Hao Hao"
                },
                {
                    "authorId": "3056881",
                    "name": "Zhang Zhiyu"
                },
                {
                    "authorId": "2157429620",
                    "name": "An Zhiwu"
                },
                {
                    "authorId": "52624926",
                    "name": "M. Kun"
                }
            ]
        },
        {
            "paperId": "ef1254bd0630b3d826371f941d4dfc9382e9a071",
            "title": "An Unsupervised Approach to Discover Media Frames",
            "abstract": "Media framing refers to highlighting certain aspect of an issue in the news to promote a particular interpretation to the audience. Supervised learning has often been used to recognize frames in news articles, requiring a known pool of frames for a particular issue, which must be identified by communication researchers through thorough manual content analysis. In this work, we devise an unsupervised learning approach to discover the frames in news articles automatically. Given a set of news articles for a given issue, e.g., gun violence, our method first extracts frame elements from these articles using related Wikipedia articles and the Wikipedia category system. It then uses a community detection approach to identify frames from these frame elements. We discuss the effectiveness of our approach by comparing the frames it generates in an unsupervised manner to the domain-expert-derived frames for the issue of gun violence, for which a supervised learning model for frame recognition exists.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "144824029",
                    "name": "Yanru Jiang"
                },
                {
                    "authorId": "2110797784",
                    "name": "Lei Guo"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "2129412",
                    "name": "D. Wijaya"
                }
            ]
        },
        {
            "paperId": "8f3507a18d78ea6efbf7221306fa14600ca9e943",
            "title": "An Exploration of Machine Learning Methods for Predicting Post-stroke Aphasia Recovery",
            "abstract": "Predicting the potential recovery outcome of post-stroke aphasia remains a challenging task. Our previous work[10] applied machine learning algorithms to predict participant response to therapy using a complex set of brain and behavioral data in individuals with post-stroke aphasia. The present work explores the additional predictive value of cognitive composite scores (CS), which measure visuo-spatial processing and verbal working memory; high-dimensional resting-state (RS) functional magnetic resonance imaging (fMRI) data, which measures the functional connectivity between brain regions; and diffusion tensor imaging (DTI) data, which provides information related to microstructural integrity via fractional anisotropy (FA) values. We first perform feature selection on the RS data as it has about 5 times more features than than all the other feature-sets combined. Next, we append these RS features, CS scores, and FA values to our existing data set. Finally, we train Support Vector Machine (SVM) and Random Forest (RF) classifiers for various combinations of feature-sets and compare their performance in terms of accuracy, F1-score, sensitivity and selectivity. Results show that combinations of feature-sets outperform most individual feature-sets and whereas each feature-set is present among the top 20 combinations, many of them contain RS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "1485910247",
                    "name": "Anne Billot"
                },
                {
                    "authorId": "3730107",
                    "name": "M. Varkanitsa"
                },
                {
                    "authorId": "152606129",
                    "name": "Emily J Braun"
                },
                {
                    "authorId": "2234560",
                    "name": "B. Rapp"
                },
                {
                    "authorId": "1779590",
                    "name": "T. Parrish"
                },
                {
                    "authorId": "3185730",
                    "name": "Ajay S. Kurani"
                },
                {
                    "authorId": "2056806541",
                    "name": "James Higgins"
                },
                {
                    "authorId": "2071357151",
                    "name": "D. Caplan"
                },
                {
                    "authorId": "144721942",
                    "name": "C. Thompson"
                },
                {
                    "authorId": "32459665",
                    "name": "S. Kiran"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                }
            ]
        },
        {
            "paperId": "9105ca6940f765bc3865c6b4ebd074e1c5bb006d",
            "title": "Accurate, Fast, But Not Always Cheap: Evaluating \u201cCrowdcoding\u201d as an Alternative Approach to Analyze Social Media Data",
            "abstract": "Crowdcoding, a method that outsources \u201ccoding\u201d tasks to numerous people on the internet, has emerged as a popular approach for annotating texts and visuals. However, the performance of this approach for analyzing social media data in the context of journalism and mass communication research has not been systematically assessed. This study evaluated the validity and efficiency of crowdcoding based on the analysis of 4,000 tweets about the 2016 U.S. presidential election. The results show that compared with the traditional quantitative content analysis, crowdcoding yielded comparably valid results and was superior in efficiency, but was more expensive under most circumstances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46845996",
                    "name": "Lei Guo"
                },
                {
                    "authorId": "3451534",
                    "name": "Kate K. Mays"
                },
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "47801182",
                    "name": "Mona Jalal"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                }
            ]
        },
        {
            "paperId": "fd52fcf3f1ac9ec68ce9ac37a71e18581b250650",
            "title": "A machine learning approach for predicting post-stroke aphasia recovery: a pilot study",
            "abstract": "The potential recovery of post-stroke aphasia is highly variable and the rehabilitation outcomes are difficult to predict. This interdisciplinary collaboration builds on data collected as part of a large set of behavioral and brain variables in patients with post-stroke aphasia, charting the course of recovery associated with therapy across language domains and examining the basis of neuroplasticity. In this pilot study, we created and tested a predictive framework based on a subset of the data collected and developed machine-learning algorithms that take as input a complex set of brain and behavioral features to classify and predict the participants' responsiveness to therapy. We developed Random Forest models that enabled us to rank the importance of these features. We then compared the contributions of different feature sets and discussed their physiological implications. Our preliminary results suggest the potential of our framework, and, thus, this study takes an important first step towards predicting individualized rehabilitation outcomes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46964309",
                    "name": "Yiwen Gu"
                },
                {
                    "authorId": "1780608806",
                    "name": "Murtadha Bahrani"
                },
                {
                    "authorId": "1485910247",
                    "name": "Anne Billot"
                },
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "152606129",
                    "name": "Emily J Braun"
                },
                {
                    "authorId": "3730107",
                    "name": "M. Varkanitsa"
                },
                {
                    "authorId": "1780507152",
                    "name": "Julia Bighetto"
                },
                {
                    "authorId": "2234560",
                    "name": "B. Rapp"
                },
                {
                    "authorId": "1779590",
                    "name": "T. Parrish"
                },
                {
                    "authorId": "2071357151",
                    "name": "D. Caplan"
                },
                {
                    "authorId": "144721942",
                    "name": "C. Thompson"
                },
                {
                    "authorId": "32459665",
                    "name": "S. Kiran"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                }
            ]
        },
        {
            "paperId": "3794d16052809611365eb4b87e32ccf017877152",
            "title": "BUOCA: Budget-Optimized Crowd Worker Allocation",
            "abstract": "Due to concerns about human error in crowdsourcing, it is standard practice to collect labels for the same data point from multiple internet workers. We here show that the resulting budget can be used more effectively with a flexible worker assignment strategy that asks fewer workers to analyze easy-to-label data and more workers to analyze data that requires extra scrutiny. Our main contribution is to show how the allocations of the number of workers to a task can be computed optimally based on task features alone, without using worker profiles. Our target tasks are delineating cells in microscopy images and analyzing the sentiment toward the 2016 U.S. presidential candidates in tweets. We first propose an algorithm that computes budget-optimized crowd worker allocation (BUOCA). We next train a machine learning system (BUOCA-ML) that predicts an optimal number of crowd workers needed to maximize the accuracy of the labeling. We show that the computed allocation can yield large savings in the crowdsourcing budget (up to 49 percent points) while maintaining labeling accuracy. Finally, we envisage a human-machine system for performing budget-optimized data analysis at a scale beyond the feasibility of crowdsourcing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "1998921",
                    "name": "Sha Lai"
                },
                {
                    "authorId": "3451534",
                    "name": "Kate K. Mays"
                },
                {
                    "authorId": "2110797784",
                    "name": "Lei Guo"
                },
                {
                    "authorId": "1756038",
                    "name": "P. Ishwar"
                },
                {
                    "authorId": "1723703",
                    "name": "Margrit Betke"
                }
            ]
        }
    ]
}