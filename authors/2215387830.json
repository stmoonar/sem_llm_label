{
    "authorId": "2215387830",
    "papers": [
        {
            "paperId": "3420a593756c15ce90189ea0f41a9320f7de5591",
            "title": "CapAlign: Improving Cross Modal Alignment via Informative Captioning for Harmful Meme Detection",
            "abstract": "Harmful memes detection is challenging due to the semantic gap between different modalities. Previous studies mainly focus on feature extraction and fusion to learn discriminative information from memes. However, they ignore the misalignment of the modalities caused by the modality gap and suffer from data scarcity, resulting in insufficient learning of fusion-based models. Recently, researchers transformed images into textual captions and used language models for predictions, resulting in non-informative image captions. To address these gaps, this paper proposes an instructions-based abstracting approach CapAlign, in zero-shot visual question-answering settings. Precisely, we prompt a large language model (LLM) to ask informative questions to a pre-trained vision-language model and use the dialogues to generate a high-quality image caption. Further, to align the generated caption with the textual content of a meme, we used an LLM with instructions to generate informative captions of the meme and then prepend it with the attributes of the visual content of a meme to a prompt-based LM for prediction. Experimental findings on two benchmark datasets show that our approach produces informative captions and outperforms state-of-the-art methods for detecting harmful memes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215387830",
                    "name": "Junhui Ji"
                },
                {
                    "authorId": "2300408961",
                    "name": "Xuanrui Lin"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "df870cbb16212a545b84cad2146927cbc241d9e0",
            "title": "Identifying Creative Harmful Memes via Prompt based Approach",
            "abstract": "The creative nature of memes has made it possible for harmful content to spread quickly and widely on the internet. Harmful memes can range from spreading hate speech promoting violence, and causing emotional distress to individuals or communities. These memes are often designed to be misleading, manipulative, and controversial, making it challenging to detect and remove them from online platforms. Previous studies focused on how to fuse visual and language modalities to capture contextual information. However, meme analysis still severely suffers from data deficiency, resulting in insufficient learning of fusion modules. Further, using conventional pretrained encoders for text and images exhibits a greater semantic gap in feature spaces and leads to low performance. To address these gaps, this paper reformulates a harmful meme analysis as an auto-filling and presents a prompt-based approach to identify harmful memes. Specifically, we first transform multimodal data to a single (i.e., textual) modality by generating the captions and attributes of the visual data and then prepend the textual data in the prompt-based pre-trained language model. Experimental results on two benchmark harmful memes datasets demonstrate that our method outperformed state-of-the-art methods. We conclude with the transferability and robustness of our approach to identify creative harmful memes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215387830",
                    "name": "Junhui Ji"
                },
                {
                    "authorId": "2053308398",
                    "name": "Wei Ren"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                }
            ]
        }
    ]
}