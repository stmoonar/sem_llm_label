{
    "authorId": "1682418",
    "papers": [
        {
            "paperId": "09f43150f01824ddd2bcc56629f87e26df57b0c3",
            "title": "Sharpness-Aware Data Poisoning Attack",
            "abstract": "Recent research has highlighted the vulnerability of Deep Neural Networks (DNNs) against data poisoning attacks. These attacks aim to inject poisoning samples into the models' training dataset such that the trained models have inference failures. While previous studies have executed different types of attacks, one major challenge that greatly limits their effectiveness is the uncertainty of the re-training process after the injection of poisoning samples, including the re-training initialization or algorithms. To address this challenge, we propose a novel attack method called ''Sharpness-Aware Data Poisoning Attack (SAPA)''. In particular, it leverages the concept of DNNs' loss landscape sharpness to optimize the poisoning effect on the worst re-trained model. It helps enhance the preservation of the poisoning effect, regardless of the specific retraining procedure employed. Extensive experiments demonstrate that SAPA offers a general and principled strategy that significantly enhances various types of poisoning attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2049444216",
                    "name": "P. He"
                },
                {
                    "authorId": "46485412",
                    "name": "Han Xu"
                },
                {
                    "authorId": "143702207",
                    "name": "J. Ren"
                },
                {
                    "authorId": "2218740984",
                    "name": "Yingqian Cui"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2115879611",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "109d9859c4e99188c1d4f4b71d2570a3bf017e75",
            "title": "Heterogeneous Social Event Detection via Hyperbolic Graph Representations",
            "abstract": "Social events reflect the dynamics of society and, here, natural disasters and emergencies receive significant attention. The timely detection of these events can provide organisations and individuals with valuable information to reduce or avoid losses. However, due to the complex heterogeneities of the content and structure of social media, existing models can only learn limited information; large amounts of semantic and structural information are ignored. In addition, due to high labour costs, it is rare for social media datasets to include high-quality labels, which also makes it challenging for models to learn information from social media. In this study, we propose two hyperbolic graph representation-based methods for detecting social events from heterogeneous social media environments. For cases where a dataset has labels, we designed a Hyperbolic Social Event Detection (HSED) model that converts complex social information into a unified social message graph. This model addresses the heterogeneity of social media, and, with this graph, the information in social media can be used to capture structural information based on the properties of hyperbolic space. For cases where the dataset is unlabelled, we designed an Unsupervised Hyperbolic Social Event Detection (UHSED). This model is based on the HSED model but includes graph contrastive learning to make it work in unlabelled scenarios. Extensive experiments demonstrate the superiority of the proposed approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2208967342",
                    "name": "Zitai Qiu"
                },
                {
                    "authorId": "2142734769",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "2118801701",
                    "name": "Jian Yang"
                },
                {
                    "authorId": "2106353243",
                    "name": "Xing Su"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                }
            ]
        },
        {
            "paperId": "5ff8c0c4c8de76e0e925fe716d0411d3e74653fc",
            "title": "A Comprehensive Survey of Graph-level Learning",
            "abstract": "\u2014Graphs have a superior ability to represent relational data, like chemical compounds, proteins, and social networks. Hence, graph-level learning, which takes a set of graphs as input, has been applied to many tasks including comparison, regression, classi\ufb01cation, and more. Traditional approaches to learning a set of graphs tend to rely on hand-crafted features, such as substructures. But while these methods bene\ufb01t from good interpretability, they often suffer from computational bottlenecks as they cannot skirt the graph isomorphism problem. Conversely, deep learning has helped graph-level learning adapt to the growing scale of graphs by extracting features automatically and decoding graphs into low-dimensional representations. As a result, these deep graph learning methods have been responsible for many successes. Yet, there is no comprehensive survey that reviews graph-level learning starting with traditional learning and moving through to the deep learning approaches. This article \ufb01lls this gap and frames the representative algorithms into a systematic taxonomy covering traditional learning, graph-level deep neural networks, graph-level graph neural networks, and graph pooling. To ensure a thoroughly comprehensive survey, the evolutions, interactions, and communications between methods from four different branches of development are also examined. This is followed by a brief review of the benchmark data sets, evaluation metrics, and common downstream applications. The survey concludes with 13 future directions of necessary research that will help to overcome the challenges facing this booming \ufb01eld.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152747612",
                    "name": "Zhenyu Yang"
                },
                {
                    "authorId": "2151251543",
                    "name": "Ge Zhang"
                },
                {
                    "authorId": "2142734769",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "2118801701",
                    "name": "Jian Yang"
                },
                {
                    "authorId": "120607997",
                    "name": "Quan.Z Sheng"
                },
                {
                    "authorId": "2057237074",
                    "name": "Shan Xue"
                },
                {
                    "authorId": "2110713858",
                    "name": "Chuan Zhou"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2146226874",
                    "name": "Wenbin Hu"
                },
                {
                    "authorId": "2064408469",
                    "name": "Edwin R. Hancock"
                },
                {
                    "authorId": "2075355155",
                    "name": "Pietro Lio'"
                }
            ]
        },
        {
            "paperId": "6c7796ba7f04c77d888bf6b65d3498abfacfe71a",
            "title": "State of the Art and Potentialities of Graph-level Learning",
            "abstract": "Graphs have a superior ability to represent relational data, like chemical compounds, proteins, and social networks. Hence, graph-level learning, which takes a set of graphs as input, has been applied to many tasks including comparison, regression, classification, and more. Traditional approaches to learning a set of graphs heavily rely on hand-crafted features, such as substructures. While these methods benefit from good interpretability, they often suffer from computational bottlenecks as they cannot skirt the graph isomorphism problem. Conversely, deep learning has helped graph-level learning adapt to the growing scale of graphs by extracting features automatically and encoding graphs into low-dimensional representations. As a result, these deep graph learning methods have been responsible for many successes. Yet, no comprehensive survey reviews graph-level learning starting with traditional learning and moving through to the deep learning approaches. This article fills this gap and frames the representative algorithms into a systematic taxonomy covering traditional learning, graph-level deep neural networks, graph-level graph neural networks, and graph pooling. In addition, the evolution and interaction between methods from these four branches within their developments are examined to provide an in-depth analysis. This is followed by a brief review of the benchmark datasets, evaluation metrics, and common downstream applications. Finally, the survey concludes with an in-depth discussion of 12 current and future directions in this booming field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149233069",
                    "name": "Zhenyu Yang"
                },
                {
                    "authorId": "2151251543",
                    "name": "Ge Zhang"
                },
                {
                    "authorId": "2142734769",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "2118801701",
                    "name": "Jian Yang"
                },
                {
                    "authorId": "120607997",
                    "name": "Quan.Z Sheng"
                },
                {
                    "authorId": "2057237074",
                    "name": "Shan Xue"
                },
                {
                    "authorId": "1857210",
                    "name": "Chuan Zhou"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2146226874",
                    "name": "Wenbin Hu"
                },
                {
                    "authorId": "2064408469",
                    "name": "Edwin R. Hancock"
                },
                {
                    "authorId": "2075355155",
                    "name": "Pietro Lio'"
                }
            ]
        },
        {
            "paperId": "d2dc5f3e7ce45d25b8133f50db84eda9c3035404",
            "title": "Automated Feature Selection: A Reinforcement Learning Perspective",
            "abstract": "Feature selection is a critical step in machine learning that selects the most important features for a subsequent prediction task. Effective feature selection can help to reduce dimensionality, improve prediction accuracy, and increase result comprehensibility. It is traditionally challenging to find the optimal feature subset from the feature subset space as the space could be very large. While much effort has been made on feature selection, reinforcement learning can provide a new perspective towards a more globally-optimal searching strategy. In the preliminary work, we propose a multi-agent reinforcement learning framework for the feature selection problem. Specifically, we first reformulate feature selection with a reinforcement learning framework by regarding each feature as an agent. Besides, we obtain the state of the environment in three ways, i.e., statistic description, autoencoder, and graph convolutional network (GCN), in order to derive a fixed-length state representation as the input of reinforcement learning. In addition, we study how the coordination among feature agents can be improved by a more effective reward scheme. Also, we provide a GMM-based generative rectified sampling strategy to accelerate the convergence of multi-agent reinforcement learning. Our method searches the feature subset space more globally and can be easily adapted to real-time scenarios due to the nature of reinforcement learning. In the extended version, we further accelerate the framework from two aspects. From the sampling aspect, we show the indirect acceleration by proposing a rank-based softmax sampling strategy. From the exploration aspect, we show the direct acceleration by proposing an interactive reinforcement learning (IRL)-based exploration strategy. Extensive experimental results show the significant improvement of the proposed method over conventional approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "2148926829",
                    "name": "Le Wu"
                },
                {
                    "authorId": "2108673315",
                    "name": "Xiaolin Li"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2152081288",
                    "name": "H. Xiong"
                }
            ]
        },
        {
            "paperId": "ea3ecb8b809e7d5ae1bbc267863c0c4e72401a68",
            "title": "A Survey on Explainability of Graph Neural Networks",
            "abstract": "Graph neural networks (GNNs) are powerful graph-based deep-learning models that have gained significant attention and demonstrated remarkable performance in various domains, including natural language processing, drug discovery, and recommendation systems. However, combining feature information and combinatorial graph structures has led to complex non-linear GNN models. Consequently, this has increased the challenges of understanding the workings of GNNs and the underlying reasons behind their predictions. To address this, numerous explainability methods have been proposed to shed light on the inner mechanism of the GNNs. Explainable GNNs improve their security and enhance trust in their recommendations. This survey aims to provide a comprehensive overview of the existing explainability techniques for GNNs. We create a novel taxonomy and hierarchy to categorize these methods based on their objective and methodology. We also discuss the strengths, limitations, and application scenarios of each category. Furthermore, we highlight the key evaluation metrics and datasets commonly used to assess the explainability of GNNs. This survey aims to assist researchers and practitioners in understanding the existing landscape of explainability methods, identifying gaps, and fostering further advancements in interpretable graph-based machine learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2219548757",
                    "name": "Jaykumar Kakkad"
                },
                {
                    "authorId": "2219549243",
                    "name": "Jaspal Jannu"
                },
                {
                    "authorId": "1571168324",
                    "name": "Kartik Sharma"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "3390598",
                    "name": "Sourav Medya"
                }
            ]
        },
        {
            "paperId": "f4e18d4aefc1ee0f88f0bb09fa5c17c74aad767e",
            "title": "Counterfactual Learning on Graphs: A Survey",
            "abstract": "Graph-structured data are pervasive in the real-world such as social networks, molecular graphs and transaction networks. Graph neural networks (GNNs) have achieved great success in representation learning on graphs, facilitating various downstream tasks. However, GNNs have several drawbacks such as lacking interpretability, can easily inherit the bias of data and cannot model casual relations. Recently, counterfactual learning on graphs has shown promising results in alleviating these drawbacks. Various approaches have been proposed for counterfactual fairness, explainability, link prediction and other applications on graphs. To facilitate the development of this promising direction, in this survey, we categorize and comprehensively review papers on graph counterfactual learning. We divide existing methods into four categories based on problems studied. For each category, we provide background and motivating examples, a general framework summarizing existing works and a detailed review of these works. We point out promising future research directions at the intersection of graph-structured data, counterfactual learning, and real-world applications. To offer a comprehensive view of resources for future studies, we compile a collection of open-source implementations, public datasets, and commonly-used evaluation metrics. This survey aims to serve as a ``one-stop-shop'' for building a unified understanding of graph counterfactual learning categories and current resources. We also maintain a repository for papers and resources and will keep updating the repository https://github.com/TimeLovercc/Awesome-Graph-Causal-Learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149465392",
                    "name": "Zhimeng Guo"
                },
                {
                    "authorId": "33664431",
                    "name": "Teng Xiao"
                },
                {
                    "authorId": "2284641919",
                    "name": "Zongyu Wu"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2116430057",
                    "name": "Suhang Wang"
                }
            ]
        },
        {
            "paperId": "fcf1badf515d74d8ee40fa8e6c64f5464da90c74",
            "title": "Towards Label Position Bias in Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for semi-supervised node classification tasks. However, recent studies have revealed various biases in GNNs stemming from both node features and graph topology. In this work, we uncover a new bias - label position bias, which indicates that the node closer to the labeled nodes tends to perform better. We introduce a new metric, the Label Proximity Score, to quantify this bias, and find that it is closely related to performance disparities. To address the label position bias, we propose a novel optimization framework for learning a label position unbiased graph structure, which can be applied to existing GNNs. Extensive experiments demonstrate that our proposed method not only outperforms backbone methods but also significantly mitigates the issue of label position bias in GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2124928119",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "122710522",
                    "name": "Feng Shi"
                },
                {
                    "authorId": "2937550",
                    "name": "MohamadAli Torkamani"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "188aa3d4e7bf862e0aadc0fbc1ec203097d89aca",
            "title": "Self-supervised Short-text Modeling through Auxiliary Context Generation",
            "abstract": "Short text is ambiguous and often relies predominantly on the domain and context at hand in order to attain semantic relevance. Existing classification models perform poorly on short text due to data sparsity and inadequate context. Auxiliary context, which can often provide sufficient background regarding the domain, is typically available in several application scenarios. While some of the existing works aim to leverage real-world knowledge to enhance short-text representations, they fail to place appropriate emphasis on the auxiliary context. Such models do not harness the full potential of the available context in auxiliary sources. To address this challenge, we reformulate short-text classification as a dual channel self-supervised learning problem (that leverages auxiliary context) with a generation network and a corresponding prediction model. We propose a self-supervised framework, Pseudo-Auxiliary Context generation network for Short-text Modeling (PACS), to comprehensively leverage auxiliary context and it is jointly learned with a prediction network in an end-to-end manner. Our PACS model consists of two sub-networks: a Context Generation Network (CGN) that models the auxiliary context\u2019s distribution and a Prediction Network (PN) to map the short-text features and auxiliary context distribution to the final class label. Our experimental results on diverse datasets demonstrate that PACS outperforms formidable state-of-the-art baselines. We also demonstrate the performance of our model on cold-start scenarios (where contextual information is non-existent) during prediction. Furthermore, we perform interpretability and ablation studies to analyze various representational features captured by our model and the individual contribution of its modules to the overall performance of PACS, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2726036",
                    "name": "Nurendra Choudhary"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                }
            ]
        },
        {
            "paperId": "1c31db01ef955b05e022bf0101a2db4830b2b9bd",
            "title": "DAGAD: Data Augmentation for Graph Anomaly Detection",
            "abstract": "Graph anomaly detection in this paper aims to distinguish abnormal nodes that behave differently from the benign ones accounting for the majority of graph-structured instances. Receiving increasing attention from both academia and industry, yet existing research on this task still suffers from two critical issues when learning informative anomalous behavior from graph data. For one thing, anomalies are usually hard to capture because of their subtle abnormal behavior and the shortage of background knowledge about them, which causes severe anomalous sample scarcity. Meanwhile, the overwhelming majority of objects in real-world graphs are normal, bringing the class imbalance problem as well. To bridge the gaps, this paper devises a novel Data Augmentation-based Graph Anomaly Detection (DAGAD) framework for attributed graphs, equipped with three specially designed modules: 1) an information fusion module employing graph neural network encoders to learn representations, 2) a graph data augmentation module that fertilizes the training set with generated samples, and 3) an imbalance-tailored learning module to discriminate the distributions of the minority (anomalous) and majority (normal) classes. A series of experiments on three datasets prove that DAGAD outperforms ten state-of-the-art baseline detectors concerning various mostly-used metrics, together with an extensive ablation study validating the strength of our proposed modules.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "20893416",
                    "name": "Fanzhen Liu"
                },
                {
                    "authorId": "2115722071",
                    "name": "Xiaoxiao Ma"
                },
                {
                    "authorId": "2142734769",
                    "name": "Jia Wu"
                },
                {
                    "authorId": null,
                    "name": "Jian Yang"
                },
                {
                    "authorId": "2057237074",
                    "name": "Shan Xue"
                },
                {
                    "authorId": "24901061",
                    "name": "A. Beheshti"
                },
                {
                    "authorId": "1857210",
                    "name": "Chuan Zhou"
                },
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "120607997",
                    "name": "Quan.Z Sheng"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                }
            ]
        }
    ]
}