{
    "authorId": "2263564996",
    "papers": [
        {
            "paperId": "0bf001a7cec990dabadf4b9fb428a0520ba836cc",
            "title": "FairLabel: Correcting Bias in Labels",
            "abstract": "There are several algorithms for measuring fairness of ML models. A fundamental assumption in these approaches is that the ground truth is fair or unbiased. In real-world datasets, however, the ground truth often contains data that is a result of historical and societal biases and discrimination. Models trained on these datasets will inherit and propagate the biases to the model outputs. We propose FairLabel, an algorithm which detects and corrects biases in labels. The goal of FairLabel is to reduce the Disparate Impact (DI) across groups while maintaining high accuracy in predictions. We propose metrics to measure the quality of bias correction and validate FairLabel on synthetic datasets and show that the label correction is correct 86.7% of the time vs. 71.9% for a baseline model. We also apply FairLabel on benchmark datasets such as UCI Adult, German Credit Risk, and Compas datasets and show that the Disparate Impact Ratio increases by as much as 54.2%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                },
                {
                    "authorId": "2263564996",
                    "name": "Hien Pham"
                }
            ]
        }
    ]
}