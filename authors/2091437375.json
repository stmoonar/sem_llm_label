{
    "authorId": "2091437375",
    "papers": [
        {
            "paperId": "385805acfaa108ced2d7e8d32845c18502ef1628",
            "title": "Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions",
            "abstract": "As LLMs continuously evolve, there is an urgent need for a reliable evaluation method that delivers trustworthy results promptly. Currently, static benchmarks suffer from inflexibility and unreliability, leading users to prefer human voting platforms like Chatbot Arena. However, human evaluations require significant manual effort. To address this, we propose the Auto-Arena, an innovative framework that automates the entire evaluation process using LLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM candidates engage in a multi-round peer battle based on individual questions, aiming at revealing their true performance differences. Finally, a committee of LLM judges collaboratively discusses and decides the winner, reducing bias and enhancing fairness. During the peer battles, we observe intriguing scenarios where the LLM candidates display competitive behaviors and even learn from the opponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena shows a 92.14% correlation with human preferences, surpassing all previous expert-annotated benchmarks without any manual efforts. As a result, Auto-Arena offers a promising alternative to current human evaluation platforms for evaluating LLMs automatically.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2257089455",
                    "name": "Wenxuan Zhang"
                },
                {
                    "authorId": "2066312627",
                    "name": "Yew Ken Chia"
                },
                {
                    "authorId": "2303980061",
                    "name": "Deli Zhao"
                },
                {
                    "authorId": "1996394",
                    "name": "Lidong Bing"
                }
            ]
        },
        {
            "paperId": "3a4eb7540a7dc371f3814ed4b57e001b5b288456",
            "title": "Explaining Language Model Predictions with High-Impact Concepts",
            "abstract": "To encourage fairness and transparency, there exists an urgent demand for deriving reliable explanations for large language models (LLMs). One promising solution is concept-based explanations, i.e., human-understandable concepts from internal representations. However, due to the compositional nature of languages, current methods mostly discover correlational explanations instead of causal features. Therefore, we propose a novel framework to provide impact-aware explanations for users to understand the LLM\u2019s behavior, which are robust to feature changes and influential to the model\u2019s predictions. Specifically, we extract predictive high-level features (concepts) from the model\u2019s hidden layer activations. Then, we innovatively optimize for features whose existence causes the output predictions to change substantially. Extensive experiments on real and synthetic tasks demonstrate that our method achieves superior results on predictive impact, explainability, and faithfulness compared to the baselines, especially for LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2298015346",
                    "name": "Tan Wang"
                },
                {
                    "authorId": "2291439162",
                    "name": "Yongjie Wang"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "3edc37be7ffe4647f8f271c0f0aa1861d98a11be",
            "title": "Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges",
            "abstract": "In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transfor-mative impact of LLMs on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From both data and learning perspectives, we examine various strategies that utilize LLMs for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for diverse forms of further training. Additionally, this paper highlights the primary open challenges faced in this domain, ranging from controllable data augmentation to multi-modal data augmentation. This survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve as a comprehensive guide for researchers and practitioners.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064493724",
                    "name": "Bosheng Ding"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2290030532",
                    "name": "Tianze Luo"
                },
                {
                    "authorId": "2290023354",
                    "name": "Xinze Li"
                },
                {
                    "authorId": "2290026474",
                    "name": "Guizhen Chen"
                },
                {
                    "authorId": "2276610995",
                    "name": "Wenhan Xia"
                },
                {
                    "authorId": "2290145274",
                    "name": "Junjie Hu"
                },
                {
                    "authorId": "1755919",
                    "name": "A. Luu"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "660ec26b660315ba42e91b6e722836abbafb98b5",
            "title": "Data Augmentation using Large Language Models: Data Perspectives, Learning Paradigms and Challenges",
            "abstract": "In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of LLMs on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From both data and learning perspectives, we examine various strategies that utilize LLMs for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for diverse forms of further training. Additionally, this paper highlights the primary open challenges faced in this domain, ranging from controllable data augmentation to multi-modal data augmentation. This survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve as a comprehensive guide for researchers and practitioners.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064493724",
                    "name": "Bosheng Ding"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2290030532",
                    "name": "Tianze Luo"
                },
                {
                    "authorId": "2290023354",
                    "name": "Xinze Li"
                },
                {
                    "authorId": "2290026474",
                    "name": "Guizhen Chen"
                },
                {
                    "authorId": "2276610995",
                    "name": "Wenhan Xia"
                },
                {
                    "authorId": "2290145274",
                    "name": "Junjie Hu"
                },
                {
                    "authorId": "1755919",
                    "name": "A. Luu"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "8e90bba98fdd41a9046ba00ad527441a447c56bb",
            "title": "Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks",
            "abstract": "State-of-the-art large language models (LLMs) exhibit impressive problem-solving capabilities but may struggle with complex reasoning and factual correctness. Existing methods harness the strengths of chain-of-thought and retrieval-augmented generation (RAG) to decompose a complex problem into simpler steps and apply retrieval to improve factual correctness. These methods work well on straightforward reasoning tasks but often falter on challenging tasks such as competitive programming and mathematics, due to frequent reasoning errors and irrelevant knowledge retrieval. To address this, we introduce Critic-guided planning with Retrieval-augmentation, CR-Planner, a novel framework that leverages fine-tuned critic models to guide both reasoning and retrieval processes through planning. CR-Planner solves a problem by iteratively selecting and executing sub-goals. Initially, it identifies the most promising sub-goal from reasoning, query generation, and retrieval, guided by rewards given by a critic model named sub-goal critic. It then executes this sub-goal through sampling and selecting the optimal output based on evaluations from another critic model named execution critic. This iterative process, informed by retrieved information and critic models, enables CR-Planner to effectively navigate the solution space towards the final answer. We employ Monte Carlo Tree Search to collect the data for training the critic models, allowing for a systematic exploration of action sequences and their long-term impacts. We validate CR-Planner on challenging domain-knowledge-intensive and reasoning-heavy tasks, including competitive programming, theorem-driven math reasoning, and complex domain retrieval problems. Our experiments demonstrate that CR-Planner significantly outperforms baselines, highlighting its effectiveness in addressing challenging problems by improving both reasoning and retrieval.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155447436",
                    "name": "Xingxuan Li"
                },
                {
                    "authorId": "2313881740",
                    "name": "Weiwen Xu"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "1689176705",
                    "name": "Fangkai Jiao"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2211459675",
                    "name": "Li Bing"
                }
            ]
        },
        {
            "paperId": "95c117cb5dd40d9a86df09a252c7874c84dd7feb",
            "title": "How Much are Large Language Models Contaminated? A Comprehensive Survey and the LLMSanitize Library",
            "abstract": "With the rise of Large Language Models (LLMs) in recent years, abundant new opportunities are emerging, but also new challenges, among which contamination is quickly becoming critical. Business applications and fundraising in AI have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a major issue: LLMs' performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes the entire progress in the field of NLP, yet, there remains a lack of methods on how to efficiently detect contamination.In this paper, we survey all recent work on contamination detection with LLMs, and help the community track contamination levels of LLMs by releasing an open-source Python library named LLMSanitize implementing major contamination detection algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "14038850",
                    "name": "Mathieu Ravaut"
                },
                {
                    "authorId": "2064493724",
                    "name": "Bosheng Ding"
                },
                {
                    "authorId": "1689176705",
                    "name": "Fangkai Jiao"
                },
                {
                    "authorId": "2258571998",
                    "name": "Hailin Chen"
                },
                {
                    "authorId": "2155447436",
                    "name": "Xingxuan Li"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2267728986",
                    "name": "Caiming Xiong"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "9b95f38c64cd6de13c84edc46feae235d0a9bc4d",
            "title": "Lifelong Event Detection with Embedding Space Separation and Compaction",
            "abstract": "To mitigate forgetting, existing lifelong event detection methods typically maintain a memory module and replay the stored memory data during the learning of a new task. However, the simple combination of memory data and new-task samples can still result in substantial forgetting of previously acquired knowledge, which may occur due to the potential overlap between the feature distribution of new data and the previously learned embedding space. Moreover, the model suffers from overfitting on the few memory samples rather than effectively remembering learned patterns. To address the challenges of forgetting and overfitting, we propose a novel method based on embedding space separation and compaction. Our method alleviates forgetting of previously learned tasks by forcing the feature distribution of new data away from the previous embedding space. It also mitigates overfitting by a memory calibration mechanism that encourages memory data to be close to its prototype to enhance intra-class compactness. In addition, the learnable parameters of the new task are initialized by drawing upon acquired knowledge from the previously learned task to facilitate forward knowledge transfer. With extensive experiments, we demonstrate that our method can significantly outperform previous state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2293667903",
                    "name": "Ruirui Chen"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2276610995",
                    "name": "Wenhan Xia"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "00a9a469bb019bf33eeee438c110f704b71cda73",
            "title": "Retrieving Multimodal Information for Augmented Generation: A Survey",
            "abstract": "As Large Language Models (LLMs) become popular, there emerged an important trend of using multimodality to augment the LLMs' generation ability, which enables LLMs to better interact with the world. However, there lacks a unified perception of at which stage and how to incorporate different modalities. In this survey, we review methods that assist and augment generative models by retrieving multimodal knowledge, whose formats range from images, codes, tables, graphs, to audio. Such methods offer a promising solution to important concerns such as factuality, reasoning, interpretability, and robustness. By providing an in-depth review, this survey is expected to provide scholars with a deeper understanding of the methods' applications and encourage them to adapt existing techniques to the fast-growing field of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2118442481",
                    "name": "Hailin Chen"
                },
                {
                    "authorId": "2108528154",
                    "name": "Weishi Wang"
                },
                {
                    "authorId": "1689176705",
                    "name": "Fangkai Jiao"
                },
                {
                    "authorId": "2060491855",
                    "name": "Do Xuan Long"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2064493724",
                    "name": "Bosheng Ding"
                },
                {
                    "authorId": "151479832",
                    "name": "Xiaobao Guo"
                },
                {
                    "authorId": "2161729126",
                    "name": "Minzhi Li"
                },
                {
                    "authorId": "2155447436",
                    "name": "Xingxuan Li"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "049ad4be9cdfd92f02c36f8fb056c5c7a98ff750",
            "title": "PromptSum: Parameter-Efficient Controllable Abstractive Summarization",
            "abstract": "Prompt tuning (PT), a parameter-efficient technique that only tunes the additional prompt embeddings while keeping the backbone pre-trained language model (PLM) frozen, has shown promising results in language understanding tasks, especially in low-resource scenarios. However, effective prompt design methods suitable for generation tasks such as summarization are still lacking. At the same time, summarization guided through instructions (discrete prompts) can achieve a desirable double objective of high quality and controllability in summary generation. Towards a goal of strong summarization performance under the triple conditions of parameter-efficiency, data-efficiency, and controllability, we introduce PromptSum, a method combining PT with a multi-task objective and discrete entity prompts for abstractive summarization. Our model achieves competitive ROUGE results on popular abstractive summarization benchmarks coupled with a strong level of controllability through entities, all while only tuning several orders of magnitude less parameters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "14038850",
                    "name": "Mathieu Ravaut"
                },
                {
                    "authorId": "2118442481",
                    "name": "Hailin Chen"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2118768398",
                    "name": "Nancy F. Chen"
                }
            ]
        },
        {
            "paperId": "4b5fefaccd9153da9895f69ee3ec7ce6c0b747d0",
            "title": "Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications",
            "abstract": "Large-scale pre-trained language models have shown outstanding performance in a variety of NLP tasks. However, they are also known to be significantly brittle against specifically crafted adversarial examples, leading to increasing interest in probing the adversarial robustness of NLP systems. We introduce RSMI, a novel two-stage framework that combines randomized smoothing (RS) with masked inference (MI) to improve the adversarial robustness of NLP systems. RS transforms a classifier into a smoothed classifier to obtain robust representations, whereas MI forces a model to exploit the surrounding context of a masked token in an input sequence. RSMI improves adversarial robustness by 2 to 3 times over existing state-of-the-art methods on benchmark datasets. We also perform in-depth qualitative analysis to validate the effectiveness of the different stages of RSMI and probe the impact of its components through extensive ablations. By empirically proving the stability of RSMI, we put it forward as a practical method to robustly train large-scale NLP models. Our code and datasets are available at https://github.com/Han8931/rsmi_nlp",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1382771958",
                    "name": "Han Cheol Moon"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2162736149",
                    "name": "Xu Chi"
                }
            ]
        }
    ]
}