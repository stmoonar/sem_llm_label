{
    "authorId": "2061977359",
    "papers": [
        {
            "paperId": "a30bd328bc36a3f75aa18f653919611b1a8ea23d",
            "title": "Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs",
            "abstract": "Large language models (LLMs), while exhibiting exceptional performance, suffer from hallucinations, especially on knowledge-intensive tasks. Existing works propose to augment LLMs with individual text units retrieved from external knowledge corpora to alleviate the issue. However, in many domains, texts are interconnected (e.g., academic papers in a bibliographic graph are linked by citations and co-authorships) which form a (text-attributed) graph. The knowledge in such graphs is encoded not only in single texts/nodes but also in their associated connections. To facilitate the research of augmenting LLMs with graphs, we manually construct a Graph Reasoning Benchmark dataset called GRBench, containing 1,740 questions that can be answered with the knowledge from 10 domain graphs. Then, we propose a simple and effective framework called Graph Chain-of-thought (Graph-CoT) to augment LLMs with graphs by encouraging LLMs to reason on the graph iteratively. Each Graph-CoT iteration consists of three sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. We conduct systematic experiments with three LLM backbones on GRBench, where Graph-CoT outperforms the baselines consistently. The code is available at https://github.com/PeterGriffinJin/Graph-CoT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057050247",
                    "name": "Bowen Jin"
                },
                {
                    "authorId": "150961077",
                    "name": "Chulin Xie"
                },
                {
                    "authorId": "2295927976",
                    "name": "Jiawei Zhang"
                },
                {
                    "authorId": "2061977359",
                    "name": "Kashob Kumar Roy"
                },
                {
                    "authorId": "2293820617",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2286977473",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "2257136881",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "c86c5a8098701fe226c77a5419001b55e2e4dc6e",
            "title": "Mining Sequential Patterns in Uncertain Databases Using Hierarchical Index Structure",
            "abstract": "In this uncertain world, data uncertainty is inherent in many applications and its importance is growing drastically due to the rapid development of modern technologies. Nowadays, researchers have paid more attention to mine patterns in uncertain databases. A few recent works attempt to mine frequent uncertain sequential patterns. Despite their success, they are incompetent to reduce the number of false-positive pattern generation in their mining process and maintain the patterns efficiently. In this paper, we propose multiple theoretically tightened pruning upper bounds that remarkably reduce the mining space. A novel hierarchical structure is introduced to maintain the patterns in a space-efficient way. Afterward, we develop a versatile framework for mining uncertain sequential patterns that can effectively handle weight constraints as well. Besides, with the advent of incremental uncertain databases, existing works are not scalable. There exist several incremental sequential pattern mining algorithms, but they are limited to mine in precise databases. Therefore, we propose a new technique to adapt our framework to mine patterns when the database is incremental. Finally, we conduct extensive experiments on several real-life datasets and show the efficacy of our framework in different applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2061977359",
                    "name": "Kashob Kumar Roy"
                },
                {
                    "authorId": "2091457256",
                    "name": "Md Hasibul Haque Moon"
                },
                {
                    "authorId": "2116361104",
                    "name": "Md Mahmudur Rahman"
                },
                {
                    "authorId": "2168828",
                    "name": "Chowdhury Farhan Ahmed"
                },
                {
                    "authorId": "1726081",
                    "name": "C. Leung"
                }
            ]
        },
        {
            "paperId": "ac67be8051be6be674a444337f07ab72f2353f06",
            "title": "Long-form Question Answering: An Iterative Planning-Retrieval-Generation Approach",
            "abstract": "Long-form question answering (LFQA) poses a challenge as it involves generating detailed answers in the form of paragraphs, which go beyond simple yes/no responses or short factual answers. While existing QA models excel in questions with concise answers, LFQA requires handling multiple topics and their intricate relationships, demanding comprehensive explanations. Previous attempts at LFQA focused on generating long-form answers by utilizing relevant contexts from a corpus, relying solely on the question itself. However, they overlooked the possibility that the question alone might not provide sufficient information to identify the relevant contexts. Additionally, generating detailed long-form answers often entails aggregating knowledge from diverse sources. To address these limitations, we propose an LFQA model with iterative Planning, Retrieval, and Generation. This iterative process continues until a complete answer is generated for the given question. From an extensive experiment on both an open domain and a technical domain QA dataset, we find that our model outperforms the state-of-the-art models on various textual and factual metrics for the LFQA task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66622709",
                    "name": "Pritom Saha Akash"
                },
                {
                    "authorId": "2061977359",
                    "name": "Kashob Kumar Roy"
                },
                {
                    "authorId": "2266837256",
                    "name": "Lucian Popa"
                },
                {
                    "authorId": "2260292765",
                    "name": "Kevin Chen-Chuan Chang"
                }
            ]
        },
        {
            "paperId": "8bd4b09f4e5201abf43aa34744a04afadb7c39da",
            "title": "Node Embedding using Mutual Information and Self-Supervision based Bi-level Aggregation",
            "abstract": "Graph Neural Networks (GNNs) learn low dimensional representations of nodes by aggregating information from their neighborhood in graphs. However, traditional GNNs suffer from two fundamental shortcomings due to their local (l-hop neighborhood) aggregation scheme. First, not all nodes in the neighborhood carry relevant information for the target node. Since GNNs do not exclude noisy nodes in their neighborhood, irrelevant information gets aggregated, which reduces the quality of the representation. Second, traditional GNNs also fail to capture long-range non-local dependencies between nodes. To address these limitations, we exploit mutual information (MI) to define two types of neighborhood, 1) Local Neighborhood where nodes are densely connected within a community and each node would share higher MI with its neighbors, and 2) Non-Local Neighborhood where MI-based node clustering is introduced to assemble informative but graphically distant nodes in the same cluster. To generate node presentations, we combine the embeddings generated by bi-level aggregation - local aggregation to aggregate features from local neighborhoods to avoid noisy information and non-local aggregation to aggregate features from non-local neighborhoods. Furthermore, we leverage self-supervision learning to estimate MI with few labeled data. Finally, we show that our model significantly outperforms the state-of-the-art methods in a wide range of assortative and disassortative graphs11Source Code at: https://github.com/forkkr/LnL-GNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2061977359",
                    "name": "Kashob Kumar Roy"
                },
                {
                    "authorId": "2088206446",
                    "name": "Amit Roy"
                },
                {
                    "authorId": "2107144671",
                    "name": "A. Rahman"
                },
                {
                    "authorId": "145637145",
                    "name": "M. Amin"
                },
                {
                    "authorId": "1782708",
                    "name": "A. Ali"
                }
            ]
        },
        {
            "paperId": "e053117afb0cd79709b512dc2f920d33914d0246",
            "title": "Structure-Aware Hierarchical Graph Pooling using Information Bottleneck",
            "abstract": "Graph pooling is an essential ingredient of Graph Neural Networks (GNNs) in graph classification and regression tasks. For these tasks, different pooling strategies have been proposed to generate a graph-level representation by downsampling and summarizing nodes' features in a graph. However, most existing pooling methods are unable to capture distinguishable structural information effectively. Besides, they are prone to adversarial attacks. In this work, we propose a novel pooling method named as HIBPool where we leverage the Information Bottleneck (IB) principle that optimally balances the expressiveness and robustness of a model to learn representations of input data. Furthermore, we introduce a novel structure-aware Discriminative Pooling Readout (DiP-Readout) function to capture the informative local subgraph structures in the graph. Finally, our experimental results show that our model significantly outperforms other state-of-art methods on several graph classification benchmarks and more resilient to feature-perturbation attack than existing pooling methods11Source code at: https://github.com/forkkr/HIBPool.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2061977359",
                    "name": "Kashob Kumar Roy"
                },
                {
                    "authorId": "2088206446",
                    "name": "Amit Roy"
                },
                {
                    "authorId": "2107144671",
                    "name": "A. Rahman"
                },
                {
                    "authorId": "145637145",
                    "name": "M. Amin"
                },
                {
                    "authorId": "1782708",
                    "name": "A. Ali"
                }
            ]
        },
        {
            "paperId": "f2b1e659eef5b38f5da6956d814950bc82a9c334",
            "title": "Unified Spatio-Temporal Modeling for Traffic Forecasting using Graph Neural Network",
            "abstract": "Research in deep learning models to forecast traffic intensities has gained great attention in recent years due to their capability to capture the complex spatio-temporal relationships within the traffic data. However, most state-of-the-art approaches have designed spatial-only (e.g. Graph Neural Networks) and temporal-only (e.g. Recurrent Neural Networks) modules to separately extract spatial and temporal features. However, we argue that it is less effective to extract the complex spatiotemporal relationship with such factorized modules. Besides, most existing works predict the traffic intensity of a particular time interval only based on the traffic data of the previous one hour of that day. And thereby ignores the repetitive daily/weekly pattern that may exist in the last hour of data. Therefore, we propose a Unified Spatio-Temporal Graph Convolution Network (USTGCN) for traffic forecasting that performs both spatial and temporal aggregation through direct information propagation across different timestamp nodes with the help of spectral graph convolution on a spatio-temporal graph. Furthermore, it captures historical daily patterns in previous days and current-day patterns in current-day traffic data. Finally, we validate our work's effectiveness through experimental analysis11Code is available at github.com/AmitRoy7781/USTGCN, which shows that our model USTGCN can outperform state-of-the-art performances in three popular benchmark datasets from the Performance Measurement System (PeMS). Moreover, the training time is reduced significantly with our proposed USTGCN model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2088206446",
                    "name": "Amit Roy"
                },
                {
                    "authorId": "2061977359",
                    "name": "Kashob Kumar Roy"
                },
                {
                    "authorId": "1782708",
                    "name": "A. Ali"
                },
                {
                    "authorId": "145637145",
                    "name": "M. Amin"
                },
                {
                    "authorId": "2107144671",
                    "name": "A. Rahman"
                }
            ]
        }
    ]
}