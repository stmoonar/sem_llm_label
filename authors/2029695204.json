{
    "authorId": "2029695204",
    "papers": [
        {
            "paperId": "dd184ded1197ab01cadbb9398e987dcd5874ec45",
            "title": "A Comprehensive Survey on Data Augmentation",
            "abstract": "Data augmentation is a series of techniques that generate high-quality artificial data by manipulating existing data samples. By leveraging data augmentation techniques, AI models can achieve significantly improved applicability in tasks involving scarce or imbalanced datasets, thereby substantially enhancing AI models' generalization capabilities. Existing literature surveys only focus on a certain type of specific modality data, and categorize these methods from modality-specific and operation-centric perspectives, which lacks a consistent summary of data augmentation methods across multiple modalities and limits the comprehension of how existing data samples serve the data augmentation process. To bridge this gap, we propose a more enlightening taxonomy that encompasses data augmentation techniques for different common data modalities. Specifically, from a data-centric perspective, this survey proposes a modality-independent taxonomy by investigating how to take advantage of the intrinsic relationship between data samples, including single-wise, pair-wise, and population-wise sample data augmentation methods. Additionally, we categorize data augmentation methods across five data modalities through a unified inductive approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301261259",
                    "name": "Zaitian Wang"
                },
                {
                    "authorId": "2301248160",
                    "name": "Pengfei Wang"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "35629977",
                    "name": "Pengyang Wang"
                },
                {
                    "authorId": "2281907272",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "2301541398",
                    "name": "Chang-Tien Lu"
                },
                {
                    "authorId": "2227721329",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2301454226",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2145108199",
                    "name": "Yuanchun Zhou"
                }
            ]
        },
        {
            "paperId": "f8e89dc4802b5da2d3584b95250446f7b5148b7c",
            "title": "Enhanced Gene Selection in Single-Cell Genomics: Pre-Filtering Synergy and Reinforced Optimization",
            "abstract": "Recent advancements in single-cell genomics necessitate precision in gene panel selection to interpret complex biological data effectively. Those methods aim to streamline the analysis of scRNA-seq data by focusing on the most informative genes that contribute significantly to the specific analysis task. Traditional selection methods, which often rely on expert domain knowledge, embedded machine learning models, or heuristic-based iterative optimization, are prone to biases and inefficiencies that may obscure critical genomic signals. Recognizing the limitations of traditional methods, we aim to transcend these constraints with a refined strategy. In this study, we introduce an iterative gene panel selection strategy that is applicable to clustering tasks in single-cell genomics. Our method uniquely integrates results from other gene selection algorithms, providing valuable preliminary boundaries or prior knowledge as initial guides in the search space to enhance the efficiency of our framework. Furthermore, we incorporate the stochastic nature of the exploration process in reinforcement learning (RL) and its capability for continuous optimization through reward-based feedback. This combination mitigates the biases inherent in the initial boundaries and harnesses RL's adaptability to refine and target gene panel selection dynamically. To illustrate the effectiveness of our method, we conducted detailed comparative experiments, case studies, and visualization analysis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2305735775",
                    "name": "Weiliang Zhang"
                },
                {
                    "authorId": "2287843869",
                    "name": "Zhen Meng"
                },
                {
                    "authorId": "2305658288",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "2306163263",
                    "name": "Min Wu"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2145108199",
                    "name": "Yuanchun Zhou"
                },
                {
                    "authorId": "2099595860",
                    "name": "Meng Xiao"
                }
            ]
        },
        {
            "paperId": "07f187699a444dc8e2bebe212bf83f0181f823ef",
            "title": "A Counterfactual Collaborative Session-based Recommender System",
            "abstract": "Most session-based recommender systems (SBRSs) focus on extracting information from the observed items in the current session of a user to predict a next item, ignoring the causes outside the session (called outer-session causes, OSCs) that influence the user\u2019s selection of items. However, these causes widely exist in the real world, and few studies have investigated their role in SBRSs. In this work, we analyze the causalities and correlations of the OSCs in SBRSs from the perspective of causal inference. We find that the OSCs are essentially the confounders in SBRSs, which leads to spurious correlations in the data used to train SBRS models. To address this problem, we propose a novel SBRS framework named COCO-SBRS (COunterfactual COllaborative Session-Based Recommender Systems) to learn the causality between OSCs and user-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised approach to pre-train a recommendation model by designing pseudo-labels of causes for each user\u2019s selection of the item in data to guide the training process. Next, COCO-SBRS adopts counterfactual inference to recommend items based on the outputs of the pre-trained recommendation model considering the causalities to alleviate the data sparsity problem. As a result, COCO-SBRS can learn the causalities in data, preventing the model from learning spurious correlations. The experimental results of our extensive experiments conducted on three real-world datasets demonstrate the superiority of our proposed framework over ten representative SBRSs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51122248",
                    "name": "Wenzhuo Song"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2152541925",
                    "name": "Yan Wang"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "120280976",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2105567718",
                    "name": "Minghao Yin"
                }
            ]
        },
        {
            "paperId": "2b484b5903f0c02c9c7d25a8fa171625f27c8826",
            "title": "Deep Adaptive Graph Clustering via von Mises-Fisher Distributions",
            "abstract": "Graph clustering has been a hot research topic and is widely used in many fields, such as community detection in social networks. Lots of works combining auto-encoder and graph neural networks have been applied to clustering tasks by utilizing node attributes and graph structure. These works usually assumed the inherent parameters (i.e., size and variance) of different clusters in the latent embedding space are homogeneous, and hence the assigned probability is monotonous over the Euclidean distance between node embeddings and centroids. Unfortunately, this assumption usually does not hold since the size and concentration of different clusters can be quite different, which limits the clustering accuracy. In addition, the node embeddings in deep graph clustering methods are usually L2 normalized so that it lies on the surface of a unit hyper-sphere. To solve this problem, we proposed Deep Adaptive Graph Clustering via von Mises-Fisher distributions, namely DAGC. DAGC assumes the node embeddings H can be drawn from a von Mises-Fisher distribution and each cluster k is associated with cluster inherent parameters \u03c1k which includes cluster center \u03bc and cluster cohesion degree \u03ba. Then we adopt an EM-like approach (i.e., \ud835\udcab(H|\u03c1) and \ud835\udcab(\u03c1|H), respectively) to learn the embedding and cluster inherent parameters alternately. Specifically, with the node embeddings, we proposed to update the cluster centers in an attraction-repulsion manner to make the cluster centers more separable. And given the cluster inherent parameters, a likelihood-based loss is proposed to make node embeddings more concentrated around cluster centers. Thus, DAGC can simultaneously improve the intra-cluster compactness and inter-cluster heterogeneity. Finally, extensive experiments conducted on four benchmark datasets have demonstrated that the proposed DAGC consistently outperforms the state-of-the-art methods, especially on imbalanced datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46808435",
                    "name": "P. Wang"
                },
                {
                    "authorId": "2118209133",
                    "name": "Daqing Wu"
                },
                {
                    "authorId": "2135176888",
                    "name": "Chong Chen"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "50535545",
                    "name": "Jianqiang Huang"
                },
                {
                    "authorId": "2145108199",
                    "name": "Yuanchun Zhou"
                },
                {
                    "authorId": "2056780339",
                    "name": "Jianfeng Zhan"
                },
                {
                    "authorId": "2053903039",
                    "name": "Xiansheng Hua"
                }
            ]
        },
        {
            "paperId": "46c9b043326e6a8d8df6208cff465b45ff934dd9",
            "title": "Self-optimizing Feature Generation via Categorical Hashing Representation and Hierarchical Reinforcement Crossing",
            "abstract": "Feature generation aims to generate new and meaningful features to create a discriminative representation space. A generated feature is meaningful when the generated feature is from a feature pair with inherent feature interaction. In the real world, experienced data scientists can identify potentially useful feature-feature interactions, and generate meaningful dimensions from an exponentially large search space in an optimal crossing form over an optimal generation path. But, machines have limited human-like abilities. We generalize such learning tasks as self-optimizing feature generation. Self-optimizing feature generation imposes several under-addressed challenges on existing systems: meaningful, robust, and efficient generation. To tackle these challenges, we propose a principled and generic representation-crossing framework to solve self-optimizing feature generation. To achieve hashing representation, we propose a three-step approach: feature discretization, feature hashing, and descriptive summarization. To achieve reinforcement crossing, we develop a hierarchical reinforcement feature crossing approach. We present extensive experimental results to demonstrate the effectiveness and efficiency of the proposed method. The code is available at https://github.com/yingwangyang/HRC_feature_cross.git.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238955278",
                    "name": "Wangyang Ying"
                },
                {
                    "authorId": "1669829502",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2239062108",
                    "name": "Leilei Sun"
                },
                {
                    "authorId": "2239058389",
                    "name": "Yanjie Fu"
                }
            ]
        },
        {
            "paperId": "4ba094f74e3681072cfb120498bbb4147a6e94f9",
            "title": "Reinforced Explainable Knowledge Concept Recommendation in MOOCs",
            "abstract": "In this article, we study knowledge concept recommendation in Massive Open Online Courses (MOOCs) in an explainable manner. Knowledge concepts, composing course units (e.g., videos) in MOOCs, refer to topics and skills that students are expected to master. Compared to traditional course recommendation in MOOCs, knowledge concepts recommendation has drawn more attention because students\u2019 interests over knowledge concepts can better revealstudents\u2019 real intention in a more refined granularity. However, there are three unique challenges in knowledge concept recommendation: (1) How to design an appropriate data structure to capture complex relationships between knowledge concepts, course units, and other participants (e.g., students, teachers)? (2) How to model interactions between students and knowledge concepts? (3) How to make explainable recommendation results to students? To tackle these challenges, we formulate the knowledge concept recommendation as a reinforcement learning task integrated with MOOC knowledge graph (KG). Specifically, we first construct MOOC KG as the environment to capture all the relationships and behavioral histories by considering all the entities (e.g., students, teachers, videos, courses, and knowledge concepts) on the MOOC provider. Then, to model the interactions between students and knowledge concepts, we train an agent to mimic students\u2019 learning behavioral patterns facing the complex environment. Moreover, to provide explainable recommendation results, we generate recommended knowledge concepts in the format of a path from MOOC KG to indicate semantic reasons. Finally, we conduct extensive experiments on a real-world MOOC dataset to demonstrate the effectiveness of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112546695",
                    "name": "Lu Jiang"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2108825329",
                    "name": "Yibin Wang"
                },
                {
                    "authorId": "1669829502",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "35629977",
                    "name": "Pengyang Wang"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "2105567718",
                    "name": "Minghao Yin"
                }
            ]
        },
        {
            "paperId": "77bfe732dbd17f4b816027bee0d041bc6874cf34",
            "title": "Traceable Group-Wise Self-Optimizing Feature Transformation Learning: A Dual Optimization Perspective",
            "abstract": "Feature transformation aims to reconstruct an effective representation space by mathematically refining the existing features. It serves as a pivotal approach to combat the curse of dimensionality, enhance model generalization, mitigate data sparsity, and extend the applicability of classical models. Existing research predominantly focuses on domain knowledge-based feature engineering or learning latent representations. However, these methods, while insightful, lack full automation and fail to yield a traceable and optimal representation space. An indispensable question arises: Can we concurrently address these limitations when reconstructing a feature space for a machine learning task? Our initial work took a pioneering step towards this challenge by introducing a novel self-optimizing framework. This framework leverages the power of three cascading reinforced agents to automatically select candidate features and operations for generating improved feature transformation combinations. Despite the impressive strides made, there was room for enhancing its effectiveness and generalization capability. In this extended journal version, we advance our initial work from two distinct yet interconnected perspectives: 1) We propose a refinement of the original framework, which integrates a graph-based state representation method to capture the feature interactions more effectively and develop different Q-learning strategies to alleviate Q-value overestimation further. 2) We utilize a new optimization technique (actor-critic) to train the entire self-optimizing framework in order to accelerate the model convergence and improve the feature transformation performance. Finally, to validate the improved effectiveness and generalization capability of our framework, we perform extensive experiments and conduct comprehensive analyses. These provide empirical evidence of the strides made in this journal version over the initial work, solidifying our framework\u2019s standing as a substantial contribution to the field of automated feature transformation. To improve the reproducibility, we have released the associated code and data by the Github link https://github.com/coco11563/TKDD2023_code.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2099595860",
                    "name": "Meng Xiao"
                },
                {
                    "authorId": "1669829502",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "2144152753",
                    "name": "Min Wu"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2152081288",
                    "name": "H. Xiong"
                },
                {
                    "authorId": "2145108199",
                    "name": "Yuanchun Zhou"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                }
            ]
        },
        {
            "paperId": "c1d677c058bb354da4418ebc3d168f4d7c5064b2",
            "title": "Feature Interaction Aware Automated Data Representation Transformation",
            "abstract": "Creating an effective representation space is crucial for mitigating the curse of dimensionality, enhancing model generalization, addressing data sparsity, and leveraging classical models more effectively. Recent advancements in automated feature engineering (AutoFE) have made significant progress in addressing various challenges associated with representation learning, issues such as heavy reliance on intensive labor and empirical experiences, lack of explainable explicitness, and inflexible feature space reconstruction embedded into downstream tasks. However, these approaches are constrained by: 1) generation of potentially unintelligible and illogical reconstructed feature spaces, stemming from the neglect of expert-level cognitive processes; 2) lack of systematic exploration, which subsequently results in slower model convergence for identification of optimal feature space. To address these, we introduce an interaction-aware reinforced generation perspective. We redefine feature space reconstruction as a nested process of creating meaningful features and controlling feature set size through selection. We develop a hierarchical reinforcement learning structure with cascading Markov Decision Processes to automate feature and operation selection, as well as feature crossing. By incorporating statistical measures, we reward agents based on the interaction strength between selected features, resulting in intelligent and efficient exploration of the feature space that emulates human decision-making. Extensive experiments are conducted to validate our proposed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069495317",
                    "name": "Ehtesamul Azim"
                },
                {
                    "authorId": "1669829502",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2256596936",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2239058389",
                    "name": "Yanjie Fu"
                }
            ]
        },
        {
            "paperId": "d2dc5f3e7ce45d25b8133f50db84eda9c3035404",
            "title": "Automated Feature Selection: A Reinforcement Learning Perspective",
            "abstract": "Feature selection is a critical step in machine learning that selects the most important features for a subsequent prediction task. Effective feature selection can help to reduce dimensionality, improve prediction accuracy, and increase result comprehensibility. It is traditionally challenging to find the optimal feature subset from the feature subset space as the space could be very large. While much effort has been made on feature selection, reinforcement learning can provide a new perspective towards a more globally-optimal searching strategy. In the preliminary work, we propose a multi-agent reinforcement learning framework for the feature selection problem. Specifically, we first reformulate feature selection with a reinforcement learning framework by regarding each feature as an agent. Besides, we obtain the state of the environment in three ways, i.e., statistic description, autoencoder, and graph convolutional network (GCN), in order to derive a fixed-length state representation as the input of reinforcement learning. In addition, we study how the coordination among feature agents can be improved by a more effective reward scheme. Also, we provide a GMM-based generative rectified sampling strategy to accelerate the convergence of multi-agent reinforcement learning. Our method searches the feature subset space more globally and can be easily adapted to real-time scenarios due to the nature of reinforcement learning. In the extended version, we further accelerate the framework from two aspects. From the sampling aspect, we show the indirect acceleration by proposing a rank-based softmax sampling strategy. From the exploration aspect, we show the direct acceleration by proposing an interactive reinforcement learning (IRL)-based exploration strategy. Extensive experimental results show the significant improvement of the proposed method over conventional approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "2148926829",
                    "name": "Le Wu"
                },
                {
                    "authorId": "2108673315",
                    "name": "Xiaolin Li"
                },
                {
                    "authorId": "1682418",
                    "name": "C. Aggarwal"
                },
                {
                    "authorId": "2152081288",
                    "name": "H. Xiong"
                }
            ]
        },
        {
            "paperId": "d7ab41d046d8538374008576fdd6da8b8de6455c",
            "title": "RDKG: A Reinforcement Learning Framework for Disease Diagnosis on Knowledge Graph",
            "abstract": "Automatic disease diagnosis from symptoms has attracted much attention in medical practices. It can assist doctors and medical practitioners in narrowing down disease candidates, reducing testing costs, improving diagnosis efficiency, and more importantly, saving human lives. Existing research has made significant progress in diagnosing disease but was limited by the gap between interpretability and accuracy. To fill this gap, in this paper, we propose a method called Reinforced Disease Diagnosis on Knowlege Graph (RDKG). Specifically, we first construct a knowledge graph containing all information from electronic medical records. To capture informative embeddings, we propose an enhanced knowledge graph embedding method that can embed information outside the knowledge graph into entity embedding. Then we transform the automatic disease diagnosis task into a Markov decision process on the knowledge graph. After that, we design a reinforcement learning method with a soft reward mechanism and a pruning strategy to solve the Markov decision process. We accomplish automated disease diagnosis by finding a path from symptoms to disease. The experimental results show that our model can effectively utilize heterogeneous information in the knowledge graph to complete the automatic disease diagnosis. Besides, our model demonstrates supreme performance in both accuracy and interpretability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283016330",
                    "name": "Shipeng Guo"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2249299439",
                    "name": "Pengfei Wang"
                },
                {
                    "authorId": "2206202197",
                    "name": "Weiwei Dai"
                },
                {
                    "authorId": "2047314150",
                    "name": "Yi Du"
                },
                {
                    "authorId": "2145108199",
                    "name": "Yuanchun Zhou"
                },
                {
                    "authorId": "2645671",
                    "name": "Wenjuan Cui"
                }
            ]
        }
    ]
}