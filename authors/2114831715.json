{
    "authorId": "2114831715",
    "papers": [
        {
            "paperId": "00af36ae2b615a8300348386052e38f4ddeb32e3",
            "title": "DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection",
            "abstract": "Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where LLMs could be incorporated as part of the pipeline: 1) LLMs could \\emph{generate news reactions} to represent diverse perspectives and simulate user-news interaction networks; 2) LLMs could \\emph{generate explanations} for proxy tasks (e.g., sentiment, stance) to enrich the contexts of news articles and produce experts specializing in various aspects of news understanding; 3) LLMs could \\emph{merge task-specific experts} and provide an overall prediction by incorporating the predictions and confidence scores of varying experts. Extensive experiments on seven datasets with three LLMs demonstrate that DELL outperforms state-of-the-art baselines by up to 16.8\\% in macro f1-score. Further analysis reveals that the generated reactions and explanations are greatly helpful in misinformation detection, while our proposed LLM-guided expert merging helps produce better-calibrated predictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2249583325",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "2260397981",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "614639931a1598e8a0eca39b595a792ff42a0059",
            "title": "What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection",
            "abstract": "Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language models (LLMs) in social bot detection. To investigate the opportunities, we design novel LLM-based bot detectors by proposing a mixture-of-heterogeneous-experts framework to divide and conquer diverse user information modalities. To illuminate the risks, we explore the possibility of LLM-guided manipulation of user textual and structured information to evade detection. Extensive experiments with three LLMs on two datasets demonstrate that instruction tuning on merely 1,000 annotated examples produces specialized LLMs that outperform state-of-the-art baselines by up to 9.1% on both datasets, while LLM-guided manipulation strategies could significantly bring down the performance of existing bot detectors by up to 29.6% and harm the calibration and reliability of bot detection systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2152170253",
                    "name": "Ningnan Wang"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2260397981",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2249583325",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "97d62525c8258e283fc08fa182f77673441552c2",
            "title": "Disentangled Noisy Correspondence Learning",
            "abstract": "Cross-modal retrieval is crucial in understanding latent correspondences across modalities. However, existing methods implicitly assume well-matched training data, which is impractical as real-world data inevitably involves imperfect alignments, i.e., noisy correspondences. Although some works explore similarity-based strategies to address such noise, they suffer from sub-optimal similarity predictions influenced by modality-exclusive information (MEI), e.g., background noise in images and abstract definitions in texts. This issue arises as MEI is not shared across modalities, thus aligning it in training can markedly mislead similarity predictions. Moreover, although intuitive, directly applying previous cross-modal disentanglement methods suffers from limited noise tolerance and disentanglement efficacy. Inspired by the robustness of information bottlenecks against noise, we introduce DisNCL, a novel information-theoretic framework for feature Disentanglement in Noisy Correspondence Learning, to adaptively balance the extraction of MII and MEI with certifiable optimal cross-modal disentanglement efficacy. DisNCL then enhances similarity predictions in modality-invariant subspace, thereby greatly boosting similarity-based alleviation strategy for noisy correspondences. Furthermore, DisNCL introduces soft matching targets to model noisy many-to-many relationships inherent in multi-modal input for noise-robust and accurate cross-modal alignment. Extensive experiments confirm DisNCL's efficacy by 2% average recall improvement. Mutual information estimation and visualization results show that DisNCL learns meaningful MII/MEI subspaces, validating our theoretical analyses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192703079",
                    "name": "Zhuohang Dang"
                },
                {
                    "authorId": "2269762117",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2315940640",
                    "name": "Jihong Wang"
                },
                {
                    "authorId": "2147134586",
                    "name": "Chengyou Jia"
                },
                {
                    "authorId": "2148302310",
                    "name": "Haocheng Han"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "1486400091",
                    "name": "Guangwen Dai"
                },
                {
                    "authorId": "2840330",
                    "name": "Xiao Chang"
                },
                {
                    "authorId": "2265463017",
                    "name": "Jingdong Wang"
                }
            ]
        },
        {
            "paperId": "e974084ef8da1a7898d97013c974a6180f681b87",
            "title": "How Do Social Bots Participate in Misinformation Spread? A Comprehensive Dataset and Analysis",
            "abstract": "Information spreads faster through social media platforms than traditional media, thus becoming an ideal medium to spread misinformation. Meanwhile, automated accounts, known as social bots, contribute more to the misinformation dissemination. In this paper, we explore the interplay between social bots and misinformation on the Sina Weibo platform. We propose a comprehensive and large-scale misinformation dataset, containing 11,393 misinformation and 16,416 unbiased real information with multiple modality information, with 952,955 related users. We propose a scalable weak-surprised method to annotate social bots, obtaining 68,040 social bots and 411,635 genuine accounts. To the best of our knowledge, this dataset is the largest dataset containing misinformation and social bots. We conduct comprehensive experiments and analysis on this dataset. Results show that social bots play a central role in misinformation dissemination, participating in news discussions to amplify echo chambers, manipulate public sentiment, and reverse public stances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2260397981",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2316446785",
                    "name": "Zihan Ma"
                },
                {
                    "authorId": "2316434991",
                    "name": "Guang Dai"
                },
                {
                    "authorId": "2316443129",
                    "name": "Xiang Zhao"
                }
            ]
        },
        {
            "paperId": "1bc0dc96d745325d89ec5bee1da1541255e6d1eb",
            "title": "BotPercent: Estimating Twitter Bot Populations from Groups to Crowds",
            "abstract": "Twitter bot detection has become increasingly important in combating misinformation, identifying malicious online cam-paigns, and protecting the integrity of social media discourse. While existing bot detection literature mostly focuses on identifying individual bots, it remains underexplored how to estimate the proportion of bots within speci\ufb01c communities and social networks, which has great implications for both content moderators and day-to-day users. In this work, we propose community-level bot detection , a novel approach to estimating the amount of malicious interference in online communities by estimating the percentage of bot accounts. Speci\ufb01cally, we introduce BotPercent , an amalgamation of Twitter bot-detection datasets and feature, text, and graph-based models that overcome generalization issues in existing individual-level models, resulting in a more accurate community-level bot estimation. Experiments demonstrate that BotPercent achieves state-of-the-art community-level bot detection performance on the TwiBot-22 benchmark while showing great robustness towards the tampering of speci\ufb01c user features. Armed with BotPercent , we analyze bot rates in different Twitter groups and communities, such as all active Twitter users, users that interact with partisan news media, users that participate in Elon Musk\u2019s content moderation votes, and the political communities in different countries and regions. Our experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more. The BotPercent implementation is available at https://github.com/TamSiuhin/BotPercent",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "1947172233",
                    "name": "Melanie Sclar"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "1699545",
                    "name": "Yejin Choi"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "5cd7c5f4e21cb541d7c553b04074335e858847c2",
            "title": "BotPercent: Estimating Bot Populations in Twitter Communities",
            "abstract": "Twitter bot detection is vital in combating misinformation and safeguarding the integrity of social media discourse. While malicious bots are becoming more and more sophisticated and personalized, standard bot detection approaches are still agnostic to social environments (henceforth, communities) the bots operate at. In this work, we introduce community-specific bot detection, estimating the percentage of bots given the context of a community. Our method -- BotPercent -- is an amalgamation of Twitter bot detection datasets and feature-, text-, and graph-based models, adjusted to a particular community on Twitter. We introduce an approach that performs confidence calibration across bot detection models, which addresses generalization issues in existing community-agnostic models targeting individual bots and leads to more accurate community-level bot estimations. Experiments demonstrate that BotPercent achieves state-of-the-art performance in community-level Twitter bot detection across both balanced and imbalanced class distribution settings, %outperforming existing approaches and presenting a less biased estimator of Twitter bot populations within the communities we analyze. We then analyze bot rates in several Twitter groups, including users who engage with partisan news media, political communities in different countries, and more. Our results reveal that the presence of Twitter bots is not homogeneous, but exhibiting a spatial-temporal distribution with considerable heterogeneity that should be taken into account for content moderation and social media policy making. The implementation of BotPercent is available at https://github.com/TamSiuhin/BotPercent.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "1947172233",
                    "name": "Melanie Sclar"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2260397981",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2259707400",
                    "name": "Yejin Choi"
                },
                {
                    "authorId": "2258958466",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "2d1048d7ab145d17a521a5126b1124b475eac314",
            "title": "GraTO: Graph Neural Network Framework Tackling Over-smoothing with Neural Architecture Search",
            "abstract": "Current Graph Neural Networks (GNNs) suffer from the over-smoothing problem, which results in indistinguishable node representations and low model performance with more GNN layers. Many methods have been put forward to tackle this problem in recent years. However, existing tackling over-smoothing methods emphasize model performance and neglect the over-smoothness of node representations. Additional, different approaches are applied one at a time, while there lacks an overall framework to jointly leverage multiple solutions to the over-smoothing challenge. To solve these problems, we propose GraTO, a framework based on neural architecture search to automatically search for GNNs architecture. GraTO adopts a novel loss function to facilitate striking a balance between model performance and representation smoothness. In addition to existing methods, our search space also includes DropAttribute, a novel scheme for alleviating the over-smoothing challenge, to fully leverage diverse solutions. We conduct extensive experiments on six real-world datasets to evaluate GraTo, which demonstrates that GraTo outperforms baselines in the over-smoothing metrics and achieves competitive performance in accuracy. GraTO is especially effective and robust with increasing numbers of GNN layers. Further experiments bear out the quality of node representations learned with GraTO and the effectiveness of model architecture. We make the code of GraTo available at Github (https://github.com/fxsxjtu/GraTO).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2169404546",
                    "name": "Xinshun Feng"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2169403637",
                    "name": "Hongrui Wang"
                },
                {
                    "authorId": "2151549863",
                    "name": "Jun Zhou"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "7066c88ffd227c74479f29f917f0db73270afa24",
            "title": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
            "abstract": "Twitter bot detection has become an increasingly important task to combat misinformation, facilitate social media moderation, and preserve the integrity of the online discourse. State-of-the-art bot detection methods generally leverage the graph structure of the Twitter network, and they exhibit promising performance when confronting novel Twitter bots that traditional methods fail to detect. However, very few of the existing Twitter bot detection datasets are graph-based, and even these few graph-based datasets suffer from limited dataset scale, incomplete graph structure, as well as low annotation quality. In fact, the lack of a large-scale graph-based Twitter bot detection benchmark that addresses these issues has seriously hindered the development and evaluation of novel graph-based bot detection approaches. In this paper, we propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark that presents the largest dataset to date, provides diversified entities and relations on the Twitter network, and has considerably better annotation quality than existing datasets. In addition, we re-implement 35 representative Twitter bot detection baselines and evaluate them on 9 datasets, including TwiBot-22, to promote a fair comparison of model performance and a holistic understanding of research progress. To facilitate further research, we consolidate all implemented codes and datasets into the TwiBot-22 evaluation framework, where researchers could consistently evaluate new models and datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation framework are publicly available at https://twibot22.github.io/",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2152170253",
                    "name": "Ningnan Wang"
                },
                {
                    "authorId": "2117098676",
                    "name": "Zilong Chen"
                },
                {
                    "authorId": "2134483590",
                    "name": "Binchi Zhang"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "49039233",
                    "name": "Wenqian Zhang"
                },
                {
                    "authorId": "2161968765",
                    "name": "Zhenyu Lei"
                },
                {
                    "authorId": "2169372154",
                    "name": "Shujie Yang"
                },
                {
                    "authorId": "2169404546",
                    "name": "Xinshun Feng"
                },
                {
                    "authorId": "2261664149",
                    "name": "Qingyue Zhang"
                },
                {
                    "authorId": "2169403637",
                    "name": "Hongrui Wang"
                },
                {
                    "authorId": "2169159066",
                    "name": "Yuhan Liu"
                },
                {
                    "authorId": "2170130468",
                    "name": "Yuyang Bai"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2169253157",
                    "name": "Zijian Cai"
                },
                {
                    "authorId": "2107964144",
                    "name": "Yanbo Wang"
                },
                {
                    "authorId": "1964303146",
                    "name": "Lijing Zheng"
                },
                {
                    "authorId": "2169172454",
                    "name": "Zihan Ma"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "8160e4342bea1cad1a95aa519a7b3e2ba0601e71",
            "title": "BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency",
            "abstract": "Twitter bots are automatic programs operated by malicious actors to manipulate public opinion and spread misinformation. Research efforts have been made to automatically identify bots based on texts and networks on social media. Existing methods only leverage texts or networks alone, and while few works explored the shallow combination of the two modalities, we hypothesize that the interaction and information exchange between texts and graphs could be crucial for holistically evaluating bot activities on social media. In addition, according to a recent survey (Cresci, 2020), Twitter bots are constantly evolving while advanced bots steal genuine users\u2019 tweets and dilute their malicious content to evade detection. This results in greater inconsistency across the timeline of novel Twitter bots, which warrants more attention. In light of these challenges, we propose BIC, a Twitter Bot detection framework with text-graph Interaction and semantic Consistency. Specifically, in addition to separately modeling the two modalities on social media, BIC employs a text-graph interaction module to enable information exchange across modalities in the learning process. In addition, given the stealing behavior of novel Twitter bots, BIC proposes to model semantic consistency in tweets based on attention weights while using it to augment the decision process. Extensive experiments demonstrate that BIC consistently outperforms state-of-the-art baselines on two widely adopted datasets. Further analyses reveal that text-graph interactions and modeling semantic consistency are essential improvements and help combat bot evolution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161968765",
                    "name": "Zhenyu Lei"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "49039233",
                    "name": "Wenqian Zhang"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2117098676",
                    "name": "Zilong Chen"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "4ee6bdb383badfe6b61ad07f1dab9864fcd9f4f7",
            "title": "SATAR: A Self-supervised Approach to Twitter Account Representation Learning and its Application in Bot Detection",
            "abstract": "Twitter has become a major social media platform since its launching in 2006, while complaints about bot accounts have increased recently. Although extensive research efforts have been made, the state-of-the-art bot detection methods fall short of generalizability and adaptability. Specifically, previous bot detectors leverage only a small fraction of user information and are often trained on datasets that only cover few types of bots. As a result, they fail to generalize to real-world scenarios on the Twittersphere where different types of bots co-exist. Additionally, bots in Twitter are constantly evolving to evade detection. Previous efforts, although effective once in their context, fail to adapt to new generations of Twitter bots. To address the two challenges of Twitter bot detection, we propose SATAR, a self-supervised representation learning framework of Twitter users, and apply it to the task of bot detection. In particular, SATAR generalizes by jointly leveraging the semantics, property and neighborhood information of a specific user. Meanwhile, SATAR adapts by pre-training on a massive number of self-supervised users and fine-tuning on detailed bot detection scenarios. Extensive experiments demonstrate that SATAR outperforms competitive baselines on different bot detection datasets of varying information completeness and collection time. SATAR is also proved to generalize in real-world scenarios and adapt to evolving generations of social media bots.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "2152170253",
                    "name": "Ningnan Wang"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        }
    ]
}