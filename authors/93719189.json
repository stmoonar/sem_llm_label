{
    "authorId": "93719189",
    "papers": [
        {
            "paperId": "8758e094bd55c6810728963f212e07722a50ab74",
            "title": "Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation",
            "abstract": "Session-based recommendation has gained increasing attention in recent years, with its aim to offer tailored suggestions based on users' historical behaviors within sessions. To advance this field, a variety of methods have been developed, with ID-based approaches typically demonstrating promising performance. However, these methods often face challenges with long-tail items and overlook other rich forms of information, notably valuable textual semantic information. To integrate text information, various methods have been introduced, mostly following a naive fusion framework. Surprisingly, we observe that fusing these two modalities does not consistently outperform the best single modality by following the naive fusion framework. Further investigation reveals an potential imbalance issue in naive fusion, where the ID dominates and text modality is undertrained. This suggests that the unexpected observation may stem from naive fusion's failure to effectively balance the two modalities, often over-relying on the stronger ID modality. This insight suggests that naive fusion might not be as effective in combining ID and text as previously expected. To address this, we propose a novel alternative training strategy AlterRec. It separates the training of ID and text, thereby avoiding the imbalance issue seen in naive fusion. Additionally, AlterRec designs a novel strategy to facilitate the interaction between the two modalities, enabling them to mutually learn from each other and integrate the text more effectively. Comprehensive experiments demonstrate the effectiveness of AlterRec in session-based recommendation. The implementation is available at https://github.com/Juanhui28/AlterRec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2284066656",
                    "name": "Amin Javari"
                },
                {
                    "authorId": "2256937217",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "8b1137db77f4142449cfbcd13af4040025bc8e37",
            "title": "A LLM-Powered Automatic Grading Framework with Human-Level Guidelines Optimization",
            "abstract": "Open-ended short-answer questions (SAGs) have been widely recognized as a powerful tool for providing deeper insights into learners' responses in the context of learning analytics (LA). However, SAGs often present challenges in practice due to the high grading workload and concerns about inconsistent assessments. With recent advancements in natural language processing (NLP), automatic short-answer grading (ASAG) offers a promising solution to these challenges. Despite this, current ASAG algorithms are often limited in generalizability and tend to be tailored to specific questions. In this paper, we propose a unified multi-agent ASAG framework, GradeOpt, which leverages large language models (LLMs) as graders for SAGs. More importantly, GradeOpt incorporates two additional LLM-based agents - the reflector and the refiner - into the multi-agent system. This enables GradeOpt to automatically optimize the original grading guidelines by performing self-reflection on its errors. Through experiments on a challenging ASAG task, namely the grading of pedagogical content knowledge (PCK) and content knowledge (CK) questions, GradeOpt demonstrates superior performance in grading accuracy and behavior alignment with human graders compared to representative baselines. Finally, comprehensive ablation studies confirm the effectiveness of the individual components designed in GradeOpt.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296130053",
                    "name": "Yucheng Chu"
                },
                {
                    "authorId": "2321298358",
                    "name": "Hang Li"
                },
                {
                    "authorId": "2261395882",
                    "name": "Kaiqi Yang"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2324165547",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2295987777",
                    "name": "Yasemin Copur-Gencturk"
                },
                {
                    "authorId": "2314887353",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "be21727ba12cdb50401b30c29a46d05c799f7945",
            "title": "Towards Better Benchmark Datasets for Inductive Knowledge Graph Completion",
            "abstract": "Knowledge Graph Completion (KGC) attempts to predict missing facts in a Knowledge Graph (KG). Recently, there's been an increased focus on designing KGC methods that can excel in the {\\it inductive setting}, where a portion or all of the entities and relations seen in inference are unobserved during training. Numerous benchmark datasets have been proposed for inductive KGC, all of which are subsets of existing KGs used for transductive KGC. However, we find that the current procedure for constructing inductive KGC datasets inadvertently creates a shortcut that can be exploited even while disregarding the relational information. Specifically, we observe that the Personalized PageRank (PPR) score can achieve strong or near SOTA performance on most inductive datasets. In this paper, we study the root cause of this problem. Using these insights, we propose an alternative strategy for constructing inductive KGC datasets that helps mitigate the PPR shortcut. We then benchmark multiple popular methods using the newly constructed datasets and analyze their performance. The new benchmark datasets help promote a better understanding of the capabilities and challenges of inductive KGC by removing any shortcuts that obfuscate performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2296816494",
                    "name": "Jay Revolinsky"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "31407867ee91254c550b642308a6c3ddfa97d443",
            "title": "A Mix-up Strategy to Enhance Adversarial Training with Imbalanced Data",
            "abstract": "Adversarial training has been proven to be one of the most effective techniques to defend against adversarial examples. The majority of existing adversarial training methods assume that every class in the training data is equally distributed. However, in reality, some classes often have a large number of training data while others only have a very limited amount. Recent studies have shown that the performance of adversarial training will degrade drastically if the training data is imbalanced. In this paper, we propose a simple yet effective framework to enhance the robustness of DNN models under imbalanced scenarios. Our framework, Imb-Mix, first augments the training dataset by generating multiple adversarial examples for samples in the minority classes. This is done by first adding random noise to the original adversarial examples created by one specific adversarial attack method. It then constructs Mixup-mimic mixed examples upon the augmented dataset used by adversarial training. In addition, we theoretically prove the regularization effect of our Mixup-mimic mixed examples generation technique in Imb-Mix. Extensive experiments on various imbalanced datasets verify the effectiveness of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108329255",
                    "name": "Wentao Wang"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2260856560",
                    "name": "Yuxuan Wan"
                },
                {
                    "authorId": "2260818199",
                    "name": "Yaxin Li"
                },
                {
                    "authorId": "2261094674",
                    "name": "Jiangtao Huang"
                },
                {
                    "authorId": "2261366610",
                    "name": "Hui Liu"
                }
            ]
        },
        {
            "paperId": "3e80c134db377491c12e8cc9a65752444cc5c0d3",
            "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
            "abstract": "Knowledge graph completion (KGC) aims to predict unseen edges in knowledge graphs (KGs), resulting in the discovery of new facts. A new class of methods have been proposed to tackle this problem by aggregating path information. These methods have shown tremendous ability in the task of KGC. However they are plagued by efficiency issues. Though there are a few recent attempts to address this through learnable path pruning, they often sacrifice the performance to gain efficiency. In this work, we identify two intrinsic limitations of these methods that affect the efficiency and representation quality. To address the limitations, we introduce a new method, TAGNet, which is able to efficiently propagate information. This is achieved by only aggregating paths in a fixed window for each source-target pair. We demonstrate that the complexity of TAGNet is independent of the number of layers. Extensive experiments demonstrate that TAGNet can cut down on the number of propagated messages by as much as 90% while achieving competitive performance on multiple KG datasets. The code is available at https://github.com/HarryShomer/TAGNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2259889350",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2166048911",
                    "name": "Charu Aggarwal"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f3fa1ef467c996b30242124a298b5b9d031e9ed5",
            "title": "Toward Degree Bias in Embedding-Based Knowledge Graph Completion",
            "abstract": "A fundamental task for knowledge graphs (KGs) is knowledge graph completion (KGC). It aims to predict unseen edges by learning representations for all the entities and relations in a KG. A common concern when learning representations on traditional graphs is degree bias. It can affect graph algorithms by learning poor representations for lower-degree nodes, often leading to low performance on such nodes. However, there has been limited research on whether there exists degree bias for embedding-based KGC and how such bias affects the performance of KGC. In this paper, we validate the existence of degree bias in embedding-based KGC and identify the key factor to degree bias. We then introduce a novel data augmentation method, KG-Mixup, to generate synthetic triples to mitigate such bias. Extensive experiments have demonstrated that our method can improve various embedding-based KGC methods and outperform other methods tackling the bias problem on multiple benchmark datasets. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2108329255",
                    "name": "Wentao Wang"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f7cbe49ee96dfa3ee18b5dd5413355a75f98e8a7",
            "title": "Adaptive Pairwise Encodings for Link Prediction",
            "abstract": "Link prediction is a common task on graph-structured data that has seen applications in a variety of domains. Classically, hand-crafted heuristics were used for this task. Heuristic measures are chosen such that they correlate well with the underlying factors re-lated to link formation. In recent years, a new class of methods has emerged that combines the advantages of message-passing neural networks (MPNN) and heuristics methods. These methods perform predictions by using the output of an MPNN in conjunction with a \u201cpairwise encoding\" that captures the relationship between nodes in the candidate link. They have been shown to achieve strong performance on numerous datasets. However, current pairwise encodings often contain a strong inductive bias, using the same underlying factors to classify all links. This limits the ability of existing meth-ods to learn how to properly classify a variety of different links that may form from different factors. To address this limitation, we propose a new method, LPFormer , which attempts to adaptively learn the pairwise encodings for each link. LPFormer models the link factors via an attention module that learns the pairwise encoding that exists between nodes by modeling multiple factors integral to link prediction. Extensive experiments demonstrate that LPFormer can achieve SOTA performance on numerous datasets while maintaining efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2259889350",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "0fb235cc59cd7198b5a1494157b0250cfca04386",
            "title": "Detecting Harmful Online Conversational Content towards LGBTQIA+ Individuals",
            "abstract": "Online discussions, panels, talk page edits, etc., often contain harmful conversational content i.e., hate speech, death threats and offensive language, especially towards certain demographic groups. For example, individuals who identify as members of the LGBTQIA+ community and/or BIPOC (Black, Indigenous, People of Color) are at higher risk for abuse and harassment online. In this work, we first introduce a real-world dataset that will enable us to study and understand harmful online conversational content. Then, we conduct several exploratory data analysis experiments to gain deeper insights from the dataset. We later describe our approach for detecting harmful online Anti-LGBTQIA+ conversational content, and finally, we implement two baseline machine learning models (i.e., Support Vector Machine and Logistic Regression), and fine-tune 3 pre-trained large language models (BERT, RoBERTa, and HateBERT). Our findings verify that large language models can achieve very promising performance on detecting online Anti-LGBTQIA+ conversational content detection tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1380259269",
                    "name": "Jamell Dacon"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2177338974",
                    "name": "Shaylynn Crum-Dacon"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "67784eedd6f76a5ee26feae28e1578d3a4d3c280",
            "title": "Are Graph Neural Networks Really Helpful for Knowledge Graph Completion?",
            "abstract": "Knowledge graphs (KGs) facilitate a wide variety of applications due to their ability to store relational knowledge applicable to many areas. Despite great efforts invested in creation and maintenance, even the largest KGs are far from complete. Hence, KG completion (KGC) has become one of the most crucial tasks for KG research. Recently, considerable literature in this space has centered around the use of Graph Neural Networks (GNNs) to learn powerful embeddings which leverage topological structures in the KGs. Specifically, dedicated efforts have been made to extend GNNs, which are com-monly designed for simple homogeneous and uni-relational graphs, to the KG context which has diverse and multi-relational connec-tions between entities, by designing more complex aggregation schemes over neighboring nodes (crucial to GNN performance) to appropriately leverage multi-relational information. The success of these methods is naturally attributed to the use of GNNs over simpler multi-layer perceptron (MLP) models, owing to their additional aggregation functionality. In this work, we find that surprisingly, simple MLP models are able to achieve comparable performance to GNNs, suggesting that aggregation may not be as crucial as previ-ously believed. With further exploration, we show careful scoring function and loss function design has a much stronger influence on KGC model performance, and aggregation is not practically required. This suggests a conflation of scoring function design, loss function design, and aggregation in prior",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "50813549",
                    "name": "Jiayu Ding"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "145474474",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "91e9ef35323b059feaed63ac30b6bef553773e05",
            "title": "Learning Representations for Hyper-Relational Knowledge Graphs",
            "abstract": "Knowledge graphs (KGs) have gained prominence for their ability to learn representations for uni-relational facts. Recently, research has focused on modeling hyper-relational facts, which move beyond the restriction of uni-relational facts and allow us to represent more complex and real-world information. However, existing approaches for learning representations on hyper-relational KGs majorly focus on enhancing the communication from qualifiers to base triples while overlooking the flow of information from base triple to qualifiers. This can lead to suboptimal qualifier representations, especially when a large amount of qualifiers are presented. It motivates us to design a framework that utilizes multiple aggregators to learn representations for hyper-relational facts: one from the perspective of the base triple and the other one from the perspective of the qualifiers. Experiments demonstrate the effectiveness of our framework for hyper-relational knowledge graph completion across multiple datasets. Furthermore, we conduct an ablation study that validates the importance of the various components in our framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        }
    ]
}