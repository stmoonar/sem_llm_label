{
    "authorId": "2143666481",
    "papers": [
        {
            "paperId": "4698689b13386fafe6a894af9d9f75952695d07c",
            "title": "DiffCP: Ultra-Low Bit Collaborative Perception via Diffusion Model",
            "abstract": "Collaborative perception (CP) is emerging as a promising solution to the inherent limitations of stand-alone intelligence. However, current wireless communication systems are unable to support feature-level and raw-level collaborative algorithms due to their enormous bandwidth demands. In this paper, we propose DiffCP, a novel CP paradigm that utilizes a specialized diffusion model to efficiently compress the sensing information of collaborators. By incorporating both geometric and semantic conditions into the generative model, DiffCP enables feature-level collaboration with an ultra-low communication cost, advancing the practical implementation of CP systems. This paradigm can be seamlessly integrated into existing CP algorithms to enhance a wide range of downstream tasks. Through extensive experimentation, we investigate the trade-offs between communication, computation, and performance. Numerical results demonstrate that DiffCP can significantly reduce communication costs by 14.5-fold while maintaining the same performance as the state-of-the-art algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "2323566657",
                    "name": "Haotian Wu"
                },
                {
                    "authorId": "2154697858",
                    "name": "Yukuan Jia"
                },
                {
                    "authorId": "151401090",
                    "name": "Zhaojun Nan"
                },
                {
                    "authorId": "2109440325",
                    "name": "Yuxuan Sun"
                },
                {
                    "authorId": "2293220025",
                    "name": "Sheng Zhou"
                },
                {
                    "authorId": "2302248476",
                    "name": "Deniz Gunduz"
                },
                {
                    "authorId": "2285329831",
                    "name": "Zhisheng Niu"
                }
            ]
        },
        {
            "paperId": "935664b9491de8e3de84665d4cc3ade54021c0f6",
            "title": "C-MASS: Combinatorial Mobility-Aware Sensor Scheduling for Collaborative Perception with Second-Order Topology Approximation",
            "abstract": "Collaborative Perception (CP) has been a promising solution to address occlusions in the traffic environment by sharing sensor data among collaborative vehicles (CoV) via vehicle-to-everything (V2X) network. With limited wireless bandwidth, CP necessitates task-oriented and receiver-aware sensor scheduling to prioritize important and complementary sensor data. However, due to vehicular mobility, it is challenging and costly to obtain the up-to-date perception topology, i.e., whether a combination of CoVs can jointly detect an object. In this paper, we propose a combinatorial mobility-aware sensor scheduling (C-MASS) framework for CP with minimal communication overhead. Specifically, detections are replayed with sensor data from individual CoVs and pairs of CoVs to maintain an empirical perception topology up to the second order, which approximately represents the complete perception topology. A hybrid greedy algorithm is then proposed to solve a variant of the budgeted maximum coverage problem with a worst-case performance guarantee. The C-MASS scheduling algorithm adapts the greedy algorithm by incorporating the topological uncertainty and the unexplored time of CoVs to balance exploration and exploitation, addressing the mobility challenge. Extensive numerical experiments demonstrate the near-optimality of the proposed C-MASS framework in both edge-assisted and distributed CP configurations. The weighted recall improvements over object-level CP are 5.8% and 4.2%, respectively. Compared to distance-based and area-based greedy heuristics, the gaps to the offline optimal solutions are reduced by up to 75% and 71%, respectively.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2154697858",
                    "name": "Yukuan Jia"
                },
                {
                    "authorId": "2109440325",
                    "name": "Yuxuan Sun"
                },
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "151401090",
                    "name": "Zhaojun Nan"
                },
                {
                    "authorId": "2293220025",
                    "name": "Sheng Zhou"
                },
                {
                    "authorId": "2285329831",
                    "name": "Zhisheng Niu"
                }
            ]
        },
        {
            "paperId": "db110e1e5f4d845d16de6ad5d97f0e638b353a94",
            "title": "Infrastructure-Assisted Collaborative Perception in Automated Valet Parking: A Safety Perspective",
            "abstract": "Environmental perception in Automated Valet Parking (AVP) has been a challenging task due to severe occlusions in parking garages. Although Collaborative Perception (CP) can be applied to broaden the field of view of connected vehicles, the limited bandwidth of vehicular communications restricts its application. In this work, we propose a BEV feature-based CP network architecture for infrastructure-assisted AVP systems. The model takes the roadside camera and LiDAR as optional inputs and adaptively fuses them with onboard sensors in a unified BEV representation. Autoencoder and downsampling are applied for channel-wise and spatial-wise dimension reduction, while sparsification and quantization further compress the feature map with little loss in data precision. Combining these techniques, the size of a BEV feature map is effectively compressed to fit in the feasible data rate of the NR-V2X network. With the synthetic AVP dataset, we observe that CP can effectively increase perception performance, especially for pedestrians. Moreover, the advantage of infrastructure-assisted CP is demonstrated in two typical safety-critical scenarios in the AVP setting, increasing the maximum safe cruising speed by up to 3m/s in both scenarios.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2154697858",
                    "name": "Yukuan Jia"
                },
                {
                    "authorId": "2293211278",
                    "name": "Jiawen Zhang"
                },
                {
                    "authorId": "2293339366",
                    "name": "Shimeng Lu"
                },
                {
                    "authorId": "2293170134",
                    "name": "Baokang Fan"
                },
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "2293220025",
                    "name": "Sheng Zhou"
                },
                {
                    "authorId": "145273634",
                    "name": "Z. Niu"
                }
            ]
        },
        {
            "paperId": "dd9027bb6ab79cdf1da7017752e1a0e6800fa99d",
            "title": "Task-Oriented Wireless Communications for Collaborative Perception in Intelligent Unmanned Systems",
            "abstract": "Collaborative Perception (CP) has shown great potential to achieve more holistic and reliable environmental perception in intelligent unmanned systems (IUSs). However, implementing CP still faces key challenges due to the characteristics of the CP task and the dynamics of wireless channels. In this article, a task-oriented wireless communication framework is proposed to jointly optimize the communication scheme and the CP procedure. We first propose channel-adaptive compression and robust fusion approaches to extract and exploit the most valuable semantic information under wireless communication constraints. We then propose a task-oriented distributed scheduling algorithm to identify the best collaborators for CP under dynamic environments. The main idea is learning while scheduling, where the collaboration utility is effectively learned with low computation and communication overhead. Case studies are carried out in connected autonomous driving scenarios to verify the proposed framework. Finally, we identify several future research directions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2293220025",
                    "name": "Sheng Zhou"
                },
                {
                    "authorId": "2154697858",
                    "name": "Yukuan Jia"
                },
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "151401090",
                    "name": "Zhaojun Nan"
                },
                {
                    "authorId": "2109440325",
                    "name": "Yuxuan Sun"
                },
                {
                    "authorId": "2285329831",
                    "name": "Zhisheng Niu"
                }
            ]
        },
        {
            "paperId": "7a406fbedf2544d4050f5ee74d4565c7ae8aa30c",
            "title": "Live Demonstration: An Integrated Computing and Communication Platform for Vehicle-Infrastructure Cooperative Autonomous Driving",
            "abstract": "Perception, computing and communication are usually decoupled in today\u2019s vehicle-road coordination applications, which significantly adds to the system delay and cost. In contrast, we showcase a platform that integrates perception, communication and computing to provide timely roadside bird-eye-view (BEV) maps to vehicles for vision fusion. A neural processing unit and a cellular vehicle-to-everything (C-V2X) wireless baseband are both implemented on FPGA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2222887849",
                    "name": "Yuhang Gu"
                },
                {
                    "authorId": "2155469922",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "153212289",
                    "name": "Yi-xing Shi"
                },
                {
                    "authorId": "2115196093",
                    "name": "Limin Jiang"
                },
                {
                    "authorId": "122616107",
                    "name": "Shan-Guo Li"
                },
                {
                    "authorId": "2302662",
                    "name": "Sha Cao"
                },
                {
                    "authorId": "4302623",
                    "name": "Zhiyuan Jiang"
                },
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "2090490303",
                    "name": "Zhewen Lou"
                },
                {
                    "authorId": "2221285178",
                    "name": "Sheng Zhou"
                }
            ]
        },
        {
            "paperId": "82a12414a27969b9b644c08e4608db4c33b16631",
            "title": "An FPGA-based Low Latency Sensing and Communication Platform for Collaborative Autonomous Driving",
            "abstract": "Vehicle-Infrastructure cooperation is an advanced development stage of autonomous driving, which helps to upgrade the capability of vehicles by fully implementing real-time information interaction among vehicles, roads and pedestrians. However, perception, computing and communication are usually decoupled in today\u2019s vehicle-road coordination applications, which significantly adds delay and cost to the system. In this paper, we propose and implement a platform that integrates perception, computing and communication to provide timely roadside feature maps to vehicles for vision fusion. A neural processing unit (NPU) for computing and a cellular vehicle-to-everything (C-V2X) wireless baseband IP for communication are both implemented on FPGA. We evaluate the effectiveness of the proposed platform using CoBEVT algorithm on the camera track of the OPV2V perception dataset. The experimental result show that our platform can expand the view of vehicles as well as improve information freshness in terms of end-to-end delay.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155469922",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2222887849",
                    "name": "Yuhang Gu"
                },
                {
                    "authorId": "153212289",
                    "name": "Yi-xing Shi"
                },
                {
                    "authorId": "2115196093",
                    "name": "Limin Jiang"
                },
                {
                    "authorId": "2265661770",
                    "name": "Shan Li"
                },
                {
                    "authorId": "2265719092",
                    "name": "Yijie Huang"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                },
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "2221285178",
                    "name": "Sheng Zhou"
                }
            ]
        },
        {
            "paperId": "909e0f6c3764d788c577b2833f8985174ca9e8fe",
            "title": "MoRFF: Multi-View Object Detection for Connected Autonomous Driving under Communication and Localization Limitations",
            "abstract": "Vehicle-to-Everything network enabled connected autonomous driving has been regarded as a promising solution to realize advanced autonomous driving. However, non-ideal factors in wireless communication and localization severely limit the development. In this work, we propose MoRFF, a Mobility-robust Regional Features Fusion framework for multi-terminal multi-view object detection to realize wireless cooperative perception. To conquer the limited communication bandwidth, stochastic latency, and inaccurate positioning caused by wireless links and mobility, our method features a universal two-stage detection paradigm with deep metric learning, matching the same object from different viewpoints directly on the regional feature maps, and thus helps to greatly reduce the data size to transmit. Our proposed architecture only requires image data without any additional information such as geo-positions, sensor poses, or point clouds from LiDAR, and thus conducive to the promotion of connected autonomous driving. Experimental evaluations show that the proposed algorithm successfully benefits from other viewpoints, increases the detection precision of barely visible objects by 13.42%, and achieves tenfold promotion in communication bandwidth requirements. Furthermore, the proposed algorithm is robust under various communication delays.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "2274192519",
                    "name": "Jingyu Guo"
                },
                {
                    "authorId": "2154697858",
                    "name": "Yukuan Jia"
                },
                {
                    "authorId": "2274082580",
                    "name": "Jialin Dong"
                },
                {
                    "authorId": "2109440325",
                    "name": "Yuxuan Sun"
                },
                {
                    "authorId": "143676396",
                    "name": "Sheng Zhou"
                },
                {
                    "authorId": "145273634",
                    "name": "Z. Niu"
                }
            ]
        }
    ]
}