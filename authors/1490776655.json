{
    "authorId": "1490776655",
    "papers": [
        {
            "paperId": "3c632184a105d2a639f8d7e66a7e4999142b6a63",
            "title": "Correcting misinformation on social media with a large language model",
            "abstract": "Real-world misinformation, often multimodal, can be partially or fully factual but misleading using diverse tactics like conflating correlation with causation. Such misinformation is severely understudied, challenging to address, and harms various social domains, particularly on social media, where it can spread rapidly. High-quality and timely correction of misinformation that identifies and explains its (in)accuracies effectively reduces false beliefs. Despite the wide acceptance of manual correction, it is difficult to be timely and scalable. While LLMs have versatile capabilities that could accelerate misinformation correction, they struggle due to a lack of recent information, a tendency to produce false content, and limitations in addressing multimodal information. We propose MUSE, an LLM augmented with access to and credibility evaluation of up-to-date information. By retrieving evidence as refutations or supporting context, MUSE identifies and explains content (in)accuracies with references. It conducts multimodal retrieval and interprets visual content to verify and correct multimodal content. Given the absence of a comprehensive evaluation approach, we propose 13 dimensions of misinformation correction quality. Then, fact-checking experts evaluate responses to social media content that are not presupposed to be misinformation but broadly include (partially) incorrect and correct posts that may (not) be misleading. Results demonstrate MUSE's ability to write high-quality responses to potential misinformation--across modalities, tactics, domains, political leanings, and for information that has not previously been fact-checked online--within minutes of its appearance on social media. Overall, MUSE outperforms GPT-4 by 37% and even high-quality responses from laypeople by 29%. Our work provides a general methodological and evaluative framework to correct misinformation at scale.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "122990697",
                    "name": "Ashish Sharma"
                },
                {
                    "authorId": "2282231707",
                    "name": "Amy X. Zhang"
                },
                {
                    "authorId": "2261390356",
                    "name": "Tim Althoff"
                }
            ]
        },
        {
            "paperId": "d577c390dc56d65377f97098ea43c6a1f495f1b4",
            "title": "Linguistic-style-aware Neural Networks for Fake News Detection",
            "abstract": "We propose the hierarchical recursive neural network (HERO) to predict fake news by learning its linguistic style, which is distinguishable from the truth, as psychological theories reveal. We first generate the hierarchical linguistic tree of news documents; by doing so, we translate each news document's linguistic style into its writer's usage of words and how these words are recursively structured as phrases, sentences, paragraphs, and, ultimately, the document. By integrating the hierarchical linguistic tree with the neural network, the proposed method learns and classifies the representation of news documents by capturing their locally sequential and globally recursive structures that are linguistically meaningful. It is the first work offering the hierarchical linguistic tree and the neural network preserving the tree information to our best knowledge. Experimental results based on public real-world datasets demonstrate the proposed method's effectiveness, which can outperform state-of-the-art techniques in classifying short and long news documents. We also examine the differential linguistic style of fake news and the truth and observe some patterns of fake news. The code and data have been publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "2109012520",
                    "name": "Jiayuan Li"
                },
                {
                    "authorId": "2199804655",
                    "name": "Qinzhou Li"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                }
            ]
        },
        {
            "paperId": "1ddcfffea73bdd94d98ddebf6191ec65fb907620",
            "title": "\u201cThis is Fake! Shared it by Mistake\u201d:Assessing the Intent of Fake News Spreaders",
            "abstract": "Individuals can be misled by fake news and spread it unintentionally without knowing it is false. This phenomenon has been frequently observed but has not been investigated. Our aim in this work is to assess the intent of fake news spreaders. To distinguish between intentional versus unintentional spreading, we study the psychological explanations of unintentional spreading. With this foundation, we then propose an influence graph, using which we assess the intent of fake news spreaders. Our extensive experiments show that the assessed intent can help significantly differentiate between intentional and unintentional fake news spreaders. Furthermore, the estimated intent can significantly improve the current techniques that detect fake news. To our best knowledge, this is the first work to model individuals\u2019 intent in fake news spreading.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                },
                {
                    "authorId": "145041157",
                    "name": "V. Phoha"
                },
                {
                    "authorId": "38746648",
                    "name": "Huan Liu"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                }
            ]
        },
        {
            "paperId": "597cd3a02c52853abd38f163979f480ac3649ed4",
            "title": "From Fake News to #FakeNews: Mining Direct and Indirect Relationships among Hashtags for Fake News Detection",
            "abstract": "The COVID-19 pandemic has gained worldwide attention and allowed fake news, such as ``COVID-19 is the flu,'' to spread quickly and widely on social media. Combating this coronavirus infodemic demands effective methods to detect fake news. To this end, we propose a method to infer news credibility from hashtags involved in news dissemination on social media, motivated by the tight connection between hashtags and news credibility observed in our empirical analyses. We first introduce a new graph that captures all (direct and \\textit{indirect}) relationships among hashtags. Then, a language-independent semi-supervised algorithm is developed to predict fake news based on this constructed graph. This study first investigates the indirect relationship among hashtags;the proposed approach can be extended to any homogeneous graph to capture a comprehensive relationship among nodes. Language independence opens the proposed method to multilingual fake news detection. Experiments conducted on two real-world datasets demonstrate the effectiveness of our approach in identifying fake news, especially at an \\textit{early} stage of propagation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "06fb506703d8015b67d8f0ecdf01d7b23cd99f22",
            "title": "ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research",
            "abstract": "First identified in Wuhan, China, in December 2019, the outbreak of COVID-19 has been declared as a global emergency in January, and a pandemic in March 2020 by the World Health Organization (WHO). Along with this pandemic, we are also experiencing an \"infodemic\" of information with low credibility such as fake news and conspiracies. In this work, we present ReCOVery, a repository designed and constructed to facilitate research on combating such information regarding COVID-19. We first broadly search and investigate ~2,000 news publishers, from which 60 are identified with extreme [high or low] levels of credibility. By inheriting the credibility of the media on which they were published, a total of 2,029 news articles on coronavirus, published from January to May 2020, are collected in the repository, along with 140,820 tweets that reveal how these news articles have spread on the Twitter social network. The repository provides multimodal information of news articles on coronavirus, including textual, visual, temporal, and network information. The way that news credibility is obtained allows a trade-off between dataset scalability and label accuracy. Extensive experiments are conducted to present data statistics and distributions, as well as to provide baseline performances for predicting news credibility so that future methods can be compared. Our repository is available at http://coronavirus-fakenews.com.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "72018607",
                    "name": "Apurva Mulay"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                }
            ]
        },
        {
            "paperId": "559cf6845766cabd40bb5c659b3933df514a9166",
            "title": "Sentiment Paradoxes in Social Networks: Why Your Friends Are More Positive Than You?",
            "abstract": "Most people consider their friends to be more positive than themselves, exhibiting a Sentiment Paradox. Psychology research attributes this paradox to human cognition bias. With the goal to understand this phenomenon, we study sentiment paradoxes in social networks. Our work shows that social connections (friends, followees, or followers) of users are indeed (not just illusively) more positive than the users themselves. This is mostly due to positive users having more friends. We identify five sentiment paradoxes at different network levels ranging from triads to large-scale communities. Empirical and theoretical evidence are provided to validate the existence of such sentiment paradoxes. By investigating the relationships between the sentiment paradox and other well-developed network paradoxes, i.e., friendship paradox and activity paradox, we find that user sentiments are positively correlated to their number of friends but rarely to their social activity. Finally, we demonstrate how sentiment paradoxes can be used to predict user sentiments.",
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "28044622",
                    "name": "Shengmin Jin"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                }
            ]
        },
        {
            "paperId": "7ec72edf11f3f199df367bc38edebc7948aeb378",
            "title": "A Survey of Fake News",
            "abstract": "The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news detection and intervention. This survey reviews and evaluates methods that can detect fake news from four perspectives: the false knowledge it carries, its writing style, its propagation patterns, and the credibility of its source. The survey also highlights some potential research tasks based on the review. In particular, we identify and detail related fundamental theories across various disciplines to encourage interdisciplinary research on fake news. It is our hope that this survey can facilitate collaborative efforts among experts in computer and information sciences, social sciences, political science, and journalism to research fake news, where such efforts can lead to fake news detection that is not only efficient but, more importantly, explainable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                }
            ]
        },
        {
            "paperId": "0ccbc077ce72212523249af52ed91d79bc2a8d43",
            "title": "The Role of User Profiles for Fake News Detection",
            "abstract": "Consuming news from social media is becoming increasingly popular. Social media appeals to users due to its fast dissemination of information, low cost, and easy access. However, social media also enables the widespread of fake news. Due to the detrimental societal effects of fake news, detecting fake news has attracted increasing attention. However, the detection performance only using news contents is generally not satisfactory as fake news is written to mimic true news. Thus, there is a need for an in-depth understanding on the relationship between user profiles on social media and fake news. In this paper, we study the problem of understanding and exploiting user profiles on social media for fake news detection. In an attempt to understand connections between user profiles and fake news, first, we measure users' sharing behaviors and group representative users who are more likely to share fake and real news; then, we perform a comparative analysis of explicit and implicit profile features between these user groups, which reveals their potential to help differentiate fake news from real news. To exploit user profile features, we demonstrate the usefulness of these user profile features in a fake news classification task. We further validate the effectiveness of these features through feature importance analysis. The findings of this work lay the foundation for deeper exploration of user profile features of social media and enhance the capabilities for fake news detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                },
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "2893721",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "38746648",
                    "name": "Huan Liu"
                }
            ]
        },
        {
            "paperId": "285659a292e6b5fb0820941241311a8e8b35586e",
            "title": "Fake News Detection: An Interdisciplinary Research",
            "abstract": "The explosive growth of fake news and its erosion to democracy, journalism and economy has increased the demand for fake news detection. To achieve efficient and explainable fake news detection, an interdisciplinary approach is required, relying on scientific contributions from various disciplines, e.g., social sciences, engineering, among others. Here, we illustrate how such multidisciplinary contributions can help detect fake news by improving feature engineering, or by providing well-justified machine learning models. We demonstrate how news content, news propagation patterns, and users\u2019 engagements with news can help detect fake news.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                }
            ]
        },
        {
            "paperId": "3a86c96e20544bc597fea6ff675a6caeb017a04d",
            "title": "Fake News: Fundamental Theories, Detection Strategies and Challenges",
            "abstract": "The explosive growth of fake news and its erosion to democracy, justice, and public trust increased the demand for fake news detection. As an interdisciplinary topic, the study of fake news encourages a concerted effort of experts in computer and information science, political science, journalism, social science, psychology, and economics. A comprehensive framework to systematically understand and detect fake news is necessary to attract and unite researchers in related areas to conduct research on fake news. This tutorial aims to clearly present (1) fake news research, its challenges, and research directions; (2) a comparison between fake news and other related concepts (e.g., rumors); (3) the fundamental theories developed across various disciplines that facilitate interdisciplinary research; (4) various detection strategies unified under a comprehensive framework for fake news detection; and (5) the state-of-the-art datasets, patterns, and models. We present fake news detection from various perspectives, which involve news content and information in social networks, and broadly adopt techniques in data mining, machine learning, natural language processing, information retrieval and social search. Facing the upcoming 2020 U.S. presidential election, challenges for automatic, effective and efficient fake news detection are also clarified in this tutorial.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490776655",
                    "name": "Xinyi Zhou"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "145800151",
                    "name": "Kai Shu"
                },
                {
                    "authorId": "145896397",
                    "name": "Huan Liu"
                }
            ]
        }
    ]
}