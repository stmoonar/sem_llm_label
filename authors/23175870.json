{
    "authorId": "23175870",
    "papers": [
        {
            "paperId": "71303f1c03a56694d983b1c0230b432714243ba2",
            "title": "SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature",
            "abstract": "We present SciRIFF (Scientific Resource for Instruction-Following and Finetuning), a dataset of 137K instruction-following demonstrations for 54 tasks covering five essential scientific literature understanding capabilities: information extraction, summarization, question answering, claim verification, and classification. SciRIFF demonstrations are notable for their long input contexts, detailed task specifications, and complex structured outputs. While instruction-following resources are available in specific domains such as clinical medicine and chemistry, SciRIFF is the first dataset focused on extracting and synthesizing information from research literature across a wide range of scientific fields. To demonstrate the utility of SciRIFF, we develop a sample-efficient strategy to adapt a general instruction-following model for science by performing additional finetuning on a mix of general-domain and SciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our model -- called SciTulu -- improves over a strong LLM baseline by 28.1% and 6.5% at the 7B and 70B scales respectively, while maintaining general instruction-following performance within 2% of the baseline. We are optimistic that SciRIFF will facilitate the development and evaluation of LLMs to help researchers navigate the ever-growing body of scientific literature. We release our dataset, model checkpoints, and data processing and evaluation code to enable further research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30051202",
                    "name": "David Wadden"
                },
                {
                    "authorId": "2259032293",
                    "name": "Kejian Shi"
                },
                {
                    "authorId": "2146964035",
                    "name": "Jacob Daniel Morrison"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "14918655",
                    "name": "Shruti Singh"
                },
                {
                    "authorId": "2305813534",
                    "name": "Nitzan Barzilay"
                },
                {
                    "authorId": "2285152499",
                    "name": "Kyle Lo"
                },
                {
                    "authorId": "2266841339",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "2280666145",
                    "name": "Luca Soldaini"
                },
                {
                    "authorId": "2306748517",
                    "name": "Shannon Zejiang Shen"
                },
                {
                    "authorId": "2266840873",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "2264251662",
                    "name": "Hanna Hajishirzi"
                },
                {
                    "authorId": "2527954",
                    "name": "Arman Cohan"
                }
            ]
        },
        {
            "paperId": "ac45bbf9940512d9d686cf8cd3a95969bc313570",
            "title": "OLMo: Accelerating the Science of Language Models",
            "abstract": "Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and development undisclosed. Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs. To this end, we have built OLMo, a competitive, truly Open Language Model, to enable the scientific study of language models. Unlike most prior efforts that have only released model weights and inference code, we release OLMo alongside open training data and training and evaluation code. We hope this release will empower the open research community and inspire a new wave of innovation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3458736",
                    "name": "Dirk Groeneveld"
                },
                {
                    "authorId": "2260133345",
                    "name": "Iz Beltagy"
                },
                {
                    "authorId": "2158819969",
                    "name": "Pete Walsh"
                },
                {
                    "authorId": "2166136235",
                    "name": "Akshita Bhagia"
                },
                {
                    "authorId": "2282136328",
                    "name": "Rodney Kinney"
                },
                {
                    "authorId": "3385516",
                    "name": "Oyvind Tafjord"
                },
                {
                    "authorId": "47286118",
                    "name": "A. Jha"
                },
                {
                    "authorId": "2056776606",
                    "name": "Hamish Ivison"
                },
                {
                    "authorId": "2124977543",
                    "name": "Ian Magnusson"
                },
                {
                    "authorId": "1705260",
                    "name": "Yizhong Wang"
                },
                {
                    "authorId": "2259924223",
                    "name": "Shane Arora"
                },
                {
                    "authorId": "2282136757",
                    "name": "David Atkinson"
                },
                {
                    "authorId": "2202417686",
                    "name": "Russell Authur"
                },
                {
                    "authorId": "37619618",
                    "name": "Khyathi Raghavi Chandu"
                },
                {
                    "authorId": "2527954",
                    "name": "Arman Cohan"
                },
                {
                    "authorId": "2282136556",
                    "name": "Jennifer Dumas"
                },
                {
                    "authorId": "51131518",
                    "name": "Yanai Elazar"
                },
                {
                    "authorId": "2261456046",
                    "name": "Yuling Gu"
                },
                {
                    "authorId": "2689239",
                    "name": "Jack Hessel"
                },
                {
                    "authorId": "2236429",
                    "name": "Tushar Khot"
                },
                {
                    "authorId": "2282138468",
                    "name": "William Merrill"
                },
                {
                    "authorId": "2146964035",
                    "name": "Jacob Daniel Morrison"
                },
                {
                    "authorId": "2037383772",
                    "name": "Niklas Muennighoff"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2282136595",
                    "name": "Crystal Nam"
                },
                {
                    "authorId": "2267244582",
                    "name": "Matthew E. Peters"
                },
                {
                    "authorId": "22330666",
                    "name": "Valentina Pyatkin"
                },
                {
                    "authorId": "3023068",
                    "name": "Abhilasha Ravichander"
                },
                {
                    "authorId": "2264248042",
                    "name": "Dustin Schwenk"
                },
                {
                    "authorId": "2282190660",
                    "name": "Saurabh Shah"
                },
                {
                    "authorId": "2282155558",
                    "name": "Will Smith"
                },
                {
                    "authorId": "2268272",
                    "name": "Emma Strubell"
                },
                {
                    "authorId": "34202134",
                    "name": "Nishant Subramani"
                },
                {
                    "authorId": "52193502",
                    "name": "Mitchell Wortsman"
                },
                {
                    "authorId": "2697425",
                    "name": "Pradeep Dasigi"
                },
                {
                    "authorId": "2267244197",
                    "name": "Nathan Lambert"
                },
                {
                    "authorId": "46666605",
                    "name": "Kyle Richardson"
                },
                {
                    "authorId": "2137813791",
                    "name": "Luke S. Zettlemoyer"
                },
                {
                    "authorId": "34176020",
                    "name": "Jesse Dodge"
                },
                {
                    "authorId": "46258841",
                    "name": "Kyle Lo"
                },
                {
                    "authorId": "3328733",
                    "name": "Luca Soldaini"
                },
                {
                    "authorId": "2264002618",
                    "name": "Noah A. Smith"
                },
                {
                    "authorId": "2264251662",
                    "name": "Hanna Hajishirzi"
                }
            ]
        },
        {
            "paperId": "ad1bb59e3e18a0dd8503c3961d6074f162baf710",
            "title": "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research",
            "abstract": "Information about pretraining corpora used to train the current best-performing language models is seldom discussed: commercial models rarely detail their data, and even open models are often released without accompanying training data or recipes to reproduce them. As a result, it is challenging to conduct and advance scientific research on language modeling, such as understanding how training data impacts model capabilities and limitations. To facilitate scientific research on language model pretraining, we curate and release Dolma, a three-trillion-token English corpus, built from a diverse mixture of web content, scientific papers, code, public-domain books, social media, and encyclopedic materials. We extensively document Dolma, including its design principles, details about its construction, and a summary of its contents. We present analyses and experimental results on intermediate states of Dolma to share what we have learned about important data curation practices. Finally, we open-source our data curation toolkit to enable reproduction of our work as well as support further research in large-scale data curation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3328733",
                    "name": "Luca Soldaini"
                },
                {
                    "authorId": "2282136328",
                    "name": "Rodney Kinney"
                },
                {
                    "authorId": "2166136235",
                    "name": "Akshita Bhagia"
                },
                {
                    "authorId": "2264248042",
                    "name": "Dustin Schwenk"
                },
                {
                    "authorId": "2282136757",
                    "name": "David Atkinson"
                },
                {
                    "authorId": "2202417686",
                    "name": "Russell Authur"
                },
                {
                    "authorId": "50757607",
                    "name": "Ben Bogin"
                },
                {
                    "authorId": "37619618",
                    "name": "Khyathi Raghavi Chandu"
                },
                {
                    "authorId": "2282136556",
                    "name": "Jennifer Dumas"
                },
                {
                    "authorId": "51131518",
                    "name": "Yanai Elazar"
                },
                {
                    "authorId": "2275055850",
                    "name": "Valentin Hofmann"
                },
                {
                    "authorId": "47286118",
                    "name": "A. Jha"
                },
                {
                    "authorId": "2282203839",
                    "name": "Sachin Kumar"
                },
                {
                    "authorId": "2259003726",
                    "name": "L. Lucy"
                },
                {
                    "authorId": "2156533327",
                    "name": "Xinxi Lyu"
                },
                {
                    "authorId": "2267244197",
                    "name": "Nathan Lambert"
                },
                {
                    "authorId": "2124977543",
                    "name": "Ian Magnusson"
                },
                {
                    "authorId": "2146964035",
                    "name": "Jacob Daniel Morrison"
                },
                {
                    "authorId": "2037383772",
                    "name": "Niklas Muennighoff"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2282136595",
                    "name": "Crystal Nam"
                },
                {
                    "authorId": "2267244582",
                    "name": "Matthew E. Peters"
                },
                {
                    "authorId": "3023068",
                    "name": "Abhilasha Ravichander"
                },
                {
                    "authorId": "46666605",
                    "name": "Kyle Richardson"
                },
                {
                    "authorId": "101568984",
                    "name": "Zejiang Shen"
                },
                {
                    "authorId": "2268272",
                    "name": "Emma Strubell"
                },
                {
                    "authorId": "34202134",
                    "name": "Nishant Subramani"
                },
                {
                    "authorId": "3385516",
                    "name": "Oyvind Tafjord"
                },
                {
                    "authorId": "2158819969",
                    "name": "Pete Walsh"
                },
                {
                    "authorId": "2137813791",
                    "name": "Luke S. Zettlemoyer"
                },
                {
                    "authorId": "2264002618",
                    "name": "Noah A. Smith"
                },
                {
                    "authorId": "2264251662",
                    "name": "Hanna Hajishirzi"
                },
                {
                    "authorId": "2260133345",
                    "name": "Iz Beltagy"
                },
                {
                    "authorId": "3458736",
                    "name": "Dirk Groeneveld"
                },
                {
                    "authorId": "34176020",
                    "name": "Jesse Dodge"
                },
                {
                    "authorId": "46258841",
                    "name": "Kyle Lo"
                }
            ]
        },
        {
            "paperId": "cc13d65f00d02c6fc01fc996a10e7bc503e3deec",
            "title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER",
            "abstract": "Despite their general capabilities, LLMs still struggle on biomedicalNER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs.For example, it leads to a relative improvement of 15% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code at https://github.com/allenai/beacon.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294363095",
                    "name": "Monica Munnangi"
                },
                {
                    "authorId": "2294364786",
                    "name": "Sergey Feldman"
                },
                {
                    "authorId": "2306260315",
                    "name": "Byron C. Wallace"
                },
                {
                    "authorId": "2294355004",
                    "name": "Silvio Amir"
                },
                {
                    "authorId": "2266841339",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                }
            ]
        },
        {
            "paperId": "096ca3c5da860d41811c741ddc29242d90d1ccea",
            "title": "The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces",
            "abstract": "\n Scholarly publications are key to the transfer of knowledge from scholars to others. However, research papers are information-dense, and as the volume of the scientific literature grows, the greater the need for new technology to support scholars. In contrast to the process of\n finding\n papers, which has been transformed by Internet technology, the experience of\n reading\n research papers has changed little in decades. For instance, the PDF format for sharing papers remains widely used due to its portability but has significant downsides, inter alia, static content and poor accessibility for low-vision readers. This paper explores the question \u201cCan recent advances in AI and HCI power intelligent, interactive, and accessible reading interfaces\u2014even for legacy PDFs?\u201d We describe the Semantic Reader Project, a collaborative effort across multiple institutions to explore automatic creation of dynamic reading interfaces for research papers. Through this project, we\u2019ve developed a collection of novel reading interfaces and evaluated them with study participants and real-world users to show improved reading experiences for scholars. We\u2019ve also released a production research paper reading interface that will continuously incorporate novel features from our research as they mature. We structure this paper around five key opportunities for AI assistance in scholarly reading \u2014discovery, efficiency, comprehension, synthesis, and accessibility\u2014and present an overview of our progress and discuss remaining open challenges.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46258841",
                    "name": "Kyle Lo"
                },
                {
                    "authorId": "48808806",
                    "name": "Joseph Chee Chang"
                },
                {
                    "authorId": "2065039588",
                    "name": "Andrew Head"
                },
                {
                    "authorId": "2699105",
                    "name": "Jonathan Bragg"
                },
                {
                    "authorId": "144518215",
                    "name": "Amy X. Zhang"
                },
                {
                    "authorId": "2212791328",
                    "name": "Cassidy Trier"
                },
                {
                    "authorId": "1667818755",
                    "name": "Chloe Anastasiades"
                },
                {
                    "authorId": "50509991",
                    "name": "Tal August"
                },
                {
                    "authorId": "2202417686",
                    "name": "Russell Authur"
                },
                {
                    "authorId": "36472974",
                    "name": "Danielle Bragg"
                },
                {
                    "authorId": "2203427167",
                    "name": "Erin Bransom"
                },
                {
                    "authorId": "51199773",
                    "name": "Isabel Cachola"
                },
                {
                    "authorId": "2202412446",
                    "name": "Stefan Candra"
                },
                {
                    "authorId": "1648642525",
                    "name": "Yoganand Chandrasekhar"
                },
                {
                    "authorId": "2014491",
                    "name": "Yen-Sung Chen"
                },
                {
                    "authorId": "2087062598",
                    "name": "Evie (Yu-Yen) Cheng"
                },
                {
                    "authorId": "2212532904",
                    "name": "Yvonne Chou"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "79519990",
                    "name": "Rob Evans"
                },
                {
                    "authorId": "27083453",
                    "name": "Raymond Fok"
                },
                {
                    "authorId": "2200023814",
                    "name": "F.Q. Hu"
                },
                {
                    "authorId": "153179615",
                    "name": "Regan Huff"
                },
                {
                    "authorId": "48493368",
                    "name": "Dongyeop Kang"
                },
                {
                    "authorId": "1410132100",
                    "name": "Tae Soo Kim"
                },
                {
                    "authorId": "143967880",
                    "name": "Rodney Michael Kinney"
                },
                {
                    "authorId": "145234497",
                    "name": "A. Kittur"
                },
                {
                    "authorId": "26997666",
                    "name": "Hyeonsu B Kang"
                },
                {
                    "authorId": "2082935910",
                    "name": "Egor Klevak"
                },
                {
                    "authorId": "2003338023",
                    "name": "Bailey Kuehl"
                },
                {
                    "authorId": "48758753",
                    "name": "Michael Langan"
                },
                {
                    "authorId": "2087047386",
                    "name": "Matt Latzke"
                },
                {
                    "authorId": "3047023",
                    "name": "Jaron Lochner"
                },
                {
                    "authorId": "2071601396",
                    "name": "Kelsey MacMillan"
                },
                {
                    "authorId": "2212655982",
                    "name": "Eric Stuart Marsh"
                },
                {
                    "authorId": "144240185",
                    "name": "Tyler C. Murray"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2212649446",
                    "name": "Ngoc-Uyen Nguyen"
                },
                {
                    "authorId": "144358729",
                    "name": "Srishti Palani"
                },
                {
                    "authorId": "2504744",
                    "name": "Soya Park"
                },
                {
                    "authorId": "2213513911",
                    "name": "Caroline Paulic"
                },
                {
                    "authorId": "3124383",
                    "name": "Napol Rachatasumrit"
                },
                {
                    "authorId": "2115660042",
                    "name": "Smita R Rao"
                },
                {
                    "authorId": "114609552",
                    "name": "Paul Sayre"
                },
                {
                    "authorId": "101568984",
                    "name": "Zejiang Shen"
                },
                {
                    "authorId": "3061428",
                    "name": "Pao Siangliulue"
                },
                {
                    "authorId": "3328733",
                    "name": "Luca Soldaini"
                },
                {
                    "authorId": "2057077868",
                    "name": "Huy Tran"
                },
                {
                    "authorId": "15292561",
                    "name": "Madeleine van Zuylen"
                },
                {
                    "authorId": "31860505",
                    "name": "Lucy Lu Wang"
                },
                {
                    "authorId": "46212260",
                    "name": "Christopher Wilhelm"
                },
                {
                    "authorId": "2109360295",
                    "name": "Caroline M Wu"
                },
                {
                    "authorId": "82148460",
                    "name": "Jiangjiang Yang"
                },
                {
                    "authorId": "98442688",
                    "name": "Angele Zamarron"
                },
                {
                    "authorId": "1716902",
                    "name": "Marti A. Hearst"
                },
                {
                    "authorId": "1780531",
                    "name": "Daniel S. Weld"
                }
            ]
        },
        {
            "paperId": "0bc975e61002ec29ac67d44d91d35cdbfc56982a",
            "title": "S2abEL: A Dataset for Entity Linking from Scientific Tables",
            "abstract": "Entity linking (EL) is the task of linking a textual mention to its corresponding entry in a knowledge base, and is critical for many knowledge-intensive NLP applications. When applied to tables in scientific papers, EL is a step toward large-scale scientific knowledge bases that could enable advanced scientific question answering and analytics. We present the first dataset for EL in scientific tables. EL for scientific tables is especially challenging because scientific knowledge bases can be very incomplete, and disambiguating table mentions typically requires understanding the papers's tet in addition to the table. Our dataset, S2abEL, focuses on EL in machine learning results tables and includes hand-labeled cell types, attributed sources, and entity links from the PaperswithCode taxonomy for 8,429 cells from 732 tables. We introduce a neural baseline method designed for EL on scientific tables containing many out-of-knowledge-base mentions, and show that it significantly outperforms a state-of-the-art generic table EL method. The best baselines fall below human performance, and our analysis highlights avenues for improvement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143904011",
                    "name": "Yuze Lou"
                },
                {
                    "authorId": "2003338023",
                    "name": "Bailey Kuehl"
                },
                {
                    "authorId": "2203427167",
                    "name": "Erin Bransom"
                },
                {
                    "authorId": "46411828",
                    "name": "Sergey Feldman"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                }
            ]
        },
        {
            "paperId": "316a011bf461d3a96965fb9f69398888da19bd9f",
            "title": "SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design",
            "abstract": "Predicting synergistic drug combinations can help accelerate discovery of cancer treatments, particularly therapies personalized to a patient\u2019s specific tumor via biopsied cells. In this paper, we propose a novel setting and models for in-context drug synergy learning. We are given a small \u201cpersonalized dataset\u201d of 10-20 drug synergy relationships in the context of specific cancer cell targets. Our goal is to predict additional drug synergy relationships in that context. Inspired by recent work that pre-trains a GPT language model (LM) to \u201cin-context learn\u201d common function classes, we devise novel pre-training schemes that enable a GPT model to in-context learn \u201cdrug synergy functions\u201d. Our model\u2014which does not use any textual corpora, molecular fingerprints, protein interaction or any other domain-specific knowledge\u2014 is able to achieve competitive results. We further integrate our in-context approach with a genetic algorithm to optimize model prompts and select synergy candidates to test after conducting a patient biopsy. Finally, we explore a novel task of inverse drug design which can potentially enable the design of drugs that synergize specifically to target a given patient\u2019s \u201cpersonalized dataset\u201d. Our findings can potentially have an important impact on precision cancer medicine, and also raise intriguing questions on non-textual pre-training for LMs.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "48870109",
                    "name": "Carl N. Edwards"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2236429",
                    "name": "Tushar Khot"
                },
                {
                    "authorId": "2199258773",
                    "name": "Martin Burke"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                }
            ]
        },
        {
            "paperId": "c388626d1a342339078aaab7acc280efbc4f77fc",
            "title": "Relatedly: Scaffolding Literature Reviews with Existing Related Work Sections",
            "abstract": "Scholars who want to research a scientific topic must take time to read, extract meaning, and identify connections across many papers. As scientific literature grows, this becomes increasingly challenging. Meanwhile, authors summarize prior research in papers\u2019 related work sections, though this is scoped to support a single paper. A formative study found that while reading multiple related work paragraphs helps overview a topic, it is hard to navigate overlapping and diverging references and research foci. In this work, we design a system, Relatedly, that scaffolds exploring and reading multiple related work paragraphs on a topic, with features including dynamic re-ranking and highlighting to spotlight unexplored dissimilar information, auto-generated descriptive paragraph headings, and low-lighting of redundant information. From a within-subjects user study (n=15), we found that scholars generate more coherent, insightful, and comprehensive topic outlines using Relatedly compared to a baseline paper list.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144358729",
                    "name": "Srishti Palani"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "144518215",
                    "name": "Amy X. Zhang"
                },
                {
                    "authorId": "2699105",
                    "name": "Jonathan Bragg"
                },
                {
                    "authorId": "48808806",
                    "name": "Joseph Chee Chang"
                }
            ]
        },
        {
            "paperId": "f11c2caf3e919ce62d7c73ae0e22370ec6a56d42",
            "title": "CARE: Extracting Experimental Findings From Clinical Literature",
            "abstract": "Extracting fine-grained experimental findings from literature can provide dramatic utility for scientific applications. Prior work has developed annotation schemas and datasets for limited aspects of this problem, failing to capture the real-world complexity and nuance required. Focusing on biomedicine, this work presents CARE -- a new IE dataset for the task of extracting clinical findings. We develop a new annotation schema capturing fine-grained findings as n-ary relations between entities and attributes, which unifies phenomena challenging for current IE systems such as discontinuous entity spans, nested relations, variable arity n-ary relations and numeric results in a single schema. We collect extensive annotations for 700 abstracts from two sources: clinical trials and case reports. We also demonstrate the generalizability of our schema to the computer science and materials science domains. We benchmark state-of-the-art IE systems on CARE, showing that even models such as GPT4 struggle. We release our resources to advance research on extracting and aggregating literature findings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2003338023",
                    "name": "Bailey Kuehl"
                },
                {
                    "authorId": "2203427167",
                    "name": "Erin Bransom"
                },
                {
                    "authorId": "2266840873",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "2266841339",
                    "name": "Tom Hope"
                }
            ]
        },
        {
            "paperId": "cc2afed978808b26c752b6a0de682febd4d0f1dd",
            "title": "Distilling Multi-Scale Knowledge for Event Temporal Relation Extraction",
            "abstract": "Event Temporal Relation Extraction (ETRE) is paramount but challenging. Within a discourse, event pairs are situated at different distances or the so-called proximity bands. The temporal ordering communicated about event pairs where at more remote (i.e., ``long'') or less remote (i.e., ``short'') proximity bands are encoded differently. SOTA models have tended to perform well on events situated at either short or long proximity bands, but not both. Nonetheless, real-world, natural texts contain all types of temporal event-pairs. In this paper, we present MulCo: Distilling Multi-Scale Knowledge via Contrastive Learning, a knowledge co-distillation approach that shares knowledge across multiple event pair proximity bands to improve performance on all types of temporal datasets. Our experimental results show that MulCo successfully integrates linguistic cues pertaining to temporal reasoning across both short and long proximity bands and achieves new state-of-the-art results on several ETRE benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "95930559",
                    "name": "Hao-Ren Yao"
                },
                {
                    "authorId": "113477466",
                    "name": "Luke Breitfeller"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2181179636",
                    "name": "Chunxiao Zhou"
                },
                {
                    "authorId": "35959897",
                    "name": "C. Ros\u00e9"
                }
            ]
        }
    ]
}