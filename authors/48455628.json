{
    "authorId": "48455628",
    "papers": [
        {
            "paperId": "f23e6fccf1c9ac8146ace7bf1882aa0f2088d4c5",
            "title": "Tailoring Generative Adversarial Networks for Smooth Airfoil Design",
            "abstract": "In the realm of aerospace design, achieving smooth curves is paramount, particularly when crafting objects such as airfoils. Generative Adversarial Network (GAN), a widely employed generative AI technique, has proven instrumental in synthesizing airfoil designs. However, a common limitation of GAN is the inherent lack of smoothness in the generated airfoil surfaces. To address this issue, we present a GAN model featuring a customized loss function built to produce seamlessly contoured airfoil designs. Additionally, our model demonstrates a substantial increase in design diversity compared to a conventional GAN augmented with a post-processing smoothing filter.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49379063",
                    "name": "Joyjit Chattoraj"
                },
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "2297357465",
                    "name": "Zexuan Zhang"
                },
                {
                    "authorId": "2278427776",
                    "name": "Manna Dai"
                },
                {
                    "authorId": "2278551769",
                    "name": "Yingzhi Xia"
                },
                {
                    "authorId": "2297342890",
                    "name": "Jichao Li"
                },
                {
                    "authorId": "2297245403",
                    "name": "Xinxing Xu"
                },
                {
                    "authorId": "2299593461",
                    "name": "Chin Chun Ooi"
                },
                {
                    "authorId": "2298007507",
                    "name": "Yang Feng"
                },
                {
                    "authorId": "47355071",
                    "name": "M. Dao"
                },
                {
                    "authorId": "2290684177",
                    "name": "Yong Liu"
                }
            ]
        },
        {
            "paperId": "21caec3a73113032ebde1e53d7b8ea1a799d26bf",
            "title": "LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry",
            "abstract": "We present a novel loss formulation for efficient learning of complex dynamics from governing physics, typically described by partial differential equations (PDEs), using physics-informed neural networks (PINNs). In our experiments, existing versions of PINNs are seen to learn poorly in many problems, especially for complex geometries, as it becomes increasingly difficult to establish appropriate sampling strategy at the near boundary region. Overly dense sampling can adversely impede training convergence if the local gradient behaviors are too complex to be adequately modelled by PINNs. On the other hand, if the samples are too sparse, existing PINNs tend to overfit the near boundary region, leading to incorrect solution. To prevent such issues, we propose a new Boundary Connectivity (BCXN) loss function which provides linear local structure approximation (LSA) to the gradient behaviors at the boundary for PINN. Our BCXN-loss implicitly imposes local structure during training, thus facilitating fast physics-informed learning across entire prob-lem domains with order of magnitude sparser training samples. This LSA-PINN method shows a few orders of magnitude smaller errors than existing methods in terms of the standard L2-norm metric, while using dramatically fewer training samples and iterations. Our proposed LSA-PINN does not pose any requirement on the differentiable property of the networks, and we demonstrate its benefits and ease of implementation on both multi-layer perceptron and convolutional neural network versions as commonly used in current PINN literature.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                },
                {
                    "authorId": "47355071",
                    "name": "M. Dao"
                },
                {
                    "authorId": "144848119",
                    "name": "Y. Ong"
                }
            ]
        },
        {
            "paperId": "afcdf1fdec05ab4e02ad903d1dddd9b48bd7cdb2",
            "title": "Generalizable Neural Physics Solvers by Baldwinian Evolution",
            "abstract": "Physics-informed neural networks (PINNs) are at the forefront of scientific machine learning, making possible the creation of machine intelligence that is cognizant of physical laws and able to accurately simulate them. In this paper, the potential of discovering PINNs that generalize over an entire family of physics tasks is studied, for the first time, through a biological lens of the Baldwin effect. Drawing inspiration from the neurodevelopment of precocial species that have evolved to learn, predict and react quickly to their environment, we envision PINNs that are pre-wired with connection strengths inducing strong biases towards efficient learning of physics. To this end, evolutionary selection pressure (guided by proficiency over a family of tasks) is coupled with lifetime learning (to specialize on a smaller subset of those tasks) to produce PINNs that demonstrate fast and physics-compliant prediction capabilities across a range of empirically challenging problem instances. The Baldwinian approach achieves an order of magnitude improvement in prediction accuracy at a fraction of the computation cost compared to state-of-the-art results with PINNs meta-learned by gradient descent. This paper marks a leap forward in the meta-learning of PINNs as generalizable physics solvers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                },
                {
                    "authorId": "2116391700",
                    "name": "Abhishek Gupta"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "2269982639",
                    "name": "Joshua Shao Zheng Low"
                },
                {
                    "authorId": "47355071",
                    "name": "M. Dao"
                },
                {
                    "authorId": "8748397",
                    "name": "Y. Ong"
                }
            ]
        },
        {
            "paperId": "0362bf13bf4be5959683c2bd792d08913f4529d6",
            "title": "JAX-Accelerated Neuroevolution of Physics-informed Neural Networks: Benchmarks and Experimental Results",
            "abstract": "\u2013 This paper introduces the use of evolutionary algorithms for solving differential equations. The solution is obtained by optimizing a deep neural network whose loss function is defined by the residual terms from the differential equations. Recent studies have used stochastic gradient descent (SGD) variants to train these physics-informed neural networks (PINNs), but these methods can struggle to find accurate solutions due to optimization challenges. When solving differential equations, it is important to find the globally optimum parameters of the network, rather than just finding a solution that works well during training. SGD only searches along a single gradient direction, so it may not be the best approach for training PINNs with their accompanying complex optimization landscapes. In contrast, evolutionary algorithms perform a parallel exploration of different solutions in order to avoid getting stuck in local optima and can potentially find more accurate solutions. However, evolutionary algorithms can be slow, which can make them difficult to use in practice. To address this, we provide a set of five benchmark problems with associated performance metrics and baseline results to support the development of evolutionary algorithms for enhanced PINN training. As a baseline, we evaluate the performance and speed of using the widely adopted Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for solving PINNs. We provide the loss and training time for CMA-ES run on TensorFlow (both with and without GPU acceleration), and CMA-ES and SGD run on JAX (with GPU acceleration) for the five benchmark problems. Our results show that JAX-accelerated evolutionary algorithms, particularly CMA-ES, can be a useful approach for solving differential equations. We hope that our work will support the exploration and development of alternative optimization algorithms for the complex task of optimizing PINNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2095456267",
                    "name": "N. Yong"
                },
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "2116391700",
                    "name": "Abhishek Gupta"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                },
                {
                    "authorId": "144848119",
                    "name": "Y. Ong"
                }
            ]
        },
        {
            "paperId": "2b8ed70ee0065ac2fb9eef478c3f89ceb515e2e1",
            "title": "Physics Compliance as a Metric for Neural Network Uncertainty",
            "abstract": "Machine learning models are gradually gaining acceptance for deployment in science and engineering in recent years as industries mature and become more comfortable with data-driven methods, spanning the whole spectrum from data collection through to data engineering and data modelling. However, unease remains about the accuracy of predictions from these surrogate models when applied in industry, especially as these methods are often utilized as a black-box. Demand for uncertainty quantification has thus increased, especially in critical processes where one requires information about the degree of uncertainty in the prediction to better manage associated risks. Statistical methods such as Bayesian networks and deep ensembles have correspondingly been developed as possible solutions in recent years. While these methods are applicable across multiple domains, they can be computationally expensive or difficult to implement, and fail to capitalize on inherent physics present in many real-world problems. In this work, we thus propose to exploit our prior knowledge of the system, and use physics-based rules and relationships to estimate the degree of uncertainty in the model predictions. We compare the obtained results on a metasurface model system to state-of-the-art methods such as deep ensembles and hyperparameter ensembles. The promising results on this model system suggest that metrics to measure compliance to physics-based rules and relationships can indeed be a useful proxy for estimating these data-driven models' uncertainty, with these relations performing as well as conventional ensemble-based approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204745601",
                    "name": "Zhong Liang Ou Yang"
                },
                {
                    "authorId": "2151912562",
                    "name": "Yang Jiang"
                },
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "2155577916",
                    "name": "Weijiang Zhao"
                },
                {
                    "authorId": "47355071",
                    "name": "M. Dao"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                }
            ]
        },
        {
            "paperId": "3406cf2d8483fe718aea0f80ee015475c664fb35",
            "title": "Neuroevolution of Physics-Informed Neural Nets: Benchmark Problems and Comparative Results",
            "abstract": "The potential of learned models for fundamental scientific research and discovery is drawing increasing attention worldwide. Physics-informed neural networks (PINNs), where the loss function directly embeds governing equations of scientific phenomena, is one of the key techniques at the forefront of recent advances. PINNs are typically trained using stochastic gradient descent methods, akin to their deep learning counterparts. However, analysis in this paper shows that PINNs' unique loss formulations lead to a high degree of complexity and ruggedness that may not be conducive for gradient descent. Unlike in standard deep learning, PINN training requires globally optimum parameter values that satisfy physical laws as closely as possible. Spurious local optimum, indicative of erroneous physics, must be avoided. Hence, neuroevolution algorithms, with their superior global search capacity, may be a better choice for PINNs relative to gradient descent methods. Here, we propose a set of five benchmark problems, with open-source codes, spanning diverse physical phenomena for novel neuroevolution algorithm development. Using this, we compare two neuroevolution algorithms against the commonly used stochastic gradient descent, and our baseline results support the claim that neuroevolution can surpass gradient descent, ensuring better physics compliance in the predicted outputs.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2224581148",
                    "name": "Nicholas Sung"
                },
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                },
                {
                    "authorId": "2116391700",
                    "name": "Abhishek Gupta"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "8748397",
                    "name": "Y. Ong"
                }
            ]
        },
        {
            "paperId": "4f647c333307f7742ab08a1ed691d0068036d3f8",
            "title": "Design of Turing Systems with Physics-Informed Neural Networks",
            "abstract": "Reaction-diffusion (Turing) systems are fundamental to the formation of spatial patterns in nature and engineering. These systems are governed by a set of non-linear partial differential equations containing parameters that determine the rate of constituent diffusion and reaction. Critically, these parameters, such as diffusion coefficient, heavily influence the mode and type of the final pattern, and quantitative characterization and knowledge of these parameters can aid in bio-mimetic design or understanding of real-world systems. However, the use of numerical methods to infer these parameters can be difficult and computationally expensive. Typically, adjoint solvers may be used, but they are frequently unstable for very non-linear systems. Alternatively, massive amounts of iterative forward simulations are used to find the best match, but this is extremely effortful. Recently, physics-informed neural networks have been proposed as a means for data-driven discovery of partial differential equations, and have seen success in various applications. Thus, we investigate the use of physics-informed neural networks as a tool to infer key parameters in reaction\u2500diffusion systems in the steady-state for scientific discovery or design. Our proof-of-concept results show that the method is able to infer parameters for different pattern modes and types with errors of less than 10%. In addition, the stochastic nature of this method can be exploited to provide multiple parameter alternatives to the desired pattern, highlighting the versatility of this method for bio-mimetic design. This work thus demonstrates the utility of physics-informed neural networks for inverse parameter inference of reaction-diffusion systems to enhance scientific discovery and design.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "71310335",
                    "name": "J. Kho"
                },
                {
                    "authorId": "36749921",
                    "name": "W. Koh"
                },
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                }
            ]
        },
        {
            "paperId": "953d6c230cb2c1880ebc8f9b04140ef56c44c007",
            "title": "FastFlow: AI for Fast Urban Wind Velocity Prediction",
            "abstract": "Data-driven approaches, including deep learning, have shown great promise as surrogate models across many domains, including computer vision and natural language pro-cessing. These extend to various areas in sustainability, including for satellite image analysis to obtain information such as land usage and extent of development. An interesting direction for which data-driven methods have not been applied much yet is in the quick quantitative evaluation of urban layouts for planning and design. In particular, urban designs typically involve complex trade-offs between multiple objectives, including limits on urban build-up and/or consideration of urban heat island effect. Hence, it can be beneficial to urban planners to have a fast surrogate model to predict urban characteristics of a hypothetical layout, e.g. pedestrian-level wind velocity, without having to run compu-tationally expensive and time-consuming high-fidelity numerical simulations each time. This fast surrogate can then be potentially integrated into other design optimization frameworks, including generative models or other gradient-based methods. Here we present an investigation into the use of convolutional neural networks as a surrogate for urban layout characterization that is typically done via high-fidelity numerical simulation. We then further apply this model towards a first demonstration of its utility for data-driven pedestrian-level wind velocity prediction. The data set in this work comprises results from high-fidelity numerical simulations of wind velocities for a diverse set of realistic urban layouts, based on randomized samples from a real-world, highly built-up urban city. We then provide prediction results obtained from the neural network trained on this data-set, demonstrating test errors of under 0.1 m/s for previously unseen novel urban layouts. We further illustrate how this can be useful for purposes such as rapid evaluation of pedestrian wind velocity for a potential new layout. In addition, it is hoped that this data set will further inspire, facilitate and accelerate research in data-driven urban AI, even as our baseline model facilitates quantitative comparison to future, more innovative methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2191681998",
                    "name": "Shi Jer Low"
                },
                {
                    "authorId": "100823300",
                    "name": "V. Raghavan"
                },
                {
                    "authorId": "36448393",
                    "name": "H. Gopalan"
                },
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "48959757",
                    "name": "J. Yeoh"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                }
            ]
        },
        {
            "paperId": "c0122d0a551207106dfcf987a6ec4ffb952c1f60",
            "title": "Robustness of Physics-Informed Neural Networks to Noise in Sensor Data",
            "abstract": "\u2014Physics-Informed Neural Networks (PINNs) have been shown to be an effective way of incorporating physics-based domain knowledge into neural network models for many important real-world systems. They have been particularly effective as a means of inferring system information based on data, even in cases where data is scarce. Most of the current work however assumes the availability of high-quality data. In this work, we further conduct a preliminary investigation of the robustness of physics-informed neural networks to the magnitude of noise in the data. Interestingly, our experiments reveal that the inclusion of physics in the neural network is suf\ufb01cient to negate the impact of noise in data originating from hypothetical low quality sensors with high signal-to-noise ratios of up to 1. The resultant predictions for this test case are seen to still match the predictive value obtained for equivalent data obtained from high-quality sensors with potentially 10x less noise. This further implies the utility of physics-informed neural network modeling for making sense of data from sensor networks in the future, especially with the advent of Industry 4.0 and the increasing trend towards ubiquitous deployment of low-cost sensors which are typically noisier.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "32416743",
                    "name": "P. Chiu"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                },
                {
                    "authorId": "2191691312",
                    "name": "My Ha Da"
                }
            ]
        },
        {
            "paperId": "d42b06f76705a650bcaecb55f6de11b10d3f796f",
            "title": "Graph Neural Network Based Surrogate Model of Physics Simulations for Geometry Design",
            "abstract": "Computational Intelligence (CI) techniques have shown great potential as a surrogate model of expensive physics simulation, with demonstrated ability to make fast predictions, albeit at the expense of accuracy in some cases. For many scientific and engineering problems involving geometrical design, it is desirable for the surrogate models to precisely describe the change in geometry and predict the consequences. In that context, we develop graph neural networks (GNNs) as fast surrogate models for physics simulation, which allow us to directly train the models on 2/3D geometry designs that are represented by an unstructured mesh or point cloud, without the need for any explicit or hand-crafted parameterization. We utilize an encoder-processor-decoder-type architecture which can flexibly make prediction at both node level and graph level. The performance of our proposed GNN-based surrogate model is demonstrated on 2 example applications: feature designs in the domain of additive engineering and airfoil design in the domain of aerodynamics. The models show good accuracy in their predictions on a separate set of test geometries after training, with almost instant prediction speeds, as compared to O(hour) for the high-fidelity simulations required otherwise.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48455628",
                    "name": "Jian Cheng Wong"
                },
                {
                    "authorId": "121106799",
                    "name": "C. Ooi"
                },
                {
                    "authorId": "49379063",
                    "name": "Joyjit Chattoraj"
                },
                {
                    "authorId": "80559775",
                    "name": "Lucas Lestandi"
                },
                {
                    "authorId": "27197532",
                    "name": "Guoying Dong"
                },
                {
                    "authorId": "102270824",
                    "name": "Umesh Kizhakkinan"
                },
                {
                    "authorId": "102544413",
                    "name": "D. W. Rosen"
                },
                {
                    "authorId": "8129130",
                    "name": "M. Jhon"
                },
                {
                    "authorId": "47355071",
                    "name": "M. Dao"
                }
            ]
        }
    ]
}