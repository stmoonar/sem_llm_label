{
    "authorId": "22656934",
    "papers": [
        {
            "paperId": "a65df3205cc9f0380cf4f5c46ca58033d7caab65",
            "title": "Breaking the Time-Frequency Granularity Discrepancy in Time-Series Anomaly Detection",
            "abstract": "In light of the remarkable advancements made in time-series anomaly detection(TSAD), recent emphasis has been placed on exploiting the frequency domain as well as the time domain to address the difficulties in precisely detecting pattern-wise anomalies. However, in terms of anomaly scores, the window granularity of the frequency domain is inherently distinct from the data-point granularity of the time domain. Owing to this discrepancy, the anomaly information in the frequency domain has not been utilized to its full potential for TSAD. In this paper, we propose a TSAD framework, Dual-TF, that simultaneously uses both the time and frequency domains while breaking the time-frequency granularity discrepancy. To this end, our framework employs nested-sliding windows, with the outer and inner windows responsible for the time and frequency domains, respectively, and aligns the anomaly scores of the two domains. As a result of the high resolution of the aligned scores, the boundaries of pattern-wise anomalies can be identified more precisely. In six benchmark datasets, our framework outperforms state-of-the-art methods by 12.0--147%, as demonstrated by experimental results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1900303688",
                    "name": "Youngeun Nam"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2278437886",
                    "name": "Minyoung Bae"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2222379427",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "2179670697",
                    "name": "Byung Suk Lee"
                }
            ]
        },
        {
            "paperId": "10fd2f9b47da6c769dedd81125564ca21acc01c3",
            "title": "One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for Continual Learning",
            "abstract": "In real-world continual learning (CL) scenarios, tasks often exhibit intricate and unpredictable semantic shifts, posing challenges for fixed prompt management strategies which are tailored to only handle semantic shifts of uniform degree (i.e., uniformly mild or uniformly abrupt). To address this limitation, we propose an adaptive prompting approach that effectively accommodates semantic shifts of varying degree where mild and abrupt shifts are mixed. AdaPromptCL employs the assign-and-refine semantic grouping mechanism that dynamically manages prompt groups in accordance with the semantic similarity between tasks, enhancing the quality of grouping through continuous refinement. Our experiment results demonstrate that AdaPromptCL outperforms existing prompting methods by up to 21.3%, especially in the benchmark datasets with diverse semantic shifts between tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2267504094",
                    "name": "Youngjun Lee"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "3008cee71743197a6b68e8b76c6b512b61a6832d",
            "title": "Online Boundary-Free Continual Learning by Scheduled Data Prior",
            "abstract": "Typical continual learning setup assumes that the dataset is split into multiple discrete tasks. We argue that it is less realistic as the streamed data would have no notion of task boundary in real-world data. Here, we take a step forward to investigate more realistic online continual learning \u2013 learning continuously changing data distribution without explicit task boundary, which we call boundary-free setup. Due to the lack of boundary, it is not obvious when and what information in the past to be preserved for a better remedy for the stability-plasticity dilemma. To this end, we propose a scheduled transfer of previously learned knowledge. In addition, we further propose a data-driven balancing between the knowledge in the past and the present in learning objective. Moreover, since it is not straightforward to use the previously proposed forgetting measure without task boundaries, we further propose a novel forgetting and knowledge gain measure based on information theory. We empirically evaluate our method on a Gaussian data stream and its periodic extension, which is frequently observed in real-life data, as well as the conventional disjoint task-split. Our method outperforms prior arts by large margins in various setups, using four benchmark datasets in continual learning literature \u2013 CIFAR-10, CIFAR-100, TinyImageNet and ImageNet. Code is available at https://github.com/yonseivnl/sdp.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3219674",
                    "name": "Hyun-woo Koh"
                },
                {
                    "authorId": "2155704523",
                    "name": "Minhyuk Seo"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "133833735",
                    "name": "Deokki Hong"
                },
                {
                    "authorId": "2115603040",
                    "name": "Seulki Park"
                },
                {
                    "authorId": "2112436632",
                    "name": "Jung-Woo Ha"
                },
                {
                    "authorId": "2112287145",
                    "name": "Jonghyun Choi"
                }
            ]
        },
        {
            "paperId": "76d8a0fabeebeab3011bd53cefa76a88888adc75",
            "title": "Re-Thinking Federated Active Learning Based on Inter-Class Diversity",
            "abstract": "Although federated learning has made awe-inspiring advances, most studies have assumed that the client's data are fully labeled. However, in a real-world scenario, every client may have a significant amount of unlabeled instances. Among the various approaches to utilizing un-labeled data, a federated active learning framework has emerged as a promising solution. In the decentralized setting, there are two types of available query selector models, namely \u2018global\u2019 and \u2018local-only\u2019 models, but little literature discusses their performance dominance and its causes. In this work, we first demonstrate that the superiority of two selector models depends on the global and local inter-class diversity. Furthermore, we observe that the global and local-only models are the keys to resolving the imbalance of each side. Based on our findings, we propose LoGo, a FAL sampling strategy robust to varying local heterogeneity levels and global imbalance ratio, that integrates both models by two steps of active selection scheme. LoGo consistently outperforms six active learning strategies in the total number of 38 experimental settings. The code is available at: https://github.com/raymin0223/LoGo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72109105",
                    "name": "Sangmook Kim"
                },
                {
                    "authorId": "2104224550",
                    "name": "Sangmin Bae"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "70509252",
                    "name": "Se-Young Yun"
                }
            ]
        },
        {
            "paperId": "8c822db0f9bb4aad268d2fed2a26c46915b4603e",
            "title": "Generating Instance-level Prompts for Rehearsal-free Continual Learning",
            "abstract": "We introduce Domain-Adaptive Prompt (DAP), a novel method for continual learning using Vision Transformers (ViT). Prompt-based continual learning has recently gained attention due to its rehearsal-free nature. Currently, the prompt pool, which is suggested by prompt-based continual learning, is key to effectively exploiting the frozen pretrained ViT backbone in a sequence of tasks. However, we observe that the use of a prompt pool creates a domain scalability problem between pre-training and continual learning. This problem arises due to the inherent encoding of group-level instructions within the prompt pool. To address this problem, we propose DAP, a pool-free approach that generates a suitable prompt in an instance-level manner at inference time. We optimize an adaptive prompt generator that creates instance-specific fine-grained instructions required for each input, enabling enhanced model plasticity and reduced forgetting. Our experiments on seven datasets with varying degrees of domain similarity to ImageNet demonstrate the superiority of DAP over state-of-the-art prompt-based methods. Code is publicly available at https://github.com/naver-ai/dap-cl.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268370487",
                    "name": "Dahuin Jung"
                },
                {
                    "authorId": "2268676739",
                    "name": "Dongyoon Han"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                }
            ]
        },
        {
            "paperId": "96760559b7a9b2bc55b97eb518a5daa409f43bda",
            "title": "Toward Robustness in Multi-label Classification: A Data Augmentation Strategy against Imbalance and Noise",
            "abstract": "Multi-label classification poses challenges due to imbalanced and noisy labels in training data. In this paper, we propose a unified data augmentation method, named BalanceMix, to address these challenges. Our approach includes two samplers for imbalanced labels, generating minority-augmented instances with high diversity. It also refines multi-labels at the label-wise granularity, categorizing noisy labels as clean, re-labeled, or ambiguous for robust optimization. Extensive experiments on three benchmark datasets demonstrate that BalanceMix outperforms existing state-of-the-art methods. We release the code at https://github.com/DISL-Lab/BalanceMix.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "9736cc2d5b52bb2c9fd305d07f23b4a6c70cefc9",
            "title": "Context Consistency Regularization for Label Sparsity in Time Series",
            "abstract": "Labels are typically sparse in real-world time series due to the high annotation cost. Recently, consistency regularization techniques have been used to generate artificial labels from unlabeled augmented instances. To fully exploit the sequential characteristic of time series in consistency regularization, we propose a novel method of data augmentation called context-attached augmentation , which adds preceding and succeeding instances to a target instance to form its augmented instance. Unlike the existing augmentation techniques that modify a target instance by directly perturbing its attributes, the context-attached augmentation generates instances augmented with varying contexts while maintaining the target instance. Based on our augmentation method, we propose a context consistency regularization framework, which first adds different contexts to a target instance sampled from a given time series and then shares unitary reliability-based cross-window labels across the augmented instances to maintain consistency. We demonstrate that the proposed framework outperforms the existing state-of-the-art consistency regularization frameworks through comprehensive experiments on real-world time-series datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2196449069",
                    "name": "Byunghyun Kim"
                },
                {
                    "authorId": "2143422249",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "2152439884",
                    "name": "Byung Suk Lee"
                }
            ]
        },
        {
            "paperId": "bec491b0956ea7bb5a40595b66e5f72c14c07c0b",
            "title": "Q-HyViT: Post-Training Quantization of Hybrid Vision Transformers With Bridge Block Reconstruction for IoT Systems",
            "abstract": "Recently, vision transformers (ViTs) have superseded convolutional neural networks in numerous applications, including classification, detection, and segmentation. However, the high computational requirements of ViTs hinder their widespread implementation. To address this issue, researchers have proposed efficient hybrid transformer architectures that combine convolutional and transformer layers with optimized attention computation of linear complexity. Additionally, post-training quantization has been proposed as a means of mitigating computational demands. For mobile devices, achieving optimal acceleration for ViTs necessitates the strategic integration of quantization techniques and efficient hybrid transformer structures. However, no prior investigation has applied quantization to efficient hybrid transformers. In this paper, we discover that applying existing post-training quantization (PTQ) methods for ViTs to efficient hybrid transformers leads to a drastic accuracy drop, attributed to the four following challenges: (i) highly dynamic ranges, (ii) zero-point overflow, (iii) diverse normalization, and (iv) limited model parameters ($<$5M). To overcome these challenges, we propose a new post-training quantization method, which is the first to quantize efficient hybrid ViTs (MobileViTv1, MobileViTv2, Mobile-Former, EfficientFormerV1, EfficientFormerV2). We achieve a significant improvement of 17.73% for 8-bit and 29.75% for 6-bit on average, respectively, compared with existing PTQ methods (EasyQuant, FQ-ViT, PTQ4ViT, and RepQ-ViT)}. We plan to release our code at https://gitlab.com/ones-ai/q-hyvit.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154961369",
                    "name": "Jemin Lee"
                },
                {
                    "authorId": "3156595",
                    "name": "Yongin Kwon"
                },
                {
                    "authorId": "1936868",
                    "name": "Sihyeong Park"
                },
                {
                    "authorId": "2212155475",
                    "name": "Misun Yu"
                },
                {
                    "authorId": "19243159",
                    "name": "Jeman Park"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                }
            ]
        },
        {
            "paperId": "c1acda8a20d4874d12ced526d07acfb158b9e68c",
            "title": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object Detection",
            "abstract": "Prompt-OVD is an efficient and effective framework for open-vocabulary object detection that utilizes class embeddings from CLIP as prompts, guiding the Transformer decoder to detect objects in both base and novel classes. Additionally, our novel RoI-based masked attention and RoI pruning techniques help leverage the zero-shot classification ability of the Vision Transformer-based CLIP, resulting in improved detection performance at minimal computational cost. Our experiments on the OV-COCO and OVLVIS datasets demonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference speed than the first end-to-end open-vocabulary detection method (OV-DETR), while also achieving higher APs than four two-stage-based methods operating within similar inference time ranges. Code will be made available soon.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                }
            ]
        },
        {
            "paperId": "ca622fde1f31e86a3328504c17605298c6129414",
            "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy",
            "abstract": "Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy and generalization performance. Extensive experiments on four real and one synthetic noisy datasets show that \\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as well as those with a standard model by up to 21.6%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2265081094",
                    "name": "Seola Choi"
                },
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        }
    ]
}