{
    "authorId": "1404333852",
    "papers": [
        {
            "paperId": "06ee844b1b3ebdabe213cfcb5ff779e005263b24",
            "title": "XSD2SHACL: Capturing RDF Constraints from XML Schema",
            "abstract": "SHACL shapes describe the constraints of RDF subgraphs which are constructed from heterogeneous data, such as RDBs, JSONs, XMLs, etc. These heterogeneous data often already have constraints defined in their schemas, e.g., JSON Schema for JSON or XSD for XML, but this information is ignored when the RDF graph is constructed, as there are currently not many works that translate such schemas into SHACL. In this paper, we focus on the incorporation of XSD constraints for XML data sources in SHACL shapes. We define a translation from XSD to SHACL, and provide a corresponding system. We compare our solution with XMLSchema2ShEx which translates XSD constraints to ShEx and validate our solution against two use cases. Our solution provides the desired SHACL shapes in a reasonable time. This allows us to automatically derive SHACL shapes for some original raw data without any manual effort.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2267506504",
                    "name": "Xuemin Duan"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "2267499807",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "9dfdc45d0b9f1b59d8e8737559e8aaf5f5de7f04",
            "title": "Declarative RDF Construction from In-Memory Data Structures with RML",
            "abstract": "Knowledge graphs are often constructed from heterogeneous data sources using declarative mapping languages. Mapping languages define rules that apply ontology terms to raw data to describe how a knowledge graph should be constructed from these raw data. While most mapping languages and systems support knowledge graph construction from different data formats, e.g., CSV, XML or JSON, and different types of data sources, e.g., files, Web APIs or databases, there is still no support for mapping in-memory data structures to knowledge graphs, i.e. data which is temporarily stored in RAM. Currently, this data must first be stored in HDD, locally or in the cloud, for RDF construction systems to access them and construct a knowledge graph. However, writing these data to HDD and reading from HDD is a computationally expensive and redundant task. In this paper, we propose a method to construct RDF graphs from data produced by a software process and stored in RAM. We introduce an extension of RML\u2019s Logical Source to describe data structures produced by software, and exemplify our proposal with Python data structures. We extend a well-known RML system, Morph-KGC, to show the feasibility of our method and validate this extension with two use cases: OpenML, which translates machine learning executions into RDF, and SOMEF, which extracts software metadata from its documentation, converting them to triples. This proposal simplifies the construction of RDF graphs from in-memory data structures stored temporarily in RAM and enables the integration of data stored both in RAM and HDD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220348484",
                    "name": "Ioannis Dasoulas"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "e3630dd923613c4e7fbf4a7264493674dc0c4bf8",
            "title": "Re-Construction Impact on Metadata Representation Models",
            "abstract": "Reification in knowledge graphs has been present since the inception of RDF to allow capturing additional information in triples, usually metadata. The need of adopting or changing a metadata representation in a pre-existing graph to enhance the knowledge capture and access can lead to inducing complex structural changes in the graph, according the target representation\u2019s schema. In these situations, it is necessary to decide whether to construct the knowledge graph again from its original sources, or to re-construct it using the current version of the graph. In this paper we conduct an empirical study to analyze which re-construction approach is more suitable for switching the representation approach from the created graph ensuring that the additional represented knowledge is preserved. We study four well-known metadata representations, using mapping languages to construct the graph, and SPARQL CONSTRUCT queries to re-construct it. With this work we aim to provide insights about the impact of re-construction on metadata representations interoperability and the implications of different approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268766312",
                    "name": "Ana Iglesias-Molina"
                },
                {
                    "authorId": "2056266963",
                    "name": "Jhon Toledo"
                },
                {
                    "authorId": "2265658023",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                }
            ]
        },
        {
            "paperId": "1df5a9fcdcef9461abfdd5da2521331627edb6eb",
            "title": "Declarative Description of Knowledge Graphs Construction Automation: Status & Challenges",
            "abstract": "Nowadays, Knowledge Graphs (KG) are among the most powerful mechanisms to represent knowledge and integrate data from multiple domains. However, most of the available data sources are still described in heterogeneous data structures, schemes, and formats. The conversion of these sources into the desirable KG requires manual and time-consuming tasks, such as programming translation scripts, defining declarative mapping rules, etc. In this vision paper, we analyze the trends regarding the automation of KG construction but also the use of mapping languages for the same process, and align the two by analyzing their tasks and a few exemplary tools. Our aim is not to have a complete study but to investigate if there is potential in this direction and, if so, to discuss what challenges we need to address to guarantee the maintainability, explainability, and reproducibility of the KG construction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                }
            ]
        },
        {
            "paperId": "2739f6ed43bc5ed80ea8e5542882a9d54aa36c52",
            "title": "Systematic Construction of Knowledge Graphs for Research-Performing Organizations",
            "abstract": "Research-Performing Organizations (e.g., research centers, universities) usually accumulate a wealth of data related to their researchers, the generated scientific results and research outputs, and publicly and privately-funded projects that support their activities, etc. Even though the types of data handled may look similar across organizations, it is common to see that each institution has developed its own data model to provide support for many of their administrative activities (project reporting, curriculum management, personnel management, etc.). This creates obstacles to the integration and linking of knowledge across organizations, as well as difficulties when researchers move from one institution to another. In this paper, we take advantage of the ontology network created by the Spanish HERCULES initiative to facilitate the construction of knowledge graphs from existing information systems, such as the one managed by the company Universitas XXI, which provides support to more than 100 Spanish-speaking research-performing organizations worldwide. Our effort is not just focused on following the modeling choices from that ontology, but also on demonstrating how the use of standard declarative mapping rules (i.e., R2RML) guarantees a systematic and sustainable workflow for constructing and maintaining a KG. We also present several real-world use cases in which the proposed workflow is adopted together with a set of lessons learned and general recommendations that may also apply to other domains. The next steps include researching in the automation of the creation of the mapping rules, the enrichment of the KG with external sources, and its exploitation though distributed environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "2193319632",
                    "name": "Francisco Yedro"
                },
                {
                    "authorId": "2192933420",
                    "name": "Roberto Moreno"
                },
                {
                    "authorId": "47469584",
                    "name": "J. Ol\u00edas"
                },
                {
                    "authorId": "13082627",
                    "name": "A. Azuela"
                }
            ]
        },
        {
            "paperId": "51676b836654d4fd202cd0cc7123d31d27140d86",
            "title": "Editorial of transport data on the web",
            "abstract": "Whether you are planning your next trip abroad or want a package delivered to your doorstep, chances are high that you will need a chain of services provided by multiple companies. Transport is inherently a geographically and administratively decentralized domain composed of a diverse set of actors, \u2013 from public transport authorities to vehicle sharing companies, infrastructure managers in different sectors (road, rail, etc.), transport operators, retailers, and distributors. As a result, it suffers vast data heterogeneity, which, in turn, brings severe challenges to data interoperability. However, such challenges have also been posed in other domains such as the Internet of Things [18], agriculture [11], building data management [17], biology [7] or open data [2], which have found their solutions using semantic web technologies. However, despite several research contributions [6,14,19,23,25], public-funded projects1,2 or academic-industry events,3,4 we have not yet seen a wide adoption of semantic technologies in the transport domain. We may only guess the inhibitors for adopting Linked Data in this domain: i) the SPARQL query language is not built for optimal path planning, and ii) RDF is perceived as highly conceptual by industry experts. We argue that SPARQL does not fit well with the concerns that typically matter to route planners (e.g., calculating the optimal Pareto path [4]). While calculating a path with SPARQL is feasible through property paths, controlling the path planning algorithm, which can hardly be done in SPARQL, is the core concern of route planners. On the other hand, the transport domain is dominated by different standards (e.g., NeTEx,5 or DATEX II6) and vocabularies, which are based on legacy data exchange technologies (e.g., XML or RDB). However, to construct a distributed and scalable architecture that addresses the current needs of this domain, the Web and its associated technologies (i.e., the Semantic Web) are the key resource.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "2370758",
                    "name": "Pieter Colpaert"
                },
                {
                    "authorId": "51486610",
                    "name": "Mersedeh Sadeghi"
                },
                {
                    "authorId": "3169902",
                    "name": "M. Comerio"
                }
            ]
        },
        {
            "paperId": "6d702da5dea94d0b0a9302ae579ce995357dd960",
            "title": "An ontological approach for representing declarative mapping languages",
            "abstract": "Knowledge Graphs are currently created using an assortment of techniques and tools: ad hoc code in a programming language, database export scripts, OpenRefine transformations, mapping languages, etc. Focusing on the latter, the wide variety of use cases, data peculiarities, and potential uses has had a substantial impact in how mappings have been created, extended, and applied. As a result, a large number of languages and their associated tools have been created. In this paper, we present the Conceptual Mapping ontology, that is designed to represent the features and characteristics of existing declarative mapping languages to construct Knowledge Graphs. This ontology is built upon the requirements extracted from experts experience, a thorough analysis of the features and capabilities of current mapping languages presented as a comparative framework; and the languages\u2019 limitations discussed by the community and denoted as Mapping Challenges. The ontology is evaluated to ensure that it meets these requirements and has no inconsistencies, pitfalls or modelling errors, and is publicly available online along with its documentation and related resources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1485497099",
                    "name": "Ana Iglesias-Molina"
                },
                {
                    "authorId": "3413290",
                    "name": "Andrea Cimmino"
                },
                {
                    "authorId": "1792630",
                    "name": "E. Ruckhaus"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "1398854351",
                    "name": "R. Garc\u00eda-Castro"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "f37bf57147465dbf72a3d2e9155ddd279b0b4575",
            "title": "Morph-KGC: Scalable knowledge graph materialization with mapping partitions",
            "abstract": "Knowledge graphs are often constructed from heterogeneous data sources, using declarative rules that map them to a target ontology and materializing them into RDF. When these data sources are large, the materialization of the entire knowledge graph may be computationally expensive and not suitable for those cases where a rapid materialization is required. In this work, we propose an approach to overcome this limitation, based on the novel concept of mapping partitions. Mapping partitions are defined as groups of mapping rules that generate disjoint subsets of the knowledge graph. Each of these groups can be processed separately, reducing the total amount of memory and execution time required by the materialization process. We have included this optimization in our materialization engine Morph-KGC, and we have evaluated it over three different benchmarks. Our experimental results show that, compared with state-of-the-art techniques, the use of mapping partitions in Morph-KGC presents the following advantages: (i) it decreases significantly the time required for materialization, (ii) it reduces the maximum peak of memory used, and (iii) it scales to data sizes that other engines are not capable of processing currently.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107052011",
                    "name": "Juli\u00e1n Arenas-Guerrero"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "2056266963",
                    "name": "Jhon Toledo"
                },
                {
                    "authorId": "145002690",
                    "name": "Mar\u00eda S. P\u00e9rez"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "f6547db9118871c0fa9e503375afebaa27983d86",
            "title": "Handling qualitative preferences in SPARQL over virtual ontology-based data access",
            "abstract": "With the increase of data volume in heterogeneous datasets that are being published following Open Data initiatives, new operators are necessary to help users to find the subset of data that best satisfies their preference criteria. Quantitative approaches such as top-k queries may not be the most appropriate approaches as they require the user to assign weights that may not be known beforehand to a scoring function. Unlike the quantitative approach, under the qualitative approach, which includes the well-known skyline, preference criteria are more intuitive in certain cases and can be expressed more naturally. In this paper, we address the problem of evaluating SPARQL qualitative preference queries over an Ontology-Based Data Access (OBDA) approach, which provides uniform access over multiple and heterogeneous data sources. Our main contribution is Morph-Skyline++, a framework for processing SPARQL qualitative preferences by directly querying relational databases. Our framework implements a technique that translates SPARQL qualitative preference queries directly into queries that can be evaluated by a relational database management system. We evaluate our approach over different scenarios, reporting the effects of data distribution, data size, and query complexity on the performance of our proposed technique in comparison with state-of-the-art techniques. Obtained results suggest that the execution time can be reduced by up to two orders of magnitude in comparison to current techniques scaling up to larger datasets while identifying precisely the result set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145182016",
                    "name": "Marlene Goncalves"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                }
            ]
        },
        {
            "paperId": "7747127c5cfbdd746c6bd1414b955dc989ae7d22",
            "title": "Knowledge Graph Construction with R2RML and RML: An ETL System-based Overview",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107052011",
                    "name": "Juli\u00e1n Arenas-Guerrero"
                },
                {
                    "authorId": "1485497099",
                    "name": "Ana Iglesias-Molina"
                },
                {
                    "authorId": "2056266963",
                    "name": "Jhon Toledo"
                },
                {
                    "authorId": "2008195813",
                    "name": "Luis Pozo-Gilo"
                },
                {
                    "authorId": "5776411",
                    "name": "D. Dona'"
                },
                {
                    "authorId": "70053552",
                    "name": "\u00d3scar Corcho"
                },
                {
                    "authorId": "1404333852",
                    "name": "David Chaves-Fraga"
                }
            ]
        }
    ]
}