{
    "authorId": "1688428",
    "papers": [
        {
            "paperId": "2f85ed4e4ed4d599e5a78b90e970fa5d2d22e3a5",
            "title": "Power Optimization of Cooperative Relay Network With Uncertain Channel Gain in Smart Grid",
            "abstract": "The packet loss during transmission of load control commands can lead to regulation errors in the smart grid and further increase the cost of utility companies due to the purchase of additional automatic generation control services. This article considers a cooperative communication network consisting of multiple data aggregation units (DAUs) and multiple relays in smart grid, and each relay can forward data for all DAUs. We optimize the transmission power allocation of the relays to reduce the demand-side regulation errors and the cost of utility companies. However, additional cost is incurred due to the rental of relay in commercial networks. In order to minimize the total costs of utility companies, a two-layer game model is proposed and an iterative algorithm is developed. Simulation results show that the cost of utility companies can be reduced under the proposed scheme.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238404423",
                    "name": "Kai Ma"
                },
                {
                    "authorId": "2129353382",
                    "name": "Pei Liu"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                },
                {
                    "authorId": "2119660190",
                    "name": "Bo-Jun Yang"
                },
                {
                    "authorId": "2238370382",
                    "name": "Rong Wu"
                },
                {
                    "authorId": "2238545913",
                    "name": "Kuan Zhang"
                }
            ]
        },
        {
            "paperId": "04fb3ce57e2205b4b2918df462961a0a644b4fdc",
            "title": "An Automatic Key-points Detection and Style Transfer based Method of Articulatory Animation Generation",
            "abstract": "The method of generating articulatory animation based on automatic key point detection and style transfer. This paper proposes a system of key-points detection and registration based on image feature space, and uses the GAN for motion transfer, which is used to automatically generate oral and tongue articulatory animation of English. First, by obtaining the standard articulation image of the International Phonetic Alphabet from the public dataset, we train a deep-learning motion model according to the characteristics of the tongue, upper jaw, lower jaw, small tongue, soft palate and other motion features, according to the characteristics of articulatory organ, and automatically detect the key-points in the image feature space. According to the existing MRI articulatory videos, using different styles of articulatory images, a generative model is used to generate end-to-end animation of different styles automatically. For different combinations of consonants and vowels, generate animation of different syllables, and according to different categories of articulatory, such as stress and light tone, adjust the duration of articulatory to form different animation of stress and light tone of the same syllable. And form the animation of words through syllables, and then form the animation of each sentence. Experiments show that this method can simulate realistic articulatory animation according to input phonetic symbols, and has a very positive effect on English articulatory correction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46641573",
                    "name": "W. Liu"
                },
                {
                    "authorId": "2056682000",
                    "name": "Xufeng Ling"
                },
                {
                    "authorId": "2149061152",
                    "name": "Jingxin Liang"
                },
                {
                    "authorId": "2159215224",
                    "name": "Xiao-Bing Wang"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "0b601ed987b6d16666f3b432d22b0d6cea75b08c",
            "title": "pLMFPPred: a novel approach for accurate prediction of functional peptides integrating embedding from pre-trained protein language model and imbalanced learning",
            "abstract": "Functional peptides have the potential to treat a variety of diseases. Their good therapeutic efficacy and low toxicity make them ideal therapeutic agents. Artificial intelligence-based computational strategies can help quickly identify new functional peptides from collections of protein sequences and discover their different functions.Using protein language model-based embeddings (ESM-2), we developed a tool called pLMFPPred (Protein Language Model-based Functional Peptide Predictor) for predicting functional peptides and identifying toxic peptides. We also introduced SMOTE-TOMEK data synthesis sampling and Shapley value-based feature selection techniques to relieve data imbalance issues and reduce computational costs. On a validated independent test set, pLMFPPred achieved accuracy, Area under the curve - Receiver Operating Characteristics, and F1-Score values of 0.974, 0.99, and 0.974, respectively. Comparative experiments show that pLMFPPred outperforms current methods for predicting functional peptides.The experimental results suggest that the proposed method (pLMFPPred) can provide better performance in terms of Accuracy, Area under the curve - Receiver Operating Characteristics, and F1-Score than existing methods. pLMFPPred has achieved good performance in predicting functional peptides and represents a new computational method for predicting functional peptides.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2246884932",
                    "name": "Zebin Ma"
                },
                {
                    "authorId": "145767113",
                    "name": "Yongli Zou"
                },
                {
                    "authorId": "2247600745",
                    "name": "Xiaobin Huang"
                },
                {
                    "authorId": "2048734067",
                    "name": "Wenjin Yan"
                },
                {
                    "authorId": "2247489829",
                    "name": "Hao Xu"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                },
                {
                    "authorId": "2248285463",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2246946416",
                    "name": "Jinqi Huang"
                }
            ]
        },
        {
            "paperId": "2bb5939cb35454a21514452880a5c49dca41aa0d",
            "title": "Inherent Consistent Learning for Accurate Semi-supervised Medical Image Segmentation",
            "abstract": "Semi-supervised medical image segmentation has attracted much attention in recent years because of the high cost of medical image annotations. In this paper, we propose a novel Inherent Consistent Learning (ICL) method, aims to learn robust semantic category representations through the semantic consistency guidance of labeled and unlabeled data to help segmentation. In practice, we introduce two external modules, namely Supervised Semantic Proxy Adaptor (SSPA) and Unsupervised Semantic Consistent Learner (USCL) that is based on the attention mechanism to align the semantic category representations of labeled and unlabeled data, as well as update the global semantic representations over the entire training set. The proposed ICL is a plug-and-play scheme for various network architectures, and the two modules are not involved in the testing stage. Experimental results on three public benchmarks show that the proposed method can outperform the state-of-the-art, especially when the number of annotated data is extremely limited. Code is available at: https://github.com/zhuye98/ICL.git.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2171358738",
                    "name": "Ye Zhu"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                },
                {
                    "authorId": "2108638581",
                    "name": "Sichen Liu"
                },
                {
                    "authorId": "2109960585",
                    "name": "Ruimao Zhang"
                }
            ]
        },
        {
            "paperId": "2dd451439571e0097be9acd871579a1661080725",
            "title": "Variational Feature Disentanglement for Few-Shot Domain Adaptation",
            "abstract": "In this paper, we focus on the few-shot domain adaptation problem. With limited training data in target domain, a new approach is emerging to acquire the transferable knowledge from the source domain. Previous methods aligned the embedding space between domains by reducing the pair-wise distance. However, these methods are reporting the misalignment and poor generalization. To solve this problem, we propose a variational feature disentanglement framework. The embedding features are explicitly disentangled into domaininvariant and domain-specific components. The distributions of domain-invariant variance are estimated and aligned by the variational inference. For further disentanglement, the domain-invariant and domain-specific components are separated by the orthogonal constraints of subspaces. The experiments on Digits dataset and VisDA-C dataset demonstrate that the proposed method can outperform the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240268405",
                    "name": "Weiduo Wang"
                },
                {
                    "authorId": "143908242",
                    "name": "Yun Gu"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "40256569800fa9eb035e1d8b595f270461a58d79",
            "title": "MGTAB: A Multi-Relational Graph-Based Twitter Account Detection Benchmark",
            "abstract": "The development of social media user stance detection and bot detection methods rely heavily on large-scale and high-quality benchmarks. However, in addition to low annotation quality, existing benchmarks generally have incomplete user relationships, suppressing graph-based account detection research. To address these issues, we propose a Multi-Relational Graph-Based Twitter Account Detection Benchmark (MGTAB), the first standardized graph-based benchmark for account detection. To our knowledge, MGTAB was built based on the largest original data in the field, with over 1.55 million users and 130 million tweets. MGTAB contains 10,199 expert-annotated users and 7 types of relationships, ensuring high-quality annotation and diversified relations. In MGTAB, we extracted the 20 user property features with the greatest information gain and user tweet features as the user features. In addition, we performed a thorough evaluation of MGTAB and other public datasets. Our experiments found that graph-based approaches are generally more effective than feature-based approaches and perform better when introducing multiple relations. By analyzing experiment results, we identify effective approaches for account detection and provide potential future research directions in this field. Our benchmark and standardized evaluation procedures are freely available at: https://github.com/GraphDetec/MGTAB.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106709150",
                    "name": "S. Shi"
                },
                {
                    "authorId": "48017396",
                    "name": "Kai Qiao"
                },
                {
                    "authorId": "2118446044",
                    "name": "Jian Chen"
                },
                {
                    "authorId": "2145096712",
                    "name": "Shuai Yang"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                },
                {
                    "authorId": "2199193304",
                    "name": "Baojie Song"
                },
                {
                    "authorId": "82527663",
                    "name": "Linyuan Wang"
                },
                {
                    "authorId": "35841257",
                    "name": "Binghai Yan"
                }
            ]
        },
        {
            "paperId": "40682af793358c6f412c734d840232ff28dda916",
            "title": "A Phoneme Localization Based Liveness Detection for Text-Independent Speaker Verification",
            "abstract": "Voice authentication is drawing increasing attention and becomes an attractive alternative to passwords for mobile authentication. Recent advances in mobile technology further accelerate the adoption of voice biometrics in an array of diverse mobile applications. However, recent studies show that voice authentication is vulnerable to replay attacks, where an adversary can spoof a voice authentication system using a pre-recorded voice sample collected from the victim. In this article, we propose VoiceLive, a liveness detection system for both text-dependent and text-independent voice authentication on smartphones. VoiceLive detects a live user by leveraging the user's unique vocal system and the stereo recording of smartphones. In particular, utilizing the built-in gyroscope, loudspeaker and microphone, VoiceLive first measures the smartphone's distance and angle from the user, then it captures the position specific time-difference-of-arrival (TDoA) changes in a sequence of phoneme sounds to the two microphones of the phone, and uses such unique TDoA dynamic which doesn't exist under replay attacks for liveness detection. VoiceLive is practical as it doesn't require additional hardware but two-channel stereo recording that is supported by virtually all smartphones. Our experimental evaluation with 12 participants and different types of phones shows that VoiceLive achieves over 99% detection accuracy at around 1% Equal Error Rate (EER) on the text-dependent system and around 99% accuracy and 2% EER on the text-independent one. Results also show that VoiceLive is robust to different phone positions, i.e., the user are free to hold the smartphone with distinct distances and angles.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2033112144",
                    "name": "Linghan Zhang"
                },
                {
                    "authorId": "145092664",
                    "name": "Sheng Tan"
                },
                {
                    "authorId": "2156597262",
                    "name": "Yingying Chen"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "4fb4aeae6c886aeb85b80f8ca65408450127cbce",
            "title": "detrex: Benchmarking Detection Transformers",
            "abstract": "The DEtection TRansformer (DETR) algorithm has received considerable attention in the research community and is gradually emerging as a mainstream approach for object detection and other perception tasks. However, the current field lacks a unified and comprehensive benchmark specifically tailored for DETR-based models. To address this issue, we develop a unified, highly modular, and lightweight codebase called detrex, which supports a majority of the mainstream DETR-based instance recognition algorithms, covering various fundamental tasks, including object detection, segmentation, and pose estimation. We conduct extensive experiments under detrex and perform a comprehensive benchmark for DETR-based models. Moreover, we enhance the performance of detection transformers through the refinement of training hyper-parameters, providing strong baselines for supported algorithms.We hope that detrex could offer research communities a standardized and unified platform to evaluate and compare different DETR-based models while fostering a deeper understanding and driving advancements in DETR-based instance recognition. Our code is available at https://github.com/IDEA-Research/detrex. The project is currently being actively developed. We encourage the community to use detrex codebase for further development and contributions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143150727",
                    "name": "Tianhe Ren"
                },
                {
                    "authorId": "150301258",
                    "name": "Siyi Liu"
                },
                {
                    "authorId": "2152978390",
                    "name": "Feng Li"
                },
                {
                    "authorId": "2315254849",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "51286000",
                    "name": "Ailing Zeng"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                },
                {
                    "authorId": "71425456",
                    "name": "Xingyu Liao"
                },
                {
                    "authorId": "2117587273",
                    "name": "Ding Jia"
                },
                {
                    "authorId": null,
                    "name": "Hongyang Li"
                },
                {
                    "authorId": "2153244338",
                    "name": "He Cao"
                },
                {
                    "authorId": "2109495782",
                    "name": "Jianan Wang"
                },
                {
                    "authorId": "2075413603",
                    "name": "Zhaoyang Zeng"
                },
                {
                    "authorId": "2689287",
                    "name": "Xianbiao Qi"
                },
                {
                    "authorId": "49521390",
                    "name": "Yuhui Yuan"
                },
                {
                    "authorId": "120157163",
                    "name": "Jianwei Yang"
                },
                {
                    "authorId": "2152832911",
                    "name": "Lei Zhang"
                }
            ]
        },
        {
            "paperId": "62a4b1ea4d091f1c5700dc06c9bf2503ea9ecfac",
            "title": "Streamlining Social Media Information Retrieval for COVID-19 Research with Deep Learning (preprint)",
            "abstract": "Objective: Social media-based public health research is crucial for epidemic surveillance, but most studies identify relevant corpora with keyword-matching. This study develops a system to streamline the process of curating colloquial medical dictionaries. We demonstrate the pipeline by curating a UMLS-colloquial symptom dictionary from COVID-19-related tweets as proof of concept. Methods: COVID-19-related tweets from February 1, 2020, to April 30, 2022 were used. The pipeline includes three modules: a named entity recognition module to detect symptoms in tweets; an entity normalization module to aggregate detected entities; and a mapping module that iteratively maps entities to Unified Medical Language System concepts. A random 500 entity sample were drawn from the final dictionary for accuracy validation. Additionally, we conducted a symptom frequency distribution analysis to compare our dictionary to a pre-defined lexicon from previous research. Results: We identified 498,480 unique symptom entity expressions from the tweets. Pre-processing reduces the number to 18,226. The final dictionary contains 38,175 unique expressions of symptoms that can be mapped to 966 UMLS concepts (accuracy = 95%). Symptom distribution analysis found that our dictionary detects more symptoms and is effective at identifying psychiatric disorders like anxiety and depression, often missed by pre-defined lexicons. Conclusions: This study advances public health research by implementing a novel, systematic pipeline for curating symptom lexicons from social media data. The final lexicon's high accuracy, validated by medical professionals, underscores the potential of this methodology to reliably interpret and categorize vast amounts of unstructured social media data into actionable medical insights across diverse linguistic and regional landscapes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2147311343",
                    "name": "Y. Hua"
                },
                {
                    "authorId": "2174092254",
                    "name": "Shixu Lin"
                },
                {
                    "authorId": "2186950276",
                    "name": "Minghui Li"
                },
                {
                    "authorId": "2145064768",
                    "name": "Yujie Zhang"
                },
                {
                    "authorId": "1800462890",
                    "name": "Peilin Zhou"
                },
                {
                    "authorId": "2055654560",
                    "name": "Y. Lo"
                },
                {
                    "authorId": "2116636556",
                    "name": "Li Zhou"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "6c7165e534111639f3ad35fa3e0dab3a658f0cae",
            "title": "Energy Trading and Power Allocation Strategies for Relay-Assisted Smart Grid Communications: A Three-Stage Game Approach",
            "abstract": "In smart grid, serious packet loss often occurs in the process of information interaction between the Utilities and customers, which results in supply-demand deviation and further increases the cost of the Utilities. In order to improve the information transmission performance of communication networks, the Utilities purchase relay service from telecom operator to help data aggregator units (DAU) transfer information to gateway (GW), so as to improve communication quality and reduce the cost of the Utilities. Second, in order to solve the problem of telecom operators\u2019 energy reduction and reduce the cost of purchasing energy, we utilize energy supply point (ESP) to collect the surplus energy of retail customers for energy supply, and telecom operator pays a certain amount of remuneration to ESP in exchange for ESP to continuously supply energy to telecom operator. Then, we establish a three-stage game method and system model between the Utilities, telecom operator and ESP, and propose the relay power allocation and energy transaction pricing strategy. Due to the real-time change of energy demand, we consider two situations of energy oversupply and conservative supply, and use the backward induction method and iterative algorithm to obtain the equilibrium solution of the Stackelberg game, including the unit energy price of ESP, total power of telecom operator, the proportion of transmission power allocated to the relay service, and payment scheme of the Utilities. Simulation results show that the proposed algorithm can quickly and accurately converge to the optimal solution of the problem, and the method can improve the stability of demand-side regulation, reduce the cost of the Utilities and increase the profit of telecom operator.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                },
                {
                    "authorId": "2108066522",
                    "name": "Yajing Zhang"
                },
                {
                    "authorId": "145412873",
                    "name": "Yazhou Yuan"
                },
                {
                    "authorId": "143915557",
                    "name": "K. Ma"
                },
                {
                    "authorId": "2186960362",
                    "name": "Jianbo Li"
                }
            ]
        }
    ]
}