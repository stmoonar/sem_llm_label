{
    "authorId": "2300095635",
    "papers": [
        {
            "paperId": "37d6bb9dee00730eaf24c38be40cf2e2b05c4f4d",
            "title": "Enriching Ontologies with Disjointness Axioms using Large Language Models",
            "abstract": "Ontologies often lack explicit disjointness declarations between classes, despite their usefulness for sophisticated reasoning and consistency checking in Knowledge Graphs. In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms. Our approach aims at leveraging the implicit knowledge embedded in LLMs, using prompt engineering to elicit this knowledge for classifying ontological disjointness. We validate our methodology on the DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs, when guided by effective prompt strategies, can reliably identify disjoint class relationships, thus streamlining the process of ontology completion without extensive manual input. For comprehensive disjointness enrichment, we propose a process that takes logical relationships between disjointness and subclass statements into account in order to maintain satisfiability and reduce the number of calls to the LLM. This work provides a foundation for future applications of LLMs in automated ontology enhancement and offers insights into optimizing LLM performance through strategic prompt design. Our code is publicly available on GitHub at https://github.com/n28div/llm-disjointness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2324581938",
                    "name": "Elias Crum"
                },
                {
                    "authorId": "2300095635",
                    "name": "Antonio De Santis"
                },
                {
                    "authorId": "2324578412",
                    "name": "Manon Ovide"
                },
                {
                    "authorId": null,
                    "name": "Jiaxin Pan"
                },
                {
                    "authorId": "2051890807",
                    "name": "Alessia Pisu"
                },
                {
                    "authorId": "2284772780",
                    "name": "Nicolas Lazzari"
                },
                {
                    "authorId": "2284774561",
                    "name": "Sebastian Rudolph"
                }
            ]
        },
        {
            "paperId": "42567e6ca98a94ad9ae44959ee592376d93a69eb",
            "title": "Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification",
            "abstract": "Transparency and explainability in image classification are essential for establishing trust in machine learning models and detecting biases and errors. State-of-the-art explainability methods generate saliency maps to show where a specific class is identified, without providing a detailed explanation of the model's decision process. Striving to address such a need, we introduce a post-hoc method that explains the entire feature extraction process of a Convolutional Neural Network. These explanations include a layer-wise representation of the features the model extracts from the input. Such features are represented as saliency maps generated by clustering and merging similar feature maps, to which we associate a weight derived by generalizing Grad-CAM for the proposed methodology. To further enhance these explanations, we include a set of textual labels collected through a gamified crowdsourcing activity and processed using NLP techniques and Sentence-BERT. Finally, we show an approach to generate global explanations by aggregating labels across multiple images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2300095729",
                    "name": "Matteo Bianchi"
                },
                {
                    "authorId": "2300095635",
                    "name": "Antonio De Santis"
                },
                {
                    "authorId": "71223212",
                    "name": "Andrea Tocchetti"
                },
                {
                    "authorId": "2261363606",
                    "name": "Marco Brambilla"
                }
            ]
        },
        {
            "paperId": "d1f289b1b6ca11032419a7224f24bee9dd6b1ace",
            "title": "Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data",
            "abstract": "Aerospace manufacturing companies, such as Thales Alenia Space, design, develop, integrate, verify, and validate products characterized by high complexity and low volume. They carefully document all phases for each product but analyses across products are challenging due to the heterogeneity and unstructured nature of the data in documents. In this paper, we propose a hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with Large Language Models (LLMs) to extract and validate data contained in these documents. We consider a case study focused on test data related to electronic boards for satellites. To do so, we extend the Semantic Sensor Network ontology. We store the metadata of the reports in a KG, while the actual test results are stored in parquet accessible via a Virtual Knowledge Graph. The validation process is managed using an LLM-based approach. We also conduct a benchmarking study to evaluate the performance of state-of-the-art LLMs in executing this task. Finally, we analyze the costs and benefits of automating preexisting processes of manual data extraction and validation for subsequent cross-report analyses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2300095635",
                    "name": "Antonio De Santis"
                },
                {
                    "authorId": "50535911",
                    "name": "Marco Balduini"
                },
                {
                    "authorId": "2311297309",
                    "name": "Federico De Santis"
                },
                {
                    "authorId": "2314831556",
                    "name": "Andrea Proia"
                },
                {
                    "authorId": "2314835847",
                    "name": "Arsenio Leo"
                },
                {
                    "authorId": "2314831211",
                    "name": "Marco Brambilla"
                },
                {
                    "authorId": "2539248",
                    "name": "Emanuele Della Valle"
                }
            ]
        }
    ]
}