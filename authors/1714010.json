{
    "authorId": "1714010",
    "papers": [
        {
            "paperId": "285ad71fbb601661dd6fa7dc6c0d64a3649726ba",
            "title": "Extended Overview of the CLEF 2024 LongEval Lab on Longitudinal Evaluation of Model Performance",
            "abstract": "We describe the second edition of the LongEval CLEF 2024 shared task. This lab evaluates the temporal persistence of Information Retrieval (IR) systems and Text Classifiers. Task 1 requires IR systems to run on corpora acquired at several timestamps, and evaluates the drop in system quality (NDCG) along these timestamps. Task 2 tackles binary sentiment classification at different points in time",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1917612940",
                    "name": "Rabab Alkhalifa"
                },
                {
                    "authorId": "2022477509",
                    "name": "Hsuvas Borkakoty"
                },
                {
                    "authorId": "2241526757",
                    "name": "Romain Deveaud"
                },
                {
                    "authorId": "1412404246",
                    "name": "Alaa El-Ebshihy"
                },
                {
                    "authorId": "2287959796",
                    "name": "Luis Espinosa-Anke"
                },
                {
                    "authorId": "2241503500",
                    "name": "Tobias Fink"
                },
                {
                    "authorId": "1832372",
                    "name": "P. Galusc\u00e1kov\u00e1"
                },
                {
                    "authorId": "1414343431",
                    "name": "Gabriela Gonz\u00e1lez-S\u00e1ez"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "2311380637",
                    "name": "David Iommi"
                },
                {
                    "authorId": "1991548",
                    "name": "Maria Liakata"
                },
                {
                    "authorId": "3467205",
                    "name": "Harish Tayyar Madabushi"
                },
                {
                    "authorId": "2261402559",
                    "name": "Pablo Medina-Alias"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "3309646",
                    "name": "Florina Piroi"
                },
                {
                    "authorId": "2241519380",
                    "name": "Martin Popel"
                },
                {
                    "authorId": "2805349",
                    "name": "A. Zubiaga"
                }
            ]
        },
        {
            "paperId": "6015655b879a93e8b7715e19912061c12c026e95",
            "title": "Improving Causality in Interpretable Video Retrieval",
            "abstract": "This paper focuses on the causal relation between the detection scores of concept (or tag) classifiers and the ranking decisions based on these scores, paving the way for these tags to be used in the visual explanations. We first define a measure for quantifying a causality on a set of tags, typically those involved in visual explanations. We use this measure for evaluating the actual causality in the explanations generated using a recent interpretable video retrieval system (Dong et al. [4]), which we find to be quite low. We then propose and evaluate improvements for significantly increasing this causality without sacrificing the retrieval accuracy of the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276781053",
                    "name": "Varsha Devi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "6be95ee876d0ab467931b13e29ed4c644cc9fff2",
            "title": "Extended Overview of the CLEF-2023 LongEval Lab on Longitudinal Evaluation of Model Performance",
            "abstract": "We describe the first edition of the LongEval CLEF 2023 shared task. This lab evaluates the temporal persistence of Information Retrieval (IR) systems and Text Classifiers. Task 1 requires IR systems to run on corpora acquired at several timestamps, and evaluates the drop in system quality (NDCG) along these timestamps. Task 2 tackles binary sentiment classification at different points in time, and evaluates the performance drop for different temporal gaps. Overall, 37 teams registered for Task 1 and 25 for Task 2. Ultimately, 14 and 4 teams participated in Task 1 and Task 2, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1917612940",
                    "name": "Rabab Alkhalifa"
                },
                {
                    "authorId": "2117010132",
                    "name": "I. Bilal"
                },
                {
                    "authorId": "2022477509",
                    "name": "Hsuvas Borkakoty"
                },
                {
                    "authorId": "1387447871",
                    "name": "Jos\u00e9 Camacho-Collados"
                },
                {
                    "authorId": "2241526757",
                    "name": "Romain Deveaud"
                },
                {
                    "authorId": "1412404246",
                    "name": "Alaa El-Ebshihy"
                },
                {
                    "authorId": "2258950306",
                    "name": "Luis Espinosa Anke"
                },
                {
                    "authorId": "2003700617",
                    "name": "Gabriela Nicole Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "1832372",
                    "name": "P. Galusc\u00e1kov\u00e1"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "144318711",
                    "name": "E. Kochkina"
                },
                {
                    "authorId": "48717312",
                    "name": "M. Liakata"
                },
                {
                    "authorId": "144653901",
                    "name": "Daniel Loureiro"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "3309646",
                    "name": "Florina Piroi"
                },
                {
                    "authorId": "2241519380",
                    "name": "Martin Popel"
                },
                {
                    "authorId": "2261405292",
                    "name": "Christophe Servan"
                },
                {
                    "authorId": "3467205",
                    "name": "Harish Tayyar Madabushi"
                },
                {
                    "authorId": "2805349",
                    "name": "A. Zubiaga"
                }
            ]
        },
        {
            "paperId": "a05f156c374fe93f25cad2b0874413fc341be60e",
            "title": "Exploratory Visualization Tool for the Continuous Evaluation of Information Retrieval Systems",
            "abstract": "This paper introduces a novel visualization tool that facilitates the exploratory analysis of continuous evaluation for information retrieval systems. We base our analysis on score standardization and meta-analysis techniques applied to Information Retrieval evaluation. We present three functionalities: evaluation overview, delta evaluation, and meta-analysis applied to three perspectives: evaluation rounds, queries, and systems. To illustrate the use of the tool, we provide an example using the TREC-COVID test collection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1414343431",
                    "name": "Gabriela Gonz\u00e1lez-S\u00e1ez"
                },
                {
                    "authorId": "1832372",
                    "name": "P. Galusc\u00e1kov\u00e1"
                },
                {
                    "authorId": "2287725",
                    "name": "Romain Deveaud"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "ed728a16c14977965c8214d5f64431ef59d230db",
            "title": "Towards Result Delta Prediction Based on Knowledge Deltas for Continuous IR Evaluation",
            "abstract": "The continuous evaluation of Information Retrieval Systems requires comparing IR systems both one to another, but also across collections, in other words across different evaluation environments (test collection and evaluation metrics). These evaluation environments may also be evolutionary versions of some given evaluation environment. In this work, we propose a methodology to measure and understand the impact the differences between test collection representations (i.e. knowledge delta, \ud835\udca6 \u0394 ) has on system performance, and we look at the differences in their outputs (i.e. result delta, \u211b \u0394 ). We present initial experiments with various text representations on the TREC 2004 Robust Collection, and look at the relation between the \ud835\udca6 \u0394 and the \u211b \u0394 .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2003700617",
                    "name": "Gabriela Nicole Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "1412404246",
                    "name": "Alaa El-Ebshihy"
                },
                {
                    "authorId": "1832372",
                    "name": "P. Galusc\u00e1kov\u00e1"
                },
                {
                    "authorId": "2311380637",
                    "name": "David Iommi"
                },
                {
                    "authorId": "3309646",
                    "name": "Florina Piroi"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "f15df5b8bada2ee8ba1c94e47dda4f621a322ba1",
            "title": "Entity Enhanced Attention Graph-Based Passages Retrieval",
            "abstract": "Passage retrieval is crucial in specialized domains where documents are long and complex, such as patents, legal documents, scientific reports, etc. We explore in this paper how the integration of Entities and passages in Heterogeneous Attention Graph Models can improve passage retrieval. We use the two passage retrieval architectures based on re-ranking proposed at ECIR 2022. We experiment our proposal on the TREC CAR Y3 Passage Retrieval Task. The results obtained show an improvement over state-of-the-art techniques and proves the effectiveness of the approach. Our experiments also show the importance of using adequate parameters for such approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161653321",
                    "name": "Lucas Albarede"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1412933472",
                    "name": "Claude Le Pape-Gardeux"
                },
                {
                    "authorId": "2257960730",
                    "name": "Sylvain Mari\u00e9"
                },
                {
                    "authorId": "1448437923",
                    "name": "Trinidad Chardin-Segui"
                }
            ]
        },
        {
            "paperId": "f40debce2b7caf35ea0730c27c5330989d20b300",
            "title": "LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation",
            "abstract": "LongEval-Retrieval is a Web document retrieval benchmark that focuses on continuous retrieval evaluation. This test collection is intended to be used to study the temporal persistence of Information Retrieval systems and will be used as the test collection in the Longitudinal Evaluation of Model Performance Track (LongEval) at CLEF 2023. This benchmark simulates an evolving information system environment - such as the one a Web search engine operates in - where the document collection, the query distribution, and relevance all move continuously, while following the Cranfield paradigm for offline evaluation. To do that, we introduce the concept of a dynamic test collection that is composed of successive sub-collections each representing the state of an information system at a given time step. In LongEval-Retrieval, each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models. The data comes from Qwant, a privacy-preserving Web search engine that primarily focuses on the French market. LongEval-Retrieval also provides a 'mirror' collection: it is initially constructed in the French language to benefit from the majority of Qwant's traffic, before being translated to English. This paper presents the creation process of LongEval-Retrieval and provides baseline runs and analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1832372",
                    "name": "P. Galusc\u00e1kov\u00e1"
                },
                {
                    "authorId": "2287725",
                    "name": "Romain Deveaud"
                },
                {
                    "authorId": "2223885719",
                    "name": "Gabriela Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "3309646",
                    "name": "Florina Piroi"
                },
                {
                    "authorId": "3209310",
                    "name": "M. Popel"
                }
            ]
        },
        {
            "paperId": "1208e65dfff9756d3884b31623ad5f995eab7ed2",
            "title": "Multi-element protocol on IR experiments stability: Application to the TREC-COVID test collection",
            "abstract": "The evaluation of information retrieval systems is performed using test collections. The classical Cranfield evaluation paradigm is defined on one fixed corpus of documents and topics. Following this paradigm, several systems can only be compared over the same test collections (documents, topics, assessments). In this work, we explore in a systematic way the impact of similarity of test collections on the comparability of the experiments: characterizing the minimal changes between the collections upon which the performance of IR system evaluated can be compared. To do that, we create pair instances of sub-test collections from one reference collection with controlled overlapping elements, and we compare the Ranking of Systems (RoS) of a defined list of IR systems. We can then compute the probability that the RoS are the same across the sub-test collections. We experiment with our framework proposed on the TREC-COVID collections, and two of our findings show that: a) the ranking of systems, according to the MaP, is very stable even for overlaps smaller than 10% for documents, relevance assessments and positive relevance assessments sub-collections, and b) stability is not ensured for MaP, Rprec, Bpref and ndcg evaluation measures even when considering large overlap for the topics. \u00a9 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2003700617",
                    "name": "Gabriela Nicole Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1832372",
                    "name": "P. Galusc\u00e1kov\u00e1"
                }
            ]
        },
        {
            "paperId": "c45a8ba136ae6e5ebdd0c6a2a1d1a8cbd5a7b912",
            "title": "Analysis of the Complementarity of Latent and Concept Spaces for Cross-Modal Video Search",
            "abstract": "This paper focuses on studying the complementarity between the spaces from hybrid cross-modal state-of-the-art systems for video retrieval like [5]. We aim at investigating if these spaces really convey different features, or if they are representing the same things. We use PCA (Principal Component Analysis) to study the optimal dimensions, CCA (Canonical Correlation Analysis) to assess the similarity of the spaces, and check if such approach is in fact similar to ensemble learning. We achieve experiments on the MST-VTT corpus, and show that in fact these two spaces are indeed very similar, paving the way for new models that could enforce more dissimilar spaces.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144564400",
                    "name": "Varsha Devi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "7ab51ae92f4af51cf054c15f496802f9eba6b7cd",
            "title": "Consumer Health Search at CLEF eHealth 2021",
            "abstract": "This paper details materials, methods, results, and analyses of the Consumer Health Search Task of the CLEF eHealth 2021 Evaluation Lab. This task investigates the effectiveness of information retrieval (IR) approaches in providing access to medical information to laypeople. For this a TREC -style evaluation methodology was applied: a shared collection of documents and queries is distributed, participants\u2019 runs received, relevance assessments generated, and participants\u2019 submissions evaluated. The task generated a new representative web corpus including web pages acquired from a 2021 CommonCrawl and social media content from Twitter and Reddit, along with a new collection of 55 manually generated layperson medical queries and their respective credibility, understandability, and topicality assessments for returned documents. This year\u2019s task focused on three subtask: (i) ad-hoc IR, (ii) weakly supervised IR, and (iii) document credibility prediction. In total, 15 runs were submitted to the three subtasks: eight addressed the ad-hoc IR task, three the weakly supervised IR challenge, and 4 the document credibility prediction challenge. As in previous years, the organizers have made data and tools associated with the task available for future research and development.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "2065161943",
                    "name": "H. Suominen"
                },
                {
                    "authorId": "2065794132",
                    "name": "G. Pasi"
                },
                {
                    "authorId": "52211445",
                    "name": "Elias Bassani"
                },
                {
                    "authorId": "1422792186",
                    "name": "N. Brew-Sam"
                },
                {
                    "authorId": "2003700617",
                    "name": "Gabriela Nicole Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "47146974",
                    "name": "Liadh Kelly"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "148135947",
                    "name": "Sandaru Seneviratne"
                },
                {
                    "authorId": "2074409385",
                    "name": "Rishabh Upadhyay"
                },
                {
                    "authorId": "40449696",
                    "name": "Marco Viviani"
                },
                {
                    "authorId": "2153075496",
                    "name": "Chenchen Xu"
                }
            ]
        },
        {
            "paperId": "a5f1c6c0b9637e78498fb238cd00d47f52358195",
            "title": "Addressing Different Evaluation Environments for Information Retrieval through Pivot Systems",
            "abstract": ". Classical evaluations of Information Retrieval systems, under the Cran\ufb01eld Paradigm, compare several systems within one evaluation environment, de\ufb01ned by its settings (document collection, topics, assessments and evaluation measures). In this paper, we pro-pose a framework to handle the comparison of systems across several evaluation environments. To achieve this goal, we investigate the use of pivot systems, allowing an indirect comparison of systems across evaluation environments by computing Result Deltas, i.e. the differences between their evaluation measures values. We detail the proposed pivot-based methodology, de\ufb01ne a pivot characteristics and present experiments to validate our proposal (and in particular the pivot characteristics). We create altered environments that differ from their topic sets using the 2018 and 2020 CLEF eHealth evaluation campaigns (Goeuriot et al. , 2020). We explore the behaviour of the metrics and pivots measuring the correlation between the result deltas, and the ranking of systems through the pivots compared to the of\ufb01cial ranking of the systems. Our experiment show that correlations can greatly vary according to the chosen pivot and metric. We show that some pivot/metric pairs achieve high correlation values across the altered environments, with a ranking of systems similar to the of\ufb01cial ranking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2003700617",
                    "name": "Gabriela Nicole Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "46d0c0b0866e8bd83c412c7e65b3d66acf2ddfa4",
            "title": "Learning Term Discrimination",
            "abstract": "Document indexing is a key component for efficient information retrieval (IR). After preprocessing steps such as stemming and stop-word removal, document indexes usually store term-frequencies (tf). Along with tf (that only reflects the importance of a term in a document), traditional IR models use term discrimination values (TDVs) such as inverse document frequency (idf) to favor discriminative terms during retrieval. In this work, we propose to learn TDVs for document indexing with shallow neural networks that approximate traditional IR ranking functions such as TF-IDF and BM25. Our proposal outperforms, both in terms of nDCG and recall, traditional approaches, even with few positively labelled query-document pairs as learning data. Our learned TDVs, when used to filter out terms of the vocabulary that have zero discrimination value, allow to both significantly lower the memory footprint of the inverted index and speed up the retrieval process (BM25 is up to 3~times faster), without degrading retrieval quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35342746",
                    "name": "Jibril Frej"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2504683",
                    "name": "D. Schwab"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                }
            ]
        },
        {
            "paperId": "499d7853989509152b21324d4fc7113d323591d5",
            "title": "Proof of Concept and Evaluation of Eye Gaze Enhanced Relevance Feedback in Ecological Context",
            "abstract": "The major method for evaluating Information Retrieval systems still relies nowadays on the \u201cCranfield paradigm\", supported by test collections. This sheds light on the fact that human behaviour is not considered central to Information Retrieval. For instance, some Information Retrieval systems that need users feedback to improve results relevance can not completely be evaluated with classical test collections (since the interaction itself is not a part of the evaluation). Our goal is to work toward the integration of specific human behaviour in Information Retrieval. More precisely, we studied the impact of eye gaze analysis on information retrieval. The hypothesis is that acquiring the terms read by a user on the result page displayed may be beneficial for a relevance feedback mechanism, without any explicit intervention of the user. We have implemented a proof of concept which allows us to experiment with this new method of interaction with a search engine. The contributions of our work are twofold. First, the proof of concept we created shows that eye gaze enhanced relevance feedback information retrieval systems could be implemented and that its evaluation gives interesting results. Second, we propose the basis of a evaluation platform for Information Retrieval systems that take into account users behaviour in ecological contexts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1859506757",
                    "name": "Vaynee Sungeelee"
                },
                {
                    "authorId": "1755319",
                    "name": "F. Jambon"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "5e0ac371b579ccceb21a00dce1ec9304ba1d49ac",
            "title": "LIG-Health at Adhoc and Spoken IR Consumer Health Search: expanding queries using UMLS and FastText",
            "abstract": ". This paper describes the work done by the LIG of Grenoble for the Adhoc and the Spoken Consumer Health search. Our focus for this participation is to study the e\ufb00ectiveness of simple query expansions for health related retrieval. We focused on several query expansions, us-ing knowledge-based or embedding-based techniques, with and without weighting of expansions, with and without Pseudo Relevance Feedback. The results obtained for Adhoc queries show that our baseline run out-performs the query expansions proposed. The results obtained for spoken queries show that several speakers lead to very di\ufb00erent results, and that merging the results from several users improve the quality of the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2003700617",
                    "name": "Gabriela Nicole Gonz\u00e1lez S\u00e1ez"
                },
                {
                    "authorId": "2003619686",
                    "name": "Aidan Mannion"
                },
                {
                    "authorId": "2504683",
                    "name": "D. Schwab"
                },
                {
                    "authorId": "35342746",
                    "name": "Jibril Frej"
                }
            ]
        },
        {
            "paperId": "804f4cfede2f08501e15e5f9af7062489e924660",
            "title": "Fairness in Online Jobs: A Case Study on TaskRabbit and Google",
            "abstract": "Online job marketplaces are becoming very popular. Either jobs or people are ranked by algorithms. For example, Google and Facebook job search return a ranked list of jobs given a search query. TaskRabbit and Fiverr, on the other hand, produce rank-ings of workers for a given query. Qapa, an online marketplace, can be used to rank both workers and jobs. In this paper, we develop a unified framework for fairness to study ranking workers and jobs. We case study two particular sites: Google job search and TaskRabbit. Our framework addresses group fairness where groups are obtained with any combination of protected attributes. We define a measure for unfairness for a given group, query and location. We also define two generic fairness problems that we address in our framework: quantification, such as finding the k groups (resp., queries, locations) for which the site is most or least unfair, and comparison, such as finding the locations at which fairness between two groups differs from all locations, or finding the queries for which fairness at two locations differ from all queries. Since the number of groups, queries and locations can be arbitrarily large, we adapt Fagin top-k algorithms to address our fairness problems. To evaluate our framework, we run extensive experiments on two datasets crawled from TaskRabbit and Google job search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1863248",
                    "name": "Shady Elbassuoni"
                },
                {
                    "authorId": "1410761195",
                    "name": "Ahmad Ghizzawi"
                },
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "51493818",
                    "name": "Emilie Hoareau"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "84114ea28401aa2d0a4874a4aeb853ec9887b405",
            "title": "Explaining Visual Classification using Attributes",
            "abstract": "The performance of deep Convolutional Neural Networks (CNN) has been reaching or even exceeding the human level on large number of tasks. Some examples are image classification, Mastering Go game, speech understanding etc. However, their lack of decomposability into intuitive and understandable components make them hard to interpret, i.e. no information is provided about what makes them arrive at their prediction. We propose a technique to interpret CNN classification task and justify the classification result with visual explanation and visual search. The model consists of two sub networks: a deep recurrent neural network for generating textual justification and a deep convolutional network for image analysis. This multimodal approach generates the textual justification about the classification decision. To verify the textual justification, we use the visual search to extract the similar content from the training set. We evaluate our strategy on a novel CUB dataset with the ground-truth attributes. We make use of these attributes to further strengthen the justification by providing the attributes of images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145884586",
                    "name": "M. Hassan"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "31617713",
                    "name": "D. Pellerin"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "4c2f2f3f2413e16469ed5b7bffa6b516d0a16dcc",
            "title": "Combining Subword information and Language model for Information Retrieval",
            "abstract": "InformationRetrieval(IR)classicallyreliesonseveralprocessestoimproveperfor- mance of language modeling approaches. When considering semantic of words, Neural Word Embeddings (Mikolov et al., 2013) have been shown to catch semantic similarities between words. Such Distributed Representations represent terms in a dense vector space are efficiently learned from large corpora. Lately, they have been used to compute the translation probabilities between terms in the Neural Translation Language Model (NTLM) (Zuccon et al., 2015) frame- work for Information Retrieval in order to deal with the vocabulary mismatch issue. In this work, we propose to test this model with recent vectorial representations (Bojanowski et al., 2016) that take into account the internal structure of words.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35342746",
                    "name": "Jibril Frej"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2504683",
                    "name": "D. Schwab"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                }
            ]
        },
        {
            "paperId": "dce992119217cca668d10bc290cda58600e15533",
            "title": "Building Evaluation Datasets for Cultural Microblog Retrieval",
            "abstract": "ECLEF Microblog Cultural Contextualization is an evaluation challenge aiming at providing the research community with datasetsto gather, organize and deliver relevant social data related to events generating large number of microblogs and web documents. Theevaluation challenges runs every year since 2016. We describe in this paper the resources built for the challenge, that can be used outsideof the context of the challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1707022",
                    "name": "J. Mothe"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "71701890",
                    "name": "Eric SanJuan"
                }
            ]
        },
        {
            "paperId": "496d0eb822381932e8defd213cac0eb7ab0c58a1",
            "title": "CLEF 2017 MC2 Search and Time Line tasks Overview",
            "abstract": "MC2 CLEF 2017 lab investigates the relationship between cultural microblogs and their social context. This involves microblog search, classification, filtering, language recognition, localization, entity extraction, linking open data, and summarization. The goal of the timeline illustration track is to study approaches that better retrieve microblogs issued during a cultural event, in order to get a glimpse of the attendees\u2019 perception. Regular Lab participants have access to the private massive multilingual microblog stream of The Festival Galleries project. Festivals have a large presence on social media. The topics were in four languages: Arabic, English, French and Spanish, and results were expected in any language.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "71701890",
                    "name": "Eric SanJuan"
                }
            ]
        },
        {
            "paperId": "39852d3f4f90a74b7af750ec43dcadab418fd46f",
            "title": "LIG at CLEF 2016 Cultural Microblog Contextualization: TimeLine illustration based on Microblogs",
            "abstract": "This paper presents the approach used by the LIG-MRIM research group to the participation of the task 3 (TimeLine illustration based on Microblogs) for the CLEF of Cultural Microblog Contextualization track. This task deals with the retrieval of tweets related to cultural events (music festivals). For the content-based elements, we use the classical BM25 model [4]. Then, we diversify the results based on duplicate removal, using tf-based representations of tweets. In a third step, we apply optional re-ranking related to time-line, activity and popularity of authors of tweets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2071584937",
                    "name": "N. Dogra"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2017118",
                    "name": "Nawal Ould Amer"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                }
            ]
        },
        {
            "paperId": "43464b28a14143ae197a7955194a2dc41da41260",
            "title": "Cultural micro-blog Contextualization 2016 Workshop Overview: data and pilot tasks",
            "abstract": "CLEF Cultural micro-blog Contextualization Workshop is aiming at providing the research community with data sets to gather, organize and deliver relevant social data related to events generating a large number of micro-blog posts and web documents. It is also devoted to discussing tasks to be run from this data set and that could serve applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143828316",
                    "name": "Liana Ermakova"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1707022",
                    "name": "J. Mothe"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "143619007",
                    "name": "Jian-Yun Nie"
                },
                {
                    "authorId": "71701890",
                    "name": "Eric SanJuan"
                }
            ]
        },
        {
            "paperId": "630f76281f65e69cfa99bde63901fa220699534c",
            "title": "Word Embedding for Social Book Suggestion",
            "abstract": "This paper presents the joint work of the Universities of Grenoble and Saint-\u00b4 Etienne at CLEF 2016 Social Book Search Suggestion Track. The approaches studied are based on personalization, considering the user's profile in the ranking process. The profile is filtered using Word Embedding, by proposing several ways to handle the generated relationships between terms. We find that tackling the problem of \" non-topical \" only queries is a great challenge in this case. The official results show that Word Embedding methods are able to improve results in the SBS case.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2017118",
                    "name": "Nawal Ould Amer"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1704972",
                    "name": "M. G\u00e9ry"
                },
                {
                    "authorId": "2497572",
                    "name": "Karam Abdulahhad"
                }
            ]
        },
        {
            "paperId": "948ab39cf99adc870d617d9f11c6f88019401cd0",
            "title": "MRIM-LIG at ImageCLEF 2016 Scalable Concept Image Annotation Task",
            "abstract": "This paper describes the participation of the the MRIM research Group of the LIG laboratory in the ImageCLEF scalable concept image annotation subtask 1. We made use of a classical framework to annotate the 500K images of this task: we tuned an existing Convolutional Neural Network model to learn the 251 concepts and to locate bounding boxes of such concepts, and we applied a specific process to handle faces and face parts. Because of time constraints, we fully processed 35% of the full corpus (i.e. 180K images), and partially the remaining images of the corpus. For our first participation to this task, the results obtained show that we have to manage the localization in a more effective way.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1869972",
                    "name": "Maxime Portaz"
                },
                {
                    "authorId": "1957245",
                    "name": "Mateusz Budnik"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2416217",
                    "name": "Johann Poignant"
                }
            ]
        },
        {
            "paperId": "c0abd79e615ef1914ce0460ba5bacb6a4cdda5f7",
            "title": "Lifelog Semantic Annotation using deep visual features and metadata-derived descriptors",
            "abstract": "This paper describes a method for querying lifelog data from visual content and from metadata associated with the recorded images. Our approach mainly relies on mapping the query terms to visual concepts computed on the Lifelogs images according to two separated learning schemes based on use of deep visual features. A post-processing is then performed if the topic is related to time, location or activity information associated with the images. This work was evaluated in the context of the Lifelog Semantic Access sub-task of the NTCIR-12 (2016). The results obtained are promising for a first participation to such a task, with an event-based MAP above 29% and an event-based nDCG value close to 39%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                }
            ]
        },
        {
            "paperId": "e513b6d8b5f474ad4224b8b7a9c700d22328d908",
            "title": "Tweet Contextualization Approach Based on Wikipedia and Dbpedia",
            "abstract": "Bound to 140 characters, tweets are short and not written maintaining formal grammar and proper spelling. These spelling variations increase the likelihood of vocabulary mismatch and make them difficult to understand without context. This paper falls under the tweet contextualization task that aims at providing, automatically, a summary that explains a given tweet, allowing a reader to understand it. We propose different tweet expansion approaches based on Wikipeda and Dbpedia as external knowledge sources. These proposed approaches are divided into two steps. The first step consists in generating the candidate terms for a given tweet, while the second one consists in ranking and selecting these candidate terms using a \nsimilarity measure. The effectiveness of our methods is proved through an experimental study conducted on the INEX 2014 collection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2411622",
                    "name": "Meriem Amina Zingla"
                },
                {
                    "authorId": "2324964",
                    "name": "C. Latiri"
                },
                {
                    "authorId": "1706591",
                    "name": "Y. Slimani"
                },
                {
                    "authorId": "1736012",
                    "name": "C. Berrut"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "e61aab696a6117d75573614ba0ad69d3e95dd95e",
            "title": "Toward Word Embedding for Personalized Information Retrieval",
            "abstract": "This paper presents preliminary works on using Word Embedding (word2vec) for query expansion in the context of Personalized Information Retrieval. Traditionally, word embeddings are learned on a general corpus, like Wikipedia. In this work we try to personalize the word embeddings learning, by achieving the learning on the user's profile. The word embeddings are then in the same context than the user interests. Our proposal is evaluated on the CLEF Social Book Search 2016 collection. The results obtained show that some efforts should be made in the way to apply Word Embedding in the context of Personalized Information Retrieval.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2017118",
                    "name": "Nawal Ould Amer"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1704972",
                    "name": "M. G\u00e9ry"
                }
            ]
        },
        {
            "paperId": "fbf4416b8e4846c5069e4f4c6f6d16d783605bd2",
            "title": "LIG-MRIM at NTCIR-12 Lifelog Semantic Access Task",
            "abstract": "This paper describes the participation of the LIG-MRIM research team to the Lifelog Semantic Access sub-task of the NTCIR-12 (2016). Our approach mainly relies on mapping the query terms to visual concepts computed on the Lifel-ogs images according to two separated learning schemes. A post-processing is then performed if the topic is related to temporal, location or activity information associated with the images. The results obtained are promising for a first participation to such a task, with event-based MAP above 29% and an event-based nDCG value close to 39%. Team Name MRIM Subtasks Lifelog Semantic Access Task",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                }
            ]
        },
        {
            "paperId": "72dad0a47a8f3a309ea8410e4c3c7759482cd641",
            "title": "LIG at TRECVid 2015: Semantic Indexing",
            "abstract": "LIG participated to the semantic indexing main task. LIG also participated to the organization of this task. This paper describes these participations which are quite similar to our previous year's participations (within the Quaero consortium). Our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classification, fusion of descriptor variants, higher-level fusion, and re-ranking. We used a number of different descriptors and a hierarchical fusion strategy. We also used conceptual feedback by adding a vector of classification score to the pool of descriptors. The main innovation this year consisted in the inclusion of semantic descriptors computed using a deep learning method. We also used multiple frames for some features and this did lead to a significant improvement. The best LIG run has a Mean Inferred Average Precision of 0.2935, which ranked it 5$^{th}$ out of 15 participants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "3224603",
                    "name": "N. Derbas"
                },
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1957245",
                    "name": "Mateusz Budnik"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "bb11fc1d0ed970bc06b389f9c169ba66ff9cabc2",
            "title": "LIG at CLEF 2015 SBS Lab",
            "abstract": "This paper describes the work achieved by the MRIM research group of Grenoble, using some data from the LaHC of SaintEtienne, in a way to test personalized retrieval of books for the Social Book Search Lab of CLEF 2015. Our proposal rely on a biased fusion of content-only retrieval, using BM25F and LGD retrieval models, user non-social profile based on the catalog of the requester, and social profiles using user/user links generated from their catalogs and ratings on books. The official results obtained show a clear positive impact of user profile, and a small positive impact of the social elements we used. Post official results that present non biased fusion scores are also presented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2017118",
                    "name": "Nawal Ould Amer"
                },
                {
                    "authorId": "1704972",
                    "name": "M. G\u00e9ry"
                }
            ]
        },
        {
            "paperId": "edf7582a4f198f510cd663539c0be27dd7f0d597",
            "title": "Temporal re-scoring vs. temporal descriptors for semantic indexing of videos",
            "abstract": "The automated indexing of image and video is a difficult problem because of the \u201cdistance\u201d between the arrays of numbers encoding these documents and the concepts (e.g. people, places, events or objects) with which we wish to annotate them. Methods exist for this but their results are far from satisfactory in terms of generality and accuracy. Existing methods typically use a single set of such examples and consider it as uniform. This is not optimal because the same concept may appear in various contexts and its appearance may be very different depending upon these contexts. The context has been widely used in the state of the art to treat various problems. However, the temporal context seems to be the most crucial and the most effective for the case of videos. In this paper, we present a comparative study between two methods exploiting the temporal context for semantic video indexing. The proposed approaches use temporal information that is derived from two different sources: low-level content and semantic information. Our experiments on TRECVID'12 collection showed interesting results that confirm the usefulness of the temporal context and demonstrate which of the two approaches is more effective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "1cdc1e264f22f79475e8d9ebd619bb2c7b5f0fc1",
            "title": "LIG at TRECVid 2014: Semantic Indexing",
            "abstract": "LIG participated to the semantic indexing main task. LIG also participated to the organization of this task. This paper describes these participations which are quite similar to our previous year's participations (within the Quaero consortium). \nFor the semantic indexing main task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classification, fusion of descriptor variants , higher-level fusion, and re-ranking. We used a number of different descriptors and a hierarchical fusion strategy. We also used conceptual feedback by adding a vector of classification score to the pool of de-scriptors. The main innovation this year consisted in the inclusion of semantic descriptors computed using a deep learning method. We also used the uploader field available in the metadata and this did lead to a small improvement. The best LIG run has a Mean Inferred Average Precision of 0.2659, which ranked us 4th out of 15 participants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "3224603",
                    "name": "N. Derbas"
                },
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1957245",
                    "name": "Mateusz Budnik"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "7ec418378d7709f625988bc2e8501288fdf7d5a0",
            "title": "Infrequent concept pairs detection in multimedia documents",
            "abstract": "Single visual concept detection in videos is a hard task, especially for infrequent concepts or for those difficult to model. This question becomes even more difficult in the case of concept pairs. Two main directions may tackle this problem: 1) combine the predictions of their corresponding detectors in a way which is similar to usual information retrieval, or 2) build supervised learners for these pairs of concepts by generating annotations based on the occurrences of the two individual concepts. Each of these approaches have advantages and drawbacks. We evaluated them in the context of the concept pair detection subtask of the TRECVid 2013 semantic indexing (SIN) task and found that information retrieval-like fusions of concept detection scores outperforms the learning approaches. The described methods outperform the best official result of the evaluation campaign cited previously, by 9% in terms of relative improvement on MAP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "bb5481d50edc2130baadb208daa08a03b419f65c",
            "title": "Annotation of still images by multiple visual concepts",
            "abstract": "The automatic indexing of images and videos is a highly relevant and important research area in the field of multimedia information retrieval. The difficulty of this task is no longer something to prove. The majority of the efforts of the research community have been focused in the past on the detection of single concepts in images/videos, which is already a hard task. With the evolution of the information retrieval systems, users needs are more abstract, and lead to a larger number of words composing the queries. It is sensible to think about indexing multimedia documents by more than one concept, to help retrieval systems to answer such complex queries. Few studies addressed specifically the problem of detecting multiple concepts (multi-concept) in images and videos, most of them concern the detection of concept pairs. These studies showed that such challenge is even greater than the one of single concept detection. In this work, we address this problematic of mult-concept detection in still images. Two types of approaches are considered : 1) building models per multi-concept and 2) fusion of single concepts detectors. We conducted our evaluation on PASCAL VOC'12 collection regarding the detection of pairs and triplets of concepts. Our results show that the two types of approaches give globally comparable results, but they differ for specific kinds of pairs/triplets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "0a3424d4a345e0783439d7054a8929f04175af6e",
            "title": "Multimedia Information Modeling and Retrieval, Laboratoire d'Informatique de Grenoble (LIG-MRIM) at CHiC2013",
            "abstract": "Numerous cultural heritage materials are accessible through online digital library portals. However, this conversion resulted in the issues of inconsistency and incompleteness. The Cultural Heritage in CLEF 2013 (CHiC) takes the initiative to organize an evaluation campaign which involve several tasks such as 1) multilingual task, 2) polish task and 3) interactive task. We present the results of the MRIM/LIG team for the Ad-Hoc task and for the Semantic Enrichment task. For the Ad-Hoc task, we incorporate Term Links based on Wikipedia into the Language Model. Our approach has the following advantages: 1) it is easy and simple to generate the Term Similarity Matrix based on statistical information 2) a light weight integration in the Language Model. For the semantic query enrichment task, we deal with short queries found in this collection. These short queries cannot describe a specific information need. Hence, the goal of this task is to find best ten terms for a query to semantically enrich the topic and guess the user's information need or original query intent. We use the Wikipedia as a semantic resource in order to find these related terms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72214874",
                    "name": "Kian Lam Tan"
                },
                {
                    "authorId": "2325185",
                    "name": "M. Almasri"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                },
                {
                    "authorId": "2064281685",
                    "name": "Catherine Berrut"
                }
            ]
        },
        {
            "paperId": "2f0a93d45d6dd532423181c563fe80192635e236",
            "title": "Quaero at TRECVID 2013: Semantic Indexing and Instance Search",
            "abstract": "The Quaero group is a consortium of French and German organizations working on Multimedia Indexing and Retrieval1. LIG participated to the semantic indexing main task, localization task and concept pair task. LIG also participated to the organization of this task. This paper describes these participations which are quite similar to our previous year's participations. For the semantic indexing main task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classiffication, fusion of descriptor variants, higher-level fusion, and re-ranking. We used a number of different descriptors and a hierarchical fusion strategy. We also used conceptual feedback by adding a vector of classiffication score to the pool of descriptors. The best Quaero run has a Mean Inferred Average Precision of 0.2848, which ranked us 2nd out of 26 participants. We also co-organized the TRECVid SIN 2013 task and collaborative annotation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "3224603",
                    "name": "N. Derbas"
                },
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "73735314",
                    "name": "Thi-Thu-Thuy Vuong"
                },
                {
                    "authorId": "2113412342",
                    "name": "Han Dong"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "6e4765f66582537940299931f0bb092ce7864e0d",
            "title": "Reading contexts for structured documents retrieval",
            "abstract": "This paper focuses on the retrieval of parts of structured document called doxels. We propose a notion of reading context of a doxel and we exploit it to extend an Indexing Language Model (LM) with Dirichlet smoothing. We interpret a context of a doxel as a propagation of the content of the connected doxels via document structure links. We experiment this model on INEX corpus 2009, and test different context propagations. We measure a significant increase in results using contexts, compared to a reference approach without the use of context for 3 types of doxels. Moreover, our proposal outperforms the best result obtained for the Focused evaluation for the Ad Hoc task at INEX 2009.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                }
            ]
        },
        {
            "paperId": "766e9c31953618ac439cb2c6279fd5562cb32284",
            "title": "Clustering based rescoring for semantic indexing of multimedia documents",
            "abstract": "This paper describes a new approach for multimedia documents indexing and addresses the problem of automatically detecting a large number of visual concepts. Though using a multi-label approaches are used in some works, concepts detectors are often trained independently. We propose a model that takes into account the detection of not only a target concept but also other ones and regroups in terms of semantics similar samples. The expected benefit from such a combination is to consider the relationships between concepts in order to reclassify the results of an initial indexing system. Experiments on the TRECVID 2012 data are presented and discussed. Our method has significantly improved a quite good baseline system performance up to +6 % on mean average precision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "9f9478ffc32872c5ccefdce49de6fa58d1597409",
            "title": "Conceptual feedback for semantic multimedia indexing",
            "abstract": "In this paper, we consider the problem of automatically detecting a large number of visual concepts in images or video shots. State of the art systems involve feature (descriptor) extraction, classification (supervised learning) and fusion when several descriptors and/or classifiers are used. Though direct multi-label approaches are considered in some works, detection scores are often computed independently for each target concept. We propose here a method that we call \u201cconceptual feedback\u201d for improving the overall detection performance that implicitly takes into account the relations between concepts. The vector of normalized detection scores is added to the pool of available descriptors. It is then processed just as the other descriptors for the normalization, optimization and classification steps. The resulting detection scores are finally fused with the already available detection scores obtained with the original descriptors. The feedback of the global detection scores in the pool of descriptors can be iterated several times. It is also compatible with the use of the temporal context that also improves the overall performance by taking into account the local homogeneity of video contents. The method has been evaluated in the context of the TRECVID 2012 semantic indexing task involving the detection of 346 visual or multimodal concepts. Combined with temporal re-scoring, the proposed method increased the global system performance (MAP) from 0.2613 to 0.3014 (+15.3% of relative improvement) while the temporal re-scoring alone increased it only from 0.2613 to 0.2691 (+3.0%).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "a69e7d50da4a73bdfac6247396ca96ad0ad5f862",
            "title": "Multimedia Information Modeling and Retrieval (MRIM) /Laboratoire d'Informatique de Grenoble (LIG) at CHiC2013",
            "abstract": "Numerous cultural heritage materials are accessible through online digital library portals. However, this conversion resulted in the issues of inconsistency and incompleteness. The Cultural Heritage in CLEF 2013 (CHiC) takes the initiative to organize an evaluation campaign which involve several tasks such as 1) multilingual task, 2) polish task and 3) interactive task. We present the results of the MRIM/LIG team for the Ad-Hoc task and for the Semantic Enrichment task. For the Ad-Hoc task, we incorporate Term Links based on Wikipedia into the Language Model. Our approach has the following advantages: 1) it is easy and simple to generate the Term Similarity Matrix based on statistical information 2) a light weight integration in the Language Model. For the semantic query enrichment task, we deal with short queries found in this collection. These short queries can not describe a specific information need. Hence, the goal of this task is to find best ten terms for a query to semantically enrich the topic and guess the user\u2019s information need or original query intent. We use the Wikipedia as a semantic resource in order to find these related terms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72214874",
                    "name": "Kian Lam Tan"
                },
                {
                    "authorId": "2325185",
                    "name": "M. Almasri"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2064281685",
                    "name": "Catherine Berrut"
                }
            ]
        },
        {
            "paperId": "f579da7ee8ea217c0af2de9198ce2f8253a59376",
            "title": "Quaero at TRECVID 2013: Semantic Indexing",
            "abstract": "The Quaero group is a consortium of French and German organizations working on Multimedia Indexing and Retrieval 1 . LIG participated to the semantic indexing main task, localization task and concept pair task. LIG also participated to the organization of this task. This paper describes these participations which are quite similar to our previous year\u2019s participations. For the semantic indexing main task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classication, fusion of descriptor variants, higher-level fusion, and re-ranking. We used a number of dierent descriptors and a hierarchical fusion strategy. We also used conceptual feedback by adding a vector of classication score to the pool of descriptors. The best Quaero run has a Mean Inferred Average Precision of 0.2848, which ranked us 2 nd out of 26 participants. We also co-organized the TRECVid SIN 2013 task and collaborative annotation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "3224603",
                    "name": "N. Derbas"
                },
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "73735314",
                    "name": "Thi-Thu-Thuy Vuong"
                },
                {
                    "authorId": "2113412342",
                    "name": "Han Dong"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "e13e9aca1adc73f17f6ba3d25f21f61a5fefc4b2",
            "title": "Two-layers re-ranking approach based on contextual information for visual concepts detection in videos",
            "abstract": "Context helps to understand the meaning of a word and allows the disambiguation of polysemic terms. Many researches took advantage of this notion in information retrieval. For concept-based video indexing and retrieval, this idea seems a priori valid. One of the major problems is then to provide a definition of the context and to choose the most appropriate methods for using it. Two kinds of contexts were exploited in the past to improve concepts detection: in some works, inter-concepts relations are used as semantic context, where other approaches use the temporal features of videos to improve concepts detection. Results of these works showed that the \u201ctemporal\u201d and the \u201csemantic\u201d contexts can improve concept detection. In this work we use the semantic context through an ontology and exploit the efficiency of the temporal context in a \u201ctwo-layers\u201d re-ranking approach. Experiments conducted on TRECVID 2010 data show that the proposed approach always improves over initial results obtained using either MSVM or KNN classifiers or their late fusion, achieving relative gains between 9% and 33% of the MAP measure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1877339",
                    "name": "Abdelkader Hamadi"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "888f56439229d26efaf67edb5a2dcfe59d461c9b",
            "title": "A new ROI grouping schema for automatic image annotation",
            "abstract": "Regions Of Interest (ROI) are successfully used in automatic image annotation through Bag of Visual Words (BoVW) models. However, the \u201cflat\u201d BoVW models ignore potentially relevant topological relationships between the ROI. While several works tried to take into account such relations for Content Based Image Retrieval (CBIR), few works evaluated clearly their effects in the context of automatic image annotation. In this article, we propose to explicit the relationships between ROI in automatic annotation methods in order to evaluate their contributions on the results quality. This is done through a model, called \u201cphrasing model\u201d, that generates groups of ROI called Visual Phrases according to relationships constraints. Based on our phrasing model, we define two kinds of Visual Phrases and we show that taking into account topological ROI relationships can significantly overcome the results of the classical BoVW model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3174279",
                    "name": "Rami Albatal"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                }
            ]
        },
        {
            "paperId": "bab71eb8ce716ae52246e91aba447dde4c53cdad",
            "title": "LIG-MRIM at Image Photo Annotation Task in ImageCLEF 2011",
            "abstract": "We describe in this paper the different approaches tested for the Photo Annotation task for CLEF 2011. We experimented state of the art techniques, by proposing late fusions of several classifiers trained on several features extracted from the images. The classifiers are SVMs and the late fusion is a simple addition of classification probabilities coming from the SVMs. The results obtained place our runs in the middle of the pack, with our best visual-based MAP at 0.337 We also integrated of Flickr human annotations, leading to a large increase of the MAP with a value of 0.377.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3174279",
                    "name": "Rami Albatal"
                },
                {
                    "authorId": "2357942",
                    "name": "Bahjat Safadi"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "0a727b1396f662de65dee70246200ce997e171bf",
            "title": "Integration of spatial relationships in visual language model for scene retrieval",
            "abstract": "In this paper, we describe a method to use a graph-based language modeling approach for image retrieval and image categorization. We first mapped image regions to induced concepts and then spatial relationships between these regions to build a graph representation of images. Our method allows to deal with different scenarii, where isolated images or groups of images are used for training and testing. The results obtained on an image categorization problem comprising of 3849 images from 101 landmarks of Singapore show that (a) the procedure to automatically induce concepts from an image is effective, and (b) the use of spatial relationships, in addition to concepts, for representing an image content helps improve the classifier accuracy. This approach is the first one, to our knowledge, to present a complete extension of the language modeling approach from information retrieval to the problem of graph-based image categorization and retrieval.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689263",
                    "name": "Trong-Ton Pham"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2454024",
                    "name": "Lo\u00efc Maisonnasse"
                },
                {
                    "authorId": "48819635",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "1404571875",
                    "name": "Ali A\u00eft-Bachir"
                }
            ]
        },
        {
            "paperId": "4d7c95b55a69616d7081215ed666077cbcef991f",
            "title": "Visual Phrases for automatic images annotation",
            "abstract": "Visual characteristics of objects of a class vary with the considered instance and the shooting conditions. In this paper we proposed a visual characterization of object parts, called \"Visual Phrase\", robust to these variations. A Visual Phrase is a set of regions of interest built according to predefined criteria; a topological criterion was studied in this paper. An automatic annotation method is proposed based on our definition and characterization of Visual Phrases. Experiments on VOC2009 collection is presented, we show that the late fusion of our method with a standard Bag of Visual Words approach on full images provides better results than those obtained via each approach independently.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3174279",
                    "name": "Rami Albatal"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                }
            ]
        },
        {
            "paperId": "4dcb1d0e15d4c526ff25b152df1d154689921842",
            "title": "Spatial relationships in visual graph modeling for image categorization",
            "abstract": "In this paper, a language model adapted to graph-based representation of image content is proposed and assessed. The full indexing and retrieval processes are evaluated on two different image corpora. We show that using the spatial relationships with graph model has a positive impact on the results of standard Language Model (LM) and outperforms the baseline built upon the current state-of-the-art Support Vector Machine (SVM) classification method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689263",
                    "name": "Trong-Ton Pham"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2454024",
                    "name": "Lo\u00efc Maisonnasse"
                }
            ]
        },
        {
            "paperId": "bbec4a20ee5cbdac1944cabb49031450573fa235",
            "title": "Visual Graph Modeling for Image Categorization and Robot Localization",
            "abstract": "Image analysis and retrieval may need to consider several types of visual features and spatial information between them (e.g. different points of views of an image). This paper presents a novel approach that exploits an extension of the language modeling approach from information retrieval to the problem of graph-based image retrieval and categorization. Such versatile graph model is needed to represent the multiple points of views of images. A language model is defined on such graphs to handle a fast graph matching. We present the experiments achieved with several instances of the proposed model on two collections of images (one composed of 3849 touristic images and one composed of 3633 images captured by a mobile robot), and show that the results obtained using visual graph model improve the accuracies of the results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689263",
                    "name": "Trong-Ton Pham"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2454024",
                    "name": "Lo\u00efc Maisonnasse"
                },
                {
                    "authorId": "48819635",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "6516914",
                    "name": "Joo-Hwee Lim"
                }
            ]
        },
        {
            "paperId": "ce197d9f1bcee7a28e77be38bab6aa2d5c6adb5f",
            "title": "MRIM-LIG at ImageCLEF 2010 Visual Concept Detection and Annotation task",
            "abstract": "This paper focuses on one of the Image CLEF Photo tasks at which the MRIM research group of the LIG participated: the Visual Concept Detection and Annotation. For this task, we applied a simple state of the art technique based on bag of vi- sual words. We extracted SIFT-like features that integrate colors (rgSIFT) proposed by van de Sande(10). We used then a Kmeans clustering in a way to group these features according to 4000 clus- ters. We generated then for each image of the training set a 4000 dimensions histogram by summing all the occurrences of each clus- ter, using the nearest neighbour centroid for each extracted feature. For the recognition we extracted the rgSIFT features from the test set, before generating the 4000 dimensional histograms. We applied then SVMs with RBF kernels using a probabilistic estimation of recognition. The results obtained by our run are presented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3174279",
                    "name": "Rami Albatal"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "07acc75c7fd04a190d321f9285d571995bf8252a",
            "title": "MRIM-LIG at ImageCLEF 2009: Photo Retrieval and Photo Annotation Tasks",
            "abstract": "This paper describes the different experiments that have been conducted by the MRIM group at the LIG in Grenoble for the ImageCLEF 2009 campaign. The group participated in the following tasks: Image Retrieval and Image Annotation. For the Image Retrieval task, we submitted runs with both text and image features, and a diversification process was applied. For the Image Annotation task, we used several features and classifiers in a way to generate keyword descriptions. For these two tasks, the results obtained are above the average of the participants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1702093",
                    "name": "J. Chevallet"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "3174279",
                    "name": "Rami Albatal"
                }
            ]
        },
        {
            "paperId": "5174bc4e269adcaed225296e0ea514ca24e1c263",
            "title": "Comparing image segmentation algorithms for content based image retrieval systems.",
            "abstract": "This article discusses how to compare different image segmentation algorithms parameters in order to choose the most optimal algorithm parameters for a specific task(s) (e.g. feature extraction, spatial reasoning, topological analysis). Our method of comparison lets the user decide which segmentation algorithm/parameters are the most suitable for his system, this decision is obtained according to three indicators: the amount of relevant visual information as well as the noise in image regions, the average number of regions per images and the average number of regions per object.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3174279",
                    "name": "Rami Albatal"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                },
                {
                    "authorId": "49671775",
                    "name": "Tat-Jun Chin"
                }
            ]
        },
        {
            "paperId": "601329e85b295046b721979a223f13ea5b5f7d27",
            "title": "Comparison of Various AVEIR Visual Concept Detectors with an Index of Carefulness",
            "abstract": "Visual annotation is still an open issue. The Content Based community admits that \na plurality of features and systems shall be considered. We present in this paper four \nvery different strategies using not only visual information but also text, to implement \nImageCLEF2009 Photo Annotation Task. The visual features are various, such as HSV, \nGabor, EDGE, SIFT, and some more recent. Then we study each model performances, \nand propose a new measure, the Carefulness Index (Q) computed on the histogram of \nthe model?s outputs. Q seems to be correlated with the model performances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1742496",
                    "name": "H. Glotin"
                },
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "145567641",
                    "name": "Marin Ferecatu"
                },
                {
                    "authorId": "2218889657",
                    "name": "Z. Zhao"
                },
                {
                    "authorId": "2793292",
                    "name": "Sabrina Tollari"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1692389",
                    "name": "H. Sahbi"
                },
                {
                    "authorId": "153339732",
                    "name": "Emilie Dumont"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "815d5b966c1ae779f5a5b9cb82cade16ac083921",
            "title": "Visual Language Modeling for Mobile Localization: LIG Participation in RobotVision'09",
            "abstract": "This working note presents our novel approach for scene recognition (i.e. localization of mobile robot using visual information) in the RobotVision task [1] based on language model [2]. Language model has been successfully used for information retrieval (specifically for textual retrieval). In recent study [3], this model has also showed a good performance on modeling the visual information. For this reason, it can be used to address several problems in image understanding such as: scene recognition, image retrieval, etc. We have developed a visual language framework to participate in RobotVision\u201909 task this year. This framework consists of 3 principal components: a training step, a matching step and a post-processing step. Finally, we present the results of our approach on both validation set and test set released by the ImageCLEF\u2019s organizer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689263",
                    "name": "Trong-Ton Pham"
                },
                {
                    "authorId": "2454024",
                    "name": "Lo\u00efc Maisonnasse"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "15706f0a81daae563b59072d64336a19b76b835f",
            "title": "Consortium AVEIR at ImageCLEFphoto 2008: on the Fusion of Runs",
            "abstract": "In this working note, we present the submission of the AVEIR consortium, composed of 4 French laboratories, to ImageCLEFphoto 2008. The submitted runs correspond to different fusion strategies applied to four individual ranks, each proposed by an AVEIR consortium partner. In particular, we study the complete, and partial, average of the ranking values, the minimum of these values, and a random based diversification. We first briefly describe the individual run of each partner, then we describe the fusion runs. The official results classed one of the runs, the MEAN fusion, as the third best in the automatic text-image run category. This run gives better results than the best partner run.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2793292",
                    "name": "Sabrina Tollari"
                },
                {
                    "authorId": "1762116",
                    "name": "Marcin Detyniecki"
                },
                {
                    "authorId": "145567641",
                    "name": "Marin Ferecatu"
                },
                {
                    "authorId": "1742496",
                    "name": "H. Glotin"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                },
                {
                    "authorId": "1692389",
                    "name": "H. Sahbi"
                },
                {
                    "authorId": "33698309",
                    "name": "Zhong-Qiu Zhao"
                }
            ]
        },
        {
            "paperId": "dec7d4f86a32fee72d8021108d361b96a360e4d9",
            "title": "LIG at ImageCLEFphoto 2008",
            "abstract": "This working notes describe the runs and results obtained by the LIG at ImageCLEFphoto 2008. The submitted runs are: two runs (text only and text+image) without diversification on classes, and two runs (text only and text+image) with class diversification were submitted. The text retrieval is based on language model of Information Retrieval, and the image part is processed using RGB histograms on 9 image blocks with a similarity value based on Jeffrey divergence. Results using text+image are obtained by a linear combination of normalized results on text and image. The diversification is based on clusters, according to the cluster given in the queries. When the cluster name is not directly extracted from the images (like city or country), we apply a visual clustering. Not surprisingly, the cluster recall at 20 (i.e., cr(20)) results are higher for the runs that include diversification. On the other hand, the precision at 20 and the mean average precision results are higher without diversification on our runs, for both text only and image+text results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "df1373c82af48bcb229a52604917920b0d723f4d",
            "title": "Doxels in context for retrieval: from structure to neighbours",
            "abstract": "We propose in this paper a new way of considering retrieval of structured documents, by exploiting non-structural relations between structured document elements (doxels). These relations may be defined by human beings (e.g. by the authors of the documents for navigation or reference purposes), but may also be created by the information retrieval system (e.g. using kNN). Unlike Pagerank or HITS that separate features link and content features, we integrate these two aspects by defining a relative specificity and a relative exhaustivity between doxels. We use these features, as well as the doxel content, in a comprehensive matching process. One concern here is to facilitate the exploration of the result space by selecting the relevant doxels, and by indicating potential good neighbours to access from one doxel. Results of experiments on the INEX2005 test collection are presented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2082528193",
                    "name": "Delphine Verbyst"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "70ae8867ea3e0141294038fea1481ab7f233ad43",
            "title": "Metadata handling: A video perspective",
            "abstract": "This article addresses the problem of processing the annotations of preexisting video productions to enable reuse and repurposing of metadata. We introduce the concept of automatic content-based editing of preexisting semantic home video metadata. We propose a formal representation and implementation techniques for reusing and repurposing semantic video metadata in concordance with the actual video editing operations. A novel representation for metadata editing is proposed and an implementation framework for editing the metadata in accordance with the video editing operations is demonstrated. Conflict resolution and regularization operations are defined and implemented in the context of the video metadata editing operations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3063232",
                    "name": "C. Madhwacharyula"
                },
                {
                    "authorId": "144562609",
                    "name": "Marc Davis"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                }
            ]
        },
        {
            "paperId": "c5ed33fb00d91a0415f85e77dd405ab62e32824b",
            "title": "A framework for Mixed Symbolic-based and Feature-based Query by Example Image Retrieval",
            "abstract": "This paper defines and studies the use of query by example (QBE) in the context of photograph retrieval. The novelty of our approach lies in considering an automatic indexing process of photographs as well as a representation of the features of image regions in a single knowledge representation formalism. Both symbolic and feature based representation are used during the query by example process. More precisely, the QBE process is able to take into account the symbolic descriptors of the images but also the extracted features from image under the form of histograms. The aim of this process is to detect the relative importance of the symbolic elements and of the feature elements according to the user's query by example. We experiment the query by example process on two collections of a total of 1100 photographs. The precision measures we have obtained are as good as a baseline defined as explicit textual queries processing. Keyword: Symbolic Image Indexing, Image Retrieval, Conceptual Graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2585539",
                    "name": "Emmanuel Debanne"
                }
            ]
        },
        {
            "paperId": "7f4d18ed0c8e08c86b93f96931a444249d99752c",
            "title": "A model for weighting image objects in home photographs",
            "abstract": "The paper presents a contribution to image indexing consisting in a weighting model for visible objects -- or image objects -- in home photographs. To improve its effectiveness this weighting model has been designed according to human perception criteria about what is estimated as important in photographs. Four basic hypotheses related to human perception are presented, and their validity is estimated as compared to actual observations from a user study. Finally a formal definition of this weighting model is presented and its consistence with the user study is evaluated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34990008",
                    "name": "J. Martinet"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "1ce19d061285f2b50552c8cdbae38efa02fd5c44",
            "title": "Content based editing of semantic video metadata",
            "abstract": "Bridging the 'signal-symbol gap' existing between multimedia signals generated through audio, video or other multimedia streams and the high level symbols (metadata) which describe them is presently one of the most vital areas of multimedia research. The paper attempts to bridge this significant gap by proposing a novel automatic mechanism for XML based video metadata editing, in tandem with video editing operations. An implementation framework for editing metadata in accordance with the video editing operations is demonstrated. Conflicting resolution and regularization operations are defined and implemented with respect to video metadata editing operations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3063232",
                    "name": "C. Madhwacharyula"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "705a265373e1a64d3d83defc46c062fece0861d8",
            "title": "Towards Personalized Image Retrieval",
            "abstract": "This paper describes an approach to personalized image indexing and retrieval. To tackle the issue of subjectivity in Content-Based Image Retrieval (CBIR), users can define their own indexing vocabulary and make the system learn it. These indexing concepts may be both local (objects) and global (image ategories). The system guides the user in the selection of relevant training examples. Concept learning in the system is incremental and hierarchical: global concepts are built upon local concepts as well as low-level features. Similarity measures tuning is used to emphasize relevant features for a given concept. To illustrate the potential of this approach, an implementation of this model has been developed; preliminary results are given in this paper.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3257657",
                    "name": "S. Bissol"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                }
            ]
        },
        {
            "paperId": "88dce6d06b9893e962be17113f50d5b77fd3f95d",
            "title": "Advances in Digital Home Photo Albums",
            "abstract": "In this chapter, we study the needs of digital home photo albums and the different components that are required to provide effective and efficient computer-based tools to match the users\u2019 expectations for such systems. We focus mainly on indexing and retrieval of photographic images using symbolic descriptions of image contents. We describe how symbolic labeling of image regions can be achieved, how the representation of image content is achieved using two different kinds of representations supporting different needs, and how the retrieval is performed on these image descriptions. Other features of digital home photo management are also described, and our proposal is evaluated on a genuine collection of 2,400 home photographs. 200 Mulhem, Lim, Leow, & Kankanhalli Copyright \u00a9 2004, Idea Group Inc. Copying or distributing in print or electronic forms without written permission of Idea Group Inc. is prohibited. INTRODUCTION The last few decades have witnessed a dizzying rate of technological innovation in the areas of computing and communication. While the effects of cheaper and faster computation power manifest explicitly in many places, slightly less obvious are the technological advances in sensor and signal processing technologies. Their impact is being increasingly felt in the form of digitization of all forms of communication and media. These advances have directly led to increased inexpensive communication bandwidth, which in turn has spurred the rapid acceleration of the Internet globally. In terms of consumer electronics devices, we are currently witnessing the mass-scale switchover to digital cameras from the traditional analog cameras. In fact, the year 2002 is expected to be a significant milestone since it will perhaps become the first year when the sales of digital cameras will outstrip those of their analog predecessors. The history of the invention of the camera is quite interesting. Joseph Nicephore Niepce and Louis-Jacques-Mande Daguerre\u2019s invention of photography in 1825 was followed by the landmark contributions of George Eastman\u2019s dry photographic film with the associated camera in 1888 and Edwin Land\u2019s instant Polaroid photography in 1948. Essentially, the camera has democratized the preservation of images and, thus, it has had a tremendous impact on society. In the ancient times, only the kings and nobles could afford to engage artists to paint portraits, depict monuments and glorify conquests. With the invention of the camera, even ordinary people\u2019s lives started getting captured visually through this powerful medium. It basically eliminated the need of a skilled intermediary and simultaneously collapsed the time-period between the intent and production of a visual memory. Thus, the camera has been one of the first technological devices to be utilized on a large scale by people that demand neither the mastery of the technology nor the refinement of artistic skills. Hence, it rapidly became a mass-market consumer device. We are at an interesting technological cusp today. On one hand, the falling price of digital devices is rapidly pushing up the sales of digital cameras. On the other hand, increased global affluence coupled with the growing mobility of people is leading to an ever-greater use of the camera. Consequently, a huge amount of digital images is being generated everyday. We are quite familiar with the traditional paradigm of handling photographs. Analog cameras are used with a film roll that can capture several photos, which are processed at one shot. The output of the rolls used for significant events such as birthdays, weddings, graduation ceremonies and travel are stored in a home photo album. This paradigm of capturing memories strongly resembles the book paradigm and quite easy to use for most people. Though it has some disadvantages in terms of limited use capabilities in terms of making copies or searching by only global album labels, it is a familiar and comfortable approach for most people. Given that we are undergoing a paradigm shift in terms of camera technology, we can respond to this change in two ways. One way of responding to the challenge of managing large numbers of digital photographs is by faithfully mapping the analog photo album paradigm onto the digital arena, replicating both the look and functionality of the traditional approach. An alternative response would be to totally rethink and completely reengineer the way home users create, store, and manage digital home photo albums. Thus, with more and more digital photos being accumulated, home users definitely need effective and efficient tools to organize and access their images. To address this Advances in Digital Home Photo Albums 201 Copyright \u00a9 2004, Idea Group Inc. Copying or distributing in print or electronic forms without written permission of Idea Group Inc. is prohibited. genuine need, a three-year international collaborative project between CNRS, France, School of Computing; the National University of Singapore and Laboratories for Information Technology, Singapore was formed in 2000 to develop the next generation Digital Image/Video Album (DIVA) for home users. The goal of this chapter is to explain the work carried out in this DIVA international project. In particular, we will describe the needs of home users and possible solutions in the domain of management of digital images. At the very outset, the DIVA project has adopted the second approach of having a fresh look at digital home photo albums in order to come up with an appropriate solution without being encumbered by habits and legacies of the past. Having settled on the approach, we came up with some fundamental assumptions related to digital home photo albums: \u2022 A digital home photo album should not engender any digital divide between the ordinary home user and a technologically savvy home user. In particular, the digital home photo album should be intuitively easy to use for most users while offering the subtle flexibilities to the sophisticated user. \u2022 Users take photographs (digital or otherwise) in order to preserve and share memories across space and time. Thus, sharing of home photos is at least as important as archiving the photographs. \u2022 Given that sharing is important, users should be provided with extremely flexible means of searching and locating the appropriate photographs that are to be shared. This implies that the semantic content of the photographs needs to be represented along with the image. \u2022 The user is likely to share his/her photographs with various people of different degrees of acquaintance and varying tastes. Hence, each presentation of shared photographs should be different \u2014 tailored to that particular individual or target group. Therefore, the ability to build custom presentations out of the same set of photographs is absolutely necessary. \u2022 The digital home photo album of a user should adapt itself to the quirks and predilections of the user (instead of vice versa). For example, common content of the images such as the user\u2019s face, name and family members should be learned by the album over a period of time instead of being a memory-less stateless system. Thus, implicit and explicit personalization should be built into the system. Given the above set of fundamental assumptions, we need to develop several technical pieces before we can solve the technological jigsaw puzzle. In particular, these technical considerations stemming from the fundamental assumptions need to be addressed: 1. Image capture and transfer: how should the image (and perhaps the camera parameters such as focal length, flash use, etc.) captured on the digital camera be transferred to the digital home photo album, which could reside on a computing device like a personal computer or possibly an embedded system consumer appliance like a portable image jukebox or perhaps be integrated with the camera itself. 202 Mulhem, Lim, Leow, & Kankanhalli Copyright \u00a9 2004, Idea Group Inc. Copying or distributing in print or electronic forms without written permission of Idea Group Inc. is prohibited. 2. Image coding techniques: for efficient storage of the digital image. 3. Image annotation: how to index the images with information related to the semantic content of the image. In other words, capturing the metadata about the digital photo. 4. Representation of the metadata: which can facilitate flexible searching. 5. Query languages: in order to pose the search constraints which enables efficient searching. 6. User interfaces: which obliterates any digital divide by making the use very natural. 7. Presentation tools: in order to customize the presentations for target audiences. 8. Web interface: in order to use the worldwide web as a global channel for the sharing of images. 9. Personalization: the system should have a means of personalizing explicitly the layout, the metadata and the sharing mechanisms. Moreover, it should strive for implicit personalization based on observed user behavior. Thus, how to manage digital images is a challenging problem. We will now detail some of the efforts towards resolving a few of the above issues in the DIVA project. While we are taking an integrated approach of solving this problem in our project, our focus in this chapter is biased by the overall theme of this book, which basically deals with the content-related aspects. Hence, we will discuss in detail the content-based retrieval aspects while only briefly alluding to the other aspects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "6516914",
                    "name": "Joo-Hwee Lim"
                },
                {
                    "authorId": "1787377",
                    "name": "W. Leow"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                }
            ]
        },
        {
            "paperId": "8e097b35ee164daadcfb5bbfa40dfe324cf0dc60",
            "title": "The outline of an 'intelligent' image retrieval engine",
            "abstract": "The first image retrieval systems hold the advantage of being fully automatic, and thus scalable to large collections of images but are restricted to the representation of low-level aspects (e.g. colors, textures...) without considering the semantic content of images. This obviously compromises interaction, making it difficult for a user to query with precision. The growing need for 'intelligent' systems, i.e. being capable of bridging this semantic gap, leads to new architectures combining multiple characterizations of the image content. This paper presents SIR1, a promising high-level framework featuring semantics, signal color and spatial characterizations. It features a fully-textual query module based on a language manipulating both boolean and quantification operators, therefore making it possible for a user to request elaborate image scenes such as a \"covered(mostly grey) sky\" or \"people in front of a building\".",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239306",
                    "name": "M. Belkhatir"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                }
            ]
        },
        {
            "paperId": "b32567c14e16ed4414b715e2b06bccd0d32c3581",
            "title": "Query by Example for Symbolic Still Image Retrieval",
            "abstract": "RESUME. Cet article decrit et defini l\u2019utilisation de requetes par l\u2019exemple (QBE) dans le cadre de recherche symbolique d\u2019images photographiques. La nouveaute de cette approche consiste en l\u2019utilisation conjointe d\u2019indexation symbolique automatique et d\u2019un formalisme de representation de connaissances pour representer le contenu des images. De plus, le mecanisme d\u2019abstraction perm la recherche d\u2019images par l\u2019exemple et le bouclage de pertinence bases sur la representation symbolique des images, et pas sur leur description signal de bas niveau. Nous montrons sur deux collections d\u2019images d\u2019un total de plus de 1100 photographies que la recherche par l\u2019exemple fournit des resultats comparables a ceux par symboles en terme de mesures de rappel-precision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2585539",
                    "name": "Emmanuel Debanne"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "154010fc68c2be69ae0d59a68df55d196d65519c",
            "title": "Semantic video summarization in compressed domain MPEG video",
            "abstract": "In this paper, we present a semantic summarization algorithm that interfaces with the metadata and that works in compressed domain, in particular MPEG-1 and MPEG-2 videos. In enabling a summarization algorithm through high-level semantic content, we try to address two major problems. First, we present the facility provided in the DVA system that allows the semi-automatic creation of this metadata. Second, we address the main point of this system which is the utilization of this metadata to filter out frames, creating an abstract of a video summary quality survey indicates that the proposed method performs satisfactorily.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41175877",
                    "name": "Jek Charlson So Yu"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "2188ac79779deaff852ed372c59cdf2aa918b7ef",
            "title": "Event-based home photo retrieval",
            "abstract": "With rapid advances in sensor, storage, processor, and communication technologies, consumers can now afford to create, store, process, and share large digital photo collections. With more and more digital photos accumulated, consumers need effective and efficient tools to organize and access photos in a semantically meaningful way without too much manual annotation effort. From user studies, we confirm that users prefer to organize and access photos along semantic axes such as event, people, time, and place. In this paper, we propose a computational learning framework to construct event models from sample photos with event labels given by a user and to compute relevance measures of unlabeled photos to the event models. We demonstrate event-based retrieval on 2400 genuine home photos using our proposed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6516914",
                    "name": "Joo-Hwee Lim"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2056267488",
                    "name": "Q. Tian"
                }
            ]
        },
        {
            "paperId": "35db7ce3397f712e51e9290ce0bd3622a88cd59f",
            "title": "Home Photo Content Modeling for Personalized Event-Based Retrieval",
            "abstract": "Rapid advances in sensor, storage, processor, and communication technologies let consumers store large digital photo collections. Consumers need effective tools to organize and access photos in a semantically meaningful way. We address the semantic gap between feature-based indexes computed automatically and human query and retrieval preferences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240464453",
                    "name": "J. Lim"
                },
                {
                    "authorId": "2256567912",
                    "name": "Qi Tian"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "3bf05e6a3a7b837f372bc877a0144c6ca97a9bf9",
            "title": "Content-based summarization for personal image library",
            "abstract": "With the accumulation of consumer's personal image library, the problem of managing, browsing, querying and presenting photos effectively and efficiently would become critical. We propose a framework for automatic organization of personal image libraries based on analysis of image creation time stamps and image contents to facilitate browsing and summarization of images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6516914",
                    "name": "Joo-Hwee Lim"
                },
                {
                    "authorId": "46276037",
                    "name": "Jun Yu Li"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2056267488",
                    "name": "Q. Tian"
                }
            ]
        },
        {
            "paperId": "74e912d1b13c11efec752fc0cc2f9444bda09ce6",
            "title": "Pivot Vector Space Approach for Audio-Video Mixing",
            "abstract": "An audio-mixing artist usually adds the musical accompaniment to video. Employing such artists is expensive and not feasible for a home video presentation. Our automatic audio-video mixing technique is suited for home videos. It uses a pivot vector space mapping method that matches video shots with music segments based on aesthetic cinematographic heuristics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                },
                {
                    "authorId": "32876724",
                    "name": "J. Yi"
                },
                {
                    "authorId": "2054268540",
                    "name": "Hadi Hassan"
                }
            ]
        },
        {
            "paperId": "754cee194a17032604a941f4c05ce20c5a29b0b0",
            "title": "Semantic Video Annotation and Vague Query",
            "abstract": "The Digital Video Album (DVA) system described here integrates various cooperating subsystems to index and query video documents according to their semantic content and other metadata. A simple structured model is proposed to represent the video content. This model is compatible with XML Schemas and supports typed attributes and composition relationships. The architecture of DVA is described, and the workflows related to the semi-automatic indexing of videos are presented. The querying processing on video metadata is based on an extension of Boolean search, in a way to avoid empty answers and to rank query results. The query interface is also described.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116682391",
                    "name": "Qiuying Zhang"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "8b0be06c2ce239f2cae7b6d898b878db3c34e87e",
            "title": "Photograph indexing and retrieval using star-graphs",
            "abstract": "We present in this paper a relational approach for indexing and retrieving photographs from a collection. Instead of using simple keywords as an indexing language, we propose to use star-graphs as document descriptors. A star-graph is a conceptual graph that contains a single relation, with some concepts linked to it. They are elementary pieces of information describing combinations of concepts. We use star-graphs as descriptors - or index terms - for image content representation. This allows for relational indexing and expression of complex user needs, in comparison to classical text retrieval, where simple keywords are generally used as document descriptors. We present a document representation model, a weighting scheme for star-graphs inspired by the tf.idf used in text retrieval. We have applied our model to image retrieval, and show the system evaluation results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34990008",
                    "name": "J. Martinet"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1698205",
                    "name": "I. Ounis"
                }
            ]
        },
        {
            "paperId": "9a393a4e4ee17b26c347d8d9db0c3b59d9a10c0e",
            "title": "Dynamic Learning of Indexing Concepts for Home Image Retrieval",
            "abstract": "This paper presents a component of a content based image retrieval system dedicated to let a user define the indexing terms used later during retrieval. A user inputs a indexing term name, image examples and counter-examples of the term,and the system learns a model of the concept as well as a similarity measure for this term. The similarity measure is based on weights reflecting the importance of each low-level feature extracted from the images. The system computes these weights using a genetic algorithm. Rating a particular similarity measure is done by clustering the examples and counter-examples using these weights and computing the quality of the obtained clusters. Experiments are conducted and results are presented on a set of 600 images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3257657",
                    "name": "S. Bissol"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                }
            ]
        },
        {
            "paperId": "b0d367cbc35db617f95c111180ab840ca9dd587a",
            "title": "Using Speech Annotation for Home Digital Image Indexing and Retrieval",
            "abstract": "We present in this paper a system for image indexing and retrieval through speech annotation made directly on a digital camera. The annotations are based on a pre-defined structured syntax and transcribed by an automatic speech recognition engine. N-best lists are incorporated in the index generation and query expansion process to introduce probabilistic model and compensate recognition errors. We also apply a practical noise cancellation algorithm to enhance the speech signal collected directly through the built-in microphone on a digital camera. Experiments show that by utilizing automatic query expansion and noise cancellation together, the overall system performance improve significantly to be comparable to the lab environment collected data. Key-Words: Speech Recognition, Speech Signal Processing, Spoken Document Retrieval, Image Retrieval",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Jiayi Chen"
                },
                {
                    "authorId": "1749078",
                    "name": "T. Tan"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "d0a1199e4d8f50555ec67f073e9575117b5fc425",
            "title": "A hierarchical framework for face tracking using state vector fusion for compressed video",
            "abstract": "Faces usually are the most interesting objects in certain categories of video, like home videos and news clips. A novel sensor fusion based face tracking system is presented that tracks faces in compressed video, and aids automatic video indexing. Tracking is done by fusing the measurements from three independent sensors - motion and colour based trackers (Achanta, R. et al., IEEE Int. Conf. on Multimedia and Expo, 2002) and a face detector (Wang, J. et al., Proc. Int. Workshop on Advanced Image Technology, 2002) using a novel hierarchical framework based on Kalman filter state vector fusion. The tracking results show that the fused results are better than those of any individual sensors or their mean.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152809850",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "47375534",
                    "name": "Radhakrishna S. V. Achanta"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "fcd43a4a4fdd976ff1cad9373db4d2c30bdedc40",
            "title": "An Improved Method for Image Retrieval Using Speech Annotation",
            "abstract": "In this paper, we present a system for the image indexing and retrieval using speech annotations based on a pre-defined structured syntax. In addition to the introduction of N-best lists for index generation, a query expansion technique is explored to enhance the query terms and to improve retrieval effectiveness. By adding the most probable substitutions for the query terms, more relevant images are distinguished from the data collection. This approach is particularly helpful to deal with those less frequently used words, including out-of-vocabulary (OOV) words, which are very common for names of people and places. Experiments on a collection of 1,200 photos show that the retrieval effectiveness is increased considerably for segment of individual domain on People, Location and Event. With this method, the average value of precision versus recall over a combination of segments has improved significantly, from 50% to 72.4%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Jiayi Chen"
                },
                {
                    "authorId": "1749078",
                    "name": "T. Tan"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                }
            ]
        },
        {
            "paperId": "5f6fc04aead9ea2a75dbbb64771a48e8cefa6ac3",
            "title": "Recovering Camera Motion and Mobile Objects in Video Documents",
            "abstract": "This chapter presents a set of methods related to the recovery of camera motion parameters and to the segmentation of mobile objects in video documents for content indexing. This includes methods for the segmentation of video documents into continuous shots, methods for motion analysis, methods for extracting reliable trajectories within shots, and two different methods for the recovery of the camera motion (relatively to the main background), the first one for a camera maintained at a fixed location with rotational and zoom degrees of freedom, and the second one for a camera of arbitrary motion but assuming a fixed focal length. The first camera motion recovery method is based on the search of an optimal projective transform between consecutive images combined with an iterative background / mobile objects segmentation process. The second one is based on a paraperspective factorization method for shape and motion recovery. The presented methods are illustrated in the context of a video indexing system developed at CLIPS-IMAG into which they are integrated. The system also attempts to classify shots or sub-segments of shots into one of the following categories of ''no motion'', ''non mobile camera motion'', ''mobile camera motion'' or ''other type of motion''. Further sub-categorization can be done for each recovered type. Sample results are presented using sequences extracted from video documents of the ISIS GDR-PRC GT10/AIM test corpus.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "72023931",
                    "name": "D. Paulin"
                },
                {
                    "authorId": "2111858728",
                    "name": "Dinesh Kumar"
                },
                {
                    "authorId": "144082649",
                    "name": "Raghav Bhaskar"
                },
                {
                    "authorId": "2448626",
                    "name": "Arvind Bhusnurmath"
                }
            ]
        },
        {
            "paperId": "7196551b46cc7c96ebedb53cc53f57ae502b222d",
            "title": "SmartAlbum-towards unification of approaches for image retrieval",
            "abstract": "We present an application (called SmartAlbum) for photo indexing and retrieval that unifies two different image indexing approaches. The system uses two modalities to extract information about a digital photograph; i.e. content-based and speech annotation for image description. The result is a powerful image retrieval tool that has capabilities beyond what current single-mode retrieval systems can offer. We show on a corpus of 1200 images the interest of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1749078",
                    "name": "T. Tan"
                },
                {
                    "authorId": null,
                    "name": "Jiayi Chen"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "bc02ef268f54755278a9abdfa9c1aad667869c56",
            "title": "Symbolic photograph content-based retrieval",
            "abstract": "Photograph retrieval systems face the difficulty to deal with the different ways to apprehend the content of images. We consider and demonstrate here the use of multiple index representations of photographs to achieve effective retrieval. The use of multiple indexes allows integration of the complementary strengths of different indexing and retrieval models. The proposed representation supports multiple labels for regions and attributes, and handles inferences and relationships. We define links between indexing levels and the related query modes. The experiment conducted on 2400 home photographs shows the behavior of the multiple indexing levels during retrieval.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "6516914",
                    "name": "Joo-Hwee Lim"
                }
            ]
        },
        {
            "paperId": "d50ba8415339e5f3d93bd4d5815dbc2039963a28",
            "title": "SmartAlbum: a multi-modal photo annotation system",
            "abstract": "This demonstration presents a novel application (called SmartAlbum) for photo indexing and retrieval that unifies two different image indexing approaches. The system uses two modalities to extract information about a digital photograph; i.e. content-based and speech annotation for image description. The result is a powerful image retrieval tool that has capabilities beyond what current single-mode retrieval systems can offer. We show on a corpus of 1200 images the interest of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1749078",
                    "name": "T. Tan"
                },
                {
                    "authorId": null,
                    "name": "Jiayi Chen"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1744045",
                    "name": "M. Kankanhalli"
                }
            ]
        },
        {
            "paperId": "56c0ae79fda621f2d1fa1f714b80af0f278bcb88",
            "title": "Fuzzy Conceptual Graphs for Matching Images of Natural Scenes",
            "abstract": "Conceptual graphs are very useful for representing structured knowledge. However, existing formulations of fuzzy conceptual graphs are not suitable for matching images of natural scenes. This paper presents a new variation of fuzzy conceptual graphs that is more suited to image matching. This variant differentiates between a model graph that describes a known scene and an image graph which describes an input image. A new measurement is defined to measure how well a model graph matches an image graph. A fuzzy graph matching algorithm is developed based on error-tolerant subgraph isomorphism. Test results show that the matching algorithm gives very good results for matching images to predefined scene models.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1787377",
                    "name": "W. Leow"
                },
                {
                    "authorId": "2110391587",
                    "name": "Yoong Keok Lee"
                }
            ]
        },
        {
            "paperId": "9d97f1d3f126ebf081ff5626318c55d95f8e5e25",
            "title": "Image query system using object probes",
            "abstract": "This paper presents a novel image-based indexing scheme called object probes. Object probes make use of both physical features and a manually formulated decision tree to classify objects in the scene. A conceptual graph is used to represent the association of the labels found in each labeled image. We develop a query formalism that translates the query elements into a graph structure. The query process can be seen as matching the query graph with those sub-graphs found in the database of images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1749078",
                    "name": "T. Tan"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "5a2f92cdde5a192184c251d218a741f04e0d08fa",
            "title": "A Comparison of XML and SMIL for on the fly generation of Multimedia Documents from Databases",
            "abstract": "This paper describes the problem of generation into the future Web document standards of multimedia documents stored in databases. In our context, multimedia presentations are both spatially and temporally constrained according to template descriptions. The templates provide also access to database data. The standards under consideration are XML and SMIL. We explain how the presentations are generated from templates. The conclusion is that, as expected, SMIL is better suited for our purpose, despite its lack of integration of database access methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144651881",
                    "name": "H. Martin"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "be04a2c26a5a0190eaae20bd8a8c2b917048397a",
            "title": "Updating Labeling of Photographic Segmented Regions using Knowledge Representation Formalism and Dempster-Shafer Theory",
            "abstract": "This paper discusses the inclusion of explicit symbolic knowledge during the labeling process of segmented images. We intend to update the initial labeling of photographs segmented regions obtained by an existing labeling process. We use the Dempster-Schafer theory of evidence in conjunction with a knowledge representation formalism, namely the Conceptual Graphs. The use of conceptual graphs allows a strong control of the features used to define relevant frames of discernment. The update process uses a set spatial relationships that characterize the image segmented regions, and takes into account learned samples that are not based on segmented regions but on user manual annotations. On a set of more than 350 objects recognized, a significant increase of well-labeled segmented regions is achieved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "3248744",
                    "name": "Dezhong Hong"
                },
                {
                    "authorId": "2109178668",
                    "name": "Jian-Kang Wu"
                }
            ]
        },
        {
            "paperId": "fd26c598fe90bad185cb9aac0a61cbfee0395d70",
            "title": "Labeling update of segmented images using conceptual graphs and Dempster-Shafer theory of evidence",
            "abstract": "The extraction of objects present in photographs is a major problem to tackle when considering photograph retrieval. Such objects (or people) have to be detected in a way to allow retrieval based on concepts and not on physical characteristics like colors or textures. To achieve a reasonable detection rate, in-context image analysis has to be used. We propose to use conceptual graphs (a knowledge representation formalism that allow fast processing) with Dempster-Shafer theory of evidence to update original labeling coming from a segmentation that labels image regions out of context. We explain the whole process and the results obtained on real home photos. The encouraging results obtained show the potential of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "3248744",
                    "name": "Dezhong Hong"
                },
                {
                    "authorId": "2109178668",
                    "name": "Jian-Kang Wu"
                }
            ]
        },
        {
            "paperId": "1d4e6d4a6da877e381095c0369569b7259b92eb9",
            "title": "Two Systems for Temporal Video Segmentation",
            "abstract": "This paper presents two different temporal video segmentation systems and their performance evaluation using a standard test corpus. The first system uses two separate detection subsystems respectively based on color histogram comparison and on rough edge tracking, and then fuses their results. The second system uses direct image comparison after motion compensation. Both systems are described and evaluated using the ''AIM'' corpus and reference segmentation. Though very different in principle, both systems perform similarly well on the test database. Combining the systems' output even in very simple ways yields a significant performance improvement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "6215399039993718b59ea2926750c42755f1dc97",
            "title": "A Two-time Model for Video Content Representation and Retrieval",
            "abstract": "This paper presents a temporal model of video for video retrieval systems. Time is the dimension that plays an essential role in the perception of video document content. The modelling of the different temporal characteristics of the video content is however a complicated problem. Our approach to this problem has consisted of distinguishing two different dimensions of time for video documents: video time and story time. The semantic structure proposed based on these two temporal dimensions, provides the user with a new modality of content description which is close to the semantic perception of the video documents. We present here how using the conceptual graphs formalism, the details of the temporal model can be represented in query, document and matching function of the retrieval process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34906533",
                    "name": "Nastaran Fatemi"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "9fb467200cb9e630d4cc9794963af8c9e8ad04b1",
            "title": "Towards a fast precision-oriented image retrieval system",
            "abstract": "Expressive indexing languages are called for to obtain faithful representations of multimedia documents. They become a decisive factor to alleviate the noise problem, which is now often encountered with commercial search engines. In this case, noise consists in a great number of non-relevant answers to user\u2019s queries, which compromises interrogation efficiency. The use of complex formalisms to handle the problem is not straight-forward, as one of their general characteristics is to have high, sometimes unacceptable computational costs. The RELIEF image retrieval system [OP98] is the result of research conducted for several years at the IMAG research institute of the University of Grenoble. It is proposed as a solution to the challenge of using powerful indexing languages to reduce noise and conversely increase precision, while limiting execution times to acceptable values. RELIEF takes benefit from the richness of the conceptual graphs formalism [Sow841 and the speed provided by classical information retrieval (IR) techniques. The system is an operational implementation of a logical IR model applied to the conceptual graphs formalism. A sound algebraic approach is proposed that permits to organize the indexes, which am conceptual graphs, into an inverted file-based structure that is then used for faster retrieval [OP98]. The system is integrated on top of the 02 object-oriented DBMS, which provides a complete programming environment, including the fourth generation language OsC, the OQL query language that conforms to the ODMG standard, and the OzLook graphical interface tool. The architecture of our system is shown in figure 1. It supports image handling, by an image manager that makes use of basic 0s classes. The ROGER platform [Oun98] handles conceptual graphs; it is programmed in OsC and an 02Look interface allows for off-line insertion, change, consistency tests and visualization of the indexes. Retrieval can be performed from a Web browser, through our interrogation interface, which uses the OsWeb tool to access the database. To achieve portability and to manage the presentation, an additional JAVA-based layer is provided. The availability of recent advances in the object-oriented database domain and the support of database connections via Web browsers are the main reasons for the choice of 0s OG DBMS. RELIEF is proposed as a solution to the integration of object oriented modeling and Web technologies in the IR domain, based on indexing and interrogation functionalities. l Indexing facilities Image indexing is performed with a computer-assisted pmcess, according to a particular image indexing model [Mec95]. A basic part of the indexing consists in the introduction and",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2941979",
                    "name": "Y. Chiaramella"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1741477",
                    "name": "M. Mechkour"
                },
                {
                    "authorId": "1698205",
                    "name": "I. Ounis"
                },
                {
                    "authorId": "1724629",
                    "name": "Marius Pasca"
                }
            ]
        },
        {
            "paperId": "a77b418ed32cdbdd85d17a164f843a7b2325ca0b",
            "title": "PRIME-GC. A medical information retrieval prototype on the Web",
            "abstract": "The authors describe a prototype, PRIME, of a multimedia medical information retrieval system. The documents managed by PRIME are patient records, which are composed of administrative data, textual reports, and magnetic resonance images. PRIME is developed on top of the object oriented DBMS O/sub 2/ and its interface can be any WWW navigator (Netscape, InternetExplorer, etc.). The retrieval engine of PRIME is based on Sowa's (1984, 1991) conceptual graph formalism structures and operations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1741477",
                    "name": "M. Mechkour"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2764793",
                    "name": "F. Fourel"
                },
                {
                    "authorId": "1736012",
                    "name": "C. Berrut"
                }
            ]
        },
        {
            "paperId": "72d82f9cf39c7304aee3108fadb1cb7cf781b8a0",
            "title": "Modelling multimedia structured documents: a retrieval oriented approach",
            "abstract": "The authors describe the modelling of multimedia structured documents according to the potential retrieval methods. They consider that the works already done on such documents do not focus on this point enough. So, their model is based on views that reflect the potential ways of \"seeing\" multimedia documents. The semantic content of a document is one way of seeing documents. So, another problem is the way to determine this semantic content by using semantic channels between composing and composed documents. They present an application of their work in the RIME medical context dealing with texts and still images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2764793",
                    "name": "F. Fourel"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                }
            ]
        },
        {
            "paperId": "7d957da02b05e028e6ec3a10f9f1e68797f68c64",
            "title": "Interactive information retrieval systems: from user centered interface design to software design",
            "abstract": "This article is concerned with the design and implementation of Information Retrieval Systems (IRS). We show how theories and models from the domain of Human Computer Interaction (HCI) can be applied to the design of IRS. We first study the user\u2019s tasks by modelling the mental activities of the user while accomplishing a task. Adopting a system perspective, we consider the processing tasks of an IRS and organize them in a design space. We then build upon the design space to consider the implications of such data processing and levels of abstraction on software design. Finally we present PAC-Amodeus, a software architecture model and illustrate the applicability of the approach with the implementation of an IRS: the TIAPRI system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1807947",
                    "name": "L. Nigay"
                }
            ]
        },
        {
            "paperId": "a0797f27d52c987161301b5e5b2706107fca2832",
            "title": "The RIME Prototype",
            "abstract": "In this paper we give a technical description of the PRIME system prototype. PRIME allows us to provide an operational side to the theoretical work we have done in the \"Modelling and Multimedia Information Retrieval\" (MRIM) team. PRIME is designed to provide a generic way to express the storing, manipulating and retrieval of multimedia data. These tasks are separated into two parts, namely the strict database tasks and the information retrieval tasks. This paper focus on this generic part, and we address more specifically the problem of managing and retrieving images. We describe the implementation of a medical application managing Magnetic Resonance Images based on the generic core.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "1736012",
                    "name": "C. Berrut"
                }
            ]
        },
        {
            "paperId": "5d2927d24321073ef32c9d9ccfdfb8cf1edf45ff",
            "title": "A way to compare objects",
            "abstract": "This paper presents outlines to express the matchmg between complex objects, using works done in the Information Retrieval field. The basic idea is to help an application programmer to describe theorcticatly the matching using modal logic, and then to express the operational matching. We describe here these two parts using a medical information retrieval example. We are implementing our work on the 02 system [1].",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "2159603",
                    "name": "Marie-France Bruandet"
                }
            ]
        }
    ]
}