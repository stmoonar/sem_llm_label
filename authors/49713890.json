{
    "authorId": "49713890",
    "papers": [
        {
            "paperId": "b46f0ec1fb045aaf501a4252d4f80575f3cd4f08",
            "title": "Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia",
            "abstract": "To explain social phenomena and identify systematic biases, much research in computational social science focuses on comparative text analyses. These studies often rely on coarse corpus-level statistics or local word-level analyses, mainly in English. We introduce the InfoGap method -- an efficient and reliable approach to locating information gaps and inconsistencies in articles at the fact level, across languages. We evaluate InfoGap by analyzing LGBT people's portrayals, across 2.7K biography pages on English, Russian, and French Wikipedias. We find large discrepancies in factual coverage across the languages. Moreover, our analysis reveals that biographical facts carrying negative connotations are more likely to be highlighted in Russian Wikipedia. Crucially, InfoGap both facilitates large scale analyses, and pinpoints local document- and fact-level information gaps, laying a new foundation for targeted and nuanced comparative language analysis at scale.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266466672",
                    "name": "Farhan Samir"
                },
                {
                    "authorId": "50487261",
                    "name": "Chan Young Park"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "3103343",
                    "name": "Vered Shwartz"
                },
                {
                    "authorId": "2324782612",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee",
            "title": "Riveter: Measuring Power and Social Dynamics Between Entities",
            "abstract": "Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34199564",
                    "name": "Maria Antoniak"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "2219642161",
                    "name": "Jimin Mun"
                },
                {
                    "authorId": "51038621",
                    "name": "Melanie Walsh"
                },
                {
                    "authorId": "3458698",
                    "name": "Lauren F. Klein"
                },
                {
                    "authorId": "2729164",
                    "name": "Maarten Sap"
                }
            ]
        },
        {
            "paperId": "346e4f35a5a81ef893792133ec1fec18f23c1768",
            "title": "Examining risks of racial biases in NLP tools for child protective services",
            "abstract": "Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in coreference resolution models, and little evidence of exacerbated racial bias in risk prediction. While there is existing pronounced criticism of risk prediction, our results expose previously undocumented risks of racial bias in realistic information extraction systems, highlighting potential concerns in deploying them, even though they may appear more benign. Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "48577290",
                    "name": "Amanda Coston"
                },
                {
                    "authorId": "47404598",
                    "name": "Nupoor Gandhi"
                },
                {
                    "authorId": "2082393",
                    "name": "A. Chouldechova"
                },
                {
                    "authorId": "1398859796",
                    "name": "Emily Putnam-Hornstein"
                },
                {
                    "authorId": "2082303978",
                    "name": "David Steier"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "38c2e4e54a50ea5027c7a06ab325c22ece7b6c40",
            "title": "Developing Speech Processing Pipelines for Police Accountability",
            "abstract": "Police body-worn cameras have the potential to improve accountability and transparency in policing. Yet in practice, they result in millions of hours of footage that is never reviewed. We investigate the potential of large pre-trained speech models for facilitating reviews, focusing on ASR and officer speech detection in footage from traffic stops. Our proposed pipeline includes training data alignment and filtering, fine-tuning with resource constraints, and combining officer speech detection with ASR for a fully automated approach. We find that (1) fine-tuning strongly improves ASR performance on officer speech (WER=12-13%), (2) ASR on officer speech is much more accurate than on community member speech (WER=43.55-49.07%), (3) domain-specific tasks like officer speech detection and diarization remain challenging. Our work offers practical applications for reviewing body camera footage and general guidance for adapting pre-trained speech models to noisy multi-speaker domains.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "50882405",
                    "name": "Prateek Verma"
                },
                {
                    "authorId": "79396737",
                    "name": "Nay San"
                },
                {
                    "authorId": "3165935",
                    "name": "J. Eberhardt"
                },
                {
                    "authorId": "1746807",
                    "name": "Dan Jurafsky"
                }
            ]
        },
        {
            "paperId": "00e206fe648173483f85a95921429ec4989f53f0",
            "title": "Annotating Mentions Alone Enables Efficient Domain Adaptation for Coreference Resolution",
            "abstract": "Although recent neural models for coreference resolution have led to substantial improvements on benchmark datasets, it remains a challenge to successfully transfer these models to new target domains containing many out-of-vocabulary spans and requiring differing annotation schemes. Typical approaches involve continued training on annotated target-domain data, but obtaining annotations is costly and time-consuming. In this work, we show that adapting mention detection is the key component to successful domain adaptation of coreference models, rather than antecedent linking. We also show annotating mentions alone is nearly twice as fast as annotating full coreference chains. Based on these insights, we propose a method for efficiently adapting coreference models, which includes a high-precision mention detection objective and requires only mention annotations in the target domain. Extensive evaluation across three English coreference datasets: CoNLL-2012 (news/conversation), i2b2/VA (medical notes), and child welfare notes, reveals that our approach facilitates annotation-efficient transfer and results in a 7-14% improvement in average F1 without increasing annotator time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47404598",
                    "name": "Nupoor Gandhi"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "2268272",
                    "name": "Emma Strubell"
                }
            ]
        },
        {
            "paperId": "215a6f2b4c206975f59d81c0c9f45cfe935a85e9",
            "title": "VoynaSlov: A Data Set of Russian Social Media Activity during the 2022 Ukraine-Russia War",
            "abstract": "In this report, we describe a new data set called VoynaSlov which contains 21M+ Russian-language social media activities (i.e. tweets, posts, comments) made by Russian media outlets and by the general public during the time of war between Ukraine and Russia. We scraped the data from two major platforms that are widely used in Russia: Twitter and VKontakte (VK), a Russian social media platform based in Saint Petersburg commonly referred to as \u201cRussian Facebook\u201d. We provide descriptions of our data collection process and data statistics that compare state-a\ufb03liated and independent Russian media, and also the two platforms, VK and Twitter. The main di\ufb00erences that distinguish our data from previously released data related to the ongoing war are its focus on Russian media and consideration of state-a\ufb03liation as well as the inclusion of data from VK , which is more suitable than Twitter for understanding Russian public sentiment considering its wide use within Russia. We hope our data set can facilitate future research on information warfare and ultimately enable the reduction and prevention of disinformation and opinion manipulation campaigns. The data set is available at https://github.com/chan0park/VoynaSlov and will be regularly updated as we continuously collect more data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50487261",
                    "name": "Chan Young Park"
                },
                {
                    "authorId": "32163938",
                    "name": "Julia Mendelsohn"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "145317727",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "43f09be116b87046334d395a71919ab423b204a1",
            "title": "Mention Annotations Alone Enable Efficient Domain Adaptation for Coreference Resolution",
            "abstract": "Although, recent advances in neural network models for coreference resolution have led to substantial improvements on benchmark datasets, it remains a challenge to successfully transfer those models to new target domains containing many out-of-vocabulary spans and requiring differing annotation schemes. Typical approaches for domain adaptation involve continued training on coreference annotations in the target domain, but obtaining those annotations is costly and time-consuming. In this work, we show that adapting mention detection is the key component to successful domain adaptation of coreference models, rather than antecedent linking. Through timed annotation experiments, we also show annotating mentions alone is nearly twice as fast as annotating full coreference chains. Based on these insights, we propose a method for effectively adapting coreference models that requires only mention annotations in the target domain. We use an auxiliary mention detection objective trained with mention examples in the target domain resulting in higher mention precision. We demonstrate that our approach facilitates sampleand time-efficient transfer to new annotation schemes and lexicons in extensive evaluation across three English coreference datasets: CoNLL-2012 (news/conversation), i2b2/VA (medical case notes), and a dataset of child welfare case notes. We show that annotating mentions results in 7-14% improvement in average F1 over annotating coreference over an equivalent amount of time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47404598",
                    "name": "Nupoor Gandhi"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "2268272",
                    "name": "Emma Strubell"
                }
            ]
        },
        {
            "paperId": "b616154578751e156b21561e1a5d5ed833a3506f",
            "title": "Challenges and Opportunities in Information Manipulation Detection: An Examination of Wartime Russian Media",
            "abstract": "NLP research on public opinion manipulation campaigns has primarily focused on detecting overt strategies such as fake news and disinformation. However, information manipulation in the ongoing Russia-Ukraine war exemplifies how governments and media also employ more nuanced strategies. We release a new dataset, VoynaSlov, containing 38M+ posts from Russian media outlets on Twitter and VKontakte, as well as public activity and responses, immediately preceding and during the 2022 Russia-Ukraine war. We apply standard and recently-developed NLP models on VoynaSlov to examine agenda setting, framing, and priming, several strategies underlying information manipulation, and reveal variation across media outlet control, social media platform, and time. Our examination of these media effects and extensive discussion of current approaches' limitations encourage further development of NLP models for understanding information manipulation in emerging crises, as well as other real-world and interdisciplinary tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50487261",
                    "name": "Chan Young Park"
                },
                {
                    "authorId": "32163938",
                    "name": "Julia Mendelsohn"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "e4d0ec7f52c054d171ef8d4ec4a389e0757c6ea3",
            "title": "Gendered Mental Health Stigma in Masked Language Models",
            "abstract": "Mental health stigma prevents many individuals from receiving the appropriate care, and social psychology studies have shown that mental health tends to be overlooked in men. In this work, we investigate gendered mental health stigma in masked language models. In doing so, we operationalize mental health stigma by developing a framework grounded in psychology research: we use clinical psychology literature to curate prompts, then evaluate the models\u2019 propensity to generate gendered words. We find that masked language models capture societal stigma about gender in mental health: models are consistently more likely to predict female subjects than male in sentences about having a mental health condition (32% vs. 19%), and this disparity is exacerbated for sentences that indicate treatment-seeking behavior. Furthermore, we find that different models capture dimensions of stigma differently for men and women, associating stereotypes like anger, blame, and pity more with women with mental health conditions than with men. In showing the complex nuances of models\u2019 gendered mental health stigma, we demonstrate that context and overlapping dimensions of identity are important considerations when assessing computational models\u2019 social biases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2004896071",
                    "name": "Inna Wanyin Lin"
                },
                {
                    "authorId": "79336318",
                    "name": "Lucille Njoo"
                },
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "122990697",
                    "name": "Ashish Sharma"
                },
                {
                    "authorId": "1801464280",
                    "name": "K. Reinecke"
                },
                {
                    "authorId": "1745524",
                    "name": "Tim Althoff"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "353c88c231ce156d604e074af276422422fc73f7",
            "title": "A Survey of Race, Racism, and Anti-Racism in NLP",
            "abstract": "Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed single-dimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49713890",
                    "name": "Anjalie Field"
                },
                {
                    "authorId": "3422038",
                    "name": "Su Lin Blodgett"
                },
                {
                    "authorId": "2138053020",
                    "name": "Zeerak Talat"
                },
                {
                    "authorId": "145317727",
                    "name": "Yulia Tsvetkov"
                }
            ]
        }
    ]
}