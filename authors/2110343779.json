{
    "authorId": "2110343779",
    "papers": [
        {
            "paperId": "13df472c3fe81bf1b615238fbd7884c8b45d8d1c",
            "title": "Large Language Models for Time Series: A Survey",
            "abstract": "Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs' original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) aligning techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey offers a comprehensive overview of the existing multimodal time series and text datasets in diverse domains, and discusses the challenges and future opportunities of this emerging field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "3adbca134ac20e69d7215537c703db9faf483b35",
            "title": "Towards Diverse and Coherent Augmentation for Time-Series Forecasting",
            "abstract": "Time-series data augmentation mitigates the issue of insufficient training data for deep learning models. Yet, existing augmentation methods are mainly designed for classification, where class labels can be preserved even if augmentation alters the temporal dynamics. We note that augmentation designed for forecasting requires diversity as well as coherence with the original temporal dynamics. As time-series data generated by real-life physical processes exhibit characteristics in both the time and frequency domains, we propose to combine Spectral and Time Augmentation (STAug) for generating more diverse and coherent samples. Specifically, in the frequency domain, we use the Empirical Mode Decomposition to decompose a time series and reassemble the subcomponents with random weights. This way, we generate diverse samples while being coherent with the original temporal relationships as they contain the same set of base components. In the time domain, we adapt a mix-up strategy that generates diverse as well as linearly in-between coherent samples. Experiments on five real-world time-series datasets demonstrate that STAug outperforms the base models without data augmentation as well as state-of-the-art augmentation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "622661d68c40e2e0da6d2639c53f0640b3c01cf8",
            "title": "Targeted collapse regularized autoencoder for anomaly detection: black hole at the center",
            "abstract": "Autoencoders have been extensively used in the development of recent anomaly detection techniques. The premise of their application is based on the notion that after training the autoencoder on normal training data, anomalous inputs will exhibit a significant reconstruction error. Consequently, this enables a clear differentiation between normal and anomalous samples. In practice, however, it is observed that autoencoders can generalize beyond the normal class and achieve a small reconstruction error on some of the anomalous samples. To improve the performance, various techniques propose additional components and more sophisticated training procedures. In this work, we propose a remarkably straightforward alternative: instead of adding neural network components, involved computations, and cumbersome training, we complement the reconstruction loss with a computationally light term that regulates the norm of representations in the latent space. The simplicity of our approach minimizes the requirement for hyperparameter tuning and customization for new applications which, paired with its permissive data modality constraint, enhances the potential for successful adoption across a broad range of applications. We test the method on various visual and tabular benchmarks and demonstrate that the technique matches and frequently outperforms more complex alternatives. We further demonstrate that implementing this idea in the context of state-of-the-art methods can further improve their performance. We also provide a theoretical analysis and numerical simulations that help demonstrate the underlying process that unfolds during training and how it helps with anomaly detection. This mitigates the black-box nature of autoencoder-based anomaly detection algorithms and offers an avenue for further investigation of advantages, fail cases, and potential new directions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2074484496",
                    "name": "A. Ghafourian"
                },
                {
                    "authorId": "83087301",
                    "name": "Huanyi Shui"
                },
                {
                    "authorId": "2435331",
                    "name": "D. Upadhyay"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "1760459",
                    "name": "Dimitar Filev"
                },
                {
                    "authorId": "31292611",
                    "name": "I. S. Bozchalooi"
                }
            ]
        },
        {
            "paperId": "681f05c1952ce3e1dc48a4ceb230a6033092be68",
            "title": "Unleashing the Power of Shared Label Structures for Human Activity Recognition",
            "abstract": "Current human activity recognition (HAR) techniques regard activity labels as integer class IDs without explicitly modeling the semantics of class labels. We observe that different activity names often have shared structures. For example, \"open door\" and \"open fridge\" both have \"open\" as the action; \"kicking soccer ball\" and \"playing tennis ball\" both have \"ball\" as the object. Such shared structures in label names can be translated to the similarity in sensory data and modeling common structures would help uncover knowledge across different activities, especially for activities with limited samples. In this paper, we propose SHARE, a HAR framework that takes into account shared structures of label names for different activities. To exploit the shared structures, SHARE comprises an encoder for extracting features from input sensory time series and a decoder for generating label names as a token sequence. We also propose three label augmentation techniques to help the model more effectively capture semantic structures across activities, including a basic token-level augmentation, and two enhanced embedding-level and sequence-level augmentations utilizing the capabilities of pre-trained models. SHARE outperforms state-of-the-art HAR models in extensive experiments on seven HAR benchmark datasets. We also evaluate in few-shot learning and label imbalance settings and observe even more significant performance gap.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "70e5e9bd353d1b1e54b4eebd3a67b58026a13dff",
            "title": "PrimeNet: Pre-training for Irregular Multivariate Time Series",
            "abstract": "Real-world applications often involve irregular time series, for which the time intervals between successive observations are non-uniform. Irregularity across multiple features in a multi-variate time series further results in a different subset of features at any given time (i.e., asynchronicity). Existing pre-training schemes for time-series, however, often assume regularity of time series and make no special treatment of irregularity. We argue that such irregularity offers insight about domain property of the data\u2014for example, frequency of hospital visits may signal patient health condition\u2014that can guide representation learning. In this work, we propose PrimeNet to learn a self-supervised representation for irregular multivariate time-series. Specifically, we design a time sensitive contrastive learning and data reconstruction task to pre-train a model. Irregular time-series exhibits considerable variations in sampling density over time. Hence, our triplet generation strategy follows the density of the original data points, preserving its native irregularity. Moreover, the sampling density variation over time makes data reconstruction difficult for different regions. Therefore, we design a data masking technique that always masks a constant time duration to accommodate reconstruction for regions of different sampling density. We learn with these tasks using unlabeled data to build a pre-trained model and fine-tune on a downstream task with limited labeled data, in contrast with existing fully supervised approach for irregular time-series, requiring large amounts of labeled data. Experiment results show that PrimeNet significantly outperforms state-of-the-art methods on naturally irregular and asynchronous data from Healthcare and IoT applications for several downstream tasks, including classification, interpolation, and regression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "97483167",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "9bf1a897c6d6f959b0160c0cc1675f528b974b28",
            "title": "Minimally Supervised Contextual Inference from Human Mobility: An Iterative Collaborative Distillation Framework",
            "abstract": "The context about trips and users from mobility data is valuable for mobile service providers to understand their customers and improve their services. Existing inference methods require a large number of labels for training, which is hard to meet in practice. In this paper, we study a more practical yet challenging setting\u2014contextual inference using mobility data with minimal supervision (i.e., a few labels per class and massive unlabeled data). A typical solution is to apply semi-supervised methods that follow a self-training framework to bootstrap a model based on all features. However, using a limited labeled set brings high risk of overfitting to self-training, leading to unsatisfactory performance. We propose a novel collaborative distillation framework STCOLAB. It sequentially trains spatial and temporal modules at each iteration following the supervision of ground-truth labels. In addition, it distills knowledge to the module being trained using the logits produced by the latest trained module of the other modality, thereby mutually calibrating the two modules and combining the knowledge from both modalities. Extensive experiments on two real-world datasets show STCOLAB achieves significantly more accurate contextual inference than various baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "9d697c46e6fa79f4c3a283c7539cb58f8cd5e2e8",
            "title": "Federated Learning with Client-Exclusive Classes",
            "abstract": "Existing federated classification algorithms typically assume the local annotations at every client cover the same set of classes. In this paper, we aim to lift such an assumption and focus on a more general yet practical non-IID setting where every client can work on non-identical and even disjoint sets of classes (i.e., client-exclusive classes ), and the clients have a common goal which is to build a global classification model to identify the union of these classes. Such heterogeneity in client class sets poses a new challenge: how to ensure different clients are operating in the same latent space so as to avoid the drift after aggregation? We observe that the classes can be described in natural languages (i.e., class names) and these names are typically safe to share with all parties. Thus, we formulate the classification problem as a matching process between data representations and class representations and break the classification model into a data encoder and a label encoder. We leverage the natural-language class names as the common ground to anchor the class representations in the label encoder. In each iteration, the label encoder updates the class representations and regulates the data representations through matching. We further use the updated class representations at each round to annotate data samples for locally-unaware classes according to similarity and distill knowledge to local models. Extensive experiments on four real-world datasets show that the proposed method can outperform various classical and state-of-the-art federated learning methods designed for learning with non-IID data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108130022",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "b26182a81185552efaaec9e79579b333901410bd",
            "title": "Navigating Alignment for Non-identical Client Class Sets: A Label Name-Anchored Federated Learning Framework",
            "abstract": "Traditional federated classification methods, even those designed for non-IID clients, assume that each client annotates its local data with respect to the same universal class set. In this paper, we focus on a more general yet practical setting, non-identical client class sets, where clients focus on their own (different or even non-overlapping) class sets and seek a global model that works for the union of these classes. If one views classification as finding the best match between representations produced by data/label encoder, such heterogeneity in client class sets poses a new significant challenge-local encoders at different clients may operate in different and even independent latent spaces, making it hard to aggregate at the server. We propose a novel framework, FedAlign1, to align the latent spaces across clients from both label and data perspectives. From a label perspective, we leverage the expressive natural language class names as a common ground for label encoders to anchor class representations and guide the data encoder learning across clients. From a data perspective, during local training, we regard the global class representations as anchors and leverage the data points that are close/far enough to the anchors of locally-unaware classes to align the data encoders across clients. Our theoretical analysis of the generalization performance and extensive experiments on four real-world datasets of different tasks confirm that FedAlign outperforms various state-of-the-art (non-IID) federated classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "c26c4bbac1170f7e7fb7c4298c384c859098f71f",
            "title": "Physics-Informed Data Denoising for Real-Life Sensing Systems",
            "abstract": "Sensors measuring real-life physical processes are ubiquitous in today's interconnected world. These sensors inherently bear noise that often adversely affects the performance and reliability of the systems they support. Classic filtering approaches introduce strong assumption on the time or frequency characteristics of sensory measurements, while learning-based denoising approaches typically rely on using ground truth clean data to train a denoising model, which is often challenging or prohibitive to obtain for many real-world applications. We observe that in many scenarios, the relationships between different sensor measurements (e.g., location and acceleration) are analytically described by laws of physics (e.g., second-order differential equation). By incorporating such physics constraints, we can guide the denoising process to improve performance even in the absence of ground truth data. In light of this, we design a physics-informed denoising model that leverages the inherent algebraic relationships between different measurements governed by the underlying physics. By obviating the need for ground truth clean data, our method offers a practical denoising solution for real-world applications. We conducted experiments in various domains, including inertial navigation, CO2 monitoring, and HVAC control, and achieved state-of-the-art performance compared with existing denoising methods. Our method can denoise data in real time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results that closely align with those from high-precision, high-cost alternatives, leading to an efficient, cost-effective approach for more accurate sensor-based systems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2265354336",
                    "name": "Xiaohan Fu"
                },
                {
                    "authorId": "2266398673",
                    "name": "Diyan Teng"
                },
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "2266420695",
                    "name": "Keerthivasan Vijayakumar"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266424978",
                    "name": "Junsheng Han"
                },
                {
                    "authorId": "2266398035",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2266398313",
                    "name": "Rashmi Kulkarni"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                }
            ]
        },
        {
            "paperId": "d16da2ad581945602b07c004039a1c717d1b1432",
            "title": "Rule-based Policy Regularization for Reinforcement Learning-based Building Control",
            "abstract": "Rule-based control (RBC) is widely adopted in buildings due to its stability and robustness. It resembles a behavior cloning methodology refined by human experts; however, it is incapable of adapting to distribution drifts. Reinforcement learning (RL) can adapt to changes but needs to learn from scratch in the online setting. On the other hand, the learning ability is limited in offline settings due to extrapolation errors caused by selecting out-of-distribution actions. In this paper, we explore how to incorporate RL with a rule-based control policy to combine their strengths to continuously learn a scalable and robust policy in both online and offline settings. We start with representative online and offline RL methods, TD3 and TD3+BC, respectively. Then, we develop a dynamically weighted actor loss function to selectively choose which policy for RL models to learn from at each training iteration. With extensive experiments across various weather conditions in both deterministic and stochastic scenarios, we demonstrate that our algorithm, rule-based incorporated control regularization (RUBICON), outperforms state-of-the-art methods in offline settings by and improves the baseline method by in online settings with respect to a reward consisting of thermal comfort and energy consumption in building-RL environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "95813069",
                    "name": "Hsin-Yu Liu"
                },
                {
                    "authorId": "144019834",
                    "name": "Bharathan Balaji"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        }
    ]
}