{
    "authorId": "2251205420",
    "papers": [
        {
            "paperId": "07bd842ee329888e5c2ca66a1105bcdbddab04cc",
            "title": "LLMs generate structurally realistic social networks but overestimate political homophily",
            "abstract": "Generating social networks is essential for many applications, such as epidemic modeling and social simulations. Prior approaches either involve deep learning models, which require many observed networks for training, or stylized models, which are limited in their realism and flexibility. In contrast, LLMs offer the potential for zero-shot and flexible network generation. However, two key questions are: (1) are LLM's generated networks realistic, and (2) what are risks of bias, given the importance of demographics in forming social ties? To answer these questions, we develop three prompting methods for network generation and compare the generated networks to real social networks. We find that more realistic networks are generated with\"local\"methods, where the LLM constructs relations for one persona at a time, compared to\"global\"methods that construct the entire network at once. We also find that the generated networks match real networks on many characteristics, including density, clustering, community structure, and degree. However, we find that LLMs emphasize political homophily over all other types of homophily and overestimate political homophily relative to real-world measures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2231606961",
                    "name": "Serina Chang"
                },
                {
                    "authorId": "2317961789",
                    "name": "Alicja Chaszczewicz"
                },
                {
                    "authorId": "2317923986",
                    "name": "Emma Wang"
                },
                {
                    "authorId": "2317961820",
                    "name": "Maya Josifovska"
                },
                {
                    "authorId": "2277459687",
                    "name": "Emma Pierson"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "1181c36f7b932384defbc97c9b5d792618fda1a5",
            "title": "Position: Relational Deep Learning - Graph Representation Learning on Relational Databases",
            "abstract": "Much of the world\u2019s most valued data is stored in relational databases and data warehouses, where the data is organized into tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming because no ML algorithm can directly learn from multiple connected tables. Current approaches can only learn from a single table, so data must first be manually joined and aggregated into this format, the laborious process known as feature engineering. This position paper introduces Relational Deep Learning (RDL) , a blueprint for end-to-end learning on relational databases. The key is to represent relational databases as temporal, heterogeneous graphs, with a node for each row in each table, and edges specified by primary-foreign key links. Graph Neural Networks then learn representations that leverage all input data, without any manual feature engineering. We also introduce R EL B ENCH , and benchmark and testing suite, demonstrating strong initial results. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294360908",
                    "name": "Matthias Fey"
                },
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "2301109776",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "9572099",
                    "name": "J. E. Lenssen"
                },
                {
                    "authorId": "2268710645",
                    "name": "Rishabh Ranjan"
                },
                {
                    "authorId": "2268728614",
                    "name": "Joshua Robinson"
                },
                {
                    "authorId": "2319128990",
                    "name": "Rex Ying"
                },
                {
                    "authorId": "145829303",
                    "name": "Jiaxuan You"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "39fbce781d28b36ad41bd897e0a0ca71a285351a",
            "title": "From Similarity to Superiority: Channel Clustering for Time Series Forecasting",
            "abstract": "Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent (CI) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent (CD) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adaptable Channel Clustering Module (CCM). CCM dynamically groups channels characterized by intrinsic similarities and leverages cluster identity instead of channel identity, combining the best of CD and CI worlds. Extensive experiments on real-world datasets demonstrate that CCM can (1) boost the performance of CI and CD models by an average margin of 2.4% and 7.2% on long-term and short-term forecasting, respectively; (2) enable zero-shot forecasting with mainstream time series forecasting models; (3) uncover intrinsic time series patterns among channels and improve interpretability of complex time series models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2263472358",
                    "name": "Jialin Chen"
                },
                {
                    "authorId": "9572099",
                    "name": "J. E. Lenssen"
                },
                {
                    "authorId": "2268782997",
                    "name": "Aosong Feng"
                },
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "2294360908",
                    "name": "Matthias Fey"
                },
                {
                    "authorId": "2065219256",
                    "name": "L. Tassiulas"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "2290490102",
                    "name": "Rex Ying"
                }
            ]
        },
        {
            "paperId": "7f0f99b2863dc64f606f3d9c636452834478ccdb",
            "title": "TimeGraphs: Graph-based Temporal Reasoning",
            "abstract": "Many real-world systems exhibit temporal, dynamic behaviors, which are captured as time series of complex agent interactions. To perform temporal reasoning, current methods primarily encode temporal dynamics through simple sequence-based models. However, in general these models fail to efficiently capture the full spectrum of rich dynamics in the input, since the dynamics is not uniformly distributed. In particular, relevant information might be harder to extract and computing power is wasted for processing all individual timesteps, even if they contain no significant changes or no new information. Here we propose TimeGraphs, a novel approach that characterizes dynamic interactions as a hierarchical temporal graph, diverging from traditional sequential representations. Our approach models the interactions using a compact graph-based representation, enabling adaptive reasoning across diverse time scales. Adopting a self-supervised method, TimeGraphs constructs a multi-level event hierarchy from a temporal input, which is then used to efficiently reason about the unevenly distributed dynamics. This construction process is scalable and incremental to accommodate streaming data. We evaluate TimeGraphs on multiple datasets with complex, dynamic agent interactions, including a football simulator, the Resistance game, and the MOMA human activity dataset. The results demonstrate both robustness and efficiency of TimeGraphs on a range of temporal reasoning tasks. Our approach obtains state-of-the-art performance and leads to a performance increase of up to 12.2% on event prediction and recognition tasks over current approaches. Our experiments further demonstrate a wide array of capabilities including zero-shot generalization, robustness in case of data sparsity, and adaptability to streaming data flow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278426663",
                    "name": "Paridhi Maheshwari"
                },
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "2257348997",
                    "name": "Yanan Wang"
                },
                {
                    "authorId": "48523334",
                    "name": "R. Sosi\u010d"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "bb80043b795dec1736be4329a5588ce5a5b093fd",
            "title": "PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning",
            "abstract": "We present PyTorch Frame, a PyTorch-based framework for deep learning over multi-modal tabular data. PyTorch Frame makes tabular deep learning easy by providing a PyTorch-based data structure to handle complex tabular data, introducing a model abstraction to enable modular implementation of tabular models, and allowing external foundation models to be incorporated to handle complex columns (e.g., LLMs for text columns). We demonstrate the usefulness of PyTorch Frame by implementing diverse tabular models in a modular way, successfully applying these models to complex multi-modal tabular data, and integrating our framework with PyTorch Geometric, a PyTorch library for Graph Neural Networks (GNNs), to perform end-to-end learning over relational databases.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "2294517654",
                    "name": "Yiwen Yuan"
                },
                {
                    "authorId": "2294848842",
                    "name": "Zecheng Zhang"
                },
                {
                    "authorId": "2294360062",
                    "name": "Akihiro Nitta"
                },
                {
                    "authorId": "48865984",
                    "name": "Kaidi Cao"
                },
                {
                    "authorId": "2281744793",
                    "name": "Vid Kocijan"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "2294360908",
                    "name": "Matthias Fey"
                }
            ]
        },
        {
            "paperId": "c1e21b3dcca043cf2243f456b0d6c76e70eeb5a4",
            "title": "Representation Learning for Frequent Subgraph Mining",
            "abstract": "Identifying frequent subgraphs, also called network motifs, is crucial in analyzing and predicting properties of real-world networks. However, finding large commonly-occurring motifs remains a challenging problem not only due to its NP-hard subroutine of subgraph counting, but also the exponential growth of the number of possible subgraphs patterns. Here we present Subgraph Pattern Miner (SPMiner), a novel neural approach for approximately finding frequent subgraphs in a large target graph. SPMiner combines graph neural networks, order embedding space, and an efficient search strategy to identify network subgraph patterns that appear most frequently in the target graph. SPMiner first decomposes the target graph into many overlapping subgraphs and then encodes each subgraph into an order embedding space. SPMiner then uses a monotonic walk in the order embedding space to identify frequent motifs. Compared to existing approaches and possible neural alternatives, SPMiner is more accurate, faster, and more scalable. For 5- and 6-node motifs, we show that SPMiner can almost perfectly identify the most frequent motifs while being 100x faster than exact enumeration methods. In addition, SPMiner can also reliably identify frequent 10-node motifs, which is well beyond the size limit of exact enumeration approaches. And last, we show that SPMiner can find large up to 20 node motifs with 10-100x higher frequency than those found by current approximate methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "83539859",
                    "name": "Rex Ying"
                },
                {
                    "authorId": "48737592",
                    "name": "Tianyu Fu"
                },
                {
                    "authorId": "2285685097",
                    "name": "Andrew Wang"
                },
                {
                    "authorId": "145829303",
                    "name": "Jiaxuan You"
                },
                {
                    "authorId": "2285001660",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "c29aa2e58d91e733685914b40eadb83d719c59dd",
            "title": "STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases",
            "abstract": "Answering real-world complex queries, such as complex product search, often requires accurate retrieval from semi-structured knowledge bases that involve blend of unstructured (e.g., textual descriptions of products) and structured (e.g., entity relations of products) information. However, previous works have mostly studied textual and relational retrieval tasks as separate topics. To address the gap, we develop STARK, a large-scale Semi-structure retrieval benchmark on Textual and Relational K nowledge Bases. Our benchmark covers three domains/datasets: product search, academic paper search, and queries in precision medicine. We design a novel pipeline to synthesize realistic user queries that integrate diverse relational information and complex textual properties, together with their ground-truth answers (items). We conduct rigorous human evaluation to validate the quality of our synthesized queries. We further enhance the benchmark with high-quality human-generated queries to provide an authentic reference. STARK serves as a comprehensive testbed for evaluating the performance of retrieval systems driven by large language models (LLMs). Our experiments suggest that STARK presents significant challenges to the current retrieval and LLM systems, indicating the demand for building more capable retrieval systems. The benchmark data and code are available on https://github.com/snap-stanford/stark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774538",
                    "name": "Shirley Wu"
                },
                {
                    "authorId": "2297830746",
                    "name": "Shiyu Zhao"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "48865984",
                    "name": "Kaidi Cao"
                },
                {
                    "authorId": "2302855404",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2265619476",
                    "name": "James Zou"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "db22b645cb9d213095089a9ba88d02d18e6543a6",
            "title": "AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval",
            "abstract": "Large language model (LLM) agents have demonstrated impressive capability in utilizing external tools and knowledge to boost accuracy and reduce hallucinations. However, developing the prompting techniques that make LLM agents able to effectively use external tools and knowledge is a heuristic and laborious task. Here, we introduce AvaTaR, a novel and automatic framework that optimizes an LLM agent to effectively use the provided tools and improve its performance on a given task/domain. During optimization, we design a comparator module to iteratively provide insightful and holistic prompts to the LLM agent via reasoning between positive and negative examples sampled from training data. We demonstrate AvaTaR on four complex multimodal retrieval datasets featuring textual, visual, and relational information. We find AvaTaR consistently outperforms state-of-the-art approaches across all four challenging tasks and exhibits strong generalization ability when applied to novel cases, achieving an average relative improvement of 14% on the Hit@1 metric. Code and dataset are available at https://github.com/zou-group/avatar.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774538",
                    "name": "Shirley Wu"
                },
                {
                    "authorId": "2297830746",
                    "name": "Shiyu Zhao"
                },
                {
                    "authorId": "2302855404",
                    "name": "Qian Huang"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "19168196",
                    "name": "Michihiro Yasunaga"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "2265619476",
                    "name": "James Zou"
                }
            ]
        },
        {
            "paperId": "f61e5d651061070dec0c40eb3513f0dfb62b4de4",
            "title": "RelBench: A Benchmark for Deep Learning on Relational Databases",
            "abstract": "We present RelBench, a public benchmark for solving predictive tasks over relational databases with graph neural networks. RelBench provides databases and tasks spanning diverse domains and scales, and is intended to be a foundational infrastructure for future research. We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables. End-to-end learned RDL models fully exploit the predictive signal encoded in primary-foreign key links, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular models. To thoroughly evaluate RDL against this prior gold-standard, we conduct an in-depth user study where an experienced data scientist manually engineers features for each task. In this study, RDL learns better models whilst reducing human work needed by more than an order of magnitude. This demonstrates the power of deep learning for solving predictive tasks over relational databases, opening up many new research opportunities enabled by RelBench.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268728614",
                    "name": "Joshua Robinson"
                },
                {
                    "authorId": "2268710645",
                    "name": "Rishabh Ranjan"
                },
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "2301109776",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "2280291938",
                    "name": "Jiaqi Han"
                },
                {
                    "authorId": "2078560313",
                    "name": "Alejandro Dobles"
                },
                {
                    "authorId": "2294360908",
                    "name": "Matthias Fey"
                },
                {
                    "authorId": "9572099",
                    "name": "J. E. Lenssen"
                },
                {
                    "authorId": "2294517654",
                    "name": "Yiwen Yuan"
                },
                {
                    "authorId": "2294848842",
                    "name": "Zecheng Zhang"
                },
                {
                    "authorId": "2313796183",
                    "name": "Xinwei He"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "17a6213e30895fb7e5d0b368236ea8beeb94ee86",
            "title": "Relational Deep Learning: Graph Representation Learning on Relational Databases",
            "abstract": "Much of the world's most valued data is stored in relational databases and data warehouses, where the data is organized into many tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming. The core problem is that no machine learning method is capable of learning on multiple tables interconnected by primary-foreign key relations. Current methods can only learn from a single table, so the data must first be manually joined and aggregated into a single training table, the process known as feature engineering. Feature engineering is slow, error prone and leads to suboptimal models. Here we introduce an end-to-end deep representation learning approach to directly learn on data laid out across multiple tables. We name our approach Relational Deep Learning (RDL). The core idea is to view relational databases as a temporal, heterogeneous graph, with a node for each row in each table, and edges specified by primary-foreign key links. Message Passing Graph Neural Networks can then automatically learn across the graph to extract representations that leverage all input data, without any manual feature engineering. Relational Deep Learning leads to more accurate models that can be built much faster. To facilitate research in this area, we develop RelBench, a set of benchmark datasets and an implementation of Relational Deep Learning. The data covers a wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon Product Catalog. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability to a wide set of AI use cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3410500",
                    "name": "Matthias Fey"
                },
                {
                    "authorId": "2146241852",
                    "name": "Weihua Hu"
                },
                {
                    "authorId": "2257213179",
                    "name": "Kexin Huang"
                },
                {
                    "authorId": "9572099",
                    "name": "J. E. Lenssen"
                },
                {
                    "authorId": "2268710645",
                    "name": "Rishabh Ranjan"
                },
                {
                    "authorId": "2268728614",
                    "name": "Joshua Robinson"
                },
                {
                    "authorId": "83539859",
                    "name": "Rex Ying"
                },
                {
                    "authorId": "145829303",
                    "name": "Jiaxuan You"
                },
                {
                    "authorId": "2251205420",
                    "name": "J. Leskovec"
                }
            ]
        }
    ]
}