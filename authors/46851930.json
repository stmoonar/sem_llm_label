{
    "authorId": "46851930",
    "papers": [
        {
            "paperId": "4086fc2bc4b7966698e31c0d5ddc19f31b4702c4",
            "title": "REACTCLASS: Cross-Modal Supervision for Subword-Guided Reactant Entity Classification",
            "abstract": "We propose REACTCLASS that automatically maps the low-level concrete chemical entities into the high-level reactant groups without human effort for training data annotation. REACTCLASS is designed to take two special characteristics of the chemical molecules into consideration. The first characteristic is that each chemical molecule can be represented in two modalities: a chemical name in the text and a molecular structure in the graph. We propose to use cross-modal supervision to automatically create the training data for chemical name classification in the text via molecular structure matching in the graph. The second characteristic is that there is a knowledge-aware subword correlation between the surface names of the chemical entities to be classified and that of the reactant groups as class labels. We propose to train a classification model based on the subword cross-attention map between each chemical name and the corresponding reaction group. Experiments demonstrate that REACTCLASS is highly effective, achieving state-of-the-art performance in classifying the chemical names into human-defined reactant groups without requiring human effort for training data annotation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154990549",
                    "name": "Xuan Wang"
                },
                {
                    "authorId": "50161308",
                    "name": "Vivian Hu"
                },
                {
                    "authorId": "2800541",
                    "name": "Minhao Jiang"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "1499269725",
                    "name": "Danielle C. Loving"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2199258773",
                    "name": "Martin Burke"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "112dd6f0a395b52a55d9c1db0f53464c41729c53",
            "title": "Fine-Grained Chemical Entity Typing with Multimodal Knowledge Representation",
            "abstract": "Automated knowledge discovery from trending chemical literature is essential for more efficient biomedical research. How to extract detailed knowledge about chemical reactions from the core chemistry literature is a new emerging challenge that has not been well studied. In this paper, we study the new problem of fine-grained chemical entity typing, which poses interesting new challenges especially because of the complex name mentions frequently occurring in chemistry literature and graphic representation of entities. We introduce a new benchmark data set (CHEMET) to facilitate the study of the new task and propose a novel multi-modal representation learning framework to solve the problem of fine-grained chemical entity typing by leveraging external resources with chemical structures and using cross-modal attention to learn effective representation of text in the chemistry domain. Experiment results show that the proposed framework outperforms multiple state-of-the-art methods. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118831287",
                    "name": "Chenkai Sun"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "1736467",
                    "name": "ChengXiang Zhai"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                }
            ]
        },
        {
            "paperId": "3ede448b85b71790eda31de51ce663e5980eab78",
            "title": "Knowledge-Rich Self-Supervised Entity Linking",
            "abstract": "Entity linking faces signi\ufb01cant challenges, such as proli\ufb01c variations and prevalent ambiguities, especially in high-value domains with myriad entities. Standard classi\ufb01cation approaches suffer from the annotation bottle-neck and cannot effectively handle unseen entities. Zero-shot entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ( KRISS ) for entity linking, by leveraging readily available domain knowledge. In training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. For inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. Our approach subsumes zero-shot and few-shot methods, and can easily incorporate entity descriptions and gold mention labels if available. Using biomedicine as a case study, we conducted extensive experiments on seven standard datasets spanning biomedical literature and clinical notes. With-out using any labeled information, our method produces KRISSBERT , a universal entity linker for four million UMLS entities, which attains new state of the art across the board, outper-forming prior best self-supervised methods by as much as over 20 absolute points in accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41209309",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "3404827",
                    "name": "Shikhar Vashishth"
                },
                {
                    "authorId": "2109566188",
                    "name": "Cliff Wong"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "40466858",
                    "name": "Tristan Naumann"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "1759772",
                    "name": "Hoifung Poon"
                }
            ]
        },
        {
            "paperId": "4361c498f45cc6d1ef4e98b75b23af6c598da54d",
            "title": "Knowledge-Rich Self-Supervision for Biomedical Entity Linking",
            "abstract": "Entity linking faces significant challenges such as prolific variations and prevalent ambiguities, especially in high-value domains with myriad entities. Standard classification approaches suffer from the annotation bottleneck and cannot effectively handle unseen entities. Zero-shot entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ($\\tt KRISS$) for biomedical entity linking, by leveraging readily available domain knowledge. In training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. For inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. Our approach can easily incorporate entity descriptions and gold mention labels if available. We conducted extensive experiments on seven standard datasets spanning biomedical literature and clinical notes. Without using any labeled information, our method produces $\\tt KRISSBERT$, a universal entity linker for four million UMLS entities that attains new state of the art, outperforming prior self-supervised methods by as much as 20 absolute points in accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72655349",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "3404827",
                    "name": "Shikhar Vashishth"
                },
                {
                    "authorId": "2109566188",
                    "name": "Cliff Wong"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "40466858",
                    "name": "Tristan Naumann"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "1759772",
                    "name": "Hoifung Poon"
                }
            ]
        },
        {
            "paperId": "81e1e9375a939e1a4c6d0185d38bb6cbda394f96",
            "title": "Scaling Up Data Science Course Projects: A Case Study",
            "abstract": "Large-scale, online Data Science (DS) courses and degree programs are becoming increasingly common due to the global rise in popularity and demand for data scientists. Although project-based learning is integral to gaining hands-on experience in DS education, providing fair, timely, and high-quality feedback on varied projects for a large number of diverse students is challenging. To address those challenges in scaling up the assessment of DS group projects, we integrated multiple techniques, such as rapid feedback, peer grading, graders as meta-reviewers, etc. We present a case study of deploying those strategies for group projects in a large online DS course titled Text Information Systems offered in Fall, 2020. We synthesize our findings from analyzing student and grader survey responses, and share useful lessons and future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080053811",
                    "name": "B. Bhavya"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "1736467",
                    "name": "ChengXiang Zhai"
                }
            ]
        },
        {
            "paperId": "f6cb7363464ee8f15183fbb93f768ff2d78b0f8e",
            "title": "ChemNER: Fine-Grained Chemistry Named Entity Recognition with Ontology-Guided Distant Supervision",
            "abstract": "Scientific literature analysis needs fine-grained named entity recognition (NER) to provide a wide range of information for scientific discovery. For example, chemistry research needs to study dozens to hundreds of distinct, fine-grained entity types, making consistent and accurate annotation difficult even for crowds of domain experts. On the other hand, domain-specific ontologies and knowledge bases (KBs) can be easily accessed, constructed, or integrated, which makes distant supervision realistic for fine-grained chemistry NER. In distant supervision, training labels are generated by matching mentions in a document with the concepts in the knowledge bases (KBs). However, this kind of KB-matching suffers from two major challenges: incomplete annotation and noisy annotation. We propose ChemNER, an ontology-guided, distantly-supervised method for fine-grained chemistry NER to tackle these challenges. It leverages the chemistry type ontology structure to generate distant labels with novel methods of flexible KB-matching and ontology-guided multi-type disambiguation. It significantly improves the distant label generation for the subsequent sequence labeling model training. We also provide an expert-labeled, chemistry NER dataset with 62 fine-grained chemistry types (e.g., chemical compounds and chemical reactions). Experimental results show that ChemNER is highly effective, outperforming substantially the state-of-the-art NER methods (with .25 absolute F1 score improvement).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154990549",
                    "name": "Xuan Wang"
                },
                {
                    "authorId": "50161308",
                    "name": "Vivian Hu"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "50064464",
                    "name": "Shweta Garg"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "131d30cdaa978e113e2a5f5113fe7590dc1e8c5e",
            "title": "Open-Domain Question Answering with Pre-Constructed Question Spaces",
            "abstract": "Open-domain question answering aims at locating the answers to user-generated questions in massive collections of documents. Retriever-readers and knowledge graph approaches are two big families of solutions to this task. A retriever-reader first applies information retrieval techniques to locate a few passages that are likely to be relevant, and then feeds the retrieved text to a neural network reader to extract the answer. Alternatively, knowledge graphs can be constructed and queried to answer users\u2019 questions. We propose an algorithm with a novel reader-retriever design that differs from both families. Our reader-retriever first uses an offline reader to read the corpus and generate collections of all answerable questions associated with their answers, and then uses an online retriever to respond to user queries by searching the pre-constructed question spaces for answers that are most likely to be asked in the given way. We further combine one retriever-reader and two reader-retrievers into a hybrid model called R6 for the best performance. Experiments with two large-scale public datasets show that R6 achieves state-of-the-art accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "145262461",
                    "name": "Trung Bui"
                },
                {
                    "authorId": "1500530510",
                    "name": "Tong Sun"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "85ed6806f86be81647e9707d563ec3092c21060a",
            "title": "Leveraging Personalized Sentiment Lexicons for Sentiment Analysis",
            "abstract": "We propose a novel personalized approach for the sentiment analysis task. The approach is based on the intuition that the same sentiment words can carry different sentiment weights for different users. For each user, we learn a language model over a sentiment lexicon to capture her writing style. We further correlate this user-specific language model with the user's historical ratings of reviews. Additionally, we discuss how two standard CNN and CNN+LSTM models can be improved by adding these user-based features. Our evaluation on the Yelp dataset shows that the proposed new personalized sentiment analysis features are effective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40499153",
                    "name": "Dominic Seyler"
                },
                {
                    "authorId": "3363642",
                    "name": "Jiaming Shen"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2107919851",
                    "name": "Yiren Wang"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "036451fec8f408fc978194519635facafd123dc6",
            "title": "Query-Specific Knowledge Summarization with Entity Evolutionary Networks",
            "abstract": "Given a query, unlike traditional IR that finds relevant documents or entities, in this work, we focus on retrieving both entities and their connections for insightful knowledge summarization. For example, given a query \"computer vision'' on a CS literature corpus, rather than returning a list of relevant entities like \"cnn'', \"imagenet'' and \"svm'', we are interested in the connections among them, and furthermore, the evolution patterns of such connections along particular ordinal dimensions such as time. Particularly, we hope to provide structural knowledge relevant to the query, such as \"svm'' is related to \"imagenet'' but not \"cnn''. Moreover, we aim to model the changing trends of the connections, such as \"cnn'' becomes highly related to \"imagenet'' after 2010, which enables the tracking of knowledge evolutions. In this work, to facilitate such a novel insightful search system, we propose SetEvolve, which is a unified framework based on nonparanomal graphical models for evolutionary network construction from large text corpora. Systematic experiments on synthetic data and insightful case studies on real-world corpora demonstrate the utility of SetEvolve.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390553618",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "145211637",
                    "name": "Lingrui Gan"
                },
                {
                    "authorId": "2108183936",
                    "name": "Zongyi Wang"
                },
                {
                    "authorId": "3363642",
                    "name": "Jiaming Shen"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "048e89b05b3a6224c5063d1c117424cab597ae40",
            "title": "Knowledge-guided analysis of \"omics\" data using the KnowEnG cloud platform",
            "abstract": "We present KnowEnG, a free-to-use computational system for analysis of genomics data sets, designed to accelerate biomedical discovery. It includes tools for popular bioinformatics tasks such as gene prioritization, sample clustering, gene set analysis and expression signature analysis. The system offers \u2018knowledge-guided\u2019 data-mining and machine learning algorithms, where user-provided data are analyzed in light of prior information about genes, aggregated from numerous knowledge-bases and encoded in a massive \u2018Knowledge Network\u2019. KnowEnG adheres to \u2018FAIR\u2019 principles: its tools are easily portable to diverse computing environments, run on the cloud for scalable and cost-effective execution of compute-intensive and data-intensive algorithms, and are interoperable with other computing platforms. They are made available through multiple access modes including a web-portal, and include specialized visualization modules. We present use cases and re-analysis of published cancer data sets using KnowEnG tools and demonstrate its potential value in democratization of advanced tools for the modern genomics era.",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "3077932",
                    "name": "Charles A. Blatti"
                },
                {
                    "authorId": "1802821",
                    "name": "A. Emad"
                },
                {
                    "authorId": "48647163",
                    "name": "Michael J. Berry"
                },
                {
                    "authorId": "89649860",
                    "name": "Lisa Gatzke"
                },
                {
                    "authorId": "81877634",
                    "name": "M. Epstein"
                },
                {
                    "authorId": "112910389",
                    "name": "D. Lanier"
                },
                {
                    "authorId": "147836419",
                    "name": "P. Rizal"
                },
                {
                    "authorId": "2065022934",
                    "name": "J. Ge"
                },
                {
                    "authorId": "2075368210",
                    "name": "X. Liao"
                },
                {
                    "authorId": "3415039",
                    "name": "Omar Sobh"
                },
                {
                    "authorId": "2057212278",
                    "name": "M. Lambert"
                },
                {
                    "authorId": "1490760135",
                    "name": "C. S. Post"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "143927280",
                    "name": "P. Groves"
                },
                {
                    "authorId": "2052370083",
                    "name": "A. Epstein"
                },
                {
                    "authorId": "2145306805",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "48596257",
                    "name": "S. Srinivasan"
                },
                {
                    "authorId": "46456331",
                    "name": "E. Lehnert"
                },
                {
                    "authorId": "2090320",
                    "name": "Krishna R. Kalari"
                },
                {
                    "authorId": "48170093",
                    "name": "Liewei Wang"
                },
                {
                    "authorId": "144553753",
                    "name": "R. Weinshilboum"
                },
                {
                    "authorId": "2144573847",
                    "name": "Jun S. Song"
                },
                {
                    "authorId": "144289001",
                    "name": "C. Jongeneel"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2762077",
                    "name": "Umberto Ravaioli"
                },
                {
                    "authorId": "47221821",
                    "name": "N. Sobh"
                },
                {
                    "authorId": "2244634",
                    "name": "C. Bushell"
                },
                {
                    "authorId": "2241595996",
                    "name": "S. Sinha"
                }
            ]
        }
    ]
}