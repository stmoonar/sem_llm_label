{
    "authorId": "2308097253",
    "papers": [
        {
            "paperId": "0e15965ba3838ca249ddfd3a47b1d182a63d071f",
            "title": "TaPS: A Performance Evaluation Suite for Task-based Execution Frameworks",
            "abstract": "Task-based execution frameworks, such as parallel programming libraries, computational workflow systems, and function-as-a-service platforms, enable the composition of distinct tasks into a single, unified application designed to achieve a computational goal and abstract the parallel and distributed execution of those tasks on arbitrary hardware. Research into these task executors has accelerated as computational sciences increasingly need to take advantage of parallel compute and/or heterogeneous hardware. However, the lack of evaluation standards makes it challenging to compare and contrast novel systems against existing implementations. Here, we introduce TaPS, the Task Performance Suite, to support continued research in distributed task executor frameworks. TaPS provides (1) a unified, modular interface for writing and evaluating applications using arbitrary execution frameworks and data management systems and (2) an initial set of reference synthetic and real-world science applications. We discuss how the design of TaPS supports the reliable evaluation of frameworks and demonstrate TaPS through a survey of benchmarks using the provided reference applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51916788",
                    "name": "J. G. Pauloski"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2311500388",
                    "name": "Maxime Gonthier"
                },
                {
                    "authorId": "48808283",
                    "name": "Nathaniel Hudson"
                },
                {
                    "authorId": "1471350193",
                    "name": "Haochen Pan"
                },
                {
                    "authorId": "2311641474",
                    "name": "Sicheng Zhou"
                },
                {
                    "authorId": "2303397640",
                    "name": "Ian Foster"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                }
            ]
        },
        {
            "paperId": "1e133b080d4a53ed305d043005c2e7e79533d27f",
            "title": "Object Proxy Patterns for Accelerating Distributed Applications",
            "abstract": "Workflow and serverless frameworks have empowered new approaches to distributed application design by abstracting compute resources. However, their typically limited or one-size-fits-all support for advanced data flow patterns leaves optimization to the application programmer -- optimization that becomes more difficult as data become larger. The transparent object proxy, which provides wide-area references that can resolve to data regardless of location, has been demonstrated as an effective low-level building block in such situations. Here we propose three high-level proxy-based programming patterns -- distributed futures, streaming, and ownership -- that make the power of the proxy pattern usable for more complex and dynamic distributed program structures. We motivate these patterns via careful review of application requirements and describe implementations of each pattern. We evaluate our implementations through a suite of benchmarks and by applying them in three substantial scientific applications, in which we demonstrate substantial improvements in runtime, throughput, and memory usage.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51916788",
                    "name": "J. G. Pauloski"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2256987355",
                    "name": "Logan Ward"
                },
                {
                    "authorId": "2309245702",
                    "name": "Alexander Brace"
                },
                {
                    "authorId": "2239105163",
                    "name": "Andr\u00e9 Bauer"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                },
                {
                    "authorId": "2303397640",
                    "name": "Ian Foster"
                }
            ]
        },
        {
            "paperId": "3d50c441a4bcf4713a4e9f4642df2e3c75c701a7",
            "title": "Enhancing Energy Efficiency with Multi-Site Scheduling Strategies",
            "abstract": "We analyze the energy efficiency of small application components across commodity resources. We demonstrate that 1) no single machine is ideal for all tasks examined, 2) the energy efficiency of an application varies by machine, and 3) runtime is insufficient to approximate energy consumption. These results illustrate that intelligent matching of tasks to machines has the potential to save without impacting performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2044357637",
                    "name": "Alok V. Kamatar"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2115014071",
                    "name": "Y. Babuji"
                },
                {
                    "authorId": "2239105163",
                    "name": "Andr\u00e9 Bauer"
                },
                {
                    "authorId": "8776771",
                    "name": "Gourav Rattihalli"
                },
                {
                    "authorId": "52141406",
                    "name": "Ninad Hogade"
                },
                {
                    "authorId": "2263733652",
                    "name": "D. Milojicic"
                },
                {
                    "authorId": "2141693724",
                    "name": "K. Chard"
                },
                {
                    "authorId": "2268575237",
                    "name": "Ian Foster"
                }
            ]
        },
        {
            "paperId": "61d1f5c90f2d5415b6b8045314cbf97273a58a6d",
            "title": "Octopus: Experiences with a Hybrid Event-Driven Architecture for Distributed Scientific Computing",
            "abstract": "Scientific research increasingly relies on distributed computational resources, storage systems, networks, and instruments, ranging from HPC and cloud systems to edge devices. Event-driven architecture (EDA) benefits applications targeting distributed research infrastructures by enabling the organization, communication, processing, reliability, and security of events generated from many sources. To support the development of scientific EDA, we introduce Octopus, a hybrid, cloud-to-edge event fabric designed to link many local event producers and consumers with cloud-hosted brokers. Octopus can be scaled to meet demand, permits the deployment of highly available Triggers for automatic event processing, and enforces fine-grained access control. We identify requirements in self-driving laboratories, scientific data automation, online task scheduling, epidemic modeling, and dynamic workflow management use cases, and present results demonstrating Octopus' ability to meet those requirements. Octopus supports producing and consuming events at a rate of over 4.2 M and 9.6 M events per second, respectively, from distributed clients.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1471350193",
                    "name": "Haochen Pan"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "2311641474",
                    "name": "Sicheng Zhou"
                },
                {
                    "authorId": "2044357637",
                    "name": "Alok V. Kamatar"
                },
                {
                    "authorId": "46204073",
                    "name": "Rafael Vescovi"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2239105163",
                    "name": "Andr\u00e9 Bauer"
                },
                {
                    "authorId": "2311500388",
                    "name": "Maxime Gonthier"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                },
                {
                    "authorId": "2303397640",
                    "name": "Ian Foster"
                }
            ]
        },
        {
            "paperId": "6f36d0b055566281d36efcef8d63f423e099671f",
            "title": "Flight: A FaaS-Based Framework for Complex and Hierarchical Federated Learning",
            "abstract": "Federated Learning (FL) is a decentralized machine learning paradigm where models are trained on distributed devices and are aggregated at a central server. Existing FL frameworks assume simple two-tier network topologies where end devices are directly connected to the aggregation server. While this is a practical mental model, it does not exploit the inherent topology of real-world distributed systems like the Internet-of-Things. We present Flight, a novel FL framework that supports complex hierarchical multi-tier topologies, asynchronous aggregation, and decouples the control plane from the data plane. We compare the performance of Flight against Flower, a state-of-the-art FL framework. Our results show that Flight scales beyond Flower, supporting up to 2048 simultaneous devices, and reduces FL makespan across several models. Finally, we show that Flight's hierarchical FL model can reduce communication overheads by more than 60%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48808283",
                    "name": "Nathaniel Hudson"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2115014071",
                    "name": "Y. Babuji"
                },
                {
                    "authorId": "46202504",
                    "name": "Matt Baughman"
                },
                {
                    "authorId": "51916788",
                    "name": "J. G. Pauloski"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "2303397640",
                    "name": "Ian Foster"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                }
            ]
        },
        {
            "paperId": "95c845a1d40efb9685751bfb2ad51dd048235b15",
            "title": "Diaspora: Resilience-Enabling Services for Real-Time Distributed Workflows",
            "abstract": "The need for real-time processing to enable automated decision making and experimental steering has driven a shift from high-performance computing workflows on a centralized system to a distributed approach that integrates remote data sources, edge devices, and diverse compute facilities. Under this paradigm, data can be processed close to the source where it is generated, thus reducing latency and bandwidth usage. System resilience is thus a key challenge, requiring distributed workflows to survive component failures and to meet stringent quality-of-service requirements, which results in the need to mitigate anomalies such as congestion and low availability of resources. To address these challenges, we propose Diaspora, a unified resilience framework that is inspired by event-driven communication patterns used in public clouds. Specifically, we propose an event fabric that extends across sites, facilities, and computations to provide timely, reliable, and accurate information about data, application, and resource status. On top of the event fabric, we build resilience-enabling services that combine QoS-aware data streaming, resilient data views, resilient compute and data resources, and anomaly detection and prediction, all of which collectively enhance workflow resilience for these scientific cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2304755030",
                    "name": "Bogdan Nicolae"
                },
                {
                    "authorId": "2247731967",
                    "name": "Justin M. Wozniak"
                },
                {
                    "authorId": "2323588",
                    "name": "Tekin Bicer"
                },
                {
                    "authorId": "2321983833",
                    "name": "Hai Nguyen"
                },
                {
                    "authorId": "2321991933",
                    "name": "Parth Patel"
                },
                {
                    "authorId": "2323521842",
                    "name": "Haochen Pan"
                },
                {
                    "authorId": "2313120070",
                    "name": "Amal Gueroudji"
                },
                {
                    "authorId": "2311500388",
                    "name": "Maxime Gonthier"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2321948704",
                    "name": "Eliu Huerta"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "3253869",
                    "name": "Matthieu Dorier"
                },
                {
                    "authorId": "2247718527",
                    "name": "Nageswara S. V. Rao"
                },
                {
                    "authorId": "1409679740",
                    "name": "Anees Al-Najjar"
                },
                {
                    "authorId": "2321950648",
                    "name": "Alessandra Corsi"
                },
                {
                    "authorId": "2303397640",
                    "name": "Ian Foster"
                }
            ]
        },
        {
            "paperId": "a0f94de1a1f09778b6912343665440f005fe29ac",
            "title": "GreenFaaS: Maximizing Energy Efficiency of HPC Workloads with FaaS",
            "abstract": "Application energy efficiency can be improved by executing each application component on the compute element that consumes the least energy while also satisfying time constraints. In principle, the function as a service (FaaS) paradigm should simplify such optimizations by abstracting away compute location, but existing FaaS systems do not provide for user transparency over application energy consumption or task placement. Here we present GreenFaaS, a novel open source framework that bridges this gap between energy-efficient applications and FaaS platforms. GreenFaaS can be deployed by end users or providers across systems to monitor energy use, provide task-specific feedback, and schedule tasks in an energy-aware manner. We demonstrate that intelligent placement of tasks can both reduce energy consumption and improve performance. For a synthetic workload, GreenFaaS reduces the energy-delay product by 45% compared to alternatives. Furthermore, running a molecular design application through GreenFaaS can reduce energy consumption by 21% and runtime by 63% by better matching tasks with machines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2044357637",
                    "name": "Alok V. Kamatar"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2115014071",
                    "name": "Y. Babuji"
                },
                {
                    "authorId": "2239105163",
                    "name": "Andr\u00e9 Bauer"
                },
                {
                    "authorId": "8776771",
                    "name": "Gourav Rattihalli"
                },
                {
                    "authorId": "52141406",
                    "name": "Ninad Hogade"
                },
                {
                    "authorId": "2263733652",
                    "name": "D. Milojicic"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                },
                {
                    "authorId": "2268575237",
                    "name": "Ian Foster"
                }
            ]
        },
        {
            "paperId": "c6288014f901edc611c8541c157b9c8438385e5a",
            "title": "Employing Artificial Intelligence to Steer Exascale Workflows with Colmena",
            "abstract": "Computational workflows are a common class of application on supercomputers, yet the loosely coupled and heterogeneous nature of workflows often fails to take full advantage of their capabilities. We created Colmena to leverage the massive parallelism of a supercomputer by using Artificial Intelligence (AI) to learn from and adapt a workflow as it executes. Colmena allows scientists to define how their application should respond to events (e.g., task completion) as a series of cooperative agents. In this paper, we describe the design of Colmena, the challenges we overcame while deploying applications on exascale systems, and the science workflows we have enhanced through interweaving AI. The scaling challenges we discuss include developing steering strategies that maximize node utilization, introducing data fabrics that reduce communication overhead of data-intensive tasks, and implementing workflow tasks that cache costly operations between invocations. These innovations coupled with a variety of application patterns accessible through our agent-based steering model have enabled science advances in chemistry, biophysics, and materials science using different types of AI. Our vision is that Colmena will spur creative solutions that harness AI across many domains of scientific computing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256987355",
                    "name": "Logan Ward"
                },
                {
                    "authorId": "51916788",
                    "name": "J. G. Pauloski"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2115014071",
                    "name": "Y. Babuji"
                },
                {
                    "authorId": "2309245702",
                    "name": "Alexander Brace"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "2267696593",
                    "name": "Kyle Chard"
                },
                {
                    "authorId": "2314492392",
                    "name": "Rajeev Thakur"
                },
                {
                    "authorId": "2303397640",
                    "name": "Ian Foster"
                }
            ]
        },
        {
            "paperId": "d24f874c1d58ca42a9117c2896e878f184407672",
            "title": "Steering a Fleet: Adaptation for Large-Scale, Workflow-Based Experiments",
            "abstract": "Experimental science is increasingly driven by instruments that produce vast volumes of data and thus a need to manage, compute, describe, and index this data. High performance and distributed computing provide the means of addressing the computing needs; however, in practice, the variety of actions required and the distributed set of resources involved, requires sophisticated\"flows\"defining the steps to be performed on data. As each scan or measurement is performed by an instrument, a new instance of the flow is initiated resulting in a\"fleet\"of concurrently running flows, with the overall goal to process all the data collected during a potentially long-running experiment. During the course of the experiment, each flow may need to adapt its execution due to changes in the environment, such as computational or storage resource availability, or based on the progress of the fleet as a whole such as completion or discovery of an intermediate result leading to a change in subsequent flow's behavior. We introduce a cloud-based decision engine, Braid, which flows consult during execution to query their run-time environment and coordinate with other flows within their fleet. Braid accepts streams of measurements taken from the run-time environment or from within flow runs which can then be statistically aggregated and compared to other streams to determine a strategy to guide flow execution. For example, queue lengths in execution environments can be used to direct a flow to run computations in one environment or another, or experiment progress as measured by individual flows can be aggregated to determine the progress and subsequent direction of the flows within a fleet. We describe Braid, its interface, implementation and performance characteristics. We further show through examples and experience modifying an existing scientific flow how Braid is used to make adaptable flows.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3264638",
                    "name": "J. Pruyne"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2290980475",
                    "name": "Weijian Zheng"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "8962431",
                    "name": "J. Wozniak"
                },
                {
                    "authorId": "2323588",
                    "name": "Tekin Bicer"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "2270007050",
                    "name": "Ian T. Foster"
                }
            ]
        },
        {
            "paperId": "17d2696c60b1df14354d7914595a6401aa2edea1",
            "title": "Lazy Python Dependency Management in Large-Scale Systems",
            "abstract": "Python has become the language of choice for managing many scientific applications. However, when distributing a Python application, it is necessary that all application dependencies be distributed and available in the target execution environment. A specific consequence is that Python workflows suffer from slow scale out due to the time required to import dependencies. We describe ProxyImports, a method to package and distribute Python dependencies in a lazy fashion while remaining transparent and easy to use. Using ProxyImports, Python packages are loaded only once (e.g., by a workflow head node) and are transferred asynchronously to compute nodes. We evaluate our implementation on the Perlmutter and Theta supercomputers and in an HPC cloud-bursting scenario. Our experiments show that ProxyImports significantly reduces the average time to import large modules across an HPC system and demonstrate that this method can be used easily to distribute user-packages to cloud resources. We conclude that ProxyImports improves application runtime, reduces contention on metadata servers and facilitates runtime portability of Python applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2044357637",
                    "name": "Alok V. Kamatar"
                },
                {
                    "authorId": "2239104574",
                    "name": "Mansi Sakarvadia"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "1698701",
                    "name": "Ian T Foster"
                }
            ]
        }
    ]
}