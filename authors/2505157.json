{
    "authorId": "2505157",
    "papers": [
        {
            "paperId": "3adbca134ac20e69d7215537c703db9faf483b35",
            "title": "Towards Diverse and Coherent Augmentation for Time-Series Forecasting",
            "abstract": "Time-series data augmentation mitigates the issue of insufficient training data for deep learning models. Yet, existing augmentation methods are mainly designed for classification, where class labels can be preserved even if augmentation alters the temporal dynamics. We note that augmentation designed for forecasting requires diversity as well as coherence with the original temporal dynamics. As time-series data generated by real-life physical processes exhibit characteristics in both the time and frequency domains, we propose to combine Spectral and Time Augmentation (STAug) for generating more diverse and coherent samples. Specifically, in the frequency domain, we use the Empirical Mode Decomposition to decompose a time series and reassemble the subcomponents with random weights. This way, we generate diverse samples while being coherent with the original temporal relationships as they contain the same set of base components. In the time domain, we adapt a mix-up strategy that generates diverse as well as linearly in-between coherent samples. Experiments on five real-world time-series datasets demonstrate that STAug outperforms the base models without data augmentation as well as state-of-the-art augmentation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "681f05c1952ce3e1dc48a4ceb230a6033092be68",
            "title": "Unleashing the Power of Shared Label Structures for Human Activity Recognition",
            "abstract": "Current human activity recognition (HAR) techniques regard activity labels as integer class IDs without explicitly modeling the semantics of class labels. We observe that different activity names often have shared structures. For example, \"open door\" and \"open fridge\" both have \"open\" as the action; \"kicking soccer ball\" and \"playing tennis ball\" both have \"ball\" as the object. Such shared structures in label names can be translated to the similarity in sensory data and modeling common structures would help uncover knowledge across different activities, especially for activities with limited samples. In this paper, we propose SHARE, a HAR framework that takes into account shared structures of label names for different activities. To exploit the shared structures, SHARE comprises an encoder for extracting features from input sensory time series and a decoder for generating label names as a token sequence. We also propose three label augmentation techniques to help the model more effectively capture semantic structures across activities, including a basic token-level augmentation, and two enhanced embedding-level and sequence-level augmentations utilizing the capabilities of pre-trained models. SHARE outperforms state-of-the-art HAR models in extensive experiments on seven HAR benchmark datasets. We also evaluate in few-shot learning and label imbalance settings and observe even more significant performance gap.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "70e5e9bd353d1b1e54b4eebd3a67b58026a13dff",
            "title": "PrimeNet: Pre-training for Irregular Multivariate Time Series",
            "abstract": "Real-world applications often involve irregular time series, for which the time intervals between successive observations are non-uniform. Irregularity across multiple features in a multi-variate time series further results in a different subset of features at any given time (i.e., asynchronicity). Existing pre-training schemes for time-series, however, often assume regularity of time series and make no special treatment of irregularity. We argue that such irregularity offers insight about domain property of the data\u2014for example, frequency of hospital visits may signal patient health condition\u2014that can guide representation learning. In this work, we propose PrimeNet to learn a self-supervised representation for irregular multivariate time-series. Specifically, we design a time sensitive contrastive learning and data reconstruction task to pre-train a model. Irregular time-series exhibits considerable variations in sampling density over time. Hence, our triplet generation strategy follows the density of the original data points, preserving its native irregularity. Moreover, the sampling density variation over time makes data reconstruction difficult for different regions. Therefore, we design a data masking technique that always masks a constant time duration to accommodate reconstruction for regions of different sampling density. We learn with these tasks using unlabeled data to build a pre-trained model and fine-tune on a downstream task with limited labeled data, in contrast with existing fully supervised approach for irregular time-series, requiring large amounts of labeled data. Experiment results show that PrimeNet significantly outperforms state-of-the-art methods on naturally irregular and asynchronous data from Healthcare and IoT applications for several downstream tasks, including classification, interpolation, and regression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "97483167",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "9bf1a897c6d6f959b0160c0cc1675f528b974b28",
            "title": "Minimally Supervised Contextual Inference from Human Mobility: An Iterative Collaborative Distillation Framework",
            "abstract": "The context about trips and users from mobility data is valuable for mobile service providers to understand their customers and improve their services. Existing inference methods require a large number of labels for training, which is hard to meet in practice. In this paper, we study a more practical yet challenging setting\u2014contextual inference using mobility data with minimal supervision (i.e., a few labels per class and massive unlabeled data). A typical solution is to apply semi-supervised methods that follow a self-training framework to bootstrap a model based on all features. However, using a limited labeled set brings high risk of overfitting to self-training, leading to unsatisfactory performance. We propose a novel collaborative distillation framework STCOLAB. It sequentially trains spatial and temporal modules at each iteration following the supervision of ground-truth labels. In addition, it distills knowledge to the module being trained using the logits produced by the latest trained module of the other modality, thereby mutually calibrating the two modules and combining the knowledge from both modalities. Extensive experiments on two real-world datasets show STCOLAB achieves significantly more accurate contextual inference than various baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "9d697c46e6fa79f4c3a283c7539cb58f8cd5e2e8",
            "title": "Federated Learning with Client-Exclusive Classes",
            "abstract": "Existing federated classification algorithms typically assume the local annotations at every client cover the same set of classes. In this paper, we aim to lift such an assumption and focus on a more general yet practical non-IID setting where every client can work on non-identical and even disjoint sets of classes (i.e., client-exclusive classes ), and the clients have a common goal which is to build a global classification model to identify the union of these classes. Such heterogeneity in client class sets poses a new challenge: how to ensure different clients are operating in the same latent space so as to avoid the drift after aggregation? We observe that the classes can be described in natural languages (i.e., class names) and these names are typically safe to share with all parties. Thus, we formulate the classification problem as a matching process between data representations and class representations and break the classification model into a data encoder and a label encoder. We leverage the natural-language class names as the common ground to anchor the class representations in the label encoder. In each iteration, the label encoder updates the class representations and regulates the data representations through matching. We further use the updated class representations at each round to annotate data samples for locally-unaware classes according to similarity and distill knowledge to local models. Extensive experiments on four real-world datasets show that the proposed method can outperform various classical and state-of-the-art federated learning methods designed for learning with non-IID data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108130022",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "b26182a81185552efaaec9e79579b333901410bd",
            "title": "Navigating Alignment for Non-identical Client Class Sets: A Label Name-Anchored Federated Learning Framework",
            "abstract": "Traditional federated classification methods, even those designed for non-IID clients, assume that each client annotates its local data with respect to the same universal class set. In this paper, we focus on a more general yet practical setting, non-identical client class sets, where clients focus on their own (different or even non-overlapping) class sets and seek a global model that works for the union of these classes. If one views classification as finding the best match between representations produced by data/label encoder, such heterogeneity in client class sets poses a new significant challenge-local encoders at different clients may operate in different and even independent latent spaces, making it hard to aggregate at the server. We propose a novel framework, FedAlign1, to align the latent spaces across clients from both label and data perspectives. From a label perspective, we leverage the expressive natural language class names as a common ground for label encoders to anchor class representations and guide the data encoder learning across clients. From a data perspective, during local training, we regard the global class representations as anchors and leverage the data points that are close/far enough to the anchors of locally-unaware classes to align the data encoders across clients. Our theoretical analysis of the generalization performance and extensive experiments on four real-world datasets of different tasks confirm that FedAlign outperforms various state-of-the-art (non-IID) federated classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "d16da2ad581945602b07c004039a1c717d1b1432",
            "title": "Rule-based Policy Regularization for Reinforcement Learning-based Building Control",
            "abstract": "Rule-based control (RBC) is widely adopted in buildings due to its stability and robustness. It resembles a behavior cloning methodology refined by human experts; however, it is incapable of adapting to distribution drifts. Reinforcement learning (RL) can adapt to changes but needs to learn from scratch in the online setting. On the other hand, the learning ability is limited in offline settings due to extrapolation errors caused by selecting out-of-distribution actions. In this paper, we explore how to incorporate RL with a rule-based control policy to combine their strengths to continuously learn a scalable and robust policy in both online and offline settings. We start with representative online and offline RL methods, TD3 and TD3+BC, respectively. Then, we develop a dynamically weighted actor loss function to selectively choose which policy for RL models to learn from at each training iteration. With extensive experiments across various weather conditions in both deterministic and stochastic scenarios, we demonstrate that our algorithm, rule-based incorporated control regularization (RUBICON), outperforms state-of-the-art methods in offline settings by and improves the baseline method by in online settings with respect to a reward consisting of thermal comfort and energy consumption in building-RL environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "95813069",
                    "name": "Hsin-Yu Liu"
                },
                {
                    "authorId": "144019834",
                    "name": "Bharathan Balaji"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "1a876b4f5c1be5c1471119dbb7fc4f7f13a57d53",
            "title": "ESC-GAN: Extending Spatial Coverage of Physical Sensors",
            "abstract": "Scientific discoveries and studies about our physical world have long benefited from large-scale and planetary sensing, from weather forecasting to wildfire monitoring. However, the limited deployment of sensors in the environment due to cost or physical access constraints has lagged behind our ever-growing need for increased data coverage and higher resolution, impeding timely and precise monitoring and understanding of the environment. Therefore, we seek to extend the spatial coverage of analysis based on existing sensory data, that is, to \"generate\" data for locations where no historical data exists. This problem is fundamentally different and more challenging than the traditional spatio-temporal imputation that assumes data for any particular location are only partially missing across time. Inspired by the success of Generative Adversarial Network (GAN) in imputation, we propose a novel ESC-GAN. We observe that there are local patterns in nearby locations, as well as trends in a global manner (e.g., temperature drops as altitude increases regardless of the location). As local patterns may exhibit at different scales (from meters to kilometers), we employ a multi-branch generator to aggregate information of different granularity. More specifically, each branch in the generator contains 1) randomly masked 3D partial convolutions at different resolutions to capture the local patterns and 2) global attention modules for global similarity. Next, we adversarially train a 3D convolution-based discriminator to distinguish the generator's output from the ground truth. Extensive experiments on three geo-sensor datasets demonstrate that ESC-GAN outperforms state-of-the-art methods on extending spatial coverage and also achieves the best results on a traditional spatio-temporal imputation task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2057080004",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "289c7bd0420a88bbff6b99826c2c03f15d9ba750",
            "title": "B2RL: an open-source dataset for building batch reinforcement learning",
            "abstract": "Batch reinforcement learning (BRL) is an emerging research area in the RL community. It learns exclusively from static datasets (i.e. replay buffers) without interaction with the environment. In the offline settings, existing replay experiences are used as prior knowledge for BRL models to find the optimal policy. Thus, generating replay buffers is crucial for BRL model benchmark. In our B2RL (Building Batch RL) dataset, we collected real-world data from our building management systems, as well as buffers generated by several behavioral policies in simulation environments. We believe it could help building experts on BRL research. To the best of our knowledge, we are the first to open-source building datasets for the purpose of BRL learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "95813069",
                    "name": "Hsin-Yu Liu"
                },
                {
                    "authorId": "2119033469",
                    "name": "Xiaohan Fu"
                },
                {
                    "authorId": "144019834",
                    "name": "Bharathan Balaji"
                },
                {
                    "authorId": "145504430",
                    "name": "Rajesh E. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "3848daf38c39983650a3f6ecb4ccd11dbfab757a",
            "title": "TARNet: Task-Aware Reconstruction for Time-Series Transformer",
            "abstract": "Time-series data contains temporal order information that can guide representation learning for predictive end tasks (e.g., classification, regression). Recently, there are some attempts to leverage such order information to first pre-train time-series models by reconstructing time-series values of randomly masked time segments, followed by an end-task fine-tuning on the same dataset, demonstrating improved end-task performance. However, this learning paradigm decouples data reconstruction from the end task. We argue that the representations learnt in this way are not informed by the end task and may, therefore, be sub-optimal for the end-task performance. In fact, the importance of different timestamps can vary significantly in different end tasks. We believe that representations learnt by reconstructing important timestamps would be a better strategy for improving end-task performance. In this work, we propose TARNet, Task-Aware Reconstruction Network, a new model using Transformers to learn task-aware data reconstruction that augments end-task performance. Specifically, we design a data-driven masking strategy that uses self-attention score distribution from end-task training to sample timestamps deemed important by the end task. Then, we mask out data at those timestamps and reconstruct them, thereby making the reconstruction task-aware. This reconstruction task is trained alternately with the end task at every epoch, sharing parameters in a single model, allowing the representation learnt through reconstruction to improve end-task performance. Extensive experiments on tens of classification and regression datasets show that TARNet significantly outperforms state-of-the-art baseline models across all evaluation metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        }
    ]
}