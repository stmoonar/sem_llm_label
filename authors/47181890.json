{
    "authorId": "47181890",
    "papers": [
        {
            "paperId": "10fd2f9b47da6c769dedd81125564ca21acc01c3",
            "title": "One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for Continual Learning",
            "abstract": "In real-world continual learning (CL) scenarios, tasks often exhibit intricate and unpredictable semantic shifts, posing challenges for fixed prompt management strategies which are tailored to only handle semantic shifts of uniform degree (i.e., uniformly mild or uniformly abrupt). To address this limitation, we propose an adaptive prompting approach that effectively accommodates semantic shifts of varying degree where mild and abrupt shifts are mixed. AdaPromptCL employs the assign-and-refine semantic grouping mechanism that dynamically manages prompt groups in accordance with the semantic similarity between tasks, enhancing the quality of grouping through continuous refinement. Our experiment results demonstrate that AdaPromptCL outperforms existing prompting methods by up to 21.3%, especially in the benchmark datasets with diverse semantic shifts between tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2267504094",
                    "name": "Youngjun Lee"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "ca622fde1f31e86a3328504c17605298c6129414",
            "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy",
            "abstract": "Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy and generalization performance. Extensive experiments on four real and one synthetic noisy datasets show that \\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as well as those with a standard model by up to 21.6%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2265081094",
                    "name": "Seola Choi"
                },
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "eaab62c1865f2359e98117f063e1190d16ec602a",
            "title": "Adaptive Shortcut Debiasing for Online Continual Learning",
            "abstract": "We propose a novel framework DropTop that suppresses the shortcut bias in online continual learning (OCL) while being adaptive to the varying degree of the shortcut bias incurred by continuously changing environment. By the observed high-attention property of the shortcut bias, highly-activated features are considered candidates for debiasing. More importantly, resolving the limitation of the online environment where prior knowledge and auxiliary data are not ready, two novel techniques---feature map fusion and adaptive intensity shifting---enable us to automatically determine the appropriate level and proportion of the candidate shortcut features to be dropped. Extensive experiments on five benchmark datasets demonstrate that, when combined with various OCL algorithms, DropTop increases the average accuracy by up to 10.4% and decreases the forgetting by up to 63.2%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "df2dc4370ae3c0b44566dd32e0e1aeadab5f4702",
            "title": "COVID-EENet: Predicting Fine-Grained Impact of COVID-19 on Local Economies",
            "abstract": "Assessing the impact of the COVID-19 crisis on economies is fundamental to tailor the responses of the governments to recover from the crisis. In this paper, we present a novel approach to assessing the economic impact with a large-scale credit card transaction dataset at a fine granularity. For this purpose, we develop a fine-grained economic-epidemiological modeling framework COVID-EENet, which is featured with a two-level deep neural network. In support of the fine-grained EEM, COVID-EENet learns the impact of nearby mass infection cases on the changes of local economies in each district. Through the experiments using the nationwide dataset, given a set of active mass infection cases, COVID-EENet is shown to precisely predict the sales changes in two or four weeks for each district and business category. Therefore, policymakers can be informed of the predictive impact to put in the most effective mitigation measures. Overall, we believe that our work opens a new perspective of using financial data to recover from the economic crisis. For public use in this urgent problem, we release the source code at https://github.com/kaist-dmlab/COVID-EENet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "1891408783",
                    "name": "Hyangsuk Min"
                },
                {
                    "authorId": "1900303688",
                    "name": "Youngeun Nam"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "084b10e890d07802936fc7f9dfa6d03bdbee3b9a",
            "title": "PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation",
            "abstract": "Point-of-interest (POI) recommendation has become an important research topic in these days. The user check-in history used as the input to POI recommendation is very imbalanced and noisy because of sparse and missing check-ins. Although sample reweighting is commonly adopted for addressing this challenge with the input data, its fixed weighting scheme is often inappropriate to deal with different characteristics of users or POIs. Thus, in this paper, we propose PREMERE, an adaptive weighting scheme based on meta-learning. Because meta-data is typically required by meta-learning but is inherently hard to obtain in POI recommendation, we self-generate the meta-data via self-ensembling. Furthermore, the meta-model architecture is extended to deal with the scarcity of check-ins. Thorough experiments show that replacing a weighting scheme with PREMERE boosts the performance of the state-of-the-art recommender algorithms by 2.36\u201326.9% on three benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "738c301780d48dc91a36e4609abba664de459908",
            "title": "Hi-COVIDNet: Deep Learning Approach to Predict Inbound COVID-19 Patients and Case Study in South Korea",
            "abstract": "The escalating crisis of COVID-19 has put people all over the world in danger. Owing to the high contagion rate of the virus, COVID-19 cases continue to increase globally. To further suppress the threat of the COVID-19 pandemic and minimize its damage, it is imperative that each country monitors inbound travelers. Moreover, given that resources for quarantine are often limited, they must be carefully allocated. In this paper, to aid in such allocation by predicting the number of inbound COVID-19 cases, we propose Hi-COVIDNet, which takes advantage of the geographic hierarchy. Hi-COVIDNet is based on a neural network with two-level components, namely, country-level and continent-level encoders, which understand the complex relationships among foreign countries and derive their respective contagion risk to the destination country. An in-depth case study in South Korea with real-world COVID-19 datasets confirmed the effectiveness and practicality of Hi-COVIDNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "153041205",
                    "name": "Junhyeok Kang"
                },
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "1891408783",
                    "name": "Hyangsuk Min"
                },
                {
                    "authorId": "1900303688",
                    "name": "Youngeun Nam"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        }
    ]
}