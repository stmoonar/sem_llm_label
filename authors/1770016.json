{
    "authorId": "1770016",
    "papers": [
        {
            "paperId": "22ec32d2669c3d9c7599906a2d364d78415df981",
            "title": "Enhancing Machine Learning Based SQL Injection Detection Using Contextualized Word Embedding",
            "abstract": "SQL injection (SQLi) attacks continue to severely threaten application security, allowing malicious actors to exploit web input and manipulate an application's database with malicious SQL code. This work explores the possibility of building effective SQLi detectors through machine learning. Specifically, we investigate the impact of contextualized and non-contextualized embedding methods for converting SQL queries into vector space. Our results demonstrate the superiority of the contextualized embedding method, achieving consistent accuracy above 99% across various classification algorithms and reducing model training time by 31 times. In addition, the analysis of reliability diagrams indicates that contextualized embeddings provide better model calibrations. These findings underscore the significance of contextualized word embeddings in enhancing the performance and reliability of SQLi detection models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266109036",
                    "name": "Janet Zulu"
                },
                {
                    "authorId": "2299291695",
                    "name": "Bonian Han"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "2275224682",
                    "name": "Gongbo Liang"
                }
            ]
        },
        {
            "paperId": "26b15f176b95a52a5b294d9c5e53d580c926dc42",
            "title": "Ensemble-based Cyber Intrusion Detection for Robust Smart City Protection",
            "abstract": "The rapid rise of 5G networks has accelerated the integration of smart cities, marking the emergence of increased intelligence in urban environments, often referred to as Smart Cities. This swift integration has interconnected a wide range of devices and systems, thereby exposing them to potential vulnerabilities. As a result, a smart urban landscape has emerged where valuable and sensitive information is shared without adequate attention to security considerations. Given these challenges, it is essential to implement an effective cloud-based Intrusion Detection System (IDS) for the security of smart cities. This work examines the reliability and robustness of various ensemble learning models, focusing on evaluating the performance and efficiency of an IDS strategy based on machine learning to enhance the security of IoT in smart urban networks. We conducted experimental procedures on three commonly used datasets to achieve the objectives of our study. The results obtained from these procedures are crucial for developing practical IDS solutions that address the ever-changing challenges posed by diverse, smart, cloud-based network traffic systems in smart cities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "89776598",
                    "name": "Alaa Alhowaide"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "2316070750",
                    "name": "Belal Alsinglawi"
                }
            ]
        },
        {
            "paperId": "92fd71b65aa911804b2e3769414bfb0f824d778a",
            "title": "Using Large Language Models in Public Transit Systems, San Antonio as a case study",
            "abstract": "The integration of large language models into public transit systems represents a significant advancement in urban transportation management and passenger experience. This study examines the impact of LLMs within San Antonio's public transit system, leveraging their capabilities in natural language processing, data analysis, and real time communication. By utilizing GTFS and other public transportation information, the research highlights the transformative potential of LLMs in enhancing route planning, reducing wait times, and providing personalized travel assistance. Our case study is the city of San Antonio as part of a project aiming to demonstrate how LLMs can optimize resource allocation, improve passenger satisfaction, and support decision making processes in transit management. We evaluated LLM responses to questions related to both information retrieval and also understanding. Ultimately, we believe that the adoption of LLMs in public transit systems can lead to more efficient, responsive, and user-friendly transportation networks, providing a model for other cities to follow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2311505053",
                    "name": "Ramya Jonnala"
                },
                {
                    "authorId": "2275224682",
                    "name": "Gongbo Liang"
                },
                {
                    "authorId": "2311564904",
                    "name": "Jeong Yang"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                }
            ]
        },
        {
            "paperId": "a379aa7c4a51f0068c485ca78b168263ea850c9f",
            "title": "Transforming Computer Security and Public Trust Through the Exploration of Fine-Tuning Large Language Models",
            "abstract": "Large language models (LLMs) have revolutionized how we interact with machines. However, this technological advancement has been paralleled by the emergence of\"Mallas,\"malicious services operating underground that exploit LLMs for nefarious purposes. Such services create malware, phishing attacks, and deceptive websites, escalating the cyber security threats landscape. This paper delves into the proliferation of Mallas by examining the use of various pre-trained language models and their efficiency and vulnerabilities when misused. Building on a dataset from the Common Vulnerabilities and Exposures (CVE) program, it explores fine-tuning methodologies to generate code and explanatory text related to identified vulnerabilities. This research aims to shed light on the operational strategies and exploitation techniques of Mallas, leading to the development of more secure and trustworthy AI applications. The paper concludes by emphasizing the need for further research, enhanced safeguards, and ethical guidelines to mitigate the risks associated with the malicious application of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2304493756",
                    "name": "Garrett Crumrine"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "2197778371",
                    "name": "Jesus Guerrero"
                },
                {
                    "authorId": "2034354265",
                    "name": "Yuvaraj Munian"
                }
            ]
        },
        {
            "paperId": "c4e3e08148a2b78a25bd79d9a98bb0bb07507f85",
            "title": "Predicting Question Quality on StackOverflow with Neural Networks",
            "abstract": "The wealth of information available through the Internet and social media is unprecedented. Within computing fields, websites such as Stack Overflow are considered important sources for users seeking solutions to their computing and programming issues. However, like other social media platforms, Stack Overflow contains a mixture of relevant and irrelevant information. In this paper, we evaluated neural network models to predict the quality of questions on Stack Overflow, as an example of Question Answering (QA) communities. Our results demonstrate the effectiveness of neural network models compared to baseline machine learning models, achieving an accuracy of 80%. Furthermore, our findings indicate that the number of layers in the neural network model can significantly impact its performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "70162761",
                    "name": "M. Al-Ramahi"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "1390578625",
                    "name": "A. Wahbeh"
                }
            ]
        },
        {
            "paperId": "dd4d62e2d927f610996bca5c9abd6824ede91adc",
            "title": "Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors",
            "abstract": "With the launch of ChatGPT, large language models (LLMs) have attracted global attention. In the realm of article writing, LLMs have witnessed extensive utilization, giving rise to concerns related to intellectual property protection, personal privacy, and academic integrity. In response, AI-text detection has emerged to distinguish between human and machine-generated content. However, recent research indicates that these detection systems often lack robustness and struggle to effectively differentiate perturbed texts. Currently, there is a lack of systematic evaluations regarding detection performance in real-world applications, and a comprehensive examination of perturbation techniques and detector robustness is also absent. To bridge this gap, our work simulates real-world scenarios in both informal and professional writing, exploring the out-of-the-box performance of current detectors. Additionally, we have constructed 12 black-box text perturbation methods to assess the robustness of current detection models across various perturbation granularities. Furthermore, through adversarial learning experiments, we investigate the impact of perturbation data augmentation on the robustness of AI-text detectors. We have released our code and data at https://github.com/zhouying20/ai-text-detector-evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278435713",
                    "name": "Albert Q. Jiang"
                },
                {
                    "authorId": "2256994781",
                    "name": "Alexandre Sablayrolles"
                },
                {
                    "authorId": "2304963186",
                    "name": "Arthur Men-702"
                },
                {
                    "authorId": "2256994975",
                    "name": "Chris Bamford"
                },
                {
                    "authorId": "2302815701",
                    "name": "Devendra Singh"
                },
                {
                    "authorId": "2302809975",
                    "name": "Diego Chaplot"
                },
                {
                    "authorId": "2237425585",
                    "name": "John Kirchenbauer"
                },
                {
                    "authorId": "2284863781",
                    "name": "Jonas Geiping"
                },
                {
                    "authorId": "123191916",
                    "name": "Yuxin Wen"
                },
                {
                    "authorId": "2203810783",
                    "name": "Khalid Saifullah"
                },
                {
                    "authorId": "2304963458",
                    "name": "Kezhi Kong"
                },
                {
                    "authorId": "2304962931",
                    "name": "Kasun Fernando"
                },
                {
                    "authorId": "2056290221",
                    "name": "Aniruddha Saha"
                },
                {
                    "authorId": "121592562",
                    "name": "Micah Goldblum"
                },
                {
                    "authorId": "40899329",
                    "name": "Tharindu Kumarage"
                },
                {
                    "authorId": "73409823",
                    "name": "Paras Sheth"
                },
                {
                    "authorId": "11064745",
                    "name": "Raha Moraffah"
                },
                {
                    "authorId": "46853620",
                    "name": "T. Lavergne"
                },
                {
                    "authorId": "2827705",
                    "name": "Tanguy Urvoy"
                },
                {
                    "authorId": "2304964852",
                    "name": "Fran\u00e7ois Yvon"
                },
                {
                    "authorId": "2261973116",
                    "name": "Mike Lewis"
                },
                {
                    "authorId": "11323179",
                    "name": "Yinhan Liu"
                },
                {
                    "authorId": "2277123641",
                    "name": "Marjan Naman Goyal"
                },
                {
                    "authorId": "2277128824",
                    "name": "Abdelrahman Ghazvininejad"
                },
                {
                    "authorId": "2277123536",
                    "name": "Omer Mohamed"
                },
                {
                    "authorId": "2277129332",
                    "name": "Levy"
                },
                {
                    "authorId": "2275224682",
                    "name": "Gongbo Liang"
                },
                {
                    "authorId": "2197778371",
                    "name": "Jesus Guerrero"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "40511414",
                    "name": "Myle Ott"
                },
                {
                    "authorId": "3048577",
                    "name": "Jingfei Du"
                },
                {
                    "authorId": "2285032310",
                    "name": "Mandar Joshi"
                },
                {
                    "authorId": "2255489905",
                    "name": "Danqi Chen"
                },
                {
                    "authorId": "2253752918",
                    "name": "Omer Levy"
                }
            ]
        },
        {
            "paperId": "ed205c653c706dde5c7976ce890ca9dc4a51ca1c",
            "title": "Cyber Ready Rural: Understanding Law Enforcement Cyber Readiness",
            "abstract": "As rural communities increasingly become inter-connected through digital platforms, law enforcement agencies face unprecedented challenges in safeguarding their jurisdictions against cyber threats. This study delves into the concept of \u201cCyber Ready Rural,\u201d examining the cyber readiness of law enforcement agencies operating in rural settings. The research explores the unique dynamics, constraints, and opportunities that shape the cybersecurity landscape in rural areas, emphasizing the need for tailored strategies to enhance law enforcement's preparedness for cyber threats. Ultimately, the study aspires to offer actionable recommendations that empower rural law enforcement agencies to navigate the evolving cyber landscape effectively. By fostering a deeper understanding of the challenges and opportunities inherent in securing rural communities against cyber threats, this research aims to assist policymakers, law enforcement leaders, and cy-bersecurity professionals in formulating informed strategies that ensure a Cyber Ready Rural future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301347207",
                    "name": "Lucy Tsado"
                },
                {
                    "authorId": "2301344058",
                    "name": "Camille Gibson"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "2301342666",
                    "name": "Janaya Bob"
                }
            ]
        },
        {
            "paperId": "2f8ca761d8910775c1d79821a958af7dbb4222a6",
            "title": "A Review on Searchable Encryption Functionality and the Evaluation of Homomorphic Encryption",
            "abstract": "Cloud Service Providers, exemplified by industry leaders like Google Cloud Platform, Microsoft Azure, and Amazon Web Services, deliver a dynamic array of cloud services in an ever-evolving landscape. This sector is witnessing substantial growth, with enterprises such as Netflix and PayPal heavily relying on cloud infrastructure for various needs such as data storage, computational resources, and various other services. The adoption of cloud solutions by businesses not only facilitates cost reduction but also fosters flexibility and supports scalability. Despite the undeniable advantages, concerns surrounding security and privacy persist in the realm of Cloud Computing. Given that Cloud services are accessible via the internet, there is a potential vulnerability to unauthorized access by hackers or malicious entities from anywhere in the world. A crucial aspect of addressing this challenge is the implementation of robust security measures, particularly focusing on data protection. To safeguard data in the Cloud, a fundamental recommendation is the encryption of data prior to uploading. Encryption should be maintained consistently, both during storage and in transit. While encryption enhances security, it introduces a potential challenge for data owners who may need to perform various operations on their encrypted data, such as accessing, modifying, updating, deleting, reading, searching, or sharing them with others. One viable solution to balance the need for data security and operational functionality is the adoption of Searchable Encryption (SE). SE operates on encrypted data, allowing authorized users to perform certain operations without compromising the security of sensitive information. The effectiveness of SE has notably advanced since its inception, and ongoing research endeavors aim to further enhance its capabilities. This paper provides a comprehensive review of the functionality of Searchable Encryption, with a primary focus on its applications in Cloud services during the period spanning 2019 to 2023. Additionally, the study evaluates one of its prominent schemes, namely Fully Homomorphic Encryption (FHE). The analysis indicates an overall positive trajectory in SE research, showcasing increased efficiency as multiple functionalities are aggregated and rigorously tested.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2211799114",
                    "name": "Brian Kishiyama"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                }
            ]
        },
        {
            "paperId": "374ff52faeea2a519a3b8eafcf0fc10e9e1b96ad",
            "title": "Adversarial NLP for Social Network Applications: Attacks, Defenses, and Research Directions",
            "abstract": "The growing use of media has led to the development of several machine learning (ML) and natural language processing (NLP) tools to process the unprecedented amount of social media content to make actionable decisions. However, these ML and NLP algorithms have been widely shown to be vulnerable to adversarial attacks. These vulnerabilities allow adversaries to launch a diversified set of adversarial attacks on these algorithms in different applications of social media text processing. In this article, we provide a comprehensive review of the main approaches for adversarial attacks and defenses in the context of social media applications with a particular focus on key challenges and future research directions. In detail, we cover literature on six key applications: 1) rumors detection; 2) satires detection; 3) clickbaits and spams identification; 4) hate speech detection; 5) misinformation detection; and 6) sentiment analysis. We then highlight the concurrent and anticipated future research questions and provide recommendations and directions for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "143623051",
                    "name": "Kashif Ahmad"
                },
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "1404786833",
                    "name": "Ala I. Al-Fuqaha"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "3027509",
                    "name": "A. Algosaibi"
                }
            ]
        },
        {
            "paperId": "b3372bb75a5f3baaceb028a83ce8f0ec0805a255",
            "title": "Warm-Starting for Improving the Novelty of Abstractive Summarization",
            "abstract": "Abstractive summarization is distinguished by using novel phrases that are not found in the source text. However, most previous research ignores this feature in favour of enhancing syntactical similarity with the reference. To improve novelty aspects, we have used multiple warm-started models with varying encoder and decoder checkpoints and vocabulary. These models are then adapted to the paraphrasing task and the sampling decoding strategy to further boost the levels of novelty and quality. In addition, to avoid relying only on the syntactical similarity assessment, two additional abstractive summarization metrics are introduced: 1) NovScore: a new novelty metric that delivers a summary novelty score; and 2) NSSF: a new comprehensive metric that ensembles Novelty, Syntactic, Semantic, and Faithfulness features into a single score to simulate human assessment in providing a reliable evaluation. Finally, we compare our models to the state-of-the-art sequence-to-sequence models using the current and the proposed metrics. As a result, warm-starting, sampling, and paraphrasing improve novelty degrees by 2%, 5%, and 14%, respectively, while maintaining comparable scores on other metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130042263",
                    "name": "Ayham Alomari"
                },
                {
                    "authorId": "1403466899",
                    "name": "A. S. Al-Shamayleh"
                },
                {
                    "authorId": "36826893",
                    "name": "N. Idris"
                },
                {
                    "authorId": "2049063550",
                    "name": "Aznul Qalid Md Sabri"
                },
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "2182454665",
                    "name": "Danah Omary"
                }
            ]
        }
    ]
}