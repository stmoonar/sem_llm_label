{
    "authorId": "1502765940",
    "papers": [
        {
            "paperId": "52a857b64992012016501961a3425ea356bdcc02",
            "title": "SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions",
            "abstract": "With the widespread application of artificial intelligence (AI), particularly deep learning (DL) and vision-based large language models (VLLMs), in skin disease diagnosis, the need for interpretability becomes crucial. However, existing dermatology datasets are limited in their inclusion of concept-level meta-labels, and none offer rich medical descriptions in natural language. This deficiency impedes the advancement of LLM-based methods in dermatological diagnosis. To address this gap and provide a meticulously annotated dermatology dataset with comprehensive natural language descriptions, we introduce SkinCAP: a multi-modal dermatology dataset annotated with rich medical captions. SkinCAP comprises 4,000 images sourced from the Fitzpatrick 17k skin disease dataset and the Diverse Dermatology Images dataset, annotated by board-certified dermatologists to provide extensive medical descriptions and captions. Notably, SkinCAP represents the world's first such dataset and is publicly available at https://huggingface.co/datasets/joshuachou/SkinCAP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "2262402779",
                    "name": "Liyuan Sun"
                },
                {
                    "authorId": "2303833541",
                    "name": "Yan Xu"
                },
                {
                    "authorId": "2303611974",
                    "name": "Wenbin Liu"
                },
                {
                    "authorId": "2303462846",
                    "name": "Shawn Afvari"
                },
                {
                    "authorId": "2279914462",
                    "name": "Zhongyi Han"
                },
                {
                    "authorId": "2303674473",
                    "name": "Jiaoyan Song"
                },
                {
                    "authorId": "2303964488",
                    "name": "Yongzhi Ji"
                },
                {
                    "authorId": "2262512290",
                    "name": "Xiaonan He"
                },
                {
                    "authorId": "2254373994",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "6dcc524fcd56dec219c3160824049a9182538888",
            "title": "HELM-GPT: de novo macrocyclic peptide design using generative pre-trained transformer",
            "abstract": "Abstract Motivation Macrocyclic peptides hold great promise as therapeutics targeting intracellular proteins. This stems from their remarkable ability to bind flat protein surfaces with high affinity and specificity while potentially traversing the cell membrane. Research has already explored their use in developing inhibitors for intracellular proteins, such as KRAS, a well-known driver in various cancers. However, computational approaches for de novo macrocyclic peptide design remain largely unexplored. Results Here, we introduce HELM-GPT, a novel method that combines the strength of the hierarchical editing language for macromolecules (HELM) representation and generative pre-trained transformer (GPT) for de novo macrocyclic peptide design. Through reinforcement learning (RL), our experiments demonstrate that HELM-GPT has the ability to generate valid macrocyclic peptides and optimize their properties. Furthermore, we introduce a contrastive preference loss during the RL process, further enhanced the optimization performance. Finally, to co-optimize peptide permeability and KRAS binding affinity, we propose a step-by-step optimization strategy, demonstrating its effectiveness in generating molecules fulfilling both criteria. In conclusion, the HELM-GPT method can be used to identify novel macrocyclic peptides to target intracellular proteins. Availability and implementation The code and data of HELM-GPT are freely available on GitHub (https://github.com/charlesxu90/helm-gpt).",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142540079",
                    "name": "Xiaopeng Xu"
                },
                {
                    "authorId": "2306245483",
                    "name": "Chencheng Xu"
                },
                {
                    "authorId": "2256740529",
                    "name": "Wenjia He"
                },
                {
                    "authorId": "2306159083",
                    "name": "Lesong Wei"
                },
                {
                    "authorId": "2307185284",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "2265715482",
                    "name": "Ruochi Zhang"
                },
                {
                    "authorId": "2153610377",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2282356598",
                    "name": "Yuanpeng Xiong"
                },
                {
                    "authorId": "2260728623",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "9efe1a3ff07b2255b506d1bf0c0379474746054b",
            "title": "ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering",
            "abstract": "Question Answering (QA) effectively evaluates language models' reasoning and knowledge depth. While QA datasets are plentiful in areas like general domain and biomedicine, academic chemistry is less explored. Chemical QA plays a crucial role in both education and research by effectively translating complex chemical information into readily understandable format. Addressing this gap, we introduce ScholarChemQA, a large-scale QA dataset constructed from chemical papers. This dataset reflects typical real-world challenges, including an imbalanced data distribution and a substantial amount of unlabeled data that can be potentially useful. Correspondingly, we introduce a QAMatch model, specifically designed to effectively answer chemical questions by fully leveraging our collected data. We first address the issue of imbalanced label distribution by re-weighting the instance-wise loss based on the inverse frequency of each class, ensuring minority classes are not dominated by majority ones during optimization. Next, we utilize the unlabeled data to enrich the learning process, generating a variety of augmentations based on a SoftMix operation and ensuring their predictions align with the same target, i.e., pseudo-labels. To ensure the quality of the pseudo-labels, we propose a calibration procedure aimed at closely aligning the pseudo-label estimates of individual samples with a desired ground truth distribution. Experiments show that our QAMatch significantly outperforms the recent similar-scale baselines and Large Language Models (LLMs) not only on our ScholarChemQA dataset but also on four benchmark datasets. We hope our benchmark and model can facilitate and promote more research on chemical QA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257124794",
                    "name": "Xiuying Chen"
                },
                {
                    "authorId": "2285000293",
                    "name": "Tairan Wang"
                },
                {
                    "authorId": "2179710545",
                    "name": "Taicheng Guo"
                },
                {
                    "authorId": "2256989341",
                    "name": "Kehan Guo"
                },
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "1499279004",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "1722264111",
                    "name": "Mingchen Zhuge"
                },
                {
                    "authorId": "2311440772",
                    "name": "Jurgen Schmidhuber"
                },
                {
                    "authorId": "2281910084",
                    "name": "Xin Gao"
                },
                {
                    "authorId": "2258447205",
                    "name": "Xiangliang Zhang"
                }
            ]
        },
        {
            "paperId": "d2ce3deb40b4b3099e014c651c33dbe210bfee56",
            "title": "Deep learning-driven pulmonary arteries and veins segmentation reveals demography-associated pulmonary vasculature anatomy",
            "abstract": "Pulmonary artery-vein segmentation is crucial for diagnosing pulmonary diseases and surgical planning, and is traditionally achieved by Computed Tomography Pulmonary Angiography (CTPA). However, concerns regarding adverse health effects from contrast agents used in CTPA have constrained its clinical utility. In contrast, identifying arteries and veins using non-contrast CT, a conventional and low-cost clinical examination routine, has long been considered impossible. Here we propose a High-abundant Pulmonary Artery-vein Segmentation (HiPaS) framework achieving accurate artery-vein segmentation on both non-contrast CT and CTPA across various spatial resolutions. HiPaS first performs spatial normalization on raw CT scans via a super-resolution module, and then iteratively achieves segmentation results at different branch levels by utilizing the low-level vessel segmentation as a prior for high-level vessel segmentation. We trained and validated HiPaS on our established multi-centric dataset comprising 1,073 CT volumes with meticulous manual annotation. Both quantitative experiments and clinical evaluation demonstrated the superior performance of HiPaS, achieving a dice score of 91.8% and a sensitivity of 98.0%. Further experiments demonstrated the non-inferiority of HiPaS segmentation on non-contrast CT compared to segmentation on CTPA. Employing HiPaS, we have conducted an anatomical study of pulmonary vasculature on 10,613 participants in China (five sites), discovering a new association between pulmonary vessel abundance and sex and age: vessel abundance is significantly higher in females than in males, and slightly decreases with age, under the controlling of lung volumes (p<0.0001). HiPaS realizing accurate artery-vein segmentation delineates a promising avenue for clinical diagnosis and understanding pulmonary physiology in a non-invasive manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2918346",
                    "name": "Gongning Luo"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "46179154",
                    "name": "Shaodong Cao"
                },
                {
                    "authorId": "2296138398",
                    "name": "Guolin Ma"
                },
                {
                    "authorId": "2296129078",
                    "name": "Xianglin Meng"
                },
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "2296664618",
                    "name": "Changchun Yang"
                },
                {
                    "authorId": "2269547024",
                    "name": "Dexuan Xie"
                },
                {
                    "authorId": "2295987429",
                    "name": "Ricardo Henao"
                },
                {
                    "authorId": "2296478530",
                    "name": "Xigang Xiao"
                },
                {
                    "authorId": "2296240078",
                    "name": "Lianming Wu"
                },
                {
                    "authorId": "2254314887",
                    "name": "Zhaowen Qiu"
                },
                {
                    "authorId": "2254373994",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "27387572208cf777fb2c55db8880dd5407d0e779",
            "title": "Personalized and privacy-preserving federated heterogeneous medical image analysis with PPPML-HMI",
            "abstract": "Heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging. However, there are few open-source frameworks for federated heterogeneous medical image analysis with personalization and privacy protection without the demand to modify the existing model structures or to share any private data. In this paper, we proposed PPPML-HMI, a novel open-source learning paradigm for personalized and privacy-preserving federated heterogeneous medical image analysis. To our best knowledge, personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the PerFedAvg algorithm and designing the novel cyclic secure aggregation with the homomorphic encryption algorithm. To show the utility of PPPML-HMI, we applied it to a simulated classification task namely the classification of healthy people and patients from the RAD-ChestCT Dataset, and one real-world segmentation task namely the segmentation of lung infections from COVID-19 CT scans. For the real-world task, PPPML-HMI achieved $sim$5% higher Dice score on average compared to conventional FL under the heterogeneous scenario. Meanwhile, we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the strong privacy-preserving capability of PPPML-HMI. By applying PPPML-HMI to both tasks with different neural networks, a varied number of users, and sample sizes, we further demonstrated the strong generalizability of PPPML-HMI.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2161017247",
                    "name": "Di Wang"
                },
                {
                    "authorId": "2142540079",
                    "name": "Xiaopeng Xu"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2028962393",
                    "name": "Wenkai Han"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "27d0d2923a42bd2bced1b100844e232ff87368e3",
            "title": "SkinGPT-4: An Interactive Dermatology Diagnostic System with Visual Large Language Model",
            "abstract": "Skin and subcutaneous diseases rank high among the leading contributors to the global burden of nonfatal diseases, impacting a considerable portion of the population. Nonetheless, the field of dermatology diagnosis faces three significant hurdles. Firstly, there is a shortage of dermatologists accessible to diagnose patients, particularly in rural regions. Secondly, accurately interpreting skin disease images poses a considerable challenge. Lastly, generating patient-friendly diagnostic reports is usually a time-consuming and labor-intensive task for dermatologists. To tackle these challenges, we present SkinGPT-4, which is the world's first interactive dermatology diagnostic system powered by an advanced visual large language model. SkinGPT-4 leverages a fine-tuned version of MiniGPT-4, trained on an extensive collection of skin disease images (comprising 52,929 publicly available and proprietary images) along with clinical concepts and doctors' notes. We designed a two-step training process to allow SkinGPT to express medical features in skin disease images with natural language and make accurate diagnoses of the types of skin diseases. With SkinGPT-4, users could upload their own skin photos for diagnosis, and the system could autonomously evaluate the images, identifies the characteristics and categories of the skin conditions, performs in-depth analysis, and provides interactive treatment recommendations. Meanwhile, SkinGPT-4's local deployment capability and commitment to user privacy also render it an appealing choice for patients in search of a dependable and precise diagnosis of their skin ailments. To demonstrate the robustness of SkinGPT-4, we conducted quantitative evaluations on 150 real-life cases, which were independently reviewed by certified dermatologists, and showed that SkinGPT-4 could provide accurate diagnoses of skin diseases. Though SkinGPT-4 is not a substitute for doctors, it could enhance users' comprehension of their medical conditions, facilitate improve communication between patients and doctors, expedite the diagnostic process for dermatologists, and potentially promote human-centred care and healthcare equity in underdeveloped areas.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "3455313",
                    "name": "Xiao-Zhen He"
                },
                {
                    "authorId": "46732892",
                    "name": "Liyuan Sun"
                },
                {
                    "authorId": "2293560831",
                    "name": "Jiannan Xu"
                },
                {
                    "authorId": "46772896",
                    "name": "Xiuying Chen"
                },
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "51072831",
                    "name": "Xingyu Liao"
                },
                {
                    "authorId": "2119454424",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "7562e25b666cba841b1dd5cf6e700978922beb04",
            "title": "SkinGPT: A Dermatology Diagnostic System with Vision Large Language Model",
            "abstract": "\u2014Skin and subcutaneous diseases are among the major causes of the nonfatal disease burden worldwide, affecting a signi\ufb01cant proportion of the population. However, there are three major challenges in the \ufb01eld of dermatology diagnosis. Firstly, there is a shortage of dermatologists available to diagnose patients. Secondly, accurately diagnosing dermatological pictures can be challenging. Lastly, providing user-friendly diagnostic reports can be dif\ufb01cult. Recent advancements in the \ufb01eld of large language models (LLMs) have shown potential for clinical applications. However, current LLMs have dif\ufb01culty processing images, and there are potential privacy concerns associated with using ChatGPT\u2019s API for uploading data. In this paper, we propose SkinGPT, which is the \ufb01rst dermatology diagnostic system that utilizes an advanced vision-based large language model. SkinGPT is the \ufb01rst system of its kind, incorporating a \ufb01ne-tuned version of MiniGPT-4 with a vast collection of in-house skin disease images, accompanied by doctor\u2019s notes. With SkinGPT, users can upload their own skin photos for diagnosis, and the system can autonomously determine the characteristics and categories of skin conditions, perform analysis, and provide treatment recommendations. The ability to deploy it locally and protect user privacy makes SkinGPT an attractive option for patients seeking an accurate and reliable diagnosis of their skin conditions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "7839d037bb0e41f8a9898f177d2710cfe23633fc",
            "title": "Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest Cost",
            "abstract": "Medical artificial general intelligence (AGI) is an emerging field that aims to develop systems specifically designed for medical applications that possess the ability to understand, learn, and apply knowledge across a wide range of tasks and domains. Large language models (LLMs) represent a significant step towards AGI. However, training cross-domain LLMs in the medical field poses significant challenges primarily attributed to the requirement of collecting data from diverse domains. This task becomes particularly difficult due to privacy restrictions and the scarcity of publicly available medical datasets. Here, we propose Medical AGI (MedAGI), a paradigm to unify domain-specific medical LLMs with the lowest cost, and suggest a possible path to achieve medical AGI. With an increasing number of domain-specific professional multimodal LLMs in the medical field being developed, MedAGI is designed to automatically select appropriate medical models by analyzing users' questions with our novel adaptive expert selection algorithm. It offers a unified approach to existing LLMs in the medical field, eliminating the need for retraining regardless of the introduction of new models. This characteristic renders it a future-proof solution in the dynamically advancing medical domain. To showcase the resilience of MedAGI, we conducted an evaluation across three distinct medical domains: dermatology diagnosis, X-ray diagnosis, and analysis of pathology pictures. The results demonstrated that MedAGI exhibited remarkable versatility and scalability, delivering exceptional performance across diverse domains. Our code is publicly available to facilitate further research at https://github.com/JoshuaChou2018/MedAGI.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "46772896",
                    "name": "Xiuying Chen"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "9d6b5bd74f17b2768290189f6548312df83abb67",
            "title": "A unified method to revoke the private data of patients in intelligent healthcare with audit to forget",
            "abstract": "Revoking personal private data is one of the basic human rights, which has already been sheltered by several privacy-preserving laws in many countries. However, with the development of data science, machine learning and deep learning techniques, this right is usually neglected or violated as more and more patients\u2019 data are being collected and used for model training, especially in intelligent healthcare, thus making intelligent healthcare a sector where technology must meet the law, regulations, and privacy principles to ensure that the innovation is for the common good. In order to secure patients\u2019 right to be forgotten, we proposed a novel solution by using auditing to guide the forgetting process, where auditing means determining whether a dataset has been used to train the model and forgetting requires the information of a query dataset to be forgotten from the target model. We unified these two tasks by introducing a new approach called knowledge purification. To implement our solution, we developed AFS, a unified open-source software, which is able to evaluate and revoke patients\u2019 private data from pre-trained deep learning models. We demonstrated the generality of AFS by applying it to four tasks on different datasets with various data sizes and architectures of deep learning networks. The software is publicly available at https://github.com/JoshuaChou2018/AFS.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "51072831",
                    "name": "Xingyu Liao"
                },
                {
                    "authorId": "2119454424",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": null,
                    "name": "Wenjia He"
                },
                {
                    "authorId": "66545108",
                    "name": "Zhongxiao Li"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "9ab09643688e4acbc0e26fd00e2171cce5dc7d0e",
            "title": "SD2: spatially resolved transcriptomics deconvolution through integration of dropout and spatial information",
            "abstract": "Abstract Motivation Unveiling the heterogeneity in the tissues is crucial to explore cell\u2013cell interactions and cellular targets of human diseases. Spatial transcriptomics (ST) supplies spatial gene expression profile which has revolutionized our biological understanding, but variations in cell-type proportions of each spot with dozens of cells would confound downstream analysis. Therefore, deconvolution of ST has been an indispensable step and a technical challenge toward the higher-resolution panorama of tissues. Results Here, we propose a novel ST deconvolution method called SD2 integrating spatial information of ST data and embracing an important characteristic, dropout, which is traditionally considered as an obstruction in single-cell RNA sequencing data (scRNA-seq) analysis. First, we extract the dropout-based genes as informative features from ST and scRNA-seq data by fitting a Michaelis\u2013Menten function. After synthesizing pseudo-ST spots by randomly composing cells from scRNA-seq data, auto-encoder is applied to discover low-dimensional and non-linear representation of the real- and pseudo-ST spots. Next, we create a graph containing embedded profiles as nodes, and edges determined by transcriptional similarity and spatial relationship. Given the graph, a graph convolutional neural network is used to predict the cell-type compositions for real-ST spots. We benchmark the performance of SD2 on the simulated seqFISH+ dataset with different resolutions and measurements which show superior performance compared with the state-of-the-art methods. SD2 is further validated on three real-world datasets with different ST technologies and demonstrates the capability to localize cell-type composition accurately with quantitative evidence. Finally, ablation study is conducted to verify the contribution of different modules proposed in SD2. Availability and implementation The SD2 is freely available in github (https://github.com/leihouyeung/SD2) and Zenodo (https://doi.org/10.5281/zenodo.7024684). Supplementary information Supplementary data are available at Bioinformatics online.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2184423698",
                    "name": "Hanmin Li"
                },
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "2156258219",
                    "name": "Xin Gao"
                }
            ]
        }
    ]
}