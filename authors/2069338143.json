{
    "authorId": "2069338143",
    "papers": [
        {
            "paperId": "c73146cf9f1284a5aaf3eec0d13215191489de13",
            "title": "Equitable Top-k Results for Long Tail Data",
            "abstract": "For datasets exhibiting long tail phenomenon, we identify a fairness concern in existing top-k algorithms, that return a \"fixed\" set of k results for a given query. This causes a handful of popular records (products, items, etc) getting overexposed and always be returned to the user query, whereas, there exists a long tail of niche records that may be equally desirable (have similar utility). To alleviate this, we propose \u03b8-Equiv-top-k-MMSP inside existing top-k algorithms - instead of returning a fixed top-k set, it generates all (or many) top-k sets that are equivalent in utility and creates a probability distribution over those sets. The end user will be returned one of these sets during the query time proportional to its associated probability, such that, after many draws from many end users, each record will have as equal exposure as possible (governed by uniform selection probability). \u03b8-Equiv-top-k-MMSP is formalized with two sub-problems. (a) \u03b8-Equiv-top-k-Sets to produce a set S of sets, each set has k records, where the sets are equivalent in utility with the top-k set; (b) MaxMinFair to produce a probability distribution over S, that is, PDF(S), such that the records in S have uniform selection probability. We formally study the hardness of \u03b8-Equiv-top-k-MMSP. We present multiple algorithmic results - (a) An exact solution for \u03b8-Equiv-top-k-Sets, and MaxMinFair. (b) We design highly scalable algorithms that solve \u03b8-Equiv-top-k-Sets through a random walk and is backed by probability theory, as well as a greedy solution designed for MaxMinFair. (c) We finally present an adaptive random walk based algorithm that solves \u03b8-Equiv-top-k-Sets and MaxMinFair at the same time. We empirically study how \u03b8-Equiv-top-k-MMSP can alleviate a equitable exposure concerns that group fairness suffers from. We run extensive experiments using 6 datasets and design intuitive baseline algorithms that corroborate our theoretical analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157481581",
                    "name": "Md Mouinul Islam"
                },
                {
                    "authorId": "2069338143",
                    "name": "Mahsa Asadi"
                },
                {
                    "authorId": "2034201368",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "6759d5855e8b184352bfb347255c4ed69e5aefd7",
            "title": "A Scalable Method for One-Mode Projection of Bipartite Networks Based on Hadoop Platform",
            "abstract": "People look for models and methods to organize, classify, compress and filter the information due to the difficulty in maintenance and using immense sources of information. The bipartite graphs are particularly useful among the variety of presenting methods such as recommender systems. Most of the bipartite networks tend to cluster one side of graph behavior to recognize communications and interactions between members of that side and discover similar members. The one-mode projection technique is widely used for this purpose. However, parts of the primary information of the original bipartite graph is missed under the projection. So we need to exploit a method for determining the weights that yield projected edges in a way that minimizes information loss. While such methods exist, the majority of investigated databases in the field of bipartite network projection are huge, consequently, executing a projection procedure takes lots of times. In this paper, we propose a scalable method based on resource allocation for bipartite network projection. It provides a high performance while preserving precision through transferring the needed operations on a distributed platform like Hadoop. Moreover, as a case study, we evaluate the performance of the presented scalable algorithm in the field of social network which results in short projection operation time in comparison to the undistributed mode. Also, we compared our proposed method with a collaborative filtering method, a well-known algorithm in the recommendation field and as a result, our method had higher overall execution speed. With using the largest dataset of our experiments, the Orkut dataset, the proposed method has higher speed than the scalable CF by 33 %. Then, we evaluate the scalability of the introduced method by a scalability metric namely Speedup, which showed good scalability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069338143",
                    "name": "Mahsa Asadi"
                },
                {
                    "authorId": "145254791",
                    "name": "Nasser Ghadiri"
                },
                {
                    "authorId": "3407734",
                    "name": "M. Nikbakht"
                }
            ]
        },
        {
            "paperId": "8d01e8214211943b12e6d0215f6d3dc1ede4860a",
            "title": "Fast and scalable protein motif sequence clustering based on Hadoop framework",
            "abstract": "In recent years, we are faced with large amounts of sporadic unstructured data on the web. With the explosive growth of such data, there is a growing need for effective methods such as clustering to analyze and extract information. Biological data forms an important part of unstructured data on the web. Protein sequence databases are considered as a primary source of biological data. Clustering can help to organize sequences into homologous and functionally similar groups and can improve the speed of data processing and analysis. Proteins are responsible for most of the activities in cells. The majority of proteins show their function through interaction with other proteins. Hence, prediction of protein interactions is an important research area in the biomedical sciences. Motifs are fragments frequently occurred in protein sequences. A well- known method to specify the protein interaction is based on motif Clustering. Existing works on motif clustering methods share the problem of limitation in the number of clusters. However, regarding the vast amount of motifs and the necessity of a large number of clusters, it seems that an efficient, scalable and fast method is necessary to cluster such large number of sequences. In this paper, we propose a novel approach to cluster a large number of motifs. Our approach includes extracting motifs within protein sequences, feature selection, preprocessing, dimension reduction and utilizing BigFCM (a large-scale fuzzy clustering) on several distributed nodes with Hadoop framework to take the advantage of MapReduce Programming. Experimental Results show very good Performance of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40330710",
                    "name": "Erfan Farhangi"
                },
                {
                    "authorId": "145254791",
                    "name": "Nasser Ghadiri"
                },
                {
                    "authorId": "2069338143",
                    "name": "Mahsa Asadi"
                },
                {
                    "authorId": "3407734",
                    "name": "M. Nikbakht"
                },
                {
                    "authorId": "2192078",
                    "name": "Sylvain Pitre"
                }
            ]
        }
    ]
}