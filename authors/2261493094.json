{
    "authorId": "2261493094",
    "papers": [
        {
            "paperId": "4f452e6a453f4ccd8f6c1960a8291a0ad8e4c2ee",
            "title": "Exploring the Limitations of Detecting Machine-Generated Text",
            "abstract": "Recent improvements in the quality of the generations by large language models have spurred research into identifying machine-generated text. Systems proposed for the task often achieve high performance. However, humans and machines can produce text in different styles and in different domains, and it remains unclear whether machine generated-text detection models favour particular styles or domains. In this paper, we critically examine the classification performance for detecting machine-generated text by evaluating on texts with varying writing styles. We find that classifiers are highly sensitive to stylistic changes and differences in text complexity, and in some cases degrade entirely to random classifiers. We further find that detection systems are particularly susceptible to misclassify easy-to-read texts while they have high performance for complex texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2261493094",
                    "name": "Hawau Olamide Toyin"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2138053020",
                    "name": "Zeerak Talat"
                }
            ]
        },
        {
            "paperId": "59d7714fd2a0160c938af5340c223eae6f8099dd",
            "title": "ArTST: Arabic Text and Speech Transformer",
            "abstract": "We present ArTST, a pre-trained Arabic text and speech transformer for supporting open-source speech technologies for the Arabic language. The model architecture follows the unified-modal framework, SpeechT5, that was recently released for English, and is focused on Modern Standard Arabic (MSA), with plans to extend the model for dialectal and code-switched Arabic in future editions. We pre-trained the model from scratch on MSA speech and text data, and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR), Text-To-Speech synthesis (TTS), and spoken dialect identification. In our experiments comparing ArTST with SpeechT5, as well as with previously reported results in these tasks, ArTST performs on a par with or exceeding the current state-of-the-art in all three tasks. Moreover, we find that our pre-training is conducive for generalization, which is particularly evident in the low-resource TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models are released for research use.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2261493094",
                    "name": "Hawau Olamide Toyin"
                },
                {
                    "authorId": "2261492948",
                    "name": "Amirbek Djanibekov"
                },
                {
                    "authorId": "2257027215",
                    "name": "Ajinkya Kulkarni"
                },
                {
                    "authorId": "2315308263",
                    "name": "Hanan Aldarmaki"
                }
            ]
        }
    ]
}