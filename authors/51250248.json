{
    "authorId": "51250248",
    "papers": [
        {
            "paperId": "59ef1b67c5f238d5d6d175d84fb6b239b4221a97",
            "title": "Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking",
            "abstract": "Prompt-based methods with large pre-trained language models (PLMs) have shown impressive unaided performance across many NLP tasks. These models improve even further with the addition of a few labeled in-context exemplars to guide output generation. However, for more complex tasks such as dialogue state tracking (DST), designing prompts that reliably convey the desired intent is nontrivial, leading to unstable results. Furthermore, building in-context exemplars for dialogue tasks is difficult because conversational contexts are long while model input lengths are relatively short.To overcome these issues we first adapt a meta-learning scheme to the dialogue domain which stabilizes the ability of the model to perform well under various prompts. We additionally design a novel training method to improve upon vanilla retrieval mechanisms to find ideal in-context examples. Finally, we introduce a saliency model to limit dialogue text length, allowing us to include more exemplars per query. In effect, we are able to achieve highly competitive results for few-shot DST on MultiWOZ.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "a120e3583f37495b10e3fa831a5087a0471638ca",
            "title": "Using Textual Interface to Align External Knowledge for End-to-End Task-Oriented Dialogue Systems",
            "abstract": "Traditional end-to-end task-oriented dialogue systems have been built with a modularized design. However, such design often causes misalignment between the agent response and external knowledge, due to inadequate representation of information. Furthermore, its evaluation metrics emphasize assessing the agent's pre-lexicalization response, neglecting the quality of the completed response. In this work, we propose a novel paradigm that uses a textual interface to align external knowledge and eliminate redundant processes. We demonstrate our paradigm in practice through MultiWOZ-Remake, including an interactive textual interface built for the MultiWOZ database and a correspondingly re-processed dataset. We train an end-to-end dialogue system to evaluate this new dataset. The experimental results show that our approach generates more natural final responses and achieves a greater task success rate compared to the previous models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "2428276",
                    "name": "Deema Alnuhait"
                },
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "fecbce223a6da402b6df875dfa5ff0fd3fc457c2",
            "title": "Sources of Noise in Dialogue and How to Deal with Them",
            "abstract": "Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs. Despite their prevalence, there currently lacks an accurate survey of dialogue noise, nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise. Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise. Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "2167255986",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "8c0ec929aac2eb67d36f383f3175f22a1b285264",
            "title": "Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task-Oriented Dialogue Systems",
            "abstract": "Existing goal-oriented dialogue datasets focus mainly on identifying slots and values. However, customer support interactions in reality often involve agents following multi-step procedures derived from explicitly-defined company policies as well. To study customer service dialogue systems in more realistic settings, we introduce the Action-Based Conversations Dataset (ABCD), a fully-labeled dataset with over 10K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success. We propose two additional dialog tasks, Action State Tracking and Cascading Dialogue Success, and establish a series of baselines involving large-scale, pre-trained language models on this dataset. Empirical results demonstrate that while more sophisticated networks outperform simpler models, a considerable gap (50.8% absolute accuracy) still exists to reach human-level performance on ABCD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "2108271953",
                    "name": "Howard Chen"
                },
                {
                    "authorId": "2048438762",
                    "name": "Yi Yang"
                },
                {
                    "authorId": "2054897343",
                    "name": "A. Lin"
                },
                {
                    "authorId": "1564034697",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "b626754a0fd7de12c87e88165b2484ac5d98212a",
            "title": "Decoupling Strategy and Generation in Negotiation Dialogues",
            "abstract": "We consider negotiation settings in which two agents use natural language to bargain on goods. Agents need to decide on both high-level strategy (e.g., proposing $50) and the execution of that strategy (e.g., generating \u201cThe bike is brand new. Selling for just $50!\u201d). Recent work on negotiation trains neural models, but their end-to-end nature makes it hard to control their strategy, and reinforcement learning tends to lead to degenerate solutions. In this paper, we propose a modular approach based on coarse dialogue acts (e.g., propose(price=50)) that decouples strategy and generation. We show that we can flexibly set the strategy using supervised learning, reinforcement learning, or domain-specific knowledge without degeneracy, while our retrieval-based generation can maintain context-awareness and produce diverse utterances. We test our approach on the recently proposed DEALORNODEAL game, and we also collect a richer dataset based on real items on Craigslist. Human evaluation shows that our systems achieve higher task success rate and more human-like negotiation behavior than previous approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144533687",
                    "name": "He He"
                },
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "2053499940",
                    "name": "Anusha Balakrishnan"
                },
                {
                    "authorId": "145419642",
                    "name": "Percy Liang"
                }
            ]
        }
    ]
}