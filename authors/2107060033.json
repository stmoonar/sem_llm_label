{
    "authorId": "2107060033",
    "papers": [
        {
            "paperId": "4f4991f93ed86b777c8b0f192dac034a3144b165",
            "title": "Pruning Compact ConvNets for Efficient Inference",
            "abstract": "Neural network pruning is frequently used to compress over-parameterized networks by large amounts, while incurring only marginal drops in generalization performance. However, the impact of pruning on networks that have been highly optimized for efficient inference has not received the same level of attention. In this paper, we analyze the effect of pruning for computer vision, and study state-of-the-art ConvNets, such as the FBNetV3 family of models. We show that model pruning approaches can be used to further optimize networks trained through NAS (Neural Architecture Search). The resulting family of pruned models can consistently obtain better performance than existing FBNetV3 models at the same level of computation, and thus provide state-of-the-art results when trading off between computational complexity and generalization performance on the ImageNet benchmark. In addition to better generalization performance, we also demonstrate that when limited computation resources are available, pruning FBNetV3 models incur only a fraction of GPU-hours involved in running a full-scale NAS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143032877",
                    "name": "Sayan Ghosh"
                },
                {
                    "authorId": "2107060033",
                    "name": "Karthik Prasad"
                },
                {
                    "authorId": "4527324",
                    "name": "Xiaoliang Dai"
                },
                {
                    "authorId": "2918780",
                    "name": "Peizhao Zhang"
                },
                {
                    "authorId": "3130257",
                    "name": "Bichen Wu"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "48682997",
                    "name": "P\u00e9ter Vajda"
                }
            ]
        },
        {
            "paperId": "42e685d9997e579746b4e2f39988e3ddb59899f3",
            "title": "Reconciling Security and Communication Efficiency in Federated Learning",
            "abstract": "Cross-device Federated Learning is an increasingly popular machine learning setting to train a model by leveraging a large population of client devices with high privacy and security guarantees. However, communication efficiency remains a major bottleneck when scaling federated learning to production environments, particularly due to bandwidth constraints during uplink communication. In this paper, we formalize and address the problem of compressing client-to-server model updates under the Secure Aggregation primitive, a core component of Federated Learning pipelines that allows the server to aggregate the client updates without accessing them individually. In particular, we adapt standard scalar quantization and pruning methods to Secure Aggregation and propose Secure Indexing, a variant of Secure Aggregation that supports quantization for extreme compression. We establish state-of-the-art results on LEAF benchmarks in a secure Federated Learning setup with up to 40$\\times$ compression in uplink communication with no meaningful loss in utility compared to uncompressed baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107060033",
                    "name": "Karthik Prasad"
                },
                {
                    "authorId": "2041115682",
                    "name": "Sayan Ghosh"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "2065193618",
                    "name": "Ilya Mironov"
                },
                {
                    "authorId": "36737249",
                    "name": "Ashkan Yousefpour"
                },
                {
                    "authorId": "37502184",
                    "name": "Pierre Stock"
                }
            ]
        },
        {
            "paperId": "4ace0211031f9ef79c70fbeca9e07dc121be90ff",
            "title": "Antipodes of Label Differential Privacy: PATE and ALIBI",
            "abstract": "We consider the privacy-preserving machine learning (ML) setting where the trained model must satisfy differential privacy (DP) with respect to the labels of the training examples. We propose two novel approaches based on, respectively, the Laplace mechanism and the PATE framework, and demonstrate their effectiveness on standard benchmarks. While recent work by Ghazi et al. proposed Label DP schemes based on a randomized response mechanism, we argue that additive Laplace noise coupled with Bayesian inference (ALIBI) is a better fit for typical ML tasks. Moreover, we show how to achieve very strong privacy levels in some regimes, with our adaptation of the PATE framework that builds on recent advances in semi-supervised learning. We complement theoretical analysis of our algorithms' privacy guarantees with empirical evaluation of their memorization properties. Our evaluation suggests that comparing different algorithms according to their provable DP guarantees can be misleading and favor a less private algorithm with a tighter analysis. Code for implementation of algorithms and memorization attacks is available from https://github.com/facebookresearch/label_dp_antipodes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107060266",
                    "name": "Mani Malek"
                },
                {
                    "authorId": "2065193618",
                    "name": "Ilya Mironov"
                },
                {
                    "authorId": "2107060033",
                    "name": "Karthik Prasad"
                },
                {
                    "authorId": "2107059646",
                    "name": "I. Shilov"
                },
                {
                    "authorId": "2444919",
                    "name": "Florian Tram\u00e8r"
                }
            ]
        },
        {
            "paperId": "bea1187a1f8a68f1a93f0c2fa10d31f93a30f84e",
            "title": "Opacus: User-Friendly Differential Privacy Library in PyTorch",
            "abstract": "We introduce Opacus, a free, open-source PyTorch library for training deep learning models with differential privacy (hosted at opacus.ai). Opacus is designed for simplicity, flexibility, and speed. It provides a simple and user-friendly API, and enables machine learning practitioners to make a training pipeline private by adding as little as two lines to their code. It supports a wide variety of layers, including multi-head attention, convolution, LSTM, GRU (and generic RNN), and embedding, right out of the box and provides the means for supporting other user-defined layers. Opacus computes batched per-sample gradients, providing higher efficiency compared to the traditional\"micro batch\"approach. In this paper we present Opacus, detail the principles that drove its implementation and unique features, and benchmark it against other frameworks for training models with differential privacy as well as standard PyTorch.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36737249",
                    "name": "Ashkan Yousefpour"
                },
                {
                    "authorId": "2107059646",
                    "name": "I. Shilov"
                },
                {
                    "authorId": "2319225824",
                    "name": "Alexandre Sablayrolles"
                },
                {
                    "authorId": "1389630028",
                    "name": "Davide Testuggine"
                },
                {
                    "authorId": "2107060033",
                    "name": "Karthik Prasad"
                },
                {
                    "authorId": "2107060266",
                    "name": "Mani Malek"
                },
                {
                    "authorId": "2131399147",
                    "name": "John Nguyen"
                },
                {
                    "authorId": "2129469303",
                    "name": "Sayan Gosh"
                },
                {
                    "authorId": "2528900",
                    "name": "Akash Bharadwaj"
                },
                {
                    "authorId": "2024689450",
                    "name": "Jessica Zhao"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "2065193618",
                    "name": "Ilya Mironov"
                }
            ]
        }
    ]
}