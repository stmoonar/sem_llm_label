{
    "authorId": "2143919864",
    "papers": [
        {
            "paperId": "0275f92a81459bf84d7cba4700b4e8be1109b9f2",
            "title": "Combating Robocalls with Phone Virtual Assistant Mediated Interaction",
            "abstract": "Mass robocalls affect millions of people on a daily basis. Unfortunately, most current defenses against robocalls rely on phone blocklists and are ineffective against caller ID spoo\ufb01ng. To enable detection and blocking of spoofed robocalls, we propose a NLP-based smartphone virtual assistant that automatically vets incoming calls. Similar to a human assistant, the virtual assistant picks up an incoming call and uses machine learning models to interact with the caller to determine if the call source is a human or a robocaller. It interrupts a user by ringing the phone only when the call is determined to be not from a robocaller. Security analysis performed by us shows that such a system can stop current and more sophisticated robocallers that might emerge in the future. We also conduct a user study that shows that the virtual assistant can preserve phone call user experience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3147186",
                    "name": "Sharbani Pandit"
                },
                {
                    "authorId": "3179340",
                    "name": "Krishanu Sarker"
                },
                {
                    "authorId": "2822260",
                    "name": "R. Perdisci"
                },
                {
                    "authorId": "144939423",
                    "name": "M. Ahamad"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "178237a9c864fccb240238f31f2e0d4551db575d",
            "title": "Shaping the Emerging Norms of Using Large Language Models in Social Computing Research",
            "abstract": "The emergence of Large Language Models (LLMs) has brought both excitement and concerns to social computing research. On the one hand, LLMs offer unprecedented capabilities in analyzing vast amounts of textual data and generating human-like responses, enabling researchers to delve into complex social phenomena. On the other hand, concerns are emerging regarding the validity, privacy, and ethics of the research when LLMs are involved. This SIG aims at offering an open space for social computing researchers who are interested in understanding the impacts of LLMs to discuss their current practices, perspectives, challenges when engaging with LLMs in their everyday work and collectively shaping the emerging norms of using LLMs in social computing research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110816375",
                    "name": "Hong Shen"
                },
                {
                    "authorId": "2118910701",
                    "name": "Tianshi Li"
                },
                {
                    "authorId": "34997918",
                    "name": "Toby Jia-Jun Li"
                },
                {
                    "authorId": "2116649486",
                    "name": "J. Park"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "20a4b2db20c1f06eab6f26cf8b7bf1748e54e6df",
            "title": "NormBank: A Knowledge Bank of Situational Social Norms",
            "abstract": "We present NormBank, a knowledge bank of 155k situational norms. This resource is designed to ground flexible normative reasoning for interactive, assistive, and collaborative AI systems. Unlike prior commonsense resources, NormBank grounds each inference within a multivalent sociocultural frame, which includes the setting (e.g., restaurant), the agents\u2019 contingent roles (waiter, customer), their attributes (age, gender), and other physical, social, and cultural constraints (e.g., the temperature or the country of operation). In total, NormBank contains 63k unique constraints from a taxonomy that we introduce and iteratively refine here. Constraints then apply in different combinations to frame social norms. Under these manipulations, norms are non-monotonic \u2014 one can cancel an inference by updating its frame even slightly. Still, we find evidence that neural models can help reliably extend the scope and coverage of NormBank. We further demonstrate the utility of this resource with a series of transfer experiments. For data and code, see https://github.com/SALT-NLP/normbank",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1399135100",
                    "name": "Caleb Ziems"
                },
                {
                    "authorId": "2284686652",
                    "name": "Jane Dwivedi-Yu"
                },
                {
                    "authorId": "2116640035",
                    "name": "Yi-Chia Wang"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "220ddeb4dc43bc922289fec8b1b60d7226068b20",
            "title": "Parameter-Efficient Fine-Tuning Design Spaces",
            "abstract": "Parameter-efficient fine-tuning aims to achieve performance comparable to fine-tuning, using fewer trainable parameters. Several strategies (e.g., Adapters, prefix tuning, BitFit, and LoRA) have been proposed. However, their designs are hand-crafted separately, and it remains unclear whether certain design patterns exist for parameter-efficient fine-tuning. Thus, we present a parameter-efficient fine-tuning design paradigm and discover design patterns that are applicable to different experimental settings. Instead of focusing on designing another individual tuning strategy, we introduce parameter-efficient fine-tuning design spaces that parameterize tuning structures and tuning strategies. Specifically, any design space is characterized by four components: layer grouping, trainable parameter allocation, tunable groups, and strategy assignment. Starting from an initial design space, we progressively refine the space based on the model quality of each design choice and make greedy selection at each stage over these four components. We discover the following design patterns: (i) group layers in a spindle pattern; (ii) allocate the number of trainable parameters to layers uniformly; (iii) tune all the groups; (iv) assign proper tuning strategies to different groups. These design patterns result in new parameter-efficient fine-tuning methods. We show experimentally that these methods consistently and significantly outperform investigated parameter-efficient fine-tuning strategies across different backbone models and different tasks in natural language processing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47739850",
                    "name": "Jiaao Chen"
                },
                {
                    "authorId": "2085709",
                    "name": "Aston Zhang"
                },
                {
                    "authorId": "2110332219",
                    "name": "Xingjian Shi"
                },
                {
                    "authorId": "1701799",
                    "name": "Mu Li"
                },
                {
                    "authorId": "78088877",
                    "name": "Alexander J. Smola"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "3f83582c08a62e5bd02398fafc93f7eaf1e4b84e",
            "title": "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints",
            "abstract": "The limits of open-ended generative models are unclear, yet increasingly important. What causes them to succeed and what causes them to fail? In this paper, we take a prompt-centric approach to analyzing and bounding the abilities of open-ended generative models. We present a generic methodology of analysis with two challenging prompt constraint types: structural and stylistic. These constraint types are categorized into a set of well-defined constraints that are analyzable by a single prompt. We then systematically create a diverse set of simple, natural, and useful prompts to robustly analyze each individual constraint. Using the GPT-3 text-davinci-002 model as a case study, we generate outputs from our collection of prompts and analyze the model\u2019s generative failures. We also show the generalizability of our proposed method on other large models like BLOOM and OPT. Our results and our in-context mitigation strategies reveal open challenges for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2208657585",
                    "name": "Albert Lu"
                },
                {
                    "authorId": "2118083343",
                    "name": "Hongxin Zhang"
                },
                {
                    "authorId": "2121290295",
                    "name": "Yanzhe Zhang"
                },
                {
                    "authorId": "1524732527",
                    "name": "Xuezhi Wang"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "4fcfe83c05402b5c5fb6e853082e74af6379d7f9",
            "title": "Missing Information, Unresponsive Authors, Experimental Flaws: The Impossibility of Assessing the Reproducibility of Previous Human Evaluations in NLP",
            "abstract": "We report our efforts in identifying a set of previous human evaluations in NLP that would be suitable for a coordinated study examining what makes human evaluations in NLP more/less reproducible. We present our results and findings, which include that just 13% of papers had (i) sufficiently low barriers to reproduction, and (ii) enough obtainable information, to be considered for reproduction, and that all but one of the experiments we selected for reproduction was discovered to have flaws that made the meaningfulness of conducting a reproduction questionable. As a result, we had to change our coordinated study design from a reproduce approach to a standardise-then-reproduce-twice approach. Our overall (negative) finding that the great majority of human evaluations in NLP is not repeatable and/or not reproducible and/or too flawed to justify reproduction, paints a dire picture, but presents an opportunity for a rethink about how to design and report human evaluations in NLP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41052836",
                    "name": "Anya Belz"
                },
                {
                    "authorId": "2122535749",
                    "name": "Craig Thomson"
                },
                {
                    "authorId": "2113922820",
                    "name": "Ehud Reiter"
                },
                {
                    "authorId": "17038002",
                    "name": "Gavin Abercrombie"
                },
                {
                    "authorId": "2151319597",
                    "name": "J. Alonso-Moral"
                },
                {
                    "authorId": "9364658",
                    "name": "Mohammad Arvan"
                },
                {
                    "authorId": "3159752",
                    "name": "J. Cheung"
                },
                {
                    "authorId": "2648584",
                    "name": "Mark Cieliebak"
                },
                {
                    "authorId": "40684993",
                    "name": "Elizabeth Clark"
                },
                {
                    "authorId": "10708829",
                    "name": "K. V. Deemter"
                },
                {
                    "authorId": "72115354",
                    "name": "Tanvi Dinkar"
                },
                {
                    "authorId": "2544049",
                    "name": "Ondrej Dusek"
                },
                {
                    "authorId": "2620186",
                    "name": "Steffen Eger"
                },
                {
                    "authorId": "1720986506",
                    "name": "Qixiang Fang"
                },
                {
                    "authorId": "1700894",
                    "name": "Albert Gatt"
                },
                {
                    "authorId": "2921637",
                    "name": "Dimitra Gkatzia"
                },
                {
                    "authorId": "2215866480",
                    "name": "Javier Gonz'alez-Corbelle"
                },
                {
                    "authorId": "2022288",
                    "name": "Dirk Hovy"
                },
                {
                    "authorId": "2165661802",
                    "name": "Manuela Hurlimann"
                },
                {
                    "authorId": "119804885",
                    "name": "Takumi Ito"
                },
                {
                    "authorId": "1380281888",
                    "name": "John D. Kelleher"
                },
                {
                    "authorId": "3201315",
                    "name": "Filip Klubicka"
                },
                {
                    "authorId": "66376493",
                    "name": "Huiyuan Lai"
                },
                {
                    "authorId": "50521235",
                    "name": "Chris van der Lee"
                },
                {
                    "authorId": "3192572",
                    "name": "Emiel van Miltenburg"
                },
                {
                    "authorId": "2142159995",
                    "name": "Yiru Li"
                },
                {
                    "authorId": "2221260",
                    "name": "Saad Mahamood"
                },
                {
                    "authorId": "2921990",
                    "name": "Margot Mieskes"
                },
                {
                    "authorId": "2742475",
                    "name": "M. Nissim"
                },
                {
                    "authorId": "2326758",
                    "name": "Natalie Parde"
                },
                {
                    "authorId": "2201327940",
                    "name": "Ondvrej Pl'atek"
                },
                {
                    "authorId": "1681799",
                    "name": "Verena Rieser"
                },
                {
                    "authorId": "2150388522",
                    "name": "Pablo Romero"
                },
                {
                    "authorId": "2086973507",
                    "name": "Joel R. Tetreault"
                },
                {
                    "authorId": "2065048323",
                    "name": "Antonio Toral"
                },
                {
                    "authorId": "9714242",
                    "name": "Xiao-Yi Wan"
                },
                {
                    "authorId": "9092408",
                    "name": "L. Wanner"
                },
                {
                    "authorId": "145148787",
                    "name": "Lewis J. Watson"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "5242aa4319203dc2773c31b1c6a1c159dc63fb7e",
            "title": "DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules",
            "abstract": "Existing large language models (LLMs) that mainly focus on Standard American English (SAE) often lead to significantly worse performance when being applied to other English dialects. While existing mitigations tackle discrepancies for individual target dialects, they assume access to high-accuracy dialect identification systems. The boundaries between dialects are inherently flexible, making it difficult to categorize language into discrete predefined categories. In this paper, we propose DADA (Dialect Adaptation via Dynamic Aggregation), a modular approach to imbue SAE-trained models with multi-dialectal robustness by composing adapters which handle specific linguistic features. The compositional architecture of DADA allows for both targeted adaptation to specific dialect variants and simultaneous adaptation to various dialects. We show that DADA is effective for both single task and instruction finetuned language models, offering an extensible and interpretable framework for adapting existing LLMs to different English dialects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108082280",
                    "name": "Yanchen Liu"
                },
                {
                    "authorId": "46552910",
                    "name": "William B. Held"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "53831a304fb568aea4548efcef910cc62f2d2dcb",
            "title": "Werewolf Among Us: Multimodal Resources for Modeling Persuasion Behaviors in Social Deduction Games",
            "abstract": "Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpora. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26 , 647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset can be found at https://persuasion-deductiongame. socialai-data.org . The codes and models are available at https://github.com/ SALT-NLP/PersuationGames .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057732429",
                    "name": "Bolin Lai"
                },
                {
                    "authorId": "2118083343",
                    "name": "Hongxin Zhang"
                },
                {
                    "authorId": "2108511234",
                    "name": "Miao Liu"
                },
                {
                    "authorId": "2197412970",
                    "name": "Aryan Pariani"
                },
                {
                    "authorId": "119797486",
                    "name": "Fiona Ryan"
                },
                {
                    "authorId": "2072957749",
                    "name": "Wenqi Jia"
                },
                {
                    "authorId": "31998283",
                    "name": "Shirley Anugrah Hayati"
                },
                {
                    "authorId": "50779871",
                    "name": "J. Rehg"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "55707013ab7912450a4632d13e8b919a58cb1077",
            "title": "Auditing Gender Presentation Differences in Text-to-Image Models",
            "abstract": "Text-to-image models, which can generate high-quality images based on textual input, have recently enabled various content-creation tools. Despite significantly affecting a wide range of downstream applications, the distributions of these generated images are still not fully understood, especially when it comes to the potential stereotypical attributes of different genders. In this work, we propose a paradigm (Gender Presentation Differences) that utilizes fine-grained self-presentation attributes to study how gender is presented differently in text-to-image models. By probing gender indicators in the input text (e.g.,\"a woman\"or\"a man\"), we quantify the frequency differences of presentation-centric attributes (e.g.,\"a shirt\"and\"a dress\") through human annotation and introduce a novel metric: GEP. Furthermore, we propose an automatic method to estimate such differences. The automatic GEP metric based on our approach yields a higher correlation with human annotations than that based on existing CLIP scores, consistently across three state-of-the-art text-to-image models. Finally, we demonstrate the generalization ability of our metrics in the context of gender stereotypes related to occupations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121290295",
                    "name": "Yanzhe Zhang"
                },
                {
                    "authorId": null,
                    "name": "Lu Jiang"
                },
                {
                    "authorId": "1713189",
                    "name": "Greg Turk"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "61d40d7263d9c03649fcd6ccb840ef8dac2243d1",
            "title": "TADA: Task-Agnostic Dialect Adapters for English",
            "abstract": "Large Language Models, the dominant starting point for Natural Language Processing (NLP) applications, fail at a higher rate for speakers of English dialects other than Standard American English (SAE). Prior work addresses this using task-specific data or synthetic data augmentation, both of which require intervention for each dialect and task pair. This poses a scalability issue that prevents the broad adoption of robust dialectal English NLP. We introduce a simple yet effective method for task-agnostic dialect adaptation by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on 4 dialectal variants of the GLUE benchmark without task-specific supervision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46552910",
                    "name": "William B. Held"
                },
                {
                    "authorId": "1399135100",
                    "name": "Caleb Ziems"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        }
    ]
}