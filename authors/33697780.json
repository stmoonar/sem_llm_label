{
    "authorId": "33697780",
    "papers": [
        {
            "paperId": "f0d502277fa88adc345ae0c5f695e41bfb71602d",
            "title": "Navigating the Feedback Loop in Recommender Systems: Insights and Strategies from Industry Practice",
            "abstract": "Understanding and measuring the impact of feedback loops in industrial recommender systems is challenging, leading to the underestimation of their deterioration. In this study, we define open and closed feedback loops and investigate the unique reasons behind the emergence of feedback loops in the industry, drawing from real-world examples that have received limited attention in prior research. We highlight the measurement challenges associated with capturing the full impact of feedback loops using traditional online A/B tests. To address this, we propose the use of offline evaluation frameworks as surrogates for long-term feedback loop bias, supported by a practical simulation system using real data. Our findings provide valuable insights for optimizing the performance of recommender systems operating under feedback loop conditions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240552418",
                    "name": "Ding Tong"
                },
                {
                    "authorId": "2240552294",
                    "name": "Qifeng Qiao"
                },
                {
                    "authorId": "2240739634",
                    "name": "Ting-Po Lee"
                },
                {
                    "authorId": "2240551840",
                    "name": "James McInerney"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                }
            ]
        },
        {
            "paperId": "cfeff493387b9229a610e72904b259529cc5f12f",
            "title": "Deep Learning for Recommender Systems: A Netflix Case Study",
            "abstract": "Deep learning has profoundly impacted many areas of machine learning. However, it took a while for its impact to be felt in the field of recommender systems. In this article, we outline some of the challenges encountered and lessons learned in using deep learning for recommender systems at Netflix. We first provide an overview of the various recommendation tasks on the Netflix service. We found that different model architectures excel at different tasks. Even though many deep-learning models can be understood as extensions of existing (simple) recommendation algorithms, we initially did not observe significant improvements in performance over well-tuned non-deep-learning approaches. Only when we added numerous features of heterogeneous types to the input data, deep-learning models did start to shine in our setting. We also observed that deep-learning methods can exacerbate the problem of offline\u2013online metric (mis-)alignment. After addressing these challenges, deep learning has ultimately resulted in large improvements to our recommendations as measured by both offline and online metrics. On the practical side, integrating deep-learning toolboxes in our system has made it faster and easier to implement and experiment with both deep-learning and non-deep-learning approaches for various recommendation tasks. We conclude this article by summarizing our take-aways that may generalize to other applications beyond Netflix.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2454529",
                    "name": "H. Steck"
                },
                {
                    "authorId": "2666397",
                    "name": "L. Baltrunas"
                },
                {
                    "authorId": "8023629",
                    "name": "Ehtsham Elahi"
                },
                {
                    "authorId": "1702877",
                    "name": "Dawen Liang"
                },
                {
                    "authorId": "1774742",
                    "name": "Yves Raimond"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                }
            ]
        },
        {
            "paperId": "03bc6e8f9150ceb35ff0a910b82fa206348bb495",
            "title": "RecSysOps: Best Practices for Operating a Large-Scale Recommender System",
            "abstract": "Ensuring the health of a modern large-scale recommendation system is a very challenging problem. To address this, we need to put in place proper logging, sophisticated exploration policies, develop ML-interpretability tools or even train new ML models to predict/detect issues of the main production model. In this talk, we shine a light on this less-discussed but important area and share some of the best practices, called RecSysOps, that we\u2019ve learned while operating our increasingly complex recommender systems at Netflix. RecSysOps is a set of best practices for identifying issues and gaps as well as diagnosing and resolving them in a large-scale machine-learned recommender system. RecSysOps helped us to 1) reduce production issues and 2) increase recommendation quality by identifying areas of improvement and 3) make it possible to bring new innovations faster to our members by enabling us to spend more of our time on new innovations and less on debugging and firefighting issues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1780809",
                    "name": "M. Saberian"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                }
            ]
        },
        {
            "paperId": "10320abbc9bd2f1b84bb6be6c76ee14e880c4372",
            "title": "Accordion: A Trainable Simulator for Long-Term Interactive Systems",
            "abstract": "As machine learning methods are increasingly used in interactive systems it becomes common for user experiences to be the result of an ecosystem of machine learning models in aggregate. Simulation offers a way to deal with the resulting complexity by approximating the real system in a tractable and interpretable manner. Existing methods do not fully incorporate the interactions between user history, recommendation quality, and subsequent visits. We develop Accordion, a trainable simulator based on Poisson processes that can model visit patterns to an interactive system over time from large-scale data. New methods for training and simulation are developed and tested on two datasets of real world interactive systems. Accordion shows greater sensitivity to hyperparameter tuning and offline A/B testing than comparison methods, an important step in building realistic task-oriented simulators for recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059894216",
                    "name": "James McInerney"
                },
                {
                    "authorId": "8023629",
                    "name": "Ehtsham Elahi"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                },
                {
                    "authorId": "1774742",
                    "name": "Yves Raimond"
                },
                {
                    "authorId": "1768120",
                    "name": "Tony Jebara"
                }
            ]
        },
        {
            "paperId": "750d6f7fcd1977d6c15fd7c778657959461098e6",
            "title": "2nd International Workshop on Industrial Recommendation Systems (IRS)",
            "abstract": "Recommendation systems are used widely across many industries, such as e-commerce, multimedia content platforms and social networks, to provide suggestions that a user will most likely consume or connect; thus, improving the user experience. This motivates people in both industry and research organizations to focus on personalization or recommendation algorithms, which has resulted in a plethora of research papers. While academic research mostly focuses on the performance of recommendation algorithms in terms of ranking quality or accuracy, it often neglects key factors that impact how a recommendation system will perform in a real-world environment. These key factors include but are not limited to: business metric definition and evaluation, recommendation quality control, data and model scalability, model interpretability, model robustness and fairness, and resource limitations, such as computing and memory resources budgets, engineering workforce cost, etc. The gap in constraints and requirements between academic research and industry limits the broad applicability of many of academia's contributions for industrial recommendation systems. This workshop aspires to bridge this gap by bringing together researchers from both academia and industry. Its goal is to serve as a venue through which academic researchers become aware of the additional factors that may affect the adoption of an algorithm into real production systems, and how well it will perform if deployed. Industrial researchers will also benefit from sharing the practical insights, approaches, and frameworks as well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139102391",
                    "name": "Jianpeng Xu"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2061203657",
                    "name": "Xiaolin Pang"
                },
                {
                    "authorId": "2110360100",
                    "name": "Mohit Sharma"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                },
                {
                    "authorId": "144019071",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "9aa3dd841b2dc52a68e281ffd5ae508e2162d416",
            "title": "Artwork personalization at netflix",
            "abstract": "For many years, the main goal of the Netflix personalized recommendation system has been to get the right titles in front of our members at the right time. But the job of recommendation does not end there. The homepage should be able to convey to the member enough evidence of why a title may be good for her, especially for shows that the member has never heard of. One way to address this challenge is to personalize the way we portray the titles on our service. An important aspect of how to portray titles is through the artwork or imagery we display to visually represent each title. The artwork may highlight an actor that you recognize, capture an exciting moment like a car chase, or contain a dramatic scene that conveys the essence of a movie or show. It is important to select good artwork because it may be the first time a member becomes aware of a title (and sometimes the only time), so it must speak to them in a meaningful way. In this talk, we will present an approach for personalizing the artwork we use on the Netflix homepage. The system selects an image for each member and video to give better visual evidence for why the title might be appealing to that particular member. There are many challenges involved in getting artwork personalization to succeed. One challenge is that we can only select a single piece of artwork to represent each title. In contrast, typical recommendation engines present multiple items (in some order) to a member allowing us to subsequently learn about preferences between items through the specific item a member selects from the presented assortment. In contrast, we only collect feedback from the one image that was presented to each member for each title. This leads to a training paradigm based on incomplete logged bandit feedback [1]. Moreover, since the artwork selection process happens on top of a recommendation system, collecting data directly from the production experience (observational data) makes it hard to detangle whether a play was due to the recommendation or from the incremental effect of personalized evidence. Another challenge is understanding the impact of changing the artwork between sessions and if that is beneficial or confusing to the user. We also need to consider how diverse artworks perform in relation to one another. Finally, given that the popularity and audiences for titles can change or drop quickly after launch, the system needs to quickly learn how to personalize images for a new item. All these considerations naturally lead us to frame the problem as online learning with contextual multi-arm bandits. Briefly, contextual bandits are a class of online learning algorithms that balance the cost of gathering randomized training data (which is required for learning an unbiased model on an ongoing basis) with the benefits of applying the learned model to each member context (to maximize user engagement). This is known as the explore-exploit trade-off. In this setting, for a given title the set of actions is the set of available images for the title. We aim to discover the underlying unknown reward, based on probability of play, for each image given a member, a title, and some context. The context could be based on profile attributes (geo-localization, previous plays, etc), the device, time, and other factors that might affect what is the optimal image to choose in each session. With a large member base, many titles in the catalog, and multiple images per title, Netflix's product is an ideal platform to test ideas for personalization of artwork. At peak, over 20 million personalized image requests per second need to be handled with low latency. To train our model, we leveraged existing logged data from a previous system that chose images in an unpersonalized manner. We will present results comparing the contextual bandit personalization algorithms using offline policy evaluation metrics [2], such as inverse propensity scoring and doubly robust estimators [3]. We will conclude with a discussion of opportunities to expand and improve our approach. This includes developing algorithms to handle cold-start by quickly personalizing new images and new titles. We also discuss extending this personalization approach across other types of artwork we use and other evidence that describe our titles such as synopses, metadata, and trailers. Finally, we discuss potentially closing the loop by looking at how we can help artists and designers figure out what new imagery they should create to make a title even more compelling and personalizable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112296294",
                    "name": "Fernando Amat Gil"
                },
                {
                    "authorId": "1950127172",
                    "name": "Ashok Chandrashekar"
                },
                {
                    "authorId": "1768120",
                    "name": "Tony Jebara"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                }
            ]
        },
        {
            "paperId": "12b07f45f4a65e6e70edcb449ce18004b60113c0",
            "title": "D\u00e9j\u00e0 Vu: The Importance of Time and Causality in Recommender Systems",
            "abstract": "Time plays a key role in recommendation. Handling it properly is especially critical when using recommender systems in real-world applications, which may not be as clear when doing research with historical data. In this talk, we will discuss some of the important challenges of handling time in recommendation algorithms at Netflix. We will focus on challenges related to how our users, items, and systems all change over time. We will then discuss some strategies for tackling these challenges, which revolves around proper treatment of causality in our systems. One clear way that time impacts recommendations is that users and items change over time. Users and items come and go from a service. Individual user interests also change, which could be someone picking up a new interest or even just people maturing and their tastes changing. Many recommendation approaches are based on historical co-occurrence, in which case they tend to lag with such changes instead of anticipating them. An item that is new to the system may start cold but then develop a lot of interest because it is new. So the level of interest in an item fluctuates across time, which can be additionally impacted by trends such as external events and seasonality. Beyond these, the system itself changes over time. Feedback loops in the system, where users actions are influenced by the output of the recommendation system, cause the data that the system uses for recommendations to evolve over time. These feedback loops also can degrade the quality of the recommendations because it becomes hard to tease apart when a user is playing something because they enjoy it versus when they are playing it because it was shown prominently. These loops also can make it difficult for new algorithms to be trained and evaluated due to the influence of the production system. Different components of the system also can change over time, which can impact the data seen by other components. Time also becomes a tradeoff for how accurate a model can be against the time it takes to learn or compute recommendations for a certain request. A model giving very promising results offline but taking weeks to learn might be outperformed online by a model with weaker results but more responsive. On the other hand, changing fast may improve online accuracy by being responsive but may also confuse users when everything changes quickly. Since time is fundamental to the recommendation problem, we seek to optimize our handling of time in our systems. This includes designing experimentation around time by splitting across time and avoiding time-traveling data. It means introducing controlled stochasticity and counterfactuals to break feedback loops and understand causality. It means treating time as a first-class citizen in algorithms. It also means that we often want to optimize our recommendation systems such that a user minimizes the time a user needs to interact with it so that they can find something great to watch.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                },
                {
                    "authorId": "1774742",
                    "name": "Yves Raimond"
                }
            ]
        },
        {
            "paperId": "2ea8380cd47581595f265625ad531a68b8a23f65",
            "title": "Using Navigation to Improve Recommendations in Real-Time",
            "abstract": "Implicit feedback is a key source of information for many recommendation and personalization approaches. However, using it typically requires multiple episodes of interaction and roundtrips to a recommendation engine. This adds latency and neglects the opportunity of immediate personalization for a user while the user is navigating recommendations. We propose a novel strategy to address the above problem in a principled manner. The key insight is that as we observe a user's interactions, it reveals much more information about her desires. We exploit this by inferring the within-session user intent on-the-fly based on navigation interactions, since they offer valuable clues into a user's current state of mind. Using navigation patterns and adapting recommendations in real-time creates an opportunity to provide more accurate recommendations. By prefetching a larger amount of content, this can be carried out entirely in the client (such as a browser) without added latency. We define a new Bayesian model with an efficient inference algorithm. We demonstrate significant improvements with this novel approach on a real-world, large-scale dataset from Netflix on the problem of adapting the recommendations on a user's homepage.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2978413",
                    "name": "Chao-Yuan Wu"
                },
                {
                    "authorId": "1684795",
                    "name": "C. Alvino"
                },
                {
                    "authorId": "46234526",
                    "name": "Alex Smola"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                }
            ]
        },
        {
            "paperId": "367a1c659ebcf9bf9e6f2bf35f41fe1b2df78b76",
            "title": "Recommending for the World",
            "abstract": "The Netflix experience is driven by a number of recommendation algorithms: personalized ranking, page generation, similarity, ratings, search, etc. On the January 6th, 2016 we simultaneously launched Netflix in 130 new countries around the world, which brought the total to over 190 countries. Preparing for such a rapid expansion while ensuring each algorithm was ready to work seamlessly created new challenges for our recommendation and search teams. In this talk, we will highlight the four most interesting challenges we encountered in making our algorithms operate globally and how this improved our ability to connect members worldwide with stories they'll love. In particular, we will dive into the problems of uneven availability across catalogs, balancing personal and cultural tastes, handling language, and tracking quality of recommendations. Uneven catalog availability is a challenge because many recommendation algorithms assume that people could interact with any item and then use the absence of interaction implicitly or explicitly as negative information in the model. However, this assumption does not hold globally and across time where item availability differs. Running algorithms globally means needing a notion of location so that we can handle local variations in taste while also providing a good basis for personalization. Language is another challenge in recommending video content because people can typically only enjoy content that has assets (audio, subtitles) in languages they understand. The preferences for how people enjoy such content also vary between people and depend on their familiarity with a language. Also, while would like our recommendations to work well for every one of our members, tracking quality becomes difficult because with so many members in so many countries speaking so many languages, it can be hard to determine when an algorithm or system is performing sub-optimally for some subset of them. Thus, to support this global launch, we examined each and every algorithm that is part of our service and began to address these challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                },
                {
                    "authorId": "1774742",
                    "name": "Yves Raimond"
                }
            ]
        },
        {
            "paperId": "b33e77f48fe526349d542b19d58781334dd3bcd7",
            "title": "Past, Present, and Future of Recommender Systems: An Industry Perspective",
            "abstract": "When the Netflix Prize launched in 2006, it put a spotlight on the importance and use of recommender systems in real-world applications. The competition provided many lessons, and many more have been learned since the Grand Prize was awarded in 2009. The use of recommender systems in industry has continued to grow driven by the availability of many kinds of user data and the continued interest for the area within the research community. In this paper, we will describe what we see as the past, present, and future of recommender systems from an industry perspective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2478897",
                    "name": "X. Amatriain"
                },
                {
                    "authorId": "33697780",
                    "name": "J. Basilico"
                }
            ]
        }
    ]
}