{
    "authorId": "29860450",
    "papers": [
        {
            "paperId": "4bdc1f0436d8ec356fc5c2bb9e1c510b7951d2ba",
            "title": "Heterogeneous Contrastive Learning for Foundation Models and Beyond",
            "abstract": "In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive self-supervised learning by learning compact and high-quality representations without relying on any label information. Amidst the explosive advancements in foundation models across multiple domains, including natural language processing and computer vision, a thorough survey on heterogeneous contrastive learning for the foundation model is urgently needed. In response, this survey critically evaluates the current landscape of heterogeneous contrastive learning for foundation models, highlighting the open challenges and future trends of contrastive learning. In particular, we first present how the recent advanced contrastive learning-based methods deal with view heterogeneity and how contrastive learning is applied to train and fine-tune the multi-view foundation models. Then, we move to contrastive learning methods for task heterogeneity, including pretraining tasks and downstream tasks, and show how different tasks are combined with contrastive learning loss for different purposes. Finally, we conclude this survey by discussing the open challenges and shedding light on the future directions of contrastive learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65990885",
                    "name": "Lecheng Zheng"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2294786726",
                    "name": "Zihao Li"
                },
                {
                    "authorId": "2294365662",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "2293155622",
                    "name": "Jingrui He"
                }
            ]
        },
        {
            "paperId": "02fa878ecc2c4426d22482a8e5cda952877b5f70",
            "title": "STERLING: Synergistic Representation Learning on Bipartite Graphs",
            "abstract": "A fundamental challenge of bipartite graph representation learning is how to extract informative node embeddings. Self-Supervised Learning (SSL) is a promising paradigm to address this challenge. Most recent bipartite graph SSL methods are based on contrastive learning which learns embeddings by discriminating positive and negative node pairs. Contrastive learning usually requires a large number of negative node pairs, which could lead to computational burden and semantic errors. In this paper, we introduce a novel synergistic representation learning model (STERLING) to learn node embeddings without negative node pairs. STERLING preserves the unique local and global synergies in bipartite graphs. The local synergies are captured by maximizing the similarity of the inter-type and intra-type positive node pairs, and the global synergies are captured by maximizing the mutual information of co-clusters. Theoretical analysis demonstrates that STERLING could improve the connectivity between different node types in the embedding space. Extensive empirical evaluation on various benchmark datasets and tasks demonstrates the effectiveness of STERLING for extracting node embeddings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "66807781",
                    "name": "Kaize Ding"
                },
                {
                    "authorId": "2109120259",
                    "name": "Chanyoung Park"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "2155337763",
                    "name": "Huan Liu"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "782d3729c99342c88438f8653b820ad36549ed6e",
            "title": "Reconciling Competing Sampling Strategies of Network Embedding",
            "abstract": "Network embedding plays a significant role in a variety of applications. To capture the topology of the network, most of the existing network embedding algorithms follow a sampling training procedure, which maximizes the similarity (e.g., embedding vectors\u2019 dot product) between positively sampled node pairs and minimizes the similarity between negatively sampled node pairs in the embedding space. Typically, close node pairs function as positive samples while distant node pairs are usually considered as negative samples. However, under different or even competing sampling strategies, some methods champion sampling distant node pairs as positive samples to encapsulate longer distance information in link prediction, whereas others advocate adding close nodes into the negative sample set to boost the performance of node recommendation. In this paper, we seek to understand the intrinsic relationships between these competing strategies. To this end, we identify two properties ( discrimination and monotonicity ) that given any node pair proximity distribution, node embeddings should embrace. Moreover, we quantify the empirical error of the trained similarity score w.r.t. the sampling strategy, which leads to an important finding that the discrimination property and the monotonicity property for all node pairs can not be satisfied simultaneously in real-world applications. Guided by such analysis, a simple yet novel model (S ENSEI ) is proposed, which seamlessly fulfills the discrimination property and the partial monotonicity within the top-K ranking list. Extensive experiments show that S ENSEI outperforms the state-of-the-arts in plain network embedding.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274018166",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "1505803281",
                    "name": "Lihui Liu"
                },
                {
                    "authorId": "2287792751",
                    "name": "Ruijie Wang"
                },
                {
                    "authorId": "2248195405",
                    "name": "Jinning Li"
                },
                {
                    "authorId": "2287824378",
                    "name": "Tarek F. Abdelzaher"
                },
                {
                    "authorId": "2278450099",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "7a2516fd7416c3d3c65e498e30c3d51531cfe175",
            "title": "Mastering Long-Tail Complexity on Graphs: Characterization, Learning, and Generalization",
            "abstract": "In the context of long-tail classification on graphs, the vast majority of existing work primarily revolves around the development of model debiasing strategies, intending to mitigate class imbalances and enhance the overall performance. Despite the notable success, there is very limited literature that provides a theoretical tool for characterizing the behaviors of long-tail classes in graphs and gaining insight into generalization performance in real-world scenarios. To bridge this gap, we propose a generalization bound for long-tail classification on graphs by formulating the problem in the fashion of multi-task learning, i.e., each task corresponds to the prediction of one particular class. Our theoretical results show that the generalization performance of long-tail classification is dominated by the overall loss range and the task complexity. Building upon the theoretical findings, we propose a novel generic framework HierTail for long-tail classification on graphs. In particular, we start with a hierarchical task grouping module that allows us to assign related tasks into hypertasks and thus control the complexity of the task space; then, we further design a balanced contrastive learning module to adaptively balance the gradients of both head and tail classes to control the loss range across all tasks in a unified fashion. Extensive experiments demonstrate the effectiveness of HierTail in characterizing long-tail classes on real graphs, which achieves up to 12.9% improvement over the leading baseline method in accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155587513",
                    "name": "Haohui Wang"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "66807781",
                    "name": "Kaize Ding"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "2304484038",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2304373824",
                    "name": "Si Zhang"
                },
                {
                    "authorId": "2304366018",
                    "name": "Yonghui Fan"
                },
                {
                    "authorId": "2304360145",
                    "name": "Liqing Zhang"
                },
                {
                    "authorId": "49407567",
                    "name": "Dawei Zhou"
                }
            ]
        },
        {
            "paperId": "0d8353b8b756d4453301650bbed2977e0d46ef1b",
            "title": "Adversarial Graph Contrastive Learning with Information Regularization",
            "abstract": "Contrastive learning is an effective unsupervised method in graph representation learning. Recently, the data augmentation based contrastive learning method has been extended from images to graphs. However, most prior works are directly adapted from the models designed for images. Unlike the data augmentation on images, the data augmentation on graphs is far less intuitive and much harder to provide high-quality contrastive samples, which are the key to the performance of contrastive learning models. This leaves much space for improvement over the existing graph contrastive learning frameworks. In this work, by introducing an adversarial graph view and an information regularizer, we propose a simple but effective method, Adversarial Graph Contrastive Learning (ArieL), to extract informative contrastive samples within a reasonable constraint. It consistently outperforms the current graph contrastive learning methods in the node classification task over various real-world datasets and further improves the robustness of graph contrastive learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "147475ad48f26f76c8862e6980917d78110982f0",
            "title": "COIN: Co-Cluster Infomax for Bipartite Graphs",
            "abstract": "Bipartite graphs are powerful data structures to model interactions between two types of nodes, which have been used in a variety of applications, such as recommender systems, information retrieval, and drug discovery. A fundamental challenge for bipartite graphs is how to learn informative node embeddings. Despite the success of recent self-supervised learning methods on bipartite graphs, their objectives are discriminating instance-wise positive and negative node pairs, which could contain cluster-level errors. In this paper, we introduce a novel co-cluster infomax (COIN) framework, which captures the cluster-level information by maximizing the mutual information of co-clusters. Different from previous infomax methods which estimate mutual information by neural networks, COIN could easily calculate mutual information. Besides, COIN is an end-to-end coclustering method which can be trained jointly with other objective functions and optimized via back-propagation. Furthermore, we also provide theoretical analysis for COIN. We theoretically prove that COIN is able to effectively maximize the mutual information of node embeddings and COIN is upper-bounded by the prior distributions of nodes. We extensively evaluate the proposed COIN framework on various benchmark datasets and tasks to demonstrate the effectiveness of COIN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2109341751",
                    "name": "Yuchen Yan"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "d6841564925af20fc23a35627f07b7c1a12e96fb",
            "title": "Retrieval Based Time Series Forecasting",
            "abstract": "Time series data appears in a variety of applications such as smart transportation and environmental monitoring. One of the fundamental problems for time series analysis is time series forecasting. Despite the success of recent deep time series forecasting methods, they require sufficient observation of historical values to make accurate forecasting. In other words, the ratio of the output length (or forecasting horizon) to the sum of the input and output lengths should be low enough (e.g., 0.3). As the ratio increases (e.g., to 0.8), the uncertainty for the forecasting accuracy increases significantly. In this paper, we show both theoretically and empirically that the uncertainty could be effectively reduced by retrieving relevant time series as references. In the theoretical analysis, we first quantify the uncertainty and show its connections to the Mean Squared Error (MSE). Then we prove that models with references are easier to learn than models without references since the retrieved references could reduce the uncertainty. To empirically demonstrate the effectiveness of the retrieval based time series forecasting models, we introduce a simple yet effective two-stage method, called ReTime consisting of a relational retrieval and a content synthesis. We also show that ReTime can be easily adapted to the spatial-temporal time series and time series imputation settings. Finally, we evaluate ReTime on real-world datasets to demonstrate its effectiveness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2108336397",
                    "name": "Si Zhang"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "1738429361",
                    "name": "B. Peng"
                },
                {
                    "authorId": "115280971",
                    "name": "K. Guan"
                },
                {
                    "authorId": "12866575",
                    "name": "A. Margenot"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "e9d6cd3ef8d05f509121ad30f193f8c8fddf2d64",
            "title": "ArieL: Adversarial Graph Contrastive Learning",
            "abstract": "Contrastive learning is an effective unsupervised method in graph representation learning. The key component of contrastive learning lies in the construction of positive and negative samples. Previous methods usually utilize the proximity of nodes in the graph as the principle. Recently, the data-augmentation-based contrastive learning method has advanced to show great power in the visual domain, and some works have extended this method from images to graphs. However, unlike the data augmentation on images, the data augmentation on graphs is far less intuitive and it is much harder to provide high-quality contrastive samples, which leaves much space for improvement. In this work, by introducing an adversarial graph view for data augmentation, we propose a simple but effective method, Adversarial Graph Contrastive Learning (ArieL), to extract informative contrastive samples within reasonable constraints. We develop a new technique called information regularization for stable training and use subgraph sampling for scalability. We generalize our method from node-level contrastive learning to the graph level by treating each graph instance as a super-node. ArieL consistently outperforms the current graph contrastive learning methods for both node-level and graph-level classification tasks on real-world datasets. We further demonstrate that ArieL is more robust in the face of adversarial attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "098d72267a1ad58b0a295c9bdb98a7b1719b06d9",
            "title": "SODA: Detecting COVID-19 in Chest X-Rays With Semi-Supervised Open Set Domain Adaptation",
            "abstract": "Due to the shortage of COVID-19 viral testing kits, radiology imaging is used to complement the screening process. Deep learning based methods are promising in automatically detecting COVID-19 disease in chest x-ray images. Most of these works first train a Convolutional Neural Network (CNN) on an existing large-scale chest x-ray image dataset and then fine-tune the model on the newly collected COVID-19 chest x-ray dataset, often at a much smaller scale. However, simple fine-tuning may lead to poor performance for the CNN model due to two issues, first the large domain shift present in chest x-ray datasets and second the relatively small scale of the COVID-19 chest x-ray dataset. In an attempt to address these two important issues, we formulate the problem of COVID-19 chest x-ray image classification in a semi-supervised open set domain adaptation setting and propose a novel domain adaptation method, Semi-supervised Open set Domain Adversarial network (SODA). SODA is designed to align the data distributions across different domains in the general domain space and also in the common subspace of source and target data. In our experiments, SODA achieves a leading classification performance compared with recent state-of-the-art models in separating COVID-19 with common pneumonia. We also present initial results showing that SODA can produce better pathology localizations in the chest x-rays.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46192632",
                    "name": "Jieli Zhou"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "1905077",
                    "name": "Zeya Wang"
                }
            ]
        },
        {
            "paperId": "245d2b50f0a8b6d60a5741e87b64d881f85ec01d",
            "title": "X-GOAL: Multiplex Heterogeneous Graph Prototypical Contrastive Learning",
            "abstract": "Graphs are powerful representations for relations among objects, which have attracted plenty of attention in both academia and industry. A fundamental challenge for graph learning is how to train an effective Graph Neural Network (GNN) encoder without labels, which are expensive and time consuming to obtain. Contrastive Learning (CL) is one of the most popular paradigms to address this challenge, which trains GNNs by discriminating positive and negative node pairs. Despite the success of recent CL methods, there are still two under-explored problems. Firstly, how to reduce the semantic error introduced by random topology based data augmentations. Traditional CL defines positive and negative node pairs via the node-level topological proximity, which is solely based on the graph topology regardless of the semantic information of node attributes, and thus some semantically similar nodes could be wrongly treated as negative pairs. Secondly, how to effectively model the multiplexity of the real-world graphs, where nodes are connected by various relations and each relation could form a homogeneous graph layer. To solve these problems, we propose a novel multiplex heterogeneous graph prototypical contrastive leaning (X-GOAL) framework to extract node embeddings. X-GOAL is comprised of two components: the GOAL framework, which learns node embeddings for each homogeneous graph layer, and an alignment regularization, which jointly models different layers by aligning layer-specific node embeddings. Specifically, the GOAL framework captures the node-level information by a succinct graph transformation technique, and captures the cluster-level information by pulling nodes within the same semantic cluster closer in the embedding space. The alignment regularization aligns embeddings across layers at both node level and cluster level. We evaluate the proposed X-GOAL on a variety of real-world datasets and downstream tasks to demonstrate the effectiveness of the X-GOAL framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "51178762",
                    "name": "Yuejia Xiang"
                },
                {
                    "authorId": "2145308154",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "2144837573",
                    "name": "Yu Chen"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        }
    ]
}