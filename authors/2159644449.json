{
    "authorId": "2159644449",
    "papers": [
        {
            "paperId": "200b2380b5d525a0e0d4826ea6f7eec38c013a8c",
            "title": "PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection",
            "abstract": "Recent literature has highlighted potential risks to academic integrity associated with large language models (LLMs), as they can memorize parts of training instances and reproduce them in the generated texts without proper attribution. In addition, given their capabilities in generating high-quality texts, plagiarists can exploit LLMs to generate realistic paraphrases or summaries indistinguishable from original work. In response to possible malicious use of LLMs in plagiarism, we introduce PlagBench, a comprehensive dataset consisting of 46.5K synthetic plagiarism cases generated using three instruction-tuned LLMs across three writing domains. The quality of PlagBench is ensured through fine-grained automatic evaluation for each type of plagiarism, complemented by human annotation. We then leverage our proposed dataset to evaluate the plagiarism detection performance of five modern LLMs and three specialized plagiarism checkers. Our findings reveal that GPT-3.5 tends to generates paraphrases and summaries of higher quality compared to Llama2 and GPT-4. Despite LLMs' weak performance in summary plagiarism identification, they can surpass current commercial plagiarism detectors. Overall, our results highlight the potential of LLMs to serve as robust plagiarism detection tools.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "2308035101",
                    "name": "Toshini Agrawal"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2260345102",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2308879633",
                    "name": "Jinghui Chen"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "5156b3be33abbc3267b2d41e35537bf33c149420",
            "title": "Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?",
            "abstract": "Advances in Large Language Models (e.g., GPT-4, LLaMA) have improved the generation of coherent sentences resembling human writing on a large scale, resulting in the creation of so-called deepfake texts. However, this progress poses security and privacy concerns, necessitating effective solutions for distinguishing deepfake texts from human-written ones. Although prior works studied humans\u2019 ability to detect deepfake texts, none has examined whether \u201ccollaboration\u201d among humans improves the detection of deepfake texts. In this study, to address this gap of understanding on deepfake texts, we conducted experiments with two groups: (1) nonexpert individuals from the AMT platform and (2) writing experts from the Upwork platform. The results demonstrate that collaboration among humans can potentially improve the detection of deepfake texts for both groups, increasing detection accuracies by 6.36% for non-experts and 12.76% for experts, respectively, compared to individuals\u2019 detection accuracies. We further analyze the explanations that humans used for detecting a piece of text as deepfake text, and find that the strongest indicator of deepfake texts is their lack of coherence and consistency. Our study provides useful insights for future tools and framework designs to facilitate the collaborative human detection of deepfake texts. The experiment datasets and AMT implementations are available at: https://github.com/huashen218/llm-deepfake-human-study.git",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "145028030",
                    "name": "Hua Shen"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "144188081",
                    "name": "Ting-Hao 'Kenneth' Huang"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "b91645729a769c09eddda2efe2512e2f6a750723",
            "title": "Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation",
            "abstract": "Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (.i.e, generating large-scale harmful and misleading content). To combat this emerging risk of LLMs, we propose a novel\"Fighting Fire with Fire\"(F3) strategy that harnesses modern LLMs' generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation. First, we leverage GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content through paraphrase-based and perturbation-based prefix-style prompts, respectively. Second, we apply zero-shot in-context semantic reasoning techniques with cloze-style prompts to discern genuine from deceptive posts and news articles. In our extensive experiments, we observe GPT-3.5-turbo's zero-shot superiority for both in-distribution and out-of-distribution datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike the decline observed in previous customized and fine-tuned disinformation detectors. Our codebase and dataset are available at https://github.com/mickeymst/F3.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260072705",
                    "name": "Jason Samuel Lucas"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "66848311",
                    "name": "Michiharu Yamashita"
                },
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "40408676",
                    "name": "Shaurya Rohatgi"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "bec51f0fcdc6cc5856f8484ebb3735eac0c814ff",
            "title": "Understanding Individual and Team-based Human Factors in Detecting Deepfake Texts",
            "abstract": "In recent years, Natural Language Generation (NLG) techniques in AI (e.g., T5, GPT-3, ChatGPT) have shown a massive improvement and are now capable of generating human-like long coherent texts at scale, yielding so-called deepfake texts . This advancement, despite their benefits, can also cause security and privacy issues (e.g., plagiarism, identity obfuscation, disinformation attack). As such, it has become critically important to develop e ff ective, practical, and scalable solutions to di ff erentiate deepfake texts from human-written texts. Toward this challenge, in this work, we investigate how factors such as skill levels and collaborations impact how humans identify deepfake texts, studying three research questions: (1) do collaborative teams detect deepfake texts better than individuals? (2) do expert humans detect deepfake texts better than non-expert humans? (3) what are the factors that maximize the detection performance of humans? We implement these questions on two platforms: (1) non-expert humans or asynchronous teams on Amazon Mechanical Turk (AMT) and (2) expert humans or synchronous teams on the Upwork. By analyzing the detection performance and the factors that a ff ected performance, some of our key findings are: (1) expert humans detect deepfake texts significantly better than non-expert humans, (2) synchronous teams on the Upwork detect deepfake texts significantly better than individuals, while asynchronous teams on the AMT detect deepfake texts weakly better than individuals, and (3) among various error categories, examining coherence and consistency in texts is useful in detecting deepfake texts. In conclusion, our work could inform the design of future tools / framework to improve collaborative human detection of deepfake texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "2257394534",
                    "name": "Hua Shen"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2253860510",
                    "name": "Ting-Hao Kenneth Huang"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "edb2adb18edb748f2f73a828c552b48a3bfaff5d",
            "title": "Comparison of L2 Korean pronunciation error patterns from five L1 backgrounds by using automatic phonetic transcription",
            "abstract": "This paper presents a large-scale analysis of L2 Korean pronunciation error patterns from five different language backgrounds, Chinese, Vietnamese, Japanese, Thai, and English, by using automatic phonetic transcription. For the analysis, confusion matrices are generated for each L1, by aligning canonical phone sequences and automatically transcribed phone sequences obtained from fine-tuned Wav2Vec2 XLS-R phone recognizer. Each value in the confusion matrices is compared to capture frequent common error patterns and to specify patterns unique to a certain language background. Using the Foreign Speakers' Voice Data of Korean for Artificial Intelligence Learning dataset, common error pattern types are found to be (1) substitutions of aspirated or tense consonants with plain consonants, (2) deletions of syllable-final consonants, and (3) substitutions of diphthongs with monophthongs. On the other hand, thirty-nine patterns including (1) syllable-final /l/ substitutions with /n/ for Vietnamese and (2) /\\textturnm/ insertions for Japanese are discovered as language-dependent.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "94069955",
                    "name": "E. Yeo"
                },
                {
                    "authorId": "2220304218",
                    "name": "Hyungshin Ryu"
                },
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "2109591731",
                    "name": "Sunhee Kim"
                },
                {
                    "authorId": "1727628",
                    "name": "Minhwa Chung"
                }
            ]
        },
        {
            "paperId": "0aa0936f8cb7dc7d83b54ab347492a7c5c1ba82c",
            "title": "Perturbations in the Wild: Leveraging Human-Written Text Perturbations for Realistic Adversarial Attack and Defense",
            "abstract": "We proposes a novel algorithm, ANTHRO, that inductively extracts over 600K human-written text perturbations in the wild and leverages them for realistic adversarial attack. Unlike existing character-based attacks which often deductively hypothesize a set of manipulation strategies, our work is grounded on actual observations from real-world texts. We find that adversarial texts generated by ANTHRO achieve the best trade-off between (1) attack success rate, (2) semantic preservation of the original text, and (3) stealthiness\u2013i.e. indistinguishable from human writings hence harder to be flagged as suspicious. Specifically, our attacks accomplished around 83% and 91% attack success rates on BERT and RoBERTa, respectively. Moreover, it outperformed the TextBugger baseline with an increase of 50% and 40% in terms of semantic preservation and stealthiness when evaluated by both layperson and professional human workers. ANTHRO can further enhance a BERT classifier\u2019s performance in understanding different variations of human-written toxic texts via adversarial training when compared to the Perspective API.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "2055489471",
                    "name": "Kevin Yen"
                },
                {
                    "authorId": "1809492",
                    "name": "Yifan Hu"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "ff96f2e0d00ddf63b3cc834bfb18b938b874ef0a",
            "title": "Korean Dialect Identification Based on an Ensemble of Prosodic and Segmental Feature Learning for Forensic Speaker Profiling",
            "abstract": "Telephonic fraud, or voice phishing, is becoming a major issue in South Korea, and there has been a high demand on AI-assisted solutions in the forensic areas to effectively narrow down the boundary of possible suspects. One such demand is use of automated Korean dialect identification in speaker profiling, which aims to classify dialect candidates of a suspect by analyzing dialectal patterns in speech, which are found in segmental and prosodic parts of the language. In this paper, an ensemble of dialect classifiers is proposed that considers both the segmental and the prosodic speech features. The classifier network is an ensemble of two sub-networks, which are an attention-based bidirectional LSTM network and a vanilla DNN for prosodic and segmental feature learning, respectively. A public dataset of Korean conversational speech is used, and the proposed model shows 61.28% in F-measure, which outperforms the baseline by 25.87%p.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159644449",
                    "name": "Jooyoung Lee"
                },
                {
                    "authorId": "2155074754",
                    "name": "K. Kim"
                },
                {
                    "authorId": "1727628",
                    "name": "Minhwa Chung"
                }
            ]
        }
    ]
}