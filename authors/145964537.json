{
    "authorId": "145964537",
    "papers": [
        {
            "paperId": "fcdacb3874356cbe54301cbcf74edb725e6d8e75",
            "title": "Significant ASR Error Detection for Conversational Voice Assistants",
            "abstract": "Modern Automatic Speech Recognition (ASR) systems are evaluated with respect to Word Error Rate (WER). While WER is a useful metric for training and evaluation of speech models, it does not fully reflect the difference in semantics between predicted and ground truth transcriptions. In conversational voice assistants, the ability to sufficiently understand semantic meaning of the user request is often more important than recognizing all words correctly. In this work, we propose a system that can determine, to a high degree of accuracy, whether the semantics of a predicted and reference transcript are significantly different. This knowledge is used to identify ASR errors that can result in downstream failure in conversational voice assistants. Reliable identification of these errors can be used to inform design choices for ASR systems targeting improvement on the most harmful errors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "104619254",
                    "name": "John Harvill"
                },
                {
                    "authorId": "145964537",
                    "name": "R. Khaziev"
                },
                {
                    "authorId": "2292671120",
                    "name": "Scarlett Li"
                },
                {
                    "authorId": "2292624944",
                    "name": "Randy Cogill"
                },
                {
                    "authorId": "2292674693",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "2292630742",
                    "name": "Gopinath Chennupati"
                },
                {
                    "authorId": "2292640763",
                    "name": "Hari Thadakamalla"
                }
            ]
        },
        {
            "paperId": "9369f9b7946d3fed4a1926ccf0942fcf3456191b",
            "title": "Self-Healing Through Error Detection, Attribution, and Retraining",
            "abstract": "Negative feedback received from users of voice agents can provide valuable training signal to their underlying ML systems. However, such systems tend to have complex inference pipelines consisting of multiple model-based and deterministic components. Therefore, when negative feedback is received, it can be difficult to attribute the system error to a specific sub-component. In this work, we address this challenge by building a system for error attribution and correction. We prototype attributing errors to the ML models used for do-main classification (DC) in the NLU component of an assistant\u2019s pipeline, using a combination of a model and rule based system. We propose a simple method to add these detected errors directly to offline DC model training, and study our system\u2019s effectiveness on a challenging test set of low-frequency utterances. Our experiments on nine domains suggest that augmenting DC training data with our method significantly improves performance on a majority of them.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46295533",
                    "name": "Ansel MacLaughlin"
                },
                {
                    "authorId": "1681193",
                    "name": "Anna Rumshisky"
                },
                {
                    "authorId": "145964537",
                    "name": "R. Khaziev"
                },
                {
                    "authorId": "2351994",
                    "name": "Anil Ramakrishna"
                },
                {
                    "authorId": "2551462",
                    "name": "Yuval Merhav"
                },
                {
                    "authorId": "145542597",
                    "name": "Rahul Gupta"
                }
            ]
        },
        {
            "paperId": "8d0ddeab6ef624d15db320eaa38df282c4dfa33a",
            "title": "FPI: Failure Point Isolation in Large-scale Conversational Assistants",
            "abstract": "Large-scale conversational assistants such as Cortana, Alexa, Google Assistant and Siri process requests through a series of modules for wake word detection, speech recognition, language understanding and response generation. An error in one of these modules can cascade through the system. Given the large traffic volumes in these assistants, it is infeasible to manually analyze the data, identify requests with processing errors and isolate the source of error. We present a machine learning system to address this challenge. First, we embed the incoming request and context, such as system response and subsequent turns, using pre-trained transformer models. Then, we combine these embeddings with encodings of additional metadata features (such as confidence scores from different modules in the online system) using a \u201cmixing-encoder\u201d to output the failure point predictions. Our system obtains 92.2% of human performance on this task while scaling to analyze the entire traffic in 8 different languages of a large-scale conversational assistant. We present detailed ablation studies analyzing the impact of different modeling choices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145964537",
                    "name": "R. Khaziev"
                },
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "2240075710",
                    "name": "Tobias R\u00f6ding"
                },
                {
                    "authorId": "147887099",
                    "name": "Rakesh Chada"
                },
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                }
            ]
        },
        {
            "paperId": "89caf9fb67cf1c33700d74b1724441e8b2f02c2b",
            "title": "Recommendation or Discrimination?: Quantifying Distribution Parity in Information Retrieval Systems",
            "abstract": "Information retrieval (IR) systems often leverage query data to suggest relevant items to users. This introduces the possibility of unfairness if the query (i.e., input) and the resulting recommendations unintentionally correlate with latent factors that are protected variables (e.g., race, gender, and age). For instance, a visual search system for fashion recommendations may pick up on features of the human models rather than fashion garments when generating recommendations. In this work, we introduce a statistical test for \"distribution parity\" in the top-K IR results, which assesses whether a given set of recommendations is fair with respect to a specific protected variable. We evaluate our test using both simulated and empirical results. First, using artificially biased recommendations, we demonstrate the trade-off between statistically detectable bias and the size of the search catalog. Second, we apply our test to a visual search system for fashion garments, specifically testing for recommendation bias based on the skin tone of fashion models. Our distribution parity test can help ensure that IR systems' results are fair and produce a good experience for all users.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "145964537",
                    "name": "R. Khaziev"
                },
                {
                    "authorId": "46233806",
                    "name": "Bryce Casavant"
                },
                {
                    "authorId": "3094515",
                    "name": "Pearce Washabaugh"
                },
                {
                    "authorId": "7462442",
                    "name": "Amy A. Winecoff"
                },
                {
                    "authorId": "2055069593",
                    "name": "Matthew Graham"
                }
            ]
        }
    ]
}