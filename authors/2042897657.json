{
    "authorId": "2042897657",
    "papers": [
        {
            "paperId": "9ecf184dd657640cbd1c4cc0f3c801ebd9d53162",
            "title": "ReactIE: Enhancing Chemical Reaction Extraction with Weak Supervision",
            "abstract": "Structured chemical reaction information plays a vital role for chemists engaged in laboratory work and advanced endeavors such as computer-aided drug design. Despite the importance of extracting structured reactions from scientific literature, data annotation for this purpose is cost-prohibitive due to the significant labor required from domain experts. Consequently, the scarcity of sufficient training data poses an obstacle to the progress of related models in this domain. In this paper, we propose ReactIE, which combines two weakly supervised approaches for pre-training. Our method utilizes frequent patterns within the text as linguistic cues to identify specific characteristics of chemical reactions. Additionally, we adopt synthetic data from patent records as distant supervision to incorporate domain knowledge into the model. Experiments demonstrate that ReactIE achieves substantial improvements and outperforms all existing baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1606040932",
                    "name": "Ming Zhong"
                },
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "2800541",
                    "name": "Minhao Jiang"
                },
                {
                    "authorId": "50161308",
                    "name": "Vivian Hu"
                },
                {
                    "authorId": "1381900594",
                    "name": "Yizhu Jiao"
                },
                {
                    "authorId": "2154990549",
                    "name": "Xuan Wang"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "cb1e09e90ab076471c8b8825d70c394c1a423eed",
            "title": "Compositional Data Augmentation for Abstractive Conversation Summarization",
            "abstract": "Recent abstractive conversation summarization systems generally rely on large-scale datasets with annotated summaries. However, collecting and annotating these conversations can be a time-consuming and labor-intensive task. To address this issue, in this work, we present a sub-structure level compositional data augmentation method, Compo, for generating diverse and high-quality pairs of conversations and summaries. Specifically, Compo first extracts conversation structures like topic splits and action triples as basic units. Then we organize these semantically meaningful conversation snippets compositionally to create new training instances.Additionally, we explore noise-tolerant settings in both self-training and joint-training paradigms to make the most of these augmented samples. Our experiments on benchmark datasets, SAMSum and DialogSum, show that Compo substantially outperforms prior baseline methods by achieving a nearly 10% increase of ROUGE scores with limited data. Code is available at https://github.com/ozyyshr/Compo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "47739850",
                    "name": "Jiaao Chen"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2143919864",
                    "name": "Diyi Yang"
                }
            ]
        },
        {
            "paperId": "e56aa728aaa32c087c8f7bc56a7eb225675dd8ae",
            "title": "Structured Chemistry Reasoning with Large Language Models",
            "abstract": "Large Language Models (LLMs) excel in diverse areas, yet struggle with complex scientific reasoning, especially in the field of chemistry. Different from the simple chemistry tasks (e.g., molecule classification) addressed in previous studies, complex chemistry problems require not only vast knowledge and precise calculation, but also compositional reasoning about rich dynamic interactions of different concepts (e.g., temperature changes). Our study shows that even advanced LLMs, like GPT-4, can fail easily in different ways. Interestingly, the errors often stem not from a lack of domain knowledge within the LLMs, but rather from the absence of an effective reasoning structure that guides the LLMs to elicit the right knowledge, incorporate the knowledge in step-by-step reasoning, and iteratively refine results for further improved quality. On this basis, we introduce StructChem, a simple yet effective prompting strategy that offers the desired guidance and substantially boosts the LLMs' chemical reasoning capability. Testing across four chemistry areas -- quantum chemistry, mechanics, physical chemistry, and kinetics -- StructChem substantially enhances GPT-4's performance, with up to 30\\% peak improvement. Our analysis also underscores the unique difficulties of precise grounded reasoning in science with LLMs, highlighting a need for more research in this area. Code is available at \\url{https://github.com/ozyyshr/StructChem}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "2267016631",
                    "name": "Zhuosheng Zhang"
                },
                {
                    "authorId": "2266886449",
                    "name": "Bing Yan"
                },
                {
                    "authorId": "2271402844",
                    "name": "Xuan Liu"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2267901975",
                    "name": "Lianhui Qin"
                }
            ]
        },
        {
            "paperId": "f74a7c4a2d0a0fe41a77357ce11a519f5b059dee",
            "title": "Towards End-to-End Open Conversational Machine Reading",
            "abstract": "In open-retrieval conversational machine reading (OR-CMR) task, machines are required to do multi-turn question answering given dialogue history and a textual knowledge base. Existing works generally utilize two independent modules to approach this problem\u2019s two successive sub-tasks: first with a hard-label decision making and second with a question generation aided by various entailment reasoning methods. Such usual cascaded modeling is vulnerable to error propagation and prevents the two sub-tasks from being consistently optimized. In this work, we instead model OR-CMR as a unified text-to-text task in a fully end-to-end style. Experiments on the ShARC and OR-ShARC dataset show the effectiveness of our proposed end-to-end framework on both sub-tasks by a large margin, achieving new state-of-the-art results. Further ablation studies support that our framework can generalize to different backbone models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187778761",
                    "name": "Sizhe Zhou"
                },
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "3322871",
                    "name": "Zhuosheng Zhang"
                },
                {
                    "authorId": "2187683120",
                    "name": "Hai Zhao Department of Computer Science"
                },
                {
                    "authorId": "2285034440",
                    "name": "Engineering"
                },
                {
                    "authorId": "102642891",
                    "name": "S. University"
                },
                {
                    "authorId": "2187683292",
                    "name": "Key Laboratory of Shanghai Education Commission for In Interaction"
                },
                {
                    "authorId": "2187682684",
                    "name": "Cognitive Engineering"
                },
                {
                    "authorId": "67312653",
                    "name": "Moe Intelligence"
                },
                {
                    "authorId": "2187682421",
                    "name": "AI Institute"
                }
            ]
        },
        {
            "paperId": "52c5c9575ebd990ed34867708dd42aa8ba9d561f",
            "title": "Smoothing Dialogue States for Open Conversational Machine Reading",
            "abstract": "Conversational machine reading (CMR) requires machines to communicate with humans through multi-turn interactions between two salient dialogue states of decision making and question generation processes. In open CMR settings, as the more realistic scenario, the retrieved background knowledge would be noisy, which results in severe challenges in the information transmission. Existing studies commonly train independent or pipeline systems for the two subtasks. However, those methods are trivial by using hard-label decisions to activate question generation, which eventually hinders the model performance. In this work, we propose an effective gating strategy by smoothing the two dialogue states in only one decoder and bridge decision making and question generation to provide a richer dialogue state reference. Experiments on the OR-ShARC dataset show the effectiveness of our method, which achieves new state-of-the-art results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3322871",
                    "name": "Zhuosheng Zhang"
                },
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "153716230",
                    "name": "Hai Zhao"
                },
                {
                    "authorId": "1802277",
                    "name": "M. Utiyama"
                },
                {
                    "authorId": "1698363",
                    "name": "E. Sumita"
                }
            ]
        },
        {
            "paperId": "646633e653b2ab2436fd52e31a57ee321272fe6e",
            "title": "Fact-Driven Logical Reasoning for Machine Reading Comprehension",
            "abstract": "Recent years have witnessed an increasing interest in training machines with reasoning ability, which deeply relies on accurately and clearly presented clue forms. The clues are usually modeled as entity-aware knowledge in existing studies. However, those entity-aware clues are primarily focused on commonsense, making them insufficient for tasks that require knowledge of temporary facts or events, particularly in logical reasoning for reading comprehension. To address this challenge, we are motivated to cover both commonsense and temporary knowledge clues hierarchically. Specifically, we propose a general formalism of knowledge units by extracting backbone constituents of the sentence, such as the subject-verb-object formed ``facts''. We then construct a supergraph on top of the fact units, allowing for the benefit of sentence-level (relations among fact groups) and entity-level interactions (concepts or actions inside a fact). Experimental results on logical reasoning benchmarks and dialogue modeling datasets show that our approach improves the baselines substantially, and it is general across backbone models. Code is available at https://github.com/ozyyshr/FocalReasoner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "3322871",
                    "name": "Zhuosheng Zhang"
                },
                {
                    "authorId": "2146232510",
                    "name": "Hai Zhao"
                }
            ]
        },
        {
            "paperId": "6d3287e0de1474d3143c386c4e95cdf9437df1a3",
            "title": "Fact-driven Logical Reasoning",
            "abstract": "Logical reasoning, which is closely related to human cognition, is of vital importance in human\u2019s understanding of texts. Recent years have witnessed increasing attentions on machine\u2019s logical reasoning abilities. However, previous studies commonly apply ad-hoc methods to model pre-de\ufb01ned relation patterns, such as linking named entities, which only considers global knowledge components that are related to commonsense, without local perception of complete facts or events. Such methodology is obviously insuf\ufb01cient to deal with complicated logical structures. Therefore, we argue that the natural logic units would be the group of backbone constituents of the sentence such as the subject-verb-object formed \"facts\", covering both global and local knowledge pieces that are necessary as the basis for logical reasoning. Beyond building the ad-hoc graphs, we propose a more general and convenient fact-driven approach to construct a supergraph on top of our newly de\ufb01ned fact units, and enhance the supergraph with further explicit guidance of local question and option interactions. Experiments on two challenging logical reasoning benchmark datasets, ReClor and LogiQA, show that our proposed model, F OCAL R EASONER , outperforms the baseline models dramatically. It can also be smoothly applied to other downstream tasks such as MuTual, a dialogue reasoning dataset, achieving competitive results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "3322871",
                    "name": "Zhuosheng Zhang"
                },
                {
                    "authorId": "153716230",
                    "name": "Hai Zhao"
                }
            ]
        },
        {
            "paperId": "d174cf3d233e4ea578afae3703816fdf88c13b27",
            "title": "Two-Hop Relay Deployment Based on User Trajectory in Wireless Networks",
            "abstract": "The traditional relay deployment problem typically assumes that the locations of users are known and stationary, which is not realistic in practice. The prevalence of mobile devices has made it possible to collect user trajectory and account for user movement while deploying relays. Under this background, a novel problem trajectory-based relay deployment (TBRD) is put forward. This problem considers communication-related metrics and is aimed at maximizing user connection time as users roam through the target area under relay resource constraints, which is more reasonable than the goal of expanding the relay coverage. To figure out the TBRD, we first propose the concept demand nodes (DNs), which are virtual weighted nodes representing the locations where users frequently pass or stay for a long period. Next, we design a Demand Node Generation algorithm that can transform the continuous historical user trajectory into a number of discrete DNs. By generating DNs, we convert the TBRD problem into a demand node coverage (DNC) problem, which is proved to be NP-complete. Followed by that, we introduce an approximation algorithm, named Submodular Iterative Deployment Algorithm , which solves the DNC problem with the approximation factor 1 \u2212 1 \u221a e \u00b7 ( 1 \u2212 1 / k ) , where e is the mathematical constant, and k is the relay number constraint. Finally, five real trajectory datasets are used to evaluate our proposed algorithm, and the simulation results demonstrate that our algorithm can obtain high coverage for users in motion, which can lead to better user experience. In addition, we also analyze the impact of different parameters on the coverage performance, and under this circumstance, we may safely come to the conclusion that our work is at the leading edge to utilize user trajectories for relay deployment in wireless networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2004324389",
                    "name": "Zhiyao Li"
                },
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "11732258",
                    "name": "Xiaofeng Gao"
                },
                {
                    "authorId": "2116378888",
                    "name": "Guihai Chen"
                }
            ]
        },
        {
            "paperId": "114be5db62209a0d0682279f5a054a316f56697e",
            "title": "Dialogue Graph Modeling for Conversational Machine Reading",
            "abstract": "Conversational Machine Reading (CMR) aims at answering questions in a complicated manner. Machine needs to answer questions through interactions with users based on given rule document, user scenario and dialogue history, and ask questions to clarify if necessary. In this paper, we propose a dialogue graph modeling framework to improve the understanding and reasoning ability of machine on CMR task. There are three types of graph in total. Specifically, Discourse Graph is designed to learn explicitly and extract the discourse relation among rule texts as well as the extra knowledge of scenario; Decoupling Graph is used for understanding local and contextualized connection within rule texts. And finally a global graph for fusing the information together and reply to the user with our final decision being either\"Yes/No/Irrelevant\"or to ask a follow-up question to clarify.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2042897657",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "3322871",
                    "name": "Zhuosheng Zhang"
                },
                {
                    "authorId": "47941144",
                    "name": "Hai Zhao"
                }
            ]
        }
    ]
}