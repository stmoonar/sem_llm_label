{
    "authorId": "2844293",
    "papers": [
        {
            "paperId": "2044d10c08584acee2081db2363ffb679d687df7",
            "title": "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization",
            "abstract": "Language models frequently inherit societal biases from their training data. Numerous techniques have been proposed to mitigate these biases during both the pre-training and fine-tuning stages. However, fine-tuning a pre-trained debiased language model on a downstream task can reintroduce biases into the model. Additionally, existing debiasing methods for downstream tasks either (i) require labels of protected attributes (e.g., age, race, or political views) that are often not available or (ii) rely on indicators of bias, which restricts their applicability to gender debiasing since they rely on gender-specific words. To address this, we introduce a novel debiasing regularization technique based on the class-wise variance of embeddings. Crucially, our method does not require attribute labels and targets any attribute, thus addressing the shortcomings of existing debiasing methods. Our experiments on encoder language models and three datasets demonstrate that our method outperforms existing strong debiasing baselines that rely on target attribute labels while maintaining performance on the target task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "2323514000",
                    "name": "Markus Frohman"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "c0a30b378bf897412426ba28e65c6392a65859bc",
            "title": "What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition",
            "abstract": "The knowledge encapsulated in a model is the core factor determining its final performance on downstream tasks. Much research in NLP has focused on efficient methods for storing and adapting different types of knowledge, e.g., in dedicated modularized structures, and on how to effectively combine these, e.g., by learning additional parameters. However, given the many possible options, a thorough understanding of the mechanisms involved in these compositions is missing, and hence it remains unclear which strategies to utilize. To address this research gap, we propose a novel framework for zero-shot module composition, which encompasses existing and some novel variations for selecting, weighting, and combining parameter modules under a single unified notion. Focusing on the scenario of domain knowledge and adapter layers, our framework provides a systematic unification of concepts, allowing us to conduct the first comprehensive benchmarking study of various zero-shot knowledge composition strategies. In particular, we test two module combination methods and five selection and weighting strategies for their effectiveness and efficiency in an extensive experimental setup. Our results highlight the efficacy of ensembling but also hint at the power of simple though often-ignored weighting methods. Further in-depth analyses allow us to understand the role of weighting vs. top-k selection, and show that, to a certain extent, the performance of adapter composition can even be predicted.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161965407",
                    "name": "Carolin Holtermann"
                },
                {
                    "authorId": "2226600284",
                    "name": "Markus Frohmann"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "29891652",
                    "name": "Anne Lauscher"
                }
            ]
        },
        {
            "paperId": "03627e32a048ba71ad6ed632df2f3669464a7dae",
            "title": "Domain Information Control at Inference Time for Acoustic Scene Classification",
            "abstract": "Domain shift is considered a challenge in machine learning as it causes significant degradation of model performance. In the Acoustic Scene Classification task (ASC), domain shift is mainly caused by different recording devices. Several studies have already targeted domain generalization to improve the performance of ASC models on unseen domains, such as new devices. Recently, the Controllable Gate Adapter (CONGATER) has been proposed in Natural Language Processing to address the biased training data problem. CONGATER allows controlling the debiasing process at inference time. CONGATER's main advantage is the continuous and selective debiasing of a trained model, during inference. In this work, we adapt CONGATER to the audio spectrogram transformer for an acoustic scene classification task. We show that CONGATER can be used to selectively adapt the learned representations to be invariant to device domain shifts such as recording devices. Our analysis shows that CONGATER can progressively remove device information from the learned representations and improve the model generalization, especially under domain shift conditions (e.g. unseen devices). We show that information removal can be extended to both device and location domain. Finally, we demonstrate CONGATER's ability to enhance specific device performance without further training11Source Code: https://github.com/ShawMaskldcase22_CONGATER.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "28921847",
                    "name": "Khaled Koutini"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "145964711",
                    "name": "G. Widmer"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "2cbadfa44dd2818738943c0be4a4cbd69aac9b95",
            "title": "Computational Versus Perceived Popularity Miscalibration in Recommender Systems",
            "abstract": "Popularity bias in recommendation lists refers to over-representation of popular content and is a challenge for many recommendation algorithms. Previous research has suggested several offline metrics to quantify popularity bias, which commonly relate the popularity of items in users' recommendation lists to the popularity of items in their interaction history. Discrepancies between these two factors are referred to as popularity miscalibration. While popularity metrics provide a straightforward and well-defined means to measure popularity bias, it is unknown whether they actually reflect users' perception of popularity bias. To address this research gap, we conduct a crowd-sourced user study on Prolific, involving 56 participants, to (1) investigate whether the level of perceived popularity miscalibration differs between common recommendation algorithms, (2) assess the correlation between perceived popularity miscalibration and its corresponding quantification according to a common offline metric. We conduct our study in a well-defined and important domain, namely music recommendation using the standardized LFM-2b dataset, and quantify popularity miscalibration of five recommendation algorithms by utilizing Jensen-Shannon distance (JSD). Challenging the findings of previous studies, we observe that users generally do perceive significant differences in terms of popularity bias between algorithms if this bias is framed as popularity miscalibration. In addition, JSD correlates moderately with users' perception of popularity, but not with their perception of unpopularity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "2223770106",
                    "name": "Gustavo Escobedo"
                },
                {
                    "authorId": "2614755",
                    "name": "Yashar Deldjoo"
                },
                {
                    "authorId": "3001795",
                    "name": "B. Ferwerda"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "331d5e29442cd28618921f8db5264099a15ba686",
            "title": "Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors",
            "abstract": "Sparse annotation poses persistent challenges to training dense retrieval models; for example, it distorts the training signal when unlabeled relevant documents are used spuriously as negatives in contrastive learning. To alleviate this problem, we introduce evidence-based label smoothing, a novel, computationally efficient method that prevents penalizing the model for assigning high relevance to false negatives. To compute the target relevance distribution over candidate documents within the ranking context of a given query, we assign a non-zero relevance probability to those candidates most similar to the ground truth based on the degree of their similarity to the ground-truth document(s). To estimate relevance we leverage an improved similarity metric based on reciprocal nearest neighbors, which can also be used independently to rerank candidates in post-processing. Through extensive experiments on two large-scale ad hoc text retrieval datasets, we demonstrate that reciprocal nearest neighbors can improve the ranking effectiveness of dense retrieval models, both when used for label smoothing, as well as for reranking. This indicates that by considering relationships between documents and queries beyond simple geometric distance we can effectively enhance the ranking context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30647302",
                    "name": "George Zerveas"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "30044743",
                    "name": "Carsten Eickhoff"
                }
            ]
        },
        {
            "paperId": "33ffff57ffec2eee714ccda7d9567dce1181e88b",
            "title": "Enhancing the Ranking Context of Dense Retrieval Methods through Reciprocal Nearest Neighbors",
            "abstract": "Sparse annotation poses persistent challenges to training dense retrieval models, such as the problem of false negatives, i.e. unlabeled relevant documents that are spuriously used as negatives in contrastive learning, distorting the training signal. To alleviate this problem, we introduce evidence-based label smoothing, a computationally efficient method that prevents penalizing the model for assigning high relevance to false negatives. To compute the target relevance distribution over candidate documents within the ranking context of a given query, candidates most similar to the ground truth are assigned a non-zero relevance probability based on the degree of their similarity to the ground-truth document(s). As a relevance estimate we leverage an improved similarity metric based on reciprocal nearest neighbors, which can also be used independently to rerank candidates in post-processing. Through extensive experiments on two large-scale ad hoc text retrieval datasets we demonstrate that both methods can improve the ranking effectiveness of dense retrieval models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30647302",
                    "name": "George Zerveas"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "30044743",
                    "name": "Carsten Eickhoff"
                }
            ]
        },
        {
            "paperId": "3d4545b069bd3f24b02b5f6f8ceffadd09b7973b",
            "title": "Natural language processing for humanitarian action: Opportunities, challenges, and the path toward humanitarian NLP",
            "abstract": "Natural language processing (NLP) is a rapidly evolving field at the intersection of linguistics, computer science, and artificial intelligence, which is concerned with developing methods to process and generate language at scale. Modern NLP tools have the potential to support humanitarian action at multiple stages of the humanitarian response cycle. Both internal reports, secondary text data (e.g., social media data, news media articles, or interviews with affected individuals), and external-facing documents like Humanitarian Needs Overviews (HNOs) encode information relevant to monitoring, anticipating, or responding to humanitarian crises. Yet, lack of awareness of the concrete opportunities offered by state-of-the-art techniques, as well as constraints posed by resource scarcity, limit adoption of NLP tools in the humanitarian sector. This paper provides a pragmatically-minded primer to the emerging field of humanitarian NLP, reviewing existing initiatives in the space of humanitarian NLP, highlighting potentially impactful applications of NLP in the humanitarian sector, and describing criteria, challenges, and potential solutions for large-scale adoption. In addition, as one of the main bottlenecks is the lack of data and standards for this domain, we present recent initiatives (the DEEP and HumSet) which are directly aimed at addressing these gaps. With this work, we hope to motivate humanitarians and NLP experts to create long-term impact-driven synergies and to co-develop an ambitious roadmap for the field.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40225220",
                    "name": "R. Rocca"
                },
                {
                    "authorId": "1993591232",
                    "name": "Nicol\u00f2 Tamagnone"
                },
                {
                    "authorId": "2187300092",
                    "name": "Selim Fekih"
                },
                {
                    "authorId": "2187301044",
                    "name": "Ximena Contla"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "605755564694f22a63ad5f17116704077182cdbd",
            "title": "Show me a \"Male Nurse\"! How Gender Bias is Reflected in the Query Formulation of Search Engine Users",
            "abstract": "Biases in algorithmic systems have led to discrimination against historically disadvantaged groups, including the reinforcement of outdated gender stereotypes. While a substantial body of research addresses biases in algorithms and underlying data, in this work, we study if and how users themselves reflect these biases in their interactions with systems, which expectedly leads to the further manifestation of biases. More specifically, we investigate the replication of stereotypical gender representations by users in formulating online search queries. Following prototype theory, we define the disproportionate mention of the gender that does not conform to the prototypical representative of a searched domain (e.g., \u201cmale nurse\u201d) as an indication of bias. In a pilot study with 224 US participants and a main study with 400 UK participants, we find clear evidence of gender biases in formulating search queries. We also report the effects of an educative text on user behaviour and highlight the wish of users to learn about bias-mitigating strategies in their interactions with search engines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "2424581",
                    "name": "Martina Mara"
                },
                {
                    "authorId": "2214759238",
                    "name": "Linda Ratz"
                },
                {
                    "authorId": "2150483265",
                    "name": "Klara Krieg"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "aa27b60d9ba65306502e083f4778982cad71efaa",
            "title": "Leveraging Vision-Language Models for Granular Market Change Prediction",
            "abstract": "Predicting future direction of stock markets using the historical data has been a fundamental component in \ufb01nancial forecasting. This historical data contains the information of a stock in each speci\ufb01c time span, such as the opening, closing, lowest, and highest price. Lever- aging this data, the future direction of the market is commonly predicted using various time-series models such as Long-Short Term Memory networks. This work proposes modeling and predicting market movements with a fundamentally new approach, namely by utiliz-ing image and byte-based number representation of the stock data processed with the recently introduced Vision-Language models. We conduct a large set of experiments on the hourly stock data of the German share index and evaluate various architectures on stock price prediction using historical stock data. We conduct a comprehen-sive evaluation of the results with various metrics to accurately depict the actual performance of various approaches. Our evaluation results show that our novel approach based on representation of stock data as text (bytes) and image signi\ufb01cantly outperforms strong deep learning-based baselines.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "2202462256",
                    "name": "Christopher Wimmer"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "c4ca8096f11af3c8657dd8497a4e8dcb2428d7ee",
            "title": "ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
            "abstract": "Multi-task learning (MTL) has shown considerable practical benefits, particularly when using language models (LMs). While this is commonly achieved by learning $n$ tasks under a joint optimization procedure, some methods, such as AdapterFusion, divide the problem into two stages: (i) task learning, where knowledge specific to a task is encapsulated within sets of parameters (e.g., adapters), and (ii) transfer, where this already learned knowledge is leveraged for a target task. This separation of concerns provides numerous benefits (e.g., promoting reusability). However, current two-stage MTL introduces a substantial number of additional parameters. We address this issue by leveraging the usefulness of linearly scaling the output representations of source adapters for transfer learning. We introduce ScaLearn, a simple and highly parameter-efficient two-stage MTL method that capitalizes on the knowledge of the source tasks by learning a minimal set of scaling parameters that enable effective transfer to a target task. Our experiments on three benchmarks (GLUE, SuperGLUE, and HumSet) and two encoder LMs show that ScaLearn consistently outperforms strong baselines with a small number of transfer parameters (~ $0.35$% of those of AdapterFusion). Remarkably, we observe that ScaLearn maintains its strong abilities even when further reducing parameters, achieving competitive results with only $8$ transfer parameters per target task. Our proposed approach thus demonstrates the power of simple scaling as a promise for more efficient task transfer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2226600284",
                    "name": "Markus Frohmann"
                },
                {
                    "authorId": "2161965407",
                    "name": "Carolin Holtermann"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "29891652",
                    "name": "Anne Lauscher"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        }
    ]
}