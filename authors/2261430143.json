{
    "authorId": "2261430143",
    "papers": [
        {
            "paperId": "161438c5cf4412eeb0e551c2ea4f16c5123de1fa",
            "title": "Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation",
            "abstract": "As user behaviors become complicated on business platforms, online recommendations focus more on how to touch the core conversions, which are highly related to the interests of platforms. These core conversions are usually continuous targets, such as \\textit{watch time}, \\textit{revenue}, and so on, whose predictions can be enhanced by previous discrete conversion actions. Therefore, multi-task learning (MTL) can be adopted as the paradigm to learn these hybrid targets. However, existing works mainly emphasize investigating the sequential dependence among discrete conversion actions, which neglects the complexity of dependence between discrete conversions and the final continuous conversion. Moreover, simultaneously optimizing hybrid tasks with stronger task dependence will suffer from volatile issues where the core regression task might have a larger influence on other tasks. In this paper, we study the MTL problem with hybrid targets for the first time and propose the model named Hybrid Targets Learning Network (HTLNet) to explore task dependence and enhance optimization. Specifically, we introduce label embedding for each task to explicitly transfer the label information among these tasks, which can effectively explore logical task dependence. We also further design the gradient adjustment regime between the final regression task and other classification tasks to enhance the optimization. Extensive experiments on two offline public datasets and one real-world industrial dataset are conducted to validate the effectiveness of HTLNet. Moreover, online A/B tests on the financial recommender system also show that our model has improved significantly. Our implementation is available here\\footnote{\\url{https://github.com/fuyuanlyu/HTLNet}}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2204648054",
                    "name": "Yang Qiao"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2257136810",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                }
            ]
        },
        {
            "paperId": "1d25eb96d7a3e2b26735df9a4c6cdb3cfecb96e3",
            "title": "Benchmarking for Deep Uplift Modeling in Online Marketing",
            "abstract": "Online marketing is critical for many industrial platforms and business applications, aiming to increase user engagement and platform revenue by identifying corresponding delivery-sensitive groups for specific incentives, such as coupons and bonuses. As the scale and complexity of features in industrial scenarios increase, deep uplift modeling (DUM) as a promising technique has attracted increased research from academia and industry, resulting in various predictive models. However, current DUM still lacks some standardized benchmarks and unified evaluation protocols, which limit the reproducibility of experimental results in existing studies and the practical value and potential impact in this direction. In this paper, we provide an open benchmark for DUM and present comparison results of existing models in a reproducible and uniform manner. To this end, we conduct extensive experiments on two representative industrial datasets with different preprocessing settings to re-evaluate 13 existing models. Surprisingly, our experimental results show that the most recent work differs less than expected from traditional work in many cases. In addition, our experiments also reveal the limitations of DUM in generalization, especially for different preprocessing and test distributions. Our benchmarking work allows researchers to evaluate the performance of new models quickly but also reasonably demonstrates fair comparison results with existing models. It also gives practitioners valuable insights into often overlooked considerations when deploying DUM. We will make this benchmarking library, evaluation protocol, and experimental setup available on GitHub.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2204648054",
                    "name": "Yang Qiao"
                },
                {
                    "authorId": "2144067082",
                    "name": "Miao Liu"
                },
                {
                    "authorId": "2257124500",
                    "name": "Zexu Sun"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2304455592",
                    "name": "Zhong Ming"
                }
            ]
        },
        {
            "paperId": "36c87f474378d3b352dc125d22cec672fd3c54c3",
            "title": "MultiFS: Automated Multi-Scenario Feature Selection in Deep Recommender Systems",
            "abstract": "Multi-scenario recommender systems (MSRSs) have been increasingly used in real-world industrial platforms for their excellent advantages in mitigating data sparsity and reducing maintenance costs. However, conventional MSRSs usually use all relevant features indiscriminately and ignore that different kinds of features have varying importance under different scenarios, which may cause confusion and performance degradation. In addition, existing feature selection methods for deep recommender systems may lack the exploration of scenario relations. In this paper, we propose a novel automated multi-scenario feature selection (MultiFS) framework to bridge this gap, which is able to consider scenario relations and utilize a hierarchical gating mechanism to select features for each scenario. Specifically, MultiFS first efficiently obtains feature importance across all the scenarios through a scenario-shared gate. Then, some scenario-specific gate aims to identify feature importance to individual scenarios from a subset of the former with lower importance. Subsequently, MultiFS imposes constraints on the two gates to make the learning mechanism more feasible and combines the two to select exclusive features for different scenarios. We evaluate MultiFS and demonstrate its ability to enhance the multi-scenario model performance through experiments over two public multi-scenario benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2290696975",
                    "name": "Chaohua Yang"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2261426672",
                    "name": "Weihong Luo"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2240535483",
                    "name": "Zhong Ming"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "4e68fbaa4eed750e762ad274ee67de136e8a92f1",
            "title": "End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling",
            "abstract": "In modern online platforms, incentives are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentives to individual customers. Especially in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem. This optimization aims to select the optimal incentive for each customer to maximize the return on investment. Recent works in this field frequently tackle the budget allocation problem using a two-stage approach. However, this solution is confronted with the following challenges: (1) The causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) An optimality gap between the two stages results in inferior sub-optimal allocation performance due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel End-to-End Cost-Effective Incentive Recommendation (E3IR) model under budget constraints. Specifically, our methods consist of two modules, i.e., the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (i.e., monotonic and smooth). We incorporate integer linear programming (ILP) as a differentiable layer input in the allocation module. Furthermore, we conduct extensive experiments on public and real product datasets, demonstrating that our E3IR improves allocation performance compared to existing two-stage approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257124500",
                    "name": "Zexu Sun"
                },
                {
                    "authorId": "2303418512",
                    "name": "Hao Yang"
                },
                {
                    "authorId": "2257136810",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "81049933",
                    "name": "Yunpeng Weng"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                }
            ]
        },
        {
            "paperId": "4f0cb55cf6f23e88ce1824a3100f686cc5912dfe",
            "title": "AutoDCS: Automated Decision Chain Selection in Deep Recommender Systems",
            "abstract": "Multi-behavior recommender systems (MBRS) have been commonly deployed on real-world industrial platforms for their superior advantages in understanding user preferences and mitigating data sparsity. However, the cascade graph modeling paradigm adopted in mainstream MBRS usually assumes that users will refer to all types of behavioral knowledge they have when making decisions about target behaviors, i.e., use all types of behavioral interactions indiscriminately when modeling and predicting target behaviors for each user. We call this a full decision chain constraint and argue that it may be too strict by ignoring that different types of behavioral knowledge have varying importance for different users. In this paper, we propose a novel automated decision chain selection (AutoDCS) framework to relax this constraint, which can consider each user\u2019s unique decision dependencies and select a reasonable set of behavioral knowledge to activate for the prediction of target behavior. Specifically, AutoDCS first integrates some existing MBRS methods in a base cascade module to obtain a set of behavior-aware embeddings. Then, a bilateral matching gating mechanism is used to select an exclusive set of behaviors for the current user-item pair to form a decision chain, and the corresponding behavior-augmented embeddings are selectively activated. Subse-quently, AutoDCS combines the behavior-augmented and original behavior-aware embeddings to predict the target behavior. Finally, we evaluate AutoDCS and demonstrate its effectiveness through experiments over four public multi-behavior benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2304454810",
                    "name": "Shenxian Xian"
                },
                {
                    "authorId": "2240770864",
                    "name": "Yuhao Wu"
                },
                {
                    "authorId": "2290696975",
                    "name": "Chaohua Yang"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2304455592",
                    "name": "Zhong Ming"
                }
            ]
        },
        {
            "paperId": "5d47243a1d773f4f99ca6bc9ab7e6a4d99554a18",
            "title": "Expected Transaction Value Optimization for Precise Marketing in FinTech Platforms",
            "abstract": "FinTech platforms facilitated by digital payments are watching growth rapidly, which enable the distribution of mutual funds personalized to individual investors via mobile Apps. As the important intermediation of financial products investment, these platforms distribute thousands of mutual funds obtaining impressions under guaranteed delivery (GD) strategy required by fund companies. Driven by the profit from fund purchases of users, the platform aims to maximize each transaction amount of customers by promoting mutual funds to these investors who will be interested in. Different from the conversions in traditional advertising or e-commerce recommendations, the investment amount in each purchase varies greatly even for the same financial product, which provides a significant challenge for the promotion recommendation of mutual funds. In addition to predicting the click-through rate (CTR) or the conversion rate (CVR) as in traditional recommendations, it is essential for FinTech platforms to estimate the customers' purchase amount for each delivered fund and achieve an effective allocation of impressions based on the predicted results to optimize the total expected transaction value (ETV). In this paper, we propose an ETV optimized customer allocation framework (EOCA) that aims to maximize the total ETV of recommended funds, under the constraints of GD dealt with fund companies. To the best of our knowledge, it's the first attempt to solve the GD problem for financial product promotions based on customer purchase amount prediction. We conduct extensive experiments on large scale real-world datasets and online tests based on LiCaiTong, Tencent wealth management platform, to demonstrate the effectiveness of our proposed EOCA framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "81049933",
                    "name": "Yunpeng Weng"
                },
                {
                    "authorId": "2109888596",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2261475293",
                    "name": "Liang Chen"
                },
                {
                    "authorId": "2257136810",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                }
            ]
        },
        {
            "paperId": "9ea30b735ce4b530e40c5dcff24cb1a0dcf4f76e",
            "title": "FedBAT: Communication-Efficient Federated Learning via Learnable Binarization",
            "abstract": "Federated learning is a promising distributed machine learning paradigm that can effectively exploit large-scale data without exposing users' privacy. However, it may incur significant communication overhead, thereby potentially impairing the training efficiency. To address this challenge, numerous studies suggest binarizing the model updates. Nonetheless, traditional methods usually binarize model updates in a post-training manner, resulting in significant approximation errors and consequent degradation in model accuracy. To this end, we propose Federated Binarization-Aware Training (FedBAT), a novel framework that directly learns binary model updates during the local training process, thus inherently reducing the approximation errors. FedBAT incorporates an innovative binarization operator, along with meticulously designed derivatives to facilitate efficient learning. In addition, we establish theoretical guarantees regarding the convergence of FedBAT. Extensive experiments are conducted on four popular datasets. The results show that FedBAT significantly accelerates the convergence and exceeds the accuracy of baselines by up to 9\\%, even surpassing that of FedAvg in some cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2195780326",
                    "name": "Shiwei Li"
                },
                {
                    "authorId": "2314844128",
                    "name": "Wenchao Xu"
                },
                {
                    "authorId": "51175126",
                    "name": "Haozhao Wang"
                },
                {
                    "authorId": "2315079186",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2278194140",
                    "name": "Yining Qi"
                },
                {
                    "authorId": "2315248559",
                    "name": "Shijie Xu"
                },
                {
                    "authorId": "2261426672",
                    "name": "Weihong Luo"
                },
                {
                    "authorId": "2315068141",
                    "name": "Yuhua Li"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2260298889",
                    "name": "Ruixuan Li"
                }
            ]
        },
        {
            "paperId": "a0b6640b294c23f59f9f175b95af6f135585c473",
            "title": "Rankability-enhanced Revenue Uplift Modeling Framework for Online Marketing",
            "abstract": "Uplift modeling has been widely employed in online marketing by predicting the response difference between the treatment and control groups, so as to identify the sensitive individuals toward interventions like coupons or discounts. Compared with traditional \\textit{conversion uplift modeling}, \\textit{revenue uplift modeling} exhibits higher potential due to its direct connection with the corporate income. However, previous works can hardly handle the continuous long-tail response distribution in revenue uplift modeling. Moreover, they have neglected to optimize the uplift ranking among different individuals, which is actually the core of uplift modeling. To address such issues, in this paper, we first utilize the zero-inflated lognormal (ZILN) loss to regress the responses and customize the corresponding modeling network, which can be adapted to different existing uplift models. Then, we study the ranking-related uplift modeling error from the theoretical perspective and propose two tighter error bounds as the additional loss terms to the conventional response regression loss. Finally, we directly model the uplift ranking error for the entire population with a listwise uplift ranking loss. The experiment results on offline public and industrial datasets validate the effectiveness of our method for revenue uplift modeling. Furthermore, we conduct large-scale experiments on a prominent online fintech marketing platform, Tencent FiT, which further demonstrates the superiority of our method in real-world applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256987771",
                    "name": "Bowei He"
                },
                {
                    "authorId": "81049933",
                    "name": "Yunpeng Weng"
                },
                {
                    "authorId": "2240611823",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2279336004",
                    "name": "Ziqiang Cui"
                },
                {
                    "authorId": "2257124500",
                    "name": "Zexu Sun"
                },
                {
                    "authorId": "2261475293",
                    "name": "Liang Chen"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2258189274",
                    "name": "Chen Ma"
                }
            ]
        },
        {
            "paperId": "bb0b69134e1bcddc9ffc243df852b98e994471a8",
            "title": "Treatment-Aware Hyperbolic Representation Learning for Causal Effect Estimation with Social Networks",
            "abstract": "Estimating the individual treatment effect (ITE) from observational data is a crucial research topic that holds significant value across multiple domains. How to identify hidden confounders poses a key challenge in ITE estimation. Recent studies have incorporated the structural information of social networks to tackle this challenge, achieving notable advancements. However, these methods utilize graph neural networks to learn the representation of hidden confounders in Euclidean space, disregarding two critical issues: (1) the social networks often exhibit a scalefree structure, while Euclidean embeddings suffer from high distortion when used to embed such graphs, and (2) each ego-centric network within a social network manifests a treatment-related characteristic, implying significant patterns of hidden confounders. To address these issues, we propose a novel method called Treatment-Aware Hyperbolic Representation Learning (TAHyper). Firstly, TAHyper employs the hyperbolic space to encode the social networks, thereby effectively reducing the distortion of confounder representation caused by Euclidean embeddings. Secondly, we design a treatment-aware relationship identification module that enhances the representation of hidden confounders by identifying whether an individual and her neighbors receive the same treatment. Extensive experiments on two benchmark datasets are conducted to demonstrate the superiority of our method.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2279336004",
                    "name": "Ziqiang Cui"
                },
                {
                    "authorId": "2109888596",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2204648054",
                    "name": "Yang Qiao"
                },
                {
                    "authorId": "2256987771",
                    "name": "Bowei He"
                },
                {
                    "authorId": "2261475293",
                    "name": "Liang Chen"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2261661544",
                    "name": "Chen Ma"
                }
            ]
        },
        {
            "paperId": "ca457e9b0ba0680659ed02c9d12a48c8f7d8cab9",
            "title": "Mixed-Precision Embeddings for Large-Scale Recommendation Models",
            "abstract": "Embedding techniques have become essential components of large databases in the deep learning era. By encoding discrete entities, such as words, items, or graph nodes, into continuous vector spaces, embeddings facilitate more efficient storage, retrieval, and processing in large databases. Especially in the domain of recommender systems, millions of categorical features are encoded as unique embedding vectors, which facilitates the modeling of similarities and interactions among features. However, numerous embedding vectors can result in significant storage overhead. In this paper, we aim to compress the embedding table through quantization techniques. Given that features vary in importance levels, we seek to identify an appropriate precision for each feature to balance model accuracy and memory usage. To this end, we propose a novel embedding compression method, termed Mixed-Precision Embeddings (MPE). Specifically, to reduce the size of the search space, we first group features by frequency and then search precision for each feature group. MPE further learns the probability distribution over precision levels for each feature group, which can be used to identify the most suitable precision with a specially designed sampling strategy. Extensive experiments on three public datasets demonstrate that MPE significantly outperforms existing embedding compression methods. Remarkably, MPE achieves about 200x compression on the Criteo dataset without comprising the prediction accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2195780326",
                    "name": "Shiwei Li"
                },
                {
                    "authorId": "2323521242",
                    "name": "Zhuoqi Hu"
                },
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2315079186",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2312867341",
                    "name": "Haozhao Wang"
                },
                {
                    "authorId": "2315248559",
                    "name": "Shijie Xu"
                },
                {
                    "authorId": "2261426672",
                    "name": "Weihong Luo"
                },
                {
                    "authorId": "2315068141",
                    "name": "Yuhua Li"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2261430143",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "2283487404",
                    "name": "Ruixuan Li"
                }
            ]
        }
    ]
}