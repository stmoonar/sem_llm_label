{
    "authorId": "2273771682",
    "papers": [
        {
            "paperId": "69ec9e81b1d4ced8ceb0214bdf33e38627aa5f5c",
            "title": "Enhancing Few-Shot Stock Trend Prediction with Large Language Models",
            "abstract": "The goal of stock trend prediction is to forecast future market movements for informed investment decisions. Existing methods mostly focus on predicting stock trends with supervised models trained on extensive annotated data. However, human annotation can be resource-intensive and the annotated data are not readily available. Inspired by the impressive few-shot capability of Large Language Models (LLMs), we propose using LLMs in a few-shot setting to overcome the scarcity of labeled data and make prediction more feasible to investors. Previous works typically merge multiple financial news for predicting stock trends, causing two significant problems when using LLMs: (1) Merged news contains noise, and (2) it may exceed LLMs' input limits, leading to performance degradation. To overcome these issues, we propose a two-step method 'denoising-then-voting'. Specifically, we introduce an `Irrelevant' category, and predict stock trends for individual news instead of merged news. Then we aggregate these predictions using majority voting. The proposed method offers two advantages: (1) Classifying noisy news as irrelevant removes its impact on the final prediction. (2) Predicting for individual news mitigates LLMs' input length limits. Our method achieves 66.59% accuracy in S&P 500, 62.17% in CSI-100, and 61.17% in HK stock prediction, outperforming the standard few-shot counterparts by around 7%, 4%, and 4%. Furthermore, our proposed method performs on par with state-of-the-art supervised methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266283700",
                    "name": "Yiqi Deng"
                },
                {
                    "authorId": "2273771682",
                    "name": "Xingwei He"
                },
                {
                    "authorId": "2311275129",
                    "name": "Jiahao Hu"
                },
                {
                    "authorId": "2268393548",
                    "name": "S.M. Yiu"
                }
            ]
        },
        {
            "paperId": "7673abf7150aeaf8db6b2e32f4f877a29c183d24",
            "title": "TUBench: Benchmarking Large Vision-Language Models on Trustworthiness with Unanswerable Questions",
            "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable progress on visual perception and linguistic interpretation. Despite their impressive capabilities across various tasks, LVLMs still suffer from the issue of hallucination, which involves generating content that is incorrect or unfaithful to the visual or textual inputs. Traditional benchmarks, such as MME and POPE, evaluate hallucination in LVLMs within the scope of Visual Question Answering (VQA) using answerable questions. However, some questions are unanswerable due to insufficient information in the images, and the performance of LVLMs on such unanswerable questions remains underexplored. To bridge this research gap, we propose TUBench, a benchmark specifically designed to evaluate the reliability of LVLMs using unanswerable questions. TUBench comprises an extensive collection of high-quality, unanswerable questions that are meticulously crafted using ten distinct strategies. To thoroughly evaluate LVLMs, the unanswerable questions in TUBench are based on images from four diverse domains as visual contexts: screenshots of code snippets, natural images, geometry diagrams, and screenshots of statistical tables. These unanswerable questions are tailored to test LVLMs' trustworthiness in code reasoning, commonsense reasoning, geometric reasoning, and mathematical reasoning related to tables, respectively. We conducted a comprehensive quantitative evaluation of 28 leading foundational models on TUBench, with Gemini-1.5-Pro, the top-performing model, achieving an average accuracy of 69.2%, and GPT-4o, the third-ranked model, reaching 66.7% average accuracy, in determining whether questions are answerable. TUBench is available at https://github.com/NLPCode/TUBench.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273771682",
                    "name": "Xingwei He"
                },
                {
                    "authorId": "1500649148",
                    "name": "Qianru Zhang"
                },
                {
                    "authorId": "15796861",
                    "name": "Alex Jin"
                },
                {
                    "authorId": null,
                    "name": "Yuan Yuan"
                },
                {
                    "authorId": "2184000509",
                    "name": "S. Yiu"
                }
            ]
        },
        {
            "paperId": "99b65263b82b3d9d532377706ceb5d6733e5f0a9",
            "title": "A Survey of Generative Techniques for Spatial-Temporal Data Mining",
            "abstract": "This paper focuses on the integration of generative techniques into spatial-temporal data mining, considering the significant growth and diverse nature of spatial-temporal data. With the advancements in RNNs, CNNs, and other non-generative techniques, researchers have explored their application in capturing temporal and spatial dependencies within spatial-temporal data. However, the emergence of generative techniques such as LLMs, SSL, Seq2Seq and diffusion models has opened up new possibilities for enhancing spatial-temporal data mining further. The paper provides a comprehensive analysis of generative technique-based spatial-temporal methods and introduces a standardized framework specifically designed for the spatial-temporal data mining pipeline. By offering a detailed review and a novel taxonomy of spatial-temporal methodology utilizing generative techniques, the paper enables a deeper understanding of the various techniques employed in this field. Furthermore, the paper highlights promising future research directions, urging researchers to delve deeper into spatial-temporal data mining. It emphasizes the need to explore untapped opportunities and push the boundaries of knowledge to unlock new insights and improve the effectiveness and efficiency of spatial-temporal data mining. By integrating generative techniques and providing a standardized framework, the paper contributes to advancing the field and encourages researchers to explore the vast potential of generative techniques in spatial-temporal data mining.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1500649148",
                    "name": "Qianru Zhang"
                },
                {
                    "authorId": "2279762001",
                    "name": "Haixin Wang"
                },
                {
                    "authorId": "2301457384",
                    "name": "Cheng Long"
                },
                {
                    "authorId": "2302286242",
                    "name": "Liangcai Su"
                },
                {
                    "authorId": "2273771682",
                    "name": "Xingwei He"
                },
                {
                    "authorId": "2294434616",
                    "name": "Jianlong Chang"
                },
                {
                    "authorId": "2279761135",
                    "name": "Tailin Wu"
                },
                {
                    "authorId": "2302520304",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2184000509",
                    "name": "S. Yiu"
                },
                {
                    "authorId": "2301457785",
                    "name": "Qi Tian"
                },
                {
                    "authorId": "2293317939",
                    "name": "Christian S. Jensen"
                }
            ]
        },
        {
            "paperId": "e955fc889f86f82864d0aad6b8429ff79136d1f3",
            "title": "A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security",
            "abstract": "The widespread adoption of smartphones and Location-Based Social Networks has led to a massive influx of spatio-temporal data, creating unparalleled opportunities for enhancing Point-of-Interest (POI) recommendation systems. These advanced POI systems are crucial for enriching user experiences, enabling personalized interactions, and optimizing decision-making processes in the digital landscape. However, existing surveys tend to focus on traditional approaches and few of them delve into cutting-edge developments, emerging architectures, as well as security considerations in POI recommendations. To address this gap, our survey stands out by offering a comprehensive, up-to-date review of POI recommendation systems, covering advancements in models, architectures, and security aspects. We systematically examine the transition from traditional models to advanced techniques such as large language models. Additionally, we explore the architectural evolution from centralized to decentralized and federated learning systems, highlighting the improvements in scalability and privacy. Furthermore, we address the increasing importance of security, examining potential vulnerabilities and privacy-preserving approaches. Our taxonomy provides a structured overview of the current state of POI recommendation, while we also identify promising directions for future research in this rapidly advancing field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1500649148",
                    "name": "Qianru Zhang"
                },
                {
                    "authorId": "2324725719",
                    "name": "Peng Yang"
                },
                {
                    "authorId": "28584977",
                    "name": "Junliang Yu"
                },
                {
                    "authorId": "2279762001",
                    "name": "Haixin Wang"
                },
                {
                    "authorId": "2273771682",
                    "name": "Xingwei He"
                },
                {
                    "authorId": "2184000509",
                    "name": "S. Yiu"
                },
                {
                    "authorId": null,
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "55ad0427954c97d9f9a44469d3431d3803e58de2",
            "title": "PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273771682",
                    "name": "Xingwei He"
                },
                {
                    "authorId": "15796861",
                    "name": "Alex Jin"
                },
                {
                    "authorId": "2273909915",
                    "name": "Jun Ma"
                },
                {
                    "authorId": "2273924496",
                    "name": "Yuan Yuan"
                },
                {
                    "authorId": "145964453",
                    "name": "S. Yiu"
                }
            ]
        },
        {
            "paperId": "9fef56e98cce62dee65ef623d43ece7cb54f01ba",
            "title": "Improving Factual Error Correction by Learning to Inject Factual Errors",
            "abstract": "Factual error correction (FEC) aims to revise factual errors in false claims with minimal editing, making them faithful to the provided evidence. This task is crucial for alleviating the hallucination problem encountered by large language models. Given the lack of paired data (i.e., false claims and their corresponding correct claims), existing methods typically adopt the \u2018mask-then-correct\u2019 paradigm. This paradigm relies solely on unpaired false claims and correct claims, thus being referred to as distantly supervised methods. These methods require a masker to explicitly identify factual errors within false claims before revising with a corrector. However, the absence of paired data to train the masker makes accurately pinpointing factual errors within claims challenging. To mitigate this, we propose to improve FEC by Learning to Inject Factual Errors (LIFE), a three-step distantly supervised method: \u2018mask-corrupt-correct\u2019. Specifically, we first train a corruptor using the \u2018mask-then-corrupt\u2019 procedure, allowing it to deliberately introduce factual errors into correct text. The corruptor is then applied to correct claims, generating a substantial amount of paired data. After that, we filter out low-quality data, and use the remaining data to train a corrector. Notably, our corrector does not require a masker, thus circumventing the bottleneck associated with explicit factual error identification. Our experiments on a public dataset verify the effectiveness of LIFE in two key aspects: Firstly, it outperforms the previous best-performing distantly supervised method by a notable margin of 10.59 points in SARI Final (19.3% improvement). Secondly, even compared to ChatGPT prompted with in-context examples, LIFE achieves a superiority of 7.16 points in SARI Final.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273771682",
                    "name": "Xingwei He"
                },
                {
                    "authorId": "1500649148",
                    "name": "Qianru Zhang"
                },
                {
                    "authorId": "15796861",
                    "name": "Alex Jin"
                },
                {
                    "authorId": "2273909915",
                    "name": "Jun Ma"
                },
                {
                    "authorId": "2273924496",
                    "name": "Yuan Yuan"
                },
                {
                    "authorId": "145964453",
                    "name": "S. Yiu"
                }
            ]
        }
    ]
}