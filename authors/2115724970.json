{
    "authorId": "2115724970",
    "papers": [
        {
            "paperId": "b65b6d5569bda25d5cbd398a2520265b1378a638",
            "title": "Projective Holder-Minkowski Colors: A Generalized Set of Commutative & Associative Operations with Inverse Elements for Representing and Manipulating Colors",
            "abstract": "One of the key problems in dealing with color in rendering, shading, compositing, or image manipulation is that we do not have algebraic structures that support operations over colors. In this paper, we present an all-encompassing framework that can support a set of algebraic structures with associativity, commutativity, and inverse properties. To provide these three properties, we build our algebraic structures on an extension of projective space by allowing for negative and complex numbers. These properties are important for (1) manipulating colors as periodic functions, (2) solving inverse problems dealing with colors, and (3) being consistent with the wave representation of the color. Allowance of negative and complex numbers is not a problem for practical applications, since we can always convert the results into desired range for display purposes as we do in High Dynamic Range imaging. This set of algebraic structures can be considered as a generalization of the Minkowski norm Lp in projective space. These structures also provide a new version of the generalized Holder average with associativity property. Our structures provide inverses of any operation by allowing for negative and complex numbers. These structures provide all properties of the generalized Holder average by providing a continuous bridge between the classical weighted average, harmonic mean, maximum, and minimum operations using a single parameter p.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                },
                {
                    "authorId": "2284730858",
                    "name": "Somyung Oh"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "2023711444",
                    "name": "B. T. Akg\u00fcn"
                },
                {
                    "authorId": "2246851517",
                    "name": "Jianer Chen"
                }
            ]
        },
        {
            "paperId": "e56885b2cf5bd9705ae472f7e2c4ae390a9dc0e3",
            "title": "Compositing with 2D Vector Fields by using Shape Maps that can represent Inconsistent, Impossible, and Incoherent Shapes",
            "abstract": "In this paper, we present a new compositing approach to obtain stylized reflections and refractions with a simple control. Our approach does not require any mask or separate 3D rendering. Moreover, only one additional image is sufficient to obtain a composited image with convincing qualitative reflection and refraction effects. We have also developed linearized methods that are easy to compute. Although these methods do not directly correspond to the underlying physical phenomena of reflection and refraction, they can provide results that are visually similar to realistic 3D rendering. The main advantage of this approach is the ability to treat images as ``mock-3D'' shapes that can be inserted into any digital paint system without any significant structural change. The core of our approach is the shape map, which encodes 2D shape and thickness information for all visible points of an image of a shape. This information does not have to be complete or consistent to obtain interesting composites. In particular, the shape maps allow us to represent impossible and incoherent shapes with 2D non-conservative vector fields.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "40191271",
                    "name": "Ozgur Gonen"
                }
            ]
        },
        {
            "paperId": "18e55a06ee4c6c74837fa9ffbec5ab85d3e24079",
            "title": "Representing and Modeling Inconsistent, Impossible, and Incoherent Shapes and Scenes with 2D Non-Conservative Vector Fields mapped on 2-Complexes",
            "abstract": "In this paper, we present a framework to represent mock 3D objects and scenes, which are not 3D but appear 3D. In our framework, each mock-3D object is represented using 2D non-conservative vector fields and thickness information that are mapped on 2-complexes. Mock-3D scenes are simply scenes consisting of more than one mock-3D object. We demonstrated that using this representation, we can dynamically compute a 3D shape using rays emanating from any given point in 3D. These mock-3D objects are view-dependent since their computed shapes depend on the positions of ray centers. Using these dynamically computed shapes, we can compute shadows, reflections, and refractions in real time. This representation is mainly useful for 2D artistic applications to model incoherent, inconsistent, and impossible objects. Using this representation, it is possible to obtain expressive depictions with shadows and global illumination effects. The representation can also be used to convert existing 2D artworks into a Mock-3D form that can be interactively re-rendered.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "40191271",
                    "name": "Ozgur Gonen"
                }
            ]
        },
        {
            "paperId": "7235e23b7a12a85c276d057d3796e4e646d9dfba",
            "title": "Web-Based Dynamic Paintings: Real-Time Interactive Artworks in Web Using a 2.5D Pipeline",
            "abstract": "In this work, we present a 2.5D pipeline approach to creating dynamic paintings that can be re-rendered interactively in real-time on the Web. Using this 2.5D approach, any existing simple painting such as portraits can be turned into an interactive dynamic web-based artwork. Our interactive system provides most global illumination effects such as reflection, refraction, shadow, and subsurface scattering by processing images. In our system, the scene is defined only by a set of images. These include (1) a shape image, (2) two diffuse images, (3) a background image, (4) one foreground image, and (5) one transparency image. A shape image is either a normal map or a height. Two diffuse images are usually hand-painted. They are interpolated using illumination information. The transparency image is used to define the transparent and reflective regions that can reflect the foreground image and refract the background image, both of which are also hand-drawn. This framework, which mainly uses hand-drawn images, provides qualitatively convincing painterly global illumination effects such as reflection and refraction. We also include parameters to provide additional artistic controls. For instance, using our piecewise linear Fresnel function, it is possible to control the ratio of reflection and refraction. This system is the result of a long line of research contributions. On the other hand, the art-directed Fresnel function that provides physically plausible compositing of reflection and refraction with artistic control is completely new. Art-directed warping equations that provide qualitatively convincing refraction and reflection effects with linearized artistic control are also new. You can try our web-based system for interactive dynamic real-time paintings at http://mock3d.tamu.edu/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "2268428221",
                    "name": "Yinan Xiong"
                },
                {
                    "authorId": "2268405835",
                    "name": "Anusha Shanker"
                },
                {
                    "authorId": "22715821",
                    "name": "Fermi Perumal"
                },
                {
                    "authorId": "40191271",
                    "name": "Ozgur Gonen"
                },
                {
                    "authorId": "2268406036",
                    "name": "Motahareh Fard"
                }
            ]
        },
        {
            "paperId": "b244b08644f082a600edf337b73290928ecc5c2c",
            "title": "Identification of Communities With Multi-Semantics via Bayesian Generative Model",
            "abstract": "Discovering communities is an essential step in the analysis of complex systems, and it has two purposes: to identify functional modules and to interpret semantics. However, most of the existing community detection methods only focused on identify communities, while learning the semantics interpretation of communities has not been fully studied. In this paper, we focused on the problem of identifying communities and learning the semantics interpretation of modules jointly in an end-to-end model. We designed a novel generative model which combines two closely related parts, one for community discovery and the other for content clustering and semantics interpretation. By extracting the potential correlation between these two parts, our new method is not only robust to discovering communities, but also able to provide a community with more than one semantic topic. As for model inference, we developed a variational algorithm from a Bayesian point of view. Experimental results on the artificial benchmark and real networks showed the superior performance of the proposed approach over existing methods in terms of effectiveness and efficiency. We also analyzed semantic interpretability of community detection results through a case study over a large-scale music platform dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2134116910",
                    "name": "Yanli Wu"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "12073135",
                    "name": "Zhizhi Yu"
                },
                {
                    "authorId": "2152084654",
                    "name": "Zhiyong Feng"
                },
                {
                    "authorId": "2108114840",
                    "name": "Xiaobao Wang"
                },
                {
                    "authorId": "2108728683",
                    "name": "Yuxiao Huang"
                }
            ]
        },
        {
            "paperId": "18f1833d7910c8b70af511003c9615a34d7ea6d3",
            "title": "Steadiface: Real-Time Face-Centric Stabilization On Mobile Phones",
            "abstract": "We present Steadiface, a new real-time face-centric video stabilization method that simultaneously removes hand shake and keeps subject\u2019s head stable. We use a CNN to estimate the face landmarks and use them to optimize a stabilized head center. We then formulate an optimization problem to find a virtual camera pose that locates the face to the stabilized head center while retains smooth rotation and translation transitions across frames. We test the proposed method on fieldtest videos and show it stabilizes both the head motion and background. It is robust to large head pose, occlusion, facial appearance variations, and different kinds of camera motions. We show our method advances the state of art in selfie video stabilization by comparing against alternative methods. The whole process runs very efficiently on a modern mobile phone (8.1 ms/frame).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36706427",
                    "name": "Fuhao Shi"
                },
                {
                    "authorId": "2072526731",
                    "name": "Sung-Fang Tsai"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "47546212",
                    "name": "Chia-Kai Liang"
                }
            ]
        },
        {
            "paperId": "2a84d98e1cc2d95a814dbaddfa2a97056b1ffc6b",
            "title": "Cos \u0398 shadows: an integrated model for direct illumination, subsurface scattering and shadow computation",
            "abstract": "In this work, we present an integrated model that can provide direct illumination, subsurface scattering and soft shadow effects in a single equation. We have implemented our model to render bas-reliefs, which are the shapes that are defined as height fields. Using our model it is possible to interactively obtain all three effects in a qualitatively consistent way. One of the most important properties of our model is that it provides cos \u03b8 for planar surfaces. Moreover, our formula is qualitatively related to exponential attenuation due to scattering and provides soft shadows. Therefore, this model provides qualitatively consistent shading for direct illuminated subsurface scattering and shadow regions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                },
                {
                    "authorId": "22715821",
                    "name": "Fermi Perumal"
                },
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                }
            ]
        },
        {
            "paperId": "d989cc9d14eb5ed298ac9c1b1f98918f03ffa376",
            "title": "Global illumination for 2D artworks with vector field rendering",
            "abstract": "classroom use is granted without fee provided that copies are not made or distributed for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the Owner/Author. SIGGRAPH 2014, August 10 \u2013 14, 2014, Vancouver, British Columbia, Canada. 2014 Copyright held by the Owner/Author. ACM 978-1-4503-2958-3/14/08 Global Illumination for 2D Artworks with Vector Field Rendering",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "40191271",
                    "name": "Ozgur Gonen"
                },
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                }
            ]
        },
        {
            "paperId": "652cd880e14ee25e31a4f4cca723cff4fdc8391e",
            "title": "Turning photographs into abstract expressionist paintings",
            "abstract": "During the recent history of painting there has been several movements who tried to obtain an illusion of flattened 3D space. Cubists employed multi-perspective views to flatten the 3D space [Meadows and Akleman 2000]. Impressionists and abstract expressionists, on the other hand, flattened 3D space with layers of paints to make objects fuzzy. A particular paint layering technique is impasto, which is introduced by impressionist artists such as Claude Monet or Vincent VanGogh [Schaefer et al. 2008]. Another paint layering technique is drip painting, which is introduced by abstract expressionist Jackson Pollock [Taylor 1999]. Abstract expressionism became popularized throughout the 20th century with artists such as Robert Jay Wolff, Franz Kline, Willem de Kooning, Larry Rivers, and Robert Motherwell [Ross 1990]. Unlike Pollock, most abstract expressionist painters uses impasto to obtain flatten effect and further transform images from flattened 3D representational form to abstract. Many of the abstract expressionists painted layers upon layers of paint until they were satisfied with a result. For instance, in Woman by Willem de Kooning, we may make sense of a set of eyes and a mouth, but it is really through the name of the painting that we associate a human form with the image. This abstraction is obtained by applying paint in consistent impastos which thin out to the canvas in a few places while rising elsewhere to heavy ridges.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                }
            ]
        },
        {
            "paperId": "91e53a5538c0a6db480c8ff483a672a53287d367",
            "title": "Calligraphic cutting: extreme image resizing with cuts in continuous domain",
            "abstract": "Seam carving [Avidan and Shamir 2007; Rubinstein et al. 2009] revolutionized the way we think about image resizing by demonstrating that it is possible to obtain significant changes in image sizes with changes in proximity relationships, which we call topological properties of an image. Seam carving can change the size of an image by progressively carving out (or carving in) seams, which are monotonically connected paths of low-energy pixels crossing an image from top to bottom, or from left to right. Unfortunately, it quickly became obvious that seam carving creates geometric discontinuities once low-energy regions start to diminish. As a result, improvements and alternative approaches have been suggested to minimize discontinuities.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2115724970",
                    "name": "Youyou Wang"
                },
                {
                    "authorId": "1739799",
                    "name": "E. Akleman"
                }
            ]
        }
    ]
}