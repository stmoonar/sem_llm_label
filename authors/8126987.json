{
    "authorId": "8126987",
    "papers": [
        {
            "paperId": "01aa52765031081f06365316d9569aefd03802a5",
            "title": "Deep Reinforcement Learning-Based Task Offloading for Vehicular Edge Computing With Flexible RSU-RSU Cooperation",
            "abstract": "Vehicle edge computing (VEC) acts as an enhancement to provide low latency and low energy consumption for internet of vehicles (IoV) applications. Mobility of vehicles and load difference of roadside units (RSUs) are two important issues in VEC. The former results in task result reception failures owing to vehicles moving out of the coverage of their current RSUs; the latter leads to system performance degradation owing to load imbalance among the RSUs. They can be well solved by exploiting flexible RSU-RSU cooperation, which has not been fully studied by existing works. In this paper, we propose a novel resource management scheme for joint task offloading, computing resource allocation for vehicles and RSUs, vehicle-to-RSU transmit power allocation, and RSU-to-RSU transmission rate allocation. In our scheme, a task result can be transferred to the RSU where the vehicle is currently located, and a task can be further offloaded from a high-load RSU to a low-load RSU. To minimize the total task processing delay and energy consumption of all the vehicles, we design a twin delayed deep deterministic policy gradient (TD3)-based deep reinforcement learning (DRL) algorithm, where we embed an optimization subroutine to solve 2 sub-problems via numerical methods, thus reducing the training complexity of the algorithm. Extensive simulations are conducted in 6 different scenarios. Compared with 4 reference schemes, our scheme can reduce the total task processing cost by 17.3%-28.4%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2200089182",
                    "name": "Yaoyin Zhang"
                },
                {
                    "authorId": "2279827092",
                    "name": "Guangtao Zhou"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "1dfb55c6fb7ff93abff6c8786732c413d7ab6cad",
            "title": "Time-Slotted Task Offloading and Resource Allocation for Cloud-Edge-End Cooperative Computing Networks",
            "abstract": "In time-slotted edge computing systems, task scheduling is conducted at the end of each time slot to make task offloading decisions and resource allocation for all the tasks pending for scheduling during the time slot. However, the existing works omitted the task scheduling delay, which is a period that a task has to wait from the task generation time point to the end of the current time slot. Such simplification is impractical in real scenarios because the task scheduling delay is a non-negligible part of the task processing delay, which was understood by existing works as the sum of only the task transmission and computing delays. In this paper, a novel time-slotted task offloading and resource allocation scheme for cloud-edge-end cooperative computing networks is proposed to realize the total task processing delay minimization for all the devices under the energy consumption constraint of each device. Our scheme makes task-offloading decision for each device from local processing, offloading to its affiliated base station (BS), to another BS, and to the cloud server. Besides, transmit power allocation, transmission rate allocation, and computing resource allocation are also jointly optimized in our optimization problem. We consider the impact of the task scheduling delay and design a two-stage distributed algorithm to decrease the negative impact by dividing the algorithm into a device-side part and a network-side part. The advantages of our scheme are validated by extensive simulations, where 4 reference schemes are compared in 8 different scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2186397028",
                    "name": "Xun Liu"
                },
                {
                    "authorId": "2278422586",
                    "name": "Hao Yuan"
                },
                {
                    "authorId": "2269750351",
                    "name": "Nan Li"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "253cd777340e09c9bb6390b0b1e4d4b635d352ec",
            "title": "MEC Network Slicing: Stackelberg-Game-Based Slice Pricing and Resource Allocation With QoS Guarantee",
            "abstract": "In multi-access edge computing (MEC) networks, network slicing enables the MEC network service provider (MEC-NSP) to provide customizable MEC services for user devices (UDs) with diverse QoS (Quality of Service) demands. In MEC network slicing, slice pricing and network resource allocation for slices are two core problems, which have not been jointly considered by existing works. To this end, we propose a two-stage slice pricing scheme to achieve balanced slice pricing and optimal network resource allocation. The goal of our scheme is to reduce the resource costs of the MEC-NSP and ensure its profit while meeting different user QoS requirements. At the first stage, we jointly optimize the computing, cache and communication resource allocation for all the slices by using problem decomposition. Then, we formulate a slice pricing problem based the Stackelberg game, prove the Nash equilibrium existence of the problem, and design an iterative algorithm based on the optimal response function. Extensive simulations are conducted in 4 scenarios, where our scheme is compared with 4 reference schemes. The simulation results demonstrate the superiority of our scheme in all the scenarios. The profit of the MEC-NSP optimized by our scheme is 17.64%-24.39% higher than those by the comparative works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2307485286",
                    "name": "Xuewei Li"
                },
                {
                    "authorId": "2274342023",
                    "name": "Bihua Tang"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "337546b96b1f9f259c4104d83b793374823e03d5",
            "title": "Collaborative Service Placement, Task Scheduling, and Resource Allocation for Task Offloading With Edge-Cloud Cooperation",
            "abstract": "In an edge-cloud cooperative computing network, the task offloading performance can be further improved by the edge-cloud and edge-edge cooperation, in which the tasks can be offloaded from an edge server to the cloud server or another edge server. Such edge-cloud cooperative task offloading can jointly utilize the resources of all the edge servers and the cloud server. This paper proposes a collaborative service placement, task scheduling, computing resource allocation, and transmission rate allocation scheme for a multi-task and multi-service scenario with edge-cloud cooperation. The objective of our optimization problem is to minimize the total task processing delay while guaranteeing long-term task queuing stability. Considering the high complexity of the original optimization problem, we transform the problem into a deterministic problem for each time slot based on the Lyapunov optimization. Then, we design an iterative algorithm to obtain the whole solution to the problem efficiently based on a hybrid method using multiple numerical techniques. Further, considering the inherent difference in the optimization periods of the service placement, resource allocation, and task scheduling sub-problems, we design a multi-timescale algorithm to solve the sub-problems with different optimization periods. The complexity of the proposed algorithms is analyzed, and extensive simulations are conducted by varying multiple crucial parameters. The superiority of our scheme is demonstrated in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2186397028",
                    "name": "Xun Liu"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "103483738",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "583e388d7d9fa038579f0cf9491db608c5b05f51",
            "title": "Resource Matching for Blockchain-Assisted Edge Computing Networks",
            "abstract": "The combination of edge computing (EC) and blockchain can enhance task processing while ensuring security and credibility. To maximize system performance and avoid resource waste in task offloading, it is essential to match the resource allocation of the task computing and the blockchain consensus process. However, the existing works treated the above two processes as two independent processes and optimized them separately and ignored the above matching problem. In this article, we propose a resource management scheme for blockchain-assisted EC networks consisting of multiple devices, multiple base stations equipped with edge servers, a cloud server, and a network controller deployed on the edge layer. To minimize the total task processing delay and energy consumption of the devices, we formulate a joint task processing problem incorporating task scheduling, transmit power control, and computing resource allocation. To match the computing delay and consensus delay of each task, we balance the computing resources allocated for the two processes. We design a deep reinforcement learning (DRL) algorithm that utilizes the twin-delayed deep deterministic policy gradient (TD3) technology embedded with a fast numerical method, which effectively reduces the training complexity of the DRL model. Extensive experiments are conducted by varying four crucial parameters. The superiority of our scheme is demonstrated in comparison with three other reference schemes. The performance of our scheme is about 18.3%\u201324.1% higher than that of other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2178604984",
                    "name": "Zhibo Hao"
                },
                {
                    "authorId": "2274342023",
                    "name": "Bihua Tang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "ce2eb449fa593d0f26f3dc578408bf838deb7422",
            "title": "Blockchain-Secured Task Offloading and Resource Allocation for Cloud-Edge-End Cooperative Networks",
            "abstract": "Enhanced by blockchain and cloud-edge-end cooperation, an edge computing network is capable to provide IoT (Internet of Things) devices higher task processing performance and better security and privacy guarantee. However, the joint resource management for both the task offloading and the blockchain services was less fully studied by existing works. To this end, in this paper, we focus on the task processing delay and energy consumption optimization problem in a multi-device and multi-base-station cloud-edge-end cooperative network. The task offloading, transmit power allocation, transmission rate allocation, and computing resource allocation are jointly optimized to minimize the long-term average total task processing delay of the tasks of all the devices while keeping the stability of the energy consumption of the devices and guaranteeing that the block mining speed matches the task offloading processes. We transform the optimization problem based on the Lyapunov optimization theory, and then design a hybrid deep reinforcement learning (DRL)-based algorithm. We decompose the problem into multiple sub-problems, and then embed multiple fast numerical methods into the twin delayed deep deterministic policy gradient (TD3) architecture as optimization subroutines to improve the learning performance of the DRL model. We also design a distributed deployment scheme for the algorithm and analyze the algorithm complexity. We demonstrate the superior performance of our algorithm in comparison with 5 reference schemes via extensive experiments in 7 scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                }
            ]
        },
        {
            "paperId": "f0e08ebb7b694223f7a489b5e714620265f05f9e",
            "title": "Design and Performance of Passive Virtual MIMO in Ambient Backscatter Communication",
            "abstract": "Ambient backscatter communication (AmBC) is regarded as a cutting-edge technology for the Internet of Things (IoT). In this letter, we explore a low-complexity virtual multiple-input multiple-output (MIMO) architecture for AmBC, which groups a cluster of low-cost single-antenna backscatter devices (BDs) to achieve MIMO transmission rather than using multiple antenna BDs. To overcome difficulties in virtual antenna array (VAA) configuration, a three-step strategy is introduced. After that, a semi-blind channel estimation is combined with a maximum likelihood detector (MLD) for signal detection in the MIMO channel. Numerical simulations show that our proposed strategy is effective and the proposed architectureoutperforms single-antenna AmBC systems under the same signal-to-noise ratio (SNR), which provides better performance to tolerant direct-link interference (DLI).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2271652836",
                    "name": "Diancheng Cheng"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "1744918",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "02e8d415d73b2de34f9ab8d6768837c194e3e44e",
            "title": "Joint Task Offloading and Resource Allocation for Vehicular Edge Computing Based on V2I and V2V Modes",
            "abstract": "In an internet of vehicle (IoV) scenario, vehicular edge computing (VEC) exploits the computing capabilities of the vehicles and roadside unit (RSU) to enhance the task processing capabilities of the vehicles. Resource management is essential to the performance improvement of the VEC system. In this paper, we propose a joint task offloading and resource allocation scheme to minimize the total task processing delay of all the vehicles through task scheduling, channel allocation, and computing resource allocation for the vehicles and RSU. Different from the existing works, our scheme: 1) considers task diversity by profiling the tasks of the vehicles by multiple attributes including data size, computation amount, delay tolerance, and task type; 2) considers vehicle classification by dividing the vehicles into 4 sets according to whether they have task offloading requirements or provide task processing services; 3) considers task processing flexibility by deciding for each vehicle to process its tasks locally, to offload the tasks to the RSU via V2I (Vehicle to Infrastructure) connections, or to the other vehicles via V2V (Vehicle to Vehicle) connections. An algorithm based on the Generalized Benders Decomposition (GBD) and Reformulation Linearization (RL) methods is designed to optimally solve the optimization problem. A heuristic algorithm is also designed to provide the sub-optimal solution with low computational complexity. We analyze the convergence and complexity of the proposed algorithms and conduct extensive simulations in 6 scenarios. The simulation results demonstrate the superiority of our scheme in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2146651089",
                    "name": "Jie Liu"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "40646266",
                    "name": "Wei Huang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "0531ee80c08916b3fbd63513744bcdaef6dd2fe9",
            "title": "Joint DNN Partition and Resource Allocation Optimization for Energy-Constrained Hierarchical Edge-Cloud Systems",
            "abstract": "Hierarchical edge-cloud systems collaboratively utilize the resources of both the edge server and central cloud, enabling deep neural network (DNN) partition between the edge and cloud to accelerate the inference. However, the limited energy budgets of both the edge server and central cloud restrict them from providing optimal DNN inference services. Moreover, considering the high dynamics in stochastic environments, the long-term system performance should be optimized under long-term energy constraints. How to improve the long-term DNN inference performance in such energy-constrained hierarchical edge-cloud systems is less studied by existing related works. In this paper, we aim to jointly optimize DNN partition and computing resource allocation to minimize the long-term average end-to-end delay of multiple types of deep learning (DL) tasks while guaranteeing the energy consumption of the edge server and central cloud within their energy budgets. Based on the Lyapunov optimization technique and reinforcement learning, we design a novel deep deterministic policy gradient based DNN partition and resource allocation (DDPRA) algorithm to train policy to decide DNN partition dynamically by observing the environment. Moreover, the DDPRA algorithm is embedded with a heuristic computing resource allocation (HCRA) algorithm, which effectively reduces the complexity of policy training by decoupling and optimizing the computing resource allocation separately. We analyze the complexity of our algorithms and conduct extensive simulations. The numerical results demonstrate the superiority of our algorithm in comparison with 5 other schemes in multiple scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "13383067",
                    "name": "Li Gao"
                },
                {
                    "authorId": "2065508415",
                    "name": "Lei Qiao"
                },
                {
                    "authorId": "103483738",
                    "name": "Yuan\u2019an Liu"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                }
            ]
        },
        {
            "paperId": "1aa98fa3837a8a4c498594f59b0be16c014070ce",
            "title": "Game-Based Task Offloading and Resource Allocation for Vehicular Edge Computing With Edge-Edge Cooperation",
            "abstract": "Vehicular Edge Computing (VEC) enables task offloading from vehicles to the edge servers deployed on Road Side Units (RSUs), thus enhancing the task processing performance of the vehicles. However, in a multi-RSU VEC scenario, the uneven geographical distribution of the vehicles naturally causes the load imbalance among the edge servers and leads to the overload and performance degradation problems of the edge servers in hot areas. To this end, in this paper, we propose a joint task offloading and resource allocation for VEC with edge-edge cooperation, in which the tasks offloaded to a high-load edge server can be further offloaded to the other low-load edge servers. Our objective is to minimize the total task processing delay of all the vehicles while guaranteeing the task processing delay tolerance and the holding time of each vehicle. An M/M/1 queue is used to model the task queuing and task computing processes on each RSU. An exact potential game is adopted to model the competition process for the task offloading among the RSUs. A two-stage iterative algorithm is designed to decompose the optimization problem into two stages and solve them iteratively. We analyze the computational complexity of the algorithm and conduct extensive simulations by varying different crucial parameters. The superiority of our scheme is demonstrated in comparison with 3 other reference schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2153995001",
                    "name": "Mingyu Hua"
                },
                {
                    "authorId": "2200089182",
                    "name": "Yaoyin Zhang"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2307485286",
                    "name": "Xuewei Li"
                },
                {
                    "authorId": "33949252",
                    "name": "B. Tang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        }
    ]
}