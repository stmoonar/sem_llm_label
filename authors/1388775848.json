{
    "authorId": "1388775848",
    "papers": [
        {
            "paperId": "ca63e2dbfef969a7ee147045d6df9351b04ea517",
            "title": "The Case Against Explainability",
            "abstract": "As artificial intelligence (AI) becomes more prevalent there is a growing demand from regulators to accompany decisions made by such systems with explanations. However, a persistent gap exists between the need to execute a meaningful right to explanation vs. the ability of Machine Learning systems to deliver on such a legal requirement. The regulatory appeal towards\"a right to explanation\"of AI systems can be attributed to the significant role of explanations, part of the notion called reason-giving, in law. Therefore, in this work we examine reason-giving's purposes in law to analyze whether reasons provided by end-user Explainability can adequately fulfill them. We find that reason-giving's legal purposes include: (a) making a better and more just decision, (b) facilitating due-process, (c) authenticating human agency, and (d) enhancing the decision makers' authority. Using this methodology, we demonstrate end-user Explainabilty's inadequacy to fulfil reason-giving's role in law, given reason-giving's functions rely on its impact over a human decision maker. Thus, end-user Explainability fails, or is unsuitable, to fulfil the first, second and third legal function. In contrast we find that end-user Explainability excels in the fourth function, a quality which raises serious risks considering recent end-user Explainability research trends, Large Language Models' capabilities, and the ability to manipulate end-users by both humans and machines. Hence, we suggest that in some cases the right to explanation of AI systems could bring more harm than good to end users. Accordingly, this study carries some important policy ramifications, as it calls upon regulators and Machine Learning practitioners to reconsider the widespread pursuit of end-user Explainability and a right to explanation of AI systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218042234",
                    "name": "Hofit Wasserman Rozen"
                },
                {
                    "authorId": "1414087091",
                    "name": "N. Elkin-Koren"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "30f41b10ccb0ae04f358910dc880e050a4e04ca6",
            "title": "Inherent Inconsistencies of Feature Importance",
            "abstract": "The black-box nature of modern machine learning techniques invokes a practical and ethical need for explainability. Feature importance aims to meet this need by assigning scores to features, so humans can understand their in\ufb02uence on predictions. Feature importance can be used to explain predictions under different settings: of the entire sample space or a speci\ufb01c instance; of model behavior, or the dependencies in the data themselves. However, in most cases thus far, each of these settings was studied in isolation. We attempt to develop a sound feature importance score framework by de\ufb01ning a small set of desired properties. Surprisingly, we prove an inconsistency theorem, showing that the expected properties cannot hold simultaneously. To overcome this dif\ufb01culty, we propose the novel notion of re-partitioning the feature space into separable sets. Such sets are constructed to contain features that exhibit inter-set independence with respect to the target variable. We show that there exists a unique maximal partitioning into separable sets. Moreover, assigning scores to separable sets, instead of single features, uni\ufb01es the results of commonly used feature importance scores and annihilates the inconsistencies we demonstrated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2170538926",
                    "name": "Nimrod Harel"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                },
                {
                    "authorId": "2305755029",
                    "name": "Uri Obolski"
                }
            ]
        },
        {
            "paperId": "86b145c95a28a6ef2afa722ba4a15a3b34a41c56",
            "title": "Graph Trees with Attention",
            "abstract": "When dealing with tabular data, models based on regression and decision trees are a popular choice due to the high accuracy they provide on such tasks and their ease of application as compared to other model classes. Yet, when it comes to graph-structure data, current tree learning algorithms do not provide tools to manage the structure of the data other than relying on feature engineering. In this work we address the above gap, and introduce Graph Trees with Attention (GTA), a new family of tree-based learning algorithms that are designed to operate on graphs. GTA leverages both the graph structure and the features at the vertices and employs an attention mechanism that allows decisions to concentrate on sub-structures of the graph. We analyze GTA models and show that they are strictly more expressive than plain decision trees. We also demonstrate the bene\ufb01ts of GTA empirically on multiple graph and node prediction benchmarks. In these experiments, GTA always outperformed other tree-based models and often outperformed other types of graph-learning algorithms such as Graph Neural Networks (GNNs) and Graph Kernels. Finally, we also provide an explainability mechanism for GTA, and demonstrate it can provide intuitive explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1419980979",
                    "name": "Maya Bechler-Speicher"
                },
                {
                    "authorId": "1786843",
                    "name": "A. Globerson"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "a2676e45784e8cc4b092e75d13a9f46b08b7e6b4",
            "title": "TREE-G: Decision Trees Contesting Graph Neural Networks",
            "abstract": "When dealing with tabular data, models based on decision\ntrees are a popular choice due to their high accuracy on these\ndata types, their ease of application, and explainability properties. However, when it comes to graph-structured data, it\nis not clear how to apply them effectively, in a way that in-\ncorporates the topological information with the tabular data\navailable on the vertices of the graph. To address this challenge,\nwe introduce TREE-G. TREE-G modifies standard decision\ntrees, by introducing a novel split function that is specialized\nfor graph data. Not only does this split function incorporate\nthe node features and the topological information, but it also\nuses a novel pointer mechanism that allows split nodes to\nuse information computed in previous splits. Therefore, the\nsplit function adapts to the predictive task and the graph at\nhand. We analyze the theoretical properties of TREE-G and\ndemonstrate its benefits empirically on multiple graph and\nvertex prediction benchmarks. In these experiments, TREE-G\nconsistently outperforms other tree-based models and often\noutperforms other graph-learning algorithms such as Graph\nNeural Networks (GNNs) and Graph Kernels, sometimes by\nlarge margins. Moreover, TREE-Gs models and their predic\ntions can be explained and visualized.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1419980979",
                    "name": "Maya Bechler-Speicher"
                },
                {
                    "authorId": "1786843",
                    "name": "A. Globerson"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "29323f404899fb18281593f584ced3d547f18c83",
            "title": "A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits",
            "abstract": "Motivated by the fact that humans like some level of unpredictability or novelty, and might therefore get quickly bored when interacting with a stationary policy, we introduce a novel non-stationary bandit problem, where the expected reward of an arm is fully determined by the time elapsed since the arm last took part in a switch of actions. Our model generalizes previous notions of delay-dependent rewards, and also relaxes most assumptions on the reward function. This enables the modeling of phenomena such as progressive satiation and periodic behaviours. Building upon the Combinatorial Semi-Bandits (CSB) framework, we design an algorithm and prove a bound on its regret with respect to the optimal non-stationary policy (which is NP-hard to compute). Similarly to previous works, our regret analysis is based on defining and solving an appropriate trade-off between approximation and estimation. Preliminary experiments confirm the superiority of our algorithm over both the oracle greedy approach and a vanilla CSB solver.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30304418",
                    "name": "Pierre Laforgue"
                },
                {
                    "authorId": "2134898825",
                    "name": "Giulia Clerici"
                },
                {
                    "authorId": "2286276505",
                    "name": "Nicol\u00f2 Cesa-Bianchi"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "51e40a7f14794e82bc903e21ce9f87cabe54bc52",
            "title": "Robust Model Compression Using Deep Hypotheses",
            "abstract": "Machine Learning models should ideally be compact and robust. Compactness provides efficiency and comprehensibility whereas robustness provides stability. Both topics have been studied in recent years but in isolation. Here we present a robust model compression scheme which is independent of model types: it can compress ensembles, neural networks and other types of models into diverse types of small models. \nThe main building block is the notion of depth derived from robust statistics. \nOriginally, depth was introduced as a measure of the centrality of a point in a sample such that the median is the deepest point.\nThis concept was extended to classification functions which makes it possible to define the depth of a hypothesis and the median hypothesis. Algorithms have been suggested to approximate the median but they have been limited to binary classification. In this study, we present a new algorithm, the Multiclass Empirical Median Optimization (MEMO) algorithm that finds a deep hypothesis in multi-class tasks, and prove its correctness.\nThis led to our Compact Robust Estimated Median Belief Optimization (CREMBO) algorithm for robust model compression. We demonstrate the success of this algorithm empirically by compressing neural networks and random forests into small decision trees, which are interpretable models, and show that they are more accurate and robust than other comparable methods. In addition, our empirical study shows that our method outperforms Knowledge Distillation on DNN to DNN compression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053812997",
                    "name": "Omri Armstrong"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "5e18174db0f6bee8dc9147d976774ff8290bba69",
            "title": "Trees with Attention for Set Prediction Tasks",
            "abstract": "In many machine learning applications, each record represents a set of items. For example, when making predictions from medical records, the medications prescribed to a patient are a set whose size is not fixed and whose order is arbitrary. However, most machine learning algorithms are not designed to handle set structures and are limited to processing records of fixed size. SetTree, presented in this work, extends the support for sets to tree-based models, such as RandomForest and Gradient-Boosting, by introducing an attention mechanism and set-compatible split criteria. We evaluate the new method empirically on a wide range of problems ranging from making predictions on sub-atomic particle jets to estimating the redshift of galaxies. The new method outperforms existing tree-based methods consistently and significantly. Moreover, it is competitive and often outperforms Deep Learning. We also discuss the theoretical properties of Set-Trees and explain how they enable item-level explainability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118303091",
                    "name": "Roy Hirsch"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "896e79eba0e089e700cde30bce15021d1125e39e",
            "title": "Marginal Contribution Feature Importance - an Axiomatic Approach for Explaining Data",
            "abstract": "In recent years, methods were proposed for assigning feature importance scores to measure the contribution of individual features. While in some cases the goal is to understand a specific model, in many cases the goal is to understand the contribution of certain properties (features) to a real-world phenomenon. Thus, a distinction has been made between feature importance scores that explain a model and scores that explain the data. When explaining the data, machine learning models are used as proxies in settings where conducting many real-world experiments is expensive or prohibited. While existing feature importance scores show great success in explaining models, we demonstrate their limitations when explaining the data, especially in the presence of correlations between features. Therefore, we develop a set of axioms to capture properties expected from a feature importance score when explaining data and prove that there exists only one score that satisfies all of them, the Marginal Contribution Feature Importance (MCI). We analyze the theoretical properties of this score function and demonstrate its merits empirically.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1995822153",
                    "name": "Amnon Catav"
                },
                {
                    "authorId": "1569276893",
                    "name": "Boyang Fu"
                },
                {
                    "authorId": "1490506535",
                    "name": "Yazeed Zoabi"
                },
                {
                    "authorId": "1403467804",
                    "name": "A. Weiss-Meilik"
                },
                {
                    "authorId": "2638987",
                    "name": "N. Shomron"
                },
                {
                    "authorId": "79990255",
                    "name": "J. Ernst"
                },
                {
                    "authorId": "1773997",
                    "name": "S. Sankararaman"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "90cbdbabebceb40b5a96ed6de17a0668f354d834",
            "title": "Break your Bandit Routine with LSD Rewards: a Last Switch Dependent Analysis of Satiation and Seasonality",
            "abstract": "Motivated by the fact that humans like some level of unpredictability or novelty, and might therefore get quickly bored when interacting with a stationary policy, we introduce a novel non-stationary bandit problem, where the expected reward of an arm is fully determined by the time elapsed since the arm last took part in a switch of actions. Our model generalizes previous notions of delay-dependent rewards, and also relaxes most assumptions on the reward function. This enables the modeling of phenomena such as progressive satiation and periodic behaviours. Building upon the Combinatorial Semi-Bandits (CSB) framework, we design an algorithm and prove a bound on its regret with respect to the optimal non-stationary policy (which is NP-hard to compute). Similarly to previous works, our regret analysis is based on de\ufb01ning and solving an appropriate trade-o\ufb00 between approximation and estimation. Preliminary experiments con\ufb01rm the superiority of our al-gorithm over both the oracle greedy approach and a vanilla CSB solver.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30304418",
                    "name": "Pierre Laforgue"
                },
                {
                    "authorId": "2134898825",
                    "name": "Giulia Clerici"
                },
                {
                    "authorId": "2286276505",
                    "name": "Nicol\u00f2 Cesa-Bianchi"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        },
        {
            "paperId": "9fad9ae7bb4a0a7ad51899886529d5e53ee00073",
            "title": "PyBryt: auto-assessment and auto-grading for computational thinking",
            "abstract": "We continuously interact with computerized systems to achieve goals and perform tasks in our personal and professional lives. Therefore, the ability to program such systems is a skill needed by everyone. Consequently, computational thinking skills are essential for everyone, which creates a challenge for the educational system to teach these skills at scale and allow students to practice these skills. To address this challenge, we present a novel approach to providing formative feedback to students on programming assignments. Our approach uses dynamic evaluation to trace intermediate results generated by student's code and compares them to the reference implementation provided by their teachers. We have implemented this method as a Python library and demonstrate its use to give students relevant feedback on their work while allowing teachers to challenge their students' computational thinking skills.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15812233",
                    "name": "Christopher K. Pyles"
                },
                {
                    "authorId": "35285742",
                    "name": "F. V. Schalkwyk"
                },
                {
                    "authorId": "145299521",
                    "name": "G. Gorman"
                },
                {
                    "authorId": "40602681",
                    "name": "M. Beg"
                },
                {
                    "authorId": "50860630",
                    "name": "Lee Stott"
                },
                {
                    "authorId": "2067557956",
                    "name": "Nir Levy"
                },
                {
                    "authorId": "1388775848",
                    "name": "Ran Gilad-Bachrach"
                }
            ]
        }
    ]
}