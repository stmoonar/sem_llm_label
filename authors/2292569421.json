{
    "authorId": "2292569421",
    "papers": [
        {
            "paperId": "1bd1aff50c233b235e8a8d872896ebab36ee39ca",
            "title": "ControlTraj: Controllable Trajectory Generation with Topology-Constrained Diffusion Model",
            "abstract": "Generating trajectory data is among promising solutions to addressing privacy concerns, collection costs, and proprietary restrictions usually associated with human mobility analyses. However, existing trajectory generation methods are still in their infancy due to the inherent diversity and unpredictability of human activities, grappling with issues such as fidelity, flexibility, and generalizability. To overcome these obstacles, we propose ControlTraj, a Controllable Trajectory generation framework with the topology-constrained diffusion model. Distinct from prior approaches, ControlTraj utilizes a diffusion model to generate high-fidelity trajectories while integrating the structural constraints of road network topology to guide the geographical outcomes. Specifically, we develop a novel road segment autoencoder to extract fine-grained road segment embedding. The encoded features, along with trip attributes, are subsequently merged into the proposed geographic denoising UNet architecture, named GeoUNet, to synthesize geographic trajectories from white noise. Through experimentation across three real-world data settings, ControlTraj demonstrates its ability to produce human-directed, high-fidelity trajectory generation with adaptability to unexplored geographical contexts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2292569421",
                    "name": "Yuanshao Zhu"
                },
                {
                    "authorId": "2261667444",
                    "name": "James J. Q. Yu"
                },
                {
                    "authorId": "2261673614",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "89987905",
                    "name": "Yongchao Ye"
                },
                {
                    "authorId": "2262453292",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2298640483",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2298206411",
                    "name": "Xuetao Wei"
                },
                {
                    "authorId": "2289093854",
                    "name": "Yuxuan Liang"
                }
            ]
        },
        {
            "paperId": "91580b199345721da361a3a4bffdf5da4f5f811b",
            "title": "Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond",
            "abstract": "Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety. Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities. In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj). We first define trajectory data and provide a brief overview of widely-used deep learning models. Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detection, and mobility generation). Notably, we encapsulate recent advancements in Large Language Models (LLMs) that hold the potential to augment trajectory computing. Additionally, we summarize application scenarios, public datasets, and toolkits. Finally, we outline current challenges in DL4Traj research and propose future directions. Relevant papers and open-source resources have been collated and are continuously updated at: \\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262453292",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2291969371",
                    "name": "Yuxuan Liang"
                },
                {
                    "authorId": "2292569421",
                    "name": "Yuanshao Zhu"
                },
                {
                    "authorId": "2292674387",
                    "name": "Yanchuan Chang"
                },
                {
                    "authorId": "2292397105",
                    "name": "Kang Luo"
                },
                {
                    "authorId": "2262445381",
                    "name": "Haomin Wen"
                },
                {
                    "authorId": "2292772179",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2292949566",
                    "name": "Yanwei Yu"
                },
                {
                    "authorId": "2253561592",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2292921297",
                    "name": "Chao Chen"
                },
                {
                    "authorId": "2296994338",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2271389454",
                    "name": "Yunjun Gao"
                },
                {
                    "authorId": "2258317255",
                    "name": "Xiaofang Zhou"
                },
                {
                    "authorId": "2290028296",
                    "name": "Yu Zheng"
                }
            ]
        },
        {
            "paperId": "d3486b3a6566a9fbdd26fe836dfda0dfd0b443ba",
            "title": "Towards Robust Trajectory Representations: Isolating Environmental Confounders with Causal Learning",
            "abstract": "Trajectory modeling refers to characterizing human movement behavior, serving as a pivotal step in understanding mobility patterns. Nevertheless, existing studies typically ignore the confounding effects of geospatial context, leading to the acquisition of spurious correlations and limited generalization capabilities. To bridge this gap, we initially formulate a Structural Causal Model (SCM) to decipher the trajectory representation learning process from a causal perspective. Building upon the SCM, we further present a Trajectory modeling framework (TrajCL) based on Causal Learning, which leverages the backdoor adjustment theory as an intervention tool to eliminate the spurious correlations between geospatial context and trajectories. Extensive experiments on two real-world datasets verify that TrajCL markedly enhances performance in trajectory classification tasks while showcasing superior generalization and interpretability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2292397105",
                    "name": "Kang Luo"
                },
                {
                    "authorId": "2292569421",
                    "name": "Yuanshao Zhu"
                },
                {
                    "authorId": "2262453292",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2290030203",
                    "name": "Kun Wang"
                },
                {
                    "authorId": "2274553504",
                    "name": "Zhengyang Zhou"
                },
                {
                    "authorId": "2297769202",
                    "name": "Sijie Ruan"
                },
                {
                    "authorId": "2268400993",
                    "name": "Yuxuan Liang"
                }
            ]
        },
        {
            "paperId": "f795f0b7380dbbbe8bd48f0c4505ba0d64155007",
            "title": "Large Language Model Empowered Embedding Generator for Sequential Recommendation",
            "abstract": "Sequential Recommender Systems (SRS) are extensively applied across various domains to predict users' next interaction by modeling their interaction sequences. However, these systems typically grapple with the long-tail problem, where they struggle to recommend items that are less popular. This challenge results in a decline in user discovery and reduced earnings for vendors, negatively impacting the system as a whole. Large Language Model (LLM) has the potential to understand the semantic connections between items, regardless of their popularity, positioning them as a viable solution to this dilemma. In our paper, we present LLMEmb, an innovative technique that harnesses LLM to create item embeddings that bolster the performance of SRS. To align the capabilities of general-purpose LLM with the needs of the recommendation domain, we introduce a method called Supervised Contrastive Fine-Tuning (SCFT). This method involves attribute-level data augmentation and a custom contrastive loss designed to tailor LLM for enhanced recommendation performance. Moreover, we highlight the necessity of incorporating collaborative filtering signals into LLM-generated embeddings and propose Recommendation Adaptation Training (RAT) for this purpose. RAT refines the embeddings to be optimally suited for SRS. The embeddings derived from LLMEmb can be easily integrated with any SRS model, showcasing its practical utility. Extensive experimentation on three real-world datasets has shown that LLMEmb significantly improves upon current methods when applied across different SRS models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2292569421",
                    "name": "Yuanshao Zhu"
                },
                {
                    "authorId": "2261673614",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2244621655",
                    "name": "Feng Tian"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                }
            ]
        },
        {
            "paperId": "1fb8f2d080e965c833c777f06fccf09dc9856b91",
            "title": "MOELoRA: An MOE-based Parameter Efficient Fine-Tuning Method for Multi-task Medical Applications",
            "abstract": "\u2014The recent surge in the field of Large Language Models (LLMs) has gained significant attention in numerous domains. In order to tailor an LLM to a specific domain such as a web-based healthcare system, fine-tuning with domain knowledge is necessary. However, two issues arise during fine-tuning LLMs for medical applications. The first is the problem of task variety, where there are numerous distinct tasks in real-world medical scenarios. This diversity often results in suboptimal fine-tuning due to data imbalance and seesawing problems. Additionally, the high cost of fine-tuning can be prohibitive, impeding the application of LLMs. The large number of parameters in LLMs results in enormous time and computational consumption during fine-tuning, which is difficult to justify. To address these two issues simultaneously, we propose a novel parameter-efficient fine-tuning framework for multi-task medical applications called MOELoRA. The framework aims to capitalize on the benefits of both MOE for multi-task learning and LoRA for parameter-efficient fine-tuning. To unify MOE and LoRA, we devise multiple experts as the trainable parameters, where each expert consists of a pair of low-rank matrices to maintain a small number of trainable parameters. Additionally, we propose a task-motivated gate function for all MOELoRA layers that can regulate the contributions of each expert and generate distinct parameters for various tasks. To validate the effectiveness and practicality of the proposed method, we conducted comprehensive experiments on a public multi-task Chinese medical dataset. The experimental results demonstrate that MOELoRA outperforms existing parameter-efficient fine-tuning methods. The implementation is available online for convenient reproduction of our experiments 1 .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2290857499",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2261673614",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2292569421",
                    "name": "Yuanshao Zhu"
                },
                {
                    "authorId": "2262514619",
                    "name": "Derong Xu"
                },
                {
                    "authorId": "2244621655",
                    "name": "Feng Tian"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                }
            ]
        }
    ]
}