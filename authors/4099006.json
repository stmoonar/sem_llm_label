{
    "authorId": "4099006",
    "papers": [
        {
            "paperId": "abdceff7d7983cdede9a5aabe6a476d4c72e41a3",
            "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
            "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. Our training dataset is a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance multilingual, multimodal, and long-context capabilities, we introduce three models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision. The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters, achieves superior performance in language reasoning, math, and code tasks compared to other open-source models of similar scale, such as Llama 3.1 and the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini. Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from phi-3.5-mini, excels in reasoning tasks and is adept at handling both single-image and text prompts, as well as multi-image and text prompts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114891202",
                    "name": "Marah Abdin"
                },
                {
                    "authorId": "2297768912",
                    "name": "Sam Ade Jacobs"
                },
                {
                    "authorId": "2942686",
                    "name": "A. A. Awan"
                },
                {
                    "authorId": "29956361",
                    "name": "J. Aneja"
                },
                {
                    "authorId": "113916198",
                    "name": "Ahmed Awadallah"
                },
                {
                    "authorId": "3032929",
                    "name": "H. Awadalla"
                },
                {
                    "authorId": "2297768888",
                    "name": "Nguyen Bach"
                },
                {
                    "authorId": "2297768420",
                    "name": "Amit Bahree"
                },
                {
                    "authorId": "2274106850",
                    "name": "Arash Bakhtiari"
                },
                {
                    "authorId": "145560551",
                    "name": "Harkirat Singh Behl"
                },
                {
                    "authorId": "102222453",
                    "name": "Alon Benhaim"
                },
                {
                    "authorId": "2297766346",
                    "name": "Misha Bilenko"
                },
                {
                    "authorId": "46278353",
                    "name": "Johan Bjorck"
                },
                {
                    "authorId": "121645690",
                    "name": "S\u00e9bastien Bubeck"
                },
                {
                    "authorId": "2297768425",
                    "name": "Martin Cai"
                },
                {
                    "authorId": "2157424631",
                    "name": "C. C. T. Mendes"
                },
                {
                    "authorId": "2264439430",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "113810201",
                    "name": "Vishrav Chaudhary"
                },
                {
                    "authorId": "2297780966",
                    "name": "Parul Chopra"
                },
                {
                    "authorId": "50672277",
                    "name": "Allison Del Giorno"
                },
                {
                    "authorId": "2297768528",
                    "name": "Gustavo de Rosa"
                },
                {
                    "authorId": "2297768894",
                    "name": "Matthew Dixon"
                },
                {
                    "authorId": "2315830",
                    "name": "Ronen Eldan"
                },
                {
                    "authorId": "3310951",
                    "name": "Dan Iter"
                },
                {
                    "authorId": "2054713176",
                    "name": "Abhishek Goswami"
                },
                {
                    "authorId": "2281352409",
                    "name": "S. Gunasekar"
                },
                {
                    "authorId": "2297768377",
                    "name": "Emman Haider"
                },
                {
                    "authorId": "2266241191",
                    "name": "Junheng Hao"
                },
                {
                    "authorId": "2945519",
                    "name": "Russell J. Hewett"
                },
                {
                    "authorId": "2297778093",
                    "name": "Jamie Huynh"
                },
                {
                    "authorId": "51900416",
                    "name": "Mojan Javaheripi"
                },
                {
                    "authorId": "2268726222",
                    "name": "Xin Jin"
                },
                {
                    "authorId": "2160340819",
                    "name": "Piero Kauffmann"
                },
                {
                    "authorId": "1830939",
                    "name": "Nikos Karampatziakis"
                },
                {
                    "authorId": "2297803872",
                    "name": "Dongwoo Kim"
                },
                {
                    "authorId": "2152658577",
                    "name": "Young Jin Kim"
                },
                {
                    "authorId": "2297767306",
                    "name": "Mahoud Khademi"
                },
                {
                    "authorId": "2279749803",
                    "name": "Lev Kurilenko"
                },
                {
                    "authorId": "2297805471",
                    "name": "James R. Lee"
                },
                {
                    "authorId": "2239163839",
                    "name": "Yin Tat Lee"
                },
                {
                    "authorId": "2268435346",
                    "name": "Yuanzhi Li"
                },
                {
                    "authorId": "2269852520",
                    "name": "Chen Liang"
                },
                {
                    "authorId": "2268632175",
                    "name": "Weishung Liu"
                },
                {
                    "authorId": "2297769037",
                    "name": "Eric Lin"
                },
                {
                    "authorId": "2297828605",
                    "name": "Zeqi Lin"
                },
                {
                    "authorId": "46781068",
                    "name": "Piyush Madan"
                },
                {
                    "authorId": "2256988075",
                    "name": "Arindam Mitra"
                },
                {
                    "authorId": "2297767663",
                    "name": "Hardik Modi"
                },
                {
                    "authorId": "2274742737",
                    "name": "Anh Nguyen"
                },
                {
                    "authorId": "2172095",
                    "name": "Brandon Norick"
                },
                {
                    "authorId": "27419446",
                    "name": "Barun Patra"
                },
                {
                    "authorId": "1416388980",
                    "name": "D. Perez-Becker"
                },
                {
                    "authorId": "6625302",
                    "name": "Thomas Portet"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "2279740366",
                    "name": "Heyang Qin"
                },
                {
                    "authorId": "2297777494",
                    "name": "Marko Radmilac"
                },
                {
                    "authorId": "41016119",
                    "name": "Corby Rosset"
                },
                {
                    "authorId": "2298400461",
                    "name": "Sambudha Roy"
                },
                {
                    "authorId": "2347792",
                    "name": "Olli Saarikivi"
                },
                {
                    "authorId": "2282542305",
                    "name": "Amin Saied"
                },
                {
                    "authorId": "2297768516",
                    "name": "Adil Salim"
                },
                {
                    "authorId": "1413038175",
                    "name": "Michael Santacroce"
                },
                {
                    "authorId": "2297814416",
                    "name": "Shital Shah"
                },
                {
                    "authorId": "2284868563",
                    "name": "Ning Shang"
                },
                {
                    "authorId": "2266307341",
                    "name": "Hiteshi Sharma"
                },
                {
                    "authorId": "2291873212",
                    "name": "Xianmin Song"
                },
                {
                    "authorId": "2537545",
                    "name": "Olatunji Ruwase"
                },
                {
                    "authorId": "2153689937",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "2274157852",
                    "name": "Rachel Ward"
                },
                {
                    "authorId": "2298020153",
                    "name": "Guanhua Wang"
                },
                {
                    "authorId": "2297768553",
                    "name": "Philipp Witte"
                },
                {
                    "authorId": "2226773110",
                    "name": "Michael Wyatt"
                },
                {
                    "authorId": "46747953",
                    "name": "Can Xu"
                },
                {
                    "authorId": "2257094139",
                    "name": "Jiahang Xu"
                },
                {
                    "authorId": "2297814868",
                    "name": "Sonali Yadav"
                },
                {
                    "authorId": "145338263",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2291073936",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "2287794511",
                    "name": "Donghan Yu"
                },
                {
                    "authorId": "2287118838",
                    "name": "Cheng-Yuan Zhang"
                },
                {
                    "authorId": "2297810599",
                    "name": "Cyril Zhang"
                },
                {
                    "authorId": "2297818019",
                    "name": "Jianwen Zhang"
                },
                {
                    "authorId": "2274195530",
                    "name": "L. Zhang"
                },
                {
                    "authorId": "2271712604",
                    "name": "Yi Zhang"
                },
                {
                    "authorId": "2298130748",
                    "name": "Yunan Zhang"
                },
                {
                    "authorId": "2297801063",
                    "name": "Xiren Zhou"
                }
            ]
        },
        {
            "paperId": "1b2311aba905eabfa10500d057cad5c271840344",
            "title": "Soft Convex Quantization: Revisiting Vector Quantization with Convex Optimization",
            "abstract": "Vector Quantization (VQ) is a well-known technique in deep learning for extracting informative discrete latent representations. VQ-embedded models have shown impressive results in a range of applications including image and speech generation. VQ operates as a parametric K-means algorithm that quantizes inputs using a single codebook vector in the forward pass. While powerful, this technique faces practical challenges including codebook collapse, non-differentiability and lossy compression. To mitigate the aforementioned issues, we propose Soft Convex Quantization (SCQ) as a direct substitute for VQ. SCQ works like a differentiable convex optimization (DCO) layer: in the forward pass, we solve for the optimal convex combination of codebook vectors that quantize the inputs. In the backward pass, we leverage differentiability through the optimality conditions of the forward solution. We then introduce a scalable relaxation of the SCQ optimization and demonstrate its efficacy on the CIFAR-10, GTSRB and LSUN datasets. We train powerful SCQ autoencoder models that significantly outperform matched VQ-based architectures, observing an order of magnitude better image reconstruction and codebook usage with comparable quantization runtime.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2105612963",
                    "name": "Tanmay Gautam"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "2155459391",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "2256797847",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "1685407",
                    "name": "S. Sojoudi"
                }
            ]
        },
        {
            "paperId": "39a6842456e14bc3b116a40e9fb643cf3f7cc393",
            "title": "i-Code Studio: A Configurable and Composable Framework for Integrative AI",
            "abstract": "Artificial General Intelligence (AGI) requires comprehensive understanding and generation capabilities for a variety of tasks spanning different modalities and functionalities. Integrative AI is one important direction to approach AGI, through combining multiple models to tackle complex multimodal tasks. However, there is a lack of a flexible and composable platform to facilitate efficient and effective model composition and coordination. In this paper, we propose the i-Code Studio, a configurable and composable framework for Integrative AI. The i-Code Studio orchestrates multiple pre-trained models in a finetuning-free fashion to conduct complex multimodal tasks. Instead of simple model composition, the i-Code Studio provides an integrative, flexible, and composable setting for developers to quickly and easily compose cutting-edge services and technologies tailored to their specific requirements. The i-Code Studio achieves impressive results on a variety of zero-shot multimodal tasks, such as video-to-text retrieval, speech-to-speech translation, and visual question answering. We also demonstrate how to quickly build a multimodal agent based on the i-Code Studio that can communicate and personalize for users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51444591",
                    "name": "Yuwei Fang"
                },
                {
                    "authorId": "1736464",
                    "name": "M. Khademi"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "2155459391",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "2114898054",
                    "name": "Yao Qian"
                },
                {
                    "authorId": "2218062682",
                    "name": "Takuya Yoshioka"
                },
                {
                    "authorId": "2150687325",
                    "name": "Lu Yuan"
                },
                {
                    "authorId": "48262024",
                    "name": "Michael Zeng"
                },
                {
                    "authorId": "144531812",
                    "name": "Xuedong Huang"
                }
            ]
        },
        {
            "paperId": "62454a3694e2e52b8698458440612505a3f7404b",
            "title": "The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions",
            "abstract": "Recent progress in Large Language Models (LLMs) has produced models that exhibit remarkable performance across a variety of NLP tasks. However, it remains unclear whether the existing focus of NLP research accurately captures the genuine requirements of human users. This paper provides a comprehensive analysis of the divergence between current NLP research and the needs of real-world NLP applications via a large-scale collection of user-GPT conversations. We analyze a large-scale collection of real user queries to GPT. We compare these queries against existing NLP benchmark tasks and identify a significant gap between the tasks that users frequently request from LLMs and the tasks that are commonly studied in academic research. For example, we find that tasks such as ``design'' and ``planning'' are prevalent in user interactions but are largely neglected or different from traditional NLP benchmarks. We investigate these overlooked tasks, dissect the practical challenges they pose, and provide insights toward a roadmap to make LLMs better aligned with user needs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260339714",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "2146294891",
                    "name": "Shuo Wang"
                },
                {
                    "authorId": "2260822008",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1606040932",
                    "name": "Ming Zhong"
                },
                {
                    "authorId": "1381900594",
                    "name": "Yizhu Jiao"
                },
                {
                    "authorId": "3310951",
                    "name": "Dan Iter"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "2256797847",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "bfef29e0b88a45b3b6d8018b37d6272d0f32efe2",
            "title": "In-Context Demonstration Selection with Cross Entropy Difference",
            "abstract": "Large language models (LLMs) can use in-context demonstrations to improve performance on zero-shot tasks. However, selecting the best in-context examples is challenging because model performance can vary widely depending on the selected examples. We present a cross-entropy difference (CED) method for selecting in-context demonstrations. Our method is based on the observation that the effectiveness of in-context demonstrations negatively correlates with the perplexity of the test example by a language model that was finetuned on that demonstration. We utilize parameter efficient finetuning to train small models on training data that are used for computing the cross-entropy difference between a test example and every candidate in-context demonstration. This metric is used to rank and select in-context demonstrations independently for each test input. We evaluate our method on a mix-domain dataset that combines 8 benchmarks, representing 4 text generation tasks, showing that CED for in-context demonstration selection can improve performance for a variety of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3310951",
                    "name": "Dan Iter"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "8233965",
                    "name": "Ruochen Xu"
                },
                {
                    "authorId": "2146294891",
                    "name": "Shuo Wang"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                }
            ]
        },
        {
            "paperId": "c76dd4a70361c3afd2e19d046343e2dedd16ecc3",
            "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search",
            "abstract": "Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language\"gradients\"that criticize the current prompt. The gradients are then\"propagated\"into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing techniques and improve an initial prompt's performance by up to 31%, by using data to rewrite vague task descriptions into more precise annotation instructions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "3310951",
                    "name": "Dan Iter"
                },
                {
                    "authorId": "2800851",
                    "name": "Jerry Li"
                },
                {
                    "authorId": "2109308930",
                    "name": "Y. Lee"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "48262024",
                    "name": "Michael Zeng"
                }
            ]
        },
        {
            "paperId": "cb861bd77070e4441d66ffee0801f7048a9eacbe",
            "title": "i-Code V2: An Autoregressive Generation Framework over Vision, Language, and Speech Data",
            "abstract": "The convergence of text, visual, and audio data is a key step towards human-like artificial intelligence, however the current Vision-Language-Speech landscape is dominated by encoder-only models which lack generative abilities. We propose closing this gap with i-Code V2, the first model capable of generating natural language from any combination of Vision, Language, and Speech data. i-Code V2 is an integrative system that leverages state-of-the-art single-modality encoders, combining their outputs with a new modality-fusing encoder in order to flexibly project combinations of modalities into a shared representational space. Next, language tokens are generated from these representations via an autoregressive decoder. The whole framework is pretrained end-to-end on a large collection of dual- and single-modality datasets using a novel text completion objective that can be generalized across arbitrary combinations of modalities. i-Code V2 matches or outperforms state-of-the-art single- and dual-modality baselines on 7 multimodal tasks, demonstrating the power of generative multimodal pretraining across a diversity of tasks and signals.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2155459391",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "1736464",
                    "name": "M. Khademi"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "51444591",
                    "name": "Yuwei Fang"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "49025801",
                    "name": "Dongdong Chen"
                },
                {
                    "authorId": "2114898054",
                    "name": "Yao Qian"
                },
                {
                    "authorId": "2147416198",
                    "name": "Mei Gao"
                },
                {
                    "authorId": "2109182290",
                    "name": "Yi-Ling Chen"
                },
                {
                    "authorId": "2983603",
                    "name": "R. Gmyr"
                },
                {
                    "authorId": "1833359",
                    "name": "Naoyuki Kanda"
                },
                {
                    "authorId": "40589056",
                    "name": "N. Codella"
                },
                {
                    "authorId": "2054421528",
                    "name": "Bin Xiao"
                },
                {
                    "authorId": "1844953096",
                    "name": "Yu Shi"
                },
                {
                    "authorId": "2150687325",
                    "name": "Lu Yuan"
                },
                {
                    "authorId": "34638725",
                    "name": "Takuya Yoshioka"
                },
                {
                    "authorId": "48262024",
                    "name": "Michael Zeng"
                },
                {
                    "authorId": "144531812",
                    "name": "Xuedong Huang"
                }
            ]
        },
        {
            "paperId": "46f34c48c3e0fa84a5fc257521f176d3ab046d88",
            "title": "Automatic Rule Induction for Efficient Semi-Supervised Learning",
            "abstract": "Semi-supervised learning has shown promise in allowing NLP models to generalize from small amounts of labeled data. Meanwhile, pretrained transformer models act as black-box correlation engines that are difficult to explain and sometimes behave unreliably. In this paper, we propose tackling both of these challenges via Automatic Rule Induction (ARI), a simple and general-purpose framework for the automatic discovery and integration of symbolic rules into pretrained transformer models. First, we extract weak symbolic rules from low-capacity machine learning models trained on small amounts of labeled data. Next, we use an attention mechanism to integrate these rules into high-capacity pretrained transformer models. Last, the rule-augmented system becomes part of a self-training framework to boost supervision signal on unlabeled data. These steps can be layered beneath a variety of existing weak supervision and semi-supervised NLP algorithms in order to improve performance and interpretability. Experiments across nine sequence classification and relation extraction tasks suggest that ARI can improve state-of-the-art methods with no manual effort and minimal computational overhead.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "2155459391",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "48262024",
                    "name": "Michael Zeng"
                }
            ]
        },
        {
            "paperId": "6017b049567f6b545551cf4838dde42d8ce25e3f",
            "title": "FAST: Improving Controllability for Text Generation with Feedback Aware Self-Training",
            "abstract": "Controllable text generation systems often leverage control codes to direct various properties of the output like style and length. Inspired by recent work on causal inference for NLP, this paper reveals a previously overlooked flaw in these control code-based conditional text generation algorithms. Spurious correlations in the training data can lead models to incorrectly rely on parts of the input other than the control code for attribute selection, significantly undermining downstream generation quality and controllability. We demonstrate the severity of this issue with a series of case studies and then propose two simple techniques to reduce these correlations in training sets. The first technique is based on resampling the data according to an example's propensity towards each linguistic attribute (IPS). The second produces multiple counterfactual versions of each example and then uses an additional feedback mechanism to remove noisy examples (feedback aware self-training, FAST). We evaluate on 3 tasks -- news headline, meta review, and search ads generation -- and demonstrate that FAST can significantly improve the controllability and language quality of generated outputs when compared to state-of-the-art controllable text generation approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149320764",
                    "name": "Junyi Chai"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "2180792383",
                    "name": "Victor Ye Dong"
                },
                {
                    "authorId": "2180794423",
                    "name": "Konstantin Golobokov"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "2178397972",
                    "name": "Yi Liu"
                }
            ]
        },
        {
            "paperId": "67590dc371a89bef960b7bd547110f43cbe7196e",
            "title": "APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning",
            "abstract": "Logical reasoning over text is an important ability that requires understanding the semantics of the text and reasoning through them to arrive at correct inferences. Prior works on pretraining language models to improve the logical reasoning ability require complex processing of training data (e.g., aligning symbolic knowledge to text), yielding task-specific data augmentation that is not easy to adapt to any general text corpus. In this work, we propose APOLLO, a simple adaptive pretraining approach to improve the logical reasoning skills of language models. We select a subset of Wikipedia for adaptive pretraining using a set of logical inference keywords as filter words. Further, we propose two self-supervised loss functions for training. First, we modify the masked language modeling loss only to mask specific parts-of-speech words that likely require higher-order reasoning to predict them. Second, we propose a sentence-level classification loss that teaches the model to distinguish between entailment and contradiction types of sentences. The proposed pretraining paradigm is both simple and independent of task formats. We demonstrate the effectiveness of APOLLO by comparing it with prior baselines on two logical reasoning datasets. APOLLO performs comparably on ReClor and outperforms baselines on LogiQA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3313909",
                    "name": "Soumya Sanyal"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "2992833",
                    "name": "Shuohang Wang"
                },
                {
                    "authorId": "2155459391",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "4099006",
                    "name": "Reid Pryzant"
                },
                {
                    "authorId": "38767143",
                    "name": "W. Yu"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        }
    ]
}