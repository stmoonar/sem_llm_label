{
    "authorId": "1689513",
    "papers": [
        {
            "paperId": "b173aa7013912fed7055233be2dea4428f77eceb",
            "title": "Reproducibility in Machine Learning-based Research: Overview, Barriers and Drivers",
            "abstract": "Research in various fields is currently experiencing challenges regarding the reproducibility of results. This problem is also prevalent in machine learning (ML) research. The issue arises, for example, due to unpublished data and/or source code and the sensitivity of ML training conditions. Although different solutions have been proposed to address this issue, such as using ML platforms, the level of reproducibility in ML-driven research remains unsatisfactory. Therefore, in this article, we discuss the reproducibility of ML-driven research with three main aims: (i) identifying the barriers to reproducibility when applying ML in research as well as categorize the barriers to different types of reproducibility (description, code, data, and experiment reproducibility), (ii) discussing potential drivers such as tools, practices, and interventions that support ML reproducibility, as well as distinguish between technology-driven drivers, procedural drivers, and drivers related to awareness and education, and (iii) mapping the drivers to the barriers. With this work, we hope to provide insights and to contribute to the decision-making process regarding the adoption of different solutions to support ML reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48805883",
                    "name": "Harald Semmelrock"
                },
                {
                    "authorId": "2277609888",
                    "name": "Tony Ross-Hellauer"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "2127270",
                    "name": "Dieter Theiler"
                },
                {
                    "authorId": "2181440510",
                    "name": "Armin Haberl"
                },
                {
                    "authorId": "2259939451",
                    "name": "Stefan Thalmann"
                },
                {
                    "authorId": "2259955606",
                    "name": "Dominik Kowald"
                }
            ]
        },
        {
            "paperId": "2cbadfa44dd2818738943c0be4a4cbd69aac9b95",
            "title": "Computational Versus Perceived Popularity Miscalibration in Recommender Systems",
            "abstract": "Popularity bias in recommendation lists refers to over-representation of popular content and is a challenge for many recommendation algorithms. Previous research has suggested several offline metrics to quantify popularity bias, which commonly relate the popularity of items in users' recommendation lists to the popularity of items in their interaction history. Discrepancies between these two factors are referred to as popularity miscalibration. While popularity metrics provide a straightforward and well-defined means to measure popularity bias, it is unknown whether they actually reflect users' perception of popularity bias. To address this research gap, we conduct a crowd-sourced user study on Prolific, involving 56 participants, to (1) investigate whether the level of perceived popularity miscalibration differs between common recommendation algorithms, (2) assess the correlation between perceived popularity miscalibration and its corresponding quantification according to a common offline metric. We conduct our study in a well-defined and important domain, namely music recommendation using the standardized LFM-2b dataset, and quantify popularity miscalibration of five recommendation algorithms by utilizing Jensen-Shannon distance (JSD). Challenging the findings of previous studies, we observe that users generally do perceive significant differences in terms of popularity bias between algorithms if this bias is framed as popularity miscalibration. In addition, JSD correlates moderately with users' perception of popularity, but not with their perception of unpopularity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "2223770106",
                    "name": "Gustavo Escobedo"
                },
                {
                    "authorId": "2614755",
                    "name": "Yashar Deldjoo"
                },
                {
                    "authorId": "3001795",
                    "name": "B. Ferwerda"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "605755564694f22a63ad5f17116704077182cdbd",
            "title": "Show me a \"Male Nurse\"! How Gender Bias is Reflected in the Query Formulation of Search Engine Users",
            "abstract": "Biases in algorithmic systems have led to discrimination against historically disadvantaged groups, including the reinforcement of outdated gender stereotypes. While a substantial body of research addresses biases in algorithms and underlying data, in this work, we study if and how users themselves reflect these biases in their interactions with systems, which expectedly leads to the further manifestation of biases. More specifically, we investigate the replication of stereotypical gender representations by users in formulating online search queries. Following prototype theory, we define the disproportionate mention of the gender that does not conform to the prototypical representative of a searched domain (e.g., \u201cmale nurse\u201d) as an indication of bias. In a pilot study with 224 US participants and a main study with 400 UK participants, we find clear evidence of gender biases in formulating search queries. We also report the effects of an educative text on user behaviour and highlight the wish of users to learn about bias-mitigating strategies in their interactions with search engines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "2424581",
                    "name": "Martina Mara"
                },
                {
                    "authorId": "2214759238",
                    "name": "Linda Ratz"
                },
                {
                    "authorId": "2150483265",
                    "name": "Klara Krieg"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "919aa61034458563220113c9ddea7cf831bcaa0a",
            "title": "A conceptual model for leaving the data-centric approach in machine learning",
            "abstract": "For a long time, machine learning (ML) has been seen as the abstract problem of learning relationships from data independent of the surrounding settings. This has recently been challenged, and methods have been proposed to include external constraints in the machine learning models. These methods usually come from application-specific fields, such as de-biasing algorithms in the field of fairness in ML or physical constraints in the fields of physics and engineering. In this paper, we present and discuss a conceptual high-level model that unifies these approaches in a common language. We hope that this will enable and foster exchange between the different fields and their different methods for including external constraints into ML models, and thus leaving purely data-centric approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "89677034",
                    "name": "S. Scher"
                },
                {
                    "authorId": "1770820",
                    "name": "B. Geiger"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3011260",
                    "name": "A. Tr\u00fcgler"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                }
            ]
        },
        {
            "paperId": "f150b924f1ade872e582cb2a45e25562d0357f9d",
            "title": "Reproducibility in Machine Learning-Driven Research",
            "abstract": "Research is facing a reproducibility crisis, in which the results and findings of many studies are difficult or even impossible to reproduce. This is also the case in machine learning (ML) and artificial intelligence (AI) research. Often, this is the case due to unpublished data and/or source-code, and due to sensitivity to ML training conditions. Although different solutions to address this issue are discussed in the research community such as using ML platforms, the level of reproducibility in ML-driven research is not increasing substantially. Therefore, in this mini survey, we review the literature on reproducibility in ML-driven research with three main aims: (i) reflect on the current situation of ML reproducibility in various research fields, (ii) identify reproducibility issues and barriers that exist in these research fields applying ML, and (iii) identify potential drivers such as tools, practices, and interventions that support ML reproducibility. With this, we hope to contribute to decisions on the viability of different solutions for supporting ML reproducibility.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "48805883",
                    "name": "Harald Semmelrock"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "2127270",
                    "name": "Dieter Theiler"
                },
                {
                    "authorId": "1403766183",
                    "name": "Tony Ross-Hellauer"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                }
            ]
        },
        {
            "paperId": "e9981c3af60c536b08083f8a0da59a9a18bb1c53",
            "title": "Long-term dynamics of fairness: understanding the impact of data-driven targeted help on job seekers",
            "abstract": "The use of data-driven decision support by public agencies is becoming more widespread and already influences the allocation of public resources. This raises ethical concerns, as it has adversely affected minorities and historically discriminated groups. In this paper, we use an approach that combines statistics and machine learning with dynamical modeling to assess long-term fairness effects of labor market interventions. Specifically, we develop and use a model to investigate the impact of decisions caused by a public employment authority that selectively supports job-seekers through targeted help. The selection of who receives what help is based on a data-driven intervention model that estimates an individual\u2019s chances of finding a job in a timely manner and is based on data that describes a population in which skills relevant to the labor market are unevenly distributed between two groups (e.g., males and females). The intervention model has incomplete access to the individual\u2019s actual skills and can augment this with knowledge of the individual\u2019s group affiliation, thus using a protected attribute to increase predictive accuracy. We assess this intervention model\u2019s dynamics - especially fairness-related issues and trade-offs between different fairness goals-over time and compare it to an intervention model that does not use group affiliation as a predictive feature. We conclude that in order to quantify the trade-off correctly and to assess the long-term fairness effects of such a system in the real-world, careful modeling of the surrounding labor market is indispensable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "89677034",
                    "name": "S. Scher"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3011260",
                    "name": "A. Tr\u00fcgler"
                },
                {
                    "authorId": "1803040",
                    "name": "Dominik Kowald"
                }
            ]
        },
        {
            "paperId": "175c8abaa39cf0966e0a8c239440540b721a6b7e",
            "title": "Studying Moral-based Differences in the Framing of Political Tweets",
            "abstract": "In this paper, we study the moral framing of political content on Twitter. Specifically, we examine differences in moral framing in two datasets: (i) tweets from US-based politicians annotated with political affiliation and (ii) COVID-19 related tweets in German from followers of the leaders of the five major Austrian political parties. Our research is based on recent work that introduces an unsupervised approach to extract framing bias and intensity in news using a dictionary of moral virtues and vices. In this paper, we use a more extensive dictionary and adapt it to German-language tweets. Overall, in both datasets, we observe a moral framing that is congruent with the public perception of the political parties. In the US dataset, democrats have a tendency to frame tweets in terms of care, while loyalty is a characteristic frame for republicans. In the Austrian dataset, we find that the followers of the governing conservative party emphasize care, which is a key message and moral frame in the party's COVID-19 campaign slogan. Our work complements existing studies on moral framing in social media. Also, our empirical findings provide novel insights into moral-based framing on COVID-19 in Austria.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405284505",
                    "name": "Markus Reiter-Haas"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                }
            ]
        },
        {
            "paperId": "d867b7dca02c97ef7fe92fc0da83dbec77bfc6c6",
            "title": "Societal Biases in Retrieved Contents: Measurement Framework and Adversarial Mitigation of BERT Rankers",
            "abstract": "Societal biases resonate in the retrieved contents of information retrieval (IR) systems, resulting in reinforcing existing stereotypes. Approaching this issue requires established measures of fairness in respect to the representation of various social groups in retrieval results, as well as methods to mitigate such biases, particularly in the light of the advances in deep ranking models. In this work, we first provide a novel framework to measure the fairness in the retrieved text contents of ranking models. Introducing a ranker-agnostic measurement, the framework also enables the disentanglement of the effect on fairness of collection from that of rankers. To mitigate these biases, we propose AdvBert, a ranking model achieved by adapting adversarial bias mitigation for IR, which jointly learns to predict relevance and remove protected attributes. We conduct experiments on two passage retrieval collections (MSMARCO Passage Re-ranking and TREC Deep Learning 2019 Passage Re-ranking), which we extend by fairness annotations of a selected subset of queries regarding gender attributes. Our results on the MSMARCO benchmark show that, (1) all ranking models are less fair in comparison with ranker-agnostic baselines, and (2) the fairness of Bert rankers significantly improves when using the proposed AdvBert models. Lastly, we investigate the trade-off between fairness and utility, showing that we can maintain the significant improvements in fairness without any significant loss in utility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                }
            ]
        },
        {
            "paperId": "f78b2c2be25de334566ff54dedc01b75a97912a5",
            "title": "Applying Cognitive Learner Models for Recommender Systems in Sparse Data Learning Environments",
            "abstract": "In recent years, various recommendation algorithms have been proposed to support learners in technology-enhanced learning environments. Such algorithms have proven to be quite effective in big-data learning settings (massive open online courses), yet successful applications in other informal and formal learning settings are rare. Common challenges include data sparsity, the lack of sufficiently flexible learner and domain models, and the difficulty of including pedagogical goals into recommendation strategies. Computational models of human cognition and learning are, in principle, well positioned to help meet these challenges, yet the effectiveness of cognitive models in educational recommender systems remains poorly understood to this date. This thesis contributes to this strand of research by investigating i) two cognitive learner models (CbKST and SUSTAIN) for resource recommendations that qualify for sparse user data by following theory-driven top down approaches, and ii) two tag recommendation strategies based on models of human cognition (BLL and MINERVA2) that support the creation of learning content meta-data. The results of four online and offline experiments in different learning contexts indicate that a recommendation approach based on the CbKST, a well-founded structural model of knowledge representation, can improve the users? perceived learning experience in formal learning settings. In informal settings, SUSTAIN, a human category learning model, is shown to succeed in representing dynamic, interest based learning interactions and to improve Collaborative Filtering for resource recommendations. The investigation of the two proposed tag recommender strategies underlined their ability to generate accurate suggestions (BLL) and in collaborative settings, their potential to promote the development of shared vocabulary (MINERVA2). This thesis shows that the application of computational models of human cognition holds promise for the design of recommender mechanisms and, at the same time, for gaining a deeper understanding of interaction dynamics in virtual learning systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                }
            ]
        },
        {
            "paperId": "4f82e5eeae8fcd8f6739c51e0bc4266c15370c98",
            "title": "Supporting collaborative learning with tag recommendations: a real-world study in an inquiry-based classroom project",
            "abstract": "In online social learning environments, tagging has demonstrated its potential to facilitate search, to improve recommendations and to foster reflection and learning.Studies have shown that shared understanding needs to be established in the group as a prerequisite for learning. We hypothesise that this can be fostered through tag recommendation strategies that contribute to semantic stabilization. In this study, we investigate the application of two tag recommenders that are inspired by models of human memory: (i) the base-level learning equation BLL and (ii) Minerva. BLL models the frequency and recency of tag use while Minerva is based on frequency of tag use and semantic context. We test the impact of both tag recommenders on semantic stabilization in an online study with 56 students completing a group-based inquiry learning project in school. We find that displaying tags from other group members contributes significantly to semantic stabilization in the group, as compared to a strategy where tags from the students' individual vocabularies are used. Testing for the accuracy of the different recommenders revealed that algorithms using frequency counts such as BLL performed better when individual tags were recommended. When group tags were recommended, the Minerva algorithm performed better. We conclude that tag recommenders, exposing learners to each other's tag choices by simulating search processes on learners' semantic memory structures, show potential to support semantic stabilization and thus, inquiry-based learning in groups.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689513",
                    "name": "Simone Kopeinik"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "1800363",
                    "name": "Paul Seitlinger"
                },
                {
                    "authorId": "1694011",
                    "name": "D. Albert"
                },
                {
                    "authorId": "152241455",
                    "name": "Tobias Ley"
                }
            ]
        }
    ]
}