{
    "authorId": "2218209429",
    "papers": [
        {
            "paperId": "4c843964e62b4c40e7c934fb79b27e4507975bce",
            "title": "BERTastic at SemEval-2024 Task 4: State-of-the-Art Multilingual Propaganda Detection in Memes via Zero-Shot Learning with Vision-Language Models",
            "abstract": "Analyzing propagandistic memes in a multilingual, multimodal dataset is a challenging problem due to the inherent complexity of memes\u2019 multimodal content, which combines images, text, and often, nuanced context. In this paper, we use a VLM in a zero-shot approach to detect propagandistic memes and achieve a state-of-the-art average macro F1 of 66.7% over all languages. Notably, we outperform other systems on North Macedonian memes, and obtain competitive results on Bulgarian and Arabic memes. We also present our early fusion approach for identifying persuasion techniques in memes in a hierarchical multilabel classification setting. This approach outperforms all other approaches in average hierarchical precision with an average score of 77.66%. The systems presented contribute to the evolving field of research on the detection of persuasion techniques in multimodal datasets by offering insights that could be of use in the development of more effective tools for combating online propaganda.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "b035635e7a715989941af7e1b4c0b1e09e8628df",
            "title": "FRAPPE: FRAming, Persuasion, and Propaganda Explorer",
            "abstract": "The abundance of news sources and the urgent demand for reliable information have led to serious concerns about the threat of misleading information. In this paper, we present FRAPPE, a FRAming, Persuasion, and Propaganda Explorer system. FRAPPE goes beyond conventional news analysis of articles and unveils the intricate linguistic techniques used to shape readers\u2019 opinions and emotions. Our system allows users not only to analyze individual articles for their genre, framings, and use of persuasion techniques, but also to draw comparisons between the strategies of persuasion and framing adopted by a diverse pool of news outlets and countries across multiple languages for different topics, thus providing a comprehensive understanding of how information is presented and manipulated. FRAPPE is publicly accessible at https://frappe.streamlit.app/ and a video explaining our system is available at https://www.youtube.com/watch?v=3RlTfSVnZmk",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2291367379",
                    "name": "Ahmed Sajwani"
                },
                {
                    "authorId": "2293402909",
                    "name": "Alaa Elsetohy"
                },
                {
                    "authorId": "2291366219",
                    "name": "Ali Mekky"
                },
                {
                    "authorId": "2291363086",
                    "name": "Diana Turmakhan"
                },
                {
                    "authorId": "2291361864",
                    "name": "Lara Hassan"
                },
                {
                    "authorId": "2293401556",
                    "name": "Mohamed El Zeftawy"
                },
                {
                    "authorId": "2293401831",
                    "name": "Omar El Herraoui"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2291368505",
                    "name": "Qisheng Liao"
                },
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                }
            ]
        },
        {
            "paperId": "c56eab12bd00e2fe28868af21d518044d66df00d",
            "title": "SemEval-2024 Task 8: Multidomain, Multimodel and Multilingual Machine-Generated Text Detection",
            "abstract": "We present the results and the main findings of SemEval-2024 Task 8: Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. The task featured three subtasks. Subtask A is a binary classification task determining whether a text is written by a human or generated by a machine. This subtask has two tracks: a monolingual track focused solely on English texts and a multilingual track. Subtask B is to detect the exact source of a text, discerning whether it is written by a human or generated by a specific LLM. Subtask C aims to identify the changing point within a text, at which the authorship transitions from human to machine. The task attracted a large number of participants: subtask A monolingual (126), subtask A multilingual (59), subtask B (70), and subtask C (30). In this paper, we present the task, analyze the results, and discuss the system submissions and the methods they used. For all subtasks, the best systems used LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2241417701",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "2218861055",
                    "name": "Jonibek Mansurov"
                },
                {
                    "authorId": "2058455381",
                    "name": "Petar Ivanov"
                },
                {
                    "authorId": "2265989879",
                    "name": "Jinyan Su"
                },
                {
                    "authorId": "1967424",
                    "name": "Artem Shelmanov"
                },
                {
                    "authorId": "2164381839",
                    "name": "Akim Tsvigun"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                },
                {
                    "authorId": "2284686859",
                    "name": "Giovanni Puccetti"
                },
                {
                    "authorId": "2284687590",
                    "name": "Thomas Arnold"
                },
                {
                    "authorId": "2161240241",
                    "name": "Chenxi Whitehouse"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2260340390",
                    "name": "Iryna Gurevych"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "c59628de894a4aa7f91548bad5b4103b747256e8",
            "title": "M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection",
            "abstract": "The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine human-generated text is critical in combating disinformation, preserving the integrity of education and scientific fields, and maintaining trust in communication. In this work, we address this problem by introducing a new benchmark based on a multilingual, multi-domain, and multi-generator corpus of MGTs -- M4GT-Bench. The benchmark is compiled of three tasks: (1) mono-lingual and multi-lingual binary MGT detection; (2) multi-way detection where one need to identify, which particular model generated the text; and (3) mixed human-machine text detection, where a word boundary delimiting MGT from human-written content should be determined. On the developed benchmark, we have tested several MGT detection baselines and also conducted an evaluation of human performance. We see that obtaining good performance in MGT detection usually requires an access to the training data from the same domain and generators. The benchmark is available at https://github.com/mbzuai-nlp/M4GT-Bench.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2241417701",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "2218861055",
                    "name": "Jonibek Mansurov"
                },
                {
                    "authorId": "2058455381",
                    "name": "Petar Ivanov"
                },
                {
                    "authorId": "2265989879",
                    "name": "Jinyan Su"
                },
                {
                    "authorId": "1967424",
                    "name": "Artem Shelmanov"
                },
                {
                    "authorId": "2164381839",
                    "name": "Akim Tsvigun"
                },
                {
                    "authorId": "2284688236",
                    "name": "Osama Mohanned Afzal"
                },
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                },
                {
                    "authorId": "2284686859",
                    "name": "Giovanni Puccetti"
                },
                {
                    "authorId": "2284687590",
                    "name": "Thomas Arnold"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2260340390",
                    "name": "Iryna Gurevych"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "ea4c0ab66529cac83f0b2b50eaef305da6a297e1",
            "title": "LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection",
            "abstract": "The widespread accessibility of large language models (LLMs) to the general public has significantly amplified the dissemination of machine-generated texts (MGTs). Advancements in prompt manipulation have exacerbated the difficulty in discerning the origin of a text (human-authored vs machinegenerated). This raises concerns regarding the potential misuse of MGTs, particularly within educational and academic domains. In this paper, we present $\\textbf{LLM-DetectAIve}$ -- a system designed for fine-grained MGT detection. It is able to classify texts into four categories: human-written, machine-generated, machine-written machine-humanized, and human-written machine-polished. Contrary to previous MGT detectors that perform binary classification, introducing two additional categories in LLM-DetectiAIve offers insights into the varying degrees of LLM intervention during the text creation. This might be useful in some domains like education, where any LLM intervention is usually prohibited. Experiments show that LLM-DetectAIve can effectively identify the authorship of textual content, proving its usefulness in enhancing integrity in education, academia, and other domains. LLM-DetectAIve is publicly accessible at https://huggingface.co/spaces/raj-tomar001/MGT-New. The video describing our system is available at https://youtu.be/E8eT_bE7k8c.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315296727",
                    "name": "Mervat Abassy"
                },
                {
                    "authorId": "2315302985",
                    "name": "Kareem Elozeiri"
                },
                {
                    "authorId": "2315840157",
                    "name": "Alexander Aziz"
                },
                {
                    "authorId": "2315297170",
                    "name": "Minh Ngoc Ta"
                },
                {
                    "authorId": "2309163441",
                    "name": "Raj Vardhan Tomar"
                },
                {
                    "authorId": "2315301202",
                    "name": "Bimarsha Adhikari"
                },
                {
                    "authorId": "2315642904",
                    "name": "Saad El Dine Ahmed"
                },
                {
                    "authorId": "2241417701",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2315671993",
                    "name": "Zhuohan Xie"
                },
                {
                    "authorId": "2218861055",
                    "name": "Jonibek Mansurov"
                },
                {
                    "authorId": "2300660029",
                    "name": "Ekaterina Artemova"
                },
                {
                    "authorId": "51259225",
                    "name": "V. Mikhailov"
                },
                {
                    "authorId": "2308041454",
                    "name": "Rui Xing"
                },
                {
                    "authorId": "2266466915",
                    "name": "Jiahui Geng"
                },
                {
                    "authorId": "2300555930",
                    "name": "Hasan Iqbal"
                },
                {
                    "authorId": "2266755049",
                    "name": "Zain Muhammad Mujahid"
                },
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                },
                {
                    "authorId": "2164381839",
                    "name": "Akim Tsvigun"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "1967424",
                    "name": "Artem Shelmanov"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2260340390",
                    "name": "Iryna Gurevych"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "208b091d2458d1ddef1e18d39f839fff7f992748",
            "title": "BERTastic at SemEval-2023 Task 3: Fine-Tuning Pretrained Multilingual Transformers Does Order Matter?",
            "abstract": "The naive approach for fine-tuning pretrained deep learning models on downstream tasks involves feeding them mini-batches of randomly sampled data. In this paper, we propose a more elaborate method for fine-tuning Pretrained Multilingual Transformers (PMTs) on multilingual data. Inspired by the success of curriculum learning approaches, we investigate the significance of fine-tuning PMTs on multilingual data in a sequential fashion language by language. Unlike the curriculum learning paradigm where the model is presented with increasingly complex examples, we do not adopt a notion of \u201ceasy\u201d and \u201chard\u201d samples. Instead, our experiments draw insight from psychological findings on how the human brain processes new information and the persistence of newly learned concepts. We perform our experiments on a challenging news-framing dataset that contains texts in six languages. Our proposed method outperforms the na\u00efve approach by achieving improvements of 2.57\\% in terms of F1 score. Even when we supplement the na\u00efve approach with recency fine-tuning, we still achieve an improvement of 1.34\\% with a 3.63\\%$ convergence speed-up. Moreover, we are the first to observe an interesting pattern in which deep learning models exhibit a human-like primacy-recency effect.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "60730c7baeeabf4ff2fd824effc40bca465b1334",
            "title": "M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection",
            "abstract": "Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark M4, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115829571",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "2218861055",
                    "name": "Jonibek Mansurov"
                },
                {
                    "authorId": "2058455381",
                    "name": "Petar Ivanov"
                },
                {
                    "authorId": "2116966710",
                    "name": "Jinyan Su"
                },
                {
                    "authorId": "1967424",
                    "name": "Artem Shelmanov"
                },
                {
                    "authorId": "2164381839",
                    "name": "Akim Tsvigun"
                },
                {
                    "authorId": "2161240241",
                    "name": "Chenxi Whitehouse"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2218209429",
                    "name": "Tarek Mahmoud"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                }
            ]
        }
    ]
}