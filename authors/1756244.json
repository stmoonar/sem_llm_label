{
    "authorId": "1756244",
    "papers": [
        {
            "paperId": "dcbea3751ba8803d257419846d835d87a3204e45",
            "title": "Stable Image Encryption Algorithm Based on Expanded One-Dimensional Chaotic Jumping and Parallel Encoding Operation Grouping",
            "abstract": "The current algorithm of encrypting images uses low-dimensional chaotic systems with a limited key space and poor security, while high-dimensional chaotic systems are difficult to implement and inefficient. Additionally, if image encryption algorithms use fixed DNA encoding rules, they could be cracked; dynamic coding can easily deviate from optimal solutions, thus causing algorithm instability. Based on this, a novel technique for image encryption is presented in this article. It is possible to avoid linear correlation of the chaotic sequence by randomly jumping on two uncorrelated one-dimensional chaoses. Meanwhile, numerous encryption results are generated in parallel by randomly grouping DNA encoding groups and encoding operations, and the optimal solution is then selected based on the encryption results, thereby minimizing ciphertext image instability to some extent. According to the experimental results, this algorithm produces high-security, plaintext-sensitive, and non-cracking encrypted images. Furthermore, this algorithm produces excellent encryption results both on color and sized images, and is applicable to a wide variety of applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146334895",
                    "name": "T. Zhang"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "5e46e370ab9a77210e2e94ca1692b44cb0e33299",
            "title": "The Butterfly Effect in Primary Visual Cortex",
            "abstract": "Exploring and establishing artificial neural networks with electrophysiological characteristics and high computational efficiency is a popular topic that has been explored for many years in the fields of pattern recognition and computer vision. Inspired by the working mechanism of the primary visual cortex, pulse-coupled neural networks (PCNNs) can exhibit the characteristics of synchronous oscillation, refractory period, and exponential decay. These characteristics empower the PCNN model to group pixels with similar spatiality and gray values and to process digital images without training. However, electrophysiological evidence shows that the neurons exhibit highly complex nonlinear dynamics when stimulated by external periodic signals. This chaos phenomenon, also known as the \u2018butterfly effect,\u201d cannot be explained by all PCNN models. In this work, we analyze the main obstacle preventing PCNN models from imitating a real primary visual cortex. We consider neuronal excitation as a stochastic process. We then propose a novel neural network of the primary visual cortex, called a continuous-coupled neural network (CCNN). Theoretical analysis indicates that the dynamic behavior of the CCNN is distinct from the PCNN. Numerical results show that the CCNN model exhibits periodic behavior under a DC stimulus, and exhibits chaotic behavior under an AC stimulus, which is consistent with the testing results of primary visual cortex neurons. Furthermore, the image and video processing mechanisms of the CCNN model are analyzed. For image processing tasks, this model encodes the pixel intensity as the frequency of output signals so that it can group pixels with similar gray values. This image processing method can reduce the local gray level difference of the image, and compensate for small local discontinuities in the image. For video processing tasks, the CCNN encodes changing pixels as non-periodic chaotic signals, and it encodes static pixels as periodic signals. It thus achieves the purpose of moving target object recognition by distinguishing the dynamic states corresponding to different neuron clusters in the video. Experimental results on image segmentation indicate that the CCNN model has better performance than the state-of-the-art of visual cortex neural network models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2108324267",
                    "name": "Jizhao Liu"
                },
                {
                    "authorId": "1561165594",
                    "name": "Jing Lian"
                },
                {
                    "authorId": "2935810",
                    "name": "J. Sprott"
                },
                {
                    "authorId": "2157067900",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "667cad821d964d74630c996cacf90e3a3c991309",
            "title": "A Novel Neuron Model of Visual Processor",
            "abstract": "Simulating and imitating the neuronal network of humans or mammals is a popular topic that has been explored for many years in the \ufb01elds of pattern recognition and computer vision. Inspired by neuronal conduction characteristics in the primary visual cortex of cats, pulse-coupled neural networks (PCNNs) can exhibit synchronous oscillation behavior, which can process digital images without training. However, according to the study of single cells in the cat primary visual cortex, when a neuron is stimulated by an external periodic signal, the interspike-interval (ISI) distributions represent a multimodal distribution. This phenomenon cannot be explained by all PCNN models. By analyzing the working mechanism of the PCNN, we present a novel neuron model of the primary visual cortex consisting of a continuous-coupled neural network (CCNN). Our model inherited the threshold exponential decay and synchronous pulse oscillation property of the original PCNN model, and it can exhibit chaotic behavior consistent with the testing results of cat primary visual cortex neurons. Therefore, our CCNN model is closer to real visual neural networks. For image segmentation tasks, the algorithm based on CCNN model has better performance than the state-of-art of visual cortex neural network model. The strength of our approach is that it helps neu-rophysiologists further understand how the primary visual cortex works and can be",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108324267",
                    "name": "Jizhao Liu"
                },
                {
                    "authorId": "1561165594",
                    "name": "Jing Lian"
                },
                {
                    "authorId": "2935810",
                    "name": "J. Sprott"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "c2fc124b05d522aaa9a0d051659b6f8dae2e789e",
            "title": "ASU-Net: U-shape adaptive scale network for mass segmentation in mammograms",
            "abstract": "U-Net is a commonly used deep learning model for mammogram segmentation. Despite outstanding overall performance in segmenting, U-Net still faces from two aspects of challenges: (1) the skip-connections in U-Net have limitations, which may not be able to effectively extract multi-scale features for breast masses with diverse shapes and sizes. (2) U-Net only merges low-level spatial information and high-level semantic information through concatenating, which neglects interdependencies between channels. To address these two problems, we propose the U-shape adaptive scale network (ASU-Net), which contains two modules: adaptive scale module (ASM) and feature refinement module (FRM). In each level of skip-connections, ASM is used to adaptively adjust the receptive fields according to the different scales of the mass, which makes the network adaptively capture multi-scale features. Besides, FRM is employed to allows the decoder to capture channel-wise dependencies, which make the network can selectively emphasize the feature representation of useful channels. Two commonly used mammogram databases including the DDSM-BCRP database and the INbreast database are used to evaluate the segmentation performance of ASU-Net. Finally, ASU-Net obtains the Dice Index (DI) of 91.41% and 93.55% in the DDSM-BCRP database and the INbreast database, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153616573",
                    "name": "Kexin Sun"
                },
                {
                    "authorId": "144775128",
                    "name": "Yuelan Xin"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                },
                {
                    "authorId": "2100398225",
                    "name": "Meng Lou"
                },
                {
                    "authorId": "9273627",
                    "name": "Yunliang Qi"
                },
                {
                    "authorId": "2108997568",
                    "name": "Jie Zhu"
                }
            ]
        },
        {
            "paperId": "c3525c1bd93382585f9e82ce4fd0408108c7c72e",
            "title": "A pulse-number-adjustable MSPCNN and its image enhancement application",
            "abstract": "Pulse-coupled neural network (PCNN) aims to control neuronal firing state automatically and complete related image processing tasks. This paper presents a pulse-number-adjustable MSPCNN model (PNA-MSPCNN) that can automatically acquire the firing times and the firing frequency of each neuron. Hereinto, synaptic weight matrix Wijkl and decay factor \u03b1 will generate an interaction value to determine the final calculation result of the internal activity U. Dynamic threshold amplitude V, step function Q, and auxiliary parameter P can precisely adjust the variation ranges of the dynamic threshold E. Additionally, we propose a low-light image enhancement method based on the above PNA-MSPCNN and a modified low-light image enhancement (LIME). The proposed LIME algorithm focuses mainly on the parameter setting method of weight matrix Wmq, which will bring further improvement of testing image contrast. Experimental results demonstrate that our proposed method achieves better low-light image enhancement performances, compared to prevalent image enhancement methods, including SSIM of 0.8725, AMBE of 0.0550, MSE of 0.0092, and PSNR of 45.7764.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3597137",
                    "name": "Jing Lian"
                },
                {
                    "authorId": "2108324267",
                    "name": "Jizhao Liu"
                },
                {
                    "authorId": "2149232984",
                    "name": "Zhen Yang"
                },
                {
                    "authorId": "9273627",
                    "name": "Yunliang Qi"
                },
                {
                    "authorId": "2143475266",
                    "name": "Huaikun Zhang"
                },
                {
                    "authorId": "2112122654",
                    "name": "Mingxuan Zhang"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "2ae7229622afce7a8117970ef8fc203254639581",
            "title": "A Novel Image-Encryption Scheme Based on a Non-Linear Cross-Coupled Hyperchaotic System with the Dynamic Correlation of Plaintext Pixels",
            "abstract": "Based on a logistic map and Feigenbaum map, we proposed a logistic Feigenbaum non-linear cross-coupled hyperchaotic map (LF-NCHM) model. Experimental verification showed that the system is a hyperchaotic system. Compared with the existing cross-coupled mapping, LF-NCHM demonstrated a wider hyperchaotic range, better ergodicity and richer dynamic behavior. A hyperchaotic sequence with the same number of image pixels was generated by LF-NCHM, and a novel image-encryption algorithm with permutation that is dynamically related to plaintext pixels was proposed. In the scrambling stage, the position of the first scrambled pixel was related to the sum of the plaintext pixel values, and the positions of the remaining scrambled pixels were related to the pixel values after the previous scrambling. The scrambling operation also had a certain diffusion effect. In the diffusion phase, using the same chaotic sequence as in the scrambling stage increased the usage rate of the hyperchaotic sequence and improved the calculation efficiency of the algorithm. A large number of experimental simulations and cryptanalyses were performed, and the results proved that the algorithm had outstanding security and extremely high encryption efficiency. In addition, LF-NCHM could effectively resist statistical analysis attacks, differential attacks and chosen-plaintext attacks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2098364792",
                    "name": "Wenjin Hou"
                },
                {
                    "authorId": "1753240",
                    "name": "Shouliang Li"
                },
                {
                    "authorId": "2153103338",
                    "name": "Jiapeng He"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "836739c3bc470ebf1e1a7dbb381940e249ec40ca",
            "title": "Target Recognition of Synthetic Aperture Radar Images Based on Two-Phase Sparse Representation",
            "abstract": "A synthetic aperture radar (SAR) target recognition method is proposed via linear representation over the global and local dictionaries. The collaborative representation is performed on the local dictionary, which comprises of training samples from a single class. Then, the reconstruction errors as for representing the test sample reflect the absolute representation capabilities of different training classes. Accordingly, the target label can be directly decided when one class achieves a notably lower reconstruction error than the others. Otherwise, several candidate classes with relatively low reconstruction errors are selected as the candidate classes to form the global dictionary, based on which the sparse representation-based classification (SRC) is performed. SRC also produces the reconstruction errors of the candidate classes, which reflect their relative representation capabilities for the test sample. As a comprehensive consideration, the reconstruction errors from the collaborative representation and SRC are fused for decision-making. Therefore, the proposed method could inherit the high efficiency of the collaborative representation. In addition, the selection of the candidate training classes also relieves the computational burden during SRC. By combining the absolute and relative representation capabilities, the final classification accuracy can also be improved. During the experimental evaluation, the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset is employed to test the proposed method under several different operating conditions. The proposed method is compared with some other SAR target recognition methods simultaneously. The results show the superior performance of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109051189",
                    "name": "Wen Li"
                },
                {
                    "authorId": "2146157783",
                    "name": "Jun Yang"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "85eb7038a2460f336d350980db8c153e568a97f9",
            "title": "PCNN Mechanism and its Parameter Settings",
            "abstract": "The pulse-coupled neural network (PCNN) model is a third-generation artificial neural network without training that uses the synchronous pulse bursts of neurons to process digital images, but the lack of in-depth theoretical research limits its extensive application. By analyzing the working mechanism of the PCNN, we present an expression for the fire-extinguishing time of neurons that fire in the second iteration and an expression for the firing time of neurons that extinguish in the second iteration. In addition, we find a phenomenon of the PCNN and name it mathematically coupled fire extinguishing. Based on the above analysis, we propose a new working mode for the PCNN, where the refiring of fire-extinguishing neurons is only allowed when all firing neurons are extinguished. We also work out the constraint conditions of the parameter settings under this mode. Furthermore, we analyze the relationship between the network parameters and mathematically coupled fire extinguishing, the coupling of neighboring neurons, and the convergence rate of the PCNN, respectively. In addition, we demonstrate the essential regularity of extinguished neuron in the PCNN and then propose an optimal parameter setting to achieve the best comprehensive performance of the PCNN.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49077273",
                    "name": "Xiangyu Deng"
                },
                {
                    "authorId": "2187715",
                    "name": "Chun-man Yan"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "f863519a04994da1c8b6b76cbcc4f449693f1df4",
            "title": "A Torus-Chaotic System and Its Pseudorandom Properties",
            "abstract": "Exploring and investigating new chaotic systems is a popular topic in nonlinear science. Although numerous chaotic systems have been introduced in the literature, few of them focus on torus-chaotic system. The aim of our short work is to widen the current knowledge of torus chaos. In this paper, a new torus-chaotic system is proposed, which has one positive Lyapunov exponent, two zero Lyapunov exponents, and two negative Lyapunov exponents. The dynamic behavior is investigated by Lyapunov exponents, bifurcations, and stability. The analysis shows that this system has an interesting route leading to chaos. Furthermore, the pseudorandom properties of output sequence are well studied and a random number generator algorithm is proposed, which has the potential of being used in several cyber security systems such as the verification code, secure QR code, and some secure communication protocols.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108324267",
                    "name": "Jizhao Liu"
                },
                {
                    "authorId": "11378321",
                    "name": "Xiangzi Zhang"
                },
                {
                    "authorId": "145542699",
                    "name": "Qingchun Zhao"
                },
                {
                    "authorId": "1561165594",
                    "name": "Jing Lian"
                },
                {
                    "authorId": "143890371",
                    "name": "Fangjun Huang"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                }
            ]
        },
        {
            "paperId": "244fb2ad025aea8a74e6f4899d480be2d10262f7",
            "title": "Speech Augmentation via Speaker-Specific Noise in Unseen Environment",
            "abstract": "Speech augmentation is a common and effective strategy to avoid overfitting and improve on the robustness of an emotion recognition model. In this paper, we investigate for the first time the intrinsic attributes in a speech signal using the multi-resolution analysis theory and the Hilbert-Huang Spectrum, with the goal of developing a robust speech augmentation approach from raw speech data. Specifically, speech decomposition in a double tree complex wavelet transform domain is realized, to obtain sub-speech signals; then, the Hilbert Spectrum using Hilbert-Huang Transform is calculated for each sub-band to capture the noise content in unseen environments with the voice restriction to 100\u22124000 Hz; finally, the speechspecific noise that varies with the speaker individual, scenarios, environment, and voice recording equipment, can be reconstructed from the top two high-frequency sub-bands to enhance the raw signal. Our proposed speech augmentation is demonstrated using five robust machine learning architectures based on the RAVDESS database, achieving up to 9.3 % higher accuracy compared to the performance on raw data for an emotion recognition task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145370048",
                    "name": "Yanan Guo"
                },
                {
                    "authorId": "143889734",
                    "name": "Ziping Zhao"
                },
                {
                    "authorId": "1756244",
                    "name": "Yide Ma"
                },
                {
                    "authorId": "145411696",
                    "name": "Bj\u00f6rn Schuller"
                }
            ]
        }
    ]
}