{
    "authorId": "38599655",
    "papers": [
        {
            "paperId": "cd77f734f0c54bccbea1b75c9458cbde121a38dc",
            "title": "CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models",
            "abstract": "Effectively using Natural Language Processing (NLP) tools in under-resourced languages requires a thorough understanding of the language itself, familiarity with the latest models and training methodologies, and technical expertise to deploy these models. This could present a significant obstacle for language community members and linguists to use NLP tools. This paper introduces the CMU Linguistic Annotation Backend, an open-source framework that simplifies model deployment and continuous human-in-the-loop fine-tuning of NLP models. CMULAB enables users to leverage the power of multilingual models to quickly adapt and extend existing tools for speech recognition, OCR, translation, and syntactic analysis to new languages, even with limited training data. We describe various tools and APIs that are currently available and how developers can easily add new models/functionality to the framework. Code is available at https://github.com/neulab/cmulab along with a live demo at https://cmulab.dev",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "7391530",
                    "name": "Shruti Rijhwani"
                },
                {
                    "authorId": "2219036626",
                    "name": "Lindia Tjuatja"
                },
                {
                    "authorId": "2294720293",
                    "name": "Robbie Jimerson"
                },
                {
                    "authorId": "2265547593",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "9b534639bcadc9ad232b338e760c523a4d74c8de",
            "title": "AUTOLEX: An Automatic Framework for Linguistic Exploration",
            "abstract": "Each language has its own complex systems of word, phrase, and sentence construction, the guiding principles of which are often summarized in grammar descriptions for the consumption of linguists or language learners. However, manual creation of such descriptions is a fraught process, as creating descriptions which describe the language in\"its own terms\"without bias or error requires both a deep understanding of the language at hand and linguistics as a whole. We propose an automatic framework AutoLEX that aims to ease linguists' discovery and extraction of concise descriptions of linguistic phenomena. Specifically, we apply this framework to extract descriptions for three phenomena: morphological agreement, case marking, and word order, across several languages. We evaluate the descriptions with the help of language experts and propose a method for automated evaluation when human evaluation is infeasible.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250894",
                    "name": "Aditi Chaudhary"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "3407646",
                    "name": "David R. Mortensen"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "714fef24b1e87fae20b1d49ab3b6a276548ae7a2",
            "title": "Reducing Confusion in Active Learning for Part-Of-Speech Tagging",
            "abstract": "Active learning (AL) uses a data selection algorithm to select useful training samples to minimize annotation cost. This is now an essential tool for building low-resource syntactic analyzers such as part-of-speech (POS) taggers. Existing AL heuristics are generally designed on the principle of selecting uncertain yet representative training instances, where annotating these instances may reduce a large number of errors. However, in an empirical study across six typologically diverse languages (German, Swedish, Galician, North Sami, Persian, and Ukrainian), we found the surprising result that even in an oracle scenario where we know the true uncertainty of predictions, these current heuristics are far from optimal. Based on this analysis, we pose the problem of AL as selecting instances that maximally reduce the confusion between particular pairs of output tags. Extensive experimentation on the aforementioned languages shows that our proposed AL strategy outperforms other AL strategies by a significant margin. We also present auxiliary results demonstrating the importance of proper calibration of models, which we ensure through cross-view training, and analysis demonstrating how our proposed strategy selects examples that more closely follow the oracle data distribution. The code is publicly released here.1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250894",
                    "name": "Aditi Chaudhary"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "de7d0c87794c3de6f8ab2c753ecc398c18c26631",
            "title": "Automatic Extraction of Rules Governing Morphological Agreement",
            "abstract": "Creating a descriptive grammar of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human- and machine-readable format. We focus on extracting rules describing agreement, a morphosyntactic phenomenon at the core of the grammars of many of the world's languages. We apply our framework to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the rules that our framework produces, which have an average accuracy of 78%. We release an interface demonstrating the extracted rules at this https URL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250894",
                    "name": "Aditi Chaudhary"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "51132476",
                    "name": "Adithya Pratapa"
                },
                {
                    "authorId": "3407646",
                    "name": "David R. Mortensen"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "145317727",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "0805cb1b26577f08f84190445992f7f0584e4742",
            "title": "OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis",
            "abstract": "The OPERA system of CMU and USC/ISI performs end-to-end information extraction from multiple media and languages (English, Russian, Ukrainian), integrates the results, builds Knowledge Bases about the domain, and does hypothesis creation and reasoning to answer questions. ",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144547315",
                    "name": "E. Hovy"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                },
                {
                    "authorId": "2284176",
                    "name": "Hans Chalupsky"
                },
                {
                    "authorId": "145001267",
                    "name": "A. Gershman"
                },
                {
                    "authorId": "7661726",
                    "name": "Alexander Hauptmann"
                },
                {
                    "authorId": "1740721",
                    "name": "Florian Metze"
                },
                {
                    "authorId": "1706595",
                    "name": "T. Mitamura"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "1741515",
                    "name": "Ankit Dangi"
                },
                {
                    "authorId": "51250894",
                    "name": "Aditi Chaudhary"
                },
                {
                    "authorId": "2135112672",
                    "name": "Xianyang Chen"
                },
                {
                    "authorId": "97791350",
                    "name": "Xiang Kong"
                },
                {
                    "authorId": "1410241246",
                    "name": "Bernie Huang"
                },
                {
                    "authorId": "34777258",
                    "name": "Salvador Medina"
                },
                {
                    "authorId": "2109279237",
                    "name": "H. Liu"
                },
                {
                    "authorId": "2378954",
                    "name": "Xuezhe Ma"
                },
                {
                    "authorId": "1410648718",
                    "name": "Maria Ryskina"
                },
                {
                    "authorId": "2075461978",
                    "name": "Ramon Sanabria"
                },
                {
                    "authorId": "2126048085",
                    "name": "Varun Gangal"
                }
            ]
        },
        {
            "paperId": "ea77b71385648f5c6ea533a0e3685f0e76302eba",
            "title": "A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers",
            "abstract": "Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts of labeled data, making them challenging to extend to new, lower-resourced languages. However, there are now many proposed solutions to this problem involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active learning, which efficiently selects effective training data based on model predictions. In this paper, we ask the question: given this recent progress, and some amount of human annotation, what is the most effective method for efficiently creating high-quality entity recognizers in under-resourced languages? Based on extensive experimentation using both simulated and real human annotation, we settle on a recipe of starting with a cross-lingual transferred model, then performing targeted annotation of only uncertain entity spans in the target language, minimizing annotator effort. Results demonstrate that cross-lingual transfer is a powerful tool when very little data can be annotated, but an entity-targeted annotation strategy can achieve competitive accuracy quickly, with just one-tenth of training data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250894",
                    "name": "Aditi Chaudhary"
                },
                {
                    "authorId": "20467900",
                    "name": "Jiateng Xie"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                }
            ]
        },
        {
            "paperId": "ece62ada00cef99d9fc7a60e7d4b773f6d87c8f9",
            "title": "The ARIEL-CMU Systems for LoReHLT18",
            "abstract": "This paper describes the ARIEL-CMU submissions to the Low Resource Human Language Technologies (LoReHLT) 2018 evaluations for the tasks Machine Translation (MT), Entity Discovery and Linking (EDL), and detection of Situation Frames in Text and Speech (SF Text and Speech).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250894",
                    "name": "Aditi Chaudhary"
                },
                {
                    "authorId": "35186886",
                    "name": "Siddharth Dalmia"
                },
                {
                    "authorId": "145919378",
                    "name": "Junjie Hu"
                },
                {
                    "authorId": "47058260",
                    "name": "Xinjian Li"
                },
                {
                    "authorId": "144633696",
                    "name": "Austin Matthews"
                },
                {
                    "authorId": "3456073",
                    "name": "Aldrian Obaja Muis"
                },
                {
                    "authorId": "145671279",
                    "name": "Naoki Otani"
                },
                {
                    "authorId": "7391530",
                    "name": "Shruti Rijhwani"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "47963068",
                    "name": "Nidhi Vyas"
                },
                {
                    "authorId": null,
                    "name": "Xinyi Wang"
                },
                {
                    "authorId": "20467900",
                    "name": "Jiateng Xie"
                },
                {
                    "authorId": "8233965",
                    "name": "Ruochen Xu"
                },
                {
                    "authorId": "2384711",
                    "name": "Chunting Zhou"
                },
                {
                    "authorId": "25707161",
                    "name": "Peter J. Jansen"
                },
                {
                    "authorId": "35729970",
                    "name": "Yiming Yang"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                },
                {
                    "authorId": "1740721",
                    "name": "Florian Metze"
                },
                {
                    "authorId": "1706595",
                    "name": "T. Mitamura"
                },
                {
                    "authorId": "3407646",
                    "name": "David R. Mortensen"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                },
                {
                    "authorId": "144547315",
                    "name": "E. Hovy"
                },
                {
                    "authorId": "1690706",
                    "name": "A. Black"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                },
                {
                    "authorId": "2429228",
                    "name": "Graham Horwood"
                },
                {
                    "authorId": "41123680",
                    "name": "Shabnam Tafreshi"
                },
                {
                    "authorId": "1700007",
                    "name": "Mona T. Diab"
                },
                {
                    "authorId": "2793610",
                    "name": "Efsun Sarioglu Kayi"
                },
                {
                    "authorId": "2881964",
                    "name": "N. Farra"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "6dfecb5915e8b10841abe224c5361bbda7100637",
            "title": "Parser combinators for Tigrinya and Oromo morphology",
            "abstract": "We present rule-based morphological parsers in the Tigrinya and Oromo languages, based on a parser-combinator rather than finite-state paradigm. This paradigm allows rapid development and ease of integration with other systems, although at the cost of non-optimal theoretical efficiency. These parsers produce multiple output representations simultaneously, including lemmatization, morphological segmentation, and an English word-for-word gloss, and we evaluate these representations as input for entity detection and linking and humanitarian need detection",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3070462",
                    "name": "Patrick Littell"
                },
                {
                    "authorId": "145534175",
                    "name": "R. Thomas McCoy"
                },
                {
                    "authorId": "38187902",
                    "name": "Na-Rae Han"
                },
                {
                    "authorId": "7391530",
                    "name": "Shruti Rijhwani"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "3407646",
                    "name": "David R. Mortensen"
                },
                {
                    "authorId": "1706595",
                    "name": "T. Mitamura"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                }
            ]
        },
        {
            "paperId": "b3f94c2869de7d469886ea1c4428b2a691ce5241",
            "title": "Semi-supervised training in low-resource ASR and KWS",
            "abstract": "In particular for \u201clow resource\u201d Keyword Search (KWS) and Speech-to-Text (STT) tasks, more untranscribed test data may be available than training data. Several approaches have been proposed to make this data useful during system development, even when initial systems have Word Error Rates (WER) above 70%. In this paper, we present a set of experiments on low-resource languages in telephony speech quality in Assamese, Bengali, Lao, Haitian, Zulu, and Tamil, demonstrating the impact that such techniques can have, in particular learning robust bottle-neck features on the test data. In the case of Tamil, when significantly more test data than training data is available, we integrated semi-supervised training and speaker adaptation on the test data, and achieved significant additional improvements in STT and KWS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1740721",
                    "name": "Florian Metze"
                },
                {
                    "authorId": "36881920",
                    "name": "Ankur Gandhe"
                },
                {
                    "authorId": "37467623",
                    "name": "Yajie Miao"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "2118375819",
                    "name": "Yun Wang"
                },
                {
                    "authorId": "2118920033",
                    "name": "Di Xu"
                },
                {
                    "authorId": "2144615103",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2116298763",
                    "name": "Jungsuk Kim"
                },
                {
                    "authorId": "1765892",
                    "name": "Ian Lane"
                },
                {
                    "authorId": "2756887",
                    "name": "Wonkyum Lee"
                },
                {
                    "authorId": "11126660",
                    "name": "Sebastian St\u00fcker"
                },
                {
                    "authorId": "48588187",
                    "name": "Markus M\u00fcller"
                }
            ]
        },
        {
            "paperId": "d7a314acae5777d5e27ca6ddf84869a91b5e0ca5",
            "title": "Multilingual deep bottle neck features: a study on language selection and training techniques",
            "abstract": "Previous work has shown that training the neural networks for bottle neck feature extraction in a multilingual way can lead to improvements in word error rate and average term weighted value in a telephone key word search task. In this work we conduct a systematic study on a) which multilingual training strategy to employ, b) the effect of language selection and amount of multilingual training data used and c) how to \ufb01nd a suitable combination for languages. We conducted our exper-iment on the key word search task and the languages of the IARPA BABEL program. In a \ufb01rst step, we assessed the performance of a single language out of all available languages in combination with the target language. Based on these re-sults, we then combined a multitude of languages. We also examined the in\ufb02uence of the amount of training data per language, as well as different techniques for combining the languages during network training. Our experiments show that data from arbitrary additional languages does not necessarily increase the performance of a system. But when combining a suitable set of languages, a signi\ufb01cant gain in performance can be achieved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48588187",
                    "name": "Markus M\u00fcller"
                },
                {
                    "authorId": "11126660",
                    "name": "Sebastian St\u00fcker"
                },
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "1740721",
                    "name": "Florian Metze"
                },
                {
                    "authorId": "1724972",
                    "name": "A. Waibel"
                }
            ]
        }
    ]
}