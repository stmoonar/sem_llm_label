{
    "authorId": "2297955888",
    "papers": [
        {
            "paperId": "647a42d78e5bd405014a8c878e37fb7b2da8eaa6",
            "title": "Graph Machine Learning in the Era of Large Language Models (LLMs)",
            "abstract": "Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML's generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2291324376",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2266567589",
                    "name": "Shijie Wang"
                },
                {
                    "authorId": "2298085002",
                    "name": "Jiani Huang"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "2298357027",
                    "name": "Yu Song"
                },
                {
                    "authorId": "2297995979",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2298005501",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2272987756",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "2297846971",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2297955888",
                    "name": "Qing Li"
                }
            ]
        },
        {
            "paperId": "eb9c4a07a336e8deefe7b399c550d3af0241238e",
            "title": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
            "abstract": "As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations, such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the generation quality of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: architectures, training strategies, and applications. As the preliminary knowledge, we briefly introduce the foundations and recent advances of LLMs. Then, to illustrate the practical significance of RAG for LLMs, we systematically review mainstream relevant work by their architectures, training strategies, and application areas, detailing specifically the challenges of each and the corresponding capabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2291324376",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2301103404",
                    "name": "Yujuan Ding"
                },
                {
                    "authorId": "2301015154",
                    "name": "Liang-bo Ning"
                },
                {
                    "authorId": "2266567589",
                    "name": "Shijie Wang"
                },
                {
                    "authorId": "2301167804",
                    "name": "Hengyun Li"
                },
                {
                    "authorId": "2297846971",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2279753672",
                    "name": "Tat-Seng Chua"
                },
                {
                    "authorId": "2297955888",
                    "name": "Qing Li"
                }
            ]
        },
        {
            "paperId": "85bbc8af01084d2328c49cb3c70241c76e3ef4d5",
            "title": "Embedding in Recommender Systems: A Survey",
            "abstract": "Recommender systems have become an essential component of many online platforms, providing personalized recommendations to users. A crucial aspect is embedding techniques that coverts the high-dimensional discrete features, such as user and item IDs, into low-dimensional continuous vectors and can enhance the recommendation performance. Applying embedding techniques captures complex entity relationships and has spurred substantial research. In this survey, we provide an overview of the recent literature on embedding techniques in recommender systems. This survey covers embedding methods like collaborative filtering, self-supervised learning, and graph-based techniques. Collaborative filtering generates embeddings capturing user-item preferences, excelling in sparse data. Self-supervised methods leverage contrastive or generative learning for various tasks. Graph-based techniques like node2vec exploit complex relationships in network-rich environments. Addressing the scalability challenges inherent to embedding methods, our survey delves into innovative directions within the field of recommendation systems. These directions aim to enhance performance and reduce computational complexity, paving the way for improved recommender systems. Among these innovative approaches, we will introduce Auto Machine Learning (AutoML), hash techniques, and quantization techniques in this survey. We discuss various architectures and techniques and highlight the challenges and future directions in these aspects. This survey aims to provide a comprehensive overview of the state-of-the-art in this rapidly evolving field and serve as a useful resource for researchers and practitioners working in the area of recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2262447995",
                    "name": "Xinjian Zhao"
                },
                {
                    "authorId": "2262510496",
                    "name": "Jiansheng Li"
                },
                {
                    "authorId": "2262865343",
                    "name": "Shucheng Zhou"
                },
                {
                    "authorId": "2240617631",
                    "name": "Dawei Yin"
                },
                {
                    "authorId": "2297955888",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2264097358",
                    "name": "Ruocheng Guo"
                }
            ]
        }
    ]
}