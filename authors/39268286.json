{
    "authorId": "39268286",
    "papers": [
        {
            "paperId": "097368d420604dc33de6361c9353f62d607a967e",
            "title": "Semantic Image Segmentation: Two Decades of Research",
            "abstract": "Semantic image segmentation (SiS) plays a fundamental role in a broad variety of computer vision applications, providing key information for the global understanding of an image. This survey is an effort to summarize two decades of research in the field of SiS, where we propose a literature review of solutions starting from early historical methods followed by an overview of more recent deep learning methods including the latest trend of using transformers. We complement the review by discussing particular cases of the weak supervision and side machine learning techniques that can be used to improve the semantic segmentation such as curriculum, incremental or self-supervised learning. State-of-the-art SiS models rely on a large amount of annotated samples, which are more expensive to obtain than labels for tasks such as image classification. Since unlabeled data is instead significantly cheaper to obtain, it is not surprising that Unsupervised Domain Adaptation (UDA) reached a broad success within the semantic segmentation community. Therefore, a second core contribution of this book is to summarize five years of a rapidly growing field, Domain Adaptation for Semantic Image Segmentation (DASiS) which embraces the importance of semantic segmentation itself and a critical need of adapting segmentation models to new environments. In addition to providing a comprehensive survey on DASiS techniques, we unveil also newer trends such as multi-domain learning, domain generalization, domain incremental learning, test-time adaptation and source-free domain adaptation. Finally, we conclude this survey by describing datasets and benchmarks most widely used in SiS and DASiS and briefly discuss related tasks such as instance and panoptic image segmentation, as well as applications such as medical image segmentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1808423",
                    "name": "G. Csurka"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "1729294",
                    "name": "Boris Chidlovskii"
                }
            ]
        },
        {
            "paperId": "afbdb62263b7ff5d9d62e1d80e5237825db9d09a",
            "title": "RaSP: Relation-aware Semantic Prior for Weakly Supervised Incremental Segmentation",
            "abstract": "Class-incremental semantic image segmentation assumes multiple model updates, each enriching the model to segment new categories. This is typically carried out by providing expensive pixel-level annotations to the training algorithm for all new objects, limiting the adoption of such methods in practical applications. Approaches that solely require image-level labels offer an attractive alternative, yet, such coarse annotations lack precise information about the location and boundary of the new objects. In this paper we argue that, since classes represent not just indices but semantic entities, the conceptual relationships between them can provide valuable information that should be leveraged. We propose a weakly supervised approach that exploits such semantic relations to transfer objectness prior from the previously learned classes into the new ones, complementing the supervisory signal from image-level labels. We validate our approach on a number of continual learning tasks, and show how even a simple pairwise interaction between classes can significantly improve the segmentation mask quality of both old and new classes. We show these conclusions still hold for longer and, hence, more realistic sequences of tasks and for a challenging few-shot scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2933549",
                    "name": "Subhankar Roy"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "1808423",
                    "name": "G. Csurka"
                },
                {
                    "authorId": "2295553",
                    "name": "Diane Larlus"
                }
            ]
        },
        {
            "paperId": "e925e0211bc260dad9946592ee1698be279f26d9",
            "title": "Reliability in Semantic Segmentation: Are we on the Right Track?",
            "abstract": "Motivated by the increasing popularity of transformers in computer vision, in recent times there has been a rapid development of novel architectures. While in-domain performance follows a constant, upward trend, properties like robustness or uncertainty estimation are less explored-leaving doubts about advances in model reliability. Studies along these axes exist, but they are mainly limited to classification models. In contrast, we carry out a study on semantic segmentation, a relevant task for many real-world applications where model reliability is paramount. We analyze a broad variety of models, spanning from older ResNet-based architectures to novel transformers and assess their reliability based on four metrics: robustness, calibration, misclassification detection and out-of-distribution (OOD) detection. We find that while recent models are significantly more robust, they are not overall more reliable in terms of uncertainty estimation. We further explore methods that can come to the rescue and show that improving calibration can also help with other uncertainty metrics such as misclassification or OOD detection. This is the first study on modern segmentation models focused on both robustness and uncertainty estimation and we hope it will help practitioners and researchers interested in this fundamental vision task11Code available at https://github.com/naver/relis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66320600",
                    "name": "Pau de Jorge"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "143635540",
                    "name": "Philip H. S. Torr"
                },
                {
                    "authorId": "3321919",
                    "name": "Gr\u00e9gory Rogez"
                }
            ]
        },
        {
            "paperId": "de12ecd97131c51476e0628274e5a0f5ee2474cc",
            "title": "On the Road to Online Adaptation for Semantic Image Segmentation",
            "abstract": "We propose a new problem formulation and a corresponding evaluation framework to advance research on unsupervised domain adaptation for semantic image segmentation. The overall goal is fostering the development of adaptive learning systems that will continuously learn, without supervision, in ever-changing environments. Typical protocols that study adaptation algorithms for segmentation models are limited to few domains, adaptation happens offline, and human intervention is generally required, at least to annotate data for hyperparameter tuning. We argue that such constraints are incompatible with algorithms that can continuously adapt to different real-world situations. To address this, we propose a protocol where models need to learn online, from sequences of temporally correlated images, requiring continuous, frame-by-frame adaptation. We accompany this new protocol with a variety of baselines to tackle the proposed formulation, as well as an extensive analysis of their behaviors, which can serve as a starting point for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "66320600",
                    "name": "Pau de Jorge"
                },
                {
                    "authorId": "2295553",
                    "name": "Diane Larlus"
                },
                {
                    "authorId": "1808423",
                    "name": "G. Csurka"
                }
            ]
        },
        {
            "paperId": "fa1f3bf928e435a6094b0b00008668a4b4a7294b",
            "title": "Make Some Noise: Reliable and Efficient Single-Step Adversarial Training",
            "abstract": "Recently, Wong et al. showed that adversarial training with single-step FGSM leads to a characteristic failure mode named Catastrophic Overfitting (CO), in which a model becomes suddenly vulnerable to multi-step attacks. Experimentally they showed that simply adding a random perturbation prior to FGSM (RS-FGSM) could prevent CO. However, Andriushchenko and Flammarion observed that RS-FGSM still leads to CO for larger perturbations, and proposed a computationally expensive regularizer (GradAlign) to avoid it. In this work, we methodically revisit the role of noise and clipping in single-step adversarial training. Contrary to previous intuitions, we find that using a stronger noise around the clean sample combined with \\textit{not clipping} is highly effective in avoiding CO for large perturbation radii. We then propose Noise-FGSM (N-FGSM) that, while providing the benefits of single-step adversarial training, does not suffer from CO. Empirical analyses on a large suite of experiments show that N-FGSM is able to match or surpass the performance of previous state-of-the-art GradAlign, while achieving 3x speed-up. Code can be found in https://github.com/pdejorge/N-FGSM",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66320600",
                    "name": "Pau de Jorge"
                },
                {
                    "authorId": "2314778",
                    "name": "Adel Bibi"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "3494481",
                    "name": "Amartya Sanyal"
                },
                {
                    "authorId": "143635540",
                    "name": "Philip H. S. Torr"
                },
                {
                    "authorId": "3321919",
                    "name": "Gr\u00e9gory Rogez"
                },
                {
                    "authorId": "144679302",
                    "name": "P. Dokania"
                }
            ]
        },
        {
            "paperId": "4e3be18cba72d7cc7ad08d2efaf11744efcafae1",
            "title": "Automatic Feature Extraction for Heartbeat Anomaly Detection",
            "abstract": "We focus on automatic feature extraction for raw audio heartbeat sounds, aimed at anomaly detection applications in healthcare. We learn features with the help of an autoencoder composed by a 1D non-causal convolutional encoder and a WaveNet decoder trained with a modified objective based on variational inference, employing the Maximum Mean Discrepancy (MMD). Moreover we model the latent distribution using a Gaussian chain graphical model to capture temporal correlations which characterize the encoded signals. After training the autoencoder on the reconstruction task in a unsupervised manner, we test the significance of the learned latent representations by training an SVM to predict anomalies. We evaluate the methods on a problem proposed by the PASCAL Classifying Heart Sounds Challenge and we compare with results in the literature.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2051502958",
                    "name": "Robert-George Colt"
                },
                {
                    "authorId": "2051522123",
                    "name": "Csongor-Huba V'arady"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "3085319",
                    "name": "Luigi Malag\u00f2"
                }
            ]
        },
        {
            "paperId": "abb79bf15896e0922427ca9d35b0e36ec6718e6e",
            "title": "Unsupervised Domain Adaptation for Semantic Image Segmentation: a Comprehensive Survey",
            "abstract": "Semantic segmentation plays a fundamental role in a broad variety of computer vision applications, providing key information for the global understanding of an image. Yet, the state-of-the-art models rely on large amount of annotated samples, which are more expensive to obtain than in tasks such as image classification. Since unlabelled data is instead significantly cheaper to obtain, it is not surprising that Unsupervised Domain Adaptation reached a broad success within the semantic segmentation community. This survey is an effort to summarize five years of this incredibly rapidly growing field, which embraces the importance of semantic segmentation itself and a critical need of adapting segmentation models to new environments. We present the most important semantic segmentation methods; we provide a comprehensive survey on domain adaptation techniques for semantic segmentation; we unveil newer trends such as multi-domain learning, domain generalization, test-time adaptation or source-free domain adaptation; we conclude this survey by describing datasets and benchmarks most widely used in semantic segmentation research. We hope that this survey will provide researchers across academia and industry with a comprehensive reference guide and will help them in fostering new research directions in the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1808423",
                    "name": "G. Csurka"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "1729294",
                    "name": "Boris Chidlovskii"
                }
            ]
        },
        {
            "paperId": "d1b10e49ba31c1b4287f666836e4014a04befee6",
            "title": "Changing the Geometry of Representations: \u03b1-Embeddings for NLP Tasks",
            "abstract": "Word embeddings based on a conditional model are commonly used in Natural Language Processing (NLP) tasks to embed the words of a dictionary in a low dimensional linear space. Their computation is based on the maximization of the likelihood of a conditional probability distribution for each word of the dictionary. These distributions form a Riemannian statistical manifold, where word embeddings can be interpreted as vectors in the tangent space of a specific reference measure on the manifold. A novel family of word embeddings, called \u03b1-embeddings have been recently introduced as deriving from the geometrical deformation of the simplex of probabilities through a parameter \u03b1, using notions from Information Geometry. After introducing the \u03b1-embeddings, we show how the deformation of the simplex, controlled by \u03b1, provides an extra handle to increase the performances of several intrinsic and extrinsic tasks in NLP. We test the \u03b1-embeddings on different tasks with models of increasing complexity, showing that the advantages associated with the use of \u03b1-embeddings are present also for models with a large number of parameters. Finally, we show that tuning \u03b1 allows for higher performances compared to the use of larger models in which additionally a transformation of the embeddings is learned during training, as experimentally verified in attention models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "2051842917",
                    "name": "Uddhipan Thakur"
                },
                {
                    "authorId": "3085319",
                    "name": "Luigi Malag\u00f2"
                }
            ]
        },
        {
            "paperId": "0a1c405edea5a1c1d7c151d83a914b10e70b2293",
            "title": "Evaluating Natural Alpha Embeddings on Intrinsic and Extrinsic Tasks",
            "abstract": "Skip-Gram is a simple, but effective, model to learn a word embedding mapping by estimating a conditional probability distribution for each word of the dictionary. In the context of Information Geometry, these distributions form a Riemannian statistical manifold, where word embeddings are interpreted as vectors in the tangent bundle of the manifold. In this paper we show how the choice of the geometry on the manifold allows impacts on the performances both on intrinsic and extrinsic tasks, in function of a deformation parameter alpha.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "3085319",
                    "name": "Luigi Malag\u00f2"
                }
            ]
        },
        {
            "paperId": "14cfcc3f84a7b7470641026c1866ca73b470f43f",
            "title": "Natural Wake-Sleep Algorithm",
            "abstract": "The benefits of using the natural gradient are well known in a wide range of optimization problems. However, for the training of common neural networks the resulting increase in computational complexity sets a limitation to its practical application. Helmholtz Machines are a particular type of generative model composed of two Sigmoid Belief Networks (SBNs), acting as an encoder and a decoder, commonly trained using the Wake-Sleep (WS) algorithm and its reweighted version RWS. For SBNs, it has been shown how the locality of the connections in the graphical structure induces sparsity in the Fisher information matrix. The resulting block diagonal structure can be efficiently exploited to reduce the computational complexity of the Fisher matrix inversion and thus compute the natural gradient exactly, without the need of approximations. We present a geometric adaptation of well-known methods from the literature, introducing the Natural Wake-Sleep (NWS) and the Natural Reweighted Wake-Sleep (NRWS) algorithms. We present an experimental analysis of the novel geometrical algorithms based on the convergence speed and the value of the log-likelihood, both with respect to the number of iterations and the time complexity and demonstrating improvements on these aspects over their respective non-geometric baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "121550743",
                    "name": "Csongor V\u00e1rady"
                },
                {
                    "authorId": "39268286",
                    "name": "Riccardo Volpi"
                },
                {
                    "authorId": "3085319",
                    "name": "Luigi Malag\u00f2"
                },
                {
                    "authorId": "2850091",
                    "name": "N. Ay"
                }
            ]
        }
    ]
}