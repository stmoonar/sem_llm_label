{
    "authorId": "2881417",
    "papers": [
        {
            "paperId": "3b81e878046189f1e4577f03d8f2f33338c8d481",
            "title": "A Novel Method to Design Steerable Differential Beamformer Using Linear Acoustics Vector Sensor Array",
            "abstract": "Differential beamforming techniques have gained significant attention due to their frequency-independent beampatterns, applicability for small apertures, and super-directivity. It is commonly known that the main lobe of a beam pattern based on a linear array is typically aligned with the end-fire direction. However, in some application scenarios, aligning the main lobe in the end-fire direction may not meet the actual requirements. This article focuses on studying the steering problem of differential beamformers based on linear acoustics vector sensor arrays (LAVSs). We propose a steerable differential beamformer for LAVSs, which addresses the problem of non-steerable beam patterns of linear arrays. Our approach involves approximating the beam pattern using a series expansion of the weighted steering vector to achieve frequency-independent differential directivity. The major contributions of this article include, but are not limited to, the following: First, we derive the first-order to third-order differential directivity based on the acoustics vector sensor (AVS) signal model, and obtain the weights of the corresponding channels using the least squares method. Second, we provide a theoretical analysis of the steering differential beamformer, demonstrating that the maximum directivity factor (DF) is a function of the steering angle. Finally, we conduct simulation experiments to validate the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144180429",
                    "name": "F. Chen"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "2185344138",
                    "name": "Yapeng Mao"
                },
                {
                    "authorId": "7396392",
                    "name": "Desen Yang"
                },
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "48377008",
                    "name": "Jie Shi"
                },
                {
                    "authorId": "32775916",
                    "name": "Shiqi Mo"
                },
                {
                    "authorId": "2124615025",
                    "name": "Gui Chenyang"
                },
                {
                    "authorId": "2144291935",
                    "name": "Song Li"
                }
            ]
        },
        {
            "paperId": "5bb62430ba204367c2e5de903ea459e5bbf95dcc",
            "title": "Inspired by Physical Intelligence of an Elephant Trunk: Biomimetic Soft Robot With Pre-Programmable Localized Stiffness",
            "abstract": "Soft robots exhibit promising dexterity and adaptability for manipulation because of their high compliance. However, the existing soft robots with invariant stiffness hardly interact with cluttered environments with varying curvatures. In this study, inspired by the maneuverability of an elephant trunk, we proposed a pneumatic soft robot comprised of soft pneumatic actuators and interference plates. By implementing interference plates in diverse patterns, the localized stiffness of our robot can be pre-programmed. To quantify the availability of localized stiffness regulation, we constructed four typical assembly fashions strengthened by the interference plates, and predicted robot profiles by simulation that was validated via experiments. We demonstrated the application of our soft robot with localized stiffness regulation in a variety of scenarios demanding specific configurations. Our design paradigm not only uncovers the potential methodology for regulating robotic curvature precisely, but may inspire next-generation soft robots integrating specified structural and material characteristics learned from natural intelligence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "2211720043",
                    "name": "Xiaodong Chen"
                },
                {
                    "authorId": "2159190222",
                    "name": "Jie Zhang"
                },
                {
                    "authorId": "2211778709",
                    "name": "Zekai Xie"
                },
                {
                    "authorId": "2143940462",
                    "name": "Jianing Wu"
                },
                {
                    "authorId": "2144165979",
                    "name": "Jinxiu Zhang"
                }
            ]
        },
        {
            "paperId": "baead4b50b13e38164a65de3df984f1da5fc6d9b",
            "title": "SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital Pathology",
            "abstract": "Semantic segmentations of pathological entities have crucial clinical value in computational pathology workflows. Foundation models, such as the Segment Anything Model (SAM), have been recently proposed for universal use in segmentation tasks. SAM shows remarkable promise in instance segmentation on natural images. However, the applicability of SAM to computational pathology tasks is limited due to the following factors: (1) lack of comprehensive pathology datasets used in SAM training and (2) the design of SAM is not inherently optimized for semantic segmentation tasks. In this work, we adapt SAM for semantic segmentation by introducing trainable class prompts, followed by further enhancements through the incorporation of a pathology encoder, specifically a pathology foundation model. Our framework, SAM-Path enhances SAM's ability to conduct semantic segmentation in digital pathology without human input prompts. Through experiments on two public pathology datasets, the BCSS and the CRAG datasets, we demonstrate that the fine-tuning with trainable class prompts outperforms vanilla SAM with manual prompts and post-processing by 27.52% in Dice score and 71.63% in IOU. On these two datasets, the proposed additional pathology foundation model further achieves a relative improvement of 5.07% to 5.12% in Dice score and 4.50% to 8.48% in IOU.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2116207652",
                    "name": "Jingwei Zhang"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "1818709358",
                    "name": "S. Kapse"
                },
                {
                    "authorId": "1735710",
                    "name": "J. Saltz"
                },
                {
                    "authorId": "1893915",
                    "name": "M. Vakalopoulou"
                },
                {
                    "authorId": "39017169",
                    "name": "P. Prasanna"
                },
                {
                    "authorId": "48801624",
                    "name": "D. Samaras"
                }
            ]
        },
        {
            "paperId": "c7e7c5aed74a2c11083e4c42ddbea82d82198725",
            "title": "An Ensemble Learning Approach for Exercise Detection in Type 1 Diabetes Patients",
            "abstract": "Type 1 diabetes is a serious disease in which individuals are unable to regulate their blood glucose levels, leading to various medical complications. Artificial pancreas (AP) systems have been developed as a solution for type 1 diabetic patients to mimic the behavior of the pancreas and regulate blood glucose levels. However, current AP systems lack detection capabilities for exercise-induced glucose intake, which can last up to 4 to 8 hours. This incapability can lead to hypoglycemia, which if left untreated, could have serious consequences, including death. Existing exercise detection methods are either limited to single sensor data or use inaccurate models for exercise detection, making them less effective in practice. In this work, we propose an ensemble learning framework that combines a data-driven physiological model and a Siamese network to leverage multiple physiological signal streams for exercise detection with high accuracy. To evaluate the effectiveness of our proposed approach, we utilized a public dataset with 12 diabetic patients collected from an 8-week clinical trial. Our approach achieves a true positive rate for exercise detection of 86.4% and a true negative rate of 99.1%, outperforming state-of-the-art solutions.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "2546272",
                    "name": "Hongkai Chen"
                },
                {
                    "authorId": "2115275445",
                    "name": "Shan-Shan Lin"
                }
            ]
        },
        {
            "paperId": "d7b84faaca6ea954240511e07222ddb59e7d6aad",
            "title": "Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning",
            "abstract": "Whole slide image (WSI) classification is a critical task in computational pathology, requiring the processing of gigapixel-sized images, which is challenging for current deep-learning methods. Current state of the art methods are based on multi-instance learning schemes (MIL), which usually rely on pretrained features to represent the instances. Due to the lack of task-specific annotated data, these features are either obtained from well-established backbones on natural images, or, more recently from self-supervised models pretrained on histopathology. However, both approaches yield task-agnostic features, resulting in performance loss compared to the appropriate task-related supervision, if available. In this paper, we show that when task-specific annotations are limited, we can inject such supervision into downstream task training, to reduce the gap between fully task-tuned and task agnostic features. We propose Prompt-MIL, an MIL framework that integrates prompts into WSI classification. Prompt-MIL adopts a prompt tuning mechanism, where only a small fraction of parameters calibrates the pretrained features to encode task-specific information, rather than the conventional full fine-tuning approaches. Extensive experiments on three WSI datasets, TCGA-BRCA, TCGA-CRC, and BRIGHT, demonstrate the superiority of Prompt-MIL over conventional MIL methods, achieving a relative improvement of 1.49%-4.03% in accuracy and 0.25%-8.97% in AUROC while using fewer than 0.3% additional parameters. Compared to conventional full fine-tuning approaches, we fine-tune less than 1.3% of the parameters, yet achieve a relative improvement of 1.29%-13.61% in accuracy and 3.22%-27.18% in AUROC and reduce GPU memory consumption by 38%-45% while training 21%-27% faster. Our code is available at https://github.com/cvlab-stonybrook/PromptMIL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116207652",
                    "name": "Jingwei Zhang"
                },
                {
                    "authorId": "1818709358",
                    "name": "S. Kapse"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "145391047",
                    "name": "P. Prasanna"
                },
                {
                    "authorId": "1735710",
                    "name": "J. Saltz"
                },
                {
                    "authorId": "1893915",
                    "name": "M. Vakalopoulou"
                },
                {
                    "authorId": "145654220",
                    "name": "D. Samaras"
                }
            ]
        },
        {
            "paperId": "2c745db3bc8e5637a4dc2af4f0813245525bfb3f",
            "title": "Visual Attention Analysis Of Pathologists Examining Whole Slide Images Of Prostate Cancer",
            "abstract": "We study the attention of pathologists as they examine whole-slide images (WSIs) of prostate cancer tissue using a digital microscope. To the best of our knowledge, our study is the first to report in detail how pathologists navigate WSIs of prostate cancer as they accumulate information for their diagnoses. We collected slide navigation data (i.e., viewport location, magnification level, and time) from 13 pathologists in 2 groups (5 genitourinary (GU) specialists and 8 general pathologists) and generated visual attention heatmaps and scanpaths. Each pathologist examined five WSIs from the TCGA PRAD dataset, which were selected by a GU pathology specialist. We examined and analyzed the distributions of visual attention for each group of pathologists after each WSI was examined. To quantify the relationship between a pathologist\u2019s attention and evidence for cancer in the WSI, we obtained tumor annotations from a genitourinary specialist. We used these annotations to compute the overlap between the distribution of visual attention and annotated tumor region to identify strong correlations. Motivated by this analysis, we trained a deep learning model to predict visual attention on unseen WSIs. We find that the attention heatmaps predicted by our model correlate quite well with the ground truth attention heatmap and tumor annotations on a test set of 17 WSIs by using various spatial and temporal evaluation metrics.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "31607543",
                    "name": "Souradeep Chakraborty"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "50517594",
                    "name": "Rajarsi R. Gupta"
                },
                {
                    "authorId": "143832028",
                    "name": "B. Knudsen"
                },
                {
                    "authorId": "1696991",
                    "name": "G. Zelinsky"
                },
                {
                    "authorId": "1735710",
                    "name": "J. Saltz"
                },
                {
                    "authorId": "145654220",
                    "name": "D. Samaras"
                }
            ]
        },
        {
            "paperId": "41feace950628bc0dcd00f3aaa35dae6725dd104",
            "title": "Learning From Documents in the Wild to Improve Document Unwarping",
            "abstract": "Document image unwarping is important for document digitization and analysis. The state-of-the-art approach relies on purely synthetic data to train deep networks for unwarping. As a result, the trained networks have generalization limitations when testing on real-world images, often yielding unsatisfying results. In this work, we propose to improve document unwarping performance by incorporating real-world images in training. We collected Document-in-the-Wild (DIW) dataset contains 5000 captured document images with large diversities in content, shape, and capturing environment. We annotate the boundaries of all DIW images and use them for weakly supervised learning. We propose a novel network architecture, PaperEdge, to train with a hybrid of synthetic and real document images. Additionally, we identify and analyze the flaws of popular evaluation metrics, e.g., MS-SSIM and Local Distortion (LD), for document unwarping and propose a more robust and reliable error metric called Aligned Distortion (AD). Training with a combination of synthetic and real-world document images, we demonstrate state-of-the-art performance on popular benchmarks with comprehensive quantitative evaluations and ablation studies. Code and data are available at https://github.com/cvlab-stonybrook/PaperEdge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "2116118411",
                    "name": "Sagnik Das"
                },
                {
                    "authorId": "2496409",
                    "name": "Zhixin Shu"
                },
                {
                    "authorId": "145654220",
                    "name": "D. Samaras"
                }
            ]
        },
        {
            "paperId": "57b8ff52bf3598e948457343b7c7d7832d925b43",
            "title": "Preliminary Estimation of the Friction between Force-sensing Forceps and Cornea",
            "abstract": "Continuous curvilinear capsulorhexis (CCC) is a delicate ophthalmic procedure that may benefit from robot technology. In CCC, surgeons make an incision in the cornea, insert forceps into the anterior segment through the incision, and peel the anterior lens capsule (ALC) from the lens. The absence of perception of axial peeling force applied to ALC is challenging in developing robot-assisted CCC. A potential way to deal with this challenge is measuring axial force with a mercantile force sensor, which has the advantage of sub-millinewton precision, high axial stiffness, high stability, and ease of use. However, the measured results of the mercantile force sensor contain the axial peeling force and forceps-cornea friction. Therefore, we seek to estimate the friction at the incision with the distributed LuGre friction model. The normal force and friction at incision are measured by fiber bragg grating (FBG) sensors and a mercantile force sensor, respectively. Then, the parameters of the LuGre model are identified by applying a low-frequency sinusoidal movement on the forceps. An identification experiment is performed on ex-vivo pig cornea samples. Finally, friction during inserting forceps into the anterior segment of ex-vivo pig eyes is estimated. The root mean square error of friction identification and estimation are 0.59 mN and 1.59 mN, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149513194",
                    "name": "Yu Zheng"
                },
                {
                    "authorId": "2152917182",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "2116766562",
                    "name": "Chuang Lin"
                },
                {
                    "authorId": "91731894",
                    "name": "Chenhan Guang"
                },
                {
                    "authorId": "2189603152",
                    "name": "Jun-Jie Zong"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                }
            ]
        },
        {
            "paperId": "74559ad09c0f9d3d6ad1c7c49118d4a43025a7a0",
            "title": "Optimal, centralized dynamic curbside parking space zoning",
            "abstract": "In this paper we formulate a dynamic mixed integer program for optimally zoning curbside parking spaces subject to transportation policy-inspired constraints and regularization terms. First, we illustrate how given some objective of curb zoning valuation as a function of zone type (e.g., paid parking or bus stop), dynamically rezoning involves unrolling this optimization program over a fixed time horizon. Second, we implement two different solution methods that optimize for a given curb zoning value function. In the first method, we solve long horizon dynamic zoning problems via approximate dynamic programming. In the second method, we employ Dantzig-Wolfe decomposition to break-up the mixed-integer program into a master problem and several sub-problems that we solve in parallel; this decomposition accelerates the MIP solver considerably. We present simulation results and comparisons of the different employed techniques on vehicle arrival-rate data obtained for a neighborhood in downtown Seattle, Washington, USA.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "51240232",
                    "name": "Nawaf Nazir"
                },
                {
                    "authorId": "2836907",
                    "name": "Shushman Choudhury"
                },
                {
                    "authorId": "92858908",
                    "name": "Stephen Zoepf"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "38746745",
                    "name": "Chase P. Dowling"
                }
            ]
        },
        {
            "paperId": "bce01af6d9fa67ef31d946fe68a45f3ee4c74f1a",
            "title": "Precise Location Matching Improves Dense Contrastive Learning in Digital Pathology",
            "abstract": "Dense prediction tasks such as segmentation and detection of pathological entities hold crucial clinical value in computational pathology workflows. However, obtaining dense annotations on large cohorts is usually tedious and expensive. Contrastive learning (CL) is thus often employed to leverage large volumes of unlabeled data to pre-train the backbone network. To boost CL for dense prediction, some studies have proposed variations of dense matching objectives in pre-training. However, our analysis shows that employing existing dense matching strategies on histopathology images enforces invariance among incorrect pairs of dense features and, thus, is imprecise. To address this, we propose a precise location-based matching mechanism that utilizes the overlapping information between geometric transformations to precisely match regions in two augmentations. Extensive experiments on two pretraining datasets (TCGA-BRCA, NCT-CRC-HE) and three downstream datasets (GlaS, CRAG, BCSS) highlight the superiority of our method in semantic and instance segmentation tasks. Our method outperforms previous dense matching methods by up to 7.2% in average precision for detection and 5.6% in average precision for instance segmentation tasks. Additionally, by using our matching mechanism in the three popular contrastive learning frameworks, MoCo-v2, VICRegL, and ConCL, the average precision in detection is improved by 0.7% to 5.2%, and the average precision in segmentation is improved by 0.7% to 4.0%, demonstrating generalizability. Our code is available at https://github.com/cvlab-stonybrook/PLM_SSL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116207652",
                    "name": "Jingwei Zhang"
                },
                {
                    "authorId": "1818709358",
                    "name": "S. Kapse"
                },
                {
                    "authorId": "2881417",
                    "name": "Ke Ma"
                },
                {
                    "authorId": "39017169",
                    "name": "P. Prasanna"
                },
                {
                    "authorId": "1893915",
                    "name": "M. Vakalopoulou"
                },
                {
                    "authorId": "1735710",
                    "name": "J. Saltz"
                },
                {
                    "authorId": "48801624",
                    "name": "D. Samaras"
                }
            ]
        }
    ]
}