{
    "authorId": "2021632793",
    "papers": [
        {
            "paperId": "09cc4b2c870e62b8130af47669e63998e5e90a2b",
            "title": "Implicit Query Parsing at Amazon Product Search",
            "abstract": "Query Parsing aims to extract product attributes, such as color, brand, and product type, from search queries. These attributes play a crucial role in search engines for tasks such as matching, ranking, and recommendation. There are two types of attributes: explicit attributes that are mentioned explicitly in the search query, and implicit attributes that are mentioned implicitly. Existing works on query parsing do not differentiate between explicit query parsing and implicit query parsing, which limits their performance in product search engines. In this work, we demonstrate the critical importance of implicit attributes in real-world product search engines. We then present our solution for implicit query parsing at Amazon Search, which is a unified framework combining recent advancements in knowledge graph technologies and customer behavior analysis. We demonstrate the effectiveness of our proposal through offline experiments on Amazon search log data. We also show how to deploy and use the framework on Amazon search to improve customers' shopping experiences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2223935153",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1809614",
                    "name": "Yangqiu Song"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        },
        {
            "paperId": "131c6f328c11706de2c43cd16e0b7c5d5e610b6a",
            "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond",
            "abstract": "This article presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. First, we offer an introduction and brief summary of current language models. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, generation tasks, emergent abilities, and considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated with each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide aims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide. An LLMs evolutionary tree, editable yet regularly updated, can be found at llmtree.ai.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7788583",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "1791983892",
                    "name": "Hongye Jin"
                },
                {
                    "authorId": "2057059798",
                    "name": "Ruixiang Tang"
                },
                {
                    "authorId": "50017230",
                    "name": "Xiaotian Han"
                },
                {
                    "authorId": "2151233715",
                    "name": "Qizhang Feng"
                },
                {
                    "authorId": "5795999",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2193021044",
                    "name": "Xia Hu"
                }
            ]
        },
        {
            "paperId": "35544f161c8efa6134960bf0cc770defb13e6b56",
            "title": "Exploiting Intent Evolution in E-commercial Query Recommendation",
            "abstract": "Aiming at a better understanding of the search goals in the user search sessions, recent query recommender systems explicitly model the reformulations of queries, which hopes to estimate the intents behind these reformulations and thus benefit the next-query recommendation. However, in real-world e-commercial search scenarios, user intents are much more complicated and may evolve dynamically. Existing methods merely consider trivial reformulation intents from semantic aspects and fail to model dynamic reformulation intent flows in search sessions, leading to sub-optimal capacities to recommend desired queries. To deal with these limitations, we first explicitly define six types of query reformulation intents according to the desired products of two consecutive queries. We then apply two self-attentive encoders on top of two pre-trained large language models to learn the transition dynamics from semantic query and intent reformulation sequences, respectively. We develop an intent-aware query decoder to utilize the predicted intents for suggesting the next queries. We instantiate such a framework with an Intent-aware Variational AutoEncoder (IVAE) under deployment at Amazon. We conduct comprehensive experiments on two real-world e-commercial datasets from Amazon and one public dataset from BestBuy. Specifically, IVAE improves the Recall@15 by 25.44% and 60.47% on two Amazon datasets and 13.91% on BestBuy, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153606201",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "8492168",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "48784944",
                    "name": "Xianfeng Tang"
                },
                {
                    "authorId": "2107962433",
                    "name": "Yinghan Wang"
                },
                {
                    "authorId": "46334890",
                    "name": "Danqing Zhang"
                },
                {
                    "authorId": "3122003",
                    "name": "Limeng Cui"
                },
                {
                    "authorId": "2227491227",
                    "name": "M. Cheng"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2893721",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2721708",
                    "name": "P. Yu"
                }
            ]
        },
        {
            "paperId": "37d91ebd5ec969e2b81027e05f886febf09d2504",
            "title": "Multimodal Prompt Learning for Product Title Generation with Extremely Limited Labels",
            "abstract": "Generating an informative and attractive title for the product is a crucial task for e-commerce. Most existing works follow the standard multimodal natural language generation approaches, e.g., image captioning, and employ the large scale of human-labelled datasets to train desirable models. However, for novel products, especially in a different domain, there are few existing labelled data. In this paper, we propose a prompt-based approach, i.e., the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels. We observe that the core challenges of novel product title generation are the understanding of novel product characteristics and the generation of titles in a novel writing style. To this end, we build a set of multimodal prompts from different modalities to preserve the corresponding characteristics and writing styles of novel products. As a result, with extremely limited labels for training, the proposed method can retrieve the multimodal prompts to generate desirable titles for novel products. The experiments and analyses are conducted on five novel product categories under both the in-domain and out-of-domain experimental settings. The results show that, with only 1% of downstream labelled data for training, our proposed approach achieves the best few-shot results and even achieves competitive results with fully-supervised methods trained on 100% of training data; With the full labelled data for training, our method achieves state-of-the-art results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115355581",
                    "name": "Bang Yang"
                },
                {
                    "authorId": "2218961178",
                    "name": "Fenglin Liu"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2061592207",
                    "name": "Chenyu You"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "26981150",
                    "name": "Yuexian Zou"
                }
            ]
        },
        {
            "paperId": "45a6f7ca23944aa2050c2bc6d6a580058d032b30",
            "title": "Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation",
            "abstract": "Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks. To test the potential of the dataset, we introduce three tasks in this work: (1) next-product recommendation, (2) next-product recommendation with domain shifts, and (3) next-product title generation. With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice. In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 2023 and have attracted thousands of users and submissions. The winning solutions and the associated workshop can be accessed at our website https://kddcup23.github.io/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "5795999",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2149891871",
                    "name": "Hanqing Lu"
                },
                {
                    "authorId": "8492168",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "47370334",
                    "name": "Ruirui Li"
                },
                {
                    "authorId": "1700892",
                    "name": "Z. Li"
                },
                {
                    "authorId": "2072995251",
                    "name": "Mo Cheng"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2893721",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "48784944",
                    "name": "Xianfeng Tang"
                }
            ]
        },
        {
            "paperId": "56fa65d8dc41708082f9b2ef7752c49cee9ebe01",
            "title": "SCOTT: Self-Consistent Chain-of-Thought Distillation",
            "abstract": "Large language models (LMs) beyond a certain scale, demonstrate the emergent capability of generating free-text rationales for their predictions via chain-of-thought (CoT) prompting.While CoT can yield dramatically improved performance, such gains are only observed for sufficiently large LMs. Even more concerning, there is little guarantee that the generated rationales are consistent with LM\u2019s predictions or faithfully justify the decisions. In this work, we propose SCOTT, a faithful knowledge distillation method to learn a small, self-consistent CoT model from a teacher model that is orders of magnitude larger. To form better supervision, we elicit rationales supporting the gold answers from a large LM (teacher) by contrastive decoding, which encourages the teacher to generate tokens that become more plausible only when the answer is considered. To ensure faithful distillation, we use the teacher-generated rationales to learn a student LM with a counterfactual reasoning objective, which prevents the student from ignoring the rationales to make inconsistent predictions. Experiments show that while yielding comparable performance, our method leads to a more faithful model than baselines. Further analysis shows that such a model respects the rationales more when making decisions; thus, we can improve its performance more by refining its rationales.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2784644",
                    "name": "Peifeng Wang"
                },
                {
                    "authorId": "8492168",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "1921742",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2115257544",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "57404bd8c71e2b17fce63b49229b278b6a66bf13",
            "title": "Situated Natural Language Explanations",
            "abstract": "Natural language is among the most accessible tools for explaining decisions to humans, and large pretrained language models (PLMs) have demonstrated impressive abilities to generate coherent natural language explanations (NLE). The existing NLE research perspectives do not take the audience into account. An NLE can have high textual quality, but it might not accommodate audiences' needs and preference. To address this limitation, we propose an alternative perspective, \\textit{situated} NLE. On the evaluation side, we set up automated evaluation scores. These scores describe the properties of NLEs in lexical, semantic, and pragmatic categories. On the generation side, we identify three prompt engineering techniques and assess their applicability on the situations. Situated NLE provides a perspective and facilitates further research on the generation and evaluation of explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8129672",
                    "name": "Zining Zhu"
                },
                {
                    "authorId": "2152631081",
                    "name": "Hao Jiang"
                },
                {
                    "authorId": "7788583",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "7529854",
                    "name": "Sreyashi Nag"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1490651934",
                    "name": "Jie Huang"
                },
                {
                    "authorId": "1921742",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2479037",
                    "name": "Frank Rudzicz"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        },
        {
            "paperId": "6b007811589d41723b57f963900ed616bb917c58",
            "title": "CCGen: Explainable Complementary Concept Generation in E-Commerce",
            "abstract": "We propose and study Complementary Concept Generation (CCGen): given a concept of interest, e.g.,\"Digital Cameras\", generating a list of complementary concepts, e.g., 1) Camera Lenses 2) Batteries 3) Camera Cases 4) Memory Cards 5) Battery Chargers. CCGen is beneficial for various applications like query suggestion and item recommendation, especially in the e-commerce domain. To solve CCGen, we propose to train language models to generate ranked lists of concepts with a two-step training strategy. We also teach the models to generate explanations by incorporating explanations distilled from large teacher models. Extensive experiments and analysis demonstrate that our model can generate high-quality concepts complementary to the input concept while producing explanations to justify the predictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490651934",
                    "name": "Jie Huang"
                },
                {
                    "authorId": "1921742",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "7788583",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "1809614",
                    "name": "Yangqiu Song"
                },
                {
                    "authorId": "2152735278",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "8129672",
                    "name": "Zining Zhu"
                },
                {
                    "authorId": "5795999",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "143922493",
                    "name": "K. Chang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        },
        {
            "paperId": "9f12a8726377b7b67880822c7996090859d67437",
            "title": "Knowledge Graph Reasoning over Entities and Numerical Values",
            "abstract": "A complex logic query in a knowledge graph refers to a query expressed in logic form that conveys a complex meaning, such as where did the Canadian Turing award winner graduate from? Knowledge graph reasoning-based applications, such as dialogue systems and interactive search engines, rely on the ability to answer complex logic queries as a fundamental task. In most knowledge graphs, edges are typically used to either describe the relationships between entities or their associated attribute values. An attribute value can be in categorical or numerical format, such as dates, years, sizes, etc. However, existing complex query answering (CQA) methods simply treat numerical values in the same way as they treat entities. This can lead to difficulties in answering certain queries, such as which Australian Pulitzer award winner is born before 1927, and which drug is a pain reliever and has fewer side effects than Paracetamol. In this work, inspired by the recent advances in numerical encoding and knowledge graph reasoning, we propose numerical complex query answering. In this task, we introduce new numerical variables and operations to describe queries involving numerical attribute values. To address the difference between entities and numerical values, we also propose the framework of Number Reasoning Network (NRN) for alternatively encoding entities and numerical values into separate encoding structures. During the numerical encoding process, NRN employs a parameterized density function to encode the distribution of numerical values. During the entity encoding process, NRN uses established query encoding methods for the original CQA problem. Experimental results show that NRN consistently improves various query encoding methods on three different knowledge graphs and achieves state-of-the-art results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145677395",
                    "name": "Jiaxin Bai"
                },
                {
                    "authorId": "143884453",
                    "name": "Cheng-hsin Luo"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "1809614",
                    "name": "Yangqiu Song"
                }
            ]
        },
        {
            "paperId": "ae0839885c0317560cf8c1c286fe2aad65f4aba6",
            "title": "Graph Reasoning for Question Answering with Triplet Retrieval",
            "abstract": "Answering complex questions often requires reasoning over knowledge graphs (KGs). State-of-the-art methods often utilize entities in questions to retrieve local subgraphs, which are then fed into KG encoder, e.g. graph neural networks (GNNs), to model their local structures and integrated into language models for question answering. However, this paradigm constrains retrieved knowledge in local subgraphs and discards more diverse triplets buried in KGs that are disconnected but useful for question answering. In this paper, we propose a simple yet effective method to first retrieve the most relevant triplets from KGs and then rerank them, which are then concatenated with questions to be fed into language models. Extensive results on both CommonsenseQA and OpenbookQA datasets show that our method can outperform state-of-the-art up to 4.6% absolute accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50341591",
                    "name": "SHIYANG LI"
                },
                {
                    "authorId": "1921742",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2152631081",
                    "name": "Hao Jiang"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2146249169",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "1740249",
                    "name": "Xifeng Yan"
                },
                {
                    "authorId": "2152738036",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                }
            ]
        }
    ]
}