{
    "authorId": "2277462592",
    "papers": [
        {
            "paperId": "5cdba098f7b91106333008244fd8286d83af229b",
            "title": "Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models",
            "abstract": "Knowledge graph completion (KGC) is a widely used method to tackle incompleteness in knowledge graphs (KGs) by making predictions for missing links. Description-based KGC leverages pre-trained language models to learn entity and relation representations with their names or descriptions, which shows promising results. However, the performance of description-based KGC is still limited by the quality of text and the incomplete structure, as it lacks sufficient entity descriptions and relies solely on relation names, leading to sub-optimal results. To address this issue, we propose MPIKGC, a general framework to compensate for the deficiency of contextualized knowledge and improve KGC by querying large language models (LLMs) from various perspectives, which involves leveraging the reasoning, explanation, and summarization capabilities of LLMs to expand entity descriptions, understand relations, and extract structures, respectively. We conducted extensive evaluation of the effectiveness and improvement of our framework based on four description-based KGC models, for both link prediction and triplet classification tasks. All codes and generated data will be publicly available after review.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262514619",
                    "name": "Derong Xu"
                },
                {
                    "authorId": "2030976630",
                    "name": "Ziheng Zhang"
                },
                {
                    "authorId": "2258562926",
                    "name": "Zhenxi Lin"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2288043255",
                    "name": "Zhihong Zhu"
                },
                {
                    "authorId": "2277237058",
                    "name": "Tong Xu"
                },
                {
                    "authorId": "2281902096",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                },
                {
                    "authorId": "2265580543",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "7c8609b93871c49e2e0cef2a0e11f9ec9b1ce921",
            "title": "Large Language Models Enhanced Sequential Recommendation for Long-tail User and Item",
            "abstract": "Sequential recommendation systems (SRS) serve the purpose of predicting users' subsequent preferences based on their past interactions and have been applied across various domains such as e-commerce and social networking platforms. However, practical SRS encounters challenges due to the fact that most users engage with only a limited number of items, while the majority of items are seldom consumed. These challenges, termed as the long-tail user and long-tail item dilemmas, often create obstacles for traditional SRS methods. Mitigating these challenges is crucial as they can significantly impact user satisfaction and business profitability. While some research endeavors have alleviated these issues, they still grapple with issues such as seesaw or noise stemming from the scarcity of interactions. The emergence of large language models (LLMs) presents a promising avenue to address these challenges from a semantic standpoint. In this study, we introduce the Large Language Models Enhancement framework for Sequential Recommendation (LLM-ESR), which leverages semantic embeddings from LLMs to enhance SRS performance without increasing computational overhead. To combat the long-tail item challenge, we propose a dual-view modeling approach that fuses semantic information from LLMs with collaborative signals from traditional SRS. To address the long-tail user challenge, we introduce a retrieval augmented self-distillation technique to refine user preference representations by incorporating richer interaction data from similar users. Through comprehensive experiments conducted on three authentic datasets using three widely used SRS models, our proposed enhancement framework demonstrates superior performance compared to existing methodologies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2281902096",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2269463602",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2244621655",
                    "name": "Feng Tian"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                }
            ]
        },
        {
            "paperId": "803f8cb9bdd70f11ebb3e34b19e71e2a98137e64",
            "title": "AutoPal: Autonomous Adaptation to Users for Personal AI Companisonship",
            "abstract": "Previous research has demonstrated the potential of AI agents to act as companions that can provide constant emotional support for humans. In this paper, we emphasize the necessity of autonomous adaptation in personal AI companionship, an underexplored yet promising direction. Such adaptability is crucial as it can facilitate more tailored interactions with users and allow the agent to evolve in response to users' changing needs. However, imbuing agents with autonomous adaptability presents unique challenges, including identifying optimal adaptations to meet users' expectations and ensuring a smooth transition during the adaptation process. To address them, we devise a hierarchical framework, AutoPal, that enables controllable and authentic adjustments to the agent's persona based on user interactions. A personamatching dataset is constructed to facilitate the learning of optimal persona adaptations. Extensive experiments demonstrate the effectiveness of AutoPal and highlight the importance of autonomous adaptability in AI companionship.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117232627",
                    "name": "Yi Cheng"
                },
                {
                    "authorId": "2109562691",
                    "name": "Wenge Liu"
                },
                {
                    "authorId": "2119184118",
                    "name": "Kaishuai Xu"
                },
                {
                    "authorId": "150337518",
                    "name": "Wenjun Hou"
                },
                {
                    "authorId": "2275187481",
                    "name": "Ouyang Yi"
                },
                {
                    "authorId": "2257035605",
                    "name": "Chak Tou Leong"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                }
            ]
        },
        {
            "paperId": "f795f0b7380dbbbe8bd48f0c4505ba0d64155007",
            "title": "Large Language Model Empowered Embedding Generator for Sequential Recommendation",
            "abstract": "Sequential Recommender Systems (SRS) are extensively applied across various domains to predict users' next interaction by modeling their interaction sequences. However, these systems typically grapple with the long-tail problem, where they struggle to recommend items that are less popular. This challenge results in a decline in user discovery and reduced earnings for vendors, negatively impacting the system as a whole. Large Language Model (LLM) has the potential to understand the semantic connections between items, regardless of their popularity, positioning them as a viable solution to this dilemma. In our paper, we present LLMEmb, an innovative technique that harnesses LLM to create item embeddings that bolster the performance of SRS. To align the capabilities of general-purpose LLM with the needs of the recommendation domain, we introduce a method called Supervised Contrastive Fine-Tuning (SCFT). This method involves attribute-level data augmentation and a custom contrastive loss designed to tailor LLM for enhanced recommendation performance. Moreover, we highlight the necessity of incorporating collaborative filtering signals into LLM-generated embeddings and propose Recommendation Adaptation Training (RAT) for this purpose. RAT refines the embeddings to be optimally suited for SRS. The embeddings derived from LLMEmb can be easily integrated with any SRS model, showcasing its practical utility. Extensive experimentation on three real-world datasets has shown that LLMEmb significantly improves upon current methods when applied across different SRS models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2292569421",
                    "name": "Yuanshao Zhu"
                },
                {
                    "authorId": "2261673614",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2244621655",
                    "name": "Feng Tian"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                }
            ]
        },
        {
            "paperId": "351a2d50b4aff8e9754dc7074dd589b10a7465d4",
            "title": "Large Language Models for Generative Information Extraction: A Survey",
            "abstract": "Information extraction (IE) aims to extract structural knowledge (such as entities, relations, and events) from plain natural language texts. Recently, generative Large Language Models (LLMs) have demonstrated remarkable capabilities in text understanding and generation, allowing for generalization across various domains and tasks. As a result, numerous works have been proposed to harness abilities of LLMs and offer viable solutions for IE tasks based on a generative paradigm. To conduct a comprehensive systematic review and exploration of LLM efforts for IE tasks, in this study, we survey the most recent advancements in this field. We first present an extensive overview by categorizing these works in terms of various IE subtasks and learning paradigms, then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs. Based on thorough review conducted, we identify several insights in technique and promising research directions that deserve further exploration in future studies. We maintain a public repository and consistently update related resources at: \\url{https://github.com/quqxui/Awesome-LLM4IE-Papers}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262514619",
                    "name": "Derong Xu"
                },
                {
                    "authorId": "2260766940",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "1765218",
                    "name": "Wenjun Peng"
                },
                {
                    "authorId": "2260850374",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2277237058",
                    "name": "Tong Xu"
                },
                {
                    "authorId": "2261673614",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                },
                {
                    "authorId": "2265580543",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "c90d79c3b003c72cc2b98227e7b99fd82486b1f4",
            "title": "COOPER: Coordinating Specialized Agents towards a Complex Dialogue Goal",
            "abstract": "In recent years, there has been a growing interest in exploring dialogues with more complex goals, such as negotiation, persuasion, and emotional support, which go beyond traditional service-focused dialogue systems. Apart from the requirement for much more sophisticated strategic reasoning and communication skills, a significant challenge of these tasks lies in the difficulty of objectively measuring the achievement of their goals in a quantifiable way, making it difficult for existing research to directly optimize the dialogue procedure towards them. In our work, we emphasize the multifaceted nature of complex dialogue goals and argue that it is more feasible to accomplish them by comprehensively considering and jointly promoting their different aspects. To this end, we propose a novel dialogue framework, Cooper, which coordinates multiple specialized agents, each dedicated to a specific dialogue goal aspect separately, to approach the complex objective. Through this divide-and-conquer manner, we make complex dialogue goals more approachable and elicit greater intelligence via the collaboration of individual agents. Experiments on persuasion and emotional support dialogues demonstrate the superiority of our method over a set of competitive baselines. Our codes are available at https://github.com/YiCheng98/Cooper.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117232627",
                    "name": "Yi Cheng"
                },
                {
                    "authorId": "2109562691",
                    "name": "Wenge Liu"
                },
                {
                    "authorId": "2258854033",
                    "name": "Jian Wang"
                },
                {
                    "authorId": "2257035605",
                    "name": "Chak Tou Leong"
                },
                {
                    "authorId": "2275187481",
                    "name": "Ouyang Yi"
                },
                {
                    "authorId": "2261357254",
                    "name": "Wenjie Li"
                },
                {
                    "authorId": "2277462592",
                    "name": "Xian Wu"
                },
                {
                    "authorId": "2237585282",
                    "name": "Yefeng Zheng"
                }
            ]
        }
    ]
}