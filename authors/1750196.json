{
    "authorId": "1750196",
    "papers": [
        {
            "paperId": "fddc440bcb7ad2b444e27b72fe95f52bf4c1315f",
            "title": "A Dataset for Large Language Model-Driven AI Accelerator Generation",
            "abstract": "\u2014In the ever-evolving landscape of Deep Neural Networks (DNN) hardware acceleration, unlocking the true potential of systolic array accelerators has long been hindered by the daunting challenges of expertise and time investment. Large Language Models (LLMs) offer a promising solution for automating code generation which is key to unlocking unprecedented efficiency and performance in various domains, including hardware descriptive code. However, the successful application of LLMs to hardware accelerator design is contingent upon the availability of specialized datasets tailored for this purpose. To bridge this gap, we introduce the Systolic Array-based Accelerator DataSet (SA-DS). SA-DS comprises of a diverse collection of spatial arrays following the standardized Berkeley\u2019s Gemmini accelerator generator template, enabling design reuse, adaptation, and customization. SA-DS is intended to spark LLM-centred research on DNN hardware accelerator architecture. We envision that SA-DS provides a framework which will shape the course of DNN hardware acceleration research for generations to come. SA-DS is open-sourced under the permissive MIT license at this https://github.com/ACADLab/SA-DS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "2226523621",
                    "name": "Deepak Vungarala"
                },
                {
                    "authorId": "1475748342",
                    "name": "Mehrdad Morsali"
                },
                {
                    "authorId": "2297250450",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2297352834",
                    "name": "Arnob Ghosh"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "1824271",
                    "name": "Shaahin Angizi"
                }
            ]
        },
        {
            "paperId": "374ff52faeea2a519a3b8eafcf0fc10e9e1b96ad",
            "title": "Adversarial NLP for Social Network Applications: Attacks, Defenses, and Research Directions",
            "abstract": "The growing use of media has led to the development of several machine learning (ML) and natural language processing (NLP) tools to process the unprecedented amount of social media content to make actionable decisions. However, these ML and NLP algorithms have been widely shown to be vulnerable to adversarial attacks. These vulnerabilities allow adversaries to launch a diversified set of adversarial attacks on these algorithms in different applications of social media text processing. In this article, we provide a comprehensive review of the main approaches for adversarial attacks and defenses in the context of social media applications with a particular focus on key challenges and future research directions. In detail, we cover literature on six key applications: 1) rumors detection; 2) satires detection; 3) clickbaits and spams identification; 4) hate speech detection; 5) misinformation detection; and 6) sentiment analysis. We then highlight the concurrent and anticipated future research questions and provide recommendations and directions for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1770016",
                    "name": "I. Alsmadi"
                },
                {
                    "authorId": "143623051",
                    "name": "Kashif Ahmad"
                },
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "1404786833",
                    "name": "Ala I. Al-Fuqaha"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "3027509",
                    "name": "A. Algosaibi"
                }
            ]
        },
        {
            "paperId": "42e7ea6eb841fe41d949f72d6778519a4b5b3542",
            "title": "Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection",
            "abstract": "Malicious domain detection (MDD) is an open security challenge that aims to detect if an Internet domain name is associated with cyber attacks. Many techniques have been applied to tackle this problem, among which graph neural networks (GNNs) are deemed one of the most effective approaches. GNN-based MDD employs domain name system (DNS) logs to represent Internet domains as nodes in a graph, dubbed domain maliciousness graph (DMG) and trains a GNN model to infer the maliciousness of Internet domains by leveraging the maliciousness of already identified ones. As this method heavily relies on the \"publicly\" accessible DNS logs to build DMGs, it creates a vulnerability for adversaries to manipulate the features and edges of their domain nodes within these graphs. The current body of literature primarily focuses on threat models that involve manipulating individual adversary (attacker) nodes. Nonetheless, adversaries usually create numerous domains to accomplish their attack objectives, aiming to reduce costs and evade detection. Hence, they aim to remain undetected across as many domains as possible. In this work, we call the attack that manipulates several nodes in the DMG concurrently a multi-instance evasion attack. To the best of our knowledge, this type of attack has not been explored in the prior art. We present both theoretical and empirical evidence to show that the existing single-instance evasion techniques for GNN-based MDDs are inadequate to launch multi-instance evasion attacks. Therefore, we propose an inference-time, multi-instance adversarial attack, dubbed MintA, against GNN-based MDD. MintA optimizes node perturbations to enhance the evasiveness of a node and its neighborhood. MintA only requires black-box access to the target model to launch the attack successfully. In other words, MintA does not require any knowledge of the MDD model\u2019s parameters, architecture, or information on non-adversary nodes. We formulate an optimization problem that satisfies the attack objectives of MintA and devise an approximate solution for it. We evaluate MintA on a state-of-the-art GNN-based MDD technique using real-world data, and our experiments demonstrate an attack success rate of over 80%. The findings of this study serve as a cautionary note for security experts, highlighting the vulnerability of GNN-based MDD to practical attacks that can impede the effectiveness and advantages of this approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "1783739",
                    "name": "Issa M. Khalil"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "11032760",
                    "name": "Nhathai Phan"
                },
                {
                    "authorId": "2148984778",
                    "name": "Yao Ma"
                }
            ]
        },
        {
            "paperId": "4ca35eae8677a69c6b4e116c1e84565679d27b44",
            "title": "Delay-Controlled Bidirectional Traffic Setup Scheme to Enhance the Network Coding Opportunity in Real-Time Industrial IoT Networks",
            "abstract": "Recently, network coding has become a promising transmission approach to support high throughput and low latency in distributed multihop networks. In this article, we develop a delay-controlled distributed route establishment scheme that can provide maximal bidirectional transmission to enhance network coding gain while satisfying a time-critical route setup. The scheme is called network coding-aware delayed store and forwarding (NC-DSF). It delays the received route information packets before forwarding them according to the link status and network topology. We propose a tight delay function derived using a strict end-to-end delay bound for delay control. Subsequently, we suggest a relaxed delay function derived using realistic and practical conditions. Finally, we propose a load-weighted delay function considering the tradeoff between bidirectionality and network-load balancing. The simulations confirm that the proposed scheme offers increased throughput and decreased latency in mesh and random multihop networks. The proposed transmission scheme, NC-DSF, can be efficiently employed in the future industrial Internet of Things networks requiring a time-constrained route setup, high throughput, and low latency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1783243",
                    "name": "Yunseong Lee"
                },
                {
                    "authorId": "2041306521",
                    "name": "Taeyun Ha"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "2174183",
                    "name": "Wonjong Noh"
                },
                {
                    "authorId": "51453730",
                    "name": "Sungrae Cho"
                }
            ]
        },
        {
            "paperId": "5e5c43b1dde1eae6825a17148bce62ef0c7acaa4",
            "title": "R-VLCP: Channel Modeling and Simulation in Retroreflective Visible Light Communication and Positioning Systems",
            "abstract": "Retroreflective visible light communication and positioning (R-VLCP) is a novel ultralow-power Internet of Things (IoT) technology leveraging indoor light infrastructures. Compared to traditional VLCP, R-VLCP offers several additional favorable features, including self-alignment, low-size, weight, and power (SWaP), glaring-free, and sniff-proof. In analogy to RFID, R-VLCP employs a microwatt optical modulator (e.g., LCD shutter) to manipulate the intensity of the reflected light from a corner-cube retroreflector (CCR) to the photodiodes (PDs) mounted on a light source. In our previous works, we derived a closed-form expression for the retroreflection channel model, assuming that the PD is much smaller than the CCR in geometric analysis. In this article, we generalize the channel model to arbitrary size of PD and CCR. The received optical power is fully characterized relative to the sizes of PD and CCR, and the 3-D location of CCR. We also develop a custom and open-source ray tracing simulator\u2014RetroRay, and use it to validate the channel model. Performance evaluation of area spectral efficiency and horizontal location error is carried out based on the channel model validated by RetroRay. The results reveal that increasing the size of PD and the density of CCRs improves communication and positioning performance with diminishing returns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2194154",
                    "name": "Sihua Shao"
                },
                {
                    "authorId": "2202116545",
                    "name": "A. Salustri"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "40151687",
                    "name": "Chenren Xu"
                },
                {
                    "authorId": "2046978401",
                    "name": "Shuai Ma"
                }
            ]
        },
        {
            "paperId": "85e265c696de23bc88420b1d31f38b74890d1717",
            "title": "Genetic Algorithm-Based Dynamic Backdoor Attack on Federated Learning-Based Network Traffic Classification",
            "abstract": "Federated learning enables multiple clients to collaboratively contribute to the learning of a global model orchestrated by a central server. This learning scheme promotes clients' data privacy and requires reduced communication overheads. In an application like network traffic classification, this helps hide the network vulnerabilities and weakness points. However, federated learning is susceptible to backdoor attacks, in which adversaries inject manipulated model updates into the global model. These updates inject a salient functionality in the global model that can be launched with specific input patterns. Nonetheless, the vulnerability of network traffic classification models based on federated learning to these attacks remains unexplored. In this paper, we propose GABAttack, a novel genetic algorithm-based backdoor attack against federated learning for network traffic classification. GABAttack utilizes a genetic algorithm to optimize the values and locations of backdoor trigger patterns, ensuring a better fit with the input and the model. This input-tailored dynamic attack is promising for improved attack evasiveness while being effective. Extensive experiments conducted over real-world network datasets validate the success of the proposed GABAttack in various situations while maintaining almost invisible activity. This research serves as an alarming call for network security experts and practitioners to develop robust defense measures against such attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "8776688",
                    "name": "Nura Aljaafari"
                },
                {
                    "authorId": "9196469",
                    "name": "Ahmad H. Sawalmeh"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "2066279604",
                    "name": "Muhammad Anan"
                },
                {
                    "authorId": "2222196358",
                    "name": "A. Algosaibi"
                },
                {
                    "authorId": "2165725339",
                    "name": "Mohammed Alnaeem"
                },
                {
                    "authorId": "2063954417",
                    "name": "Adel Aldalbahi"
                },
                {
                    "authorId": "2165725254",
                    "name": "Abdulaziz Alhumam"
                },
                {
                    "authorId": "71332955",
                    "name": "C. Vizcarra"
                },
                {
                    "authorId": "2021311397",
                    "name": "Shadan Alhamed"
                }
            ]
        },
        {
            "paperId": "b68288844a297b608df2f1cac985e70974b4a45a",
            "title": "IMA-GNN: In-Memory Acceleration of Centralized and Decentralized Graph Neural Networks at the Edge",
            "abstract": "In this paper, we propose IMA-GNN as an In-Memory Accelerator for centralized and decentralized Graph Neural Network inference, explore its potential in both settings and provide a guideline for the community targeting flexible and efficient edge computation. Leveraging IMA-GNN, we first model the computation and communication latencies of edge devices. We then present practical case studies on GNN-based taxi demand and supply prediction and also adopt four large graph datasets to quantitatively compare and analyze centralized and decentralized settings. Our cross-layer simulation results demonstrate that on average, IMA-GNN in the centralized setting can obtain ~790x communication speed-up compared to the decentralized GNN setting. However, the decentralized setting performs computation ~1400x faster while reducing the power consumption per device. This further underlines the need for a hybrid semi-decentralized GNN approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1475748342",
                    "name": "Mehrdad Morsali"
                },
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "1824271",
                    "name": "Shaahin Angizi"
                }
            ]
        },
        {
            "paperId": "c54f940b99664bd29c1766a965d1f4c5af96fa8b",
            "title": "Semi-decentralized Inference in Heterogeneous Graph Neural Networks for Traffic Demand Forecasting: An Edge-Computing Approach",
            "abstract": "Prediction of taxi service demand and supply is essential for improving customer's experience and provider's profit. Recently, graph neural networks (GNNs) have been shown promising for this application. This approach models city regions as nodes in a transportation graph and their relations as edges. GNNs utilize local node features and the graph structure in the prediction. However, more efficient forecasting can still be achieved by following two main routes; enlarging the scale of the transportation graph, and simultaneously exploiting different types of nodes and edges in the graphs. However, both approaches are challenged by the scalability of GNNs. An immediate remedy to the scalability challenge is to decentralize the GNN operation. However, this creates excessive node-to-node communication. In this paper, we first characterize the excessive communication needs for the decentralized GNN approach. Then, we propose a semi-decentralized approach utilizing multiple cloudlets, moderately sized storage and computation devices, that can be integrated with the cellular base stations. This approach minimizes inter-cloudlet communication thereby alleviating the communication overhead of the decentralized approach while promoting scalability due to cloudlet-level decentralization. Also, we propose a heterogeneous GNN-LSTM algorithm for improved taxi-level demand and supply forecasting for handling dynamic taxi graphs where nodes are taxis. Extensive experiments over real data show the advantage of the semi-decentralized approach as tested over our heterogeneous GNN-LSTM algorithm. Also, the proposed semi-decentralized GNN approach is shown to reduce the overall inference time by about an order of magnitude compared to centralized and decentralized inference schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7744822",
                    "name": "Mahmoud Nazzal"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "3172194",
                    "name": "Joyoung Lee"
                },
                {
                    "authorId": "1824271",
                    "name": "Shaahin Angizi"
                },
                {
                    "authorId": "1389945327",
                    "name": "Ala Al-Fuqaha"
                },
                {
                    "authorId": "2065439840",
                    "name": "M. Guizani"
                }
            ]
        },
        {
            "paperId": "d9fb25621878d18912ddeb32bd9dc4fdc6de40ea",
            "title": "Beyond Securing Networks and Storage: Emerging Attacks and Defences to Machine Intelligence",
            "abstract": "Over the past three decades most research efforts in security and privacy have focused on network and storage security. Recently, Deep Neural Network (DNN) classifiers gain wide adoption in different complex tasks, including natural language processing, computer vision and cyber security. However, the underlying assumption of attack free operating environment has been defied by the introduction of several attacks such as adversarial examples and Trojan backdoor attacks. In Adversarial attacks the adversary perturbs the input examples during inference to force the DNN to misclassify while the adversary in the Trojan Backdoor operates in both training and inference phases. In the training phase the adversary trains the DNN in a way such that it behaves normally when the Trojan trigger does not exist, and it misclassifies if the trigger exists. Given that only the adversary knows the trigger, the users of the DNN will be fooled to trust the DNN model. The adversary can now attach the Trigger to the input examples during inference causing the DNN model to misclassify. In this talk we will discuss our development of several computationally efficient defense approaches for the Adversarial attacks enabling real-time detection of the attack for the first time. We will also discuss our development of an adaptive black-box defense approach for the Trojan Backdoor attack that outperforms the state-of-the-art by studying the relationships among the prediction logits of the DNN. After that we will discuss our recent follow up work in which we show how to jointly combine the above two adversaries to practically launch a new stealthy attack, dubbed AdvTrojan. AdvTrojan is stealthy because it can be activated only when: 1) a carefully crafted adversarial perturbation is injected into the input examples during inference, and 2) a Trojan backdoor is implanted during the training process of the model. We leverage adversarial noise in the input space to move Trojan-infected examples across the model decision boundary, making it difficult to detect. The stealthiness behavior of AdvTrojan fools the users into accidentally trusting the infected model as a robust classifier against adversarial examples. We will also discuss our future research that is focused on expanding the attack and defense mechanisms to new areas such as malicious domain detection, federated learning setting, personalized federated learning, and Graph Neural Networks. We will also discuss several application domains of adversarial as well as Trojan Backdoor attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                }
            ]
        },
        {
            "paperId": "e2106bf720a92150ce71156251dcddd341da36f5",
            "title": "Federated Learning Aided Deep Convolutional Neural Network Solution for Smart Traffic Management",
            "abstract": "Machine learning models, especially neural network (NN) classifiers, have shown tremendous potential of being used in complex tasks such as image classification, object detection and video analytics. However, to be adopted in the real-world applications, there are still problems to be answered. One of these problems is that training machine learning models, especially NN models, requires a certain level of computation and data processing. Other problems are the limited bandwidth of the network and the possibility of exposing the privacy of the users to attacks if the training data (specially video) is going to be transferred through the network. To mitigate these problems, researchers recently proposed the concept of federated learning.In this paper, we build a video analytic application for traffic management and train it using federated learning. More specifically, each traffic surveillance camera combined with its co-located small PC are seen as the worker node in federated learning. In this way, the NN model in each node can be trained on data collected from all nodes without transmitting and sharing with a central server, which resolves all of the above mentioned problems. The performance of the trained NN model is evaluated via experiments under different open sourced datasets to demonstrate that the proposed work has the potential to enhance the detection accuracy (mAP) over 40%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152756608",
                    "name": "Guanxiong Liu"
                },
                {
                    "authorId": "2211952310",
                    "name": "Nicholas Furth"
                },
                {
                    "authorId": "50137133",
                    "name": "Hang Shi"
                },
                {
                    "authorId": "1750196",
                    "name": "Abdallah Khreishah"
                },
                {
                    "authorId": "2108845889",
                    "name": "Jo Young Lee"
                },
                {
                    "authorId": "2065623653",
                    "name": "Nirwan Ansari"
                },
                {
                    "authorId": "39664966",
                    "name": "Chengjun Liu"
                },
                {
                    "authorId": "1781328",
                    "name": "Y. Jararweh"
                }
            ]
        }
    ]
}