{
    "authorId": "2273766311",
    "papers": [
        {
            "paperId": "f42b97cdfbf1a78c02e78cfce6f8b0e277766ae2",
            "title": "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs",
            "abstract": "Reasoning encompasses two typical types: deductive reasoning and inductive reasoning. Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning, leading to a blending of the two. This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? While the deductive reasoning capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning tasks), have received considerable attention, their abilities in true inductive reasoning remain largely unexplored. To investigate into the true inductive reasoning capabilities of LLMs, we propose a novel framework, SolverLearner. This framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$), that maps input data points $(x)$ to their corresponding output values $(y)$, using only in-context examples. By focusing on inductive reasoning and separating it from LLM-based deductive reasoning, we can isolate and investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our observations reveal that LLMs demonstrate remarkable inductive reasoning capabilities through SolverLearner, achieving near-perfect performance with ACC of 1 in most cases. Surprisingly, despite their strong inductive reasoning abilities, LLMs tend to relatively lack deductive reasoning capabilities, particularly in tasks involving ``counterfactual'' reasoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260755600",
                    "name": "Kewei Cheng"
                },
                {
                    "authorId": "2276746186",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2312598740",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2315087538",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "2257590787",
                    "name": "Ruirui Li"
                },
                {
                    "authorId": "2314348843",
                    "name": "Shiyang Li"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2261083995",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "a072dc70413c02e6bcf80769eade6bb0bc4c1f98",
            "title": "Improving Consistency for Text Summarization with Energy Functions",
            "abstract": "Current abstractive summarization models often generate inconsistent content, i.e. texts that are not directly inferable from the source document, are not consistent with respect to world knowledge, or are self-contradictory. These inconsistencies motivate a new consistency taxonomy that we define as faithfulness, factuality, and self-supportiveness. However, most recent work on reducing inconsistency in document summarization only focuses on faithfulness detection and correction while ignoring other inconsistency phenomena, which limits the model\u2019s scalability. To improve the general consistency we introduce EnergySum, where we apply the Residual Energy-based Model by designing energy scorers that reflect each type of consistency. These energy scores are utilized in candidate re-ranking during the sampling process. Experiments on XSUM and CNN/DM datasets show that EnergySum mitigates the trade-off between accuracy and consistency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273693612",
                    "name": "Qi Zeng"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "7529854",
                    "name": "Sreyashi Nag"
                },
                {
                    "authorId": "2274037416",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2274622328",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                }
            ]
        },
        {
            "paperId": "af6da5e89b61e43bf9af2233cb003deea3d4bff1",
            "title": "Knowledge-Selective Pretraining for Attribute Value Extraction",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275053439",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2274037416",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2273814369",
                    "name": "William Wang"
                },
                {
                    "authorId": "2274054096",
                    "name": "Xiao-Dan Zhu"
                }
            ]
        }
    ]
}