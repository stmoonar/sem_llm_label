{
    "authorId": "120783624",
    "papers": [
        {
            "paperId": "221df686b58da529ad5ae68a872f6767805bd6d5",
            "title": "Prompting Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving",
            "abstract": "Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM\u2019s powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentan-gles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Trans-former. Experiments indicate that our proposed method can achieve better performance than typical prompting strategies in tasks bothered by intermediate errors and deceptive contents, such as large integer multiplication, hallucination detection and misinformation detection .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145055264",
                    "name": "Yizhou Zhang"
                },
                {
                    "authorId": "2301756083",
                    "name": "Lun Du"
                },
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2260654024",
                    "name": "Qiang Fu"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "34eedbb011e45d80045cadebaf1d01b2ddec22a1",
            "title": "GPT4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting",
            "abstract": "Time series forecasting is an essential area of machine learning with a wide range of real-world applications. Most of the previous forecasting models aim to capture dynamic characteristics from uni-modal numerical historical data. Although extra knowledge can boost the time series forecasting performance, it is hard to collect such information. In addition, how to fuse the multimodal information is non-trivial. In this paper, we first propose a general principle of collecting the corresponding textual information from different data sources with the help of modern large language models (LLM). Then, we propose a prompt-based LLM framework to utilize both the numerical data and the textual information simultaneously, named GPT4MTS. In practice, we propose a GDELT-based multimodal time series dataset for news impact forecasting, which provides a concise and well-structured version of time series dataset with textual information for further research in communication. Through extensive experiments, we demonstrate the effectiveness of our proposed method on forecasting tasks with extra-textual information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256985863",
                    "name": "Furong Jia"
                },
                {
                    "authorId": "2293923697",
                    "name": "Kevin Wang"
                },
                {
                    "authorId": "2257061490",
                    "name": "Yixiang Zheng"
                },
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "3ced5cceee0ef7ab7ea25b61fb9e4487370c44cd",
            "title": "An Examination on the Effectiveness of Divide-and-Conquer Prompting in Large Language Models",
            "abstract": "Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, simple instructional prompts suffer from inaccurate responses. Existing works show that more complicated prompting strategies, such as Chain-of-Thoughts and Least-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent researches reveal that simple divide-and-conquer prompting strategy, i.e. simply dividing the input sequence to multiple sub-inputs, can also substantially improve LLM's performance in some specific tasks such as misinformation detection. In this paper, we aim at examining the utility of divide-and-conquer prompting strategy and answer on which kind of tasks this strategy gets advantages. Specifically, we provide a theoretic analysis to divide-and-conquer prompting strategy and help us identify the specific tasks where DaC prompting can bring performance boost with theoretic guarantee. We then present two cases (large integer arithmetic and fact verification) where experimental results aligns with our theoretic analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145055264",
                    "name": "Yizhou Zhang"
                },
                {
                    "authorId": "12723949",
                    "name": "Lun Du"
                },
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2260654024",
                    "name": "Qiang Fu"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "4ac5e71b614aa0a7c4eb59f2373df836aaf44e47",
            "title": "Beyond Forecasting: Compositional Time Series Reasoning for End-to-End Task Execution",
            "abstract": "In recent decades, there has been substantial advances in time series models and benchmarks across various individual tasks, such as time series forecasting, classification, and anomaly detection. Meanwhile, compositional reasoning in time series is prevalent in real-world applications (e.g., decision-making and compositional question answering) and is in great demand. Unlike simple tasks that primarily focus on predictive accuracy, compositional reasoning emphasizes the synthesis of diverse information from both time series data and various domain knowledge, making it distinct and extremely more challenging. In this paper, we introduce Compositional Time Series Reasoning, a new task of handling intricate multistep reasoning tasks from time series data. Specifically, this new task focuses on various question instances requiring structural and compositional reasoning abilities on time series data, such as decision-making and compositional question answering. As an initial attempt to tackle this novel task, we developed TS-Reasoner, a program-aided approach that utilizes large language model (LLM) to decompose a complex task into steps of programs that leverage existing time series models and numerical subroutines. Unlike existing reasoning work which only calls off-the-shelf modules, TS-Reasoner allows for the creation of custom modules and provides greater flexibility to incorporate domain knowledge as well as user-specified constraints. We demonstrate the effectiveness of our method through a comprehensive set of experiments. These promising results indicate potential opportunities in the new task of time series reasoning and highlight the need for further research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256992266",
                    "name": "Wen Ye"
                },
                {
                    "authorId": "2145055264",
                    "name": "Yizhou Zhang"
                },
                {
                    "authorId": "2316881202",
                    "name": "Wei Yang"
                },
                {
                    "authorId": null,
                    "name": "Lumingyuan Tang"
                },
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2324863284",
                    "name": "Jie Cai"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "ace7d07de33a903e1b3052479cacd2dfa7ae2bb6",
            "title": "TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model",
            "abstract": "With recent advances in building foundation models for texts and video data, there is a surge of interest in foundation models for time series. A family of models have been developed, utilizing a temporal auto-regressive generative Transformer architecture, whose effectiveness has been proven in Large Language Models. While the empirical results are promising, almost all existing time series foundation models have only been tested on well-curated ``benchmark'' datasets very similar to texts. However, real-world time series exhibit unique challenges, such as variable channel sizes across domains, missing values, and varying signal sampling intervals due to the multi-resolution nature of real-world data. Additionally, the uni-directional nature of temporally auto-regressive decoding limits the incorporation of domain knowledge, such as physical laws expressed as partial differential equations (PDEs). To address these challenges, we introduce the Time Diffusion Transformer (TimeDiT), a general foundation model for time series that employs a denoising diffusion paradigm instead of temporal auto-regressive generation. TimeDiT leverages the Transformer architecture to capture temporal dependencies and employs diffusion processes to generate high-quality candidate samples without imposing stringent assumptions on the target distribution via novel masking schemes and a channel alignment strategy. Furthermore, we propose a finetuning-free model editing strategy that allows the seamless integration of external knowledge during the sampling process without updating any model parameters. Extensive experiments conducted on a varity of tasks such as forecasting, imputation, and anomaly detection, demonstrate the effectiveness of TimeDiT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2256992266",
                    "name": "Wen Ye"
                },
                {
                    "authorId": "2145055264",
                    "name": "Yizhou Zhang"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "c11575b69424770336add6ee1def3c63c8724411",
            "title": "An Empirical Examination of Balancing Strategy for Counterfactual Estimation on Time Series",
            "abstract": "Counterfactual estimation from observations represents a critical endeavor in numerous application fields, such as healthcare and finance, with the primary challenge being the mitigation of treatment bias. The balancing strategy aimed at reducing covariate disparities between different treatment groups serves as a universal solution. However, when it comes to the time series data, the effectiveness of balancing strategies remains an open question, with a thorough analysis of the robustness and applicability of balancing strategies still lacking. This paper revisits counterfactual estimation in the temporal setting and provides a brief overview of recent advancements in balancing strategies. More importantly, we conduct a critical empirical examination for the effectiveness of the balancing strategies within the realm of temporal counterfactual estimation in various settings on multiple datasets. Our findings could be of significant interest to researchers and practitioners and call for a reexamination of the balancing strategy in time series settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260342251",
                    "name": "Qiang Huang"
                },
                {
                    "authorId": "27737939",
                    "name": "Chuizheng Meng"
                },
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2316364477",
                    "name": "Biwei Huang"
                },
                {
                    "authorId": "2316362232",
                    "name": "Yi Chang"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "0c786bdd93186c0824d672ac8d063ee188c7e2e8",
            "title": "Large Scale Financial Time Series Forecasting with Multi-faceted Model",
            "abstract": "Data-driven approaches using deep neural networks have been successful in modeling complex financial time series and generating accurate predictions without requiring extensive domain knowledge. However, most of the existing models that assume independent and identically distributed (i.i.d.) data may not generalize well to novel situations or distributional shifts across or inside financial scenarios. To address this challenge, we introduce an invariant learning-based regularizer with relaxed bounds that expands the range of feasible solutions and mitigates over-convergence issues in Invariant Risk Minimization (IRM). In practice, the regularizer can be incorporated into both linear and nonlinear financial time series forecasting models. Experimental results on real-world large-scale financial datasets show that our proposed method enables more robust and adaptable financial forecasting models, enhancing the overall performance and generalizability of financial forecasting on both in-distribution and out-of-distribution (OOD) samples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2257061490",
                    "name": "Yixiang Zheng"
                },
                {
                    "authorId": "3468951",
                    "name": "Parisa Hassanzadeh"
                },
                {
                    "authorId": "2003643209",
                    "name": "Simran Lamba"
                },
                {
                    "authorId": "2271803804",
                    "name": "Xiaomo Liu"
                },
                {
                    "authorId": "2260272787",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "83ac79bb8e8695fb3c3c024be74790d862adea74",
            "title": "TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting",
            "abstract": "The past decade has witnessed significant advances in time series modeling with deep learning. While achieving state-of-the-art results, the best-performing architectures vary highly across applications and domains. Meanwhile, for natural language processing, the Generative Pre-trained Transformer (GPT) has demonstrated impressive performance via training one general-purpose model across various textual datasets. It is intriguing to explore whether GPT-type architectures can be effective for time series, capturing the intrinsic dynamic attributes and leading to significant accuracy improvements. In this paper, we propose a novel framework, TEMPO, that can effectively learn time series representations. We focus on utilizing two essential inductive biases of the time series task for pre-trained models: (i) decomposition of the complex interaction between trend, seasonal and residual components; and (ii) introducing the design of prompts to facilitate distribution adaptation in different types of time series. TEMPO expands the capability for dynamically modeling real-world temporal phenomena from data within diverse domains. Our experiments demonstrate the superior performance of TEMPO over state-of-the-art methods on zero shot setting for a number of time series benchmark datasets. This performance gain is observed not only in scenarios involving previously unseen datasets but also in scenarios with multi-modal inputs. This compelling finding highlights TEMPO's potential to constitute a foundational model-building framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2256985863",
                    "name": "Furong Jia"
                },
                {
                    "authorId": "2676352",
                    "name": "Sercan \u00d6. Arik"
                },
                {
                    "authorId": "1945962",
                    "name": "Tomas Pfister"
                },
                {
                    "authorId": "2257061490",
                    "name": "Yixiang Zheng"
                },
                {
                    "authorId": "2256992266",
                    "name": "Wen Ye"
                },
                {
                    "authorId": "2257088730",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "896e5cee54d50d7a1f981823b4627948610d72a5",
            "title": "Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders",
            "abstract": "Causal analysis for time series data, in particular estimating individualized treatment effect (ITE), is a key task in many real world applications, such as finance, retail, healthcare, etc. Real world time series, i.e., large-scale irregular or sparse and intermittent time series, raise significant challenges to existing work attempting to estimate treatment effects. Specifically, the existence of hidden confounders can lead to biased treatment estimates and complicate the causal inference process. In particular, anomaly hidden confounders which exceed the typical range can lead to high variance estimates. Moreover, in continuous time settings with irregular samples, it is challenging to directly handle the dynamics of causality. In this paper, we leverage recent advances in Lipschitz regularization and neural controlled differential equations (CDE) to develop an effective and scalable solution, namely LipCDE, to address the above challenges. LipCDE can directly model the dynamic causal relationships between historical data and outcomes with irregular samples by considering the boundary of hidden confounders given by Lipschitz constrained neural networks. Furthermore, we conduct extensive experiments on both synthetic and real world datasets to demonstrate the effectiveness and scalability of LipCDE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "1390029897",
                    "name": "James Enouen"
                },
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "27737939",
                    "name": "Chuizheng Meng"
                },
                {
                    "authorId": "2223921871",
                    "name": "Hao Niu"
                },
                {
                    "authorId": "47909531",
                    "name": "Yan Liu"
                }
            ]
        },
        {
            "paperId": "8b7d2029744569449d79162e701724b12b9bbdfe",
            "title": "Estimating Treatment Effects in Continuous Time with Hidden Confounders",
            "abstract": "Estimating treatment effects plays a crucial role in causal inference, having many real-world applications like policy analysis and decision making. Nevertheless, estimating treatment effects in the longitudinal setting in the presence of hidden confounders remains an extremely challenging problem. Recently, there is a growing body of work attempting to obtain unbiased ITE estimates from time-dynamic observational data by ignoring the possible existence of hidden confounders. Additionally, many existing works handling hidden confounders are not applicable for continuous-time settings. In this paper, we extend the line of work focusing on deconfounding in the dynamic time setting in the presence of hidden confounders. We leverage recent advancements in neural differential equations to build a latent factor model using a stochastic controlled differential equation and Lipschitz constrained convolutional operation in order to continuously incorporate information about ongoing interventions and irregularly sampled observations. Experiments on both synthetic and real-world datasets highlight the promise of continuous time methods for estimating treatment effects in the presence of hidden confounders.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "1390029897",
                    "name": "James Enouen"
                },
                {
                    "authorId": "1679704",
                    "name": "Y. Liu"
                }
            ]
        }
    ]
}