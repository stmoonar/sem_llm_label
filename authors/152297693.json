{
    "authorId": "152297693",
    "papers": [
        {
            "paperId": "0d20d02b38d4044c3b24b8b2f374311cbd2e9ccc",
            "title": "Dimension Independent Mixup for Hard Negative Sample in Collaborative Filtering",
            "abstract": "Collaborative filtering (CF) is a widely employed technique that predicts user preferences based on past interactions. Negative sampling plays a vital role in training CF-based models with implicit feedback. In this paper, we propose a novel perspective based on the sampling area to revisit existing sampling methods. We point out that current sampling methods mainly focus on Point-wise or Line-wise sampling, lacking flexibility and leaving a significant portion of the hard sampling area un-explored. To address this limitation, we propose Dimension Independent Mixup for Hard Negative Sampling (DINS), which is the first Area-wise sampling method for training CF-based models. DINS comprises three modules: Hard Boundary Definition, Dimension Independent Mixup, and Multi-hop Pooling. Experiments with real-world datasets on both matrix factorization and graph-based models demonstrate that DINS outperforms other negative sampling methods, establishing its effectiveness and superiority. Our work contributes a new perspective, introduces Area-wise sampling, and presents DINS as a novel approach that achieves state-of-the-art performance for negative sampling. Our implementations are available in PyTorch.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2164713748",
                    "name": "Xi Wu"
                },
                {
                    "authorId": "120378195",
                    "name": "Liangwei Yang"
                },
                {
                    "authorId": "2869419",
                    "name": "Jibing Gong"
                },
                {
                    "authorId": "2110841093",
                    "name": "Chao Zhou"
                },
                {
                    "authorId": "2115349214",
                    "name": "Tianyu Lin"
                },
                {
                    "authorId": "2142880129",
                    "name": "Xiao-lin Liu"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "25612f9294d04a87280b198f036763affe9c2296",
            "title": "Heterogeneous Graph Propagation Network",
            "abstract": "Graph neural network (GNN), as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. Recently, some works attempt to generalize GNN to heterogeneous graph which contains different types of nodes and links. Heterogeneous graph neural networks (HeteGNNs) usually follow two steps: aggregate neighbors via single meta-path and then aggregate rich semantics via multiple meta-paths. However, we discover an important semantic confusion phenomenon in HeteGNNs, i.e., with the growth of model depth, the learned node embeddings become indistinguishable, leading to the performance degradation of HeteGNNs. We explain semantic confusion by theoretically deriving that HeteGNNs and multiple meta-paths based random walk are essentially equivalent. Following the theoretical analysis, we propose a novel Heterogeneous graph Propagation Network (HPN) to alleviate the semantic confusion. Specifically, the semantic propagation mechanism improves the node-level aggregating process via absorbing node's local semantic with a proper weight, which makes HPN capture the characteristics of each node and learn distinguishable node embedding with deeper HeteGNN architecture. Then, the semantic fusion mechanism is designed to learn the importance of meta-path and fuse them judiciously. Extensive experimental results show the superior performance of the proposed HPN over the state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51111816",
                    "name": "Houye Ji"
                },
                {
                    "authorId": "2118449003",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "144123161",
                    "name": "C. Shi"
                },
                {
                    "authorId": "2156645170",
                    "name": "Bai Wang"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "32a35e04a32cf62459181538899847bf89504568",
            "title": "A Post-Training Framework for Improving Heterogeneous Graph Neural Networks",
            "abstract": "Recent years have witnessed the success of heterogeneous graph neural networks (HGNNs) in modeling heterogeneous information networks (HINs). In this paper, we focus on the benchmark task of HGNNs, i.e., node classification, and empirically find that typical HGNNs are not good at predicting the label of a test node whose receptive field (1) has few training nodes from the same category or (2) has multiple training nodes from different categories. A possible explanation is that their message passing mechanisms may involve noises from different categories, and cannot fully explore task-specific knowledge such as the label dependency between distant nodes. Therefore, instead of introducing a new HGNN model, we propose a general post-training framework that can be applied on any pretrained HGNNs to further inject task-specific knowledge and enhance their prediction performance. Specifically, we first design an auxiliary system that estimates node labels based on (1) a global inference module of multi-channel label propagation and (2) a local inference module of network schema-aware prediction. The mechanism of our auxiliary system can complement the pretrained HGNNs by providing extra task-specific knowledge. During the post-training process, we will strengthen both system-level and module-level consistencies to encourage the cooperation between a pretrained HGNN and our auxiliary system. In this way, both systems can learn from each other for better performance. In experiments, we apply our framework to four typical HGNNs. Experimental results on three benchmark datasets show that compared with pretrained HGNNs, our post-training framework can enhance Micro-F1 by a relative improvement of on average. Code, data and appendix are available at https://github.com/GXM1141/HGPF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3443627",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "2152012853",
                    "name": "Xumeng Gong"
                },
                {
                    "authorId": "2151458697",
                    "name": "Chuan Shi"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "3599a236f285af48782fc30b1341d13ec7320735",
            "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
            "abstract": "Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of recent research advancements, challenges, and opportunities for PFMs in text, image, graph, as well as other data modalities. The review covers the basic components and existing pretraining methods used in natural language processing, computer vision, and graph learning. Additionally, it explores advanced PFMs used for different data modalities and unified PFMs that consider data quality and quantity. The review also discusses research related to the fundamentals of PFMs, such as model efficiency and compression, security, and privacy. Finally, the study provides key implications, future research directions, challenges, and open problems in the field of PFMs. Overall, this survey aims to shed light on the research of the PFMs on scalability, security, logical reasoning ability, cross-domain learning ability, and the user-friendly interactive ability for artificial general intelligence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187669795",
                    "name": "Ce Zhou"
                },
                {
                    "authorId": "2117126771",
                    "name": "Qian Li"
                },
                {
                    "authorId": "2116521405",
                    "name": "Chen Li"
                },
                {
                    "authorId": null,
                    "name": "Jun Yu"
                },
                {
                    "authorId": null,
                    "name": "Yixin Liu"
                },
                {
                    "authorId": "2152582885",
                    "name": "Guan Wang"
                },
                {
                    "authorId": "2158520914",
                    "name": "Kaichao Zhang"
                },
                {
                    "authorId": "2052296239",
                    "name": "Cheng Ji"
                },
                {
                    "authorId": "2072779826",
                    "name": "Qi Yan"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                },
                {
                    "authorId": "49349645",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "47785906",
                    "name": "Jianxin Li"
                },
                {
                    "authorId": "2144139161",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "2145254462",
                    "name": "Ziwei Liu"
                },
                {
                    "authorId": "40526720",
                    "name": "P. Xie"
                },
                {
                    "authorId": "2054594326",
                    "name": "Caiming Xiong"
                },
                {
                    "authorId": "2143960747",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                },
                {
                    "authorId": "2208907959",
                    "name": "Lichao Sun Michigan State University"
                },
                {
                    "authorId": "88729424",
                    "name": "B. University"
                },
                {
                    "authorId": "103217915",
                    "name": "Lehigh University"
                },
                {
                    "authorId": "2095706829",
                    "name": "M. University"
                },
                {
                    "authorId": "88740224",
                    "name": "Nanyang Technological University"
                },
                {
                    "authorId": "102788302",
                    "name": "University of California at San Diego"
                },
                {
                    "authorId": "2303446202",
                    "name": "Duke University"
                },
                {
                    "authorId": "6106131",
                    "name": "U. Chicago"
                },
                {
                    "authorId": "2208653278",
                    "name": "Salesforce Research"
                }
            ]
        },
        {
            "paperId": "457b7dc04944d960fac7a971f09b783465d7eb44",
            "title": "SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization",
            "abstract": "Graph Neural Networks (GNNs) are de facto solutions to structural data learning. However, it is susceptible to low-quality and unreliable structure, which has been a norm rather than an exception in real-world graphs. Existing graph structure learning (GSL) frameworks still lack robustness and interpretability. This paper proposes a general GSL framework, SE-GSL, through structural entropy and the graph hierarchy abstracted in the encoding tree. Particularly, we exploit the one-dimensional structural entropy to maximize embedded information content when auxiliary neighbourhood attributes is fused to enhance the original graph. A new scheme of constructing optimal encoding trees are proposed to minimize the uncertainty and noises in the graph whilst assuring proper community partition in hierarchical abstraction. We present a novel sample-based mechanism for restoring the graph structure via node structural entropy distribution. It increases the connectivity among nodes with larger uncertainty in lower-level communities. SE-GSL is compatible with various GNN models and enhances the robustness towards noisy and heterophily structures. Extensive experiments show significant improvements in the effectiveness and robustness of structure learning and node representation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2211982723",
                    "name": "Dongcheng Zou"
                },
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2188461112",
                    "name": "Xiang Huang"
                },
                {
                    "authorId": "1894612",
                    "name": "Renyu Yang"
                },
                {
                    "authorId": "47785906",
                    "name": "Jianxin Li"
                },
                {
                    "authorId": "2144139161",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "2108013862",
                    "name": "Chun-Yi Liu"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "5bf14dda76156d62a9b3b9ff59dba90ff7b9923d",
            "title": "OrthoReg: Improving Graph-regularized MLPs via Orthogonality Regularization",
            "abstract": "Graph Neural Networks (GNNs) are currently dominating in modeling graph-structure data, while their high reliance on graph structure for inference significantly impedes them from widespread applications. By contrast, Graph-regularized MLPs (GR-MLPs) implicitly inject the graph structure information into model weights, while their performance can hardly match that of GNNs in most tasks. This motivates us to study the causes of the limited performance of GR-MLPs. In this paper, we first demonstrate that node embeddings learned from conventional GR-MLPs suffer from dimensional collapse, a phenomenon in which the largest a few eigenvalues dominate the embedding space, through empirical observations and theoretical analysis. As a result, the expressive power of the learned node representations is constrained. We further propose OrthoReg, a novel GR-MLP model to mitigate the dimensional collapse issue. Through a soft regularization loss on the correlation matrix of node embeddings, OrthoReg explicitly encourages orthogonal node representations and thus can naturally avoid dimensionally collapsed representations. Experiments on traditional transductive semi-supervised classification tasks and inductive node classification for cold-start scenarios demonstrate its effectiveness and superiority.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "2151226033",
                    "name": "Shen Wang"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2121390172",
                    "name": "Soji Adeshina"
                },
                {
                    "authorId": "73329314",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2099585332",
                    "name": "Xiao Qin"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "122579067",
                    "name": "Da Zheng"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "6d6ee72a43bac634e6f023c04724f3903b446e00",
            "title": "Hierarchical State Abstraction Based on Structural Information Principles",
            "abstract": "State abstraction optimizes decision-making by ignoring irrelevant environmental information in reinforcement learning with rich observations. Nevertheless, recent approaches focus on adequate representational capacities resulting in essential information loss, affecting their performances on challenging tasks. In this article, we propose a novel mathematical Structural Information principles-based State Abstraction framework, namely SISA, from the information-theoretic perspective. Specifically, an unsupervised, adaptive hierarchical state clustering method without requiring manual assistance is presented, and meanwhile, an optimal encoding tree is generated. On each non-root tree node, a new aggregation function and condition structural entropy are designed to achieve hierarchical state abstraction and compensate for sampling-induced essential information loss in state abstraction. Empirical evaluations on a visual gridworld domain and six continuous control benchmarks demonstrate that, compared with five SOTA state abstraction approaches, SISA significantly improves mean episode reward and sample efficiency up to 18.98 and 44.44%, respectively. Besides, we experimentally show that SISA is a general framework that can be flexibly integrated with different representation-learning objectives to improve their performances further.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2213816305",
                    "name": "Xianghua Zeng"
                },
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "145546987",
                    "name": "Angsheng Li"
                },
                {
                    "authorId": "2212098398",
                    "name": "Chunyang Liu"
                },
                {
                    "authorId": "40901818",
                    "name": "Lifang He"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "779bb347fd38df46b8179f719cfc625078014c0d",
            "title": "Graph Collaborative Signals Denoising and Augmentation for Recommendation",
            "abstract": "Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated. In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to the adjacency matrix. Our experiments demonstrate that the enhanced user-item interaction matrix with improved neighbors and lower density leads to significant benefits in graph-based recommendation. Moreover, we show that the inclusion of user-user and item-item correlations can improve recommendations for users with both abundant and insufficient interactions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2524771",
                    "name": "Ziwei Fan"
                },
                {
                    "authorId": "2152484867",
                    "name": "Ke Xu"
                },
                {
                    "authorId": "2213708371",
                    "name": "Zhang Dong"
                },
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "1718428",
                    "name": "Jiawei Zhang"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "7a1521df5ddc33283fa8f8fe7ef2558014e6f451",
            "title": "Introduction to the Special Issue on Advanced Graph Mining on the Web: Theory, Algorithms, and Applications: Part 1",
            "abstract": "We are delighted to present this special issue on Advanced Graph Mining on the Web: Theory, Algorithms, and Applications. Graph mining plays an important role in data mining on the Web. It can take full advantage of the growing and easily accessible big data resources on the Web, such as rich semantic information in social media and complex associations between users in online social networks, which is crucial for the development of systems and applications such as event detection, social bot detection, and intelligent recommendation. However, extracting valuable and representative information from Web graph data is still a great challenge and requires research and development on advanced techniques. The purpose of this special issue is to provide a forum for researchers and practitioners to present their latest research findings and engineering experiences in the theoretical foundations, empirical studies, and novel applications of Graph Mining. This special issue consists of two parts. In Part 1, the guest editors selected 10 contributions that cover varying topics within this theme, ranging from reinforced and self-supervised GNN architecture search framework to the streaming growth algorithm of bipartite graphs. Yang et al. in \u201cRoSGAS: Adaptive Social Bot Detection with Reinforced Self-supervised GNN Architecture Search\u201d proposed a novel Reinforced and Self-supervised GNN Architecture Search framework named RoSGAS, which gains improvement in terms of accuracy, training efficiency, and stability. And has better generalization when handling unseen samples. Du et al. in \u201cNiffler: Real-time Device-level Anomalies Detection in Smart Home\u201d proposed a novel notion\u2014a correlated graph, and with the aid of that, they developed a system to detect misbehaving devices without modifying the existing system, which is crucial for the device-level security in the smart home system. And then they further proposed a linkage path model and a sensitivity ranking method to assist in detecting the abnormalities. Sun et al. in \u201cGroupAligner: A Deep Reinforcement Learning with Domain Adaptation for Social Group Alignment\u201d presented a novel GroupAligner, a deep reinforcement learning with domain adaptation for social group alignment, which solves the problems of feature inconsistency across different social networks and group discovery within a social network in social group alignment. Zhu et al. in \u201cA Multi-task Graph Neural Network with Variational Graph Auto-encoders for Session-based Travel Packages Recommendation\u201d proposed a novel session-based model named STR-VGAE, which provides robust attributes\u2019 representations and takes the effects of historical sessions for the current session into consideration. The model obtained promising results in the session-based recommendation, and can fill subtasks of the travel packages recommendation and variational graph auto-encoders simultaneously.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2138443697",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2118801701",
                    "name": "Jian Yang"
                },
                {
                    "authorId": "2142734769",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "7ac3e09d74ca15fdafa5f730617cd65059a144f3",
            "title": "Weakly Supervised Anomaly Detection: A Survey",
            "abstract": "Anomaly detection (AD) is a crucial task in machine learning with various applications, such as detecting emerging diseases, identifying financial frauds, and detecting fake news. However, obtaining complete, accurate, and precise labels for AD tasks can be expensive and challenging due to the cost and difficulties in data annotation. To address this issue, researchers have developed AD methods that can work with incomplete, inexact, and inaccurate supervision, collectively summarized as weakly supervised anomaly detection (WSAD) methods. In this study, we present the first comprehensive survey of WSAD methods by categorizing them into the above three weak supervision settings across four data modalities (i.e., tabular, graph, time-series, and image/video data). For each setting, we provide formal definitions, key algorithms, and potential future directions. To support future research, we conduct experiments on a selected setting and release the source code, along with a collection of WSAD methods and data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152154941",
                    "name": "Minqi Jiang"
                },
                {
                    "authorId": "2204929921",
                    "name": "Chaochuan Hou"
                },
                {
                    "authorId": "2204948431",
                    "name": "Ao Zheng"
                },
                {
                    "authorId": "35346885",
                    "name": "Xiyang Hu"
                },
                {
                    "authorId": "2004577591",
                    "name": "Songqiao Han"
                },
                {
                    "authorId": "2146285145",
                    "name": "Hailiang Huang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                },
                {
                    "authorId": "145454815",
                    "name": "Yue Zhao"
                }
            ]
        }
    ]
}