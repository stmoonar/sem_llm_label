{
    "authorId": "1717004",
    "papers": [
        {
            "paperId": "0e523bd5345125874191e066f8cc73257063215c",
            "title": "Unified Dense Subgraph Detection: Fast Spectral Theory Based Algorithms",
            "abstract": "How can we effectively detect fake reviews or fraudulent links on a website? How can we spot communities that suddenly appear based on users\u2019 interactions? And how can we efficiently find the minimum cut in a large graph? All of these are related to the finding of dense subgraphs, a significant primitive problem in graph analysis with extensive applications across various domains. In this paper, we focus on formulating the problem of the densest subgraph detection and theoretically compare and contrast several correlated problems. Moreover, we propose a unified framework, <sc>GenDS</sc>, for the densest subgraph detection, provide some theoretical analysis based on the network flow and spectral graph theory, and devise simple and computationally efficient algorithms, <sc>SpecGDS</sc> and <sc>GepGDS</sc>, to solve it by leveraging the spectral properties and greedy search. We conduct thorough experiments on 40 real-world networks with up to 1.47 billion edges from various domains. We demonstrate that our <sc>SpecGDS</sc> yields up to <inline-formula><tex-math notation=\"LaTeX\">$58.6 \\ \\times$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>58</mml:mn><mml:mo>.</mml:mo><mml:mn>6</mml:mn><mml:mspace width=\"4pt\"/><mml:mo>\u00d7</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=\"feng-ieq1-3272574.gif\"/></alternatives></inline-formula>speedup and achieves better or approximately equal-quality solutions for the densest subgraph detection compared to the baselines. <sc>GepGDS</sc> also reveals some properties of generalized eigenvalue problems for the <sc>GenDS</sc>. Also, our methods scale linearly with the graph size and are proven effective in applications such as finding collaborations that appear suddenly in an extensive, time-evolving co-authorship network.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145948356",
                    "name": "Wenjie Feng"
                },
                {
                    "authorId": "2152939828",
                    "name": "Shenghua Liu"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "10ae25755d9aa17ebc9934cb4c4208c969c4e35c",
            "title": "Visual Transformation Telling",
            "abstract": "Humans can naturally reason from superficial state differences (e.g. ground wetness) to transformations descriptions (e.g. raining) according to their life experience. In this paper, we propose a new visual reasoning task to test this transformation reasoning ability in real-world scenarios, called \\textbf{V}isual \\textbf{T}ransformation \\textbf{T}elling (VTT). Given a series of states (i.e. images), VTT requires to describe the transformation occurring between every two adjacent states. Different from existing visual reasoning tasks that focus on surface state reasoning, the advantage of VTT is that it captures the underlying causes, e.g. actions or events, behind the differences among states. We collect a novel dataset to support the study of transformation reasoning from two existing instructional video datasets, CrossTask and COIN, comprising 13,547 samples. Each sample involves the key state images along with their transformation descriptions. Our dataset covers diverse real-world activities, providing a rich resource for training and evaluation. To construct an initial benchmark for VTT, we test several models, including traditional visual storytelling methods (CST, GLACNet, Densecap) and advanced multimodal large language models (LLaVA v1.5-7B, Qwen-VL-chat, Gemini Pro Vision, GPT-4o, and GPT-4). Experimental results reveal that even state-of-the-art models still face challenges in VTT, highlighting substantial areas for improvement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145251362",
                    "name": "Xin Hong"
                },
                {
                    "authorId": "37510256",
                    "name": "Yanyan Lan"
                },
                {
                    "authorId": "2111815778",
                    "name": "Liang Pang"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "1f6746d712bbc7a119f035c630301a2c04d58640",
            "title": "Few-shot Link Prediction on N-ary Facts",
            "abstract": "\u2014N-ary facts composed of a primary triple (head entity, relation, tail entity) and an arbitrary number of auxiliary attribute-value pairs, are prevalent in real-world knowledge graphs (KGs). Link prediction on n-ary facts is to predict a missing element in an n-ary fact. This helps populate and enrich KGs and further promotes numerous downstream applications. Previous studies usually require a substantial amount of high-quality data to understand the elements in n-ary facts. However, these studies overlook few-shot relations, which have limited labeled instances, yet are common in real-world scenarios. Thus, this paper introduces a new task, few-shot link prediction on n-ary facts. It aims to predict a missing entity in an n-ary fact with limited labeled instances. We further propose a model for Few-shot Link prEdict on N-ary facts, thus called FLEN, which consists of three modules: the relation learning, support-speci\ufb01c adjusting, and query inference modules. FLEN captures relation meta information from limited instances to predict a missing entity in a query instance. To validate the effectiveness of FLEN, we construct three datasets based on existing benchmark data. Our experimental results show that FLEN signi\ufb01cantly outperforms existing related models in both few-shot link prediction on n-ary facts and binary facts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216739591",
                    "name": "Jiyao Wei"
                },
                {
                    "authorId": "24749412",
                    "name": "Saiping Guan"
                },
                {
                    "authorId": "2149111400",
                    "name": "Xiaolong Jin"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "2da3db5656b0539ba05b0d04f030544d59f1a56a",
            "title": "Continual Learning for Generative Retrieval over Dynamic Corpora",
            "abstract": "Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To memorize new documents for querying without forgetting previous knowledge, we propose a memory-augmented learning mechanism, to form meaningful connections between old and new documents. Empirical results demonstrate the effectiveness and efficiency of the proposed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108313363",
                    "name": "Jiangui Chen"
                },
                {
                    "authorId": "2109960367",
                    "name": "Ruqing Zhang"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1696030",
                    "name": "M. de Rijke"
                },
                {
                    "authorId": "2256716717",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "7888704",
                    "name": "Yixing Fan"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "3630de1ddd8832540c1ebd027d70497766db7153",
            "title": "Fairness and Diversity in Recommender Systems: A Survey",
            "abstract": "Recommender systems (RS) are effective tools for mitigating information overload and have seen extensive applications across various domains. However, the single focus on utility goals proves to be inadequate in addressing real-world concerns, leading to increasing attention to fairness-aware and diversity-aware RS. While most existing studies explore fairness and diversity independently, we identify strong connections between these two domains. In this survey, we first discuss each of them individually and then dive into their connections. Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level. With this expanded perspective on user and item-level diversity, we re-interpret fairness studies from the viewpoint of diversity. This fresh perspective enhances our understanding of fairness-related work and paves the way for potential future research directions. Papers discussed in this survey along with public code links are available at: https://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124210729",
                    "name": "Yuying Zhao"
                },
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2027660089",
                    "name": "Yunchao Liu"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                },
                {
                    "authorId": "2166048911",
                    "name": "Charu Aggarwal"
                },
                {
                    "authorId": "2067148039",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "368c1f25109460e51522dd29fc8c5a04966adca9",
            "title": "Topic-oriented Adversarial Attacks against Black-box Neural Ranking Models",
            "abstract": "Neural ranking models (NRMs) have attracted considerable attention in information retrieval. Unfortunately, NRMs may inherit the adversarial vulnerabilities of general neural networks, which might be leveraged by black-hat search engine optimization practitioners. Recently, adversarial attacks against NRMs have been explored in the paired attack setting, generating an adversarial perturbation to a target document for a specific query. In this paper, we focus on a more general type of perturbation and introduce the topic-oriented adversarial ranking attack task against NRMs, which aims to find an imperceptible perturbation that can promote a target document in ranking for a group of queries with the same topic. We define both static and dynamic settings for the task and focus on decision-based black-box attacks. We propose a novel framework to improve topic-oriented attack performance based on a surrogate ranking model. The attack problem is formalized as a Markov decision process (MDP) and addressed using reinforcement learning. Specifically, a topic-oriented reward function guides the policy to find a successful adversarial example that can be promoted in rankings to as many queries as possible in a group. Experimental results demonstrate that the proposed framework can significantly outperform existing attack strategies, and we conclude by re-iterating that there exist potential risks for applying NRMs in the real world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143860482",
                    "name": "Yuansan Liu"
                },
                {
                    "authorId": "2109960367",
                    "name": "Ruqing Zhang"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1696030",
                    "name": "M. de Rijke"
                },
                {
                    "authorId": "2283009",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "7888704",
                    "name": "Yixing Fan"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "503330d26a5e8f1d2b357d9c791d55547f7f250f",
            "title": "Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method",
            "abstract": "Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for NRMs. We find that the promising results that have previously been reported on attacking NRMs, do not generalize to DR models: these methods underperform a simple term spamming method. We attribute the observed lack of generalizability to the interaction-focused architecture of NRMs, which emphasizes fine-grained relevance matching. DR models follow a different representation-focused architecture that prioritizes coarse-grained representations. We propose to formalize attacks on DR models as a contrastive learning problem in a multi-view representation space. The core idea is to encourage the consistency between each view representation of the target document and its corresponding viewer via view-wise supervision signals. Experimental results demonstrate that the proposed method can significantly outperform existing attack strategies in misleading the DR model with small indiscernible text perturbations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143860482",
                    "name": "Yuansan Liu"
                },
                {
                    "authorId": "2109960367",
                    "name": "Ruqing Zhang"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1696030",
                    "name": "M. de Rijke"
                },
                {
                    "authorId": "2256716717",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "7888704",
                    "name": "Yixing Fan"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "66228612cc1dc0956ab6e0b590118a53cf49d2fd",
            "title": "Inducing Causal Structure for Abstractive Text Summarization",
            "abstract": "The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Variational Auto-encoder (VAE) to fit the joint distribution of the document and summary variables from the training corpus. Experimental results on two widely used text summarization datasets demonstrate the advantages of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145146592",
                    "name": "Luyao Chen"
                },
                {
                    "authorId": "2109960367",
                    "name": "Ruqing Zhang"
                },
                {
                    "authorId": "2314536491",
                    "name": "Wei Huang"
                },
                {
                    "authorId": "2256716717",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "6e799514114128f0b98b62d94088a21aa97b8cd6",
            "title": "Prompt Tuning with Contradictory Intentions for Sarcasm Recognition",
            "abstract": "Recently, prompt tuning has achieved promising results in a variety of natural language processing (NLP) tasks. The typical approach is to insert text pieces (i.e. templates) into the input and transform downstream tasks into the same form as pre-training. In essence, a high-quality template is the foundation of prompt tuning to support the performance of the converted cloze-style task. However, for sarcasm recognition, it is time-consuming and requires increasingly sophisticated domain knowledge to determine the appropriate templates and label words due to its highly figurative nature. In this work, we propose SarcPrompt, to incorporate the prior knowledge about contradictory intentions into prompt tuning for sarcasm recognition. SarcPrompt is inspired by that the speaker usually says the opposite of what they actually mean in the sarcastic text. Based on this idea, we explicitly mimic the actual intention by prompt construction and indicate whether the actual intention is contradictory to the literal content by verbalizer engineering. Experiments on three public datasets with standard and low-resource settings demonstrate the effectiveness of our SarcPrompt for sarcasm recognition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108150932",
                    "name": "Yiyi Liu"
                },
                {
                    "authorId": "2109960367",
                    "name": "Ruqing Zhang"
                },
                {
                    "authorId": "7888704",
                    "name": "Yixing Fan"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        },
        {
            "paperId": "72bd3ee3bc2628128e369bb1babd1c776c4f26ed",
            "title": "Learning Adversarially Robust Sparse Networks via Weight Reparameterization",
            "abstract": "Although increasing model size can enhance the adversarial robustness of deep neural networks, in resource-constrained environments, there exist critical sparsity constraints. While the recent robust pruning technologies show promising direction to obtain adversarially robust sparse networks, they perform poorly with high sparsity. In this work, we bridge this performance gap by reparameterizing network parameters to simultaneously learn the sparse structure and the robustness. Specifically, we introduce Twin-Rep, which reparameterizes original weights into the product of two factors during training and performs pruning on the reparameterized weights to satisfy the target sparsity constraint. Twin-Rep implicitly adds the sparsity constraint without changing the robust training objective, thus can enhance robustness under high sparsity. We also introduce another variant of weight reparameterization for better channel pruning. When inferring, we restore the original weight structure to obtain compact and robust networks. Extensive experiments on diverse datasets demonstrate that our method achieves state-of-the-art results, outperforming the current sparse robust training method and robustness-aware pruning method. Our code is available at\nhttps://github.com/UCAS-LCH/Twin-Rep.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157345099",
                    "name": "Chenhao Li"
                },
                {
                    "authorId": "2077648",
                    "name": "Qiang Qiu"
                },
                {
                    "authorId": "2222313929",
                    "name": "Zhibin Zhang"
                },
                {
                    "authorId": "1777025",
                    "name": "J. Guo"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                }
            ]
        }
    ]
}