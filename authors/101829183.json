{
    "authorId": "101829183",
    "papers": [
        {
            "paperId": "e07893e56c63f50c0c9c11812dc61572c2d3f7a6",
            "title": "DATran: Dual Attention Transformer for Multi-Label Image Classification",
            "abstract": "Multi-label image classification is a fundamental yet challenging task, which aims to predict the labels associated with a given image. Most of previous methods directly exploit the high-level features from the last layer of convolutional neural network for classification. However, these methods cannot obtain global features due to the limited size of convolutional kernels, and they fail to extract multi-scale features to effectively recognize small-scale objects in the images. Recent studies exploit the graph convolution network to model the label correlations for boosting the classification performance. Despite substantial progress, these methods rely on manually pre-defined graph structures. Besides, they ignore the associations between semantic labels and image regions, and do not fully explore the spatial context of images. To address above issues, we propose a novel Dual Attention Transformer (DATran) model, which adopts a dual-stream architecture that simultaneously learns spatial and channel correlations from multi-label images. Firstly, in order to solve the problem that current methods are difficult to recognize small-size objects, we develop a new multi-scale feature fusion (MSFF) module to generate multi-scale feature representation by jointly integrating both high-level semantics and low-level details. Secondly, we design a prior-enhanced spatial attention (PSA) module to learn the long-range correlation between objects from different spatial positions in images to enhance the model performance. Thirdly, we devise a prior-enhanced channel attention (PCA) module to capture the inter-dependencies between different channel maps, thus effectively improving the correlation between semantic categories. It is worth noting that PSA module and PCA module complement and promote each other to further augment the feature representations. Finally, the outputs of these two attention modules are fused to obtain the final features for classification. Performance evaluation experiments are conducted on MS-COCO 2014, PASCAL VOC 2007 and VG-500 datasets, demonstrating that DATran model achieves better performance than current state-of-the-art models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "49774293",
                    "name": "Zhijie Zheng"
                },
                {
                    "authorId": "2057239241",
                    "name": "Tao Su"
                },
                {
                    "authorId": "145309512",
                    "name": "Hai Hu"
                }
            ]
        },
        {
            "paperId": "fc6604fd04d34ff96887712e42b6639a2588995c",
            "title": "Mining Semantic Information With Dual Relation Graph Network for Multi-Label Image Classification",
            "abstract": "The purpose of multi-label image classification is to assign multiple labels for multiple objects presented in one image. Recent research efforts exploit graph convolution network (GCN) to learn the label co-occurrence dependencies for enhancing the semantic representation. Although these methods have achieved promising results, they can not capture the intrinsic correlation between objects in images and do not consider the inter-channel relationship. In addition, the previous methods treat each single image independently and fail to explore the relationship between different images. To address the above challenges, we propose a novel Dual Relation Graph Network (DRGN) model, which adopts a double branch structure to excavate rich semantic information from intra-image and cross-image simultaneously. Specifically, we first develop an intra-image channel-relation mining (ICM) module to mine the inter-channel relationship in features while learning the importance of different channels. Secondly, we design a new GCN-based intra-image spatial-relation exploring (ISE) module to capture the correlation between objects in individual image. Notably, ISE module and ICM module can complement and promote each other from the spatial and channel dimensions of images to improve the correlation between objects in individual image. Thirdly, we propose a novel GCN-based cross-image semantic learning (CSL) module to learn the semantic relationship between different images in the mini-batch. Through graph reasoning, our CSL module can iteratively refine input image features by acquiring common semantic information from other images in the mini-batch. Extensive experiments on the MS-COCO 2014, PASCAL VOC 2007, and VG-500 datasets demonstrate that the proposed DRGN model outperforms current state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "49408564",
                    "name": "Weitao Jiang"
                },
                {
                    "authorId": "2547930",
                    "name": "Dihu Chen"
                },
                {
                    "authorId": "2153821312",
                    "name": "Haifeng Hu"
                },
                {
                    "authorId": "2057239241",
                    "name": "Tao Su"
                }
            ]
        },
        {
            "paperId": "019024ab0430e9575d597460c45f1dc7c856ce08",
            "title": "Global Dynamics of an Oligopoly Game Model with Nonlinear Costs and Strategic Delegation",
            "abstract": "A dynamic oligopoly game model with nonlinear cost and strategic delegation is built on the basis of isoelastic demand in this paper. And the dynamic characteristics of this game model are investigated. The local stability of the boundary equilibrium points is analyzed by means of the stability theory and Jacobian matrix, and the stability region of the Nash equilibrium point is obtained by Jury criterion. It is concluded that the system may lose stability through Flip bifurcation and Neimark\u2013Sacker bifurcation. And the effects of speed of adjustment, price elasticity, profit weight coefficient and marginal cost on the system stability are discussed through numerical simulation. After that, the coexistence of attractors is analyzed through the basin of attraction, where multiple stability always means path dependence, implying that the long-term behavior of enterprises is strongly affected by historical contingency. In other words, a small perturbation of the initial conditions will have a significant impact on the system. In addition, the global dynamical behavior of the system is analyzed by using the critical curves, the basin of attraction, absorbing areas and a noninvertible map, revealing that three global bifurcations, the first two of which are caused by the interconversion of simply-connected and multiply-connected regions in the basin of attraction, and the third global bifurcation, that is, the final bifurcation is caused by the contact between attractors and the boundary of the basin of attraction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "2155434295",
                    "name": "Yuxia Liu"
                },
                {
                    "authorId": "2133696161",
                    "name": "Rui Xue"
                }
            ]
        },
        {
            "paperId": "019b5cb9f91114c3e0e4a3f6b85cc4b0ae706264",
            "title": "BrainCLIP: Bridging Brain and Visual-Linguistic Representation via CLIP for Generic Natural Visual Stimulus Decoding from fMRI",
            "abstract": "Due to the lack of paired samples and the low signal-to-noise ratio of functional MRI (fMRI) signals, reconstructing perceived natural images or decoding their semantic contents from fMRI data are challenging tasks. In this work, we propose, for the first time, a task-agnostic fMRI-based brain decoding model, BrainCLIP, which leverages CLIP's cross-modal generalization ability to bridge the modality gap between brain activity, image, and text. Our experiments demonstrate that CLIP can act as a pivot for generic brain decoding tasks, including zero-shot visual categories decoding, fMRI-image/text matching, and fMRI-to-image generation. Specifically, BrainCLIP aims to train a mapping network that transforms fMRI patterns into a well-aligned CLIP embedding space by combining visual and textual supervision. Our experiments show that this combination can boost the decoding model's performance on certain tasks like fMRI-text matching and fMRI-to-image generation. On the zero-shot visual category decoding task, BrainCLIP achieves significantly better performance than BraVL, a recently proposed multi-modal method specifically designed for this task. BrainCLIP can also reconstruct visual stimuli with high semantic fidelity and establishes a new state-of-the-art for fMRI-based natural image reconstruction in terms of high-level semantic features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159087975",
                    "name": "Yulong Liu"
                },
                {
                    "authorId": "2034348628",
                    "name": "Yongqiang Ma"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "2894321",
                    "name": "Guibo Zhu"
                },
                {
                    "authorId": "2144620206",
                    "name": "Nanning Zheng"
                }
            ]
        },
        {
            "paperId": "0862e7a906974e7e65855688c1e9b92d7818857c",
            "title": "Influence of microstructure parameters and magnetic intensity on flexible pressure sensor with variable stiffness",
            "abstract": "This paper systematically studies the Influence of microstructure parameters and magnetic intensity on flexible pressure sensor with variable stiffness. As for the fabrication, we firstly fabricate the microstructure array with magnetic induction characteristic by 3D dynamic laser, and than sputter and pattern a pair of 80 nm thick Au electrodes on PET film. Finally, we package the microstructure array and PET film to get a variable stiffness flexible pressure sensor. The stiffness of the magnetically induced microstructure can be increased by applying a magnetic field. The performance of the sensor was tested under different magnetic intensity. The experimental results show that when the magnetic intensity is 0 mT, the sensor had higher sensitivity under low pressure load, but the linearity became worse with the continuous increase of pressure load. When the magnetic intensity is 250 mT, the sensitivity of the sensor decreases under low pressure load, but it had good linearity under both low and high pressure load.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144455395",
                    "name": "Xinying Li"
                },
                {
                    "authorId": "144354679",
                    "name": "Tian Xie"
                },
                {
                    "authorId": "38656543",
                    "name": "Wenjun Xu"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                }
            ]
        },
        {
            "paperId": "1e4c49c9c93678dec95326ce25715fd2a1e64192",
            "title": "Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model",
            "abstract": "Pretrained language models have achieved remarkable success in various natural language processing tasks. However, pretraining has recently shifted toward larger models and larger data, and this has resulted in significant computational and energy costs. In this paper, we propose Influence Subset Selection (ISS) for language model, which explicitly utilizes end-task knowledge to select a tiny subset of the pretraining corpus. Specifically, the ISS selects the samples that will provide the most positive influence on the performance of the end-task. Furthermore, we design a gradient matching based influence estimation method, which can drastically reduce the computation time of influence. With only 0.45% of the data and a three-orders-of-magnitude lower computational cost, ISS outperformed pretrained models (e.g., RoBERTa) on eight datasets covering four domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118451107",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "47835189",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2119617269",
                    "name": "Jie Zhou"
                },
                {
                    "authorId": "2181306462",
                    "name": "Songyang Gao"
                },
                {
                    "authorId": null,
                    "name": "Junzhe Wang"
                },
                {
                    "authorId": "47473887",
                    "name": "Menghan Zhang"
                },
                {
                    "authorId": "143856160",
                    "name": "Xiang Gao"
                },
                {
                    "authorId": "2144861665",
                    "name": "Yunwen Chen"
                },
                {
                    "authorId": "2067331064",
                    "name": "Tao Gui"
                }
            ]
        },
        {
            "paperId": "1f0c37f78d20022f827805a8b109cd5be86d47b4",
            "title": "A Flexible Multimodal Sensor for Fully Decoupled Crosstalk-Free Pressure and Temperature Sensing via Laser Direct Writing",
            "abstract": "This paper presents a flexible multimodal all-in-one structure sensor for pressure and temperature sensing via an ultraviolet (UV) nanosecond laser. To achieve temperature sensing, we laser patterned the flexible thermoelectric generator with the graphene film. Then, we prepared Carbon Powder-Carbon Nanotube/Polydimethylsiloxane (CP-CNT/PDMS) conducting polymers based on the principle of piezoresistive effect, and then fabricated microcone structures using UV laser as pressure-sensing layers. Experimental results show that our sensor can distinguish pressure and temperature signals with only a single channel signal acquisition. Raman spectroscopy analysis shows that P-type doping of graphene films can be performed using FeCl3, and the power factor of thermoelectric generators is four times higher than that before doping. Finite element analysis (FEA) results show a microcone array with a height of 500 \u03bcm and a width of 100 \u03bcm exhibit optimized sensitivity (sensitivity of 0.587 kPa$^{-1}$) and detection range (range of 160 kPa)",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2212834120",
                    "name": "Jincheng Wang"
                },
                {
                    "authorId": "2118230344",
                    "name": "Rui Chen"
                },
                {
                    "authorId": "2068287418",
                    "name": "Tao Luo"
                },
                {
                    "authorId": "2152558533",
                    "name": "Linjing Wu"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                }
            ]
        },
        {
            "paperId": "2b9ca9bf96871c0bac1b476aa549b976c73b3432",
            "title": "An adaptive incremental TSK fuzzy system based on stochastic configuration and its approximation capability analysis",
            "abstract": "The aim of this study is to improve randomized methods for designing a Takagi-Sugeno-Kang (TSK) fuzzy system. A novel adaptive incremental TSK fuzzy system based on stochastic configuration, named stochastic configuration fuzzy system (SCFS), is proposed in this paper. The proposed SCFS determines the appropriate number of fuzzy rules in TSK fuzzy system by incremental learning approach. From the initial system, new fuzzy rules are added incrementally to improve the system performance until the specified performance is achieved. In the process of generation of fuzzy rules, the stochastic configuration supervision mechanism is applied to ensure that the addition of fuzzy rules can continuously improve the performance. The premise parameters of new adding fuzzy rules are randomly assigned adaptively under the supervisory mechanism, and the consequent parameters are evaluated by Moore-Penrose generalized inverse. It has been proved theoretically that the supervisory mechanism can help to ensure the universal approximation of SCFS. The proposed SCFS can reach any predetermined tolerance level when there are enough fuzzy rules, and the training process is finite. A series of synthetic data and benchmark datasets are used to verify SCFS\u2019s performance. According to the experimental results, SCFS achieves satisfactory prediction accuracy compared to other models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "1739297",
                    "name": "Degang Wang"
                },
                {
                    "authorId": "2108579304",
                    "name": "Hongxing Li"
                },
                {
                    "authorId": "2130015187",
                    "name": "Menghong Bao"
                }
            ]
        },
        {
            "paperId": "3607b41048c71f806ee3a18960b14900bf84cfef",
            "title": "Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations",
            "abstract": "Extracting generalized and robust representations is a major challenge in emotion recognition in conversations (ERC). To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations in a supervised manner. SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model\u2019s context robustness. Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC. Experiments on three datasets show that SACL-LSTM achieves state-of-the-art performance on ERC. Extended experiments prove the effectiveness of SACL and CAT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120427046",
                    "name": "Dou Hu"
                },
                {
                    "authorId": "2075376745",
                    "name": "Yinan Bao"
                },
                {
                    "authorId": "12660091",
                    "name": "Lingwei Wei"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                },
                {
                    "authorId": "2115190434",
                    "name": "Song Hu"
                }
            ]
        },
        {
            "paperId": "487a049967065ea49359ce4e5fa501a24e504d9c",
            "title": "LKAT-GAN: A GAN for Thermal Infrared Image Colorization Based on Large Kernel and AttentionUNet-Transformer",
            "abstract": "Because thermal infrared (TIR) images are not affected by light and foggy environments, which are widely used in various night traffic scenarios. Especially, thermal infrared images also play an important role in autonomous vehicles. However, low contrast and lack of chromaticity have always been their problems. Image colorization is a vital technique to improve the quality of TIR images, which is beneficial to human interpretation and downstream tasks. Despite thermal infrared image colorization methods have been rapidly improved, the detail blurriness and color distortion in colorized images remain under-addressed. Mostly because these methods cannot effectively extract the ambiguous feature information of TIR images. Hence, we propose a large kernel (LK) U-Net and Attention_U-Net-Transformer (ViT-Based) based generative adversarial network. An LK_U-Net is designed to extract the feature of TIR images. Then, a branch structure composed of Attention_U-Net and ViT-Based can provide the network with semantic information from different perspectives to decode features. In addition, a composite loss function is employed to ensure the network generates a high-quality colorized image. The proposed method is evaluated on KAIST and IRVI datasets. Experimental results demonstrate the superiority of the proposed LKAT-GAN over other methods for the task of thermal infrared image colorization. The code is available at https://github.com/jinxinhuo/LKAT-GAN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6392800",
                    "name": "Youwei He"
                },
                {
                    "authorId": "2149170644",
                    "name": "Xin Jin"
                },
                {
                    "authorId": "2090288234",
                    "name": "Qian Jiang"
                },
                {
                    "authorId": "2202349129",
                    "name": "Zien Cheng"
                },
                {
                    "authorId": "1829410",
                    "name": "Puming Wang"
                },
                {
                    "authorId": "101829183",
                    "name": "Wei Zhou"
                }
            ]
        }
    ]
}