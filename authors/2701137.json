{
    "authorId": "2701137",
    "papers": [
        {
            "paperId": "05939430569cc29fd0b9b3f16eec4061d59b4459",
            "title": "Components.js: Semantic dependency injection",
            "abstract": "A common practice within object-oriented software is using composition to realize complex object behavior in a reusable way. Such compositions can be managed by Dependency Injection (DI), a popular technique in which components only depend on minimal interfaces and have their concrete dependencies passed into them. Instead of requiring program code, this separation enables describing the desired instantiations in declarative configuration files, such that objects can be wired together automatically at runtime. Configurations for existing DI frameworks typically only have local semantics, which limits their usage in other contexts. Yet some cases require configurations outside of their local scope, such as for the reproducibility of experiments, static program analysis, and semantic workflows. As such, there is a need for globally interoperable, addressable, and discoverable configurations, which can be achieved by leveraging Linked Data. We created Components.js as an open-source semantic DI framework for TypeScript and JavaScript applications, providing global semantics via Linked Data-based configuration files. In this article, we report on the Components.js framework by explaining its architecture and configuration, and discuss its impact by mentioning where and how applications use it. We show that Components.js is a stable framework that has seen significant uptake during the last couple of years. We recommend it for software projects that require high flexibility, configuration without code changes, sharing configurations with others, or applying these configurations in other contexts such as experimentation or static program analysis. We anticipate that Components.js will continue driving concrete research and development projects that require high degrees of customization to facilitate experimentation and testing, including the Comunica query engine and the Community Solid Server for decentralized data publication.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "32435123",
                    "name": "J. Herwegen"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "0ab125f11af418c598b36f108d43dd1d3d753139",
            "title": "Event Notifications in Value-Adding Networks",
            "abstract": ", Abstract. Linkages between research outputs are crucial in the scholarly knowledge graph. They include online citations, but also links between versions that di\ufb00er according to various dimensions and links to resources that were used to arrive at research results. In current scholarly communication systems this information is only made available post factum and is obtained via elaborate batch processing. In this paper we report on work aimed at making linkages available in real-time, in which an alternative, decentralised scholarly communication network is considered that consists of interacting data nodes that host artifacts and service nodes that add value to artifacts. The \ufb01rst result of this work, the \u201cEvent Noti\ufb01cations in Value-Adding Networks\u201d speci\ufb01cation, details interoperability requirements for the exchange real-time life-cycle information pertaining to artifacts using Linked Data Noti\ufb01cations. In an experiment, we applied our speci\ufb01cation to one particular use-case: distributing Scholix data-literature links to a network of Belgian institutional repositories by a national service node. The results of our experiment con\ufb01rm the potential of our approach and provide a framework to create a network of interacting nodes implementing the core scholarly functions certi\ufb01cation, awareness and archiving) in a decentralized and decoupled way.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2911425",
                    "name": "Patrick Hochstenbach"
                },
                {
                    "authorId": "8050194",
                    "name": "H. Sompel"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "40580115",
                    "name": "R. Dedecker"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "77ba60177e4577b6fbf705fdb52bc1be74f05cef",
            "title": "Optimizing Approximate Membership Metadata in Triple Pattern Fragments for Clients and Servers",
            "abstract": ".",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "32435123",
                    "name": "J. Herwegen"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "87f50273d069a12875df8da025c77ed9114bb2c5",
            "title": "Greater Control and Transparency in Personal Data Processing",
            "abstract": "Although the European General Data Protection Regulation affords data subjects more control over how their \npersonal data is stored and processed, there is a need for technical solutions to support these legal rights. \nIn this position paper we assess the level of control, transparency and compliance offered by three different \napproaches (i.e., defacto standard, SPECIAL, Solid). We propose a layered decentralised architecture based on \ncombining SPECIAL and Solid. Finally, we introduce our usage control framework, which we use to compare \nand contrast the level of control and compliance offered by the four different approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3238386",
                    "name": "Giray Havur"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "2601335",
                    "name": "S. Kirrane"
                }
            ]
        },
        {
            "paperId": "b7c62dc6c319908239447c0231eb02b80fa0777f",
            "title": "Distributed Continuous Home Care Provisioning through Personalized Monitoring & Treatment Planning",
            "abstract": "In healthcare, the aging of the population is resulting in a gradual shift from residential care to home care, requiring reliable follow-up of elderly people by a whole network of care providers. The environment of these patients is increasingly being equipped with different monitoring devices, which allow to obtain insight into the current condition of patient & environment. However, current monitoring platforms that support care providers are centralized and not personalized, reducing performance, scalability, autonomy and privacy. Because the available data is only exposed through custom APIs, profile knowledge cannot be efficiently exchanged, which is required to provide optimal care. Therefore, this paper presents a distributed data-driven platform, built on Semantic Web technologies, that enables the integration of all profile knowledge in order to deliver personalized continuous home care. It provides a distributed smart monitoring service, which allows to locally monitor only the relevant sensors according to the patient\u2019s profile, and infer personalized decisions when analyzing events. Moreover, it provides a medical treatment planning service, which composes treatment plans tailored to each patient, including personalized quality of service parameters allowing a doctor to select the optimal plan. To illustrate how the platform delivers these services, the paper also presents a demonstrator using a realistic home care scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40975212",
                    "name": "Mathias De Brouwer"
                },
                {
                    "authorId": "33122761",
                    "name": "P. Bonte"
                },
                {
                    "authorId": "38127359",
                    "name": "D\u00f6rthe Arndt"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1715957",
                    "name": "F. Turck"
                },
                {
                    "authorId": "1726557",
                    "name": "F. Ongenae"
                }
            ]
        },
        {
            "paperId": "c4cbd23a3421dde84c95613418ee48d28a419503",
            "title": "Context-Aware Route Planning: A Personalized and Situation-Aware Multi-Modal Transport Routing approach",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33122761",
                    "name": "P. Bonte"
                },
                {
                    "authorId": "40975212",
                    "name": "Mathias De Brouwer"
                },
                {
                    "authorId": "38127359",
                    "name": "D\u00f6rthe Arndt"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1896690",
                    "name": "Pieter Heyvaert"
                },
                {
                    "authorId": "1722023",
                    "name": "Anastasia Dimou"
                },
                {
                    "authorId": "2370758",
                    "name": "Pieter Colpaert"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "1715957",
                    "name": "F. Turck"
                },
                {
                    "authorId": "1726557",
                    "name": "F. Ongenae"
                }
            ]
        },
        {
            "paperId": "e988a39a2f1271e4b64150430bb4288f720537a2",
            "title": "The Semantic Web identity crisis: In search of the trivialities that never were",
            "abstract": "The focus group method continues to gain applicability in social work research. The article provides the rationale to use focus groups for a variety of research purposes in social work context. It aims at discussing practical aspects that constitute focus group research process. Based on the author\u2019s research experience and common guidelines for focus groups in social research, in addition specific implications coming from social work context are outlined. Though it is considered that focus groups are relatively easy to conduct, the article shows that in practice a researcher has to be aware of possible difficulties as well as alternative approaches towards focus group process. The role of moderator, selection of participants, deciding upon structure as well as technical requirements are discussed in detail. An exemplary framework for focus group discussion is provided for efficient planning and moderating of focus group. The article aims at social work practitioners who may find focus group useful for their research needs providing with tips for efficient practice of focus group research.",
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science",
                "Psychology"
            ],
            "authors": [
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                }
            ]
        },
        {
            "paperId": "051bf926fcdbf6241396f74f92124eecacaf70e2",
            "title": "Discovering Data Sources in a Distributed Network of Heritage Information",
            "abstract": "The Netwerk Digitaal Erfgoed is a Dutch partnership that focuses on improving the visibility, usability and sustainability of digital collections in the cultural heritage sector. The vision is to improve the usability of the data by sur- mounting the borders between the separate collections of the cultural heritage in- stitutions. Key concepts in this vision are the alignment of the data by using shared descriptions (e.g. thesauri), and the publication of the data as Linked Open Data. This demo paper describes a Proof of Concept to test this vision. It uses a register, where only summaries of datasets are stored, instead of all the data. Based on these summaries, a portal can query the register to find what data sources might be of interest, and then query the data directly from the relevant data sources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "67277779",
                    "name": "S. Valk"
                },
                {
                    "authorId": "51914406",
                    "name": "E. Meijers"
                },
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "8050194",
                    "name": "H. Sompel"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "5321404ca1bfde1b1b82b445f1f35f781693daf2",
            "title": "Reflections on: Triple Storage for Random-Access Versioned Querying of RDF Archives",
            "abstract": ".",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "32435123",
                    "name": "J. Herwegen"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        },
        {
            "paperId": "5101e5e9e6d070857e9d730fd37435e1679bdbed",
            "title": "OSTRICH: Versioned Random-Access Triple Store",
            "abstract": "The Linked Open Data cloud is evergrowing and many datasets are frequently being updated. In order to fully exploit the potential of the information that is available in and over historical dataset versions, such as discovering evolution of taxonomies or diseases in biomedical datasets, we need to be able to store and query the different versions of Linked Datasets efficiently. In this demonstration, we introduce OSTRICH, which is an efficient triple store with supported for versioned query evaluation. We demonstrate the capabilities of OSTRICH using a Web-based graphical user interface in which a store can be opened or created. Using this interface, the user is able to query in, between, and over different versions, ingest new versions, and retrieve summarizing statistics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3403873",
                    "name": "Ruben Taelman"
                },
                {
                    "authorId": "2701137",
                    "name": "M. V. Sande"
                },
                {
                    "authorId": "1723397",
                    "name": "R. Verborgh"
                }
            ]
        }
    ]
}