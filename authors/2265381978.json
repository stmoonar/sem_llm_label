{
    "authorId": "2265381978",
    "papers": [
        {
            "paperId": "9b9a614d94bf3a198f0971a63264cf5de0543f53",
            "title": "AnnoCTR: A Dataset for Detecting and Linking Entities, Tactics, and Techniques in Cyber Threat Reports",
            "abstract": "Monitoring the threat landscape to be aware of actual or potential attacks is of utmost importance to cybersecurity professionals. Information about cyber threats is typically distributed using natural language reports. Natural language processing can help with managing this large amount of unstructured information, yet to date, the topic has received little attention. With this paper, we present AnnoCTR, a new CC-BY-SA-licensed dataset of cyber threat reports. The reports have been annotated by a domain expert with named entities, temporal expressions, and cybersecurity-specific concepts including implicitly mentioned techniques and tactics. Entities and concepts are linked to Wikipedia and the MITRE ATT&CK knowledge base, the most widely-used taxonomy for classifying types of attacks. Prior datasets linking to MITRE ATT&CK either provide a single label per document or annotate sentences out-of-context; our dataset annotates entire documents in a much finer-grained way. In an experimental study, we model the annotations of our dataset using state-of-the-art neural models. In our few-shot scenario, we find that for identifying the MITRE ATT&CK concepts that are mentioned explicitly or implicitly in a text, concept descriptions from MITRE ATT&CK are an effective source for training data augmentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265758168",
                    "name": "Lukas Lange"
                },
                {
                    "authorId": "2301552596",
                    "name": "Marc M\u00fcller"
                },
                {
                    "authorId": "104424084",
                    "name": "G. H. Torbati"
                },
                {
                    "authorId": "2697520",
                    "name": "Dragan Milchevski"
                },
                {
                    "authorId": "2295988030",
                    "name": "Patrick Grau"
                },
                {
                    "authorId": "2252806",
                    "name": "S. Pujari"
                },
                {
                    "authorId": "2265381978",
                    "name": "Annemarie Friedrich"
                }
            ]
        },
        {
            "paperId": "219e69f683f56cf2534a283c8d5647d0cb47045e",
            "title": "BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural Sentence Simplification",
            "abstract": "Automatic simplification can help laypeople to comprehend complex scientific text. Language models are frequently applied to this task by translating from complex to simple language. In this paper, we describe our system based on Llama 2, which ranked first in the PLABA shared task addressing the simplification of biomedical text. We find that the large portion of shared tokens between input and output leads to weak training signals and conservatively editing models. To mitigate these issues, we propose sentence-level and token-level loss weights. They give higher weight to modified tokens, indicated by edit distance and edit operations, respectively. We conduct an empirical evaluation on the PLABA dataset and find that both approaches lead to simplifications closer to those created by human annotators (+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x / 1.8x edit distance) compared to the same model fine-tuned with standard cross entropy. We furthermore show that the hyperparameter $\\lambda$ in token-level loss weights can be used to control the edit distance and the simplicity level (FKGL).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265381943",
                    "name": "Valentin Knappich"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2265381978",
                    "name": "Annemarie Friedrich"
                }
            ]
        },
        {
            "paperId": "a5f14c59231de1cfdabb775618cd4a55eecf2e3e",
            "title": "BoschAI @ Causal News Corpus 2023: Robust Cause-Effect Span Extraction using Multi-Layer Sequence Tagging and Data Augmentation",
            "abstract": "Understanding causality is a core aspect of intelligence. The Event Causality Identification with Causal News Corpus Shared Task addresses two aspects of this challenge: Subtask 1 aims at detecting causal relationships in texts, and Subtask 2 requires identifying signal words and the spans that refer to the cause or effect, respectively. Our system, which is based on pre-trained transformers, stacked sequence tagging, and synthetic data augmentation, ranks third in Subtask 1 and wins Subtask 2 with an F1 score of 72.8, corresponding to a margin of 13 pp. to the second-best system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261387974",
                    "name": "Timo Pierre Schrader"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2265758168",
                    "name": "Lukas Lange"
                },
                {
                    "authorId": "2265381978",
                    "name": "Annemarie Friedrich"
                }
            ]
        },
        {
            "paperId": "df4759accf425eb12046a2be264c37ac9baed73e",
            "title": "MuLMS: A Multi-Layer Annotated Text Corpus for Information Extraction in the Materials Science Domain",
            "abstract": "Keeping track of all relevant recent publications and experimental results for a research area is a challenging task. Prior work has demonstrated the efficacy of information extraction models in various scientific areas. Recently, several datasets have been released for the yet understudied materials science domain. However, these datasets focus on sub-problems such as parsing synthesis procedures or on sub-domains, e.g., solid oxide fuel cells. In this resource paper, we present MuLMS, a new dataset of 50 open-access articles, spanning seven sub-domains of materials science. The corpus has been annotated by domain experts with several layers ranging from named entities over relations to frame structures. We present competitive neural models for all tasks and demonstrate that multi-task training with existing related resources leads to benefits.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261387974",
                    "name": "Timo Pierre Schrader"
                },
                {
                    "authorId": "2069766950",
                    "name": "Matteo Finco"
                },
                {
                    "authorId": "49948196",
                    "name": "Stefan Gr\u00fcnewald"
                },
                {
                    "authorId": "2221128531",
                    "name": "Felix Hildebrand"
                },
                {
                    "authorId": "2265381978",
                    "name": "Annemarie Friedrich"
                }
            ]
        }
    ]
}