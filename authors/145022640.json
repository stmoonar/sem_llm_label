{
    "authorId": "145022640",
    "papers": [
        {
            "paperId": "adb93dfc4f6f3731f9561c84797ba27f5ce4ab25",
            "title": "Leveraging Synergies Between AI and Networking to Build Next Generation Edge Networks",
            "abstract": "Networking and Artificial Intelligence (AI) are two of the most transformative information technologies over the last few decades. Building upon the synergies of these two powerful technologies, we envision designing next generation of edge networks to be highly efficient, reliable, robust and secure. To this end, in this paper, we delve into interesting and fundamental research challenges and opportunities that span two major broad and symbiotic areas: AI for Networks and Networks for AI. The former deals with the development of new AI tools and techniques that can enable the next generation AI-assisted networks; while the latter focuses on developing networking techniques and tools that will facilitate the vision of distributed intelligence, resulting in a virtuous research cycle where advances in one will help accelerate advances in the other. A wide range of applications will be further discussed to illustrate the importance of the foundational advances developed in these two areas.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1641386905",
                    "name": "Sen Lin"
                },
                {
                    "authorId": "2211513205",
                    "name": "Ming Shi"
                },
                {
                    "authorId": "144248962",
                    "name": "A. Arora"
                },
                {
                    "authorId": "1679638",
                    "name": "Raef Bassily"
                },
                {
                    "authorId": "1743774",
                    "name": "E. Bertino"
                },
                {
                    "authorId": "1764494",
                    "name": "C. Caramanis"
                },
                {
                    "authorId": "50782989",
                    "name": "K. Chowdhury"
                },
                {
                    "authorId": "1733684",
                    "name": "E. Ekici"
                },
                {
                    "authorId": "1688915",
                    "name": "A. Eryilmaz"
                },
                {
                    "authorId": "1776006",
                    "name": "Stratis Ioannidis"
                },
                {
                    "authorId": "2149818125",
                    "name": "Nan Jiang"
                },
                {
                    "authorId": "144225970",
                    "name": "Gauri Joshi"
                },
                {
                    "authorId": "2076721038",
                    "name": "J. Kurose"
                },
                {
                    "authorId": "2397352",
                    "name": "Yitao Liang"
                },
                {
                    "authorId": "2112411403",
                    "name": "Zhiqiang Lin"
                },
                {
                    "authorId": "2134800521",
                    "name": "Jia Liu"
                },
                {
                    "authorId": "39037167",
                    "name": "M. Liu"
                },
                {
                    "authorId": "145967423",
                    "name": "T. Melodia"
                },
                {
                    "authorId": "2706423",
                    "name": "Aryan Mokhtari"
                },
                {
                    "authorId": "2211574327",
                    "name": "Rob Nowak"
                },
                {
                    "authorId": "47342457",
                    "name": "Sewoong Oh"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                },
                {
                    "authorId": "1798566",
                    "name": "Chunyi Peng"
                },
                {
                    "authorId": "145991708",
                    "name": "H. Seferoglu"
                },
                {
                    "authorId": "1750487",
                    "name": "N. Shroff"
                },
                {
                    "authorId": "1688634",
                    "name": "S. Shakkottai"
                },
                {
                    "authorId": "9169035",
                    "name": "K. Srinivasan"
                },
                {
                    "authorId": "145532827",
                    "name": "Ameet Talwalkar"
                },
                {
                    "authorId": "1688603",
                    "name": "A. Yener"
                },
                {
                    "authorId": "2167030792",
                    "name": "Lei Ying"
                }
            ]
        },
        {
            "paperId": "06b24f253c827fe5192821a75318cbffb7a6c104",
            "title": "Fairness-aware Summarization for Justified Decision-Making",
            "abstract": "In consequential domains such as recidivism prediction, facility inspection, and benefit assignment, it's important for individuals to know the decision-relevant information for the model's prediction. In addition, predictions should be fair both in terms of the outcome and the justification of the outcome. In other words, decision-relevant features should provide sufficient information for the predicted outcome and should be independent of the membership of individuals in protected groups such as race and gender. In this work, we focus on the problem of (un)fairness in the justification of the text-based neural models. We tie the explanatory power of the model to fairness in the outcome and propose a fairness-aware summarization mechanism to detect and counteract the bias in such models. Given a potentially biased natural language explanation for a decision, we use a multi-task neural model and an attribution mechanism based on integrated gradients to extract high-utility and low-bias justifications in form of a summary. The extracted summary is then used for training a model to make decisions for individuals. Results on several real world datasets suggest that our method drastically limits the demographic leakage in the input (fairness in justification) while moderately enhancing the fairness in the outcome. Our model is also effective in detecting and counteracting several types of data poisoning attacks that synthesize race-coded reasoning or irrelevant justifications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "115262146",
                    "name": "Moniba Keymanesh"
                },
                {
                    "authorId": "1399635506",
                    "name": "T. Berger-Wolf"
                },
                {
                    "authorId": "1689233",
                    "name": "Micha Elsner"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                }
            ]
        },
        {
            "paperId": "0d7b21d7ec37bf69d0baec2b4eb0a8f5a1bc5a92",
            "title": "FACE-KEG: Fact Checking Explained using KnowledgE Graphs",
            "abstract": "In recent years, a plethora of fact checking and fact verification techniques have been developed to detect the veracity or factuality of online information text for various applications. However, limited efforts have been undertaken to understand the interpretability of such veracity detection, i.e. explaining why a particular piece of text is factually correct or incorrect. In this work, we seek to bridge this gap by proposing a technique, FACE-KEG, to automatically perform explainable fact checking. Given an input fact or claim, our proposed model constructs a relevant knowledge graph for it from a large-scale structured knowledge base. This graph is encoded via a novel graph transforming encoder. Our model also simultaneously retrieves and encodes relevant textual context about the input text from the knowledge base. FACE-KEG then jointly exploits both the concept-relationship structure of the knowledge graph as well as semantic contextual cues in order to (i) detect the veracity of an input fact, and (ii) generate a human-comprehensible natural language explanation justifying the fact's veracity. We conduct extensive experiments on three large-scale datasets, and demonstrate the effectiveness of FACE-KEG while performing fact checking. Automatic and human evaluations further show that FACE-KEG significantly outperforms competitive baselines in learning concise, coherent and informative explanations for the input facts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "19304470",
                    "name": "Nikhita Vedula"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                }
            ]
        },
        {
            "paperId": "325cb1fd2aff335c4aa04d95e1d9d14e9a6b5b2d",
            "title": "Evaluating Biomedical BERT Models for Vocabulary Alignment at Scale in the UMLS Metathesaurus",
            "abstract": "The current UMLS (Unified Medical Language System) Metathesaurus construction process for integrating over 200 biomedical source vocabularies is expensive and error-prone as it relies on the lexical algorithms and human editors for deciding if the two biomedical terms are synonymous. Recent advances in Natural Language Processing such as Transformer models like BERT and its biomedical variants with contextualized word embeddings have achieved state-of-the-art (SOTA) performance on downstream tasks. We aim to validate if these approaches using the BERT models can actually outperform the existing approaches for predicting synonymy in the UMLS Metathesaurus. In the existing Siamese Networks with LSTM and BioWordVec embeddings, we replace the BioWordVec embeddings with the biomedical BERT embeddings extracted from each BERT model using different ways of extraction. In the Transformer architecture, we evaluate the use of the different biomedical BERT models that have been pre-trained using different datasets and tasks. Given the SOTA performance of these BERT models for other downstream tasks, our experiments yield surprisingly interesting results: (1) in both model architectures, the approaches employing these biomedical BERT-based models do not outperform the existing approaches using Siamese Network with BioWordVec embeddings for the UMLS synonymy prediction task, (2) the original BioBERT large model that has not been pre-trained with the UMLS outperforms the SapBERT models that have been pre-trained with the UMLS, and (3) using the Siamese Networks yields better performance for synonymy prediction when compared to using the biomedical BERT models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27549522",
                    "name": "Goonmeet Bajaj"
                },
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "79596923",
                    "name": "Vishesh Javangula"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                },
                {
                    "authorId": "144463965",
                    "name": "A. Sheth"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "4abb0cd9d069cc000302610eca779c0278075bf7",
            "title": "Privacy Policy Question Answering Assistant: A Query-Guided Extractive Summarization Approach",
            "abstract": "Existing work on making privacy policies accessible has explored new presentation forms such as color-coding based on the risk factors or summarization to assist users with conscious agreement. To facilitate a more personalized interaction with the policies, in this work, we propose an automated privacy policy question answering assistant that extracts a summary in response to the input user query. This is a challenging task because users articulate their privacy-related questions in a very different language than the legal language of the policy, making it difficult for the system to understand their inquiry. Moreover, existing annotated data in this domain are limited. We address these problems by paraphrasing to bring the style and language of the user's question closer to the language of privacy policies. Our content scoring module uses the existing in-domain data to find relevant information in the policy and incorporates it in a summary. Our pipeline is able to find an answer for 89% of the user queries in the privacyQA dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "115262146",
                    "name": "Moniba Keymanesh"
                },
                {
                    "authorId": "1689233",
                    "name": "Micha Elsner"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                }
            ]
        },
        {
            "paperId": "4ef7d8d446e87e9973347a60f3da5c67e052ca9d",
            "title": "Iter8: Online Experimentation in the Cloud",
            "abstract": "Online experimentation is an agile software development practice that plays an essential role in enabling rapid innovation. Existing solutions for online experimentation in Web and mobile applications are unsuitable for cloud applications. There is a need for rethinking online experimentation in the cloud to advance the state-of-the-art by considering the unique challenges posed by cloud environments. In this paper, we introduce Iter8, an open-source system that enables practitioners to deliver code changes to cloud applications in an agile manner while minimizing risk. Iter8 embodies our novel mathematical formulation built on online Bayesian learning and multi-armed bandit algorithms to enable online experimentation tailored for the cloud, considering both SLOs and business concerns, unlike existing solutions. Using Iter8, practitioners can safely and rapidly orchestrate various types of online experiments, gain key insights into the behavior of cloud applications, and roll out the optimal versions in an automated and statistically rigorous manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1404234289",
                    "name": "M. Toslali"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                },
                {
                    "authorId": "2151029768",
                    "name": "F\u00e1bio Oliveira"
                },
                {
                    "authorId": "2146284642",
                    "name": "Hai Huang"
                },
                {
                    "authorId": "144792142",
                    "name": "A. Coskun"
                }
            ]
        },
        {
            "paperId": "6540eac26bb52395f205286dbd9498ebec007e30",
            "title": "Open Intent Extraction from Natural Language Interactions (Extended Abstract)",
            "abstract": "Accurately discovering user intents from their written or spoken language plays a critical role in natural language understanding and automated dialog response. Most existing research models this as a classification task with a single intent label per utterance. Going beyond this formulation, we define and investigate a new problem of open intent discovery. It involves discovering one or more generic intent types from text utterances, that may not have been encountered during training. We propose a novel, domain-agnostic approach, OPINE, which formulates the problem as a sequence tagging task in an open-world setting. It employs a CRF on top of a bidirectional LSTM to extract intents in a consistent format, subject to constraints among intent tag labels. We apply multi-headed self-attention and adversarial training to effectively learn dependencies between distant words, and robustly adapt our model across varying domains. We also curate and release an intent-annotated dataset of 25K real-life utterances spanning diverse domains. Extensive experiments show that OPINE outperforms state-of-art baselines by 5-15% F1 score.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "19304470",
                    "name": "Nikhita Vedula"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "8394636",
                    "name": "Pranav Maneriker"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                }
            ]
        },
        {
            "paperId": "8157b36966a2390fbd66857a942eb1eccd14ee87",
            "title": "Semi-Supervised Deep Learning for Multiplex Networks",
            "abstract": "Multiplex networks are complex graph structures in which a set of entities are connected to each other via multiple types of relations, each relation representing a distinct layer. Such graphs are used to investigate many complex biological, social, and technological systems. In this work, we present a novel semi-supervised approach for structure-aware representation learning on multiplex networks. Our approach relies on maximizing the mutual information between local node-wise patch representations and label correlated structure-aware global graph representations to model the nodes and cluster structures jointly. Specifically, it leverages a novel cluster-aware, node-contextualized global graph summary generation strategy for effective joint-modeling of node and cluster representations across the layers of a multiplex network. Empirically, we demonstrate that the proposed architecture outperforms state-of-the-art methods in a range of tasks: classification, clustering, visualization, and similarity search on seven real-world multiplex networks for various experiment settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2789681",
                    "name": "Anasua Mitra"
                },
                {
                    "authorId": "31786918",
                    "name": "Priyesh Vijayan"
                },
                {
                    "authorId": "2123019005",
                    "name": "Ranbir Sanasam"
                },
                {
                    "authorId": "145550931",
                    "name": "D. Goswami"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                },
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                }
            ]
        },
        {
            "paperId": "8bc775fdd7efc6c7ccf08c31a407e42a99374797",
            "title": "StyleML: Stylometry with Structure and Multitask Learning for Darkweb Markets",
            "abstract": "Darknet market forums are frequently used to exchange illegal goods and services between parties who use encryption to conceal their identities. The Tor network is used to host these markets, which guarantees additional anonymization from IP and location tracking, making it challenging to link across malicious users using multiple accounts (sybils). Additionally, users migrate to new forums when one is closed, making it dif\ufb01cult to link users across multiple forums. We develop a novel stylometry-based multitask learning approach for natural language and interaction modeling using graph embeddings to construct low-dimensional representations of short episodes of user activity for authorship attribution. We provide a comprehensive evaluation of our methods across four different darknet forums demonstrating its ef\ufb01cacy over the state-of-the-art, with a lift of up to 2.5X on Mean Retrieval Rank and 2X on Recall@10.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8394636",
                    "name": "Pranav Maneriker"
                },
                {
                    "authorId": "3129825",
                    "name": "Yuntian He"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                }
            ]
        },
        {
            "paperId": "9e6b5513c75938beda5b29b0a03744c62e2385ad",
            "title": "A Tight Bound for Stochastic Submodular Cover",
            "abstract": "We show that the Adaptive Greedy algorithm of Golovin and Krause achieves an approximation bound of (ln(Q/\u03b7)+1) for Stochastic Submodular Cover: here Q is the \u201cgoal value\u201d and \u03b7 is the minimum gap between Q and any attainable utility value Q\u2032<Q. Although this bound was claimed by Golovin and Krause in the original version of their paper, the proof was later shown to be incorrect by Nan and Saligrama. The subsequent corrected proof of Golovin and Krause gives a quadratic bound of (ln(Q/\u03b7)+1). A bound of 56(ln(Q/\u03b7)+1) is implied by work of Im et al. Other bounds for the problem depend on quantities other than Q and \u03b7. Our bound restores the original bound claimed by Golovin and Krause, generalizing the well-known (ln m+1) approximation bound on the greedy algorithm for the classical Set Cover problem, where m is the size of the ground set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1688713",
                    "name": "L. Hellerstein"
                },
                {
                    "authorId": "1989919",
                    "name": "Devorah Kletenik"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                }
            ]
        }
    ]
}