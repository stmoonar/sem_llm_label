{
    "authorId": "2065394520",
    "papers": [
        {
            "paperId": "ee3dd026b7158278e2da9419071852c67ebd6add",
            "title": "A Reference Model for Collaborative Business Intelligence Virtual Assistants",
            "abstract": "Collaborative Business Analysis (CBA) is a methodology that involves bringing together different stakeholders, including business users, analysts, and technical specialists, to collaboratively analyze data and gain insights into business operations. The primary objective of CBA is to encourage knowledge sharing and collaboration between the different groups involved in business analysis, as this can lead to a more comprehensive understanding of the data and better decision-making. CBA typically involves a range of activities, including data gathering and analysis, brainstorming, problem-solving, decision-making and knowledge sharing. These activities may take place through various channels, such as in-person meetings, virtual collaboration tools or online forums. This paper deals with virtual collaboration tools as an important part of Business Intelligence (BI) platform. Collaborative Business Intelligence (CBI) tools are becoming more user-friendly, accessible, and flexible, allowing users to customize their experience and adapt to their specific needs. The goal of a virtual assistant is to make data exploration more accessible to a wider range of users and to reduce the time and effort required for data analysis. It describes the unified business intelligence semantic model, coupled with a data warehouse and collaborative unit to employ data mining technology. Moreover, we propose a virtual assistant for CBI and a reference model of virtual tools for CBI, which consists of three components: conversational, data exploration and recommendation agents. We believe that the allocation of these three functional tasks allows you to structure the CBI issue and apply relevant and productive models for human-like dialogue, text-to-command transferring, and recommendations simultaneously. The complex approach based on these three points gives the basis for virtual tool for collaboration. CBI encourages people, processes, and technology to enable everyone sharing and leveraging collective expertise, knowledge and data to gain valuable insights for making better decisions. This allows to respond more quickly and effectively to changes in the market or internal operations and improve the progress.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2092735534",
                    "name": "O. Cherednichenko"
                },
                {
                    "authorId": "144031993",
                    "name": "M. Fahad"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                }
            ]
        },
        {
            "paperId": "15625ba091bdef1a617d542fbe170aef186f34fd",
            "title": "Diversity and Inclusion Activities in EGC - A 2022 Report",
            "abstract": "EGC (\"Extraction et Gestion des Connaissances\"1 in French) started in 2001 and is the reference conference for the french community in Knowledge Extraction and Management (equivalent to the French KDD).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1699192",
                    "name": "A. Bonifati"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "2262635584",
                    "name": "\u00c9. Fromont"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "2482136",
                    "name": "G. Melan\u00e7on"
                },
                {
                    "authorId": "1804438",
                    "name": "F. S\u00e8des"
                },
                {
                    "authorId": "2955369",
                    "name": "Arnaud Soulet"
                },
                {
                    "authorId": "1693038",
                    "name": "A. Termier"
                }
            ]
        },
        {
            "paperId": "56043feab68bc53af70d1b5db1551c9d6ecc55f8",
            "title": "The Collaborative Business Intelligence Ontology (CBIOnt)",
            "abstract": "In the current era, many disciplines are seen devoted towards ontology development for their domains with the intention of creating, disseminating and managing resource descriptions of their domain knowledge into machine understandable and processable manner. Ontology construction is a difficult group activity that involves many people with the different expertise. Generally, domain experts are not familiar with the ontology implementation environments and implementation experts do not have all the domain knowledge. We have designed Collaborative Business Intelligence Ontology (CBIOnt) for BI4People project. In this paper, we present CBIOnt that is OWL 2 DL ontology for the description of collaborative session between different collaborators working together on the business intelligent platform. As the collaborative session between various collaborators belongs to some collaborative form, phase and research aspect, therefore CBIOnt captures this knowledge along with the collaborative session content (comments, questions, answers, etc.) so that one can inference various types of information stored on ontologies when required. In addition, it stores the location and temporal-spatial information about the collaboration held between collaborators. We believe CBIOnt serves as a formal framework for dealing with the collaborative session taken place among collaborators on the semantic Web.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144031993",
                    "name": "M. Fahad"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                }
            ]
        },
        {
            "paperId": "e0dd3bfe7436df66424d9c57dec2bd1a5f3c7dbf",
            "title": "Promoting equity, diversity and inclusion: policies, strategies and future directions in higher education, research communities and business",
            "abstract": "This paper provides a multi-perspective vision of diversity and inclusion (D&I) projects aiming to promote equity in organisations seeking to build virtuous contexts where people can achieve positive professional and personal objectives. It introduces the understanding of D&I, best practices and outcomes of projects promoted in multicultural organisations, including academia, universities and research centres (Politecnico di Torino, university education in France and the French CNRS) and in leading international companies, namely Accenture and Nestl\u00e9. The paper gathers and extends the discussion and ideas exchanged in the D&I panel of the conference ADBIS-2022.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1393643717",
                    "name": "Genoveva Vargas-Solar"
                },
                {
                    "authorId": "2203091524",
                    "name": "Tania Cerquitelli"
                },
                {
                    "authorId": "2016022",
                    "name": "A. Montorsi"
                },
                {
                    "authorId": "2203093921",
                    "name": "Stefania Salvai"
                },
                {
                    "authorId": "2203123924",
                    "name": "Maria Teresa Sangineti"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                }
            ]
        },
        {
            "paperId": "56937048a72337608d7c04b673f301c04d4928df",
            "title": "HOUDAL: A Data Lake Implemented for Public Housing",
            "abstract": "Like all areas of economic activity, public housing is impacted by the rise of big data. While Business Intelligence and Data Science analyses are more or less mastered by social landlords, combining them inside a shared environment is still a challenge. Moreover, processing big data, such as geographical open data that sometimes exceed the capacity of traditional tools, raises a second issue. To face these problems, we propose to use a data lake, a system in which data of any type can be stored and from which various analyses can be performed. In this paper, we present a real use case on public housing that fueled our motivation to introduce a data lake. We also propose a data lake framework that is versatile enough to meet the challenges induced by the use case. Finally, we present HOUDAL, an implementation of a data lake based on our framework, which is operational and used by a social landlord.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1387993792",
                    "name": "\u00c9tienne Scholly"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1387993681",
                    "name": "\u00c9ric Ferey"
                },
                {
                    "authorId": "7533566",
                    "name": "Sabine Loudcher"
                }
            ]
        },
        {
            "paperId": "b9e0c7fc0d9f19564b8636b4e0a2fbc3da412e6e",
            "title": "Coining goldMEDAL: A New Contribution to Data Lake Generic Metadata Modeling",
            "abstract": "The rise of big data has revolutionized data exploitation practices and led to the emergence of new concepts. Among them, data lakes have emerged as large heterogeneous data repositories that can be analyzed by various methods. An efficient data lake requires a metadata system that addresses the many problems arising when dealing with big data. In consequence, the study of data lake metadata models is currently an active research topic and many proposals have been made in this regard. However, existing metadata models are either tailored for a specific use case or insufficiently generic to manage different types of data lakes, including our previous model MEDAL. In this paper, we generalize MEDAL's concepts in a new metadata model called goldMEDAL. Moreover, we compare goldMEDAL with the most recent state-of-the-art metadata models aiming at genericity and show that we can reproduce these metadata models with goldMEDAL's concepts. As a proof of concept, we also illustrate that goldMEDAL allows the design of various data lakes by presenting three different use cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1387993792",
                    "name": "\u00c9tienne Scholly"
                },
                {
                    "authorId": "134602312",
                    "name": "Pegdwend\u00e9 N. Sawadogo"
                },
                {
                    "authorId": "41158267",
                    "name": "Pengfe\u00ef Liu"
                },
                {
                    "authorId": "1405191306",
                    "name": "Javier-Alfonso Espinosa-Oviedo"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "7533566",
                    "name": "Sabine Loudcher"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "2140018458",
                    "name": "C. No\u00fbs"
                }
            ]
        },
        {
            "paperId": "8565e4428ca7fdee78b19360f8732841e01e00d9",
            "title": "Data lakes for digital humanities",
            "abstract": "Traditional data in Digital Humanities projects bear various formats (structured, semi-structured, textual) and need substantial transformations (encoding and tagging, stemming, lemmatization, etc.) to be managed and analyzed. To fully master this process, we propose the use of data lakes as a solution to data siloing and big data variety problems. We describe data lake projects we currently run in close collaboration with researchers in humanities and social sciences and discuss the lessons learned running these projects.",
            "fieldsOfStudy": [
                "Computer Science",
                "Geography"
            ],
            "authors": [
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "7533566",
                    "name": "Sabine Loudcher"
                },
                {
                    "authorId": "1744754219",
                    "name": "C. No\u00fbs"
                }
            ]
        },
        {
            "paperId": "0b921a2fa6bb3f17a3ab17dc8eb07f1647ba104e",
            "title": "Including Images into Message Veracity Assessment in Social Media",
            "abstract": "The extensive use of social media in the diffusion of information has also laid a fertile ground for the spread of rumors, which could significantly affect the credibility of social media. An ever-increasing number of users post news including, in addition to text, multimedia data such as images and videos. Yet, such multimedia content is easily editable due to the broad availability of simple and effective image and video processing tools. The problem of assessing the veracity of social network posts has attracted a lot of attention from researchers in recent years. However, almost all previous works have focused on analyzing textual contents to determine veracity, while visual contents, and more particularly images, remains ignored or little exploited in the literature. In this position paper, we propose a framework that explores two novel ways to assess the veracity of messages published on social networks by analyzing the credibility of both their textual and visual contents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2078257571",
                    "name": "Abderrazek Azri"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1804741",
                    "name": "Nouria Harbi"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                }
            ]
        },
        {
            "paperId": "8c97f24c6971719630e9b99cece31c7ebd6055fc",
            "title": "Innovative Approaches for efficiently Warehousing Complex Data from the Web",
            "abstract": "Research in data warehousing and OLAP has produced important technologies for the design, management and use of information systems for decision support. With the development of Internet, the availability of various types of data has increased. Thus, users require applications to help them obtaining knowledge from the Web. One possible solution to facilitate this task is to extract information from the Web, transform and load it to a Web Warehouse, which provides uniform access methods for automatic processing of the data. In this chapter, we present three innovative researches recently introduced to extend the capabilities of decision support systems, namely (1) the use of XML as a logical and physical model for complex data warehouses, (2) associating data mining to OLAP to allow elaborated analysis tasks for complex data and (3) schema evolution in complex data warehouses for personalized analyses. Our contributions cover the main phases of the data warehouse design process: data integration and modeling and user driven-OLAP analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "8797781",
                    "name": "Nora Ma\u00efz"
                },
                {
                    "authorId": "2485974",
                    "name": "Hadj Mahboubi"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "7533566",
                    "name": "Sabine Loudcher"
                },
                {
                    "authorId": "1804741",
                    "name": "Nouria Harbi"
                },
                {
                    "authorId": "1735803",
                    "name": "Omar Boussa\u00efd"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                }
            ]
        },
        {
            "paperId": "615d651b89da053ae791b6d15cab0b2bc05a85e5",
            "title": "OLAP Cube-based Graph Approach for Bibliographic Data",
            "abstract": "There is a growing number of di\u000berent research elds that are concerned with bibliographic data analysis. In many cases, data of interest can be described as heterogeneous information networks. To explore knowledge from that networks in a multidimensinal way, OLAP (Online Analytical Processing) analysis helps users to access data from di\u000berent points of views. The ability of OLAP for analyzing classical data is clear. However it must be adapted to provide networked data by considering both nodes and edges. In order to take into account linked data in OLAP on networks, we propose a conceptual graph model to represent bibliographic networks. Then we propose graphs enriched by cubes. Each node and edge of the considered network are described by a cube. It allows the user to quickly analyze the information summarized into cubes. Our proposal also solves the slowly changing dimension problem in OLAP analysis. To illustrate our approach, we integrate three bibliographic databases and a computation process is de ned according to user's needs. Then our implementation shows results on a real data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139984",
                    "name": "Wararat Jakawat"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "7533566",
                    "name": "Sabine Loudcher"
                }
            ]
        },
        {
            "paperId": "e043bd058a0cf14c9339c5e319af18e2ee02bd33",
            "title": "Graphs enriched by cubes for OLAP on bibliographic networks",
            "abstract": "With the recent growth of bibliographic data, many research fields work on defining new techniques for their analysis. In this context, data could be represented as heterogeneous networks. In order to analyse information networks in a multidimensional way, online analytical processing OLAP may be a relevant solution but it must be adapted for networked data by considering nodes and edges. A first approach that has been proposed in the literature consists in building cubes of graphs. In a different and complementary way, our proposal consists in enriching graphs with cubes. Indeed, the nodes or/and edges of the considered network are described by a cube. It allows interesting analyses for the user who can navigate within a graph enriched by cubes according to different granularity levels, with dedicated operators. We implemented our approach and performed an experimental study on a real dataset to show the interest of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139984",
                    "name": "Wararat Jakawat"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "7533566",
                    "name": "Sabine Loudcher"
                }
            ]
        },
        {
            "paperId": "aaa992c424b7a63ced6d84dc08ac2a60d06da4e7",
            "title": "Mention-anomaly-based Event Detection and tracking in Twitter",
            "abstract": "The ever-growing number of people using Twitter makes it a valuable source of timely information. However, detecting events in Twitter is a difficult task, because tweets that report interesting events are overwhelmed by a large volume of tweets on unrelated topics. Existing methods focus on the textual content of tweets and ignore the social aspect of Twitter. In this paper we propose MABED (Mention-Anomaly-Based Event Detection), a novel method that leverages the creation frequency of dynamic links (i.e. mentions) that users insert in tweets to detect important events and estimate the magnitude of their impact over the crowd. The main advantages of MABED over prior works are that (i) it relies solely on tweets, meaning no external knowledge is required, and that (ii) it dynamically estimates the period of time during which each event is discussed rather than assuming a predefined fixed duration. The experiments we conducted on both English and French Twitter data show that the mention-anomaly-based approach leads to more accurate event detection and improved robustness in presence of noisy Twitter content. Last, we show that MABED helps with the interpretation of detected events by providing clear and precise descriptions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1700578",
                    "name": "Adrien Guille"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                }
            ]
        },
        {
            "paperId": "25690550ccbce97eecf5bf1326ac5d1952ee2b15",
            "title": "SONDY: an open source platform for social dynamics mining and analysis",
            "abstract": "This paper describes SONDY, a tool for analysis of trends and dynamics in online social network data. SONDY addresses two audiences: (i) end-users who want to explore social activity and (ii) researchers who want to experiment and compare mining techniques on social data. SONDY helps end-users like media analysts or journalists understand social network users interests and activity by providing emerging topics and events detection as well as network analysis functionalities. To this end, the application proposes visualizations such as interactive time-lines that summarize information and colored user graphs that reflect the structure of the network. SONDY also provides researchers an easy way to compare and evaluate recent techniques to mine social data, implement new algorithms and extend the application without being concerned with how to make it accessible. In the demo, participants will be invited to explore information from several datasets of various sizes and origins (such as a dataset consisting of 7,874,772 messages published by 1,697,759 Twitter users during a period of 7 days) and apply the different functionalities of the platform in real-time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1700578",
                    "name": "Adrien Guille"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1726350",
                    "name": "Hakim Hacid"
                },
                {
                    "authorId": "1678550",
                    "name": "D. Zighed"
                }
            ]
        },
        {
            "paperId": "4a3df0c64d4e786c59334d4ea54c99b1808760a7",
            "title": "Information diffusion in online social networks: a survey",
            "abstract": "Online social networks play a major role in the spread of information at very large scale. A lot of effort have been made in order to understand this phenomenon, ranging from popular topic detection to information diffusion modeling, including influential spreaders identification. In this article, we present a survey of representative methods dealing with these issues and propose a taxonomy that summarizes the state-of-the-art. The objective is to provide a comprehensive analysis and guide of existing efforts around information diffusion in social networks. This survey is intended to help researchers in quickly understanding existing works and possible improvements to bring.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1700578",
                    "name": "Adrien Guille"
                },
                {
                    "authorId": "1726350",
                    "name": "Hakim Hacid"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1678550",
                    "name": "D. Zighed"
                }
            ]
        },
        {
            "paperId": "b3a93448a72078dae5977d6ac50c78ac8e6e0526",
            "title": "An Envisioned Approach for Modeling and Supporting User-Centric Query Activities on Data Warehouses",
            "abstract": "In this vision paper, the authors discuss models and techniques for integrating, processing and querying data, information and knowledge within data warehouses in a user-centric manner. The user-centric emphasis allows us to achieve a number of clear advantages with respect to classical data warehouse architectures, whose most relevant ones are the following: i a unified and meaningful representation of multidimensional data and knowledge patterns throughout the data warehouse layers i.e., loading, storage, metadata, etc; ii advanced query mechanisms and guidance that are capable of extracting targeted information and knowledge by means of innovative information retrieval and data mining techniques. Following this main framework, the authors first outline the importance of knowledge representation and management in data warehouses, where knowledge is expressed by existing ontology or patterns discovered from data. Then, the authors propose a user-centric architecture for OLAP query processing, which is the typical applicative interface to data warehouse systems. Finally, the authors propose insights towards cooperative query answering that make use of knowledge management principles and exploit the peculiarities of data warehouses e.g., multidimensionality, multi-resolution, and so forth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1679110",
                    "name": "Marie-Aude Aufaure"
                },
                {
                    "authorId": "145046124",
                    "name": "A. Cuzzocrea"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "1735147",
                    "name": "R. Missaoui"
                }
            ]
        },
        {
            "paperId": "f4f9c5788b5082b2ed9272e844e5b0a76df904a4",
            "title": "Predicting the Temporal Dynamics of Information Diffusion in Social Networks",
            "abstract": "Online social networks play a major role in the spread of information at very large scale and it becomes essential to provide means to analyse this phenomenon. In this paper we address the issue of predicting the temporal dynamics of the information diffusion process. We develop a graph-based approach built on the assumption that the macroscopic dynamics of the spreading process are explained by the topology of the network and the interactions that occur through it, between pairs of users, on the basis of properties at the microscopic level. We introduce a generic model, called T-BaSIC, and describe how to estimate its parameters from users behaviours using machine learning techniques. Contrary to classical approaches where the parameters are fixed in advance, T-BaSIC's parameters are functions depending of time, which permit to better approximate and adapt to the diffusion phenomenon observed in online social networks. Our proposal has been validated on real Twitter datasets. Experiments show that our approach is able to capture the particular patterns of diffusion depending of the studied sub-networks of users and topics. The results corroborate the \"two-step\" theory (1955) that states that information flows from media to a few \"opinion leaders\" who then transfer it to the mass population via social networks and show that it applies in the online context. This work also highlights interesting recommendations for future investigations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Adrien Guille"
                },
                {
                    "authorId": "1726350",
                    "name": "Hakim Hacid"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                }
            ]
        },
        {
            "paperId": "d3a5930c4d8fbdbd797ed99509006886671dd728",
            "title": "Enhancing flexibility and expressivity of contextual hierarchies",
            "abstract": "Data warehouses are nowadays extensively used to perform analyses on huge volume of data. This success is partly due to the capacity of considering data at several granularity levels thanks to the use of hierarchies. However, in previous work, we showed that the experts knowledge was not much considered in the generalization process. To overcome this drawback, we introduced a new category of hierarchies, namely the contextual hierarchies. Unfortunately, in contrast to the complexity of expert knowledge that should be considered, the knowledge definition process was too rigid. In this paper, we extend these hierarchies and their related techniques to drastically increase their flexibility and expressivity. To this purpose, we adopt a fuzzy-based methodology which allows to express expert knowledge in a very convenient way. Experiment results obtained on synthetic datasets show that the contextual generalization process is very fast and can thus be used in practice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2919587",
                    "name": "Y. Pitarch"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "145472032",
                    "name": "Anne Laurent"
                },
                {
                    "authorId": "1744598",
                    "name": "P. Poncelet"
                }
            ]
        },
        {
            "paperId": "a8da2aaab47ecab1feef4763d0fbfb5c3aa473fa",
            "title": "Context-aware generalization for cube measures",
            "abstract": "Hierarchies are crucial for analysis in data warehouses. But they can hardly be defined on measure attributes. In this paper, we tackle this issue and we show that measure generalizations often depend on a context. For instance, a given blood pressure can be either low, normal or high regarding not only the collected measure but also characteristics of the patient such as the age. The contribution of this paper is threefold. (1) Thanks to an external database storing the expert knowledge, we propose an effective solution for considering these hierarchies. (2) In order to efficiently manage this knowledge, a Rich Internet Application is developed. (3) Finally, in order to provide a flexible analysis, query rewriting module is proposed. Thus, it is possible to answer queries such as: \"Who had a low blood pressure last night?''",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2919587",
                    "name": "Y. Pitarch"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "145472032",
                    "name": "Anne Laurent"
                },
                {
                    "authorId": "1744598",
                    "name": "P. Poncelet"
                }
            ]
        },
        {
            "paperId": "ff5e5f265bec1177eceddea924381624ef251f88",
            "title": "Dynamic Workload for Schema Evolution in Data Warehouses",
            "abstract": "A data warehouse allows the integration of heterogeneous data sources for identified analysis purposes. The data warehouse schema is designed according to the available data sources and the users' analysis requirements. In order to provide an answer to new individual analysis needs, we previously proposed, in recent work, a solution for on-line analysis personalization. We based our solution on a user-driven approach for data warehouse schema evolution which consists in creating new hierarchy levels in OLAP (On-Line Analytical Processing) dimensions. One of the main objectives of OLAP, as the meaning of the acronym refers, is the performance during the analysis process. Since data warehouses contain a large volume of data, answering decision queries efficiently requires particular access methods. The main issue is to use redundant optimization structures such as views and indices. This implies to select an appropriate set of materialized views and indices, which minimizes total query response time, given a limited storage space. A judicious choice in this selection must be cost-driven and based on a workload which represents a set of users' queries on the data warehouse. In this chapter, we address the issues related to the workload\u2019s evolution and maintenance in data warehouse systems in response to new requirements modeling resulting from users\u2019 personalized analysis needs. The main issue is to avoid the workload generation from scratch. Hence, we propose a workload management system which helps the administrator to maintain and adapt dynamically the workload according to changes arising on the data warehouse schema. To achieve this maintenance, we propose two types of workload updates: (1) maintaining existing queries consistent with respect to the new data warehouse schema and (2) creating new queries based on the new dimension hierarchy levels. Our system helps the administrator in adopting a pro-active behaviour in the management of the data warehouse performance. In order to validate our workload management system, we address the implementation issues of our proposed prototype. This latter has been developed within client/server architecture with a web client interfaced with the Oracle 10g DataBase Management System.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1735803",
                    "name": "Omar Boussa\u00efd"
                }
            ]
        },
        {
            "paperId": "248a394729b5fbe43619450f33a90a12c9c08932",
            "title": "A Survey of Data Warehouse Model Evolution",
            "abstract": "A data warehouse allows the integration of heterogeneous data sources for analysis purposes. One of the key points for the success of the data warehousing process is the design of the model according to the available data sources and the analysis needs (Nabli, Soussi, Feki, Ben-Abdallah & Gargouri, 2005). However, as the business environment evolves, several changes in the content and structure of the underlying data sources may occur. In addition to these changes, analysis needs may also evolve, requiring an adaptation to the existing data warehouse\u2019s model. In this chapter, we provide an overall view of the state of the art in data warehouse model evolution. We present a set of comparison criteria and compare the various works. Moreover, we discuss the future trends in data warehouse model evolution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "9421445",
                    "name": "O. Boussaid"
                }
            ]
        },
        {
            "paperId": "8bae1c2e2d8c07a6f2a514989ef29ae0b30b2a89",
            "title": "A user-driven data warehouse evolution approach for concurrent personalized analysis needs",
            "abstract": "Data warehouses store aggregated data issued from different sources to meet users' analysis needs for decision support. The nature of the work of users implies that their requirements are often changing and do not reach a final state. Therefore, a data warehouse cannot be designed in one step, usually it evolves over the time. In this paper, we propose a user-driven approach that enables a data warehouse schema update. It consists in integrating the users' knowledge in the data warehouse modeling to allow new analysis possibilities. More precisely, we consider the specific users' knowledge, which defines new aggregated data, under the form of \"if-then\" rules that we call aggregation rules. These rules are used to dynamically create new granularity levels in dimension hierarchies, following an automatic and concurrent way. Our approach is composed of four phases: (1) users' knowledge acquisition, (2) knowledge integration, (3) data warehouse schema update, and (4) on-line analysis. To support our approach, we define a Rule-based Data Warehouse (R-DW) model composed of two parts: one \"fixed\" part and one \"evolving\" part. The fixed part corresponds to the initial data warehouse schema, whose purpose is to provide an answer to global analysis needs. The evolving part is defined by means of aggregation rules, which allow personalized analyses. To validate our approach, we developed a prototype called WEDriK (data Warehouse Evolution Driven by Knowledge), in which the R-DW model is implemented within the Oracle 10g DBMS. We also present how to achieve our approach by proposing a model dedicated to the management of the data warehouse schema evolution and the updates' algorithms. Furthermore, we applied our approach on banking data of the French bank LCL-Le Credit Lyonnais and we illustrate our purpose with the LCL case study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1735803",
                    "name": "Omar Boussa\u00efd"
                }
            ]
        },
        {
            "paperId": "40617a73319c4d7deed5bd7ea9f808516030201d",
            "title": "Dimension hierarchies updates in data warehouses - a user-driven approach",
            "abstract": "We designed a data warehouse for the French bank LCL meeting users\u2019 needs regarding marketing operations decision. However, the nature of the work of users implies that their requirements are often changing. In this paper, we propose an original and global approach to achieve a user-driven model evolution that provides answers to personalized analysis needs. We developed a prototype called WEDrik (data Warehouse Evolution Driven by Knowledge) within the Oracle 10g DBMS and applied our approach on banking data of LCL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "1735803",
                    "name": "Omar Boussa\u00efd"
                }
            ]
        },
        {
            "paperId": "9634516fcce81e01deccfcc5c931f0627e6e1268",
            "title": "Efficient online mining of large databases",
            "abstract": "Great efforts have been achieved to apply data mining algorithms onto large databases. However, long processing times remain a practical issue. This paper presents a framework to offer to database users online operators for mining large databases without size limit, in acceptable processing times. First, we integrate decision tree algorithms directly into database management systems. We are thus only limited by disc capacity and not by main memory. However, disc accesses still induce long response times. Hence, we propose two optimisations in a second step: reducing the size of the learning database by building its corresponding contingency table and reducing the number of database accesses by exploiting bitmap indices. Thus, the various decision tree based methods we implemented within Oracle deal with contingency tables or bitmap indices rather than with the whole training set. Experimentations performed show the efficiency of our integrated methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "2081456728",
                    "name": "C\u00e9dric Udr\u00e9a"
                }
            ]
        },
        {
            "paperId": "b0ff6d73831cbbfbb7ad4df5305d269b95e504c3",
            "title": "A Knowledge-Driven Data Warehouse Model for Analysis Evolution",
            "abstract": "A data warehouse is built by collecting data from external sources. Several changes on contents and structures can usually happen on these sources. Therefore, these changes have to be reflected in the data warehouse using schema updating or versioning. However a data warehouse has also to evolve according to new users' analysis needs. In this case, the evolution is rather driven by knowledge than by data. In this paper, we propose a Rule-based Data Warehouse (R-DW) model, in which rules enable the integration of users' knowledge in the data warehouse. The R-DW model is composed of two parts: one fixed part that contains a fact table related to its first level dimensions, and a second evolving part, defined by means of rules. These rules are used to dynamically create dimension hierarchies, allowing the analysis contexts evolution, according to an automatic and concurrent way. Our proposal provides flexibility to data warehouse's evolution by increasing users' interaction with the decision support system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "1739726",
                    "name": "F. Bentayeb"
                },
                {
                    "authorId": "1735803",
                    "name": "Omar Boussa\u00efd"
                }
            ]
        }
    ]
}