{
    "authorId": "2192203811",
    "papers": [
        {
            "paperId": "06df406805b59dcafb59214b99a77f9d2dad8b76",
            "title": "Large Language Models for Recommendation: Past, Present, and Future",
            "abstract": "Large language models (LLMs) have significantly influenced recommender systems, spurring interest across academia and industry in leveraging LLMs for recommendation tasks. This includes using LLMs for generative item retrieval and ranking, and developing versatile LLMs for various recommendation tasks, potentially leading to a paradigm shift in the field of recommender systems. This tutorial aims to demystify the Large Language Model for Recommendation (LLM4Rec) by reviewing its evolution and delving into cutting-edge research. We will explore how LLMs enhance recommender systems in terms of architecture, learning paradigms, and functionalities such as conversational abilities, generalization, planning, and content generation. The tutorial will shed light on the challenges and open problems in this burgeoning field, including trustworthiness, efficiency, online training, and evaluation of LLM4Rec. We will conclude by summarizing key learnings from existing studies and outlining potential avenues for future research, with the goal of equipping the audience with a comprehensive understanding of LLM4Rec and inspiring further exploration in this transformative domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188063534",
                    "name": "Keqin Bao"
                },
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2305605922",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2280911299",
                    "name": "Fuli Feng"
                }
            ]
        },
        {
            "paperId": "21a1102fae1a031e3556b251c0cfd1e3fc31f713",
            "title": "Data-efficient Fine-tuning for LLM-based Recommendation",
            "abstract": "Leveraging Large Language Models (LLMs) for recommendation has recently garnered considerable attention, where fine-tuning plays a key role in LLMs' adaptation. However, the cost of fine-tuning LLMs on rapidly expanding recommendation data limits their practical application. To address this challenge, few-shot fine-tuning offers a promising approach to quickly adapt LLMs to new recommendation data. We propose the task of data pruning for efficient LLM-based recommendation, aimed at identifying representative samples tailored for LLMs' few-shot fine-tuning. While coreset selection is closely related to the proposed task, existing coreset selection methods often rely on suboptimal heuristic metrics or entail costly optimization on large-scale recommendation data. To tackle these issues, we introduce two objectives for the data pruning task in the context of LLM-based recommendation: 1) high accuracy aims to identify the influential samples that can lead to high overall performance; and 2) high efficiency underlines the low costs of the data pruning process. To pursue the two objectives, we propose a novel data pruning method based on two scores, i.e., influence score and effort score, to efficiently identify the influential samples. Particularly, the influence score is introduced to accurately estimate the influence of sample removal on the overall performance. To achieve low costs of the data pruning process, we use a small-sized surrogate model to replace LLMs to obtain the influence score. Considering the potential gap between the surrogate model and LLMs, we further propose an effort score to prioritize some hard samples specifically for LLMs. Empirical results on three real-world datasets validate the effectiveness of our proposed method. In particular, the proposed method uses only 2% samples to surpass the full data fine-tuning, reducing time costs by 97%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2257099189",
                    "name": "Yongqi Li"
                },
                {
                    "authorId": "2281902534",
                    "name": "Shuo Yang"
                },
                {
                    "authorId": "2280911299",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2279771878",
                    "name": "Yinwei Wei"
                },
                {
                    "authorId": "2279753672",
                    "name": "Tat-Seng Chua"
                }
            ]
        },
        {
            "paperId": "61cf2eb3dc4467e96b20eef52152a8aa486da32d",
            "title": "A Survey of Generative Search and Recommendation in the Era of Large Language Models",
            "abstract": "With the information explosion on the Web, search and recommendation are foundational infrastructures to satisfying users' information needs. As the two sides of the same coin, both revolve around the same core research problem, matching queries with documents or users with items. In the recent few decades, search and recommendation have experienced synchronous technological paradigm shifts, including machine learning-based and deep learning-based paradigms. Recently, the superintelligent generative large language models have sparked a new paradigm in search and recommendation, i.e., generative search (retrieval) and recommendation, which aims to address the matching problem in a generative manner. In this paper, we provide a comprehensive survey of the emerging paradigm in information systems and summarize the developments in generative search and recommendation from a unified perspective. Rather than simply categorizing existing works, we abstract a unified framework for the generative paradigm and break down the existing works into different stages within this framework to highlight the strengths and weaknesses. And then, we distinguish generative search and recommendation with their unique challenges, identify open problems and future directions, and envision the next information-seeking paradigm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257099189",
                    "name": "Yongqi Li"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2280911299",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2263589454",
                    "name": "Liang Pang"
                },
                {
                    "authorId": "2284641622",
                    "name": "Wenjie Li"
                },
                {
                    "authorId": "2270021997",
                    "name": "Liqiang Nie"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2279753672",
                    "name": "Tat-Seng Chua"
                }
            ]
        },
        {
            "paperId": "6aa5177b38969f69a5c1b17b2846e6e90bd684e8",
            "title": "Learnable Item Tokenization for Generative Recommendation",
            "abstract": "Utilizing powerful Large Language Models (LLMs) for generative recommendation has attracted much attention. Nevertheless, a crucial challenge is transforming recommendation data into the language space of LLMs through effective item tokenization. Current approaches, such as ID, textual, and codebook-based identifiers, exhibit shortcomings in encoding semantic information, incorporating collaborative signals, or handling code assignment bias. To address these limitations, we propose LETTER (a LEarnable Tokenizer for generaTivE Recommendation), which integrates hierarchical semantics, collaborative signals, and code assignment diversity to satisfy the essential requirements of identifiers. LETTER incorporates Residual Quantized VAE for semantic regularization, a contrastive alignment loss for collaborative regularization, and a diversity loss to mitigate code assignment bias. We instantiate LETTER on two models and propose a ranking-guided generation loss to augment their ranking ability theoretically. Experiments on three datasets validate the superiority of LETTER, advancing the state-of-the-art in the field of LLM-based generative recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2301153513",
                    "name": "Honghui Bao"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "2257099189",
                    "name": "Yongqi Li"
                },
                {
                    "authorId": "2280911299",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2241348826",
                    "name": "See-kiong Ng"
                },
                {
                    "authorId": "2279753672",
                    "name": "Tat-Seng Chua"
                }
            ]
        },
        {
            "paperId": "79172e64a8b7abb8523b0fcf44802b9e1142aede",
            "title": "Efficient Inference for Large Language Model-based Generative Recommendation",
            "abstract": "Large Language Model (LLM)-based generative recommendation has achieved notable success, yet its practical deployment is costly particularly due to excessive inference latency caused by autoregressive decoding. For lossless LLM decoding acceleration, Speculative Decoding (SD) has emerged as a promising solution. However, applying SD to generative recommendation presents unique challenges due to the requirement of generating top-K items (i.e., K distinct token sequences) as a recommendation list by beam search. This leads to more stringent verification in SD, where all the top-K sequences from the target LLM must be successfully drafted by the draft model at each decoding step. To alleviate this, we consider 1) boosting top-K sequence alignment between the draft model and the target LLM, and 2) relaxing the verification strategy to reduce trivial LLM calls. To this end, we propose an alignment framework named AtSpeed, which presents the AtSpeed-S optimization objective for top-K alignment under the strict top-K verification. Moreover, we introduce a relaxed sampling verification strategy that allows high-probability non-top-K drafted sequences to be accepted, significantly reducing LLM calls. Correspondingly, we propose AtSpeed-R for top-K alignment under this relaxed sampling verification. Empirical results on two real-world datasets demonstrate that AtSpeed significantly accelerates LLM-based generative recommendation, e.g., near 2x speedup under strict top-K verification and up to 2.5 speedup under relaxed sampling verification. The codes and datasets will be released in the near future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2324959545",
                    "name": "Chaoqun Yang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2257099189",
                    "name": "Yongqi Li"
                },
                {
                    "authorId": "2324793557",
                    "name": "Cunxiao Du"
                },
                {
                    "authorId": "2280911299",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": null,
                    "name": "See-Kiong Ng"
                },
                {
                    "authorId": "2279753672",
                    "name": "Tat-Seng Chua"
                }
            ]
        },
        {
            "paperId": "c1a18ccf909433bfe6a7f485cbc73ce97c61a620",
            "title": "The 2nd Workshop on Recommendation with Generative Models",
            "abstract": "The rise of generative models has driven significant advancements in recommender systems, leaving unique opportunities for enhancing users' personalized recommendations. This workshop serves as a platform for researchers to explore and exchange innovative concepts related to the integration of generative models into recommender systems. It primarily focuses on five key perspectives: (i) improving recommender algorithms, (ii) generating personalized content, (iii) evolving the user-system interaction paradigm, (iv) enhancing trustworthiness checks, and (v) refining evaluation methodologies for generative recommendations. With generative models advancing rapidly, an increasing body of research is emerging in these domains, underscoring the timeliness and critical importance of this workshop. The related research will introduce innovative technologies to recommender systems and contribute to fresh challenges in both academia and industry. In the long term, this research direction has the potential to revolutionize the traditional recommender paradigms and foster the development of next-generation recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2292682323",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2209633655",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2267385868",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2290240238",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2290226180",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "06c9fb858fce351b724e1f5991eb6a81895aeab4",
            "title": "Equivariant Learning for Out-of-Distribution Cold-start Recommendation",
            "abstract": "Recommender systems rely on user-item interactions to learn Collaborative Filtering (CF) signals and easily under-recommend the cold-start items without historical interactions. To boost cold-start item recommendation, previous studies usually incorporate item features (e.g., micro-video content features) into CF models. They essentially align the feature representations of warm-start items with CF representations during training, and then adopt the feature representations of cold-start items to make recommendations. However, cold-start items might have feature distribution shifts from warm-start ones due to different upload times. As such, these cold-start item features fall into the underrepresented feature space, where their feature representations cannot align well with CF signals, causing poor cold-start recommendation. To combat item feature shifts, the key lies in pushing feature representation learning to well represent the shifted item features and align with the CF representations in the underrepresented feature space. To this end, we propose an equivariant learning framework, which aims to achieve equivariant alignment between item features, feature representations, and CF representations in the underrepresented feature space. Specifically, since cold-start items are unavailable for training, we interpolate the features and CF representations of two underrepresented warm items to simulate the feature shifts. The interpolated feature representations are then regulated to achieve equivariant alignment with the interpolated features and CF representations via three alignment losses. We instantiate the proposed framework on two competitive cold-start models, and empirical results on three datasets validate that the framework significantly improves cold-start recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2261789936",
                    "name": "Liuhui Wang"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "1887997",
                    "name": "Yin-wei Wei"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                }
            ]
        },
        {
            "paperId": "4c86722a587729d3e2d595aca0f5ce34805f72d4",
            "title": "Causal Disentangled Recommendation against User Preference Shifts",
            "abstract": "Recommender systems easily face the issue of user preference shifts. User representations will become out-of-date and lead to inappropriate recommendations if user preference has shifted over time. To solve the issue, existing work focuses on learning robust representations or predicting the shifting pattern. There lacks a comprehensive view to discover the underlying reasons for user preference shifts. To understand the preference shift, we abstract a causal graph to describe the generation procedure of user interaction sequences. Assuming user preference is stable within a short period, we abstract the interaction sequence as a set of chronological environments. From the causal graph, we find that the changes of some unobserved factors (e.g., becoming pregnant) cause preference shifts between environments. Besides, the fine-grained user preference over item categories sparsely affects the interactions with different items. Inspired by the causal graph, our key considerations to handle preference shifts lie in modeling the interaction generation procedure by: (1) capturing the preference shifts across environments for accurate preference prediction and (2) disentangling the sparse influence from user preference to interactions for accurate effect estimation of preference. To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which captures preference shifts via a temporal variational autoencoder and learns the sparse influence from multiple environments. Specifically, an encoder is adopted to infer the unobserved factors from user interactions while a decoder is to model the interaction generation process. Besides, we introduce two learnable matrices to disentangle the sparse influence from user preference to interactions. Last, we devise a multi-objective loss to optimize CDR. Extensive experiments on three datasets show the superiority of CDR in enhancing the generalization ability under user preference shifts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2108552313",
                    "name": "Liuhui Wang"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2109267019",
                    "name": "Yunshan Ma"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                }
            ]
        },
        {
            "paperId": "5f01fc9f0f410b8c4d47f0d13f6351f2826204ae",
            "title": "Temporally and Distributionally Robust Optimization for Cold-start Recommendation",
            "abstract": "Collaborative Filtering (CF) recommender models highly depend on user-item interactions to learn CF representations, thus falling short of recommending cold-start items. To address this issue, prior studies mainly introduce item features (e.g., thumbnails) for cold-start item recommendation. They learn a feature extractor on warm-start items to align feature representations with interactions, and then leverage the feature extractor to extract the feature representations of cold-start items for interaction prediction. Unfortunately, the features of cold-start items, especially the popular ones, tend to diverge from those of warm-start ones due to temporal feature shifts, preventing the feature extractor from accurately learning feature representations of cold-start items. \nTo alleviate the impact of temporal feature shifts, we consider using Distributionally Robust Optimization (DRO) to enhance the generation ability of the feature extractor. Nonetheless, existing DRO methods face an inconsistency issue: the worse-case warm-start items emphasized during DRO training might not align well with the cold-start item distribution. To capture the temporal feature shifts and combat this inconsistency issue, we propose a novel temporal DRO with new optimization objectives, namely, 1) to integrate a worst-case factor to improve the worst-case performance, and 2) to devise a shifting factor to capture the shifting trend of item features and enhance the optimization of the potentially popular groups in cold-start items. Substantial experiments on three real-world datasets validate the superiority of our temporal DRO in enhancing the generalization ability of cold-start recommender models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2260830089",
                    "name": "Jujia Zhao"
                },
                {
                    "authorId": "2257099189",
                    "name": "Yongqi Li"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                }
            ]
        },
        {
            "paperId": "6159549f986c63e160a678feef2130a2a4b93feb",
            "title": "Generative Recommendation: Towards Next-generation Recommender Paradigm",
            "abstract": "Recommender systems typically retrieve items from an item corpus for personalized recommendations. However, such a retrieval-based recommender paradigm faces two limitations: 1) the human-generated items in the corpus might fail to satisfy the users' diverse information needs, and 2) users usually adjust the recommendations via inefficient passive feedback, e.g., clicks. Nowadays, AI-Generated Content (AIGC) has revealed significant success, offering the potential to overcome these limitations: 1) generative AI can produce personalized items to satisfy users' information needs, and 2) the newly emerged large language models significantly reduce the efforts of users to precisely express information needs via natural language instructions. In this light, the boom of AIGC points the way towards the next-generation recommender paradigm with two new objectives: 1) generating personalized content through generative AI, and 2) integrating user instructions to guide content generation. To this end, we propose a novel Generative Recommender paradigm named GeneRec, which adopts an AI generator to personalize content generation and leverages user instructions. Specifically, we pre-process users' instructions and traditional feedback via an instructor to output the generation guidance. Given the guidance, we instantiate the AI generator through an AI editor and an AI creator to repurpose existing items and create new items. Eventually, GeneRec can perform content retrieval, repurposing, and creation to satisfy users' information needs. Besides, to ensure the trustworthiness of the generated items, we emphasize various fidelity checks. Moreover, we provide a roadmap to envision future developments of GeneRec and several domain-specific applications of GeneRec with potential research tasks. Lastly, we study the feasibility of implementing AI editor and AI creator on micro-video generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2192203811",
                    "name": "Xinyu Lin"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "143779329",
                    "name": "Tat-seng Chua"
                }
            ]
        }
    ]
}