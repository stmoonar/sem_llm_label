{
    "authorId": "40451032",
    "papers": [
        {
            "paperId": "2160e294fac83b410cdcf7436f74a3c9e77111d3",
            "title": "PyRIT: A Framework for Security Risk Identification and Red Teaming in Generative AI System",
            "abstract": "Generative Artificial Intelligence (GenAI) is becoming ubiquitous in our daily lives. The increase in computational power and data availability has led to a proliferation of both single- and multi-modal models. As the GenAI ecosystem matures, the need for extensible and model-agnostic risk identification frameworks is growing. To meet this need, we introduce the Python Risk Identification Toolkit (PyRIT), an open-source framework designed to enhance red teaming efforts in GenAI systems. PyRIT is a model- and platform-agnostic tool that enables red teamers to probe for and identify novel harms, risks, and jailbreaks in multimodal generative AI models. Its composable architecture facilitates the reuse of core building blocks and allows for extensibility to future models and modalities. This paper details the challenges specific to red teaming generative AI systems, the development and features of PyRIT, and its practical applications in real-world scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2324585501",
                    "name": "Gary D. Lopez Munoz"
                },
                {
                    "authorId": "2312208744",
                    "name": "Amanda J. Minnich"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "2312206987",
                    "name": "Richard Lundeen"
                },
                {
                    "authorId": "115637398",
                    "name": "Raja Sekhar Rao Dheekonda"
                },
                {
                    "authorId": "2312208309",
                    "name": "Nina Chikanov"
                },
                {
                    "authorId": "2211479371",
                    "name": "Bolor-Erdene Jagdagdorj"
                },
                {
                    "authorId": "2312205692",
                    "name": "Martin Pouliot"
                },
                {
                    "authorId": "26636213",
                    "name": "Shiven Chawla"
                },
                {
                    "authorId": "2324582948",
                    "name": "Whitney Maxwell"
                },
                {
                    "authorId": "2303843111",
                    "name": "Blake Bullwinkel"
                },
                {
                    "authorId": "2324585459",
                    "name": "Katherine Pratt"
                },
                {
                    "authorId": "2324584392",
                    "name": "Joris de Gruyter"
                },
                {
                    "authorId": "2324576061",
                    "name": "Charlotte Siska"
                },
                {
                    "authorId": "2312207906",
                    "name": "Pete Bryan"
                },
                {
                    "authorId": "2312206897",
                    "name": "Tori Westerhoff"
                },
                {
                    "authorId": "2324575846",
                    "name": "Chang Kawaguchi"
                },
                {
                    "authorId": "2312208541",
                    "name": "Christian Seifert"
                },
                {
                    "authorId": "2312253770",
                    "name": "Ram Shankar Siva Kumar"
                },
                {
                    "authorId": "52118354",
                    "name": "Yonatan Zunger"
                }
            ]
        },
        {
            "paperId": "d5c34e492d04b1cce31fb81ba40ac81b5feb0ef7",
            "title": "Phi-3 Safety Post-Training: Aligning Language Models with a \"Break-Fix\" Cycle",
            "abstract": "Recent innovations in language model training have demonstrated that it is possible to create highly performant models that are small enough to run on a smartphone. As these models are deployed in an increasing number of domains, it is critical to ensure that they are aligned with human preferences and safety considerations. In this report, we present our methodology for safety aligning the Phi-3 series of language models. We utilized a\"break-fix\"cycle, performing multiple rounds of dataset curation, safety post-training, benchmarking, red teaming, and vulnerability identification to cover a variety of harm areas in both single and multi-turn scenarios. Our results indicate that this approach iteratively improved the performance of the Phi-3 models across a wide range of responsible AI benchmarks. Finally, we include additional red teaming strategies and evaluations that were used to test the safety behavior of Phi-3.5-mini and Phi-3.5-MoE, which were optimized for multilingual capabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2297768377",
                    "name": "Emman Haider"
                },
                {
                    "authorId": "2312208471",
                    "name": "Daniel Perez-Becker"
                },
                {
                    "authorId": "6625302",
                    "name": "Thomas Portet"
                },
                {
                    "authorId": "46781068",
                    "name": "Piyush Madan"
                },
                {
                    "authorId": "2312211089",
                    "name": "Amit Garg"
                },
                {
                    "authorId": "2312208780",
                    "name": "David Majercak"
                },
                {
                    "authorId": "2312210094",
                    "name": "Wen Wen"
                },
                {
                    "authorId": "2297803872",
                    "name": "Dongwoo Kim"
                },
                {
                    "authorId": "2303854250",
                    "name": "Ziyi Yang"
                },
                {
                    "authorId": "2297818019",
                    "name": "Jianwen Zhang"
                },
                {
                    "authorId": "2266307341",
                    "name": "Hiteshi Sharma"
                },
                {
                    "authorId": "2303843111",
                    "name": "Blake Bullwinkel"
                },
                {
                    "authorId": "2312205692",
                    "name": "Martin Pouliot"
                },
                {
                    "authorId": "2312208744",
                    "name": "Amanda J. Minnich"
                },
                {
                    "authorId": "26636213",
                    "name": "Shiven Chawla"
                },
                {
                    "authorId": "2312206761",
                    "name": "Solianna Herrera"
                },
                {
                    "authorId": "2209667568",
                    "name": "Shahed Warreth"
                },
                {
                    "authorId": "2312208707",
                    "name": "Maggie Engler"
                },
                {
                    "authorId": "2312269715",
                    "name": "Gary Lopez"
                },
                {
                    "authorId": "2312208309",
                    "name": "Nina Chikanov"
                },
                {
                    "authorId": "115637398",
                    "name": "Raja Sekhar Rao Dheekonda"
                },
                {
                    "authorId": "2211479371",
                    "name": "Bolor-Erdene Jagdagdorj"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "2312206987",
                    "name": "Richard Lundeen"
                },
                {
                    "authorId": "2312206897",
                    "name": "Tori Westerhoff"
                },
                {
                    "authorId": "2312207906",
                    "name": "Pete Bryan"
                },
                {
                    "authorId": "2312208541",
                    "name": "Christian Seifert"
                },
                {
                    "authorId": "2312253770",
                    "name": "Ram Shankar Siva Kumar"
                },
                {
                    "authorId": "2312206949",
                    "name": "Andrew Berkley"
                },
                {
                    "authorId": "2312207057",
                    "name": "Alex Kessler"
                }
            ]
        },
        {
            "paperId": "1e3e6e847f79bb7cc2cf9c78e1a30dd96851aa81",
            "title": "A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications",
            "abstract": "We present a framework for the automated measurement of responsible AI (RAI) metrics for large language models (LLMs) and associated products and services. Our framework for automatically measuring harms from LLMs builds on existing technical and sociotechnical expertise and leverages the capabilities of state-of-the-art LLMs, such as GPT-4. We use this framework to run through several case studies investigating how different LLMs may violate a range of RAI-related principles. The framework may be employed alongside domain-specific sociotechnical expertise to create measurements for new harm areas in the future. By implementing this framework, we aim to enable more advanced harm measurement efforts and further the responsible use of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2905973",
                    "name": "Ahmed Magooda"
                },
                {
                    "authorId": "2219550562",
                    "name": "Alec Helyar"
                },
                {
                    "authorId": "2262215418",
                    "name": "Kyle Jackson"
                },
                {
                    "authorId": "2262215279",
                    "name": "David Sullivan"
                },
                {
                    "authorId": "2262214618",
                    "name": "Chad Atalla"
                },
                {
                    "authorId": "2262215122",
                    "name": "Emily Sheng"
                },
                {
                    "authorId": "2219634949",
                    "name": "Dan Vann"
                },
                {
                    "authorId": "2262214905",
                    "name": "Richard Edgar"
                },
                {
                    "authorId": "2269473744",
                    "name": "Hamid Palangi"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "2262215855",
                    "name": "Hongliang Kong"
                },
                {
                    "authorId": "2262214609",
                    "name": "Vincent Yun"
                },
                {
                    "authorId": "2256992426",
                    "name": "Eslam Kamal"
                },
                {
                    "authorId": "2262214999",
                    "name": "Federico Zarfati"
                },
                {
                    "authorId": "2286067853",
                    "name": "Hanna Wallach"
                },
                {
                    "authorId": "2262214977",
                    "name": "Sarah Bird"
                },
                {
                    "authorId": "2294672370",
                    "name": "Mei Chen"
                }
            ]
        },
        {
            "paperId": "f8515e247f95cdad1f5e1cc3263dd29469486150",
            "title": "Fairlearn: Assessing and Improving Fairness of AI Systems",
            "abstract": "Fairlearn is an open source project to help practitioners assess and improve fairness of artificial intelligence (AI) systems. The associated Python library, also named fairlearn, supports evaluation of a model's output across affected populations and includes several algorithms for mitigating fairness issues. Grounded in the understanding that fairness is a sociotechnical challenge, the project integrates learning resources that aid practitioners in considering a system's broader societal context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                }
            ]
        },
        {
            "paperId": "5894d57ea49bd5c136ebefb1e6c3986555908ea0",
            "title": "Fairlearn: A toolkit for assessing and improving fairness in AI",
            "abstract": "We introduce Fairlearn, an open source toolkit that empowers data scientists and developers to assess and improve the fairness of their AI systems. Fairlearn has two components: an interactive visualization dashboard and unfairness mitigation algorithms. These components are designed to help with navigating trade-offs between fairness and model performance. We emphasize that prioritizing fairness in AI systems is a sociotechnical challenge. Because there are many complex sources of unfairness\u2014some societal and some technical\u2014it is not possible to fully \u201cdebias\u201d a system or to guarantee fairness; the goal is to mitigate fairness-related harms as much as possible. As Fairlearn grows to include additional fairness metrics, unfairness mitigation algorithms, and visualization capabilities, we hope that it will be shaped by a diverse community of stakeholders, ranging from data scientists, developers, and business decision makers to the people whose lives may be affected by the predictions of AI systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145583374",
                    "name": "Sarah Bird"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "113003571",
                    "name": "R. Edgar"
                },
                {
                    "authorId": "2064040799",
                    "name": "Brandon Horn"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "1390070911",
                    "name": "Vanessa Milan"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "1831395",
                    "name": "Hanna M. Wallach"
                },
                {
                    "authorId": "2054043979",
                    "name": "Kathleen Walker"
                }
            ]
        },
        {
            "paperId": "b68431f0af0ab554e738c59ed7a5aa9f0e0142d4",
            "title": "Security and Privacy in Future Internet Architectures - Benefits and Challenges of Content Centric Networks",
            "abstract": "As the shortcomings of our current Internet become more and more obvious, researchers have started creating alternative approaches for the Internet of the future. Their design goals are mainly content-orientation, security, support for mobility and cloud computing. The probably most popular architecture is called Content Centric Networking. Every communication is treated as a distribution of content and caches are used within the network to improve the effectiveness. While the performance gain of Content Centric Networks is undoubted, there are questions about security and especially privacy since it is not one of its main design principle. In this work, we compare the Content Centric Networking approach with the current Internet with respect to security and privacy. We analyze improvements that have been made and new problems that have yet to be resolved. The Internet of the future could be content-oriented, so it is essential to identify potential security and privacy issues that are inherent to the architecture early on.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                }
            ]
        },
        {
            "paperId": "cd6cb85e4a1ca3c141dac1725c8be0b512d77dd2",
            "title": "NFL Play Prediction",
            "abstract": "Based on NFL game data we try to predict the outcome of a play in multiple different ways. An application of this is the following: by plugging in various play options one could determine the best play for a given situation in real time. While the outcome of a play can be described in many ways we had the most promising results with a newly defined measure that we call \"progress\". We see this work as a first step to include predictive analysis into NFL playcalling.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1916105",
                    "name": "B. Teich"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "3273455",
                    "name": "Valentin Kassarnig"
                }
            ]
        },
        {
            "paperId": "2e04f58fa272a6eea79d23113f6a4743f8f53ac0",
            "title": "Fantasy Football Prediction",
            "abstract": "The ubiquity of professional sports and specifically the NFL have lead to an increase in popularity for Fantasy Football. Users have many tools at their disposal: statistics, predictions, rankings of experts and even recommendations of peers. There are issues with all of these, though. Especially since many people pay money to play, the prediction tools should be enhanced as they provide unbiased and easy-to-use assistance for users. This paper provides and discusses approaches to predict Fantasy Football scores of Quarterbacks with relatively limited data. In addition to that, it includes several suggestions on how the data could be enhanced to achieve better results. The dataset consists only of game data from the last six NFL seasons. I used two different methods to predict the Fantasy Football scores of NFL players: Support Vector Regression (SVR) and Neural Networks. The results of both are promising given the limited data that was used.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                }
            ]
        }
    ]
}