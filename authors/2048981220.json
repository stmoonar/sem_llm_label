{
    "authorId": "2048981220",
    "papers": [
        {
            "paperId": "7adb88771376c2a31688e3b0395b0550a35b824d",
            "title": "Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models",
            "abstract": "In-context learning has emerged as a ground-breaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM\u2019s response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM\u2019s response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model\u2019s configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-context learning in a plug-and-play fashion. Extensive experiments are conducted to demonstrate the effectiveness of the decomposition. The code and data are available at: https://github. com/lingchen0331/UQ_ICL .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2255325982",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2249879747",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2238385975",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2283302224",
                    "name": "Yiyou Sun"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2265519247",
                    "name": "Mika Oishi"
                },
                {
                    "authorId": "2238209691",
                    "name": "Takao Osaki"
                },
                {
                    "authorId": "2057662658",
                    "name": "Katsushi Matsuda"
                },
                {
                    "authorId": "2284299533",
                    "name": "Jie Ji"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2282545112",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "be8c90bca14d59f180f40a41126b7cd8c29c5d4e",
            "title": "Uncertainty Quantification for In-Context Learning of Large Language Models",
            "abstract": "In-context learning has emerged as a groundbreaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM\u2019s response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM\u2019s response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model\u2019s configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-context learning in a plug-and-play fashion. Extensive experiments are conducted to demonstrate the effectiveness of the decomposition. The code and data are available at: https://github.com/lingchen0331/UQ_ICL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2255325982",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2249879747",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2238385975",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2283302224",
                    "name": "Yiyou Sun"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2265519247",
                    "name": "Mika Oishi"
                },
                {
                    "authorId": "2238209691",
                    "name": "Takao Osaki"
                },
                {
                    "authorId": "2057662658",
                    "name": "Katsushi Matsuda"
                },
                {
                    "authorId": "2284299533",
                    "name": "Jie Ji"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "138cfbdb2b4ccf9022f8c4d6f0734dd84cac4490",
            "title": "Multi-Label Temporal Evidential Neural Networks for Early Event Detection",
            "abstract": "Early event detection aims to detect events even before the event is complete. However, most of the existing methods focus on an event with a single label but fail to be applied to cases with multiple labels. Another non-negligible issue for early event detection is a prediction with overconfidence due to the high vacuity uncertainty that exists in the early time series. It results in an over-confidence estimation and hence unreliable predictions. To this end, technically, we propose a novel framework, Multi-Label Temporal Evidential Neural Network (MTENN), for multi-label uncertainty estimation in temporal data. MTENN is able to quality predictive uncertainty due to the lack of evidence for multi-label classifications at each time stamp based on belief/evidence theory. In addition, we introduce a novel uncertainty estimation head (weighted binomial comultiplication (WBC)) to quantify the fused uncertainty of a sub-sequence for early event detection. We validate the performance of our approach with state-of-the-art techniques on real-world audio datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "48505082",
                    "name": "Chengli Zhao"
                },
                {
                    "authorId": "2149896567",
                    "name": "Jinny Cho"
                },
                {
                    "authorId": "48300748",
                    "name": "L. Kaplan"
                },
                {
                    "authorId": "32106723",
                    "name": "D. Jeong"
                },
                {
                    "authorId": "9130998",
                    "name": "A. J\u00f8sang"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "144180429",
                    "name": "F. Chen"
                }
            ]
        },
        {
            "paperId": "47cae173d4618b32bf52f8b61b0a1051434d8b1f",
            "title": "Automatic Root Cause Analysis via Large Language Models for Cloud Incidents",
            "abstract": "Ensuring the reliability and availability of cloud services necessitates efficient root cause analysis (RCA) for cloud incidents. Traditional RCA methods, which rely on manual investigations of data sources such as logs and traces, are often laborious, error-prone, and challenging for on-call engineers. In this paper, we introduce RCACopilot, an innovative on-call system empowered by the large language model for automating RCA of cloud incidents. RCACopilot matches incoming incidents to corresponding incident handlers based on their alert types, aggregates the critical runtime diagnostic information, predicts the incident's root cause category, and provides an explanatory narrative. We evaluate RCACopilot using a real-world dataset consisting of a year's worth of incidents from Microsoft. Our evaluation demonstrates that RCACopilot achieves RCA accuracy up to 0.766. Furthermore, the diagnostic information collection component of RCACopilot has been successfully in use at Microsoft for over four years.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1867212",
                    "name": "Yinfang Chen"
                },
                {
                    "authorId": "2218558757",
                    "name": "Huaibing Xie"
                },
                {
                    "authorId": "3152770",
                    "name": "Minghua Ma"
                },
                {
                    "authorId": "2110042497",
                    "name": "Yu Kang"
                },
                {
                    "authorId": "2218539059",
                    "name": "Xin Gao"
                },
                {
                    "authorId": "2218320160",
                    "name": "Liu Shi"
                },
                {
                    "authorId": null,
                    "name": "Yunjie Cao"
                },
                {
                    "authorId": "2208157057",
                    "name": "Xue\u2010Chao Gao"
                },
                {
                    "authorId": "2218769443",
                    "name": "Hao Fan"
                },
                {
                    "authorId": "2143099423",
                    "name": "Ming Wen"
                },
                {
                    "authorId": "2072984554",
                    "name": "Jun Zeng"
                },
                {
                    "authorId": "3356725",
                    "name": "Supriyo Ghosh"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2793487",
                    "name": "Qingwei Lin"
                },
                {
                    "authorId": "148121358",
                    "name": "S. Rajmohan"
                },
                {
                    "authorId": "2109581369",
                    "name": "Dongmei Zhang"
                }
            ]
        },
        {
            "paperId": "5a11d45b2812904a4781a9905f520081da17f448",
            "title": "AutoARTS: Taxonomy, Insights and Tools for Root Cause Labelling of Incidents in Microsoft Azure",
            "abstract": "Labelling incident postmortems with the root causes is essential for aggregate analysis, which can reveal common problem areas, trends, patterns, and risks that may cause future incidents. A common practice is to manually label postmortems with a single root cause based on an ad hoc taxonomy of root cause tags. However, this manual process is error-prone, a single root cause is inadequate to capture all contributing factors behind an incident, and ad hoc taxonomies do not reflect the diverse categories of root causes. In this paper, we address this problem with a three-pronged approach. First, we conduct an extensive multi-year analysis of over 2000 incidents from more than 450 services in Microsoft Azure to understand all the factors that contributed to the incidents. Second, based on the empirical study, we pro-pose a novel hierarchical and comprehensive taxonomy of potential contributing factors for production incidents. Lastly, we develop an automated tool that can assist humans in the labelling process. We present empirical evaluation and a user study that show the effectiveness of our approach. To the best of our knowledge, this is the largest and most comprehensive study of production incident postmortem reports yet. We also make our taxonomy publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41016020",
                    "name": "Pradeep Dogga"
                },
                {
                    "authorId": "40097378",
                    "name": "Chetan Bansal"
                },
                {
                    "authorId": "2223157260",
                    "name": "Richard Costleigh"
                },
                {
                    "authorId": "2223163592",
                    "name": "Gopinath Jayagopal"
                },
                {
                    "authorId": "39496676",
                    "name": "Suman Nath"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                }
            ]
        },
        {
            "paperId": "6049f92e687e5db4ea509a83df4372099c516fd8",
            "title": "Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty",
            "abstract": "Open Information Extraction (OIE) task aims at extracting structured facts from unstructured text, typically in the form of (subject, relation, object) triples. Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate structured output due to the restrictions on fine-tuning the model. Second, LLMs generates responses autoregressively based on probability, which makes the predicted relations lack confidence. In this paper, we assess the capabilities of LLMs in improving the OIE task. Particularly, we propose various in-context learning strategies to enhance LLM's instruction-following ability and a demonstration uncertainty quantification module to enhance the confidence of the generated relations. Our experiments on three OIE benchmark datasets show that our approach holds its own against established supervised methods, both quantitatively and qualitatively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2238385975",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2256769706",
                    "name": "Haoyu Wang"
                },
                {
                    "authorId": "1766853",
                    "name": "Zhengzhang Chen"
                },
                {
                    "authorId": "2238209691",
                    "name": "Takao Osaki"
                },
                {
                    "authorId": "2057662658",
                    "name": "Katsushi Matsuda"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "6847b9658f287f430098199cd81bf26308da13f9",
            "title": "Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey",
            "abstract": "Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). Domain specification techniques are key to make large language models disruptive in many applications. Specifically, to solve these hurdles, there has been a notable increase in research and practices conducted in recent years on the domain specialization of LLMs. This emerging field of study, with its substantial potential for impact, necessitates a comprehensive and systematic review to better summarize and guide ongoing work in this area. In this article, we present a comprehensive survey on domain specification techniques for large language models, an emerging direction critical for large language model applications. First, we propose a systematic taxonomy that categorizes the LLM domain-specialization techniques based on the accessibility to LLMs and summarizes the framework for all the subcategories as well as their relations and differences to each other. Second, we present an extensive taxonomy of critical application domains that can benefit dramatically from specialized LLMs, discussing their practical significance and open challenges. Last, we offer our insights into the current research status and future trends in this area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059988575",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2117727751",
                    "name": "Jiaying Lu"
                },
                {
                    "authorId": "151483422",
                    "name": "Chengyuan Deng"
                },
                {
                    "authorId": "2182238045",
                    "name": "Can Zheng"
                },
                {
                    "authorId": "2120473483",
                    "name": "Junxiang Wang"
                },
                {
                    "authorId": "2123930262",
                    "name": "Tanmoy Chowdhury"
                },
                {
                    "authorId": "2110425042",
                    "name": "Yun-Qing Li"
                },
                {
                    "authorId": "2112821580",
                    "name": "Hejie Cui"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2211987764",
                    "name": "Tian-yu Zhao"
                },
                {
                    "authorId": "2218486790",
                    "name": "Amit Panalkar"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": null,
                    "name": "Haoyu Wang"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "1766853",
                    "name": "Zhengzhang Chen"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2218495127",
                    "name": "Chris White"
                },
                {
                    "authorId": "144966687",
                    "name": "Quanquan Gu"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "1390553618",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "6c4582d2d60d7f82122b237943501502282f625c",
            "title": "Open-ended Commonsense Reasoning with Unrestricted Answer Scope",
            "abstract": "Open-ended Commonsense Reasoning is defined as solving a commonsense question without providing 1) a short list of answer candidates and 2) a pre-defined answer scope. Conventional ways of formulating the commonsense question into a question-answering form or utilizing external knowledge to learn retrieval-based methods are less applicable in the open-ended setting due to an inherent challenge. Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space. Moreover, most questions require implicit multi-hop reasoning, which presents even more challenges to our problem. In this work, we leverage pre-trained language models to iteratively retrieve reasoning paths on the external knowledge base, which does not require task-specific supervision. The reasoning paths can help to identify the most precise answer to the commonsense question. We conduct experiments on two commonsense benchmark datasets. Compared to other approaches, our proposed method achieves better performance both quantitatively and qualitatively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2255325982",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2238385975",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2249879747",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2265519247",
                    "name": "Mika Oishi"
                },
                {
                    "authorId": "2238209691",
                    "name": "Takao Osaki"
                },
                {
                    "authorId": "2057662658",
                    "name": "Katsushi Matsuda"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "6e70a2b7512fde9d25176c508f9cad35e47f66ad",
            "title": "Time Series Contrastive Learning with Information-Aware Augmentations",
            "abstract": "Various contrastive learning approaches have been proposed in recent years and achieve significant empirical success. While effective and prevalent, contrastive learning has been less explored for time series data. A key component of contrastive learning is to select appropriate augmentations imposing some priors to construct feasible positive samples, such that an encoder can be trained to learn robust and discriminative representations. Unlike image and language domains where \"desired'' augmented samples can be generated with the rule of thumb guided by prefabricated human priors, the ad-hoc manual selection of time series augmentations is hindered by their diverse and human-unrecognizable temporal structures. How to find the desired augmentations of time series data that are meaningful for given contrastive learning tasks and datasets remains an open question. In this work, we address the problem by encouraging both high fidelity and variety based on information theory. A theoretical analysis leads to the criteria for selecting feasible data augmentations. On top of that, we propose a new contrastive learning approach with information-aware augmentations, InfoTS, that adaptively selects optimal augmentations for time series representation learning. Experiments on various datasets show highly competitive performance with up to a 12.0% reduction in MSE on forecasting tasks and up to 3.7% relative improvement in accuracy on classification tasks over the leading baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153640788",
                    "name": "Dongsheng Luo"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2107962435",
                    "name": "Yingheng Wang"
                },
                {
                    "authorId": "2116459424",
                    "name": "Dongkuan Xu"
                },
                {
                    "authorId": "2090567",
                    "name": "Jingchao Ni"
                },
                {
                    "authorId": "3007026",
                    "name": "Wenchao Yu"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "47557891",
                    "name": "Yuncong Chen"
                },
                {
                    "authorId": "2145225543",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2190288679",
                    "name": "Xiang Zhang"
                }
            ]
        },
        {
            "paperId": "8b97b25a0825b84feebe1b34968a8144bf5acdf0",
            "title": "Knowledge-enhanced Neural Machine Reasoning: A Review",
            "abstract": "Knowledge-enhanced neural machine reasoning has garnered significant attention as a cutting-edge yet challenging research area with numerous practical applications. Over the past few years, plenty of studies have leveraged various forms of external knowledge to augment the reasoning capabilities of deep models, tackling challenges such as effective knowledge integration, implicit knowledge mining, and problems of tractability and optimization. However, there is a dearth of a comprehensive technical review of the existing knowledge-enhanced reasoning techniques across the diverse range of application domains. This survey provides an in-depth examination of recent advancements in the field, introducing a novel taxonomy that categorizes existing knowledge-enhanced methods into two primary categories and four subcategories. We systematically discuss these methods and highlight their correlations, strengths, and limitations. Finally, we elucidate the current application domains and provide insight into promising prospects for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123930262",
                    "name": "Tanmoy Chowdhury"
                },
                {
                    "authorId": "2059988349",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                }
            ]
        }
    ]
}