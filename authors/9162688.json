{
    "authorId": "9162688",
    "papers": [
        {
            "paperId": "2683dd353629cc39ef559da4c0f8451fe6f006ad",
            "title": "Towards Efficient and Robust VQA-NLE Data Generation with Large Vision-Language Models",
            "abstract": "Natural Language Explanation (NLE) aims to elucidate the decision-making process by providing detailed, human-friendly explanations in natural language. It helps demystify the decision-making processes of large vision-language models (LVLMs) through the use of language models. While existing methods for creating a Vision Question-Answering with Natural Language Explanation (VQA-NLE) datasets can provide explanations, they heavily rely on human annotations that are time-consuming and costly. In this study, we propose a novel approach that leverages LVLMs to efficiently generate high-quality synthetic VQA-NLE datasets. By evaluating our synthetic data, we showcase how advanced prompting techniques can lead to the production of high-quality VQA-NLE data. Our findings indicate that this proposed method achieves up to 20x faster than human annotation, with only a minimal decrease in qualitative metrics, achieving robust quality that is nearly equivalent to human-annotated data. Furthermore, we show that incorporating visual prompts significantly enhances the relevance of text generation. Our study paves the way for a more efficient and robust automated generation of multi-modal NLE data, offering a promising solution to the problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2306258046",
                    "name": "Patrick Amadeus Irawan"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2220548276",
                    "name": "Samuel Cahyawijaya"
                },
                {
                    "authorId": "2257345523",
                    "name": "Ayu Purwarianti"
                }
            ]
        },
        {
            "paperId": "2b0ce68cae4203c9f2785b4ce83d0b3aff0017a5",
            "title": "ProxyLM: Predicting Language Model Performance on Multilingual Tasks via Proxy Models",
            "abstract": "Performance prediction is a method to estimate the performance of Language Models (LMs) on various Natural Language Processing (NLP) tasks, mitigating computational costs associated with model capacity and data for fine-tuning. Our paper introduces ProxyLM, a scalable framework for predicting LM performance using proxy models in multilingual tasks. These proxy models act as surrogates, approximating the performance of the LM of interest. By leveraging proxy models, ProxyLM significantly reduces computational overhead on task evaluations, achieving up to a 37.08x speedup compared to traditional methods, even with our smallest proxy models. Additionally, our methodology showcases adaptability to previously unseen languages in pre-trained LMs, outperforming the state-of-the-art performance by 1.89x as measured by root-mean-square error (RMSE). This framework streamlines model selection, enabling efficient deployment and iterative LM enhancements without extensive computational resources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282529650",
                    "name": "David Anugraha"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2306457295",
                    "name": "Chenyue Li"
                },
                {
                    "authorId": "2306258046",
                    "name": "Patrick Amadeus Irawan"
                },
                {
                    "authorId": "2282641191",
                    "name": "En-Shiun Annie Lee"
                }
            ]
        },
        {
            "paperId": "53f47501bcf5cfeb270b030dea1b1edb9f93f394",
            "title": "Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation",
            "abstract": "The widespread online communication in a modern multilingual world has provided opportunities to blend more than one language (aka code-mixed language) in a single utterance. This has resulted a formidable challenge for the computational models due to the scarcity of annotated data and presence of noise. A potential solution to mitigate the data scarcity problem in low-resource setup is to leverage existing data in resource-rich language through translation. In this paper, we tackle the problem of code-mixed (Hinglish and Bengalish) to English machine translation. First, we synthetically develop HINMIX, a parallel corpus of Hinglish to English, with ~4.2M sentence pairs. Subsequently, we propose RCMT, a robust perturbation based joint-training model that learns to handle noise in the real-world code-mixed text by parameter sharing across clean and noisy words. Further, we show the adaptability of RCMT in a zero-shot setup for Bengalish to English translation. Our evaluation and comprehensive analyses qualitatively and quantitatively demonstrate the superiority of RCMT over state-of-the-art code-mixed and robust translation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287605171",
                    "name": "Hi Bn"
                },
                {
                    "authorId": "2101320781",
                    "name": "Ramakrishna Appicharla"
                },
                {
                    "authorId": "2287932852",
                    "name": "Kamal Kumar"
                },
                {
                    "authorId": "2287400056",
                    "name": "Asif Gupta"
                },
                {
                    "authorId": "3335364",
                    "name": "Dzmitry Bahdanau"
                },
                {
                    "authorId": "2285803779",
                    "name": "Kyunghyun Cho"
                },
                {
                    "authorId": "2287584564",
                    "name": "Yoshua Ben\u00ad"
                },
                {
                    "authorId": "143832874",
                    "name": "Ondrej Bojar"
                },
                {
                    "authorId": "2287696687",
                    "name": "Christian Buck"
                },
                {
                    "authorId": "3359291",
                    "name": "C. Federmann"
                },
                {
                    "authorId": "2285976154",
                    "name": "Yong Cheng"
                },
                {
                    "authorId": "2286200780",
                    "name": "Lu Jiang"
                },
                {
                    "authorId": "2285501740",
                    "name": "Wolfgang Macherey"
                },
                {
                    "authorId": "2480903",
                    "name": "Alexis Conneau"
                },
                {
                    "authorId": "2287652471",
                    "name": "Guillaume Lample. 2019"
                },
                {
                    "authorId": "2287608547",
                    "name": "Cross\u00ad"
                },
                {
                    "authorId": "11323179",
                    "name": "Yinhan Liu"
                },
                {
                    "authorId": "2285672742",
                    "name": "Jiatao Gu"
                },
                {
                    "authorId": "39589154",
                    "name": "Naman Goyal"
                },
                {
                    "authorId": "2285853237",
                    "name": "Sergey Xian Li"
                },
                {
                    "authorId": "2287641526",
                    "name": "Carol Myers\u00adScotton. 1997"
                },
                {
                    "authorId": "2287583929",
                    "name": "El Moatez"
                },
                {
                    "authorId": "2287584547",
                    "name": "Billah Nagoudi"
                },
                {
                    "authorId": "2261741427",
                    "name": "AbdelRahim Elmadany"
                },
                {
                    "authorId": "2287609401",
                    "name": "Muhammad Abdul\u00adMageed. 2021. Investigat\u00ad"
                },
                {
                    "authorId": "40511414",
                    "name": "Myle Ott"
                },
                {
                    "authorId": "2068070",
                    "name": "Sergey Edunov"
                },
                {
                    "authorId": "14667698",
                    "name": "Alexei Baevski"
                },
                {
                    "authorId": "1579818535",
                    "name": "Parth Patwa"
                },
                {
                    "authorId": "2286509401",
                    "name": "Gustavo Aguilar"
                },
                {
                    "authorId": "3465549",
                    "name": "Sudipta Kar"
                },
                {
                    "authorId": "2286529113",
                    "name": "Suraj"
                },
                {
                    "authorId": "2286330398",
                    "name": "Srinivas Pandey"
                },
                {
                    "authorId": "2286527092",
                    "name": "Bj\u00f6rn Pykl"
                },
                {
                    "authorId": "2286539876",
                    "name": "Gamb\u00e4ck"
                },
                {
                    "authorId": "2286539871",
                    "name": "Tanmoy"
                },
                {
                    "authorId": "1630664874",
                    "name": "Ashish Vaswani"
                },
                {
                    "authorId": "1846258",
                    "name": "Noam M. Shazeer"
                },
                {
                    "authorId": "3877127",
                    "name": "Niki Parmar"
                },
                {
                    "authorId": "2287696593",
                    "name": "dukasz Kaiser"
                },
                {
                    "authorId": "2285203945",
                    "name": "Illia Polosukhin. 2017"
                },
                {
                    "authorId": "2231473624",
                    "name": "Attention"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2111680936",
                    "name": "Andrea Madotto"
                },
                {
                    "authorId": "2287585194",
                    "name": "Chien\u00adSheng"
                },
                {
                    "authorId": "2287696224",
                    "name": "Wu Pascale"
                },
                {
                    "authorId": "2287643359",
                    "name": "Fung"
                },
                {
                    "authorId": "2287605233",
                    "name": "Code\u00adswitching"
                },
                {
                    "authorId": "2285098633",
                    "name": "ing. In"
                },
                {
                    "authorId": "2257429734",
                    "name": "Felix Wu"
                },
                {
                    "authorId": "2247818297",
                    "name": "Angela Fan"
                },
                {
                    "authorId": "2285592910",
                    "name": "Yann Dauphin"
                },
                {
                    "authorId": "2286446841",
                    "name": "Linting Xue"
                },
                {
                    "authorId": "40832517",
                    "name": "Noah Constant"
                },
                {
                    "authorId": "2287583320",
                    "name": "Mihir Adam Roberts"
                },
                {
                    "authorId": "2287585179",
                    "name": "Rami Kale"
                },
                {
                    "authorId": "2287609620",
                    "name": "Aditya Al\u00adRfou"
                },
                {
                    "authorId": "9356387",
                    "name": "Aditya Siddhant"
                },
                {
                    "authorId": "2287583921",
                    "name": "Barua"
                },
                {
                    "authorId": "2287814395",
                    "name": "Shuyan Zhou"
                },
                {
                    "authorId": "2287884953",
                    "name": "Xiangkai Zeng"
                },
                {
                    "authorId": "2287655120",
                    "name": "Antonios Yingqi Zhou"
                },
                {
                    "authorId": "2287588166",
                    "name": "Anastasopoulos Graham"
                },
                {
                    "authorId": "2287605212",
                    "name": "Neubig. 2019"
                },
                {
                    "authorId": "2287641220",
                    "name": "Im\u00ad"
                }
            ]
        },
        {
            "paperId": "5840cd4edbfadee407a6195fbc111d07a5c78780",
            "title": "MINERS: Multilingual Language Models as Semantic Retrievers",
            "abstract": "Words have been represented in a high-dimensional vector space that encodes their semantic similarities, enabling downstream applications such as retrieving synonyms, antonyms, and relevant contexts. However, despite recent advances in multilingual language models (LMs), the effectiveness of these models' representations in semantic retrieval contexts has not been comprehensively explored. To fill this gap, this paper introduces the MINERS, a benchmark designed to evaluate the ability of multilingual LMs in semantic retrieval tasks, including bitext mining and classification via retrieval-augmented contexts. We create a comprehensive framework to assess the robustness of LMs in retrieving samples across over 200 diverse languages, including extremely low-resource languages in challenging cross-lingual and code-switching settings. Our results demonstrate that by solely retrieving semantically similar embeddings yields performance competitive with state-of-the-art approaches, without requiring any fine-tuning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "49775305",
                    "name": "Ruochen Zhang"
                },
                {
                    "authorId": "2273673245",
                    "name": "D. Adelani"
                }
            ]
        },
        {
            "paperId": "5e553317596d37b6438441a38cfe3562eed4d374",
            "title": "RainbowPO: A Unified Framework for Combining Improvements in Preference Optimization",
            "abstract": "Recently, numerous preference optimization algorithms have been introduced as extensions to the Direct Preference Optimization (DPO) family. While these methods have successfully aligned models with human preferences, there is a lack of understanding regarding the contributions of their additional components. Moreover, fair and consistent comparisons are scarce, making it difficult to discern which components genuinely enhance downstream performance. In this work, we propose RainbowPO, a unified framework that demystifies the effectiveness of existing DPO methods by categorizing their key components into seven broad directions. We integrate these components into a single cohesive objective, enhancing the performance of each individual element. Through extensive experiments, we demonstrate that RainbowPO outperforms existing DPO variants. Additionally, we provide insights to guide researchers in developing new DPO methods and assist practitioners in their implementations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Hanyang Zhao"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2321713566",
                    "name": "Anirban Das"
                },
                {
                    "authorId": "2321638931",
                    "name": "Shi-Xiong Zhang"
                },
                {
                    "authorId": "2303257967",
                    "name": "David D. Yao"
                },
                {
                    "authorId": null,
                    "name": "Wenpin Tang"
                },
                {
                    "authorId": "2321561313",
                    "name": "Sambit Sahu"
                }
            ]
        },
        {
            "paperId": "64c8edfd8db83a893eaf0e2d137acb23eb698fd3",
            "title": "SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages",
            "abstract": "Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader phenomenon of semantic relatedness. In this paper, we present \\textit{SemRel}, a new semantic relatedness dataset collection annotated by native speakers across 13 languages: \\textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Spanish,} and \\textit{Telugu}. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia -- regions characterised by a relatively limited availability of NLP resources. Each instance in the SemRel datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. The scores are obtained using a comparative annotation framework. We describe the data collection and annotation processes, challenges when building the datasets, baseline experiments, and their impact and utility in NLP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3056500",
                    "name": "N. Ousidhoum"
                },
                {
                    "authorId": "7744881",
                    "name": "Shamsuddeen Hassan Muhammad"
                },
                {
                    "authorId": "2283931971",
                    "name": "Mohamed Abdalla"
                },
                {
                    "authorId": "2260237439",
                    "name": "Idris Abdulmumin"
                },
                {
                    "authorId": "153795444",
                    "name": "I. Ahmad"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "71323208",
                    "name": "A. Ayele"
                },
                {
                    "authorId": "2269468034",
                    "name": "Pavan Baswani"
                },
                {
                    "authorId": "2604621",
                    "name": "Meriem Beloucif"
                },
                {
                    "authorId": "1829342",
                    "name": "Christian Biemann"
                },
                {
                    "authorId": "2266839087",
                    "name": "Sofia Bourhim"
                },
                {
                    "authorId": "2047358683",
                    "name": "Christine de Kock"
                },
                {
                    "authorId": "2283935559",
                    "name": "Genet Shanko Dekebo"
                },
                {
                    "authorId": "23245535",
                    "name": "Oumaima Hourrane"
                },
                {
                    "authorId": "2268675106",
                    "name": "Gopichand Kanumolu"
                },
                {
                    "authorId": "2268674912",
                    "name": "Lokesh Madasu"
                },
                {
                    "authorId": "30571646",
                    "name": "Samuel Rutunda"
                },
                {
                    "authorId": "2280905799",
                    "name": "Manish Shrivastava"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "2104748735",
                    "name": "Nirmal Surange"
                },
                {
                    "authorId": "2283932533",
                    "name": "Hailegnaw Getaneh Tilaye"
                },
                {
                    "authorId": "51172231",
                    "name": "Krishnapriya Vishnubhotla"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "3084761",
                    "name": "Seid Muhie Yimam"
                },
                {
                    "authorId": "2261458500",
                    "name": "Saif Mohammad"
                }
            ]
        },
        {
            "paperId": "ba5284674face6cca3b678fd7a82d691ec29349b",
            "title": "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages",
            "abstract": "Southeast Asia (SEA) is a region rich in linguistic diversity and cultural variety, with over 1,300 indigenous languages and a population of 671 million people. However, prevailing AI models suffer from a significant lack of representation of texts, images, and audio datasets from SEA, compromising the quality of AI models for SEA languages. Evaluating models for SEA languages is challenging due to the scarcity of high-quality datasets, compounded by the dominance of English training data, raising concerns about potential cultural misrepresentation. To address these challenges, we introduce SEACrowd, a collaborative initiative that consolidates a comprehensive resource hub that fills the resource gap by providing standardized corpora in nearly 1,000 SEA languages across three modalities. Through our SEACrowd benchmarks, we assess the quality of AI models on 36 indigenous languages across 13 tasks, offering valuable insights into the current AI landscape in SEA. Furthermore, we propose strategies to facilitate greater AI advancements, maximizing potential utility and resource equity for the future of AI in SEA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "116344405",
                    "name": "Holy Lovenia"
                },
                {
                    "authorId": "1935324",
                    "name": "Rahmad Mahendra"
                },
                {
                    "authorId": "2242161500",
                    "name": "Salsabil Maulana Akbar"
                },
                {
                    "authorId": "13614871",
                    "name": "Lester James Validad Miranda"
                },
                {
                    "authorId": "117696399",
                    "name": "Jennifer Santoso"
                },
                {
                    "authorId": "2306780850",
                    "name": "Elyanah Aco"
                },
                {
                    "authorId": "2306780925",
                    "name": "Akhdan Fadhilah"
                },
                {
                    "authorId": "2218861055",
                    "name": "Jonibek Mansurov"
                },
                {
                    "authorId": "151472158",
                    "name": "Joseph Marvin Imperial"
                },
                {
                    "authorId": "145315291",
                    "name": "Onno P. Kampman"
                },
                {
                    "authorId": "22272110",
                    "name": "Joel Ruben Antony Moniz"
                },
                {
                    "authorId": "2306780704",
                    "name": "Muhammad Ravi Shulthan Habibi"
                },
                {
                    "authorId": "2197090652",
                    "name": "Frederikus Hudi"
                },
                {
                    "authorId": "2306780357",
                    "name": "Railey Montalan"
                },
                {
                    "authorId": "2197071063",
                    "name": "Ryan Ignatius"
                },
                {
                    "authorId": "2265829074",
                    "name": "Joanito Agili Lopo"
                },
                {
                    "authorId": "2306780376",
                    "name": "William Nixon"
                },
                {
                    "authorId": "2047947436",
                    "name": "B\u00f6rje F. Karlsson"
                },
                {
                    "authorId": "2197071075",
                    "name": "James Jaya"
                },
                {
                    "authorId": "2197070752",
                    "name": "Ryandito Diandaru"
                },
                {
                    "authorId": "2258725381",
                    "name": "Yuze Gao"
                },
                {
                    "authorId": "2306258046",
                    "name": "Patrick Amadeus Irawan"
                },
                {
                    "authorId": "2306845506",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2282499634",
                    "name": "Jan Christian Blaise Cruz"
                },
                {
                    "authorId": "2161240241",
                    "name": "Chenxi Whitehouse"
                },
                {
                    "authorId": "134112343",
                    "name": "Ivan Halim Parmonangan"
                },
                {
                    "authorId": "2306780394",
                    "name": "Maria Khelli"
                },
                {
                    "authorId": "2306875069",
                    "name": "Wenyu Zhang"
                },
                {
                    "authorId": "2264978269",
                    "name": "Lucky Susanto"
                },
                {
                    "authorId": "2306781205",
                    "name": "Reynard Adha Ryanda"
                },
                {
                    "authorId": "2306780442",
                    "name": "Sonny Lazuardi Hermawan"
                },
                {
                    "authorId": "1994718316",
                    "name": "Dan John Velasco"
                },
                {
                    "authorId": "2264979805",
                    "name": "Muhammad Dehan Al Kautsar"
                },
                {
                    "authorId": "2093270493",
                    "name": "Willy Fitra Hendria"
                },
                {
                    "authorId": "9400076",
                    "name": "Yasmin Moslem"
                },
                {
                    "authorId": "2306780349",
                    "name": "Noah Flynn"
                },
                {
                    "authorId": "2191731497",
                    "name": "Muhammad Farid Adilazuarda"
                },
                {
                    "authorId": "2188740060",
                    "name": "Haochen Li"
                },
                {
                    "authorId": "2306864026",
                    "name": "Johanes Lee"
                },
                {
                    "authorId": "2162893011",
                    "name": "R. Damanhuri"
                },
                {
                    "authorId": "2307389481",
                    "name": "Shuo Sun"
                },
                {
                    "authorId": "2181162339",
                    "name": "M. Qorib"
                },
                {
                    "authorId": "2261492948",
                    "name": "Amirbek Djanibekov"
                },
                {
                    "authorId": "2140097897",
                    "name": "Wei Qi Leong"
                },
                {
                    "authorId": "2187874252",
                    "name": "Quyet V. Do"
                },
                {
                    "authorId": "2037383772",
                    "name": "Niklas Muennighoff"
                },
                {
                    "authorId": "113610145",
                    "name": "T. Pansuwan"
                },
                {
                    "authorId": "1943296899",
                    "name": "Ilham Firdausi Putra"
                },
                {
                    "authorId": "2286341163",
                    "name": "Yan Xu"
                },
                {
                    "authorId": "2306780314",
                    "name": "Ngee Chia Tai"
                },
                {
                    "authorId": "2257345523",
                    "name": "Ayu Purwarianti"
                },
                {
                    "authorId": "2884561",
                    "name": "Sebastian Ruder"
                },
                {
                    "authorId": "2618006",
                    "name": "William-Chandra Tjhi"
                },
                {
                    "authorId": "1596821065",
                    "name": "Peerat Limkonchotiwat"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "150299584",
                    "name": "Sedrick Scott Keh"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "49775305",
                    "name": "Ruochen Zhang"
                },
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2282475073",
                    "name": "Zheng-Xin Yong"
                },
                {
                    "authorId": "2220548276",
                    "name": "Samuel Cahyawijaya"
                }
            ]
        },
        {
            "paperId": "c4035aed5db5d3c1cffa8205de1e070960e5d860",
            "title": "MetaMetrics: Calibrating Metrics For Generation Tasks Using Human Preferences",
            "abstract": "Understanding the quality of a performance evaluation metric is crucial for ensuring that model outputs align with human preferences. However, it remains unclear how well each metric captures the diverse aspects of these preferences, as metrics often excel in one particular area but not across all dimensions. To address this, it is essential to systematically calibrate metrics to specific aspects of human preference, catering to the unique characteristics of each aspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate generation tasks across different modalities in a supervised manner. MetaMetrics optimizes the combination of existing metrics to enhance their alignment with human preferences. Our metric demonstrates flexibility and effectiveness in both language and vision downstream tasks, showing significant benefits across various multilingual and multi-domain scenarios. MetaMetrics aligns closely with human preferences and is highly extendable and easily integrable into any application. This makes MetaMetrics a powerful tool for improving the evaluation of generation tasks, ensuring that metrics are more representative of human judgment across diverse contexts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2282529650",
                    "name": "David Anugraha"
                },
                {
                    "authorId": "2264978269",
                    "name": "Lucky Susanto"
                },
                {
                    "authorId": "2301579068",
                    "name": "Garry Kuwanto"
                },
                {
                    "authorId": "2320154751",
                    "name": "Derry Tanti Wijaya"
                }
            ]
        },
        {
            "paperId": "dfa0de5cae63eacd675339fc81b13479c51bb153",
            "title": "Lessons from the Trenches on Reproducible Evaluation of Language Models",
            "abstract": "Effective evaluation of language models remains an open challenge in NLP. Researchers and engineers face methodological issues such as the sensitivity of models to evaluation setup, difficulty of proper comparisons across methods, and the lack of reproducibility and transparency. In this paper we draw on three years of experience in evaluating large language models to provide guidance and lessons for researchers. First, we provide an overview of common challenges faced in language model evaluation. Second, we delineate best practices for addressing or lessening the impact of these challenges on research. Third, we present the Language Model Evaluation Harness (lm-eval): an open source library for independent, reproducible, and extensible evaluation of language models that seeks to address these issues. We describe the features of the library as well as case studies in which the library has been used to alleviate these methodological concerns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103476203",
                    "name": "Stella Biderman"
                },
                {
                    "authorId": "2184031883",
                    "name": "Hailey Schoelkopf"
                },
                {
                    "authorId": "35566806",
                    "name": "Lintang Sutawika"
                },
                {
                    "authorId": "2027599537",
                    "name": "Leo Gao"
                },
                {
                    "authorId": "50195579",
                    "name": "J. Tow"
                },
                {
                    "authorId": "2282542564",
                    "name": "Baber Abbasi"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "1451644426",
                    "name": "Pawan Sasanka Ammanamanchi"
                },
                {
                    "authorId": "2044098905",
                    "name": "Sid Black"
                },
                {
                    "authorId": "2133312617",
                    "name": "Jordan Clive"
                },
                {
                    "authorId": "2282542841",
                    "name": "Anthony DiPofi"
                },
                {
                    "authorId": "2226458991",
                    "name": "Julen Etxaniz"
                },
                {
                    "authorId": "2302797813",
                    "name": "Benjamin Fattori"
                },
                {
                    "authorId": "2282474780",
                    "name": "Jessica Zosa Forde"
                },
                {
                    "authorId": "2282542898",
                    "name": "Charles Foster"
                },
                {
                    "authorId": "3036536",
                    "name": "Mimansa Jaiswal"
                },
                {
                    "authorId": "2183377987",
                    "name": "Wilson Y. Lee"
                },
                {
                    "authorId": "2282714065",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "10727711",
                    "name": "Charles Lovering"
                },
                {
                    "authorId": "2037383772",
                    "name": "Niklas Muennighoff"
                },
                {
                    "authorId": "2260118854",
                    "name": "Ellie Pavlick"
                },
                {
                    "authorId": "2241609611",
                    "name": "Jason Phang"
                },
                {
                    "authorId": "2213349418",
                    "name": "Aviya Skowron"
                },
                {
                    "authorId": "2260295997",
                    "name": "Samson Tan"
                },
                {
                    "authorId": "47274259",
                    "name": "Xiangru Tang"
                },
                {
                    "authorId": "2274081109",
                    "name": "Kevin A. Wang"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2302797923",
                    "name": "Franccois Yvon"
                },
                {
                    "authorId": "1380103052",
                    "name": "Andy Zou"
                }
            ]
        },
        {
            "paperId": "e397cac3f38aba116cc623bdf1a6d638537f5e29",
            "title": "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization",
            "abstract": "Pretrained language models (PLMs) have become remarkably adept at task and language generalization. Nonetheless, they often fail when faced with unseen languages. In this work, we present LinguAlchemy, a regularization method that incorporates various linguistic information covering typological, geographical, and phylogenetic features to align PLMs representation to the corresponding linguistic information on each language. Our LinguAlchemy significantly improves the performance of mBERT and XLM-R on low-resource languages in multiple downstream tasks such as intent classification, news classification, and semantic relatedness compared to fully finetuned models and displaying a high degree of unseen language generalization. We further introduce AlchemyScale and AlchemyTune, extension of LinguAlchemy which adjusts the linguistic regularization weights automatically, alleviating the need for hyperparameter search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191731497",
                    "name": "Muhammad Farid Adilazuarda"
                },
                {
                    "authorId": "66986482",
                    "name": "Samuel Cahyawijaya"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "2257345523",
                    "name": "Ayu Purwarianti"
                }
            ]
        }
    ]
}