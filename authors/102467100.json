{
    "authorId": "102467100",
    "papers": [
        {
            "paperId": "98593c51dc7090dd56023ee12105fca9c1ac2e8d",
            "title": "Data Quality Matters: A Case Study of Obsolete Comment Detection",
            "abstract": "Machine learning methods have achieved great success in many software engineering tasks. However, as a data-driven paradigm, how would the data quality impact the effectiveness of these methods remains largely unexplored. In this paper, we explore this problem under the context of just-in-time obsolete comment detection. Specifically, we first conduct data cleaning on the existing benchmark dataset, and empirically observe that with only 0.22% label corrections and even 15.0% fewer data, the existing obsolete comment detection approaches can achieve up to 10.7% relative accuracy improvement. To further mitigate the data quality issues, we propose an adversarial learning framework to simultaneously estimate the data quality and make the final predictions. Experimental evaluations show that this adversarial learning framework can further improve the relative accuracy by up to 18.1% compared to the state-of-the-art method. Although our current results are from the obsolete comment detection problem, we believe that the proposed two-phase solution, which handles the data quality issues through both the data aspect and the algorithm aspect, is also generalizable and applicable to other machine learning based software engineering tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151482825",
                    "name": "Shengbin Xu"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "2579858",
                    "name": "Tianxiao Gu"
                },
                {
                    "authorId": "2158383105",
                    "name": "Jingwei Xu"
                },
                {
                    "authorId": "1695090",
                    "name": "Xiaoxing Ma"
                }
            ]
        },
        {
            "paperId": "00fcfa3e36065bf0e6c11abda0553325600f0855",
            "title": "Detecting Topology Attacks against Graph Neural Networks",
            "abstract": "Graph neural networks (GNNs) have been widely used in many real applications, and recent studies have revealed their vulnerabilities against topology attacks. To address this issue, existing efforts have mainly been dedicated to improving the robustness of GNNs, while little attention has been paid to the detection of such attacks. In this work, we study the victim node detection problem under topology attacks against GNNs. Our approach is built upon the key observation rooted in the intrinsic message passing nature of GNNs. That is, the neighborhood of a victim node tends to have two competing group forces, pushing the node classification results towards the original label and the targeted label, respectively. Based on this observation, we propose to detect victim nodes by deliberately designing an effective measurement of the neighborhood variance for each node. Extensive experimental results on four real-world datasets and five existing topology attacks show the effectiveness and efficiency of the proposed detection approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "104262291",
                    "name": "Senrong Xu"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "2145728192",
                    "name": "Liangyue Li"
                },
                {
                    "authorId": "2150081274",
                    "name": "Wei Yang"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "111cc085b6cfadaeddb5ddb29edd1519bbd9aed4",
            "title": "Untangling Composite Commits by Attributed Graph Clustering",
            "abstract": "During software development, it is considered to be a best practice if each commit represents one distinct concern, such as fixing a bug or adding a new feature. However, developers may not always follow this practice and sometimes tangle multiple concerns into a single composite commit. This makes automatic commit untangling a necessary task, and recent approaches mainly untangle commits via applying graph clustering on the code dependency graph. In this paper, we propose a new commit untangling approach, ComUnt, to decompose the composite commits into atomic ones. Different from existing approaches, ComUnt is built upon the observation that both the textual content of code statements and the dependencies between code statements contain useful semantic information so as to better comprehend the committed code changes. Based on this observation, ComUnt first constructs an attributed graph for each commit, where code statements and various code dependencies are modeled as nodes and edges, respectively, and the textual body of code statements are maintained as node attributes. It then conducts attributed graph clustering on the constructed graph. The used attributed graph clustering algorithm can simultaneously encode both graph structure and node attributes so as to better separate the code changes into clusters with distinct concerns. We evaluate our approach on nine C# projects, and the experimental result shows that ComUnt improves the state-of-the-art by 7.8% in terms of untangling accuracy, and meanwhile it is more than 6 times faster.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185138652",
                    "name": "Siyu Chen"
                },
                {
                    "authorId": "151482825",
                    "name": "Shengbin Xu"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                }
            ]
        },
        {
            "paperId": "37aa95fd344cd223eae19327a43b7b334f59fb6a",
            "title": "Structure Meets Sequences: Predicting Network of Co-evolving Sequences",
            "abstract": "Co-evolving sequences are ubiquitous in a variety of applications, where different sequences are often inherently inter-connected with each other. We refer to such sequences, together with their inherent connections modeled as a structured network, as network of co-evolving sequences (NoCES). Typical NoCES applications include road traffic monitoring, company revenue prediction, motion capture, etc. To date, it remains a daunting challenge to accurately model NoCES due to the coupling between network structure and sequences. In this paper, we propose to modeling \\pname\\ with the aim of simultaneously capturing both the dynamics and the interplay between network structure and sequences. Specifically, we propose a joint learning framework to alternatively update the network representations and sequence representations as the sequences evolve over time. A unique feature of our framework lies in that it can deal with the case when there are co-evolving sequences on both network nodes and edges. Experimental evaluations on four real datasets demonstrate that the proposed approach (1) outperforms the existing competitors in terms of prediction accuracy, and (2) scales linearly w.r.t. the sequence length and the network size.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7708618",
                    "name": "Yaojing Wang"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "634718948c0c212a80a0b43942225a1647b0389f",
            "title": "On the Vulnerability of Graph Learning-based Collaborative Filtering",
            "abstract": "Graph learning-based collaborative filtering (GLCF), which is built upon the message-passing mechanism of graph neural networks (GNNs), has received great recent attention and exhibited superior performance in recommender systems. However, although GNNs can be easily compromised by adversarial attacks as shown by the prior work, little attention has been paid to the vulnerability of GLCF. Questions like can GLCF models be just as easily fooled as GNNs remain largely unexplored. In this article, we propose to study the vulnerability of GLCF. Specifically, we first propose an adversarial attack against CLCF. Considering the unique challenges of attacking GLCF, we propose to adopt the greedy strategy in searching for the local optimal perturbations and design a reasonable attacking utility function to handle the non-differentiable ranking-oriented metrics. Next, we propose a defense to robustify GCLF. The defense is based on the observation that attacks usually introduce suspicious interactions into the graph to manipulate the message-passing process. We then propose to measure the suspicious score of each interaction and further reduce the message weight of suspicious interactions. We also give a theoretical guarantee of its robustness. Experimental results on three benchmark datasets show the effectiveness of both our attack and defense.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "104262291",
                    "name": "Senrong Xu"
                },
                {
                    "authorId": "2145728192",
                    "name": "Liangyue Li"
                },
                {
                    "authorId": "15401196",
                    "name": "Zenan Li"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "8157135",
                    "name": "Zulong Chen"
                },
                {
                    "authorId": "2117522225",
                    "name": "Quan Lu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "6da89ce0b8968941c060599a0c2bc67d73e942f5",
            "title": "Fair Representation Learning: An Alternative to Mutual Information",
            "abstract": "Learning fair representations is an essential task to reduce bias in data-oriented decision making. It protects minority subgroups by requiring the learned representations to be independent of sensitive attributes. To achieve independence, the vast majority of the existing work primarily relaxes it to the minimization of the mutual information between sensitive attributes and learned representations. However, direct computation of mutual information is computationally intractable, and various upper bounds currently used either are still intractable or contradict the utility of the learned representations. In this paper, we introduce distance covariance as a new dependence measure into fair representation learning. By observing that sensitive attributes (e.g., gender, race, and age group) are typically categorical, the distance covariance can be converted to a tractable penalty term without contradicting the utility desideratum. Based on the tractable penalty, we propose FairDisCo, a variational method to learn fair representations. Experiments demonstrate that FairDisCo outperforms existing competitors for fair representation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2156709322",
                    "name": "Ji Liu"
                },
                {
                    "authorId": "15401196",
                    "name": "Zenan Li"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "1695090",
                    "name": "Xiaoxing Ma"
                },
                {
                    "authorId": "49235356",
                    "name": "Miao Xu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "b60c5ba08d3ad45f2771daf4c31668d5e344f4d3",
            "title": "Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer",
            "abstract": "Backdoor attacks have been shown to be a serious security threat against deep learning models, and detecting whether a given model has been backdoored becomes a crucial task. Existing defenses are mainly built upon the observation that the backdoor trigger is usually of small size or affects the activation of only a few neurons. However, the above observations are violated in many cases especially for advanced backdoor attacks, hindering the performance and applicability of the existing defenses. In this paper, we propose a backdoor defense DTInspector built upon a new observation. That is, an effective backdoor attack usually requires high prediction confidence on the poisoned training samples, so as to ensure that the trained model exhibits the targeted behavior with a high probability. Based on this observation, DTInspector first learns a patch that could change the predictions of most high-confidence data, and then decides the existence of backdoor by checking the ratio of prediction changes after applying the learned patch on the low-confidence data. Extensive evaluations on five backdoor attacks, four datasets, and three advanced attacking types demonstrate the effectiveness of the proposed defense.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116679419",
                    "name": "Tong Wang"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "2180603808",
                    "name": "Miao Xu"
                },
                {
                    "authorId": "2072528961",
                    "name": "Shengwei An"
                },
                {
                    "authorId": "2155393459",
                    "name": "Ting Wang"
                }
            ]
        },
        {
            "paperId": "d7a1196df380301628b4d40d819e627012571299",
            "title": "Combining Code Context and Fine-grained Code Difference for Commit Message Generation",
            "abstract": "Generating natural language messages for source code changes is an essential task in software development and maintenance. Existing solutions mainly treat a piece of code difference as natural language, and adopt seq2seq learning to translate it into a commit message. The basic assumption of such solutions lies in the naturalness hypothesis, i.e., source code written by programming languages is to some extent similar to natural language text. However, compared with natural language, source code also bears syntactic regularities. In this paper, we propose to simultaneously model the naturalness and syntactic regularities of source code changes for commit message generation. Specifically, to model syntactic regularities, we first enlarge the input with additional context information, i.e., the code statements that have dependency with the variables in the code difference, and then extract the paths in the corresponding ASTs. Moreover, to better model code difference, we align the two versions of code before and after the committed code change at token level, and annotate their differences with fine-grained edit operations. The context and difference are simultaneously encoded in a learning framework to generate the commit messages. We collected from GitHub a large dataset containing 480 Java projects with over 160k commits, and the experimental results demonstrate the effectiveness of the proposed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151482825",
                    "name": "Shengbin Xu"
                },
                {
                    "authorId": "46461580",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "2579858",
                    "name": "Tianxiao Gu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "264d29f70b50af918debfb2bfc9af312e7ae1f12",
            "title": "Auditing Network Embedding: An Edge Influence Based Approach",
            "abstract": "Learning node representations in a network has a wide range of applications. Most of the existing work focuses on improving the performance of the learned node representations by designing advanced network embedding models. In contrast to these work, this article aims to provide some understanding of the rationale behind the existing network embedding models, e.g., <italic>why</italic> a given embedding algorithm outputs the specific node representations and <italic>how</italic> the resulting node representations relate to the structure of the input network. In particular, we propose to discern the edge influence for two widely-studied classes of network embedding models, i.e., skip-gram based models and graph neural networks. We provide algorithms to effectively and efficiently quantify the edge influence on node representations, and further identify high-influential edges by exploiting the linkage between edge influence and network structure. Experimental evaluations are conducted on real datasets showing that: 1) in terms of quantifying edge influence, the proposed method is significantly faster (up to <inline-formula><tex-math notation=\"LaTeX\">$2,000\\times$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn><mml:mo>\u00d7</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=\"wang-ieq1-3056884.gif\"/></alternatives></inline-formula>) than straightforward methods with little quality loss, and 2) in terms of identifying high-influential edges, the identified edges by the proposed method have a significant impact in the context of downstream prediction task and adversarial attacking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7708618",
                    "name": "Yaojing Wang"
                },
                {
                    "authorId": "2116470867",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "145002167",
                    "name": "Jian Lu"
                }
            ]
        },
        {
            "paperId": "b401be63146f4249a34d7e6ad366f881cadefda7",
            "title": "Unsupervised Attributed Network Embedding via Cross Fusion",
            "abstract": "Attributed network embedding aims to learn low dimensional node representations by combining both the network's topological structure and node attributes. Most of the existing methods either propagate the attributes over the network structure or learn the node representations by an encoder-decoder framework. However, propagation based methods tend to prefer network structure to node attributes, whereas encoder-decoder methods tend to ignore the longer connections beyond the immediate neighbors. In order to address these limitations while enjoying the best of the two worlds, we design cross fusion layers for unsupervised attributed network embedding. Specifically, we first construct two separate views to handle network structure and node attributes, and then design cross fusion layers to allow flexible information exchange and integration between the two views. The key design goals of the cross fusion layers are three-fold: 1) allowing critical information to be propagated along the network structure, 2) encoding the heterogeneity in the local neighborhood of each node during propagation, and 3) incorporating an additional node attribute channel so that the attribute information will not be overshadowed by the structure view. Extensive experiments on three datasets and three downstream tasks demonstrate the effectiveness of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1381607232",
                    "name": "Guosheng Pan"
                },
                {
                    "authorId": "2116470867",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "102467100",
                    "name": "F. Xu"
                },
                {
                    "authorId": "145002167",
                    "name": "Jian Lu"
                }
            ]
        }
    ]
}