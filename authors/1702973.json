{
    "authorId": "1702973",
    "papers": [
        {
            "paperId": "078cf7814eceec44986314b2e4e84ddfa9efb927",
            "title": "Fairness and Robustness in Answering Preference Queries",
            "abstract": "Given a large number of users preferences as inputs over a large number of items, preference queries leverage different preference aggregation methods to aggregate individual preferences in a systematic manner and come up with a single output (top-k ordered or unordered/a complete order) that is most representative. The preference aggregation methods are widely adopted from the social choice theory, some of which are rank based (single-round vs. multi-round), while others are non-rank based. These queries are prevalent in high \ufb01delity applications, including search, ranking and recommendation, hiring and admission, and electoral voting systems. This article outlines algorithmic challenges and directions in designing an optimization guided computational framework that allows to change the original aggregated output (either ordered or unordered top-k or a complete order) to satisfy different criteria related to fairness and robustness, considering different preference elicitation models (ways users provide their input preferences) and aggregation methods (ways the individual preference get aggregated).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "271c35255cc05057472e78a71e65775ba2299f74",
            "title": "Satisfying Complex Top-k Fairness Constraints by Preference Substitutions",
            "abstract": "\n Given\n m\n users (voters), where each user casts her preference for a single item (candidate) over\n n\n items (candidates) as a ballot, the preference aggregation problem returns\n k\n items (candidates) that have the\n k\n highest number of preferences (votes). Our work studies this problem considering\n complex fairness constraints\n that have to be satisfied via proportionate representations of different values of the group protected attribute(s) in the top-\n k\n results. Precisely, we study\n the margin finding problem under single ballot substitutions\n , where a single substitution amounts to removing a vote from candidate\n i\n and assigning it to candidate\n j\n and the goal is to\n minimize the number of single ballot substitutions needed to guarantee that the top-k results satisfy the fairness constraints.\n We study several variants of this problem considering how top-\n k\n fairness constraints are defined, (i) MFBinaryS and MFMultiS are defined when the fairness (proportionate representation) is defined over a single, binary or multivalued, protected attribute, respectively; (ii) MF-Multi2 is studied when top-\n k\n fairness is defined over two different protected attributes; (iii) MFMulti3+ investigates the margin finding problem, considering 3 or more protected attributes. We study these problems theoretically, and present a suite of algorithms with provable guarantees. We conduct rigorous large scale experiments involving multiple real world datasets by appropriately adapting multiple state-of-the-art solutions to demonstrate the effectiveness and scalability of our proposed methods.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157481581",
                    "name": "Md Mouinul Islam"
                },
                {
                    "authorId": "2114004511",
                    "name": "Dong Wei"
                },
                {
                    "authorId": "1771729",
                    "name": "B. Schieber"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "d6f895219b74103fb24fdcac6061e9ef5115603f",
            "title": "Rank Aggregation with Proportionate Fairness",
            "abstract": "Given multiple individual rank orders over a set of candidates or items, where the candidates belong to multiple (non-binary) protected groups, we study the classical rank aggregation problem subject to proportionate fairness or p-fairness (RAPF in short), considering Kemeny distance. We first study the problem of producing the closest p-fair ranking to an individual ranked order IPF in short) considering Kendall-Tau distance, and present multiple solutions for IPF. We then present two computational frameworks(a randomized randpickperm and a deterministic algpickperm) to solve RAPF that leverages the solutions of IPF as a subroutine. We make several non-trivial algorithmic contributions: (i) we prove that when the group protected attribute is binary, IPF can be solved exactly using a greedy technique; (ii) we present two different solutions for IPF when the group protected attribute is multi-valued, algexact is optimal and algapprox admits a 2 approximation factor; (iii) we design a framework for RAPF solution with an approximation factor that is 2+ the approximation factor of the IPF solution. The resulting randpickperm and algpickperm solutions exhibit 3 and 4 approximation factors when designed using algexact and algapprox, respectively. We run extensive experiments using multiple real world and large scale synthetic datasets and compare our proposed solutions against multiple state-of-the-art related works to demonstrate the effectiveness and efficiency of our studied problem and proposed solution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114004511",
                    "name": "Dong Wei"
                },
                {
                    "authorId": "2157481581",
                    "name": "Md Mouinul Islam"
                },
                {
                    "authorId": "1771729",
                    "name": "B. Schieber"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "e710e2a5bfb95befc03cf6bb5182ca5254276d59",
            "title": "Cooperative Route Planning Framework for Multiple Distributed Assets in Maritime Applications",
            "abstract": "This work formalizes the Route Planning Problem (RPP), wherein a set of distributed assets (e.g., ships, submarines, unmanned systems) simultaneously plan routes to optimize a team goal (e.g., find the location of an unknown threat or object in minimum time and/or fuel consumption) while ensuring that the planned routes satisfy certain constraints (e.g., avoiding collisions and obstacles). This problem becomes overwhelmingly complex for multiple distributed assets as the search space grows exponentially to design such plans. The RPP is formalized as a Team Discrete Markov Decision Process (TDMDP) and we propose a Multi-agent Multi-objective Reinforcement Learning (MaMoRL) framework for solving it. We investigate challenges in deploying the solution in real-world settings and study approximation opportunities. We experimentally demonstrate MaMoRL's effectiveness on multiple real-world and synthetic grids, as well as for transfer learning. MaMoRL is deployed for use by the Naval Research Laboratory - Marine Meteorology Division (NRL-MMD), Monterey, CA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106769934",
                    "name": "Sepideh Nikookar"
                },
                {
                    "authorId": "2106777173",
                    "name": "Paras Sakharkar"
                },
                {
                    "authorId": "2134167968",
                    "name": "Sathyanarayanan Somasunder"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2059566296",
                    "name": "A. Bienkowski"
                },
                {
                    "authorId": "2110274948",
                    "name": "Matthew Macesker"
                },
                {
                    "authorId": "1680494",
                    "name": "K. Pattipati"
                },
                {
                    "authorId": "1741994",
                    "name": "D. Sidoti"
                }
            ]
        },
        {
            "paperId": "fbb9c03c1ef3b27a4ee6694d4fc6f8034d5fbe59",
            "title": "Guided Task Planning Under Complex Constraints",
            "abstract": "Creating a plan, i.e., composing a sequence of items to achieve a task is inherently complex if done manually. This requires not only finding a sequence of relevant items but also understanding user requirements and incorporating them as constraints. For instance, in course planning, items are core and elective courses, and degree requirements capture their complex dependencies as constraints. In trip planning, items are points of interest (POIs) and constraints represent time and monetary budget, two user-specified requirements. Most importantly, a plan must comply with the ideal interleaving of items to achieve a goal such as enhancing students' skills towards the broader learning goal of an education program, or in the travel scenario, improving the overall user experience. We study the Task Planning Problem (TPP) with the goal of generating a sequence of items that optimizes multiple objectives while satisfying complex constraints. TPP is modeled as a Constrained Markov Decision Process, and we adapt weighted Reinforcement Learning to learn a policy that satisfies complex dependencies between items, user requirements, and satisfaction. We present a computational framework RL-Planner for TPP. RL-Planner requires minimal input from domain experts (academic advisors for courses, or travel agents for trips), yet produces personalized plans satisfying all constraints. We run extensive experiments on datasets from university programs and from travel agencies. We compare our solutions with plans drafted by human experts and with fully automated approaches. Our experiments corroborate that existing automated solutions are not suitable to solve TPP and that our plans are highly comparable to expensive handcrafted ones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106769934",
                    "name": "Sepideh Nikookar"
                },
                {
                    "authorId": "2106777173",
                    "name": "Paras Sakharkar"
                },
                {
                    "authorId": "2180276442",
                    "name": "Baljinder Smagh"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "00aadbd1b1e83ae19372af40ba86f35d7bf108b9",
            "title": "A Generalized Approach for Reducing Expensive Distance Calls for A Broad Class of Proximity Problems",
            "abstract": "In this paper, we revisit a suite of popular proximity problems (such as, KNN, clustering, minimum spanning tree) that repeatedly perform distance computations to compare distances during their execution. Our effort here is to design principled solutions to minimize distance computations for such problems in general metric spaces, especially for the scenarios where calling an expensive oracle to resolve unknown distances are the dominant cost of the algorithms for these problems. We present a suite of techniques, including a novel formulation of the problem, that studies how distance comparisons between objects could be modelled as a system of linear inequalities that assists in saving distance computations, multiple graph based solutions, as well as a practitioners guide to adopt our solution frameworks to proximity problems. We compare our designed solutions conceptually and empirically with respect to a broad range of existing works. We finally present a comprehensive set of experimental results using multiple large scale real-world datasets and a suite of popular proximity algorithms to demonstrate the effectiveness of our proposed approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51124778",
                    "name": "Jees Augustine"
                },
                {
                    "authorId": "1442194534",
                    "name": "Suraj Shetiya"
                },
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "cc4fb324fb282dd16126695b548d8ed57aa3bc9d",
            "title": "Peer Learning Through Targeted Dynamic Groups Formation",
            "abstract": "Peer groups leverage the presence of knowledgeable individuals in order to increase the knowledge level of other participants. The \u2018smart\u2019 formation of peer groups can thus play a crucial role in educational settings, including online social networks and learning platforms. Indeed, the targeted groups formation problem, where the objective is to maximize a measure of aggregate knowledge, has received considerable attention in recent literature. In this paper we initiate a dynamic variant of the problem that, unlike previous works, allows the change of group composition over time while still targeting to maximize the aggregated knowledge level. The problem is studied in a principled way, using a realistic learning gain function and for two different interaction modes among the group members. On the algorithmic side, we present DyGroups, a generic algorithmic framework that is greedy in nature and highly scalable. We present non-trivial proofs to demonstrate theoretical guarantees for DyGroups in a special case. We also present real peer learning experiments with humans, and perform synthetic data experiments to demonstrate the effectiveness of our proposed solutions by comparing against multiple appropriately selected baseline algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114004511",
                    "name": "Dong Wei"
                },
                {
                    "authorId": "2262243",
                    "name": "I. Koutis"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "cda187be8316892eecd1f9cfbfa70972f165ecc7",
            "title": "Multi-Session Diversity to Improve User Satisfaction in Web Applications",
            "abstract": "In various Web applications, users consume content in a series of sessions. That is prevalent in online music listening, where a session is a channel and channels are listened to in sequence, or in crowdsourcing, where a session is a set of tasks and task sets are completed in sequence. Content diversity can be defined in more than one way, e.g., based on artists or genres for music, or on requesters or rewards in crowdsourcing. A user may prefer to experience diversity within or across sessions. Naturally, intra-session diversity is set-based, whereas, inter-session diversity is sequence-based. This novel multi-session diversity gives rise to four bi-objective problems with the goal of minimizing or maximizing inter and intra diversities. Given the hardness of those problems, we propose to formulate a constrained optimization problem that optimizes inter diversity, subject to the constraint of intra diversity. We develop an efficient algorithm to solve our problem. Our experiments with human subjects on two real datasets, music and crowdsourcing, show our diversity formulations do serve different user needs, and yield high user satisfaction. Our large data experiments on real and synthetic data empirically demonstrate that our solution satisfy the theoretical bounds and is highly scalable, compared to baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "2106769934",
                    "name": "Sepideh Nikookar"
                },
                {
                    "authorId": "2106777173",
                    "name": "Paras Sakharkar"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "d9afa74a583172627ad89128ebb820e6f82f1910",
            "title": "Data Management to Social Science and Back in the Future of Work",
            "abstract": "How will we work, live, and thrive in the post-pandemic future? The rapid mushrooming of online job markets has been transforming the definition of work and workplaces. After the pandemic, as we \"cope with the new normal\", the future world of work may change forever and become predominantly virtual. This makes an unprecedented pool of talent available at our beck and calls to work on \"gigs\" that disband when the job is over; this also is the time of destabilization and changing nature of job security. As scientists, we have a big responsibility and a tremendous opportunity in shaping the Future of Work (FoW) post pandemic, by designing effective platforms that support productive employment, mitigate social costs, and provide an effective and safe learning environment. A research agenda for FoW must mobilize the participation of various scientific, regulatory and miscellaneous stakeholders [10]. We will ask the questions: what is the role of Data Management (DM) in shaping research on FoW? Is now a ripe time to get Economics, Labor Theory, Psychology of Work and AI to help put DM research and technology at the center of research on FoW? Are we at all interested? The panelists will debate two complementary views: A pessimistic view on whether FoW will tend to see humans as machines, robots, or low-level agents and use them in the service of broader AI goals vs. a more optimistic view, where AI and Social Science will help DM to develop technologies that empower humans for future workforce and workplaces.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "5803beccf5ae644e58691adc6cece5ba53eb8fa0",
            "title": "Task Deployment Recommendation with Worker Availability",
            "abstract": "We study recommendation of deployment strategies to task requesters that are consistent with their deployment parameters: a lower-bound on the quality of the crowd contribution, an upper-bound on the latency of task completion, and an upper-bound on the cost incurred by paying workers. We propose BatchStrat, an optimization-driven middle layer that recommends deployment strategies to a batch of requests by accounting for worker availability. We develop computationally efficient algorithms to recommend deployments that maximize task throughput and pay-off, and empirically validate its quality and scalability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114004511",
                    "name": "Dong Wei"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "aa639036f6c4a76752b679dcde00d62d7bedd16c",
            "title": "Recommending Deployment Strategies for Collaborative Tasks",
            "abstract": "Our work contributes to aiding requesters in deploying collaborative tasks in crowdsourcing. We initiate the study of recommending deployment strategies for collaborative tasks to requesters that are consistent with deployment parameters they desire: a lower-bound on the quality of the crowd contribution, an upper-bound on the latency of task completion, and an upper-bound on the cost incurred by paying workers. A deployment strategy is a choice of value for three dimensions: Structure (whether to solicit the workforce sequentially or simultaneously), Organization (to organize it collaboratively or independently), and Style (to rely solely on the crowd or to combine it with machine algorithms). We propose StratRec, an optimization-driven middle layer that recommends deployment strategies and alternative deployment parameters to requesters by accounting for worker availability. Our solutions are grounded in discrete optimization and computational geometry techniques that produce results with theoretical guarantees. We present extensive experiments on Amazon Mechanical Turk, and conduct synthetic experiments to validate the qualitative and scalability aspects of StratRec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114004511",
                    "name": "Dong Wei"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "0d4d6cca21dccc15a3baa1f22fb93158dcff01bb",
            "title": "Capturing Human Factors to Optimize Crowdsourced Label Acquisition through Active Learning",
            "abstract": "The goal of this article is to propose an optimization framework by acknowledging human factors to enable label acquisition through active learning . In particular, we are interested to investigate tasks, such as, providing (collecting or acquiring) and validating labels, or comparing data using active learning techniques. Our basic approach is to take a set of existing active learning techniques for a few well known supervised and unsupervised algorithms, but study them in the context of crowdsourcing, especially considering worker-centric optimization (i,e., human factors) . Our innovation lies in designing optimization functions that appropriately capture these two fundamental yet complementary facets, performing systematic investigation to understand the complexity of such optimization problems, and designing ef\ufb01cient solutions with theoretical guarantees.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "1bdcb57358f2b8295f9ff9816722e0f904e2a808",
            "title": "Human-in-the-loop Exploration of Composite Items",
            "abstract": "Human-in-the-loop data exploration is seeing a renewed interest in our community. With the rise of big data analytics, this area is growing to encompass not only approaches and algorithms to find the next best data items to explore but also interactivity, i.e. accounting for feedback from the data scientist during the exploration. Interactivity is essential to account for evolving needs during the exploration and also customize the discovery process. In this tutorial, we focus on exploration of Composite Items (CIs) that require repeated interaction with human users. CIs address complex information needs and are prevalent in online shopping where products are bundled together to provide discounts, in travel itinerary recommendation where points of interest in a city are combined into a single travel package, and task assignment in crowdsourcing where persoalized micro-tasks are composed and recommended to workers. CI formation is usually expressed as a constrained optimization problem. For instance, in online shopping, package retrieval can retrieve the cheapest smartphones (optimization objective) with compatible accessories (constraints). Similarly, a city tour must be the most popular and conform to a total time and cost budget. A data scientist interested in exploring a variety of CIs has to repeatedly reformulate optimization problems with new constraints and objectives. In this tutorial, we investigate the applicability of interactive data exploration approaches to CI formation. The tutorial will have the following parts: \u2022 15 minutes We will first review CI applications and shapes (15mn) that are applicable in different domains. This part will gather different examples and attempt to unify them. \u2022 60 minutes We then discuss three big research questions: (i) existing algorithms for CI formation, (ii) human-in-the-loop CIs, and (iii) optimization opportunities. \u2022 15 minutes We conclude with ongoing and future research directions. The tutorial targets theoreticians and practitioners interested in the development of data science applications. It should be of particular interest to database researchers, applied machine learners, as well as data scientists in industrial research settings who want to learn about how different domains, such as product recommendation, scientific simulation, or team formation in the social sciences and crowdsourcing, have been developing their \"siloed\" definitions of CIs. The research direction presented in the tutorial will be helpful to converge these domain specific ideas and creating an overarching generic framework. Tutorial attendees are expected to have basic knowledge in algorithms and data management. Knowledge in constrained optimization is not necessary. The proposed tutorial is timely. It brings together several related efforts and addresses unsolved questions in the emerging area of human-in-the-loop exploration of complex information needs. The tutorial is relevant to the general area of data science and more specifically to Scalable Analytics, Data Mining, Clustering and Knowledge Discovery, Indexing, Query Processing and Optimization, and Crowdsourcing. The technical topics covered are constrained optimization, ranking semantics, clustering, algorithms, and empirical evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "49ef2ab7502931e1cd7eb6c05600f697aa6d807f",
            "title": "A Human-in-the-loop Attribute Design Framework for Classification",
            "abstract": "In this paper, we present a semi-automated, \u201chuman-in-the-loop\u201d framework for attribute design that assists human analysts to transform raw attributes into effective derived attributes for classification problems. Our proposed framework is optimization guided and fully agnostic to the underlying classification model. We present an algebra with various operators (arithmetic, relational, and logical) to transform raw attributes into derived attributes and solve two technical problems: (a) the top-k buckets design problem aims at presenting human analysts with k buckets, each bucket containing promising choices of raw attributes that she can focus on only without having to look at all raw attributes; and (b) the top-l snippets generation problem, which iteratively aids human analysts with top-l derived attributes involving an attribute. For the former problem, we present an effective exact bottom-up algorithm that is empowered by pruning capability, as well as random walk based heuristic algorithms that are intuitive and work well in practice. For the latter, we present a greedy heuristic algorithm that is scalable and effective. Rigorous evaluations are conducted involving 6 different real world datasets to showcase that our framework generates effective derived attributes compared to fully manual or fully automated methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184184985",
                    "name": "Md. Abdus Salam"
                },
                {
                    "authorId": "1415163205",
                    "name": "Mary E. Koone"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "8d130f927c170146497e6f3f029e7e173103bc45",
            "title": "Optimizing Peer Learning in Online Groups with Affinities",
            "abstract": "We investigate online group formation where members seek to increase their learning potential via collaboration. We capture two common learning models: LpA where each member learns from all higher skilled ones, and LpD where the least skilled member learns from the most skilled one. We formulate the problem of forming groups with the purpose of optimizing peer learning under different affinity structures: AffD where group affinity is the smallest between all members, and AffC where group affinity is the smallest between a designated member (e.g., the least skilled or the most skilled) and all others. This gives rise to multiple variants of a multiobjective optimization problem. We propose principled modeling of these problems and investigate theoretical and algorithmic challenges. We first present hardness results, and then develop computationally efficient algorithms with constant approximation factors. Our real-data experiments demonstrate with statistical significance that forming groups considering affinity improves learning. Our extensive synthetic experiments demonstrate the qualitative and scalability aspects of our solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "2114004511",
                    "name": "Dong Wei"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "d90fcff732e3188424971da59995249d322f0fda",
            "title": "The Ever Evolving Online Labor Market: Overview, Challenges and Opportunities",
            "abstract": "The goal of this tutorial is to make the audience aware of various discipline-specific research activities that could be characterized to be part of online labor markets and advocate for a unified framework that is interdisciplinary in nature and requires convergence of different research disciplines. We will discuss how such a framework could bring transformative effect on the nexus of humans, technology, and the future of work. PVLDB Reference Format: Sihem Amer-Yahia, Senjuti Basu Roy. The Ever Evolving Online Labor Market: Overview, Challenges and Opportunities. PVLDB, 12(12): 1978-1981, 2019. DOI: https://doi.org/10.14778/3352063.3352114 1. OVERVIEW AND RELEVANCE The rapid development of professional social networks and online labor markets, is affecting the future of jobs and workers. Professional social networks such as LinkedIn, are revolutionizing hiring practices. An increasing number of individuals rely on such networks to find jobs, and it is becoming common practice for head hunters and companies to examine one\u2019s profile on LinkedIn before contacting or hiring someone. Online job marketplaces are gaining popularity as mediums to hire people to perform certain tasks. These marketplaces include freelancing platforms such as Qapa and MisterTemp\u2019 in France, and TaskRabbit and Fiverr in the USA. On those platforms, workers can find temporary jobs in the physical world (e.g., looking for a plumber), or in the form of virtual \u201cmicro-gigs\u201d such as \u201chelp with HTML, JavaScript, CSS, and JQuery\u201d. Crowdsourcing platforms are a very popular type of online job marketplaces nowadays. These platforms are fully virtual: workers are hired online and tasks are also completed online. Examples of crowdsourcing platforms are FouleFactory, and Prolific Academic in Europe, and Amazon Mechanical Turk and Figure Eight in the USA. As the gig economy grows, an important offshoot of this movement is \u201cflash organizations\u201d, the This work is licensed under the Creative Commons AttributionNonCommercial-NoDerivatives 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. Proceedings of the VLDB Endowment, Vol. 12, No. 12 ISSN 2150-8097. DOI: https://doi.org/10.14778/3352063.3352114 pop-up shops that come together for a purpose, such as developing and marketing an app. They include entire teams that work closely together, and when the project is complete, the teams disband. For example, Gigster.com is a smart development service that brings freelancers together into software-building teams on demand at any time, or Artella.com is designed for creating complex animated features, offering teams of freelance animators, sound designers, and other talent at your beck and call. From a conceptual standpoint, online labor markets can be characterized as follows: workers are the producers of work that are to be consumed by systems, platforms, or organizations. Workers need to be hired, treated, and compensated fairly, they have to be assisted to accomplish their work or further their career. On the other hand, consumers, such as, business, organizations, or platforms need to hire an appropriate workforce to be able to accomplish their business goal in time, with certain accuracy, and within budget. Social science as well as data-centric research [5, 7, 8, 10, 13, 14, 18, 23, 26, 27] have developed disconnected and discipline-specific approaches to solve different problems in online labor markets. For example, social science researchers have proposed conceptual frameworks, visualization, and software prototypes to recruit workers and form appropriate teams, decompose complex tasks to assist workers, or propose tools to enable interactivity and collaboration among workers. Database research, on the other hand, has addressed scalability and data management challenges of how to curate and clean data produced by online labor markets, how to model the data and store it effectively, or how to form appropriate teams [3, 21, 22]. Machine learning research [7, 14, 27] proposed models that are capable of aggregating workers\u2019 contributions or infer/estimate groundtruths when that is unknown. Finally, psychology and organizational research [17, 25] proposed conceptual models that are required to understand and analyze human behavior in online labor market. We will first describe different applications that rely on free-lancing and online labor markets. Then, we will re-visit seminal and prominent works that came out from different research communities (social science, machine learning, data management, psychology and organizational research, and economics) on the topic of online labor markets, describe their approaches and summarize their impact on science, society and industry. Finally, we will outline the requirements of a unified framework that has the potential to combine the best of all these worlds and present modeling, data management, and algorithmic challenges to conceptualize it.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "0c430b800dd2afc5b4b4e6359f65205776cafd3f",
            "title": "Interactive Exploration of Composite Items",
            "abstract": "Data exploration is seeing a renewed interest in our community. With the rise of big data analytics, this area is growing to encompass not only approaches and algorithms to find the next best data items to explore but also interactivity, i.e. accounting for feedback from the data scientist during the exploration. Interactivity is essential to account for evolving needs during the exploration and also customize the discovery process. In this tutorial, we focus on the interactive exploration of Composite Items (CIs). CIs address complex information needs and are prevalent in online shopping where products are bundled together to provide discounts, in travel itinerary recommendation where points of interest in a city are combined into a single travel package, and task assignment in crowdsourcing where persoalized micro-tasks are composed and recommended to workers. CI formation is usually expressed as a constrained optimization problem. For instance, in online shopping, package retrieval can retrieve the cheapest smartphones (optimization objective) with compatible accessories (constraints). Similarly, a city tour must be the most popular and conform to a total time and cost budget. A data scientist interested in exploring a variety of CIs has to repeatedly reformulate optimization problems with new constraints and objectives. In this tutorial, we investigate the applicability of interactive data exploration approaches to CI formation. We will first review CI applications and shapes (15mn). We then discuss three big research questions 60mn): (i) algorithms for CI formation, (ii) modes of exploration for CIs, and (iii) human-inthe-loop CIs. We will conclude with research directions (15mn). The proposed tutorial is timely. It brings together several related efforts and addresses unsolved questions in the emerging area of human-in-the-loop exploration of complex information needs. The tutorial is relevant to the general area of data science and more specifically to Scalable Analytics, Data Mining, Clustering and Knowledge Discovery, Indexing, Query Processing and Optimization, and Crowdsourcing. The technical topics covered are constrained optimization, ranking semantics, clustering, algorithms, and empirical evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "4760d21ac33ad0823bc2bb4e890b6e8d66d8978f",
            "title": "Eliciting Worker Preference for Task Completion",
            "abstract": "Current crowdsourcing platforms provide little support for worker feedback. Workers are sometimes invited to post free text describing their experience and preferences in completing tasks. They can also use forums such as Turker Nation1 to exchange preferences on tasks and requesters. In fact, crowdsourcing platforms rely heavily on observing workers and inferring their preferences implicitly. In this work, we believe that asking workers to indicate their preferences explicitly improve their experience in task completion and hence, the quality of their contributions. Explicit elicitation can indeed help to build more accurate worker models for task completion that captures the evolving nature of worker preferences. We design a worker model whose accuracy is improved iteratively by requesting preferences for task factors such as required skills, task payment, and task relevance. We propose a generic framework, develop efficient solutions in realistic scenarios, and run extensive experiments that show the benefit of explicit preference elicitation over implicit ones with statistical significance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "50a75970ba569b6341df027b2000b461feb4ea12",
            "title": "Task Relevance and Diversity as Worker Motivation in Crowdsourcing",
            "abstract": "Task assignment is a central component in crowdsourcing. Organizational studies have shown that worker motivation in completing tasks has a direct impact on the quality of individual contributions. In this work, we examine motivation-aware task assignment in the presence of a set of workers. We propose to model motivation as a balance between task relevance and task diversity and argue that an adaptive approach to task assignment can best capture the evolving nature of motivation. Worker motivation is observed and task assignment is revisited appropriately across iterations. We prove the problem to be NP-hard as well as MaxSNP-Hard and develop efficient approximation algorithms with provable guarantees. Our experiments with synthetic data examine the scalability of our algorithms, and our live real data experiments show that capturing motivation using relevance and diversity leads to high crowdwork quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3416184",
                    "name": "Julien Pilourdault"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145948198",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "5e591c2e58e0e1d7e5acce728e975de6b1a52890",
            "title": "Crowdsourcing Analytics With CrowdCur",
            "abstract": "We propose to demonstrate CrowdCur \\xspace, a system that allows platform administrators, requesters, and workers to conduct various analytics of interest. CrowdCur \\xspace includes a worker curation component that relies on explicit feedback elicitation to best capture workers' preferences, a task curation component that monitors task completion and aggregates their statistics, and an OLAP-style component to query and combine analytics by a worker, by task type, etc. Administrators can fine tune their system's performance. Requesters can compare platforms and better choose the set of workers to target. Workers can compare themselves to others and find tasks and requesters that suit them best.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "2041784910",
                    "name": "Kavan Patel"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "8033d0c50794dfd251e4dab3e056977bf46be952",
            "title": "Explicit Preference Elicitation for Task Completion Time",
            "abstract": "Current crowdsourcing platforms provide little support for worker feedback. Workers are sometimes invited to post free text describing their experience and preferences in completing tasks. They can also use forums such as Turker Nation1 to exchange preferences on tasks and requesters. In fact, crowdsourcing platforms rely heavily on observing workers and inferring their preferences implicitly. On the contrary, we believe that asking workers to indicate their preferences explicitly will allow us to improve different processes in crowdsourcing platforms. We initiate a study that leverages explicit elicitation from workers to capture the evolving nature of worker preferences and we propose an optimization framework to better understand and estimate task completion time. We design a Worker model to estimate task completion time whose accuracy is improved iteratively by requesting worker preferences for task factors, such as, required skills, task payment, and task relevance. We develop efficient solutions with guarantees, run extensive experiments with large-scale real-world data that show the benefit of explicit preference elicitation over implicit ones with statistical significance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "945165ac02035b2cf7ab32775f5910e159ef6431",
            "title": "Motivation-Aware Task Assignment in Crowdsourcing",
            "abstract": "We investigate how to leverage the notion of motivation in assigning tasks to workers and improving the performance of a crowdsourcing system. In particular, we propose to model motivation as the balance between task diversity\u2013i.e., the difference in skills among the tasks to complete, and task payment\u2013i.e., the difference between how much a chosen task offers to pay and how much other available tasks pay. We propose to test different task assignment strategies: (1) relevance, a strategy that assigns matching tasks, i.e., those that fit a worker's profile, (2) diversity, a strategy that chooses matching and diverse tasks, and (3) div-pay, a strategy that selects matching tasks that offer the best compromise between diversity and payment. For each strategy , we study multiple iterations where tasks are reassigned to workers as their motivation evolves. At each iteration, relevance and diversity assign tasks to a worker from an available pool of filtered tasks. div-pay, on the other hand, estimates each worker's motivation on-the-fly at each iteration, and uses it to assign tasks to the worker. Our empirical experiments study the impact of each strategy on overall performance. We examine both requester-centric and worker-centric performance dimensions and find that different strategies prevail for different dimensions. In particular, relevance offers the best task throughput while div-pay achieves the best outcome quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3416184",
                    "name": "Julien Pilourdault"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145948198",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "9d774a0f976407296a1585750010722867baf1fe",
            "title": "Combating the Cold Start User Problem in Model Based Collaborative Filtering",
            "abstract": "For tackling the well known cold-start user problem in model-based recommender systems, one approach is to recommend a few items to a cold-start user and use the feedback to learn a profile. The learned profile can then be used to make good recommendations to the cold user. In the absence of a good initial profile, the recommendations are like random probes, but if not chosen judiciously, both bad recommendations and too many recommendations may turn off a user. We formalize the cold-start user problem by asking what are the $b$ best items we should recommend to a cold-start user, in order to learn her profile most accurately, where $b$, a given budget, is typically a small number. We formalize the problem as an optimization problem and present multiple non-trivial results, including NP-hardness as well as hardness of approximation. We furthermore show that the objective function, i.e., the least square error of the learned profile w.r.t. the true user profile, is neither submodular nor supermodular, suggesting efficient approximations are unlikely to exist. Finally, we discuss several scalable heuristic approaches for identifying the $b$ best items to recommend to the user and experimentally evaluate their performance on 4 real datasets. Our experiments show that our proposed accelerated algorithms significantly outperform the prior art in runnning time, while achieving similar error in the learned user profile as well as in the rating predictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9963020",
                    "name": "Sampoorna Biswas"
                },
                {
                    "authorId": "1708593",
                    "name": "L. Lakshmanan"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "f51874f669a1d81b48f8628325b48e7c0d78b554",
            "title": "A Probabilistic Framework for Estimating Pairwise Distances Through Crowdsourcing",
            "abstract": "Estimating all pairs of distances among a set of objects has wide applicability in various computational problems in databases, machine learning, and statistics. This work presents a probabilistic framework for estimating all pair distances through crowdsourcing, where the human workers are involved to provide distance between some object pairs. Since the workers are subject to error, their responses are considered with a probabilistic interpretation. In particular, the framework comprises of three problems : (1) Given multiple feedback on an object pair, how do we combine and aggregate those feedback and create a probability distribution of the distance? (2) Since the number of possible pairs is quadratic in the number of objects, how do we estimate, from the known feedback for a small numbers of object pairs, the unknown distances among all other object pairs? For this problem, we leverage the metric property of distance, in particular, the triangle inequality property in a probabilistic settings. (3) Finally, how do we improve our estimate by soliciting additional feedback from the crowd? For all three problems, we present principled modeling and solutions. We experimentally evaluate our proposed framework by involving multiple real-world and large scale synthetic data, by enlisting workers from a crowdsourcing platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "1fa86a9087aacb60ad691c020116d9e59726b8ab",
            "title": "Fast best-effort search on graphs with multiple attributes",
            "abstract": "We address the problem of top-k search on graphs with multiple nodal attributes, which we call WAGs (short for Weighted Attribute Graphs). For example, a co-authorship network is a WAG, where each author is a node; each attribute corresponds to a particular topic (e.g., databases, data mining, and machine learning); and the amount of expertise in a particular topic is represented by a non-negative weight on that attribute. A typical search in this setting may be: find three coauthors (i.e., a triangle) where each author's expertise is greater than 50% in at least one topic area (i.e., attribute). We show that the problem of retrieving the optimal answer for graph search on WAGs is NP-complete. Moreover, we propose a fast and effective top-k graph search algorithm for WAGs. In an extensive experimental study, our proposed algorithm exhibits significant speed-up over competing approaches. On average, our proposed method achieves 7\u00d7 faster query processing than the best competitor.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1397398770",
                    "name": "Tina Eliassi-Rad"
                },
                {
                    "authorId": "1779118",
                    "name": "S. Papadimitriou"
                }
            ]
        },
        {
            "paperId": "2812efac9ad3d0220be80c33120ec9191015bead",
            "title": "Predicting 30-Day Risk and Cost of \"All-Cause\" Hospital Readmissions",
            "abstract": "The hospital readmission rate of patients within 30 days after discharge is broadly accepted as a healthcare quality measure and cost driver in the United States. The ability to estimate hospitalization costs alongside 30 day risk-stratification for such readmissions provides additional benefit for accountable care, now a global issue and foundation for the U.S.~government mandate under the Affordable Care Act. Recent data mining efforts either predict healthcare costs or risk of hospital readmission, but not both. In this paper we present a dual predictive modeling effort that utilizes healthcare data to predict the risk and cost of any hospital readmission (``all-cause''). For this purpose, we explore machine learning algorithms to do accurate predictions of healthcare costs and risk of 30-day readmission.Results on risk prediction for ``all-cause'' readmission compared to the standardized readmission tool (LACE) are promising, and the proposed techniques for cost prediction consistently outperform baseline models and demonstrate substantially lower mean absolute error (MAE).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1804117",
                    "name": "Shanu Sushmita"
                },
                {
                    "authorId": "3444553",
                    "name": "Garima Khulbe"
                },
                {
                    "authorId": "10825534",
                    "name": "Aftab Hasan"
                },
                {
                    "authorId": "40512736",
                    "name": "S. Newman"
                },
                {
                    "authorId": "145207833",
                    "name": "P. Ravindra"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "4502624",
                    "name": "M. D. Cock"
                },
                {
                    "authorId": "1752398",
                    "name": "A. Teredesai"
                }
            ]
        },
        {
            "paperId": "7ecb34ecf8a6d3171ca4cd0c558b2071b3a74297",
            "title": "Collaborative Crowdsourcing with Crowd4U",
            "abstract": "Collaborative crowdsourcing is an emerging paradigm where a set of workers, often with diverse and complementary skills, form groups and work together to complete complex tasks. While crowdsourcing has been used successfully in many applications, collaboration is essential for achieving a high quality outcome for a number of emerging applications such as text translation, citizen journalism and surveillance tasks. However, no crowdsourcing platform today enables the end-to-end deployment of collaborative tasks. We demonstrate Crowd4U, a volunteer-based system that enables the deployment of diverse crowdsourcing tasks with complex data-flows, in a declarative manner. In addition to treating workers and tasks as rich entities, Crowd4U also provides an easy-to-use form-based task UI. Crowd4U implements worker-to-task assignment algorithms that are appropriate for each kind of task. Once workers are assigned to tasks, appropriate worker collaboration schemes are enforced in order to enable effective result coordination.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2431881",
                    "name": "Kosetsu Ikeda"
                },
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                },
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "8bb47e8900deaf371f40b3dec925b5ab35224ead",
            "title": "Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web",
            "abstract": "The purpose of the ExploreDB workshop is to bring together researchers and practitioners that approach data exploration from different angles, ranging from data management, information retrieval to data visualization and human computer interaction, in order to study the emerging needs and objectives for data exploration, as well as the challenges and problems that need to be tackled.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "12619004",
                    "name": "Kostas Stefanidis"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "1722086",
                    "name": "Mirek Riedewald"
                },
                {
                    "authorId": "1708593",
                    "name": "L. Lakshmanan"
                }
            ]
        },
        {
            "paperId": "9d2832073921f0b4681477c7c36746b1bb7c0519",
            "title": "Feature Based Task Recommendation in Crowdsourcing with Implicit Observations",
            "abstract": "Existing research in crowdsourcing has investigated how to recommend tasks to workers based on which task the workers have already completed, referred to as {\\em implicit feedback}. We, on the other hand, investigate the task recommendation problem, where we leverage both implicit feedback and explicit features of the task. We assume that we are given a set of workers, a set of tasks, interactions (such as the number of times a worker has completed a particular task), and the presence of explicit features of each task (such as, task location). We intend to recommend tasks to the workers by exploiting the implicit interactions, and the presence or absence of explicit features in the tasks. We formalize the problem as an optimization problem, propose two alternative problem formulations and respective solutions that exploit implicit feedback, explicit features, as well as similarity between the tasks. We compare the efficacy of our proposed solutions against multiple state-of-the-art techniques using two large scale real world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "a547e98ee12a9e6ef69591599d7cb742bb6ccdf0",
            "title": "Human Factors in Crowdsourcing",
            "abstract": "Today, crowdsourcing is used to \"taskify\" any job ranging from simple receipt transcription to collaborative editing, fan-subbing, citizen science, and citizen journalism. The crowd is typically volatile, its arrival and departure asynchronous, and its levels of attention and accuracy diverse. Tasks vary in complexity and may necessitate the participation of workers with varying degrees of expertise. Sometimes, workers need to collaborate explicitly and build on each other's contributions to complete a single task. For example, in disaster reporting, CrowdMap allows geographically closed people with diverse and complementary skills, to work together to report details about the course of a typhoon or the aftermath of an earthquake. \n \nThis uber-ization of human labor requires the understanding of workers motivation in completing a task, their ability to work together in collaborative tasks, as well as, helping workers find relevant tasks. For over 40 years, organization studies have thoroughly examined human factors that affect workers in physical workplaces. More recently, computer scientists have developed algorithms that verify and leverage those findings in a virtual marketplace, in this case, a crowdsourcing platform. \n \nThe goal of this tutorial is to review those two areas and discuss how their combination may improve workers' experience, task throughput and outcome quality for both micro-tasks and collaborative tasks. We will start with a coverage of motivation theory, team formation, and learning worker profiles. We will then address open research questions that result from this review.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "bb3afc3f16b8fd8bd7a558fe3312faa7a2e8c103",
            "title": "Report on the Third International Workshop on Exploratory Search in Databases and the Web (ExploreDB 2016)",
            "abstract": "The traditional way of interaction between a user and a database system is through queries, for which the correctness and completeness of their answers are key challenges. Structured query languages, such as SQL, XQuery, and SPARQL, allow users to submit queries that may precisely identify their information needs, but often require users to be familiar with the structure of data, the content of the database, and also have a clear understanding of their needs. As databases get larger and accessible to a more diverse audience, new forms of data exploration and interaction become increasingly more attractive to aid users navigate through the information space and overcome the challenges of information overload [6, 5]. The Web represents the largest and most complex repository of content. Users seek information through two predominant modes: by browsing or by searching. In the first mode, the interaction between the user and the data repository is driven directly by the user\u2019s needs interpretation. In the latter mode, a search engine typically mediates the user-data interactions and the process starts with the user entering query-terms that act as surrogates for the user information goals. Commonly, independently from data models and query languages, the query results are presented to the user as a ranked list. Clearly, there is a need to develop novel paradigms for exploratory user-data interactions that emphasize user context [13] and interactivity with the goal of facilitating exploration, retrieval, and assimilation of information. A huge number of applications need an exploratory form of querying. Ranked retrieval techniques is a first step in this direction [1, 3]. Recently, several new aspects for exploratory search, such as preferences [12], diversity [14], novelty [9], surprise [10] and serendipity [4], are gaining increasing importance. From a different perspective, recommender systems tend to anticipate user needs by suggesting the most appropriate to the users information [11], while a new line of research in the area of exploratory search is fueled by the growth of online social interactions within social networks and Web communities [2]. Overall, the query-answering task needs to be further enhanced to capture the intent that the user may have in mind during querying. Exploratory search techniques are of great assistance that facilitates and guides users to focus on the relevant aspects of their search results. To sum up, the field of data exploration is diverse in terms of research directions and potential user base. Hence, the ExploreDB workshop intends to bring together researchers and practitioners from different fields, ranging from data management and information retrieval to data visualization and human computer interaction. Its goal is to study the emerging needs and objectives for data exploration, as well as the challenges and problems that need to be tackled, and to nourish interdisciplinary synergies. We summarize the outcomes of the third workshop instance held in conjunction with ACM SIGMOD 2016 in San Francisco, USA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "12619004",
                    "name": "Kostas Stefanidis"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "1708593",
                    "name": "L. Lakshmanan"
                },
                {
                    "authorId": "1722086",
                    "name": "Mirek Riedewald"
                }
            ]
        },
        {
            "paperId": "eb48ff76e25d5add89ecdbad155eb5107650b42b",
            "title": "Toward Worker-Centric Crowdsourcing",
            "abstract": "Today",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "06eb759d5c7cacdfa3d75a33134d92ccf3d2e96c",
            "title": "ECCO- A Framework for Ecological Data Collection and Management Involving Human Workers",
            "abstract": "Scientific and ecological data collection in today\u2019s world is primarily driven by citizen-based observation networks to gather information on a diverse array of species and natural processes. Such efforts leverage the contributions of a broad recruitment of human observers to collect data and use Machine Learning algorithms to process the collected data leading to a computational power that far exceeds the sum of the individual parts. Instead of organic group formation and collaboration, our vision is the need to formalize collaboration and rethink the components of a data management system to ensure its sustainability in such human-intensive applications. The enabler of collaboration is the notion of a user group that implies different behaviors and interactions between its members. We advocate the design of new components of a data management system that deliberately acknowledge the uncertainty and dynamicity of human behavior by capturing the human factors that characterize group members. We describe ECCO, a framework that contains two generic components: adaptive collaborative human factors learning and adaptive human-centric optimization. Those are the core components that support the fundamental functionalities of a wide range of human-intensive applications. ECCO components rely on two optimization engines, namely task assignment and human data management engine .A n additional challenge in designing the components of ECCO is the need to support adaptive and incremental computation. We discuss the modeling, learning, and computational challenges of designing the components of ECCO and propose a roadmap of future directions of this vision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2262182",
                    "name": "L. Joppa"
                }
            ]
        },
        {
            "paperId": "5744c899cf2c6b49f4f5f89ca4ea348781a365a2",
            "title": "\"The Whole Is Greater Than the Sum of Its Parts\": Optimization in Collaborative Crowdsourcing",
            "abstract": "In this work, we initiate the investigation of optimization opportunities in collaborative crowdsourcing. Many popular applications, such as collaborative document editing, sentence translation, or citizen science resort to this special form of human-based computing, where, crowd workers with appropriate skills and expertise are required to form groups to solve complex tasks. Central to any collaborative crowdsourcing process is the aspect of successful collaboration among the workers, which, for the first time, is formalized and then optimized in this work. Our formalism considers two main collaboration-related human factors, affinity and upper critical mass, appropriately adapted from organizational science and social theories. Our contributions are (a) proposing a comprehensive model for collaborative crowdsourcing optimization, (b) rigorous theoretical analyses to understand the hardness of the proposed problems, (c) an array of efficient exact and approximation algorithms with provable theoretical guarantees. Finally, we present a detailed set of experimental results stemming from two real-world collaborative crowdsourcing application us- ing Amazon Mechanical Turk, as well as conduct synthetic data analyses on scalability and qualitative aspects of our proposed algorithms. Our experimental results successfully demonstrate the efficacy of our proposed solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "6c3fce00c6325e9d94e3b1e21009ad22bf1b75fa",
            "title": "Dynamic Hierarchical Classification for Patient Risk-of-Readmission",
            "abstract": "Congestive Heart Failure (CHF) is a serious chronic condition often leading to 50% mortality within 5 years. Improper treatment and post-discharge care of CHF patients leads to repeat frequent hospitalizations (i.e., readmissions). Accurately predicting patient's risk-of-readmission enables care-providers to plan resources, perform factor analysis, and improve patient quality of life. In this paper, we describe a supervised learning framework, Dynamic Hierarchical Classification (DHC) for patient's risk-of-readmission prediction. Learning the hierarchy of classifiers is often the most challenging component of such classification schemes. The novelty of our approach is to algorithmically generate various layers and combine them to predict overall 30-day risk-of-readmission. While the components of DHC are generic, in this work, we focus on congestive heart failure (CHF), a pressing chronic condition. Since healthcare data is diverse and rich and each source and feature-subset provides different insights into a complex problem, our DHC based prediction approach intelligently leverages each source and feature-subset to optimize different objectives (such as, Recall or AUC) for CHF risk-of-readmission. DHC's algorithmic layering capability is trained and tested over two real world datasets and is currently integrated into the clinical decision support tools at MultiCare Health System (MHS), a major provider of healthcare services in the northwestern US. It is integrated into a QlikView App (with EMR integration planned for Q2) and currently scores patients everyday, helping to mitigate readmissions and improve quality of care, leading to healthier outcomes and cost savings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1752398",
                    "name": "A. Teredesai"
                },
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "144207288",
                    "name": "R. Liu"
                },
                {
                    "authorId": "144925050",
                    "name": "David Hazel"
                },
                {
                    "authorId": "40512736",
                    "name": "S. Newman"
                },
                {
                    "authorId": "3251630",
                    "name": "Albert Marinez"
                }
            ]
        },
        {
            "paperId": "7c84bdec01951e9fd42ac661a8de9e5e6b8ea475",
            "title": "From Group Recommendations to Group Formation",
            "abstract": "There has been significant recent interest in the area of group recommendations, where, given groups of users of a recommender system, one wants to recommend top-$k$ items to a group that maximize the satisfaction of the group members, according to a chosen semantics of group satisfaction. Examples semantics of satisfaction of a recommended itemset to a group include the so-called least misery (LM) and aggregate voting (AV). We consider the complementary problem of how to form groups such that the users in the formed groups are most satisfied with the suggested top-k recommendations. We assume that the recommendations will be generated according to one of the two group recommendation semantics -- LM or AV. Rather than assuming groups are given, or rely on ad hoc group formation dynamics, our framework allows a strategic approach for forming groups of users in order to maximize satisfaction. We show that the problem is NP-hard to solve optimally under both semantics. Furthermore, we develop two efficient algorithms for group formation under LM and show that they achieve bounded absolute error. We develop efficient heuristic algorithms for group formation under AV. We validate our results and demonstrate the scalability and effectiveness of our group formation algorithms on two large real data sets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1708593",
                    "name": "L. Lakshmanan"
                },
                {
                    "authorId": "144207288",
                    "name": "R. Liu"
                }
            ]
        },
        {
            "paperId": "92081816012fbb6b80aeec2050f6d391dc8ddace",
            "title": "From Complex Object Exploration to Complex Crowdsourcing.",
            "abstract": "Forming and exploring complex objects is at the heart of a variety of emerging web applications. Historically, existing work on complex objects has been developed in two separate areas: composite item retrieval and team formation. At the same time, emerging applications that harness the wisdom of crowd workers, such as, document editing by workers, sentence translation by fans (or fan-subbing), innovative design, citizen science or journalism, represent complex crowdsourcing, in which an object may represent a complex task formed by a set of sub-tasks or a team of workers who work together to solve the task. The goal of this tutorial is to bridge the gap between composite item retrieval and team formation and define new research directions for complex crowdsourcing applications",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "a27bd61eb721398df23e16433d1e038beda398df",
            "title": "Worker Skill Estimation in Team-Based Tasks",
            "abstract": "Many emerging applications such as collaborative editing, multi-player games, or fan-subbing require to form a team of experts to accomplish a task together. Existing research has investigated how to assign workers to such team-based tasks to ensure the best outcome assuming the skills of individual workers to be known. In this work, we investigate how to estimate individual worker's skill based on the outcome of the team-based tasks they have undertaken. We consider two popular skill aggregation functions and estimate the skill of the workers, where skill is either a deterministic value or a probability distribution. We propose efficient solutions for worker skill estimation using continuous and discrete optimization techniques. We present comprehensive experiments and validate the scalability and effectiveness of our proposed solutions using multiple real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "b1cb0eba90c9b66ec9cb47f384c65d6b5fee3690",
            "title": "Task Assignment Optimization in Collaborative Crowdsourcing",
            "abstract": "A number of emerging applications, such as, collaborative document editing, sentence translation, and citizen journalism require workers with complementary skills and expertise to form groups and collaborate on complex tasks. While existing research has investigated task assignment for knowledge intensive crowdsourcing, they often ignore the aspect of collaboration among workers, that is central to the success of such tasks. Research in behavioral psychology has indicated that large groups hinder successful collaboration. Taking that into consideration, our work is one of the first to investigate and formalize the notion of collaboration among workers and present theoretical analyses to understand the hardness of optimizing task assignment. We propose efficient approximation algorithms with provable theoretical guarantees and demonstrate the superiority of our algorithms through a comprehensive set of experiments using real-world and synthetic datasets. Finally, we conduct a real world collaborative sentence translation application using Amazon Mechanical Turk that we hope provides a template for evaluating collaborative crowdsourcing tasks in micro-task based crowdsourcing platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "cb62de2d2387b3c3577ee81bd7d21f501c598992",
            "title": "Fast Best-Effort Search on Graphs with Multiple Attributes",
            "abstract": "We address the problem of search on graphs with multiple nodal attributes. We call such graphs weighted attribute graphs (WAGs). Nodes of a WAG exhibit multiple attributes with varying, non-negative weights. WAGs are ubiquitous in real-world applications. For example, in a co-authorship WAG, each author is a node; each attribute corresponds to a particular topic (e.g., databases, data mining, and machine learning); and the amount of expertise in a particular topic is represented by a non-negative weight on that attribute. A typical search in this setting specifies both connectivity between nodes and constraints on weights of nodal attributes. For example, a user's search may be: find three coauthors (i.e., a triangle) where each author's expertise is greater than 50 percent in at least one topic area (i.e., attribute). We propose a ranking function which unifies ranking between the graph structure and attribute weights of nodes. We prove that the problem of retrieving the optimal answer for graph search on WAGs is NP-complete. Moreover, we propose a fast and effective top-k graph search algorithm for WAGs. In an extensive experimental study with multiple real-world graphs, our proposed algorithm exhibits significant speed-up over competing approaches. On average, our proposed method is more than 7\u03c7 faster in query processing than the best competitor.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1397398770",
                    "name": "Tina Eliassi-Rad"
                },
                {
                    "authorId": "1779118",
                    "name": "S. Papadimitriou"
                }
            ]
        },
        {
            "paperId": "f265b16a21744ea7ce50708a56949640c3129188",
            "title": "Group Recommendation with Temporal Affinities",
            "abstract": "We examine the problem of recommending items to ad-hoc user groups. Group recommendation in collaborative rating datasets has received increased attention recently and has raised novel challenges. Different consensus functions that aggregate the ratings of group members with varying semantics ranging from least misery to pairwise disagreement, have been studied. In this paper, we explore a new dimension when computing group recommendations, that is, affinity between group members and its evolution over time. We extend existing group recommendation semantics to include temporal affinity in recommendations and design GRECA, an efficient algorithm that produces temporal affinity-aware recommendations for ad-hoc groups. We run extensive experiments that show substantial improvements in group recommendation quality when accounting for affinity while maintaining very good performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2707638",
                    "name": "Nafiseh Shabib"
                }
            ]
        },
        {
            "paperId": "1bbbc1702bbb9e8b07626f8433b600c77fbd5a1c",
            "title": "Optimization in Knowledge-Intensive Crowdsourcing",
            "abstract": "We present SmartCrowd, a framework for optimizing collaborative knowledge-intensive crowdsourcing. SmartCrowd distinguishes itself by accounting for human factors in the process of assigning tasks to workers. Human factors designate workers' expertise in different skills, their expected minimum wage, and their availability. In SmartCrowd, we formulate task assignment as an optimization problem, and rely on pre-indexing workers and maintaining the indexes adaptively, in such a way that the task assignment process gets optimized both qualitatively, and computation time-wise. We present rigorous theoretical analyses of the optimization problem and propose optimal and approximation algorithms. We finally perform extensive performance and quality experiments using real and synthetic data to demonstrate that adaptive indexing in SmartCrowd is necessary to achieve efficient high quality task assignment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "3229142",
                    "name": "Ioanna Lykourentzou"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "26578e374a7fcbf36d076429d6bc51e5f982700f",
            "title": "ALIAS: Author Disambiguation in Microsoft Academic Search Engine Dataset",
            "abstract": "We present a system called ALIAS, that is designed to search for duplicate authors from Microsoft Academic Search Engine dataset. Author-ambiguity is a prevalent problem in this dataset, as many authors publish under several variations of their own name, or different authors share similar or same name. ALIAS takes an author name as an input (who may or may not exist in the corpus), and outputs a set of author names from the database, that are determined as duplicates of the input author. It also provides a confidence score with each output. Additionally, ALIAS has the feature of finding a Top-k list of similar authors, given an input author name. The underlying techniques heavily rely on a mix of learning, mining, and efficient search techniques, including partitioning, clustering, supervised learning using ensemble algorithms, and indexing to perform efficient search to enable fast response for near real time user interaction. While the system is designed using Academic Search Engine data, the proposed solution is generic and could be extended to other problems in the category of entity disambiguation. In this demonstration paper, we describe different components of ALIAS and the intelligent algorithms associated with each of these components to perform author name disambiguation or similar authors finding.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069008097",
                    "name": "Michael Pitts"
                },
                {
                    "authorId": "2950577",
                    "name": "Swapna Savvana"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "34104922",
                    "name": "Vani Mandava"
                }
            ]
        },
        {
            "paperId": "2ae8e295b94b154d944e60110d9277b9348f2efd",
            "title": "Exploiting group recommendation functions for flexible preferences",
            "abstract": "We examine the problem of enabling the flexibility of updating one's preferences in group recommendation. In our setting, any group member can provide a vector of preferences that, in addition to past preferences and other group members' preferences, will be accounted for in computing group recommendation. This functionality is essential in many group recommendation applications, such as travel planning, online games, book clubs, or strategic voting, as it has been previously shown that user preferences may vary depending on mood, context, and company (i.e., other people in the group). Preferences are enforced in an feedback box that replaces preferences provided by the users by a potentially different feedback vector that is better suited for maximizing the individual satisfaction when computing the group recommendation. The feedback box interacts with a traditional recommendation box that implements a group consensus semantics in the form of Aggregated Voting or Least Misery, two popular aggregation functions for group recommendation. We develop efficient algorithms to compute robust group recommendations that are appropriate in situations where users have changing preferences. Our extensive empirical study on real world data-sets validates our findings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "82737548",
                    "name": "Cong Yu"
                }
            ]
        },
        {
            "paperId": "53a0dbdc1443c5ef4849b6cf972dbc96f1687f9f",
            "title": "IQR: an interactive query relaxation system for the empty-answer problem",
            "abstract": "We present IQR, a system that demonstrates optimization based interactive relaxations for queries that return an empty answer. Given an empty answer, IQR dynamically suggests one relaxation of the original query conditions at a time to the user, based on certain optimization objectives, and the user responds by either accepting or declining the relaxation, until the user arrives at a non-empty answer, or a non-empty answer is impossible to achieve with any further relaxations. The relaxation suggestions hinge on a proba- bilistic framework that takes into account the probability of the user accepting a suggested relaxation, as well as how much that relaxation serves towards the optimization objec- tive. IQR accepts a wide variety of optimization objectives - user centric objectives, such as, minimizing the number of user interactions (i.e., effort) or returning relevant results, as well as seller centric objectives, such as, maximizing profit. IQR offers principled exact and approximate solutions for gen- erating relaxations that are demonstrated using multiple, large real datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3094226",
                    "name": "D. Mottin"
                },
                {
                    "authorId": "2621544",
                    "name": "Alice Marascu"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1725167",
                    "name": "Themis Palpanas"
                },
                {
                    "authorId": "2163752",
                    "name": "Yannis Velegrakis"
                }
            ]
        },
        {
            "paperId": "6512b653c7a8eacf2ed175a0d903635f4515671f",
            "title": "A Framework to Recommend Interventions for 30-Day Heart Failure Readmission Risk",
            "abstract": "In this paper, we describe a novel framework to recommend personalized intervention strategies to minimize 30-day readmission risk for heart failure (HF) patients, as they move through the provider's cardiac care protocol. We design principled solutions by learning the structure and parameters of a multi-layer hierarchical Bayesian network from underlying high-dimensional patient data. Next, we generate and summarize the rules leading to personalized interventions which can be applied to individual patients as they progress from admit to discharge. We present comprehensive experimental results as well as interesting case studies to demonstrate the effectiveness of our proposed framework using large real-world patient datasets on Microsoft Azure for Research platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144207288",
                    "name": "R. Liu"
                },
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1752398",
                    "name": "A. Teredesai"
                }
            ]
        },
        {
            "paperId": "9ba4e31bc3b5a2e50feccae168dafd64d9be1f69",
            "title": "Pathway-Finder: An Interactive Recommender System for Supporting Personalized Care Pathways",
            "abstract": "Clinical pathways define the essential component of the complex care process, with the objective to optimize patient outcomes and resource allocation. Clinical pathway analysis has gained increased attention in order to augment the patient treatment process. In this demonstration paper, we propose Pathway-Finder, an interactive recommender system to visually explore and discover clinical pathways. The interactive web service efficiently collects and displays patient information in a meaningful way to support an effective personalized treatment plan. Pathway-Finder implements a Bayesian Network to discover causal relationships among different factors. To support real-time recommendation and visualization, a key-value structure has been implemented to traverse the Bayesian Network faster. Additionally, Pathway-Finder is a cloud based web service hosted on Microsoft Azure which enables the health providers to access the system without the need to deploy analytics infrastructure. We demonstrate Pathway-Finder to interactively recommend personalized interventions to minimize 30-day readmission risk for Heart Failure (HF).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144207288",
                    "name": "R. Liu"
                },
                {
                    "authorId": "2055989232",
                    "name": "R. Srinivasan"
                },
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "10825534",
                    "name": "Aftab Hasan"
                },
                {
                    "authorId": "144925050",
                    "name": "David Hazel"
                }
            ]
        },
        {
            "paperId": "d8038c8e4a2489257ca8ab3f37be4d1c6aafc5fc",
            "title": "Divide-n-Discover - Discretization based Data Exploration Framework for Healthcare Analytics",
            "abstract": "Insightful and principled visualization techniques may successfully help complex clinical data exploration tasks and aid in the process of knowledge discovery. In this paper, we propose a framework Divide-n-Discover to visualize and explore clinical data effectively, and demonstrate its effectiveness in predicting readmission risk for Congestive Heart Failure patients. Our proposed method provides clinicians a mechanism to dynamically explore the data and to understand how a single factor may influence the risk of readmission for a given patient. For example, our study indicates that patients between age 47 and 48 have 2.63 time higher chance of getting readmitted to the hospital within 30 days, compared to other patients; likewise, patients with length of stay above 13 days are 2.27 times more likely to be readmitted within 30 days. The finding suggests that hospitals might be under pressure to discharge patients within two week while some patients may benefit from a longer stay. These observations may become valid hypotheses leading to further clinical investigation or discoveries. To the best of our knowledge, this is the first ever work that proposes principled discretization and visualization techniques in the hospital readmission risk prediction problem.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                },
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1752398",
                    "name": "A. Teredesai"
                },
                {
                    "authorId": "2074923316",
                    "name": "Paul Amoroso"
                }
            ]
        },
        {
            "paperId": "dc10a1c85e61ddfd9b3709588c3883d258978337",
            "title": "Crowd4U: An Initiative for Constructing an Open Academic Crowdsourcing Network",
            "abstract": "\n \n We describe the Crowd4U initiative, which aims at constructing an all-academic open and generic platform for microvolunteering and crowdsourcing worldwide. Crowd4U provides a microtask-based platform in which most workers are volunteers at universities and other research institutions. Crowd4U is open in the sense that the platform can interact with other platforms, researchers can register their tasks, and the underlying code is not a black box. It is generic as it allows to register virtually any task. Crowd4U has already been used by several projects for public and academic purposes.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "ebf29b513bfb720e8c857755e5d74bc5c3ea6a57",
            "title": "Prediction and Management of Readmission Risk for Congestive Heart Failure",
            "abstract": "This position paper investigates the problem of 30-day readmission risk prediction and management for Congestive Heart Failure (CHF), which has been identified as one of the leading causes of hospitalization, especially for adults older than 65 years. The underlying solution is deeply related to using predictive analytics to compute the readmission risk score of a patient, and investigating respective risk management strategies for her by leveraging statistical analysis or sequence mining techniques. The outcome of this paper leads to developing a framework that suggests appropriate interventions to a patient during a hospital stay, at discharge, or post hospital-discharge period that potentially would reduce her readmission risk. The primary beneficiaries of this paper are the physicians and different \n \nentities involved in the pipeline of health care industry, and most importantly, the patients. This paper outlines the opportunities in applying data mining techniques in readmission risk prediction and management, and sheds deeper light on healthcare informatics.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                }
            ]
        },
        {
            "paperId": "150c04c002f08bf540def7d4bba31c7cd25aeeb9",
            "title": "Crowds, not Drones: Modeling Human Factors in Interactive Crowdsourcing",
            "abstract": "In this vision paper, we propose SmartCrowd, an intelligent and adaptive crowdsourcing framework. Contrary to existing crowdsourcing systems, where the process of hiring workers (crowd), learning their skills, and evaluating the accuracy of tasks they perform are fragmented, siloed, and often ad-hoc, SmartCrowd foresees a paradigm shift in that process, considering unpredictability of human nature, namely human factors. SmartCrowd oers opportunities in making crowdsourcing intelligent through iterative interaction with the workers, and adaptively learning and improving the underlying processes. Both existing (majority of which do not require longer engagement from volatile and mostly nonrecurrent workers) and next generation crowdsourcing applications (which require longer engagement from the crowd) stand to benefit from SmartCrowd. We outline the opportunities in SmartCrowd, and discuss the challenges and directions, that can potentially revolutionize the existing crowdsourcing landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "3229142",
                    "name": "Ioanna Lykourentzou"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "3d0ddaadc9e97c1cc98762bf3b477e2860511c39",
            "title": "A Probabilistic Optimization Framework for the Empty-Answer Problem",
            "abstract": "We propose a principled optimization-based interactive query relaxation framework for queries that return no answers. Given an initial query that returns an empty answer set, our framework dynamically computes and suggests alternative queries with less conditions than those the user has initially requested, in order to help the user arrive at a query with a non-empty answer, or at a query for which no matter how many additional conditions are ignored, the answer will still be empty. Our proposed approach for suggesting query relaxations is driven by a novel probabilistic framework based on optimizing a wide variety of application-dependent objective functions. We describe optimal and approximate solutions of different optimization problems using the framework. We analyze these solutions, experimentally verify their efficiency and effectiveness, and illustrate their advantage over the existing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3094226",
                    "name": "D. Mottin"
                },
                {
                    "authorId": "2621544",
                    "name": "Alice Marascu"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1725167",
                    "name": "Themis Palpanas"
                },
                {
                    "authorId": "2163752",
                    "name": "Yannis Velegrakis"
                }
            ]
        },
        {
            "paperId": "61cb263b265719e1ccfdb667d13ff51c88f8f5f2",
            "title": "Big data solutions for predicting risk-of-readmission for congestive heart failure patients",
            "abstract": "Developing holistic predictive modeling solutions for risk prediction is extremely challenging in healthcare informatics. Risk prediction involves integration of clinical factors with socio-demographic factors, health conditions, disease parameters, hospital care quality parameters, and a variety of variables specific to each health care provider making the task increasingly complex. Unsurprisingly, many of such factors need to be extracted independently from different sources, and integrated back to improve the quality of predictive modeling. Such sources are typically voluminous, diverse, and vary significantly over the time. Therefore, distributed and parallel computing tools collectively termed big data have to be developed. In this work, we study big data driven solutions to predict the 30-day risk of readmission for congestive heart failure (CHF) incidents. First, we extract useful factors from National Inpatient Dataset (NIS) and augment it with our patient dataset from Multicare Health System (MHS). Then, we develop scalable data mining models to predict risk of readmission using the integrated dataset. We demonstrate the effectiveness and efficiency of the open-source predictive modeling framework we used, describe the results from various modeling algorithms we tested, and compare the performance against baseline non-distributed, non-parallel, non-integrated small data results previously published to demonstrate comparable accuracy over millions of records.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "1708522",
                    "name": "Naren Meadem"
                },
                {
                    "authorId": "1752398",
                    "name": "A. Teredesai"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                },
                {
                    "authorId": "2763703",
                    "name": "Brian Muckian"
                }
            ]
        },
        {
            "paperId": "d0a6df5a7955827564cdef779b7922d1b1b6c564",
            "title": "Risk-O-Meter: an intelligent clinical risk calculator",
            "abstract": "We present a system called Risk-O-Meter to predict and an- alyze clinical risk via data imputation, visualization, predic- tive modeling, and association rule exploration. Clinical risk calculators provide information about a person's chance of having a disease or encountering a clinical event. Such tools could be highly useful to educate patients to understand and monitor their health conditions. Unlike existing risk calcu- lators that are primarily designed for domain experts, Risk- O-Meter is useful to patients who are unfamiliar with medi- cal terminologies, or providers who have limited information about a patient. Risk-O-Meter is designed in a way such that it is flexible enough to accept limited or incomplete data in- puts, and still manages to predict the clinical risk efficiently and effectively. Current version of Risk-O-Meter evaluates 30-day risk of hospital readmission. However, the proposed system framework is applicable to general clinical risk pre- dictions. In this demonstration paper, we describe different components of Risk-O-Meter and the intelligent algorithms associated with each of these components to evaluate risk of readmission using incomplete patient data inputs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "38351339",
                    "name": "Jayshree Agarwal"
                },
                {
                    "authorId": "2066616",
                    "name": "Deepthi Sistla"
                },
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1695138",
                    "name": "N. Verbiest"
                }
            ]
        },
        {
            "paperId": "f3cf957a443062ab1c273e384600ba24edca83cf",
            "title": "The Microsoft academic search dataset and KDD Cup 2013",
            "abstract": "KDD Cup 2013 challenged participants to tackle the problem of author name ambiguity in a digital library of scientific publications. The competition consisted of two tracks, which were based on large-scale datasets from a snapshot of Microsoft Academic Search, taken in January 2013 and including 250K authors and 2.5M papers. Participants were asked to determine which papers in an author profile are truly written by a given author (track 1), as well as to identify duplicate author profiles (track 2). Track 1 and track 2 were launched respectively on April 18 and April 20, 2013, with a common final submission deadline on June 12, 2013. For track 1 a training dataset with correct labels was diclosed at the start of the competition. This track was the most popular one, attracting submissions of 561 different teams. Track 2, which was formulated as an unsupervised learning task, received submissions from 241 participants. This paper presents details about the problem definitions, the datasets, the evaluation metrics and the results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "4502624",
                    "name": "M. D. Cock"
                },
                {
                    "authorId": "34104922",
                    "name": "Vani Mandava"
                },
                {
                    "authorId": "3370310",
                    "name": "Swapna Savanna"
                },
                {
                    "authorId": "3242748",
                    "name": "Brian Dalessandro"
                },
                {
                    "authorId": "1933403",
                    "name": "Claudia Perlich"
                },
                {
                    "authorId": "3155742",
                    "name": "William J. Cukierski"
                },
                {
                    "authorId": "3033919",
                    "name": "Benjamin Hamner"
                }
            ]
        },
        {
            "paperId": "f4faa8b1f5343fb1d3cef8b7cc608f62d1dd0986",
            "title": "Predicting Risk-of-Readmission for Congestive Heart Failure Patients: A Multi-Layer Approach",
            "abstract": "Mitigating risk-of-readmission of Congestive Heart Failure (CHF) patients within 30 days of discharge is important because such readmissions are not only expensive but also critical indicator of provider care and quality of treatment. Accurately predicting the risk-of-readmission may allow hospitals to identify high-risk patients and eventually improve quality of care by identifying factors that contribute to such readmissions in many scenarios. In this paper, we investigate the problem of predicting risk-of-readmission as a supervised learning problem, using a multi-layer classification approach. Earlier contributions inadequately attempted to assess a risk value for 30 day readmission by building a direct predictive model as opposed to our approach. We first split the problem into various stages, (a) at risk in general (b) risk within 60 days (c) risk within 30 days, and then build suitable classifiers for each stage, thereby increasing the ability to accurately predict the risk using multiple layers of decision. The advantage of our approach is that we can use different classification models for the subtasks that are more suited for the respective problems. Moreover, each of the subtasks can be solved using different features and training data leading to a highly confident diagnosis or risk compared to a one-shot single layer approach. An experimental evaluation on actual hospital patient record data from Multicare Health Systems shows that our model is significantly better at predicting risk-of-readmission of CHF patients within 30 days after discharge compared to prior attempts.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1723512",
                    "name": "K. Zolfaghar"
                },
                {
                    "authorId": "1695138",
                    "name": "N. Verbiest"
                },
                {
                    "authorId": "38351339",
                    "name": "Jayshree Agarwal"
                },
                {
                    "authorId": "1708522",
                    "name": "Naren Meadem"
                },
                {
                    "authorId": "40636092",
                    "name": "Si-Chi Chin"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1752398",
                    "name": "A. Teredesai"
                },
                {
                    "authorId": "144925050",
                    "name": "David Hazel"
                },
                {
                    "authorId": "2074923316",
                    "name": "Paul Amoroso"
                },
                {
                    "authorId": "2056055901",
                    "name": "Lester Reed"
                }
            ]
        },
        {
            "paperId": "fa7e3ec5b3a9b82c9feec6014cde42905ba26f74",
            "title": "The Microsoft Academic Search challenges at KDD Cup 2013",
            "abstract": "Microsoft Academic Search is a free search engine specific to scholarly material. It currently covers more than 50 million publications and over 19 million authors across a variety of domains. One of the main challenges in correctly indexing this material is author name ambiguity and the resulting noise in author profiles. KDD Cup 2013 invited participants to tackle this problem in 2 ways: (1) by automatically determining which papers in an author profile are truly written by a given author, and (2) by identifying which author profiles need to be merged because they belong to the same author. This paper presents a brief account of the contest and the lessons learned.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4502624",
                    "name": "M. D. Cock"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2950577",
                    "name": "Swapna Savvana"
                },
                {
                    "authorId": "34104922",
                    "name": "Vani Mandava"
                },
                {
                    "authorId": "3242748",
                    "name": "Brian Dalessandro"
                },
                {
                    "authorId": "1933403",
                    "name": "Claudia Perlich"
                },
                {
                    "authorId": "3155742",
                    "name": "William J. Cukierski"
                },
                {
                    "authorId": "3033919",
                    "name": "Benjamin Hamner"
                }
            ]
        },
        {
            "paperId": "281a8e360e3dccf986483a772ecc6fd4fa2a030e",
            "title": "Interactive itinerary planning",
            "abstract": "Planning an itinerary when traveling to a city involves substantial effort in choosing Points-of-Interest (POIs), deciding in which order to visit them, and accounting for the time it takes to visit each POI and transit between them. Several online services address different aspects of itinerary planning but none of them provides an interactive interface where users give feedbacks and iteratively construct their itineraries based on personal interests and time budget. In this paper, we formalize interactive itinerary planning as an iterative process where, at each step: (1) the user provides feedback on POIs selected by the system, (2) the system recommends the best itineraries based on all feedback so far, and (3) the system further selects a new set of POIs, with optimal utility, to solicit feedback for, at the next step. This iterative process stops when the user is satisfied with the recommended itinerary. We show that computing an itinerary is NP-complete even for simple itinerary scoring functions, and that POI selection is NP-complete. We develop heuristics and optimizations for a specific case where the score of an itinerary is proportional to the number of desired POIs it contains. Our extensive experiments show that our algorithms are efficient and return high quality itineraries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "82737548",
                    "name": "Cong Yu"
                }
            ]
        },
        {
            "paperId": "a22b1c0c6efa053e1ba78f33381480e0e54d04b5",
            "title": "Location-aware type ahead search on spatial databases: semantics and efficiency",
            "abstract": "Users often search spatial databases like yellow page data using keywords to find businesses near their current location. Typing the entire query is cumbersome and prone to errors, especially from mobile phones. We address this problem by introducing type-ahead search functionality on spatial databases. Like keyword search on spatial data, type-ahead search needs to be location-aware, i.e., with every letter being typed, it needs to return spatial objects whose names (or descriptions) are valid completions of the query string typed so far, and which rank highest in terms of proximity to the user's location and other static scores. Existing solutions for type-ahead search cannot be used directly as they are not location-aware. We show that a straight-forward combination of existing techniques for performing type-ahead search with those for performing proximity search perform poorly. We propose a formal model for query processing cost and develop novel techniques that optimize that cost. Our empirical evaluations on real and synthetic datasets demonstrate the effectiveness of our techniques. To the best of our knowledge, this is the first work on location-aware type-ahead search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145328899",
                    "name": "K. Chakrabarti"
                }
            ]
        },
        {
            "paperId": "c75e5155fd193f940f0457df55b0259724f9c6bf",
            "title": "Efficient exploration techniques on large databases",
            "abstract": "Search, retrieval, and exploration of information have become some of the most intense and principal research challenges in many enterprize and e-commerce applications off late. The mainstay of this dissertation is to analyze and investigate different aspects of online data exploration, and propose techniques to accomplish them efficiently. In particular, the results in this dissertation widen the scope of existing faceted search and recommendation systems - two upcoming fields in data exploration which are still in their infancy. \nFaceted search, the de facto standard for e-commerce applications, is an interface framework with the primary design goal of allowing users to explore large information spaces in a flexible manner. We study this alternative search and exploration paradigm in the context of structured and unstructured databases. More specifically, motivated by the rapid need of knowledge discovery and management in large enterprize organizations, we propose DynaCet, a minimum effort driven dynamic faceted search system on structured databases. In addition, we study the problem of dynamic faceted retrieval in the context of unstructured data using Wikipedia, the largest and most popular encyclopedia. We propose Facetedpedia, a faceted retrieval system which is capable of dynamically generating query-dependent facets for a set of Wikipedia articles. \nThe ever-expanding volume and increasing complexity of information on the web has made recommender systems essential tools for users in a variety of information seeking or e-commerce activities by exposing them to the most interesting items, and by offering novelty, diversity, and relevance. Current research suggests that there exists an increasing growth in online social activities that leaves behind trails of information created by users. Interestingly, recommendation tasks stand to benefit immensely by tapping into these latent information sources, and by following those trails. A significant part of this dissertation has investigated on how to improve the online recommendation tasks with novel functionalities by considering additional contexts that can be leveraged by tapping into social data. \nTo this end, this dissertation investigates problems such as, how to compute recommendation for a group of users, or how to recommend composite items to a user. Underlying models leverage on social data (co-purchase or browsing histories, social book-marking of photos) to derive additional contexts to accomplish those recommendation tasks. In particular, it focuses on techniques that enable a recommendation system to interact with the user in suggesting composite items - such as, bundled products in online shopping, or itinerary planning for vacation travel. We investigate the technical and algorithmic challenges involved in enabling efficient recommendation computation, both from the user (the interaction should be easy, and should converge quickly), as well as the system (efficient computation) points of view. \nThis dissertation also discusses extensive performance and user study results, which were conducted using the crowd-sourcing platform Amazon Mechanical Turk. We conclude by briefly describing other promising problems with future opportunities in this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "10ed88718994cb94588e40146f6280723f91e8f6",
            "title": "Constructing and exploring composite items",
            "abstract": "Nowadays, online shopping has become a daily activity. Web users purchase a variety of items ranging from books to electronics. The large supply of online products calls for sophisticated techniques to help users explore available items. We propose to build composite items which associate a central item with a set of packages, formed by satellite items, and help users explore them. For example, a user shopping for an iPhone (i.e., the central item) with a price budget can be presented with both the iPhone and a package of other items that match well with the iPhone (e.g., {Belkin case, Bose sounddock, Kroo USB cable}) as a composite item, whose total price is within the user's budget. We define and study the problem of effective construction and exploration of large sets of packages associated with a central item, and design and implement efficient algorithms for solving the problem in two stages: summarization, a technique which picks k representative packages for each central item; and visual effect optimization, which helps the user find diverse composite items quickly by minimizing overlap between packages presented to the user in a ranked order. We conduct an extensive set of experiments on Yahoo! Shopping1 data sets to demonstrate the efficiency and effectiveness of our algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2055346154",
                    "name": "Ashish Chawla"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "39931037",
                    "name": "Cong Yu"
                }
            ]
        },
        {
            "paperId": "2d25ffd17121190e0fda68ded0bfc2bd5e9fe0b9",
            "title": "Facetedpedia: dynamic generation of query-dependent faceted interfaces for wikipedia",
            "abstract": "This paper proposes Facetedpedia, a faceted retrieval system for information discovery and exploration in Wikipedia. Given the set of Wikipedia articles resulting from a keyword query, Facetedpedia generates a faceted interface for navigating the result articles. Compared with other faceted retrieval systems, Facetedpedia is fully automatic and dynamic in both facet generation and hierarchy construction, and the facets are based on the rich semantic information from Wikipedia. The essence of our approach is to build upon the collaborative vocabulary in Wikipedia, more specifically the intensive internal structures (hyperlinks) and folksonomy (category system). Given the sheer size and complexity of this corpus, the space of possible choices of faceted interfaces is prohibitively large. We propose metrics for ranking individual facet hierarchies by user's navigational cost, and metrics for ranking interfaces (each with k facets) by both their average pairwise similarities and average navigational costs. We thus develop faceted interface discovery algorithms that optimize the ranking metrics. Our experimental evaluation and user study verify the effectiveness of the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "2067145115",
                    "name": "Ning Yan"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "3042798",
                    "name": "Lekhendro Lisham"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "3c35ac7fc30425b5e24681f3c056db1bb026da0e",
            "title": "Facetedpedia: enabling query-dependent faceted search for wikipedia",
            "abstract": "Facetedpedia is a faceted search system that dynamically discovers query-dependent faceted interfaces for Wikipedia search result articles. In this paper, we give an overview of Facetedpedia, present the system architecture and implementation techniques, and elaborate on a demonstration scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067145115",
                    "name": "Ning Yan"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2312458",
                    "name": "Rakesh Ramegowda"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "1743f2c124d2c8def4fe25be05866108ee68691a",
            "title": "Group Recommendation: Semantics and Efficiency",
            "abstract": "We study the problem of group recommendation. Recommendation is an important information exploration paradigm that retrieves interesting items for users based on their profiles and past activities. Single user recommendation has received significant attention in the past due to its extensive use in Amazon and Netflix. How to recommend to a group of users who may or may not share similar tastes, however, is still an open problem. The need for group recommendation arises in many scenarios: a movie for friends to watch together, a travel destination for a family to spend a holiday break, and a good restaurant for colleagues to have a working lunch. Intuitively, items that are ideal for recommendation to a group may be quite different from those for individual members. In this paper, we analyze the desiderata of group recommendation and propose a formal semantics that accounts for both item relevance to a group and disagreements among group members. We design and implement algorithms for efficiently computing group recommendations. We evaluate our group recommendation method through a comprehensive user study conducted on Amazon Mechanical Turk and demonstrate that incorporating disagreements is critical to the effectiveness of group recommendation. We further evaluate the efficiency and scalability of our algorithms on the MovieLens data set with 10M ratings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2055346154",
                    "name": "Ashish Chawla"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "39931037",
                    "name": "Cong Yu"
                }
            ]
        },
        {
            "paperId": "6af2959bbddd6c03a86a49becfc3cc64ca3c5fa1",
            "title": "TRANS: Top-k Implementation Techniques of Minimum Effort Driven Faceted Search For Databases",
            "abstract": "In this paper, we investigate opportunities to improve the performance of minimum effort driven faceted search techniques. The main idea is motivated by the early stopping techniques used in the TA-family of algorithms for top-k computations. Our initial set of experimental results demonstrate that the proposed techniques expedite performance significantly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "761f8838bde19c2e4c7c8b7cc01fedca3318c251",
            "title": "DynaCet: Building Dynamic Faceted Search Systems over Databases",
            "abstract": "Extracting information and insights from large databases is a time-consuming activity and has received considerable research attention recently. In this demo, we present DynaCet - a domain independent system that provides effective minimum-effort based dynamic faceted search solutions over enterprise databases. At every step, Dynacet suggests facets depending on the user response in the previous step. Facets are selected based on their ability to rapidly drill down to the most promising tuples, as well as on the ability of the user to provide desired values for them. The benefits provided include faster access to information stored in databases while taking into consideration the variance in user knowledge and preferences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2108874526",
                    "name": "Haidong Wang"
                },
                {
                    "authorId": "1984030",
                    "name": "Ullas Nambiar"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1732053",
                    "name": "M. Mohania"
                }
            ]
        },
        {
            "paperId": "473b3b86b23462f6cf4e5571cc0d36c7544d2633",
            "title": "Computing Best Coverage Path In The Presence Of Obstacles In Wireless Sensor Networks",
            "abstract": "COMPUTING BEST COVERAGE PATH IN THE PRESENCE OF OBSTACLES IN WIRELESS SENSOR NETWORKS",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "de50e62c48207a8c32830de52e13673976ecaab7",
            "title": "CSE 2320-001: ALGORITHMS & DATA STRUCTURES",
            "abstract": "Outcomes: 1. Understanding of classic approaches to algorithm design decomposition, dynamic programming, and greedy methods. 2. Understanding of particular algorithms and data structures that have wide applicabilty. 3. Understanding of basic algorithm analysis concepts by applying math skills to worst-case and expected time using recurrences and asymptotic notation. 4. Improved programming skills especially data structures, recursion, and graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        },
        {
            "paperId": "7e05625dd28a56bf85b9b7104c80308e27c4cd23",
            "title": "Edge Preserving Image Compression Technique using Adaptive Feed Forward Neural Network",
            "abstract": "The aim of the paper is to develop an edge preserving image compression technique using one hidden layer feed forward neural network of which the neurons are determined adaptively. Edge detection and multi-level thresholding operations are applied to reduce the image size significantly. The processed image block is fed as single input pattern while single output pattern has been constructed from the original image unlike other neural network based techniques where multiple image blocks are fed to train the network. The paper proposes initialization of weights between the input and lone hidden layer by transforming pixel coordinates of the input pattern block into its equivalent one-dimensional representation. Initialization process exhibits better rate of convergence of the back propagation training algorithm compare to the randomization of initial weights. The proposed scheme has been demonstrated through several experiments including Lena that show very promising results in compression as well as in reconstructed images over conventional neural network based techniques available in the literature.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "1882465",
                    "name": "Kausik Kayal"
                },
                {
                    "authorId": "2105120742",
                    "name": "J. Sil"
                }
            ]
        }
    ]
}