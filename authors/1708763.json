{
    "authorId": "1708763",
    "papers": [
        {
            "paperId": "dba9906ed501d9376ae353b8174466b6ede87949",
            "title": "A Framework for the Needs of Different Types of Users in Multilingual Semantic Enrichment",
            "abstract": "The FREME framework bridges Language Technologies (LT) and Linked Data (LD). It establishes work\ufb02ows between LT and LD in a well de\ufb01ned, coherent way. FREME addresses common challenges that both researchers and industry face when integrating LT and LD: interoperability, \u201dsilo\u201d solutions and the lack of adequate tooling. Usability, reusability and interoperability are often attributes of frameworks and toolkits for LT and LD. In this paper, we take a novel approach: We de\ufb01ne user types and user levels and describe how they in\ufb02uence design decisions in a LT and LD processing framework. In this way, we combine research outcomes from various communities: language technology, linked data and software interface engineering. This paper explains the different user types and how FREME addresses the speci\ufb01c needs of each user type. Core attributes of FREME are usability, reusability and interoperability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3490071",
                    "name": "Jan Nehring"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                }
            ]
        },
        {
            "paperId": "484d9a9ddcabb4e0125c4ba5886afc390d616c94",
            "title": "Improving Machine Translation through Linked Data",
            "abstract": "Abstract With the ever increasing availability of linked multilingual lexical resources, there is a renewed interest in extending Natural Language Processing (NLP) applications so that they can make use of the vast set of lexical knowledge bases available in the Semantic Web. In the case of Machine Translation, MT systems can potentially benefit from such a resource. Unknown words and ambiguous translations are among the most common sources of error. In this paper, we attempt to minimise these types of errors by interfacing Statistical Machine Translation (SMT) models with Linked Open Data (LOD) resources such as DBpedia and BabelNet. We perform several experiments based on the SMT system Moses and evaluate multiple strategies for exploiting knowledge from multilingual linked data in automatically translating named entities. We conclude with an analysis of best practices for multilingual linked data sets in order to optimise their benefit to multilingual and cross-lingual applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48294059",
                    "name": "Ankit Srivastava"
                },
                {
                    "authorId": "2156673",
                    "name": "Georg Rehm"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                }
            ]
        },
        {
            "paperId": "478a6120d2bc84466da48d93241f384b1bf2bb38",
            "title": "FREME: Multilingual Semantic Enrichment with Linked Data and Language Technologies",
            "abstract": "In the recent years, Linked Data and Language Technology solutions gained popularity. Nevertheless, their coupling in real-world business is limited due to several issues. Existing products and services are developed for a particular domain, can be used only in combination with already integrated datasets or their language coverage is limited. In this paper, we present an innovative solution FREME - an open framework of e-Services for multilingual and semantic enrichment of digital content. The framework integrates six interoperable e-Services. We describe the core features of each e-Service and illustrate their usage in the context of four business cases: i) authoring and publishing; ii) translation and localisation; iii) cross-lingual access to data; and iv) personalised Web content recommendations. Business cases drive the design and development of the framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1819564",
                    "name": "Milan Dojchinovski"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                },
                {
                    "authorId": "3398446",
                    "name": "Tatjana Gornostaja"
                },
                {
                    "authorId": "2024066",
                    "name": "Sebastian Hellmann"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1876933",
                    "name": "Frank Salliau"
                },
                {
                    "authorId": "40551568",
                    "name": "Michele Osella"
                },
                {
                    "authorId": "2073845606",
                    "name": "Phil Ritchie"
                },
                {
                    "authorId": "1805133",
                    "name": "Giannis Stoitsis"
                },
                {
                    "authorId": "2705240",
                    "name": "Kevin Koidl"
                },
                {
                    "authorId": "37683106",
                    "name": "Markus Ackermann"
                },
                {
                    "authorId": "2067025636",
                    "name": "Nilesh Chakraborty"
                }
            ]
        },
        {
            "paperId": "81b14586ab52b8717dcaf5f1938ac66c669c6bee",
            "title": "Digital curation technologies (DKT)",
            "abstract": ". Digital Curation Technologies (\u201cDigitale Kuratierungstechnologien\u201d, DKT) is a project that involves four Berlin-based SMEs (ART+COM AG, Condat AG, 3pc GmbH and Kreuzwerker GmbH) and DFKI GmbH (Language Technology Lab). The two-year action started in Sept. 2015 and aims at supporting digital curation processes, carried out by knowledge workers, through robust, precise and modular language and knowledge technologies. We combine these into workflows for the efficient processing, creation and dissemination of digital content. DFKI contributes language and knowledge technology components, including MT, and develops them further. Together with our partners, DFKI develops a platform for digital curation technologies, which offers services such as, e.g., translation, search, analytics, re-combination and summarisation. DKT is supported by the German Federal Ministry of Education and Research, Wachstumskern-Potenzial (no. 03WKP45). Details: http://www.digitale-kuratierung.de.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2156673",
                    "name": "Georg Rehm"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                }
            ]
        },
        {
            "paperId": "eac9726e55951b775b46ed136e7e64814abdf448",
            "title": "Processing Document Collections to Automatically Extract Linked Data: Semantic Storytelling Technologies for Smart Curation Workflows",
            "abstract": "We develop a system that operates on a document collection and represents the contained information to enable the intuitive and ef\ufb01cient exploration of the collection. Using various NLP, IE and Semantic Web methods, we generate a semantic layer on top of the collection, from which we take the key concepts. We de\ufb01ne templates for structured reorgan-isation and rearrange the information related to the key concepts to \ufb01t the respective template. The use case of the system is to support knowledge workers (journalists, editors, curators, etc.) in their task of processing large amounts of documents by sum-marising the information contained in these documents and suggesting potential story paths that the knowledge worker can then process further.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3490007",
                    "name": "Peter Bourgonje"
                },
                {
                    "authorId": "39207095",
                    "name": "J. Schneider"
                },
                {
                    "authorId": "2156673",
                    "name": "Georg Rehm"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                }
            ]
        },
        {
            "paperId": "d618cbda757e2333a86fe307a83be3d9497a528e",
            "title": "Introducing FREME: Deploying Linguistic Linked Data",
            "abstract": "This paper introduces the FREME project, a new Horizon 2020 innovation action. It aims at building an open framework of e-Services for multilingual and semantic enrichment of digital content, based on a reusable set of open Application Programme Interfaces and Graphical User Interfaces to FREME enrichment services. In addition, the paper discusses how the project deploys Linguistic Linked Data (LLD), especially existing LLD resources, LLD best practices and the LLD reference architecture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                },
                {
                    "authorId": "3031172",
                    "name": "Tatiana Gornostay"
                },
                {
                    "authorId": "1819564",
                    "name": "Milan Dojchinovski"
                },
                {
                    "authorId": "40551568",
                    "name": "Michele Osella"
                },
                {
                    "authorId": "1691320",
                    "name": "E. Mannens"
                },
                {
                    "authorId": "1805133",
                    "name": "Giannis Stoitsis"
                },
                {
                    "authorId": "2073845606",
                    "name": "Phil Ritchie"
                },
                {
                    "authorId": "1743895",
                    "name": "Thierry Declerck"
                },
                {
                    "authorId": "2705240",
                    "name": "Kevin Koidl"
                }
            ]
        },
        {
            "paperId": "62a563c1b23c8ee74a4d45b915d7b24af95c6d8b",
            "title": "Open, web-based internationalization and localization tools",
            "abstract": "As many software applications have moved from a desktop software deployment model to a Software-as-a-Service (SaaS) model so we have seen tool vendors in the language service industry move to a SaaS model, e.g., for web-based Computer Assisted Translation (CAT) tools. However, many of these offerings fail to take full advantage of the Open Web Platform, i.e., the rich set of web browser-based APIs linked to HTML5. We examine the interoperability landscape that developers of web-based translation tools can benefit from, and in particular the potential offered by the open metadata defined in the W3C\u2019s (World Wide Web Consortium) recent Internationalization Tag Set v2.0 Recommendation. We examine how this can be used in conjunction with the XML Localisation Interchange File Format (XLIFF) standardized by OASIS to exchange translation jobs between servers and Javascript-based CAT tools running in the web browser. We also explore how such open metadata can support activities in the multilingual web processing chain before and after translation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152175445",
                    "name": "D. Lewis"
                },
                {
                    "authorId": "1688015",
                    "name": "Qun Liu"
                },
                {
                    "authorId": "47980477",
                    "name": "L. Finn"
                },
                {
                    "authorId": "2140238",
                    "name": "Chris Hokamp"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                },
                {
                    "authorId": "2935477",
                    "name": "David Filip"
                }
            ]
        },
        {
            "paperId": "a3fb2f2878eba46b33dcd40b6f924b6153ce77a7",
            "title": "Global Intelligent Content: Active Curation of Language Resources using Linked Data",
            "abstract": "As language resources start to become available in linked data formats, it becomes relevant to consider how linked data interoperability can play a role in active language processing workflows as well as for more static language resource publishing. This paper proposes that linked data may have a valuable role to play in tracking the use and generation of language resources in such workflows in order to assess and improve the performance of the language technologies that use the resources, based on feedback from the human involvement typically required within such processes. We refer to this as Active Curation of the language resources, since it is performed systematically over language processing workflows to continuously improve the quality of the resource in specific applications, rather than via dedicated curation steps. We use modern localisation workflows, i.e. assisted by machine translation and text analytics services, to explain how linked data can support such active curation. By referencing how a suitable linked data vocabulary can be assembled by combining existing linked data vocabularies and meta-data from other multilingual content processing annotations and tool exchange standards we aim to demonstrate the relative ease with which active curation can be deployed more broadly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152175445",
                    "name": "D. Lewis"
                },
                {
                    "authorId": "145065453",
                    "name": "Rob Brennan"
                },
                {
                    "authorId": "47980477",
                    "name": "L. Finn"
                },
                {
                    "authorId": "152208993",
                    "name": "Dominic Jones"
                },
                {
                    "authorId": "1742394404",
                    "name": "Alan Meehan"
                },
                {
                    "authorId": "1396733252",
                    "name": "D. O\u2019Sullivan"
                },
                {
                    "authorId": "2024066",
                    "name": "Sebastian Hellmann"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                }
            ]
        },
        {
            "paperId": "2a4fd6c46681ab5b681006428f815e0733ac8d3d",
            "title": "Metadata for the Multilingual Web",
            "abstract": "We describe the Internationalization Tag Set (ITS) 2.0, an upcoming standard to foster the development of the multilingual Web. ITS 2.0 provides metadata to integrate workflows for content production, localization and language technology. The technical goal is to achieve better results in content creation and other language related processes; the goal in terms of community building is to raise awareness of needs in multilingual workflows. This aim is also supported by providing re-usable software components for various use cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                }
            ]
        },
        {
            "paperId": "6a47f0ef0f6521211dd0c694dde3d84cb8a73496",
            "title": "Internationalization Tag Set (ITS) Version 2.0",
            "abstract": "The technology described in this document \u201cInternationalization Tag Set (ITS) 2.0\u201c enhances the foundation to integrate automated processing of human language into core Web technologies. ITS 2.0 bears many commonalities with its predecessor, ITS 1.0 but provides additional concepts that are designed to foster the automated creation and processing of multilingual Web content. ITS 2.0 focuses on HTML, XML-based formats in general, and can leverage processing based on the XML Localization Interchange File Format (XLIFF), as well as the Natural Language Processing Interchange Format (NIF). Status of this Document This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current W3C publications and the latest revision of this technical report can be found in the W3C technical reports index at http://www.w3.org/TR/. The technology described in this document \u201cInternationalization Tag Set (ITS) 2.0\u201c enhances the foundation to integrate automated processing of human language into core Web technologies. ITS 2.0 bears many commonalities with is predecessor, ITS 1.0 but provides additional concepts that are designed to foster the automated creation and processing of multilingual Web content. ITS 2.0 focuses on HTML, XML-based formats in general, and can leverage processing based on the XML Localization Interchange File Format (XLIFF), as well as the Natural Language Processing Interchange Format (NIF). This document was published by the MultilingualWeb-LT Working Group as a W3C Recommendation (see W3C document maturity levels). The Working Group has completed and approved this specification's Test Suite and created an Implementation Report that shows that two or more independent implementations pass each test. This document has been reviewed by W3C Members, by software developers, and by other W3C groups and interested parties, and is endorsed by the Director as a W3C Recommendation. It is a stable document and may be used as reference material or cited from another document. W3C's role in making the Recommendation is to draw attention to the specification and to promote its widespread deployment. This enhances the functionality and interoperability of the Web. The ITS 2.0 specification has a normative dependency on the HTML5 specification: it relies on the HTML5 Translate attribute. By publishing this Recommendation, W3C expects that the functionality specified in this ITS 2.0 Recommendation will not be affected by changes to HTML5 as that specification proceeds to Recommendation. If you wish to make comments, please send them to public-i18n-its-ig@w3.org. The archives for this list are publicly available. See also issues discussed within the MultilingualWeb-LT Working Group and the list of changes since the previous publication. This document was produced by a group operating under the 5 February 2004 W3C Patent Policy. W3C maintains a public list of any patent disclosures made in connection with the deliverables of the group; that page also includes instructions for disclosing a patent. An individual who has actual knowledge of a patent which the individual believes contains Essential Claim(s) must disclose the information in accordance with section 6 of the W3C Patent Policy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2935477",
                    "name": "David Filip"
                },
                {
                    "authorId": "6750898",
                    "name": "S. McCance"
                },
                {
                    "authorId": "152175445",
                    "name": "D. Lewis"
                },
                {
                    "authorId": "35411959",
                    "name": "Christian Lieske"
                },
                {
                    "authorId": "49729166",
                    "name": "A. Lommel"
                },
                {
                    "authorId": "2799865",
                    "name": "Jirka Kosek"
                },
                {
                    "authorId": "1708763",
                    "name": "F. Sasaki"
                },
                {
                    "authorId": "52043671",
                    "name": "Yves Savourel"
                }
            ]
        }
    ]
}