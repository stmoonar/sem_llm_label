{
    "authorId": "2062835",
    "papers": [
        {
            "paperId": "9beeb74e6cc38b65ec9f07766bb5a4b133aa0c39",
            "title": "What Hides behind Unfairness? Exploring Dynamics Fairness in Reinforcement Learning",
            "abstract": "In sequential decision-making problems involving sensitive attributes like race and gender, reinforcement learning (RL) agents must carefully consider long-term fairness while maximizing returns. Recent works have proposed many different types of fairness notions, but how unfairness arises in RL problems remains unclear. In this paper, we address this gap in the literature by investigating the sources of inequality through a causal lens. We first analyse the causal relationships governing the data generation process and decompose the effect of sensitive attributes on long-term well-being into distinct components. We then introduce a novel notion called dynamics fairness, which explicitly captures the inequality stemming from environmental dynamics, distinguishing it from those induced by decision-making or inherited from the past. This notion requires evaluating the expected changes in the next state and the reward induced by changing the value of the sensitive attribute while holding everything else constant. To quantitatively evaluate this counterfactual concept, we derive identification formulas that allow us to obtain reliable estimations from data. Extensive experiments demonstrate the effectiveness of the proposed techniques in explaining, detecting, and reducing inequality in reinforcement learning. We publicly release code at https://github.com/familyld/InsightFair.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2297346219",
                    "name": "Zhihong Deng"
                },
                {
                    "authorId": "1746594",
                    "name": "Jing Jiang"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "2272171127",
                    "name": "Chengqi Zhang"
                }
            ]
        },
        {
            "paperId": "38941380603cafefdb18dd47b16f981f860c9e6a",
            "title": "Graph-guided Personalization for Federated Recommendation",
            "abstract": "Federated Recommendation is a new service architecture providing recommendations without sharing user data with the server. Existing methods deploy a recommendation model on each client and co-ordinate their training by synchronizing and aggregating item embeddings. However, while users usually hold diverse preferences toward certain items, these methods indiscriminately aggregate item embeddings from all clients, neutralizing underlying user-specific preferences. Such neglect will leave the aggregated embedding less discriminative and hinder personalized recommendations. This paper proposes a novel Graph-guided Personalization framework ( GPFedRec ) for the federated recommendation. The GPFedRec enhances cross-client collaboration by leveraging an adaptive graph structure to capture the correlation of user preferences. Besides, it guides training processes on clients by formulating them into a unified federated optimization framework, where models can simultaneously use shared and personalized user preferences. Experiments on five benchmark datasets demonstrate GPFedRec\u2019s superior performance in providing personalized recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7923634",
                    "name": "Chunxu Zhang"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "2144115714",
                    "name": "Tianyi Zhou"
                },
                {
                    "authorId": "2068884459",
                    "name": "Peng Yan"
                },
                {
                    "authorId": "2217456809",
                    "name": "Zijjian Zhang"
                },
                {
                    "authorId": "2119660361",
                    "name": "Bo Yang"
                }
            ]
        },
        {
            "paperId": "39c974bb16dad006353032942186087b40e25949",
            "title": "Synergistic Interplay between Search and Large Language Models for Information Retrieval",
            "abstract": "Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern retrieval models (RMs). The emergence of large language models (LLMs) has further revolutionized the IR field by enabling users to interact with search systems in natural languages. In this paper, we explore the advantages and disadvantages of LLMs and RMs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates information refinement through synergy between RMs and LLMs. InteR allows RMs to expand knowledge in queries using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using retrieved documents. This iterative refinement process augments the inputs of RMs and LLMs, leading to more accurate retrieval. Experiments on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks demonstrate that InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, even those using relevance judgment. Source code is available at https://github.com/Cyril-JZ/InteR",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "147062881",
                    "name": "Jiazhan Feng"
                },
                {
                    "authorId": "8801869",
                    "name": "Chongyang Tao"
                },
                {
                    "authorId": "2442662",
                    "name": "Xiubo Geng"
                },
                {
                    "authorId": "143681703",
                    "name": "Tao Shen"
                },
                {
                    "authorId": "46747953",
                    "name": "Can Xu"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "144060462",
                    "name": "Dongyan Zhao"
                },
                {
                    "authorId": "2086994543",
                    "name": "Daxin Jiang"
                }
            ]
        },
        {
            "paperId": "433b12f2f635e9c4f5518398dfd74bd6b7966ee4",
            "title": "Improving Cross-modal Alignment for Text-Guided Image Inpainting",
            "abstract": "Text-guided image inpainting (TGII) aims to restore missing regions based on a given text in a damaged image. Existing methods are based on a strong vision encoder and a cross-modal fusion model to integrate cross-modal features. However, these methods allocate most of the computation to visual encoding, while light computation on modeling modality interactions. Moreover, they take cross-modal fusion for depth features, which ignores a fine-grained alignment between text and image. Recently, vision-language pre-trained models (VLPM), encapsulating rich cross-modal alignment knowledge, have advanced in most multimodal tasks. In this work, we propose a novel model for TGII by improving cross-modal alignment (CMA). CMA model consists of a VLPM as a vision-language encoder, an image generator and global-local discriminators. To explore cross-modal alignment knowledge for image restoration, we introduce cross-modal alignment distillation and in-sample distribution distillation. In addition, we employ adversarial training to enhance the model to fill the missing region in complicated structures effectively. Experiments are conducted on two popular vision-language datasets. Results show that our model achieves state-of-the-art performance compared with other strong competitors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110348767",
                    "name": "Yucheng Zhou"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                }
            ]
        },
        {
            "paperId": "4b508ba98a180f27fd93b702d7044adad91620eb",
            "title": "Re-Reading Improves Reasoning in Large Language Models",
            "abstract": "To enhance the reasoning capabilities of off-the-shelf Large Language Models (LLMs), we introduce a simple, yet general and effective prompting method, Re2, i.e., \\textbf{Re}-\\textbf{Re}ading the question as input. Unlike most thought-eliciting prompting methods, such as Chain-of-Thought (CoT), which aim to elicit the reasoning process in the output, Re2 shifts the focus to the input by processing questions twice, thereby enhancing the understanding process. Consequently, Re2 demonstrates strong generality and compatibility with most thought-eliciting prompting methods, including CoT. Crucially, Re2 facilitates a\"bidirectional\"encoding in unidirectional decoder-only LLMs because the first pass could provide global information for the second pass. We begin with a preliminary empirical study as the foundation of Re2, illustrating its potential to enable\"bidirectional\"attention mechanisms. We then evaluate Re2 on extensive reasoning benchmarks across 14 datasets, spanning 112 experiments, to validate its effectiveness and generality. Our findings indicate that, with the exception of a few scenarios on vanilla ChatGPT, Re2 consistently enhances the reasoning performance of LLMs through a simple re-reading strategy. Further analyses reveal Re2's adaptability, showing how it can be effectively integrated with different LLMs, thought-eliciting prompting, and ensemble strategies. Our code is available at \\url{https://github.com/Tebmer/Rereading-LLM-Reasoning/}",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188774115",
                    "name": "Xiaohan Xu"
                },
                {
                    "authorId": "8801869",
                    "name": "Chongyang Tao"
                },
                {
                    "authorId": "143681703",
                    "name": "Tao Shen"
                },
                {
                    "authorId": "46747953",
                    "name": "Can Xu"
                },
                {
                    "authorId": "2261472368",
                    "name": "Hongbo Xu"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "4648762",
                    "name": "Jian-Guang Lou"
                }
            ]
        },
        {
            "paperId": "4fa4f9b40c407e0153c3e2c3c429077ee90383d1",
            "title": "Dual Personalization on Federated Recommendation",
            "abstract": "Federated recommendation is a new Internet service architecture that aims to provide privacy-preserving recommendation services in federated settings. Existing solutions are used to combine distributed recommendation algorithms and privacy-preserving mechanisms. Thus it inherently takes the form of heavyweight models at the server and hinders the deployment of on-device intelligent models to end-users. This paper proposes a novel Personalized Federated Recommendation (PFedRec) framework to learn many user-specific lightweight models to be deployed on smart devices rather than a heavyweight model on a server. Moreover, we propose a new dual personalization mechanism to effectively learn fine-grained personalization on both users and items. The overall learning process is formulated into a unified federated optimization framework. Specifically, unlike previous methods that share exactly the same item embeddings across users in a federated system, dual personalization allows mild finetuning of item embeddings for each user to generate user-specific views for item representations which can be integrated into existing federated recommendation methods to gain improvements immediately. Experiments on multiple benchmark datasets have demonstrated the effectiveness of PFedRec and the dual personalization mechanism. Moreover, we provide visualizations and in-depth analysis of the personalization techniques in item embedding, which shed novel insights on the design of recommender systems in federated settings. The code is available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7923634",
                    "name": "Chunxu Zhang"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "2144115714",
                    "name": "Tianyi Zhou"
                },
                {
                    "authorId": "2068884459",
                    "name": "Peng Yan"
                },
                {
                    "authorId": "47295030",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "48934799",
                    "name": "Chengqi Zhang"
                },
                {
                    "authorId": "2119660361",
                    "name": "Bo Yang"
                }
            ]
        },
        {
            "paperId": "54508c658be1701d099d2c93fded701761d7bd48",
            "title": "Federated Recommendation with Additive Personalization",
            "abstract": "Building recommendation systems via federated learning (FL) is a new emerging challenge for advancing next-generation Internet service and privacy protection. Existing approaches train shared item embedding by FL while keeping the user embedding private on client side. However, item embedding identical for all clients cannot capture users' individual differences on perceiving the same item and thus leads to poor personalization. Moreover, dense item embedding in FL results in expensive communication cost and latency. To address these challenges, we propose Federated Recommendation with Additive Personalization (FedRAP), which learns a global view of items via FL and a personalized view locally on each user. FedRAP enforces sparsity of the global view to save FL's communication cost and encourages difference between the two views through regularization. We propose an effective curriculum to learn the local and global views progressively with increasing regularization weights. To produce recommendations for an user, FedRAP adds the two views together to obtain a personalized item embedding. FedRAP achieves the best performance in FL setting on multiple benchmarks. It outperforms recent federated recommendation methods and several ablation study baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124848726",
                    "name": "Zhiwei Li"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "2144115714",
                    "name": "Tianyi Zhou"
                }
            ]
        },
        {
            "paperId": "59c53a0e49743b247ad99129d92d545f7a506863",
            "title": "Voting from Nearest Tasks: Meta-Vote Pruning of Pre-trained Models for Downstream Tasks",
            "abstract": "As a few large-scale pre-trained models become the major choices of various applications, new challenges arise for model pruning, e.g., can we avoid pruning the same model from scratch for every downstream task? How to reuse the pruning results of previous tasks to accelerate the pruning for a new task? To address these challenges, we create a small model for a new task from the pruned models of similar tasks. We show that a few fine-tuning steps on this model suffice to produce a promising pruned-model for the new task. We study this ''meta-pruning'' from nearest tasks on two major classes of pre-trained models, convolutional neural network (CNN) and vision transformer (ViT), under a limited budget of pruning iterations. Our study begins by investigating the overlap of pruned models for similar tasks and how the overlap changes over different layers and blocks. Inspired by these discoveries, we develop a simple but effective ''Meta-Vote Pruning (MVP)'' method that significantly reduces the pruning iterations for a new task by initializing a sub-network from the pruned models of its nearest tasks. In experiments, we demonstrate MVP's advantages in accuracy, efficiency, and generalization through extensive empirical studies and comparisons with popular pruning methods over several datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216736132",
                    "name": "Haiyan Zhao"
                },
                {
                    "authorId": "2144115714",
                    "name": "Tianyi Zhou"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "1746594",
                    "name": "Jing Jiang"
                },
                {
                    "authorId": "48934799",
                    "name": "Chengqi Zhang"
                }
            ]
        },
        {
            "paperId": "5becc0d68692f36b7d87aab3f1c172a1df370670",
            "title": "A Survey on Deep Learning based Time Series Analysis with Frequency Transformation",
            "abstract": "Recently, frequency transformation (FT) has been increasingly incorporated into deep learning models to significantly enhance state-of-the-art accuracy and efficiency in time series analysis. The advantages of FT, such as high efficiency and a global view, have been rapidly explored and exploited in various time series tasks and applications, demonstrating the promising potential of FT as a new deep learning paradigm for time series analysis. Despite the growing attention and the proliferation of research in this emerging field, there is currently a lack of a systematic review and in-depth analysis of deep learning-based time series models with FT. It is also unclear why FT can enhance time series analysis and what its limitations in the field are. To address these gaps, we present a comprehensive review that systematically investigates and summarizes the recent research advancements in deep learning-based time series analysis with FT. Specifically, we explore the primary approaches used in current models that incorporate FT, the types of neural networks that leverage FT, and the representative FT-equipped models in deep time series analysis. We propose a novel taxonomy to categorize the existing methods in this field, providing a structured overview of the diverse approaches employed in incorporating FT into deep learning models for time series analysis. Finally, we highlight the advantages and limitations of FT for time series modeling and identify potential future research directions that can further contribute to the community of time series analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2060200167",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "47835189",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "8253080",
                    "name": "Zhendong Niu"
                }
            ]
        },
        {
            "paperId": "6b80dde628e86633c78cc6e53c9ac70fa9287431",
            "title": "One-Shot Pruning for Fast-adapting Pre-trained Models on Devices",
            "abstract": "Large-scale pre-trained models have been remarkably successful in resolving downstream tasks. Nonetheless, deploying these models on low-capability devices still requires an effective approach, such as model pruning. However, pruning the model from scratch can pose a practical challenge given the limited resources of each downstream task or device. To tackle this issue, we present a scalable one-shot pruning method that leverages pruned knowledge of similar tasks to extract a sub-network from the pre-trained model for a new task. Specifically, we create a score mask using the pruned models of similar tasks to identify task-specific filters/nodes in the pre-trained model for the new task. Based on this mask, we conduct a single round of pruning to extract a suitably-sized sub-network that can quickly adapt to the new task with only a few training iterations. Our experimental analysis demonstrates the effectiveness of the proposed method on the convolutional neural networks (CNNs) and vision transformers (ViT) with various datasets. The proposed method consistently outperforms popular pruning baseline methods in terms of accuracy and efficiency when dealing with diverse downstream tasks with different memory constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216736132",
                    "name": "Haiyan Zhao"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                }
            ]
        }
    ]
}