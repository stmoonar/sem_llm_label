{
    "authorId": "2121305256",
    "papers": [
        {
            "paperId": "2745899afd2513524cd7d7869dc4b5335632b93d",
            "title": "Trust the Process: Analyzing Prospective Provenance for Data Cleaning",
            "abstract": "In the field of data-driven research and analysis, the quality of results largely depends on the quality of the data used. Data cleaning is a crucial step in improving the quality of data. Still, it is equally important to document the steps made during the data cleaning process to ensure transparency and enable others to assess the quality of the resulting data. While provenance models such as W3C PROV have been introduced to track changes and events related to any entity, their use in documenting the provenance of data-cleaning workflows can be challenging, particularly when mixing different types of documents or entities in the model. To address this, we propose a conceptual model and analysis that breaks down data-cleaning workflows into process abstraction and workflow recipes, refining operations to the column level. This approach provides users with detailed provenance information, enabling transparency, auditing, and support for data cleaning workflow improvements. Our model has several features that allow static analysis, e.g., to determine the minimal input schema and expected output schema for running a recipe, to identify which steps violate the column schema requirement constraint, and to assess the reusability of a recipe on a new dataset. We hope that our model and analysis will contribute to making data processing more transparent, accessible, and reusable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "1716911",
                    "name": "Bertram Lud\u00e4scher"
                }
            ]
        },
        {
            "paperId": "4609fdad4efbb6952b197cc962d8b16284f1f225",
            "title": "DCM explorer: a tool to support transparent data cleaning through provenance exploration",
            "abstract": "Data cleaning and preparation are essential phases of data science and machine learning (ML) workflows. Unfortunately, data cleaning processes are rarely well documented, despite the fact that they are error-prone and often involve hundreds of individual transformation steps. We have developed DCM (Data Cleaning Model) which captures provenance information for data cleaning. In this paper, we present DCM Explorer, a companion tool for DCM to explore and use data cleaning provenance. With DCM Explorer, a user can query and visualize the data cleaning workflows that are \"hidden\" in recorded provenance information, show different states of the data (as it underwent cleaning), explore an individual cell's history, etc. Through query-driven provenance reports, DCM Explorer adds valuable process documentation, making data cleaning more transparent, self-explanatory, and reusable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "1716911",
                    "name": "Bertram Lud\u00e4scher"
                }
            ]
        },
        {
            "paperId": "0eb212d0d2d6c5877f3f9496fe5ef0ff48924747",
            "title": "or2yw: Modeling and Visualizing OpenRefineHistories as YesWorkflow Diagrams",
            "abstract": "OpenRefine is a popular open-source data cleaning tool. It allows users to export a previously executed data cleaning workflow in a JSON format for possible reuse on other datasets. We have developed or2yw, a novel tool that maps a JSON-formatted OpenRefine operation history to a YesWorkflow (YW) model, which then can be visualized and queried using the YW tool. The latter was originally developed to allow researchers a simple way to annotate their program scripts in order to reveal the workflow steps and dataflow dependencies implicit in those scripts. With or2yw the user can automatically generate YW models from OpenRefine operation histories, thus providing a 'workflow view' on a previously executed sequence of data cleaning operations. The or2yw tool can generate different types of YesWorkflow models, e.g., a linear model which mirrors the sequential execution order of operations in OpenRefine, and a \\emph{parallel model} which reveals independent workflow branches, based on a simple analysis of dependencies between steps: if two operations are independent of each other (e.g., when the columns they read and write do not overlap) then these can be viewed as parallel steps in the data cleaning workflow. The resulting YW models can be understood as a form of prospective provenance, i.e., knowledge artifacts that can be queried and visualized (i) to help authors document their own data cleaning workflows, thereby increasing transparency, and (ii) to help other users, who might want to reuse such workflows, to understand them better.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "2111917373",
                    "name": "Lan Li"
                },
                {
                    "authorId": "1716911",
                    "name": "Bertram Lud\u00e4scher"
                }
            ]
        },
        {
            "paperId": "112dd6f0a395b52a55d9c1db0f53464c41729c53",
            "title": "Fine-Grained Chemical Entity Typing with Multimodal Knowledge Representation",
            "abstract": "Automated knowledge discovery from trending chemical literature is essential for more efficient biomedical research. How to extract detailed knowledge about chemical reactions from the core chemistry literature is a new emerging challenge that has not been well studied. In this paper, we study the new problem of fine-grained chemical entity typing, which poses interesting new challenges especially because of the complex name mentions frequently occurring in chemistry literature and graphic representation of entities. We introduce a new benchmark data set (CHEMET) to facilitate the study of the new task and propose a novel multi-modal representation learning framework to solve the problem of fine-grained chemical entity typing by leveraging external resources with chemical structures and using cross-modal attention to learn effective representation of text in the chemistry domain. Experiment results show that the proposed framework outperforms multiple state-of-the-art methods. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118831287",
                    "name": "Chenkai Sun"
                },
                {
                    "authorId": "48624767",
                    "name": "Weijian Li"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "1736467",
                    "name": "ChengXiang Zhai"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                }
            ]
        },
        {
            "paperId": "41350b24e0766b40a90fede59adec1531340dea9",
            "title": "Fine-grained Information Extraction from Biomedical Literature based on Knowledge-enriched Abstract Meaning Representation",
            "abstract": "Biomedical Information Extraction from scientific literature presents two unique and non-trivial challenges. First, compared with general natural language texts, sentences from scientific papers usually possess wider contexts between knowledge elements. Moreover, comprehending the fine-grained scientific entities and events urgently requires domain-specific background knowledge. In this paper, we propose a novel biomedical Information Extraction (IE) model to tackle these two challenges and extract scientific entities and events from English research papers. We perform Abstract Meaning Representation (AMR) to compress the wide context to uncover a clear semantic structure for each complex sentence. Besides, we construct the sentence-level knowledge graph from an external knowledge base and use it to enrich the AMR graph to improve the model\u2019s understanding of complex scientific concepts. We use an edge-conditioned graph attention network to encode the knowledge-enriched AMR graph for biomedical IE tasks. Experiments on the GENIA 2011 dataset show that the AMR and external knowledge have contributed 1.8% and 3.0% absolute F-score gains respectively. In order to evaluate the impact of our approach on real-world problems that involve topic-specific fine-grained knowledge elements, we have also created a new ontology and annotated corpus for entity and event extraction for the COVID-19 scientific literature, which can serve as a new benchmark for the biomedical IE community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116461591",
                    "name": "Zixuan Zhang"
                },
                {
                    "authorId": "2121305256",
                    "name": "N. Parulian"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "144332315",
                    "name": "Ahmed Elsayed"
                },
                {
                    "authorId": "1380290459",
                    "name": "Skatje Myers"
                },
                {
                    "authorId": "38352944",
                    "name": "M. Palmer"
                }
            ]
        }
    ]
}