{
    "authorId": "9557137",
    "papers": [
        {
            "paperId": "04169819fe10918fef03fcc5c9c0c9eca79ff56e",
            "title": "Benign Overfitting in Deep Neural Networks under Lazy Training",
            "abstract": "This paper focuses on over-parameterized deep neural networks (DNNs) with ReLU activation functions and proves that when the data distribution is well-separated, DNNs can achieve Bayes-optimal test error for classification while obtaining (nearly) zero-training error under the lazy training regime. For this purpose, we unify three interrelated concepts of overparameterization, benign overfitting, and the Lipschitz constant of DNNs. Our results indicate that interpolating with smoother functions leads to better generalization. Furthermore, we investigate the special case where interpolating smooth ground-truth functions is performed by DNNs under the Neural Tangent Kernel (NTK) regime for generalization. Our result demonstrates that the generalization error converges to a constant order that only depends on label noise and initialization noise, which theoretically verifies benign overfitting. Our analysis provides a tight lower bound on the normalized margin under non-smooth activation functions, as well as the minimum eigenvalue of NTK under high-dimensional settings, which has its own interest in learning theory.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118933045",
                    "name": "Zhenyu Zhu"
                },
                {
                    "authorId": "2803059",
                    "name": "Fanghui Liu"
                },
                {
                    "authorId": "34586458",
                    "name": "Grigorios G. Chrysos"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "1678641",
                    "name": "V. Cevher"
                }
            ]
        },
        {
            "paperId": "d0dc041f09ffdcf18d3342cd37f16683236a5971",
            "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
            "abstract": "As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidence for the causal models whenever compatibility entails strong implications for the joint distribution. We also demonstrate experimentally that detection of incompatibilities can aid in causal model selection.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2007696776",
                    "name": "P. M. Faller"
                },
                {
                    "authorId": "3454807",
                    "name": "L. C. Vankadara"
                },
                {
                    "authorId": "1387253571",
                    "name": "Atalanti A. Mastakouri"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "2223966060",
                    "name": "Dominik Janzing Karlsruhe Institute of Technology"
                },
                {
                    "authorId": "2223966932",
                    "name": "Amazon Research Tuebingen"
                }
            ]
        },
        {
            "paperId": "e87cf0ae2026e1db13c944700b4dd4e6d3afa3f3",
            "title": "Causal Discovery with Score Matching on Additive Models with Arbitrary Noise",
            "abstract": "Causal discovery methods are intrinsically constrained by the set of assumptions needed to ensure structure identifiability. Moreover additional restrictions are often imposed in order to simplify the inference task: this is the case for the Gaussian noise assumption on additive non-linear models, which is common to many causal discovery approaches. In this paper we show the shortcomings of inference under this hypothesis, analyzing the risk of edge inversion under violation of Gaussianity of the noise terms. Then, we propose a novel method for inferring the topological ordering of the variables in the causal graph, from data generated according to an additive non-linear model with a generic noise distribution. This leads to NoGAM (Not only Gaussian Additive noise Models), a causal discovery algorithm with a minimal set of assumptions and state of the art performance, experimentally benchmarked on synthetic data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2213655666",
                    "name": "Francesco Montagna"
                },
                {
                    "authorId": "2600472",
                    "name": "Nicoletta Noceti"
                },
                {
                    "authorId": "1690976",
                    "name": "L. Rosasco"
                },
                {
                    "authorId": "2119016656",
                    "name": "Kun Zhang"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                }
            ]
        },
        {
            "paperId": "fe4129f98712a9dc92dbb7914b686d6ccd60e791",
            "title": "Scalable Causal Discovery with Score Matching",
            "abstract": "This paper demonstrates how to discover the whole causal graph from the second derivative of the log-likelihood in observational non-linear additive Gaussian noise models. Leveraging scalable machine learning approaches to approximate the score function $\\nabla \\log p(\\mathbf{X})$, we extend the work of Rolland et al. (2022) that only recovers the topological order from the score and requires an expensive pruning step removing spurious edges among those admitted by the ordering. Our analysis leads to DAS (acronym for Discovery At Scale), a practical algorithm that reduces the complexity of the pruning by a factor proportional to the graph size. In practice, DAS achieves competitive accuracy with current state-of-the-art while being over an order of magnitude faster. Overall, our approach enables principled and scalable causal discovery, significantly lowering the compute bar.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2213655666",
                    "name": "Francesco Montagna"
                },
                {
                    "authorId": "2600472",
                    "name": "Nicoletta Noceti"
                },
                {
                    "authorId": "1690976",
                    "name": "L. Rosasco"
                },
                {
                    "authorId": "2119016656",
                    "name": "Kun Zhang"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                }
            ]
        },
        {
            "paperId": "1b3142ee576017e5aa34aac94c658f948b75dbcd",
            "title": "Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers",
            "abstract": "Algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. Contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the performance of classifiers across all groups (with increased degradation on the best performing groups). Extending the bias-variance decomposition for classification to fairness, we theoretically explain why the majority of fairness methods designed for low capacity models should not be used in settings involving high-capacity models, a scenario common to computer vision. We corroborate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. Building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52306341",
                    "name": "Dominik Zietlow"
                },
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "47231927",
                    "name": "Guha Balakrishnan"
                },
                {
                    "authorId": "2871632",
                    "name": "Matth\u00e4us Kleindessner"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "1707625",
                    "name": "B. Scholkopf"
                },
                {
                    "authorId": "145485799",
                    "name": "Chris Russell"
                }
            ]
        },
        {
            "paperId": "74270eb578c75d5bdd9c89b047c9f211bd7e15be",
            "title": "Are Two Heads the Same as One? Identifying Disparate Treatment in Fair Neural Networks",
            "abstract": "We show that deep networks trained to satisfy demographic parity often do so through a form of race or gender awareness, and that the more we force a network to be fair, the more accurately we can recover race or gender from the internal state of the network. Based on this observation, we investigate an alternative fairness approach: we add a second classification head to the network to explicitly predict the protected attribute (such as race or gender) alongside the original task. After training the two-headed network, we enforce demographic parity by merging the two heads, creating a network with the same architecture as the original network. We establish a close relationship between existing approaches and our approach by showing (1) that the decisions of a fair classifier are well-approximated by our approach, and (2) that an unfair and optimally accurate classifier can be recovered from a fair classifier and our second head predicting the protected attribute. We use our explicit formulation to argue that the existing fairness approaches, just as ours, demonstrate disparate treatment and that they are likely to be unlawful in a wide range of scenarios under US law.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "2871632",
                    "name": "Matth\u00e4us Kleindessner"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "2052380526",
                    "name": "Chris Russell"
                }
            ]
        },
        {
            "paperId": "ce4631ab1fdcaf6320b5e05039fd5ba4535302b7",
            "title": "Score matching enables causal discovery of nonlinear additive noise models",
            "abstract": "This paper demonstrates how to recover causal graphs from the score of the data distribution in non-linear additive (Gaussian) noise models. Using score matching algorithms as a building block, we show how to design a new generation of scalable causal discovery methods. To showcase our approach, we also propose a new efficient method for approximating the score's Jacobian, enabling to recover the causal graph. Empirically, we find that the new algorithm, called SCORE, is competitive with state-of-the-art causal discovery methods while being significantly faster.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1388317622",
                    "name": "Paul Rolland"
                },
                {
                    "authorId": "1678641",
                    "name": "V. Cevher"
                },
                {
                    "authorId": "2871632",
                    "name": "Matth\u00e4us Kleindessner"
                },
                {
                    "authorId": "2158168214",
                    "name": "Chris Russel"
                },
                {
                    "authorId": "1707625",
                    "name": "B. Scholkopf"
                },
                {
                    "authorId": "1700657",
                    "name": "D. Janzing"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                }
            ]
        },
        {
            "paperId": "d542e9230e94bf7230a892b7f2df2823ebce3079",
            "title": "Stochastic Frank-Wolfe for Composite Convex Minimization",
            "abstract": "A broad class of convex optimization problems can be formulated as a semidefinite program (SDP), minimization of a convex function over the positive-semidefinite cone subject to some affine constraints. The majority of classical SDP solvers are designed for the deterministic setting where problem data is readily available. In this setting, generalized conditional gradient methods (aka Frank-Wolfe-type methods) provide scalable solutions by leveraging the so-called linear minimization oracle instead of the projection onto the semidefinite cone. Most problems in machine learning and modern engineering applications, however, contain some degree of stochasticity. In this work, we propose the first conditional-gradient-type method for solving stochastic optimization problems under affine constraints. Our method guarantees O(k\u22121/3) convergence rate in expectation on the objective residual and O(k\u22125/12) on the feasibility gap.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "34119589",
                    "name": "A. Yurtsever"
                },
                {
                    "authorId": "2442024",
                    "name": "Olivier Fercoq"
                },
                {
                    "authorId": "1678641",
                    "name": "V. Cevher"
                }
            ]
        },
        {
            "paperId": "f56d363635bc378a196bae6d886ddd2d2899a220",
            "title": "Relative representations enable zero-shot latent space communication",
            "abstract": "Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However, factors such as the random weights initialization, training hyperparameters, or other sources of randomness in the training phase may induce incoherent latent spaces that hinder any form of reuse. Nevertheless, we empirically observe that, under the same data and modeling choices, the angles between the encodings within distinct latent spaces do not change. In this work, we propose the latent similarity between each sample and a fixed set of anchors as an alternative data representation, demonstrating that it can enforce the desired invariances without any additional training. We show how neural architectures can leverage these relative representations to guarantee, in practice, invariance to latent isometries and rescalings, effectively enabling latent space communication: from zero-shot model stitching to latent space comparison between diverse settings. We extensively validate the generalization capability of our approach on different datasets, spanning various modalities (images, text, graphs), tasks (e.g., classification, reconstruction) and architectures (e.g., CNNs, GCNs, transformers).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "23991573",
                    "name": "Luca Moschella"
                },
                {
                    "authorId": "2140400495",
                    "name": "Valentino Maiorca"
                },
                {
                    "authorId": "1931675362",
                    "name": "Marco Fumero"
                },
                {
                    "authorId": "1596822208",
                    "name": "Antonio Norelli"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "1796150",
                    "name": "E. Rodol\u00e0"
                }
            ]
        },
        {
            "paperId": "02b9e41693c0ad91dbe09c781dc6818b2c4b8a3c",
            "title": "Generalization and Robustness Implications in Object-Centric Learning",
            "abstract": "The idea behind object-centric representation learning is that natural scenes can better be modeled as compositions of objects and their relations as opposed to distributed representations. This inductive bias can be injected into neural networks to potentially improve systematic generalization and performance of downstream tasks in scenes with multiple objects. In this paper, we train state-of-the-art unsupervised models on five common multi-object datasets and evaluate segmentation metrics and downstream object property prediction. In addition, we study generalization and robustness by investigating the settings where either a single object is out of distribution -- e.g., having an unseen color, texture, or shape -- or global properties of the scene are altered -- e.g., by occlusions, cropping, or increasing the number of objects. From our experimental study, we find object-centric representations to be useful for downstream tasks and generally robust to most distribution shifts affecting objects. However, when the distribution shift affects the input in a less structured manner, robustness in terms of segmentation and downstream task performance may vary significantly across models and distribution shifts.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3431679",
                    "name": "Andrea Dittadi"
                },
                {
                    "authorId": "2117266622",
                    "name": "Samuele Papa"
                },
                {
                    "authorId": "2117258567",
                    "name": "Michele De Vita"
                },
                {
                    "authorId": "1707625",
                    "name": "B. Scholkopf"
                },
                {
                    "authorId": "1724252",
                    "name": "O. Winther"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                }
            ]
        }
    ]
}