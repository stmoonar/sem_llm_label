{
    "authorId": "2056580600",
    "papers": [
        {
            "paperId": "0a6591b2d1fca32a4f6b6414c3b73b7cc7b79b5d",
            "title": "Full Stage Learning to Rank: A Unified Framework for Multi-Stage Systems",
            "abstract": "The Probability Ranking Principle (PRP) has been considered as the foundational standard in the design of information retrieval (IR) systems. The principle requires an IR module's returned list of results to be ranked with respect to the underlying user interests, so as to maximize the results' utility. Nevertheless, we point out that it is inappropriate to indiscriminately apply PRP through every stage of a contemporary IR system. Such systems contain multiple stages (e.g., retrieval, pre-ranking, ranking, and re-ranking stages, as examined in this paper). The selection bias inherent in the model of each stage significantly influences the results that are ultimately presented to users. To address this issue, we propose an improved ranking principle for multi-stage systems, namely the Generalized Probability Ranking Principle (GPRP), to emphasize both the selection bias in each stage of the system pipeline as well as the underlying interest of users. We realize GPRP via a unified algorithmic framework named Full Stage Learning to Rank. Our core idea is to first estimate the selection bias in the subsequent stages and then learn a ranking model that best complies with the downstream modules' selection bias so as to deliver its top ranked results to the final ranked list in the system's output. We performed extensive experiment evaluations of our developed Full Stage Learning to Rank solution, using both simulations and online A/B tests in one of the leading short-video recommendation platforms. The algorithm is proved to be effective in both retrieval and ranking stages. Since deployed, the algorithm has brought consistent and significant performance gain to the platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293395261",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2300284323",
                    "name": "Haijun Zhao"
                },
                {
                    "authorId": "2302519916",
                    "name": "Rui Huang"
                },
                {
                    "authorId": "2300334834",
                    "name": "Beichuan Zhang"
                },
                {
                    "authorId": "51431610",
                    "name": "Na Mou"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2290226180",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2257375902",
                    "name": "Hongning Wang"
                },
                {
                    "authorId": "2266467527",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "8c441703c1a3e6f3667889bd55bfdfd5f5358206",
            "title": "UniSAR: Modeling User Transition Behaviors between Search and Recommendation",
            "abstract": "Nowadays, many platforms provide users with both search and recommendation services as important tools for accessing information. The phenomenon has led to a correlation between user search and recommendation behaviors, providing an opportunity to model user interests in a fine-grained way. Existing approaches either model user search and recommendation behaviors separately or overlook the different transitions between user search and recommendation behaviors. In this paper, we propose a framework named UniSAR that effectively models the different types of fine-grained behavior transitions for providing users a Unified Search And Recommendation service. Specifically, UniSAR models the user transition behaviors between search and recommendation through three steps: extraction, alignment, and fusion, which are respectively implemented by transformers equipped with pre-defined masks, contrastive learning that aligns the extracted fine-grained user transitions, and cross-attentions that fuse different transitions. To provide users with a unified service, the learned representations are fed into the downstream search and recommendation models. Joint learning on both search and recommendation data is employed to utilize the knowledge and enhance each other. Experimental results on two public datasets demonstrated the effectiveness of UniSAR in terms of enhancing both search and recommendation simultaneously. The experimental analysis further validates that UniSAR enhances the results by successfully modeling the user transition behaviors between search and recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296718641",
                    "name": "Teng Shi"
                },
                {
                    "authorId": "2153850397",
                    "name": "Zihua Si"
                },
                {
                    "authorId": "2293399145",
                    "name": "Jun Xu"
                },
                {
                    "authorId": "2293646334",
                    "name": "Xiao Zhang"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2293395261",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2203912362",
                    "name": "Dewei Leng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2293392741",
                    "name": "Yang Song"
                }
            ]
        },
        {
            "paperId": "0fe861147ea756d271d33121ac48519ea3a11811",
            "title": "Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework",
            "abstract": "With the proliferation of short video applications, the significance of short video recommendations has vastly increased. Unlike other recommendation scenarios, short video recommendation systems heavily rely on feedback from watch time. Existing approaches simply treat watch time as a direct label, failing to effectively harness its extensive semantics and introduce bias, thereby limiting the potential for modeling user interests based on watch time. To overcome this challenge, we propose a framework named Debiased Multiple-semantics-extracting Labeling (DML). DML constructs labels that encompass various semantics by utilizing quantiles derived from the distribution of watch time, prioritizing relative order rather than absolute label values. This approach facilitates easier model learning while aligning with the ranking objective of recommendations. Furthermore, we introduce a method inspired by causal adjustment to refine label definitions, thereby directly mitigating bias at the label level. We substantiate the effectiveness of our DML framework through both online and offline experiments. Extensive results demonstrate that our DML could effectively leverage watch time to discover users' real interests, enhancing their engagement in our application.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "1456009564",
                    "name": "Yimeng Bai"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2220987794",
                    "name": "Song Lu"
                },
                {
                    "authorId": "2115404510",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                }
            ]
        },
        {
            "paperId": "1b2740ab1d21afb2bb1176c50344cf428f213e2b",
            "title": "Understanding and Modeling Passive-Negative Feedback for Short-video Sequential Recommendation",
            "abstract": "Sequential recommendation is one of the most important tasks in recommender systems, which aims to recommend the next interacted item with historical behaviors as input. Traditional sequential recommendation always mainly considers the collected positive feedback such as click, purchase, etc. However, in short-video platforms such as TikTok, video viewing behavior may not always represent positive feedback. Specifically, the videos are played automatically, and users passively receive the recommended videos. In this new scenario, users passively express negative feedback by skipping over videos they do not like, which provides valuable information about their preferences. Different from the negative feedback studied in traditional recommender systems, this passive-negative feedback can reflect users\u2019 interests and serve as an important supervision signal in extracting users\u2019 preferences. Therefore, it is essential to carefully design and utilize it in this novel recommendation scenario. In this work, we first conduct analyses based on a large-scale real-world short-video behavior dataset and illustrate the significance of leveraging passive feedback. We then propose a novel method that deploys the sub-interest encoder, which incorporates positive feedback and passive-negative feedback as supervision signals to learn the user\u2019s current active sub-interest. Moreover, we introduce an adaptive fusion layer to integrate various sub-interests effectively. To enhance the robustness of our model, we then introduce a multi-task learning module to simultaneously optimize two kinds of feedback \u2013 passive-negative feedback and traditional randomly-sampled negative feedback. The experiments on two large-scale datasets verify that the proposed method can significantly outperform state-of-the-art approaches. The code is released at https://github.com/tsinghua-fib-lab/RecSys2023-SINE to benefit the community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111417074",
                    "name": "Yunzhu Pan"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "31687d5dd4d97b69a3143560729f00cdc76c4b7f",
            "title": "Inverse Learning with Extremely Sparse Feedback for Recommendation",
            "abstract": "Modern personalized recommendation services often rely on user feedback, either explicit or implicit, to improve the quality of services. Explicit feedback refers to behaviors like ratings, while implicit feedback refers to behaviors like user clicks. However, in the scenario of full-screen video viewing experiences like Tiktok and Reels, the click action is absent, resulting in unclear feedback from users, hence introducing noises in modeling training. Existing approaches on de-noising recommendation mainly focus on positive instances while ignoring the noise in a large amount of sampled negative feedback. In this paper, we propose a meta-learning method to annotate the unlabeled data from loss and gradient perspectives, which considers the noises in both positive and negative instances. Specifically, we first propose anInverse Dual Loss (IDL) to boost the true label learning and prevent the false label learning. Then we further propose anInverse Gradient (IG) method to explore the correct updating gradient and adjust the updating based on meta-learning. Finally, we conduct extensive experiments on both benchmark and industrial datasets where our proposed method can significantly improve AUC by 9.25% against state-of-the-art methods. Further analysis verifies the proposed inverse learning framework is model-agnostic and can improve a variety of recommendation backbones. The source code, along with the best hyper-parameter settings, is available at this link: https://github.com/Guanyu-Lin/InverseLearning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257446689",
                    "name": "Guanyu Lin"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "118961885",
                    "name": "Y. Zheng"
                },
                {
                    "authorId": "2129445960",
                    "name": "Yinfeng Li"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2266777606",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2266467527",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "2257351656",
                    "name": "Zhiheng Li"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "7fcc1c7bc9d1f763022b7a46eb916d2d6c36af36",
            "title": "Mixed Attention Network for Cross-domain Sequential Recommendation",
            "abstract": "In modern recommender systems, sequential recommendation leverages chronological user behaviors to make effective next-item suggestions, which suffers from data sparsity issues, especially for new users. One promising line of work is the cross-domain recommendation, which trains models with data across multiple domains to improve the performance in data-scarce domains. Recent proposed cross-domain sequential recommendation models such as PiNet and DASL have a common drawback relying heavily on overlapped users in different domains, which limits their usage in practical recommender systems. In this paper, we propose a M ixed A ttention N etwork (MAN) with local and global attention modules to extract the domain-specific and cross-domain information. Firstly, we propose a local/global encoding layer to capture the domain-specific/cross-domain sequential pattern. Then we propose a mixed attention layer with item similarity attention, sequence-fusion attention, and group-prototype attention to capture the local/global item similarity, fuse the local/global item sequence, and extract the user groups across different domains, respectively. Finally, we propose a local/global prediction layer to further evolve and combine the domain-specific and cross-domain interests. Experimental results on two real-world datasets (each with two domains) demonstrate the superiority of our proposed model. Further study also illustrates that our proposed method and components are model-agnostic and effective, respectively. The code and data are available at https://github.com/Guanyu-Lin/MAN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257446689",
                    "name": "Guanyu Lin"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "118961885",
                    "name": "Y. Zheng"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2266777606",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2266467527",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "2257351656",
                    "name": "Zhiheng Li"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                },
                {
                    "authorId": "2284377864",
                    "name": "Meng Wang"
                }
            ]
        },
        {
            "paperId": "926157ec82a606939b1535cd52b1fb9a69643833",
            "title": "LabelCraft: Empowering Short Video Recommendations with Automated Label Crafting",
            "abstract": "Short video recommendations often face limitations due to the quality of user feedback, which may not accurately depict user interests. To tackle this challenge, a new task has emerged: generating more dependable labels from original feedback. Existing label generation methods rely on manual rules, demanding substantial human effort and potentially misaligning with the desired objectives of the platform. To transcend these constraints, we introduce LabelCraft, a novel automated label generation method explicitly optimizing pivotal operational metrics for platform success. By formulating label generation as a higher-level optimization problem above recommender model optimization, LabelCraft introduces a trainable labeling model for automatic label mechanism modeling. Through meta-learning techniques, LabelCraft effectively addresses the bi-level optimization hurdle posed by the recommender and labeling models, enabling the automatic acquisition of intricate label generation mechanisms. Extensive experiments on real-world datasets corroborate LabelCraft's excellence across varied operational metrics, encompassing usage time, user engagement, and retention. Codes are available at https://github.com/baiyimeng/LabelCraft.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275528388",
                    "name": "Yimeng Bai"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2275773462",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2266777606",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                }
            ]
        },
        {
            "paperId": "a33c6bd9bcdc3b99b5fec66edea6bd334163cc74",
            "title": "Dual-interest Factorization-heads Attention for Sequential Recommendation",
            "abstract": "Accurate user interest modeling is vital for recommendation scenarios. One of the effective solutions is the sequential recommendation that relies on click behaviors, but this is not elegant in the video feed recommendation where users are passive in receiving the streaming contents and return skip or no-skip behaviors. Here skip and no-skip behaviors can be treated as negative and positive feedback, respectively. With the mixture of positive and negative feedback, it is challenging to capture the transition pattern of behavioral sequence. To do so, FeedRec has exploited a shared vanilla Transformer, which may be inelegant because head interaction of multi-heads attention does not consider different types of feedback. In this paper, we propose Dual-interest Factorization-heads Attention for Sequential Recommendation (short for DFAR) consisting of feedback-aware encoding layer, dual-interest disentangling layer and prediction layer. In the feedback-aware encoding layer, we first suppose each head of multi-heads attention can capture specific feedback relations. Then we further propose factorization-heads attention which can mask specific head interaction and inject feedback information so as to factorize the relation between different types of feedback. Additionally, we propose a dual-interest disentangling layer to decouple positive and negative interests before performing disentanglement on their representations. Finally, we evolve the positive and negative interests by corresponding towers whose outputs are contrastive by BPR loss. Experiments on two real-world datasets show the superiority of our proposed method against state-of-the-art baselines. Further ablation study and visualization also sustain its effectiveness. We release the source code here: https://github.com/tsinghua-fib-lab/WWW2023-DFAR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9277993",
                    "name": "Guanyu Lin"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "118961885",
                    "name": "Y. Zheng"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": null,
                    "name": "Zhiheng Li"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "a6d06a4503b15604f51132c771cf8ea8cfdd244c",
            "title": "PEPNet: Parameter and Embedding Personalized Network for Infusing with Personalized Prior Information",
            "abstract": "With the increase of content pages and interactive buttons in online services such as online-shopping and video-watching websites, industrial-scale recommender systems face challenges in multi-domain and multi-task recommendations. The core of multi-task and multi-domain recommendation is to accurately capture user interests in multiple scenarios given multiple user behaviors. In this paper, we propose a plug-and-play Parameter and Embedding Personalized Network (PEPNet) for multi-domain and multi-task recommendation. PEPNet takes personalized prior information as input and dynamically scales the bottom-level Embedding and top-level DNN hidden units through gate mechanisms. Embedding Personalized Network (EPNet) performs personalized selection on Embedding to fuse features with different importance for different users in multiple domains. Parameter Personalized Network (PPNet) executes personalized modification on DNN parameters to balance targets with different sparsity for different users in multiple tasks. We have made a series of special engineering optimizations combining the Kuaishou training framework and the online deployment environment. By infusing personalized selection of Embedding and personalized modification of DNN parameters, PEPNet tailored to the interests of each individual obtains significant performance gains, with online improvements exceeding 1% in multiple task metrics across multiple domains. We have deployed PEPNet in Kuaishou apps, serving over 300 million users every day.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2125752970",
                    "name": "Chenbin Zhang"
                },
                {
                    "authorId": "2115330531",
                    "name": "Yiqun Hui"
                },
                {
                    "authorId": "2203912362",
                    "name": "Dewei Leng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "d12dbe90e767b299de644de41ae47a5733634e58",
            "title": "TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou",
            "abstract": "Life-long user behavior modeling, i.e., extracting a user's hidden interests from rich historical behaviors in months or even years, plays a central role in modern CTR prediction systems. Conventional algorithms mostly follow two cascading stages: a simple General Search Unit (GSU) for fast and coarse search over tens of thousands of long-term behaviors and an Exact Search Unit (ESU) for effective Target Attention (TA) over the small number of finalists from GSU. Although efficient, existing algorithms mostly suffer from a crucial limitation: the inconsistent target-behavior relevance metrics between GSU and ESU. As a result, their GSU usually misses highly relevant behaviors but retrieves ones considered irrelevant by ESU. In such case, the TA in ESU, no matter how attention is allocated, mostly deviates from the real user interests and thus degrades the overall CTR prediction accuracy. To address such inconsistency, we propose TWo-stage Interest Network (TWIN), where our Consistency-Preserved GSU (CP-GSU) adopts the identical target-behavior relevance metric as the TA in ESU, making the two stages twins. Specifically, to break TA's computational bottleneck and extend it from ESU to GSU, or namely from behavior length 102 to length 104 - 105, we build a novel attention mechanism by behavior feature splitting. For the video inherent features of a behavior, we calculate their linear projection by efficient pre-computing & caching strategies. And for the user-item cross features, we compress each into a one-dimentional bias term in the attention score calculation to save the computational cost. The consistency between two stages, together with the effective TA-based relevance metric in CP-GSU, contributes to significant performance gain in CTR prediction. Offline experiments on a 46 billion scale real production dataset from Kuaishou and an Online A/B test show that TWIN outperforms all compared SOTA algorithms. With optimized online infrastructure, we reduce the computational bottleneck by 99.3%, which contributes to the successful deployment of TWIN on Kuaishou, serving the main traffic of hundreds of millions of active users everyday.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2125752970",
                    "name": "Chenbin Zhang"
                },
                {
                    "authorId": "2068057294",
                    "name": "Zhiyi Fu"
                },
                {
                    "authorId": "2055666765",
                    "name": "Xiaoxue Zang"
                },
                {
                    "authorId": "2203437528",
                    "name": "Lin Guan"
                },
                {
                    "authorId": "2115404510",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "2115330531",
                    "name": "Yiqun Hui"
                },
                {
                    "authorId": "2203912362",
                    "name": "Dewei Leng"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        }
    ]
}