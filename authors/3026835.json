{
    "authorId": "3026835",
    "papers": [
        {
            "paperId": "b6cc82be6fb457021c2f13d5238f44c0fb128a76",
            "title": "Data-centric scientific workflow management systems",
            "abstract": "Recent trends in science and technology augur a rapid increase in the number of computations being employed by scientists. Accompanying increased volumes are growing expectations for the tools that scientists use to handle their computations. These increased volumes and expectations present a new set of problems and opportunities in computation management. In this thesis, I propose Data Centric Scientific Workflow Management Systems (DSWMSs) to address these issues. DSWMSs supersede current approaches by leveraging a deeper understanding of the data manipulated by computations to provide new features and improve usability and performance. Examples of such features include data provenance, work sharing, and interactive computational steering. \nIn this thesis, I make several contributions towards realizing the concept of a DSWMS. First, in conjunction with scientists from several scientific domains, I propose a set of services that are not provided by current paradigms, but are made possible in DSWMSs. Second, I define an abstract model, the Functional Data Model with Relational Covers (FDM/RC), for representing scientific workloads and a language for defining and manipulating instances (schemas) of the model. Third, I design and implement GridDB, a prototype DSWMS. GridDB is deployed on a large cluster at Lawrence Livermore National Laboratories where it runs science applications at real-world scales. The deployment uncovers a pair of technical problems involving the provisioning of data provenance and memoization (computational caching) so I also contribute solutions to these problems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143666627",
                    "name": "M. Franklin"
                },
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                }
            ]
        },
        {
            "paperId": "74caec1c3ebfb2bfe704669dc12f5b444fe3eb3a",
            "title": "Data-Preservation in Scientific Workflow Middleware",
            "abstract": "This paper investigates data-preservation, a feature of scientific workflow middleware (SWM) useful for supporting data provenance and \"smart recomputation.\" We observe that in order for an SWM supporting data preservation to achieve decent performance, it should execute on top of copy-on-write file systems. Unfortunately, most file systems in-use at scientific computing facilities were designed without copy-on-write semantics. In response, we design, implement and evaluate a middleware-level solution that is based on user-provided hints and parallelization. The solution can be deployed on top of current file systems and is able to scale almost arbitrarily. Our validation is based on real use-cases from astrophysics and experiments on a cluster with 4 file systems",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                },
                {
                    "authorId": "143666627",
                    "name": "M. Franklin"
                },
                {
                    "authorId": "144970712",
                    "name": "G. Abdulla"
                },
                {
                    "authorId": "3072441",
                    "name": "J. Garlick"
                },
                {
                    "authorId": "2107493221",
                    "name": "M. Miller"
                }
            ]
        },
        {
            "paperId": "0a40310d96f01ef3f58354e8dccff12789fdb5c1",
            "title": "Scaling Up Data-Centric Middleware on a Cluster Computer",
            "abstract": "Data-centric workflow middleware systems are workflow systems that treat data as first class objects alongside programs. These systems improve the usability, responsiveness and efficiency of workflow execution over cluster (and grid) computers. In this work, we explore the scalability of one such system, GridDB, on cluster computers. We measure the performance and scalability of GridDB in executing data-intensive image processing workflows from the SuperMACHO astrophysics survey on a large cluster computer. Our first experimental study concerns the scale-up of GridDB. We make a rather surprising finding, that while the middleware system issues many queries and transactions to a DBMS, file system operations present the first-tier bottleneck. We circumvent this bottleneck and increase the scalability of GridDB by more than 2-fold on our image processing application (up to 128 nodes). In a second study, we demonstrate the sensitivity of GridDB performance (and therefore application performance) to characteristics of the workflows being executed. To manage these sensitivities, we provide guidelines for trading off the costs and benefits of GridDB at a fine-grain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                },
                {
                    "authorId": "143666627",
                    "name": "M. Franklin"
                },
                {
                    "authorId": "3072441",
                    "name": "J. Garlick"
                },
                {
                    "authorId": "144970712",
                    "name": "G. Abdulla"
                }
            ]
        },
        {
            "paperId": "3a31e91357b9fe0f2ba3a62a3e8ec592a9a24427",
            "title": "Scientific data management in the coming decade",
            "abstract": "Scientific instruments and computer simulations are creating vast data stores that require new scientific methods to analyze and organize the data. Data volumes are approximately doubling each year. Since these new instruments have extraordinary precision, the data quality is also rapidly improving. Analyzing this data to find the subtle effects missed by previous studies requires algorithms that can simultaneously deal with huge datasets and that can find very subtle effects --- finding both needles in the haystack and finding very small haystacks that were undetected in previous measurements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39941882",
                    "name": "J. Gray"
                },
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                },
                {
                    "authorId": "1389942725",
                    "name": "M. Nieto-Santisteban"
                },
                {
                    "authorId": "7934073",
                    "name": "A. Szalay"
                },
                {
                    "authorId": "1765659",
                    "name": "D. DeWitt"
                },
                {
                    "authorId": "2806754",
                    "name": "G. Heber"
                }
            ]
        },
        {
            "paperId": "c1a4463923a1107a0a05fe04cbdaf3cc7d5697f8",
            "title": "Middleware for Astronomical Data Analysis Pipelines",
            "abstract": "In this paper the authors describe the approach to research, develop, and evaluate prototype middleware tools and architectures. The developed tools can be used by scientists to compose astronomical data analysis pipelines easily. They use the SuperMacho data pipelines as example applications to test the framework. they describe their experience from scheduling and running these analysis pipelines on massive parallel processing machines. they use MCR a Linux cluster machine with 1152 nodes and Luster parallel file system as the hardware test-bed to test and enhance the scalability of the tools.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144970712",
                    "name": "G. Abdulla"
                },
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                },
                {
                    "authorId": "3072441",
                    "name": "J. Garlick"
                },
                {
                    "authorId": "2107492439",
                    "name": "M. Miller"
                },
                {
                    "authorId": "145033128",
                    "name": "S. Nikolaev"
                },
                {
                    "authorId": "2052414089",
                    "name": "K. Cook"
                },
                {
                    "authorId": "40495647",
                    "name": "J. Brase"
                }
            ]
        },
        {
            "paperId": "b8126474b0202fe52127484043ab3569df2da3f7",
            "title": "GridDB: Data-Centric Services in Scientific Grids",
            "abstract": "By understanding the semantics of workflows and their data, grid middleware can provide data-centric services that are lacking in currently deployed process-centric grid middleware. We describe GridDB, a grid middleware system that provides data-centric services as well as one example service, computational steering.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                },
                {
                    "authorId": "143666627",
                    "name": "M. Franklin"
                }
            ]
        },
        {
            "paperId": "0c7b76558fd94bb1b322562f08dab40bddd07e29",
            "title": "GridDB: a relational interface for the grid",
            "abstract": "Computational Grids offer the promise of harnessing vast computing resources on a global scale for computationallyintensive tasks. While many uses are envisioned, data analysis and simulation by computational scientists seems to be the initial killer application. The data-intensive nature of modern scientific applications is driving a rethinking of basic grid architecture and tools. In emerging grid systems data management is a primary concern. Modern Grid efforts, such as the Grid Physics Network (GriPhyN) [1], are recognizing the importance of databases for data management, but have refrained from using database technology as a core paradigm. As part of the GriPhyN project we are exploring a deeper integration of grid and database technologies. We have developed GridDB, which is a system that provides a relational interface to Grid services. Our goal is to investigate the benefits of a declarative, data-centric interface that hides the complex workflows of procedural programs and non-relational data typically found in Grid data analysis. In this demonstration, we show an initial version of the GridDB system and highlight some of the advantages of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3026835",
                    "name": "David T. Liu"
                },
                {
                    "authorId": "143666627",
                    "name": "M. Franklin"
                },
                {
                    "authorId": "48331451",
                    "name": "Devesh Parekh"
                }
            ]
        }
    ]
}