{
    "authorId": "2128664093",
    "papers": [
        {
            "paperId": "c15afaab44de52971612048f91974efd8b97cbbb",
            "title": "Eliciting Joint Truthful Answers and Profiles From Strategic Workers in Mobile Crowdsourcing Systems",
            "abstract": "Mobile crowdsourcing has emerged as a promising paradigm that applies the principle of crowdsourcing to perform tasks of mobility requirement. Due to the openness of mobile crowdsourcing, workers may yield low-quality task answers. To alleviate this problem, substantial efforts have been devoted to elicit truthful data from workers. On the other hand, to facilitate task assignment, workers are required to upload the platform their profiles, such as locations and expertise. Therefore, task assignment outcomes and thus mobile crowdsourcing service accuracy is subject to the quality of workers\u2019 self-reported profiles. In this paper, we leverage incentive design to motivate workers to honestly reveal both task answers and their profiles. The challenge is to design one incentive payment for truth elicitation in two kinds of submissions. For this, we first derive the sufficient and necessary conditions for answer truthfulness and profile truthfulness separately. We then construct an incentive optimization problem that incorporates these conditions as constraints. Its optimal solution lists the payment to each worker that elicits answers and profiles jointly. Our proposed mechanism, with a formally proved bounded approximation ratio, ensures that truth-telling is a Bayesian Nash equilibrium. We prototype the mechanism and conduct a series of experiments that involve 30 volunteers to validate the efficacy and efficiency of the proposed mechanism.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3077451",
                    "name": "Mingyan Xiao"
                },
                {
                    "authorId": "1471431081",
                    "name": "Wenqiang Jin"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "2150654106",
                    "name": "Ming Li"
                }
            ]
        },
        {
            "paperId": "2a75cf81f1cafbcdc99d15467bdd4b8fca9a6902",
            "title": "Overview of the CLEF-2022 CheckThat! Lab Task 1 on Identifying Relevant Claims in Tweets",
            "abstract": "We present an overview of CheckThat! lab 2022 Task 1, part of the 2022 Conference and Labs of the Evaluation Forum (CLEF). Task 1 asked to predict which posts in a Twitter stream are worth fact-checking, focusing on COVID-19 and politics in six languages: Arabic, Bulgarian, Dutch, English, Spanish, and Turkish. A total of 19 teams participated and most submissions managed to achieve sizable improvements over the baselines using Transformer-based models such as BERT and GPT-3. Across the four subtasks, approaches that targetted multiple languages (be it individually or in conjunction, in general obtained the best performance. We describe the dataset and the task setup, including the evaluation settings, and we give a brief overview of the participating systems. As usual in the CheckThat! lab, we release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research on finding relevant tweets that can help different stakeholders such as fact-checkers, journalists, and policymakers. \u00a9 2022 Copyright for this paper by its authors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "1864635",
                    "name": "Tommaso Caselli"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "65877664",
                    "name": "Shaden Shaar"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "47195288",
                    "name": "Alex Nikolov"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                }
            ]
        },
        {
            "paperId": "3316927ed3eab0c8e4a2d11a0092aed3009ad99a",
            "title": "SUAM: A Service Unified Access Model for Microservice Management",
            "abstract": "Microservice architecture promotes the cost reduction, efficiency increase, and quality improvement of software development. However, with the diversification of manufacturers\u2019 technology and the complexity of the services, the existing research on unified access to microservice lacks a specification that can be summarized, and more intrusive transformations of access service are required in the access process. Aiming at the standardization of unified access of microservice, the Service Unified Access Model (SUAM) is proposed. The main purpose of the model is to solve the complexity of multi-language and multi-platform access of the microservice and the standardization of the access process. The model makes a contribution to the service from three aspects: service resources, product resources, and function properties. This model can not only describe the functionality of the service in more detail but also can help reduce the amount of access code by 15% without affecting the business function of the accessed service.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143514402",
                    "name": "Yu-Shi Jiang"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "2153643514",
                    "name": "Ying Li"
                }
            ]
        },
        {
            "paperId": "1fe759eb9f5c78679108950a1e8969f2be21abf7",
            "title": "A Dashboard for Mitigating the COVID-19 Misinfodemic",
            "abstract": "This paper describes the current milestones achieved in our ongoing project that aims to understand the surveillance of, impact of and intervention on COVID-19 misinfodemic on Twitter. Specifically, it introduces a public dashboard which, in addition to displaying case counts in an interactive map and a navigational panel, also provides some unique features not found in other places. Particularly, the dashboard uses a curated catalog of COVID-19 related facts and debunks of misinformation, and it displays the most prevalent information from the catalog among Twitter users in user-selected U.S. geographic regions. The paper explains how to use BERT models to match tweets with the facts and misinformation and to detect their stance towards such information. The paper also discusses the results of preliminary experiments on analyzing the spatio-temporal spread of misinformation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2741352",
                    "name": "Zhengyuan Zhu"
                },
                {
                    "authorId": "153615419",
                    "name": "Kevin Meng"
                },
                {
                    "authorId": "22717388",
                    "name": "Josue Caraballo"
                },
                {
                    "authorId": "40446918",
                    "name": "Israa Jaradat"
                },
                {
                    "authorId": "2119203789",
                    "name": "Xiao Shi"
                },
                {
                    "authorId": "2118690164",
                    "name": "Zeyu Zhang"
                },
                {
                    "authorId": "3074177",
                    "name": "F. Akrami"
                },
                {
                    "authorId": "2081874079",
                    "name": "Haojin Liao"
                },
                {
                    "authorId": "144285061",
                    "name": "Fatma Arslan"
                },
                {
                    "authorId": "143951834",
                    "name": "Damian Jimenez"
                },
                {
                    "authorId": "2081605509",
                    "name": "Mohanmmed Samiul Saeef"
                },
                {
                    "authorId": "153682198",
                    "name": "P. Pathak"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                }
            ]
        },
        {
            "paperId": "2640d13440f4df974bbea1c877d36a22e6795a3c",
            "title": "Modeling Factual Claims with Semantic Frames",
            "abstract": "In this paper, we introduce an extension of the Berkeley FrameNet for the structured and semantic modeling of factual claims. Modeling is a robust tool that can be leveraged in many different tasks such as matching claims to existing fact-checks and translating claims to structured queries. Our work introduces 11 new manually crafted frames along with 9 existing FrameNet frames, all of which have been selected with fact-checking in mind. Along with these frames, we are also providing 2,540 fully annotated sentences, which can be used to understand how these frames are intended to work and to train machine learning models. Finally, we are also releasing our annotation tool to facilitate other researchers to make their own local extensions to FrameNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144285061",
                    "name": "Fatma Arslan"
                },
                {
                    "authorId": "22717388",
                    "name": "Josue Caraballo"
                },
                {
                    "authorId": "143951834",
                    "name": "Damian Jimenez"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                }
            ]
        },
        {
            "paperId": "3365b53f671348c73f16d7d1c2284b10846095a9",
            "title": "Gradient-Based Adversarial Training on Transformer Networks for Detecting Check-Worthy Factual Claims",
            "abstract": "We present a study on the efficacy of adversarial training on transformer neural network models, with respect to the task of detecting check-worthy claims. In this work, we introduce the first adversarially-regularized, transformer-based claim spotter model that achieves state-of-the-art results on multiple challenging benchmarks. We obtain a 4.70 point F1-score improvement over current state-of-the-art models on the ClaimBuster Dataset and CLEF2019 Dataset, respectively. In the process, we propose a method to apply adversarial training to transformer models, which has the potential to be generalized to many similar text classification tasks. Along with our results, we are releasing our codebase and manually labeled datasets. We also showcase our models' real world usage via a live public API.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153615419",
                    "name": "Kevin Meng"
                },
                {
                    "authorId": "143951834",
                    "name": "Damian Jimenez"
                },
                {
                    "authorId": "144285061",
                    "name": "Fatma Arslan"
                },
                {
                    "authorId": "1493378425",
                    "name": "J. Devasier"
                },
                {
                    "authorId": "1493333237",
                    "name": "Daniel Obembe"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                }
            ]
        },
        {
            "paperId": "3764d7b273c9295dbd19cebfe039186d2ed3e966",
            "title": "Jennifer for COVID-19: An NLP-Powered Chatbot Built for the People and by the People to Combat Misinformation",
            "abstract": "Just as SARS-CoV-2, a new form of coronavirus continues to infect a growing number of people around the world, harmful misinformation about the outbreak also continues to spread. With the goal of combating misinformation, we designed and built Jennifer\u2013a chatbot maintained by a global group of volunteers. With Jennifer, we hope to learn whether public information from reputable sources could be more effectively organized and shared in the wake of a crisis as well as to understand issues that the public were most immediately curious about. In this paper, we introduce Jennifer and describe the design of this proof-of-principle system. We also present lessons learned and discuss open challenges. Finally, to facilitate future research, we release COVID-19 Question Bank, a dataset of 3,924 COVID-19-related questions in 944 groups, gathered from our users and volunteers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "47346594",
                    "name": "T. Grandison"
                },
                {
                    "authorId": "5814382",
                    "name": "P. Silveyra"
                },
                {
                    "authorId": "5307936",
                    "name": "A. Douraghy"
                },
                {
                    "authorId": "2066614915",
                    "name": "Xinyu Guan"
                },
                {
                    "authorId": "3756957",
                    "name": "T. Kieselbach"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "2108829291",
                    "name": "Haiqi Zhang"
                }
            ]
        },
        {
            "paperId": "65baa67a7cdb3b4b948d126ac5b41ca9c98b1f3b",
            "title": "A benchmarking study of embedding-based entity alignment for knowledge graphs",
            "abstract": "Entity alignment seeks to find entities in different knowledge graphs (KGs) that refer to the same real-world object. Recent advancement in KG embedding impels the advent of embedding-based entity alignment, which encodes entities in a continuous embedding space and measures entity similarities based on the learned embeddings. In this paper, we conduct a comprehensive experimental study of this emerging field. We survey 23 recent embedding-based entity alignment approaches and categorize them based on their techniques and characteristics. We also propose a new KG sampling algorithm, with which we generate a set of dedicated benchmark datasets with various heterogeneity and distributions for a realistic evaluation. We develop an open-source library including 12 representative embedding-based entity alignment approaches, and extensively evaluate these approaches, to understand their strengths and limitations. Additionally, for several directions that have not been explored in current approaches, we perform exploratory experiments and report our preliminary findings for future studies. The benchmark datasets, open-source library and experimental results are all accessible online and will be duly maintained.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "144381296",
                    "name": "Zequn Sun"
                },
                {
                    "authorId": "9482533",
                    "name": "Qingheng Zhang"
                },
                {
                    "authorId": "145066190",
                    "name": "Wei Hu"
                },
                {
                    "authorId": "2144521805",
                    "name": "Chengming Wang"
                },
                {
                    "authorId": "1998918",
                    "name": "Muhao Chen"
                },
                {
                    "authorId": "3074177",
                    "name": "F. Akrami"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                }
            ]
        },
        {
            "paperId": "6f373f4711e1285bdec23069c9503d3bf77bfaef",
            "title": "A Benchmark Dataset of Check-worthy Factual Claims",
            "abstract": "In this paper we present the ClaimBuster dataset of 23,533 statements extracted from all U.S. general election presidential debates and annotated by human coders. The ClaimBuster dataset can be leveraged in building computational methods to identify claims that are worth fact-checking from the myriad of sources of digital or traditional media. The ClaimBuster dataset is publicly available to the research community, and it can be found at http://doi.org/10.5281/zenodo.3609356.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144285061",
                    "name": "Fatma Arslan"
                },
                {
                    "authorId": "2789540",
                    "name": "Naeemul Hassan"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "2819331",
                    "name": "Mark Tremayne"
                }
            ]
        },
        {
            "paperId": "84b8ff51c8fe57426a56d0adca99495d4fce0f4c",
            "title": "Realistic Re-evaluation of Knowledge Graph Completion Methods: An Experimental Study",
            "abstract": "In the active research area of employing embedding models for knowledge graph completion, particularly for the task of link prediction, most prior studies used two benchmark datasets FB15k and WN18 in evaluating such models. Most triples in these and other datasets in such studies belong to reverse and duplicate relations which exhibit high data redundancy due to semantic duplication, correlation or data incompleteness. This is a case of excessive data leakage---a model is trained using features that otherwise would not be available when the model needs to be applied for real prediction. There are also Cartesian product relations for which every triple formed by the Cartesian product of applicable subjects and objects is a true fact. Link prediction on the aforementioned relations is easy and can be achieved with even better accuracy using straightforward rules instead of sophisticated embedding models. A more fundamental defect of these models is that the link prediction scenario, given such data, is non-existent in the real-world. This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models when the unrealistic triples are removed. Our experiment results show these models are much less accurate than what we used to perceive. Their poor accuracy renders link prediction a task without truly effective automated solution. Hence, we call for re-investigation of possible effective approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3074177",
                    "name": "F. Akrami"
                },
                {
                    "authorId": "8561847",
                    "name": "Mohammed Samiul Saeef"
                },
                {
                    "authorId": "9482533",
                    "name": "Qingheng Zhang"
                },
                {
                    "authorId": "145066190",
                    "name": "Wei Hu"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                }
            ]
        }
    ]
}