{
    "authorId": "2934941",
    "papers": [
        {
            "paperId": "4f24fdb70a70426d0cd75653148f783e69d9883b",
            "title": "Relational Data Imputation with Graph Neural Networks",
            "abstract": "Performing data analysis over incomplete data produces biased re-sultsandsub-parperformance. Imputationoverrelationaldatasets that contain both categorical and continuous variables is challenging. The challenges are accentuated when the missingness proportion of dataset is high, wherein a large fraction of the relation contain missing values, or if missing values occur in multiple attributes of a single tuple. In this paper, we propose GRIMP, a novel approach for imputation that tackles these challenges. GRIMP achieves high imputation accuracy through a combination of three novel ideas. First, it represents relational data as a heterogeneous graph, encoding sophisticated relationships be-tween tuples, attributes and cell values. Second, it uses graph representation learning based on message passing to combine and aggregate the representations from appropriate neighborhoods. This allows GRIMP to leverage information from other cell values of the same tuple and that of similar tuples for imputation. Finally, it uses a self-supervised multi-task learning paradigm for training imputation models. In other words, GRIMP does not need any explicit training data as it uses the existing relational data, even when it has missing values. GRIMP trains an imputation model for each attribute using a two-stage approach consisting of a task agnostic section, where the parameters are shared across all attributes, and an attribute specific imputation model. Experiments over ten datasets and seven baselines show that GRIMP performs accurate imputation and provides new insights about the limitations of data imputation systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51031408",
                    "name": "Riccardo Cappuzzo"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "2265384723",
                    "name": "Paolo Papotti"
                }
            ]
        },
        {
            "paperId": "52f5431e6cd02a262d9d0d7a2d4e65fc96a31137",
            "title": "Fairness and Bias in Truth Discovery Algorithms: An Experimental Analysis",
            "abstract": "Machine learning (ML) based approaches are increasingly being used in a number of applications with societal impact. Training ML models often require vast amounts of labeled data, and crowdsourcing is a dominant paradigm for obtaining labels from multiple workers. Crowd workers may sometimes provide unreliable labels, and to address this, truth discovery (TD) algorithms such as majority voting are applied to determine the consensus labels from conflicting worker responses. However, it is important to note that these consensus labels may still be biased based on sensitive attributes such as gender, race, or political affiliation. Even when sensitive attributes are not involved, the labels can be biased due to different perspectives of subjective aspects such as toxicity. In this paper, we conduct a systematic study of the bias and fairness of TD algorithms. Our findings using two existing crowd-labeled datasets, reveal that a non-trivial proportion of workers provide biased results, and using simple approaches for TD is sub-optimal. Our study also demonstrates that popular TD algorithms are not a panacea. Additionally, we quantify the impact of these unfair workers on downstream ML tasks and show that conventional methods for achieving fairness and correcting label biases are ineffective in this setting. We end the paper with a plea for the design of novel bias-aware truth discovery algorithms that can ameliorate these issues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215273194",
                    "name": "Simone Lazier"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "2126533826",
                    "name": "H. Anahideh"
                }
            ]
        },
        {
            "paperId": "b21331583813ec3b29adf8d3f632e701af1e473e",
            "title": "The Art of Losing to Win: Using Lossy Image Compression to Improve Data Loading in Deep Learning Pipelines",
            "abstract": "Training deep learning (DL) models often takes a significant amount of time and is thus typically performed on expensive GPUs to speed up the process. However, data loading has recently been identified as one of the main performance bottlenecks in DL, resulting in GPU under-utilization. Looking forward, the combination of larger datasets and faster GPUs will exacerbate the problem. The data management community has started to address this by proposing data loading optimization techniques, including lossy image compression. While lossy compression is a conceptually promising approach for mitigating data loading bottlenecks in DL, there is only limited understanding of its efficacy in terms of impact on model throughput and accuracy. In this paper, we present an extensive experimental analysis of lossy image compression as a means to improve the performance of neural network training. We find that lossy compression can improve both throughput and accuracy of DL pipelines if resources such as time or storage capacity are limited. Furthermore, the choice of compression quality and codec are important hyperparameters when training deep neural networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185529002",
                    "name": "Lennart Behme"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "2641694",
                    "name": "Alireza Rezaei Mahdiraji"
                },
                {
                    "authorId": "1399355221",
                    "name": "Jorge-Arnulfo Quian\u00e9-Ruiz"
                },
                {
                    "authorId": "1733290",
                    "name": "V. Markl"
                }
            ]
        },
        {
            "paperId": "62c508be77d7d8fc07dcb3f7c5917c033fcb83b6",
            "title": "Editorial: Special Issue on Deep Learning for Data Quality",
            "abstract": "This editorial summarizes the content of the Special Issue on Deep Learning for Data Quality of the Journal of Data and Information Quality (JDIQ).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145530628",
                    "name": "Donatello Santoro"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                }
            ]
        },
        {
            "paperId": "72d8ae327ed821b5012bd77687206504f85ce2f0",
            "title": "Big Data, Small Personas: How Algorithms Shape the Demographic Representation of Data-Driven User Segments",
            "abstract": "Derived from the notion of algorithmic bias, it is possible that creating user segments such as personas from data results in over- or under-representing certain segments (FAIRNESS), does not properly represent the diversity of the user populations (DIVERSITY), or produces inconsistent results when hyperparameters are changed (CONSISTENCY). Collecting user data on 363M video views from a global news and media organization, we compare personas created from this data using different algorithms. Results indicate that the algorithms fall into two groups: those that generate personas with low diversity-high fairness and those that generate personas with high diversity-low fairness. The algorithms that rank high on diversity tend to rank low on fairness (Spearman's correlation: -0.83). The algorithm that best balances diversity, fairness, and consistency is Spectral Embedding. The results imply that the choice of algorithm is a crucial step in data-driven user segmentation, because the algorithm fundamentally impacts the demographic attributes of the generated personas and thus influences how decision makers view the user population. The results have implications for algorithmic bias in user segmentation and creating user segments that not only consider commercial segmentation criteria but also consider criteria derived from ethical discussions in the computing community.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2734912",
                    "name": "Joni O. Salminen"
                },
                {
                    "authorId": "2089407401",
                    "name": "Kamal Chhirang"
                },
                {
                    "authorId": "1861541",
                    "name": "Soon-Gyo Jung"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1666242842",
                    "name": "Kathleen W. Guan"
                },
                {
                    "authorId": "144715575",
                    "name": "B. Jansen"
                }
            ]
        },
        {
            "paperId": "b1f0b0dcc69f61b89c53b473a2585d2566c16d21",
            "title": "Accelerating Entity Lookups in Knowledge Graphs Through Embeddings",
            "abstract": "Tabular data is widespread on the web and in enterprise data lakes. Recently, there has been increasing interest in developing algorithms for matching tabular data with knowledge graphs. This involves learning correspondences between tabular entities such as cells, rows, and columns and entities in the knowledge graph. Such semantic annotation of tabular entities has numerous applications such as entity disambiguation, knowledge graph expansion, error detection and repair in tabular data, and more. A key first step for all these applications is the lookup function that matches a query string to a candidate set of knowledge graph entities. Despite the importance of entity lookup, current implementations are not optimized, not robust to misspellings, and ignore semantic relationships. To address these problems, we represent each entity as an embedding - a compact vector representation that is cognizant of syntactic and semantic similarities and supports fast lookup. We propose, EMBLOOKUP, a novel and efficient approach for learning such an embedding. EMBLOOKUP is based on deep metric learning with triplet loss and supports accurate and efficient lookup of knowledge graph entities. We conduct extensive experiments that demonstrate that EMBLOOKUP achieves 1\u20132 orders of magnitude speedup while being tolerant to many types of errors in the query and data. We demonstrate the generality of EMBLOOKUP over diverse application scenarios in semantic table annotation, entity disambiguation, and data repair.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10667713",
                    "name": "Ghadeer Abuoda"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1704622",
                    "name": "Ashraf Aboulnaga"
                }
            ]
        },
        {
            "paperId": "b5abc4e71a1c047c46a83a47dc791b0a2673d265",
            "title": "SIRAJ: A Unified Framework for Aggregation of Malicious Entity Detectors",
            "abstract": "High-quality intelligence of Internet threat (e.g., malware files, malicious domains, phishing URLs and malicious IPs) are important for both security practitioners and the research community. Given the agility of attackers, the scale of the Internet, and the fast-evolving landscape of threats, one could not rely solely on a single source (such as an anti-malware engine or an IP blacklist) for obtaining accurate, up-to-date, and comprehensive threat analysis. Instead, we need to aggregate the analysis from multiple sources. However, it is non-trivial to do such aggregation effectively. A common practice is to label an indicator (malware, domains, URLs, etc.) as malicious if it is marked by a number of sources above an ad-hoc certain threshold. Often, this results in sub-optimal performance as it assumes that all sources are of similar quality/expertise, independent, and temporally stable, which unfortunately are often not true in practice. A natural alternative is to train a supervised machine learning model. However, this approach needs a sufficiently large amount of manually labeled ground truth, which is time-consuming to collect and has to be updated frequently, resulting in substantial recurring costs. In this paper, we propose SIRAJ, a novel framework for aggregating the detection output of various intelligence sources such as anti-malware engines. SIRAJ is based on the pretrain and fine-tune paradigm. Specifically, we use self-supervised learning-based approaches to learn a pre-trained embedding model that converts multi-source inputs into a high-dimensional embedding. The embeddings are learned through three carefully designed pretext tasks that imbue them with knowledge about dependencies between scanners and their temporal dynamics. The learned embeddings could be used for diverse downstream machine learning tasks. SIRAJ is designed to be general and can be used for diverse domains such as URLs, malware, and IPs. Further, SIRAJ works well even when there is limited to no labeled data available. Through extensive experiments, we show that our learned representations can produce results comparable to supervised methods while only requiring as little as 100 labeled samples. Importantly, the results show that SIRAJ accurately detects threat indicators much earlier than the baseline algorithms, a feat that is critical against short-lived indicators like Phishing URLs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "143811518",
                    "name": "Mohamed Nabeel"
                },
                {
                    "authorId": "40492371",
                    "name": "Euijin Choo"
                },
                {
                    "authorId": "1783739",
                    "name": "Issa M. Khalil"
                },
                {
                    "authorId": "2087140581",
                    "name": "Ting Yu"
                }
            ]
        },
        {
            "paperId": "cff151657c79e70017f654cfcc26eeca893cbe84",
            "title": "Prediction Intervals for Learned Cardinality Estimation: An Experimental Evaluation",
            "abstract": "Cardinality estimation is a fundamental and challenging problem in query optimization. Recently, a number of learned models have been proposed for this task. Often, these models significantly outperform traditional approaches in terms of accuracy. One of the stumbling blocks that prevents their increased adoption is that the learned models do not quantify the uncertainty of their estimates. It is desirable to associate each cardinality estimate of the model with a prediction interval that will contain the true cardinality with an user-specified probability. The size of the prediction interval encodes the uncertainty allowing the query optimizer to make an informed decision. For example, knowing that the cardinality of a query $q$ lies between 1\u20133% of the relation size with high probability is more informative than a single point estimate of 2%. While there has been some prior work on deriving bounds for traditional methods (such as sampling or histograms), they are not directly applicable for the learned models for cardinality estimation. In this paper, we conduct a systematic investigation of potential approaches for obtaining prediction intervals. We enumerate the list of desirable properties such as the ability to wrap around a learned model without significant internal modification and providing bounds with theoretical guarantees in a distribution agnostic manner among others. Based on an extensive literature survey, we identify four practical and high quality approaches for uncertainty quantification that satisfies these criteria. They span a wide spectrum in terms of theoretical guarantees, width of prediction interval and time taken for computing the prediction intervals. We conduct extensive experimental analysis of the efficacy of these approaches over three diverse and representative cardinality estimation algorithms. Our experiments covers diverse workloads involving both point and range queries and highlights the inherent trade-offs. Our results show that it is possible to obtain accurate prediction intervals in an efficient manner thereby opening up new avenues for future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1442194534",
                    "name": "Suraj Shetiya"
                },
                {
                    "authorId": "1721062",
                    "name": "Nick Koudas"
                },
                {
                    "authorId": "2054246177",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "251eefcad91f05e8babce1ced33beb1e2268c4ed",
            "title": "To Intervene or Not To Intervene: Cost based Intervention for Combating Fake News",
            "abstract": "Social media platforms provide valuable and powerful means with which users can share content, comment, and communicate. They also suffer from abuse through the dissemination of fake news and misinformation. While a fair amount of work has been done on detecting fake news, on the complementary problem of limiting its propagation, progress has been modest. Once an item is detected as fake, a social media company can intervene on the item and take an appropriate action, including hard intervention (e.g., removing an account) and soft intervention (e.g., labeling the item as \"suspicious\"). Given that fake news detectors are not 100% reliable, we study the problem of developing a cost aware intervention policy which decides whether to intervene based on the truthiness and popularity of the item. Our solution, Solomon, consists of three modular components - truthiness estimation, popularity estimation (with and without intervention), and intervention policy. Our extensive experiments on real and fake news from multiple domains show that Solomon can perform effective intervention.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "2053261077",
                    "name": "Michael Simpson"
                },
                {
                    "authorId": "1708593",
                    "name": "L. Lakshmanan"
                }
            ]
        },
        {
            "paperId": "2f4ddfec2ad8e44e71cc1775d561f5c8bacc918b",
            "title": "Answering Complex Queries in an Online Community Network",
            "abstract": "\n \n An online community network such as Twitter or amazon.com links entities (e.g., users, products) with various relationships (e.g., friendship, co-purchase) and make such information available for access through a web interface. The web interfaces of these networks often support features such as keyword search and \"get-neighbors\" \u2014 so a visitor can quickly find entities (e.g., users/products) of interest. Nonetheless, the interface is usually too restrictive to answer complex queries such as (1) find 100 Twitter users from California with at least 100 followers who talked about ICWSM last year or (2) find 100 books with at least 200 5-star reviews at amazon.com. In this paper, we introduce the novel problem of answering complex queries that involve non-searchable attributes through the web interface of an online community network. We model such a network as a heterogeneous graph with two access channels, Content Search and Local Search. We propose a unified approach that transforms the complex query into a small number of supported ones based on a strategic query-selection process. We conduct comprehensive experiments on Twitter and amazon.com which demonstrate the efficacy of our proposed algorithms.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3038200",
                    "name": "Azade Nazi"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1754970",
                    "name": "Vagelis Hristidis"
                },
                {
                    "authorId": "47899254",
                    "name": "Nan Zhang"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        }
    ]
}