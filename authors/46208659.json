{
    "authorId": "46208659",
    "papers": [
        {
            "paperId": "2874422b6b822631106d6d4b0cea7f356787c107",
            "title": "Zero-shot stance detection: Paradigms and challenges",
            "abstract": "A major challenge in stance detection is the large (potentially infinite) and diverse set of stance topics. Collecting data for such a set is unrealistic due to both the expense of annotation and the continuous creation of new real-world topics (e.g., a new politician runs for office). Furthermore, stancetaking occurs in a wide range of languages and genres (e.g., Twitter, news articles). While zero-shot stance detection in English, where evaluation is on topics not seen during training, has received increasing attention, we argue that this attention should be expanded to multilingual and multi-genre settings. We discuss two paradigms for English zero-shot stance detection evaluation, as well as recent work in this area. We then discuss recent work on multilingual and multi-genre stance detection, which has focused primarily on non-zero-shot settings. We argue that this work should be expanded to multilingual and multi-genre zero-shot stance detection and propose best practices to systematize and stimulate future work in this direction. While domain adaptation techniques are well-suited for work in these settings, we argue that increased care should be taken to improve model explainability and to conduct robust evaluations, considering not only empirical generalization ability but also the understanding of complex language and inferences.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "7d494710c0ae6b7608448ad22b27705a52271a9e",
            "title": "Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language",
            "abstract": "Counterspeech, i.e., responses to counteract potential harms of hateful speech, has become an increasingly popular solution to address online hate speech without censorship. However, properly countering hateful language requires countering and dispelling the underlying inaccurate stereotypes implied by such language. In this work, we draw from psychology and philosophy literature to craft six psychologically inspired strategies to challenge the underlying stereotypical implications of hateful language. We first examine the convincingness of each of these strategies through a user study, and then compare their usages in both human- and machine-generated counterspeech datasets. Our results show that human-written counterspeech uses countering strategies that are more specific to the implied stereotype (e.g., counter examples to the stereotype, external factors about the stereotype's origins), whereas machine-generated counterspeech uses less specific strategies (e.g., generally denouncing the hatefulness of speech). Furthermore, machine-generated counterspeech often employs strategies that humans deem less convincing compared to human-produced counterspeech. Our findings point to the importance of accounting for the underlying stereotypical implications of speech when generating counterspeech and for better machine reasoning about anti-stereotypical examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2219642161",
                    "name": "Jimin Mun"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "1388021166",
                    "name": "Akhila Yerukola"
                },
                {
                    "authorId": "2264512607",
                    "name": "Laura Vianna"
                },
                {
                    "authorId": "2264050472",
                    "name": "Sarah-Jane Leslie"
                },
                {
                    "authorId": "2729164",
                    "name": "Maarten Sap"
                }
            ]
        },
        {
            "paperId": "ea0585ed23e25d5f8682eb91f20c6ddbeb6a27b4",
            "title": "Towards Countering Essentialism through Social Bias Reasoning",
            "abstract": "Essentialist beliefs (i.e., believing that members of the same group are fundamentally alike) play a central role in social stereotypes and can lead to harm when left unchallenged. In our work, we conduct exploratory studies into the task of countering essentialist beliefs (e.g., ``liberals are stupid''). Drawing on prior work from psychology and NLP, we construct five types of counterstatements and conduct human studies on the effectiveness of these different strategies. Our studies also investigate the role in choosing a counterstatement of the level of explicitness with which an essentialist belief is conveyed. We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy. We conclude with a discussion of challenges and open questions for future work in this area (e.g., improving factuality, studying community-specific variation) and we emphasize the importance of work at the intersection of NLP and psychology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "70655120",
                    "name": "Nina Taneja"
                },
                {
                    "authorId": "144790242",
                    "name": "S. Leslie"
                },
                {
                    "authorId": "2729164",
                    "name": "Maarten Sap"
                }
            ]
        },
        {
            "paperId": "0b4681139e8a77a92207ed81233c16bb3772e238",
            "title": "Mitigating Covertly Unsafe Text within Natural Language Systems",
            "abstract": "An increasingly prevalent problem for intelligent technologies is text safety, as uncontrolled systems may generate recommendations to their users that lead to injury or life-threatening consequences. However, the degree of explicitness of a generated statement that can cause physical harm varies. In this paper, we distinguish types of text that can lead to physical harm and establish one particularly underexplored category: covertly unsafe text. Then, we further break down this category with respect to the system's information and discuss solutions to mitigate the generation of text in each of these subcategories. Ultimately, our work defines the problem of covertly unsafe language that causes physical harm and argues that this subtle yet dangerous issue needs to be prioritized by stakeholders and regulators. We highlight mitigation strategies to inspire future researchers to tackle this challenging problem and help improve safety within smart systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185480449",
                    "name": "Alex Mei"
                },
                {
                    "authorId": "2104456950",
                    "name": "Anisha Kabir"
                },
                {
                    "authorId": "49285370",
                    "name": "Sharon Levy"
                },
                {
                    "authorId": "2065894334",
                    "name": "Melanie Subbiah"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "144955737",
                    "name": "J. Judge"
                },
                {
                    "authorId": "2767140",
                    "name": "D. Patton"
                },
                {
                    "authorId": "1940819",
                    "name": "Bruce Bimber"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                },
                {
                    "authorId": "1682479",
                    "name": "William Yang Wang"
                }
            ]
        },
        {
            "paperId": "2b6291eb76e2ff885238e94704bb795046d7d530",
            "title": "SafeText: A Benchmark for Exploring Physical Safety in Language Models",
            "abstract": "Understanding what constitutes safe text is an important issue in natural language processing and can often prevent the deployment of models deemed harmful and unsafe. One such type of safety that has been scarcely studied is commonsense physical safety, i.e. text that is not explicitly violent and requires additional commonsense knowledge to comprehend that it leads to physical harm. We create the first benchmark dataset, SafeText, comprising real-life scenarios with paired safe and physically unsafe pieces of advice. We utilize SafeText to empirically study commonsense physical safety across various models designed for text generation and commonsense reasoning tasks. We find that state-of-the-art large language models are susceptible to the generation of unsafe text and have difficulty rejecting unsafe advice. As a result, we argue for further studies of safety and the assessment of commonsense physical safety in models before release.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49285370",
                    "name": "Sharon Levy"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "2065894334",
                    "name": "Melanie Subbiah"
                },
                {
                    "authorId": "1912259",
                    "name": "Lydia B. Chilton"
                },
                {
                    "authorId": "2767140",
                    "name": "D. Patton"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                },
                {
                    "authorId": "1682479",
                    "name": "William Yang Wang"
                }
            ]
        },
        {
            "paperId": "4e9e4403cb892a2c0facd257d832393793cbd5b4",
            "title": "Seeded Hierarchical Clustering for Expert-Crafted Taxonomies",
            "abstract": "Practitioners from many disciplines (e.g., political science) use expert-crafted taxonomies to make sense of large, unlabeled corpora. In this work, we study Seeded Hierarchical Clustering (SHC): the task of automatically fitting unlabeled data to such taxonomies using only a small set of labeled examples. We propose HierSeed, a novel weakly supervised algorithm for this task that uses only a small set of labeled seed examples. It is both data and computationally efficient. HierSeed assigns documents to topics by weighing document density against topic hierarchical structure. It outperforms both unsupervised and supervised baselines for the SHC task on three real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056290146",
                    "name": "Anish Saha"
                },
                {
                    "authorId": "2024713528",
                    "name": "Amith Ananthram"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "144016781",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "d89cee8ab8a8b775b49044aae112b3dd910d7338",
            "title": "Penguins Don\u2019t Fly: Reasoning about Generics through Instantiations and Exceptions",
            "abstract": "Generics express generalizations about the world (e.g., birds can fly) that are not universally true (e.g., newborn birds and penguins cannot fly). Commonsense knowledge bases, used extensively in NLP, encode some generic knowledge but rarely enumerate such exceptions and knowing when a generic statement holds or does not hold true is crucial for developing a comprehensive understanding of generics. We present a novel framework informed by linguistic theory to generate exemplars\u2014specific cases when a generic holds true or false. We generate ~19k exemplars for ~650 generics and show that our framework outperforms a strong GPT-3 baseline by 12.8 precision points. Our analysis highlights the importance of linguistic theory-based controllability for generating exemplars, the insufficiency of knowledge bases as a source of exemplars, and the challenges exemplars pose for the task of natural language inference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "2012510",
                    "name": "Jena D. Hwang"
                },
                {
                    "authorId": "1857797",
                    "name": "Chandra Bhagavatula"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "1699545",
                    "name": "Yejin Choi"
                }
            ]
        },
        {
            "paperId": "e329a7326ac8a96e9f224d8c41adb247e4a9a2b8",
            "title": "Legal and Political Stance Detection of SCOTUS Language",
            "abstract": "We analyze publicly available US Supreme Court documents using automated stance detection. In the first phase of our work, we investigate the extent to which the Court\u2019s public-facing language is political. We propose and calculate two distinct ideology metrics of SCOTUS justices using oral argument transcripts. We then compare these language-based metrics to existing social scientific measures of the ideology of the Supreme Court and the public. Through this cross-disciplinary analysis, we find that justices who are more responsive to public opinion tend to express their ideology during oral arguments. This observation provides a new kind of evidence in favor of the attitudinal change hypothesis of Supreme Court justice behavior. As a natural extension of this political stance detection, we propose the more specialized task of legal stance detection with our new dataset SC-stance, which matches written opinions to legal questions. We find competitive performance on this dataset using language adapters trained on legal documents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2096153562",
                    "name": "Noah Bergam"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        },
        {
            "paperId": "f210e446fcc55425d8d71a7b962c754df0d5f514",
            "title": "Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in English, Spanish, and Arabic",
            "abstract": "As natural language processing systems become more widespread, it is necessary to address fairness issues in their implementation and deployment to ensure that their negative impacts on society are understood and minimized. However, there is limited work that studies fairness using a multilingual and intersectional framework or on downstream tasks. In this paper, we introduce four multilingual Equity Evaluation Corpora, supplementary test sets designed to measure social biases, and a novel statistical framework for studying unisectional and intersectional social biases in natural language processing. We use these tools to measure gender, racial, ethnic, and intersectional social biases across five models trained on emotion regression tasks in English, Spanish, and Arabic. We find that many systems demonstrate statistically significant unisectional and intersectional social biases. We make our code and datasets available for download.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2077593669",
                    "name": "Antonio Camara"
                },
                {
                    "authorId": "70655120",
                    "name": "Nina Taneja"
                },
                {
                    "authorId": "1571776558",
                    "name": "Tamjeed Azad"
                },
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "1804104",
                    "name": "R. Zemel"
                }
            ]
        },
        {
            "paperId": "4e9d4b3d89b4dec3d313c3295c70d3afff6ae50f",
            "title": "Adversarial Learning for Zero-Shot Stance Detection on Social Media",
            "abstract": "Stance detection on social media can help to identify and understand slanted news or commentary in everyday life. In this work, we propose a new model for zero-shot stance detection on Twitter that uses adversarial learning to generalize across topics. Our model achieves state-of-the-art performance on a number of unseen test topics with minimal computational costs. In addition, we extend zero-shot stance detection to topics not previously considered, highlighting future directions for zero-shot transfer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46208659",
                    "name": "Emily Allaway"
                },
                {
                    "authorId": "145311801",
                    "name": "Malavika Srikanth"
                },
                {
                    "authorId": "145590324",
                    "name": "K. McKeown"
                }
            ]
        }
    ]
}