{
    "authorId": "2490772",
    "papers": [
        {
            "paperId": "731586270694adb69625a13597de4da53575a989",
            "title": "Uncertainty Resolution in Misinformation Detection",
            "abstract": "Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pipelines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2277448720",
                    "name": "Yury Orlovskiy"
                },
                {
                    "authorId": "2277447889",
                    "name": "Camille Thibault"
                },
                {
                    "authorId": "2150709360",
                    "name": "Anne Imouza"
                },
                {
                    "authorId": "2028704969",
                    "name": "J. Godbout"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                },
                {
                    "authorId": "104333826",
                    "name": "Kellin Pelrine"
                }
            ]
        },
        {
            "paperId": "74c7343d91d5464c27ca407fd504b07e690363be",
            "title": "Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation",
            "abstract": "Large Language Models have emerged as prime candidates to tackle misinformation mitigation. However, existing approaches struggle with hallucinations and overconfident predictions. We propose an uncertainty quantification framework that leverages both direct confidence elicitation and sampled-based consistency methods to provide better calibration for NLP misinformation mitigation solutions. We first investigate the calibration of sample-based consistency methods that exploit distinct features of consistency across sample sizes and stochastic levels. Next, we evaluate the performance and distributional shift of a robust numeric verbalization prompt across single vs. two-step confidence elicitation procedure. We also compare the performance of the same prompt with different versions of GPT and different numerical scales. Finally, we combine the sample-based consistency and verbalized methods to propose a hybrid framework that yields a better uncertainty estimation for GPT models. Overall, our work proposes novel uncertainty quantification methods that will improve the reliability of Large Language Models in misinformation mitigation applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279753745",
                    "name": "Mauricio Rivera"
                },
                {
                    "authorId": "2028704969",
                    "name": "J. Godbout"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                },
                {
                    "authorId": "104333826",
                    "name": "Kellin Pelrine"
                }
            ]
        },
        {
            "paperId": "913ffd0a2e7f794e9b2e60b9728673044be47b2a",
            "title": "T-NET: Weakly Supervised Graph Learning for Combatting Human Trafficking",
            "abstract": "Human trafficking (HT) for forced sexual exploitation, often described as modern-day slavery, is a pervasive problem that affects millions of people worldwide. Perpetrators of this crime post advertisements (ads) on behalf of their victims on adult service websites (ASW). These websites typically contain hundreds of thousands of ads including those posted by independent escorts, massage parlor agencies and spammers (fake ads). Detecting suspicious activity in these ads is difficult and developing data-driven methods is challenging due to the hard-to-label, complex and sensitive nature of the data. \n\nIn this paper, we propose T-Net, which unlike previous solutions, formulates this problem as weakly supervised classification. Since it takes several months to years to investigate a case and obtain a single definitive label, we design domain-specific signals or indicators that provide weak labels. T-Net also looks into connections between ads and models the problem as a graph learning task instead of classifying ads independently. We show that T-Net outperforms all baselines on a real-world dataset of ads by 7% average weighted F1 score. Given that this data contains personally identifiable information, we also present a realistic data generator and provide the first publicly available dataset in this domain which may be leveraged by the wider research community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48761500",
                    "name": "Pratheeksha Nair"
                },
                {
                    "authorId": "2273909422",
                    "name": "Javin Liu"
                },
                {
                    "authorId": "46260548",
                    "name": "Catalina Vajiac"
                },
                {
                    "authorId": "3254065",
                    "name": "Andreas M. Olligschlaeger"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2115254512",
                    "name": "Cara Jones"
                },
                {
                    "authorId": "2256724188",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "bcb40efaf8296033fc9a45e80f556226cf6b6a11",
            "title": "GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning",
            "abstract": "We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a general method to inject a priori knowledge into Self-Supervised Learning (SSL) positive samples selection. Current SSL methods leverage Data-Augmentations (DA) for generating positive samples and incorporate prior knowledge - an incorrect, or too weak DA will drastically reduce the quality of the learned representation. GPS-SSL proposes instead to design a metric space where Euclidean distances become a meaningful proxy for semantic relationship. In that space, it is now possible to generate positive samples from nearest neighbor sampling. Any prior knowledge can now be embedded into that metric space independently from the employed DA. From its simplicity, GPS-SSL is applicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is in reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches 85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We therefore move a step forward towards the goal of making SSL less reliant on DA. We also show that even when using strong DAs, GPS-SSL outperforms the baselines on under-studied domains. We evaluate GPS-SSL along with multiple baseline SSL methods on numerous downstream datasets from different domains when the models use strong or minimal data augmentations. We hope that GPS-SSL will open new avenues in studying how to inject a priori knowledge into SSL in a principled manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1962954677",
                    "name": "Aarash Feizi"
                },
                {
                    "authorId": "2316890879",
                    "name": "Randall Balestriero"
                },
                {
                    "authorId": "1456285042",
                    "name": "Adriana Romero-Soriano"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "c71ff780f75298cab2155538ff70863baeb8cfee",
            "title": "Comparing GPT-4 and Open-Source Language Models in Misinformation Mitigation",
            "abstract": "Recent large language models (LLMs) have been shown to be effective for misinformation detection. However, the choice of LLMs for experiments varies widely, leading to uncertain conclusions. In particular, GPT-4 is known to be strong in this domain, but it is closed source, potentially expensive, and can show instability between different versions. Meanwhile, alternative LLMs have given mixed results. In this work, we show that Zephyr-7b presents a consistently viable alternative, overcoming key limitations of commonly used approaches like Llama-2 and GPT-3.5. This provides the research community with a solid open-source option and shows open-source models are gradually catching up on this task. We then highlight how GPT-3.5 exhibits unstable performance, such that this very widely used model could provide misleading results in misinformation detection. Finally, we validate new tools including approaches to structured output and the latest version of GPT-4 (Turbo), showing they do not compromise performance, thus unlocking them for future research and potentially enabling more complex pipelines for misinformation mitigation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279544553",
                    "name": "Tyler Vergho"
                },
                {
                    "authorId": "2028704969",
                    "name": "J. Godbout"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                },
                {
                    "authorId": "104333826",
                    "name": "Kellin Pelrine"
                }
            ]
        },
        {
            "paperId": "d08c5be592e8b5696a703d19c3753b27c418d6db",
            "title": "Temporal Graph Analysis with TGX",
            "abstract": "Real-world networks, with their evolving relations, are best captured as temporal graphs. However, existing software libraries are largely designed for static graphs where the dynamic nature of temporal graphs is ignored. Bridging this gap, we introduce TGX, a Python package specially designed for analysis of temporal networks that encompasses an automated pipeline for data loading, data processing, and analysis of evolving graphs. TGX provides access to eleven built-in datasets and eight external Temporal Graph Benchmark (TGB) datasets as well as any novel datasets in the .csv format. Beyond data loading, TGX facilitates data processing functionalities such as discretization of temporal graphs and node sub-sampling to accelerate working with larger datasets. For comprehensive investigation, TGX offers network analysis by providing a diverse set of measures, including average node degree and the evolving number of nodes and edges per timestamp. Additionally, the package consolidates meaningful visualization plots indicating the evolution of temporal patterns, such as Temporal Edge Appearance (TEA) and Temporal Edge Traffic (TET) plots. The TGX package is a robust tool for examining the features of temporal graphs and can be used in various areas like studying social networks, citation networks, and tracking user interactions. We plan to continuously support and update TGX based on community feedback. TGX is publicly available on: https://github.com/ComplexData-MILA/TGX.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282976555",
                    "name": "Razieh Shirzadkhani"
                },
                {
                    "authorId": "51012317",
                    "name": "Shenyang Huang"
                },
                {
                    "authorId": "2282971574",
                    "name": "Elahe Kooshafar"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                },
                {
                    "authorId": "2282960184",
                    "name": "Farimah Poursafaei"
                }
            ]
        },
        {
            "paperId": "d6a7d49e7df3a9ca4d83b056636a20a3301b3474",
            "title": "Game On, Hate Off: A Study of Toxicity in Online Multiplayer Environments",
            "abstract": "The advent of online spaces, particularly social media platforms and video games, has brought forth a significant challenge: the detection and mitigation of toxic and harmful speech. This issue is not only pervasive but also detrimental to the overall user experience. In this study, we leverage small language models to reliably detect toxicity, achieving an average precision of 0.95. Analyzing eight months of chat data from two Ubisoft games, we uncover patterns and trends in toxic behavior. The insights derived from our research will contribute to the development of healthier online communities and inform preventive measures against toxicity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155115994",
                    "name": "Zachary Yang"
                },
                {
                    "authorId": "2103532252",
                    "name": "Nicolas Grenon-Godbout"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "0bb0ae024a30bbf67cfbff3775937136828f6c83",
            "title": "ToxBuster: In-game Chat Toxicity Buster with BERT",
            "abstract": "Detecting toxicity in online spaces is challenging and an ever more pressing problem given the increase in social media and gaming consumption. We introduce ToxBuster, a simple and scalable model trained on a relatively large dataset of 194k lines of game chat from Rainbow Six Siege and For Honor, carefully annotated for different kinds of toxicity. Compared to the existing state-of-the-art, ToxBuster achieves 82.95% (+7) in precision and 83.56% (+57) in recall. This improvement is obtained by leveraging past chat history and metadata. We also study the implication towards real-time and post-game moderation as well as the model transferability from one game to another.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155115994",
                    "name": "Zachary Yang"
                },
                {
                    "authorId": "2218035628",
                    "name": "Yasmine Maricar"
                },
                {
                    "authorId": "114508047",
                    "name": "M. Davari"
                },
                {
                    "authorId": "2103532252",
                    "name": "Nicolas Grenon-Godbout"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "3af09b9c1dcc3c0177cc46c274be27596b3ab168",
            "title": "Open, Closed, or Small Language Models for Text Classification?",
            "abstract": "Recent advancements in large language models have demonstrated remarkable capabilities across various NLP tasks. But many questions remain, including whether open-source models match closed ones, why these models excel or struggle with certain tasks, and what types of practical procedures can improve performance. We address these questions in the context of classification by evaluating three classes of models using eight datasets across three distinct tasks: named entity recognition, political party prediction, and misinformation detection. While larger LLMs often lead to improved performance, open-source models can rival their closed-source counterparts by fine-tuning. Moreover, supervised smaller models, like RoBERTa, can achieve similar or even greater performance in many datasets compared to generative LLMs. On the other hand, closed models maintain an advantage in hard tasks that demand the most generalizability. This study underscores the importance of model selection based on task requirements",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110750027",
                    "name": "Hao Yu"
                },
                {
                    "authorId": "2155115994",
                    "name": "Zachary Yang"
                },
                {
                    "authorId": "104333826",
                    "name": "Kellin Pelrine"
                },
                {
                    "authorId": "2028704969",
                    "name": "J. Godbout"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "47e4263afab38a0f0fd00a82e1a84db80590aa31",
            "title": "DeltaShield: Information Theory for Human- Trafficking Detection",
            "abstract": "Given a million escort advertisements, how can we spot near-duplicates? Such micro-clusters of ads are usually signals of human trafficking (HT). How can we summarize them to convince law enforcement to act? Spotting micro-clusters of near-duplicate documents is useful in multiple, additional settings, including spam-bot detection in Twitter ads, plagiarism, and more. We present InfoShield, which makes the following contributions: practical, being scalable and effective on real data; parameter-free and principled, requiring no user-defined parameters; interpretable, finding a document to be the cluster representative, highlighting all the common phrases, and automatically detecting \u201cslots\u201d (i.e., phrases that differ in every document); and generalizable, beating or matching domain-specific methods in Twitter bot detection and HT detection, respectively, as well as being language independent. Interpretability is particularly important for the anti-HT domain, where law enforcement must visually inspect ads. Our experiments on real data show that InfoShield correctly identifies Twitter bots with an F1 score over 90% and detects HT ads with 84% precision. Moreover, it is scalable, requiring about 8 hours for 4 million documents on a stock laptop. Our incremental version, DeltaShield, allows for fast, incremental updates, with minor loss of accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46260548",
                    "name": "Catalina Vajiac"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "136887490",
                    "name": "Aayushi Kulshrestha"
                },
                {
                    "authorId": "2054885747",
                    "name": "Sacha L\u00e9vy"
                },
                {
                    "authorId": "2867343",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "3254065",
                    "name": "Andreas M. Olligschlaeger"
                },
                {
                    "authorId": "2115254512",
                    "name": "Cara Jones"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                }
            ]
        }
    ]
}