{
    "authorId": "2154487593",
    "papers": [
        {
            "paperId": "09aa092f76375206c8c60c3d4c92a4a2fc770cae",
            "title": "FRAD: Free-Rider Attacks Detection Mechanism for Federated Learning in AIoT",
            "abstract": "The rapid development of the Artificial Intelligence of Things (AIoT) opens up a new perspective for emerging service-based applications and becomes a major driver of diverse federated learning (FL) applications. However, due to the heterogeneity of nodes and the existence of free-rider attacks, some device nodes may launch free-rider attacks to obtain the global model without any contribution, which not only dampens the enthusiasm of legitimate participants but also undermines the fairness of node contributions. In this article, we propose a free-rider attack detection (FRAD) mechanism for FL with deep autoencoding Gaussian mixture model (DAGMM) based on contribution and reputation. Specifically, we first model the contribution values based on the computing resource, communication cost, and data quality of each device node. Then, based on PageRank algorithms, we design an optimal reputation-based model to fairly and precisely choose benign nodes to participate in federated training under information asymmetry. Furthermore, we develop the FRAD mechanism via DAGMM that combines historical contribution with reputation scores. Simulation results validate that the proposed mechanism in this article outperforms the state-of-the-art baselines $(\\sim \\!\\! 2.14\\times $ and $\\sim \\!\\! 1.1\\times $ on MNIST and CIFAR, respectively) in defending against free-rider attacks, and when the main clients are free-riders, i.e., 50% or even up to 80% of the free-riders, FRAD can still maintain a high defense performance against free-rider attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153212971",
                    "name": "Bo Wang"
                },
                {
                    "authorId": "2051535429",
                    "name": "Hongtao Li"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "2218912185",
                    "name": "Yina Guo"
                }
            ]
        },
        {
            "paperId": "0baf406202f977330925166e456ac5e0f0f78d61",
            "title": "Privacy-Preserving Joint Data and Function Homomorphic Encryption for Cloud Software Services",
            "abstract": "With the widespread growth of cloud computing technology, cloud software services are ubiquitous these days. Using this technology, software providers can sell their products through cloud computing environments in the pay-as-you-use fashion. However, performing secure and accurate calculations in cloud computing environments has become extremely challenging. As the data to be processed by cloud software might be highly sensitive, its confidentiality needs to be taken care of before transferring the data to the cloud server. Also, in addition to the data confidentiality, the security of algorithms employed in the software is of vital importance, and thus software owners may be worried about revealing their algorithms through the cloud server. Homomorphic cryptosystems can provide confidentiality for data to be processed online. However, the confidentiality of algorithms is still an open problem. To address this issue, we put forward a privacy-preserving joint data and function homomorphic encryption (JDF-HE) mechanism. Our JDF-HE can provide confidentiality for both algorithms and data, thereby being suitable for cloud software services. We prove the security of JDF-HE and analyze its performance by evaluating its actual execution overhead. Our performance and security analysis demonstrate that JDF-HE is secure and suitable for real-time applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2221567569",
                    "name": "Amin Hosseingholizadeh"
                },
                {
                    "authorId": "3092672",
                    "name": "F. Rahmati"
                },
                {
                    "authorId": "3181959",
                    "name": "M. Ali"
                },
                {
                    "authorId": "102630632",
                    "name": "Hamid Damadi"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                }
            ]
        },
        {
            "paperId": "0cf205d9186de916c0b080a4e1e4d89d7cdaaa4b",
            "title": "Federated and Online Dynamic Spectrum Access for Mobile Secondary Users",
            "abstract": "Users in dynamic spectrum access (DSA) with federated reinforcement learning (FRL) autonomously access channels, avoiding centralized coordination and protecting users\u2019 privacy. However, existing FRL-based DSA mechanisms are limited to ideal network states, i.e., assuming that channel states and users\u2019 interference relationships are unchanged. Besides, users should upload intermediate results simultaneously for federated aggregation. The above conditions are impractical for mobile users since their network states and locations are unstable. Meanwhile, newly connected users have to train their models through local data with numerous computing resources since global models are unsuitable for them. We propose FRDSA, an FRL-based secure and lightweight channel selection mechanism in DSA for mobile users under dynamic network states. An independent channel selection environment with a virtual group strategy is presented to avoid interference between users under unstable channel states. Furthermore, an asynchronous parameter aggregation method in FRDSA dynamically adjusts the aggregation factors without users simultaneously uploading intermediate results. Simulations based on real trajectory data show that FRDSA significantly reduces approximately 60% interference between mobile users under unstable network states. Newly connected users can directly apply the well-trained global model to access channels autonomously instead of retraining a model, effectively reducing mobile users\u2019 computing resource requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2391551",
                    "name": "Xuewen Dong"
                },
                {
                    "authorId": "2062516108",
                    "name": "Zhichao You"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "1795475",
                    "name": "Yuanxiong Guo"
                },
                {
                    "authorId": "2152571532",
                    "name": "Yulong Shen"
                },
                {
                    "authorId": "144010840",
                    "name": "Yanmin Gong"
                }
            ]
        },
        {
            "paperId": "15ab2cd79d5e695a3c234b645599aa14d75f50c4",
            "title": "POTA: Privacy-Preserving Online Multi-Task Assignment With Path Planning",
            "abstract": "Privacy-preserving online multi-task assignment is a crucial aspect of spatial crowdsensing on untrusted platforms, where multiple real-time tasks are allocated to appropriate workers in a privacy-preserving manner. While existing schemes ensure the privacy of tasks and users, they seldom focus on minimizing the total moving distances for crowdsensing workers when assigning multiple tasks in real time, which adversely impacts the efficiency of online multi-task assignments. To address this issue, we propose POTA, the first privacy-preserving online multi-task assignment scheme with path planning that minimizes the total moving distances for crowdsensing workers without additional noise. POTA cryptographically implements the extended minimum-cost flow model, which models the encrypted data of workers and tasks in a graph and later produces optimized routing. With such a secure path-planning component, POTA reduces the total moving distances by <inline-formula><tex-math notation=\"LaTeX\">$25.19\\%-52.78\\%$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>25</mml:mn><mml:mo>.</mml:mo><mml:mn>19</mml:mn><mml:mo>%</mml:mo><mml:mo>-</mml:mo><mml:mn>52</mml:mn><mml:mo>.</mml:mo><mml:mn>78</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=\"liang-ieq1-3315324.gif\"/></alternatives></inline-formula> in the tested dataset compared with the state-of-the-art schemes with obfuscated path planning. Security analysis proves that POTA guarantees the confidentiality of sensitive data, a stronger security property than introducing obfuscation to sensitive data. Experimental evaluations on real-world datasets demonstrate the feasibility of POTA in terms of running time and its ability to achieve minimized total moving distances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153884755",
                    "name": "Chuan Zhang"
                },
                {
                    "authorId": "2187165009",
                    "name": "Xingqi Luo"
                },
                {
                    "authorId": "2225107718",
                    "name": "Jinwen Liang"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "1692039",
                    "name": "Liehuang Zhu"
                },
                {
                    "authorId": "2238439475",
                    "name": "Song Guo"
                }
            ]
        },
        {
            "paperId": "167e15ee09074a48faa32495da08e5e0b2eb27ee",
            "title": "Privacy-Preserving Multi-Label Propagation Based on Federated Learning",
            "abstract": "Multi-label propagation algorithms (MLPAs) aim to find vertex communities in a complex network or a cloud system by propagating and updating vertex labels, which have been widely applied in customer recommendation, protein molecule discovery, and criminal tracking. As more and more people are concerned about the leakage of their sensitive information, detecting communities without disclosing personal privacy has become a hot topic in complex network analysis. The existing anonymization-based community detection methods have to modify the network structure to protect the sensitive vertices or links, which complicates the recognition of true communities and incurs substantial accuracy loss. In this article, we first propose a federated graph learning model (FGLM) for distributed privacy-preserving network data mining. Second, a federated MLPA for distributed and attributed networks is implemented by adapting a standalone MLPA to FGLM to verify the model's effectiveness. We develop a label perturbation strategy to conceal vertex degrees in distributed label updating and employ a homomorphic encryption system to protect label weights exchanged between the participants. The experiments on real-world and synthetic datasets demonstrate that the new algorithm achieves zero accuracy loss and more than 200% higher accuracy than the simple distributed MLPA without federated learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2061501877",
                    "name": "Kun Guo"
                },
                {
                    "authorId": "2237319538",
                    "name": "Dangrun Chen"
                },
                {
                    "authorId": "2236987301",
                    "name": "Qingqing Huang"
                },
                {
                    "authorId": "2237067819",
                    "name": "Fuan Li"
                },
                {
                    "authorId": "2237084780",
                    "name": "Chen Guo"
                },
                {
                    "authorId": "2237080945",
                    "name": "Duanji Wu"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "2157740888",
                    "name": "Kai Chen"
                }
            ]
        },
        {
            "paperId": "2eb96b1c7de32ca25d91278c7c019574fdbbbd8b",
            "title": "Lightweight Privacy-Preserving Feature Extraction for EEG Signals Under Edge Computing",
            "abstract": "The health-related Internet of Things (IoT) plays an irreplaceable role in the collection, analysis, and transmission of medical data. As a device of the health-related IoT, the electroencephalogram (EEG) has long been a powerful tool for physiological and clinical brain research, which contains a wealth of personal information. Due to its rich computational/storage resources, cloud computing is a promising solution to extract the sophisticated feature of massive EEG signals in the age of big data. However, it needs to solve both response latency and privacy leakage. To reduce latency between users and servers while ensuring data privacy, we propose a privacy-preserving feature extraction scheme, called LightPyFE, for EEG signals in the edge computing environment. In this scheme, we design an outsourced computing toolkit, which allows the users to achieve a series of secure integer and floating-point computing operations. During the implementation, LightPyFE can ensure that the users just perform the encryption and decryption operations, where all computing tasks are outsourced to edge servers for specific processing. Theoretical analysis and experimental results have demonstrated that our scheme can successfully achieve privacy-preserving feature extraction for EEG signals, and is practical yet effective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151205957",
                    "name": "Nazhao Yan"
                },
                {
                    "authorId": "2149241553",
                    "name": "Hang Cheng"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "2156361853",
                    "name": "Fei Chen"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                }
            ]
        },
        {
            "paperId": "3087288e3103b35c13e5c6b8c4e64110a6e85797",
            "title": "A Blockchain-Based Anonymous Attribute-Based Searchable Encryption Scheme for Data Sharing",
            "abstract": "Attribute-based searchable encryption (ABSE) is a promising encryption mechanism for sharing outsourced encrypted data in clouds, allowing fine-grained access control over data while searching for encrypted data. However, the access policy in the most existing ABSE schemes exists in plaintext, which could expose sensitive information about legitimate data users. Moreover, such schemes delegate complex search operations to a cloud server, which can lead to data tampering and even untrusted results, and single point of failure. In this article, we propose a blockchain (BC)-based anonymous ABSE scheme for data sharing (BADS). First, attributes of the access policy are hidden, thus, providing confidentiality to the set of attributes that satisfy the access policy. Then combining ABSE with BC have features of tamper-proof, integrity verification, and nonrepudiation. In particular, information, such as secure index is stored in BC, while encrypted data is stored in a distributed system called the interplanetary file system (IPFS) to avoid single point of failure. Finally, BADS supports the matching algorithm that perform a fixed number of pairing operations before searching algorithm. We analysis security and evaluate performance to show the efficiency and practicability of BADS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152981255",
                    "name": "Kai Zhang"
                },
                {
                    "authorId": "36124320",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2111183245",
                    "name": "Yanping Li"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "9440160",
                    "name": "Laifeng Lu"
                }
            ]
        },
        {
            "paperId": "4771fd8f52cd038707a3c5d51c9c4e4a7ad59970",
            "title": "FlGan: GAN-Based Unbiased Federated Learning Under Non-IID Settings",
            "abstract": "Federated Learning (FL) suffers from low convergence and significant accuracy loss due to local biases caused by non-Independent and Identically Distributed (non-IID) data. To enhance the non-IID FL performance, a straightforward idea is to leverage the Generative Adversarial Network (GAN) to mitigate local biases using synthesized samples. Unfortunately, existing GAN-based solutions have inherent limitations, which do not support non-IID data and even compromise user privacy. To tackle the above issues, we propose a GAN-based unbiased FL scheme, called <sc>FlGan</sc>, to mitigate local biases using synthesized samples generated by GAN while preserving user-level privacy in the FL setting. Specifically, <sc>FlGan</sc> first presents a federated GAN algorithm using the divide-and-conquer strategy that eliminates the problem of model collapse in non-IID settings. To guarantee user-level privacy, <sc>FlGan</sc> then exploits Fully Homomorphic Encryption (FHE) to design the privacy-preserving GAN augmentation method for the unbiased FL. Extensive experiments show that <sc>FlGan</sc> achieves unbiased FL with <inline-formula><tex-math notation=\"LaTeX\">$10\\%-60\\%$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>10</mml:mn><mml:mo>%</mml:mo><mml:mo>-</mml:mo><mml:mn>60</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=\"ma-ieq1-3309858.gif\"/></alternatives></inline-formula> accuracy improvement compared with two state-of-the-art FL baselines (i.e., FedAvg and FedSGD) trained under different non-IID settings. The FHE-based privacy guarantees only cost about 0.53% of the total overhead in <sc>FlGan</sc>.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144477107",
                    "name": "Zhuo Ma"
                },
                {
                    "authorId": "40457423",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "143869661",
                    "name": "Yinbin Miao"
                },
                {
                    "authorId": "145249315",
                    "name": "Guowen Xu"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "2157314030",
                    "name": "Jianfeng Ma"
                },
                {
                    "authorId": "2130557534",
                    "name": "R. Deng"
                }
            ]
        },
        {
            "paperId": "8a4e24ce145e7e985a6d354762ae63f727c8230e",
            "title": "VeriRange: A Verifiable Range Query Model on Encrypted Geographic Data for IoT Environment",
            "abstract": "In the era of the Internet of Things (IoT), the rapid development of cloud computing has been advancing location-based services (LBSs). To enjoy the considerable advantages of lower cost and higher performance of cloud computing, it has become the first choice for most IoT enterprises to outsource data and services to public clouds. However, the privacy protection of data and the integrity of query results cannot be effectively guaranteed since public clouds cannot be fully trusted. In this article, we propose a lightweight verifiable range query scheme (namely, VeriRange). First, a pair of mutually perpendicular locality-sensitive hashing (LSH) is adopted to divide the original geographic data into subsets. Then, a pivoted $k$ dimensional (PKD) tree and a height-balanced binomial search tree (i.e., AVL tree) are established on the client and the cloud, respectively, to accelerate the processes of queries. To ensure the verification of query results, a keyed hash function is utilized to generate a verification tag for each subset. Verification tags in the public cloud are encrypted and independent of queries. It ensures fast verification of query results because the verification tags are not repeatedly calculated on each query. Formal security analysis shows VeriRange ensures the privacy of data, queries, and results. Experimental studies were conducted on real and synthetic data sets and demonstrated that the query and verification time in VeriRange is almost 2\u20133 orders of magnitude faster than that in state-of-art schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111664797",
                    "name": "Wenjie Ma"
                },
                {
                    "authorId": "7541720",
                    "name": "Yanguo Peng"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "2194464106",
                    "name": "Jiangtao Cui"
                }
            ]
        },
        {
            "paperId": "ad5f103de8e7e3cd622f87d3c99e6123915e6d57",
            "title": "DeepDIST: A Black-Box Anti-Collusion Framework for Secure Distribution of Deep Models",
            "abstract": "Due to enormous computing and storage overhead for well-trained Deep Neural Network (DNN) models, protecting the intellectual property of model owners is a pressing need. As the commercialization of deep models is becoming increasingly popular, the pre-trained models delivered to users may suffer from being illegally copied, redistributed, or abused. In this paper, we propose DeepDIST, the first end-to-end secure DNNs distribution framework in a black-box scenario. Specifically, our framework adopts a dual-level fingerprint (FP) mechanism to provide reliable ownership verification, and proposes two equivalent transformations that can resist collusion attacks, plus a newly designed similarity loss term to improve the security of the transformations. Unlike the existing passive defense schemes that detect colluding participants, we introduce an active defense strategy, namely damaging the performance of the model after the malicious collusion. The extensive experimental results show that DeepDIST can maintain the accuracy of the host DNN after embedding fingerprint conducted for true traitor tracing, and is robust against several popular model modifications. Furthermore, the anti-collusion effect is evaluated on two typical classification tasks (10-class and 100-class), and the proposed DeepDIST can drop the prediction accuracy of the collusion model to 10% and 1% (random guess), respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145928133",
                    "name": "Hang Cheng"
                },
                {
                    "authorId": "2144393294",
                    "name": "Xibin Li"
                },
                {
                    "authorId": "1576102218",
                    "name": "Huaxiong Wang"
                },
                {
                    "authorId": "152899522",
                    "name": "Xinpeng Zhang"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "1698973",
                    "name": "Fengyong Li"
                }
            ]
        }
    ]
}