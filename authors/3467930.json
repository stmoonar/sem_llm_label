{
    "authorId": "3467930",
    "papers": [
        {
            "paperId": "8ae240c8226f7f48060adcd0c8bff8517e939cec",
            "title": "Biologically-Informed Shallow Classification Learning Integrating Pathway Knowledge",
            "abstract": ": We propose a biologically-informed shallow neural network as an alternative to the common knowledge-integrating deep neural network architecture used in bio-medical classification learning. In particular, we focus on the Generalized Matrix Learning Vector Quantization (GMLVQ) model as a robust and interpretable shallow neural classifier based on class-dependent prototype learning and accompanying matrix adaptation for suitable data mapping. To incorporate the biological knowledge, we adjust the matrix structure in GMLVQ according to the pathway knowledge for the given problem. During model training both the mapping matrix and the class prototypes are optimized. Since GMLVQ is fully interpretable by design, the interpretation of the model is straightforward, taking explicit account of pathway knowledge. Furthermore, the robustness of the model is guaranteed by the implicit separation margin optimization realized by means of the stochastic gradient descent learning. We demonstrate the performance and the interpretability of the shallow network by reconsideration of a cancer research dataset, which was already investigated using a biologically-informed deep neural network.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185297399",
                    "name": "Julius Voigt"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "1790916",
                    "name": "M. Kaden"
                },
                {
                    "authorId": "1708193217",
                    "name": "Katrin Sophie Bohnsack"
                },
                {
                    "authorId": "2287250514",
                    "name": "Lynn V. Reuss"
                },
                {
                    "authorId": "2285996540",
                    "name": "Thomas Villmann"
                }
            ]
        },
        {
            "paperId": "1d5a3c90e9a1d6309ef6b59296fb650826542219",
            "title": "Robust Text Classification: Analyzing Prototype-Based Networks",
            "abstract": "Downstream applications often require text classification models to be accurate and robust. While the accuracy of the state-of-the-art Language Models (LMs) approximates human performance, they often exhibit a drop in performance on noisy data found in the real world. This lack of robustness can be concerning, as even small perturbations in the text, irrelevant to the target task, can cause classifiers to incorrectly change their predictions. A potential solution can be the family of Prototype-Based Networks (PBNs) that classifies examples based on their similarity to prototypical examples of a class (prototypes) and has been shown to be robust to noise for computer vision tasks. In this paper, we study whether the robustness properties of PBNs transfer to text classification tasks under both targeted and static adversarial attack settings. Our results show that PBNs, as a mere architectural variation of vanilla LMs, offer more robustness compared to vanilla LMs under both targeted and static settings. We showcase how PBNs' interpretability can help us to understand PBNs' robustness properties. Finally, our ablation studies reveal the sensitivity of PBNs' robustness to how strictly clustering is done in the training phase, as tighter clustering results in less robust PBNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2069729843",
                    "name": "D. Deshpande"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "24868638",
                    "name": "Kiril Gashteovski"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                }
            ]
        },
        {
            "paperId": "55f44d9024463486955151c4e75b520cf56b7697",
            "title": "A Human-Centric Assessment Framework for AI",
            "abstract": "With the rise of AI systems in real-world applications comes the need for reliable and trustworthy AI. An essential aspect of this are explainable AI systems. However, there is no agreed standard on how explainable AI systems should be assessed. Inspired by the Turing test, we introduce a human-centric assessment framework where a leading domain expert accepts or rejects the solutions of an AI system and another domain expert. By comparing the acceptance rates of provided solutions, we can assess how the AI system performs compared to the domain expert, and whether the AI system's explanations (if provided) are human-understandable. This setup -- comparable to the Turing test -- can serve as a framework for a wide range of human-centric AI system assessments. We demonstrate this by presenting two instantiations: (1) an assessment that measures the classification accuracy of a system with the option to incorporate label uncertainties; (2) an assessment where the usefulness of provided explanations is determined in a human-centric manner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "40515722",
                    "name": "Ammar Shaker"
                },
                {
                    "authorId": "2166335112",
                    "name": "Zhao Xu"
                },
                {
                    "authorId": "24868638",
                    "name": "Kiril Gashteovski"
                },
                {
                    "authorId": "2105201",
                    "name": "Bhushan Kotnis"
                },
                {
                    "authorId": "2166312218",
                    "name": "Wiem Ben-Rim"
                },
                {
                    "authorId": "152845986",
                    "name": "J\u00fcrgen Quittek"
                },
                {
                    "authorId": "19752252",
                    "name": "Carolin (Haas) Lawrence"
                }
            ]
        },
        {
            "paperId": "cfeeeefd9b5e7b1619ecbd9ef2d99f1e4e45d1c5",
            "title": "Combining Visual Saliency Methods and Sparse Keypoint Annotations to Providently Detect Vehicles at Night",
            "abstract": "Provident detection of other road users at night has the potential for increasing road safety. For this purpose, humans intuitively use visual cues, such as light cones and light reflections emitted by other road users to be able to react to oncoming traffic at an early stage. This behavior can be imitated by computer vision methods by predicting the appearance of vehicles based on emitted light reflections caused by the vehicle's headlights. Since current object detection algorithms are mainly based on detecting directly visible objects annotated via bounding boxes, the detection and annotation of light reflections without sharp boundaries is challenging. For this reason, the extensive open-source dataset PVDN (Provident Vehicle Detection at Night) was published, which includes traffic scenarios at night with light reflections annotated via keypoints. In this paper, we explore the potential of saliency-based approaches to create different object representations based on the visual saliency and sparse keypoint annotations of the PVDN dataset. For that, we extend the general idea of Boolean map saliency towards a context-aware approach by taking into consideration sparse keypoint annotations by humans. We show that this approach allows for an automated derivation of different object representations, such as binary maps or bounding boxes so that detection models can be trained on different annotation variants and the problem of providently detecting vehicles at night can be tackled from different perspectives. With that, we provide further powerful tools and methods to study the problem of detecting vehicles at night before they are actually visible.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2043236898",
                    "name": "Lukas Ewecker"
                },
                {
                    "authorId": "119118615",
                    "name": "Lars Ohnemus"
                },
                {
                    "authorId": "2163449553",
                    "name": "Robin Schwager"
                },
                {
                    "authorId": "2057050865",
                    "name": "Stefan Roos"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                }
            ]
        },
        {
            "paperId": "1161f4bf5ba34b3800ae9f7f4bc9da2f85168036",
            "title": "A Dataset for Provident Vehicle Detection at Night",
            "abstract": "In current object detection, algorithms require the object to be directly visible in order to be detected. As humans, however, we intuitively use visual cues caused by the respective object to already make assumptions about its appearance. In the context of driving, such cues can be shadows during the day and often light reflections at night. In this paper, we study the problem of how to map this intuitive human behavior to computer vision algorithms to detect oncoming vehicles at night just from the light reflections they cause by their headlights. For that, we present an extensive open-source dataset containing 59 746 annotated grayscale images out of 346 different scenes in a rural environment at night. In these images, all oncoming vehicles, their corresponding light objects (e. g., headlamps), and their respective light reflections (e. g., light reflections on guardrails) are labeled. In this context, we discuss the characteristics of the dataset and the challenges in objectively describing visual cues such as light reflections. We provide different metrics for different ways to approach the task and report the results we achieved using state-of-the-art and custom object detection models as a first benchmark. With that, we want to bring attention to a new and so far neglected field in computer vision research, encourage more researchers to tackle the problem, and thereby further close the gap between human performance and computer vision systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "119118615",
                    "name": "Lars Ohnemus"
                },
                {
                    "authorId": "2043236898",
                    "name": "Lukas Ewecker"
                },
                {
                    "authorId": "1395226933",
                    "name": "Ebubekir Asan"
                },
                {
                    "authorId": "2030993452",
                    "name": "Simon T. Isele"
                },
                {
                    "authorId": "2057050865",
                    "name": "Stefan Roos"
                }
            ]
        },
        {
            "paperId": "29eb3129dcfd34b0c5eddf9c097b2eba9c561c09",
            "title": "The Coming of Age of Interpretable and Explainable Machine Learning Models",
            "abstract": ". Machine learning-based systems are now part of a wide array of real-world applications seamlessly embedded in the social realm. In the wake of this realisation, strict legal regulations for these systems are currently being developed, addressing some of the risks they may pose. This is the coming of age of the interpretability and explainability problems in machine learning-based data analysis, which can no longer be seen just as an academic research problem. In this tutorial, associated to ESANN 2021 special session on \u201cInterpretable Models in Machine Learning and Ex-plainable Arti\ufb01cial Intelligence\u201d, we discuss explainable and interpretable machine learning as post-hoc and ante-hoc strategies to address these problems and highlight several aspects related to them, including their assessment. The contributions accepted for the session are then presented in this context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145408620",
                    "name": "P. Lisboa"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "1723612",
                    "name": "A. Vellido"
                },
                {
                    "authorId": "9320960",
                    "name": "T. Villmann"
                }
            ]
        },
        {
            "paperId": "9a9d3696e48981844973504024f9ed2613c780e4",
            "title": "The Resolved Mutual Information Function as a Structural Fingerprint of Biomolecular Sequences for Interpretable Machine Learning Classifiers",
            "abstract": "In the present article we propose the application of variants of the mutual information function as characteristic fingerprints of biomolecular sequences for classification analysis. In particular, we consider the resolved mutual information functions based on Shannon-, R\u00e9nyi-, and Tsallis-entropy. In combination with interpretable machine learning classifier models based on generalized learning vector quantization, a powerful methodology for sequence classification is achieved which allows substantial knowledge extraction in addition to the high classification ability due to the model-inherent robustness. Any potential (slightly) inferior performance of the used classifier is compensated by the additional knowledge provided by interpretable models. This knowledge may assist the user in the analysis and understanding of the used data and considered task. After theoretical justification of the concepts, we demonstrate the approach for various example data sets covering different areas in biomolecular sequence analysis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1708193217",
                    "name": "Katrin Sophie Bohnsack"
                },
                {
                    "authorId": "1790916",
                    "name": "M. Kaden"
                },
                {
                    "authorId": "2064757725",
                    "name": "J. Abel"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "9320960",
                    "name": "T. Villmann"
                }
            ]
        },
        {
            "paperId": "1a224d4e92111b54ea5cebe590c2710e58ef568e",
            "title": "Provident Detection of Vehicles at Night",
            "abstract": "Visual perception is one of the most important information sources during driving. However, current camera perception systems are limited to object detection and, hence, to directly visible objects. Because it is mandatory for vehicles to run headlights at night, their emitted light can be detected before a vehicle is directly visible. Humans use this phenomenon to providently detect vehicles at night. In this paper, we analyze the discrepancy between ordinary vehicle detection and provident detection by quantifying the time gap between the two. This is achieved by conducting a test group study where participants are recorded while driving at night. Additionally, the dataset recorded during the study is used to provide a training and test dataset for machine learning approaches. To make use of the dataset for training machine learning methods, we analyze and discuss several annotation techniques. In a proof-of-concept, we used this dataset with its annotations to train a neural network on the direct and provident vehicle detection task. The resulting model shows that neural networks can successfully learn how to detect light-features. With further research and improvements, we are confident that a model for provident vehicle detection can be industrialized for use in production vehicles so that this information can be used in various safety and planning functions, including automatically adapting the high beam before it blinds other road users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2046872108",
                    "name": "Emilio Oldenziel"
                },
                {
                    "authorId": "119118615",
                    "name": "Lars Ohnemus"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                }
            ]
        },
        {
            "paperId": "7925827f124f5be252bbc508ca94240d9bdb3e4c",
            "title": "Radar Artifact Labeling Framework (RALF): Method for Plausible Radar Detections in Datasets",
            "abstract": "Research on localization and perception for Autonomous Driving is mainly focused on camera and LiDAR datasets, rarely on radar data. Manually labeling sparse radar point clouds is challenging. For a dataset generation, we propose the cross sensor Radar Artifact Labeling Framework (RALF). Automatically generated labels for automotive radar data help to cure radar shortcomings like artifacts for the application of artificial intelligence. RALF provides plausibility labels for radar raw detections, distinguishing between artifacts and targets. The optical evaluation backbone consists of a generalized monocular depth image estimation of surround view cameras plus LiDAR scans. Modern car sensor sets of cameras and LiDAR allow to calibrate image-based relative depth information in overlapping sensing areas. K-Nearest Neighbors matching relates the optical perception point cloud with raw radar detections. In parallel, a temporal tracking evaluation part considers the radar detections' transient behavior. Based on the distance between matches, respecting both sensor and model uncertainties, we propose a plausibility rating of every radar detection. We validate the results by evaluating error metrics on semi-manually labeled ground truth dataset of $3.28\\cdot10^6$ points. Besides generating plausible radar detections, the framework enables further labeled low-level radar signal datasets for applications of perception and Autonomous Driving learning tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2030993452",
                    "name": "Simon T. Isele"
                },
                {
                    "authorId": "28197157",
                    "name": "M. Schilling"
                },
                {
                    "authorId": "2057608283",
                    "name": "Fabian E. Klein"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "1797014",
                    "name": "Johann Marius Z\u00f6llner"
                }
            ]
        },
        {
            "paperId": "c7397026747866cdf80fe59be737c56061f1e24c",
            "title": "Fast Adversarial Robustness Certification of Nearest Prototype Classifiers for Arbitrary Seminorms",
            "abstract": "Methods for adversarial robustness certi\ufb01cation aim to provide an upper bound on the test error of a classi\ufb01er under adversarial manipulation of its input. Current certi\ufb01cation methods are computationally expensive and limited to attacks that optimize the manipulation with respect to a norm. We overcome these limitations by investigating the robustness properties of Nearest Prototype Classi\ufb01ers (NPCs) like learning vector quantization and large margin nearest neighbor. For this purpose, we study the hypothesis margin. We prove that if NPCs use a dissimilarity measure induced by a seminorm, the hypothesis margin is a tight lower bound on the size of adversarial attacks and can be calculated in constant time\u2014this provides the \ufb01rst adversarial robustness certi\ufb01cate calculable in reasonable time. Finally, we show that each NPC trained by a triplet loss maximizes the hypothesis margin and is therefore optimized for adversarial robustness. In the presented evaluation, we demonstrate that NPCs optimized for adversarial robustness are competitive with state-of-the-art methods and set a new benchmark with respect to computational complexity for robustness certi\ufb01cation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                },
                {
                    "authorId": "52221725",
                    "name": "Lars Holdijk"
                },
                {
                    "authorId": "9320960",
                    "name": "T. Villmann"
                }
            ]
        }
    ]
}