{
    "authorId": "2276202987",
    "papers": [
        {
            "paperId": "2e55732bf8fa0a11cf24c9b58b25347c31557964",
            "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
            "abstract": "Do LLMs align with human perceptions of safety? We study this question via annotation alignment, the extent to which LLMs and humans agree when annotating the safety of user-chatbot conversations. We leverage the recent DICES dataset (Aroyo et al., 2023), in which 350 conversations are each rated for safety by 112 annotators spanning 10 race-gender groups. GPT-4 achieves a Pearson correlation of $r = 0.59$ with the average annotator rating, \\textit{higher} than the median annotator's correlation with the average ($r=0.51$). We show that larger datasets are needed to resolve whether LLMs exhibit disparities in how well they correlate with different demographic groups. Also, there is substantial idiosyncratic variation in correlation within groups, suggesting that race&gender do not fully capture differences in alignment. Finally, we find that GPT-4 cannot predict when one demographic group finds a conversation more unsafe than another.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405369173",
                    "name": "Rajiv Movva"
                },
                {
                    "authorId": "2276205042",
                    "name": "Pang Wei Koh"
                },
                {
                    "authorId": "2276202987",
                    "name": "Emma Pierson"
                }
            ]
        },
        {
            "paperId": "5c7752de11cb2cb9671a6f32edb046b1e0c9b7fc",
            "title": "MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning",
            "abstract": "In high-stakes domains like clinical reasoning, AI assistants powered by large language models (LLMs) are yet to be reliable and safe. We identify a key obstacle towards reliability: existing LLMs are trained to answer any question, even with incomplete context in the prompt or insufficient parametric knowledge. We propose to change this paradigm to develop more careful LLMs that ask follow-up questions to gather necessary and sufficient information and respond reliably. We introduce MEDIQ, a framework to simulate realistic clinical interactions, which incorporates a Patient System and an adaptive Expert System. The Patient may provide incomplete information in the beginning; the Expert refrains from making diagnostic decisions when unconfident, and instead elicits missing details from the Patient via follow-up questions. To evaluate MEDIQ, we convert MEDQA and CRAFT-MD -- medical benchmarks for diagnostic question answering -- into an interactive setup. We develop a reliable Patient system and prototype several Expert systems, first showing that directly prompting state-of-the-art LLMs to ask questions degrades the quality of clinical reasoning, indicating that adapting LLMs to interactive information-seeking settings is nontrivial. We then augment the Expert with a novel abstention module to better estimate model confidence and decide whether to ask more questions, thereby improving diagnostic accuracy by 20.3%; however, performance still lags compared to an (unrealistic in practice) upper bound when full information is given upfront. Further analyses reveal that interactive performance can be improved by filtering irrelevant contexts and reformatting conversations. Overall, our paper introduces a novel problem towards LLM reliability, a novel MEDIQ framework, and highlights important future directions to extend the information-seeking abilities of LLM assistants in critical domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2295954288",
                    "name": "Shuyue Stella Li"
                },
                {
                    "authorId": "143820870",
                    "name": "Vidhisha Balachandran"
                },
                {
                    "authorId": "2284701198",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2304468718",
                    "name": "Jonathan Ilgen"
                },
                {
                    "authorId": "2276202987",
                    "name": "Emma Pierson"
                },
                {
                    "authorId": "2276205042",
                    "name": "Pang Wei Koh"
                },
                {
                    "authorId": "2249583325",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "6be999792a1473be6b83a51a5c98ca4e7b9f8d44",
            "title": "Recent Advances, Applications, and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2023 Symposium",
            "abstract": "The third ML4H symposium was held in person on December 10, 2023, in New Orleans, Louisiana, USA. The symposium included research roundtable sessions to foster discussions between participants and senior researchers on timely and relevant topics for the \\ac{ML4H} community. Encouraged by the successful virtual roundtables in the previous year, we organized eleven in-person roundtables and four virtual roundtables at ML4H 2022. The organization of the research roundtables at the conference involved 17 Senior Chairs and 19 Junior Chairs across 11 tables. Each roundtable session included invited senior chairs (with substantial experience in the field), junior chairs (responsible for facilitating the discussion), and attendees from diverse backgrounds with interest in the session's topic. Herein we detail the organization process and compile takeaways from these roundtable discussions, including recent advances, applications, and open challenges for each topic. We conclude with a summary and lessons learned across all roundtables. This document serves as a comprehensive review paper, summarizing the recent advancements in machine learning for healthcare as contributed by foremost researchers in the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276192279",
                    "name": "Hyewon Jeong"
                },
                {
                    "authorId": "2284771486",
                    "name": "Sarah Jabbour"
                },
                {
                    "authorId": "2284827496",
                    "name": "Yuzhe Yang"
                },
                {
                    "authorId": "2290019163",
                    "name": "Rahul Thapta"
                },
                {
                    "authorId": "2290023216",
                    "name": "Hussein Mozannar"
                },
                {
                    "authorId": "2290084587",
                    "name": "William Jongwon Han"
                },
                {
                    "authorId": "2290023230",
                    "name": "Nikita Mehandru"
                },
                {
                    "authorId": "1993736674",
                    "name": "Michael Wornow"
                },
                {
                    "authorId": "2290022210",
                    "name": "Vladislav Lialin"
                },
                {
                    "authorId": "2290190364",
                    "name": "Xin Liu"
                },
                {
                    "authorId": "2290000605",
                    "name": "Alejandro Lozano"
                },
                {
                    "authorId": "2287916743",
                    "name": "Jiacheng Zhu"
                },
                {
                    "authorId": "1644949396",
                    "name": "Rafal Kocielnik"
                },
                {
                    "authorId": "2290022337",
                    "name": "Keith Harrigian"
                },
                {
                    "authorId": "2290148643",
                    "name": "Haoran Zhang"
                },
                {
                    "authorId": "2290028780",
                    "name": "Edward Lee"
                },
                {
                    "authorId": "2210671394",
                    "name": "Milos Vukadinovic"
                },
                {
                    "authorId": "46229877",
                    "name": "Aparna Balagopalan"
                },
                {
                    "authorId": "2007090588",
                    "name": "V. Jeanselme"
                },
                {
                    "authorId": "2290019601",
                    "name": "Katherine Matton"
                },
                {
                    "authorId": "2074703930",
                    "name": "Ilker Demirel"
                },
                {
                    "authorId": "2290022381",
                    "name": "Jason A. Fries"
                },
                {
                    "authorId": "2290019697",
                    "name": "Parisa Rashidi"
                },
                {
                    "authorId": "2291798879",
                    "name": "Brett K. Beaulieu-Jones"
                },
                {
                    "authorId": "2268804791",
                    "name": "X. Xu"
                },
                {
                    "authorId": "2256387869",
                    "name": "Matthew B. A. McDermott"
                },
                {
                    "authorId": "2113888405",
                    "name": "Tristan Naumann"
                },
                {
                    "authorId": "2276204931",
                    "name": "Monica Agrawal"
                },
                {
                    "authorId": "2274079858",
                    "name": "M. Zitnik"
                },
                {
                    "authorId": "2283135021",
                    "name": "Berk Ustun"
                },
                {
                    "authorId": "2290068116",
                    "name": "Edward Choi"
                },
                {
                    "authorId": "2290019625",
                    "name": "Kristen Yeom"
                },
                {
                    "authorId": "152258408",
                    "name": "Gamze Gursoy"
                },
                {
                    "authorId": "2279872952",
                    "name": "Marzyeh Ghassemi"
                },
                {
                    "authorId": "2276202987",
                    "name": "Emma Pierson"
                },
                {
                    "authorId": "2256946814",
                    "name": "George H. Chen"
                },
                {
                    "authorId": "47151525",
                    "name": "S. Kanjilal"
                },
                {
                    "authorId": "2047617",
                    "name": "Michael Oberst"
                },
                {
                    "authorId": "2290026402",
                    "name": "Linying Zhang"
                },
                {
                    "authorId": "2269756597",
                    "name": "Harvineet Singh"
                },
                {
                    "authorId": "2312757999",
                    "name": "Tom Hartvigsen"
                },
                {
                    "authorId": "2284823137",
                    "name": "Helen Zhou"
                },
                {
                    "authorId": "2030793519",
                    "name": "Chinasa T. Okolo"
                }
            ]
        },
        {
            "paperId": "8fdb8148966066ae4923f3348a15d64b3247c47b",
            "title": "Participation in the age of foundation models",
            "abstract": "Growing interest and investment in the capabilities of foundation models has positioned such systems to impact a wide array of services, from banking to healthcare. Alongside these opportunities is the risk that these systems reify existing power imbalances and cause disproportionate harm to historically marginalized groups. The larger scale and domain-agnostic manner in which these models operate further heightens the stakes: any errors or harms are liable to reoccur across use cases. In AI & ML more broadly, participatory approaches hold promise to lend agency and decision-making power to marginalized stakeholders, leading to systems that better benefit justice through equitable and distributed governance. But existing approaches in participatory AI/ML are typically grounded in a specific application and set of relevant stakeholders, and it is not straightforward how to apply these lessons to the context of foundation models. Our paper aims to fill this gap. First, we examine existing attempts at incorporating participation into foundation models. We highlight the tension between participation and scale, demonstrating that it is intractable for impacted communities to meaningfully shape a foundation model that is intended to be universally applicable. In response, we develop a blueprint for participatory foundation models that identifies more local, application-oriented opportunities for meaningful participation. In addition to the \u201cfoundation\u201d layer, our framework proposes the \u201csubfloor\u201d layer, in which stakeholders develop shared technical infrastructure, norms and governance for a grounded domain such as clinical care, journalism, or finance, and the \u201csurface\u201d (or application) layer, in which affected communities shape the use of a foundation model for a specific downstream task. The intermediate \u201csubfloor\u201d layer scopes the range of potential harms to consider, and affords communities more concrete avenues for deliberation and intervention. At the same time, it avoids duplicative effort by scaling input across relevant use cases. Through three case studies in clinical care, financial services, and journalism, we illustrate how this multi-layer model can create more meaningful opportunities for participation than solely intervening at the foundation layer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276205059",
                    "name": "Harini Suresh"
                },
                {
                    "authorId": "97560872",
                    "name": "Emily Tseng"
                },
                {
                    "authorId": "47533677",
                    "name": "Meg Young"
                },
                {
                    "authorId": "2303843955",
                    "name": "Mary L. Gray"
                },
                {
                    "authorId": "2276202987",
                    "name": "Emma Pierson"
                },
                {
                    "authorId": "2238709356",
                    "name": "Karen Levy"
                }
            ]
        },
        {
            "paperId": "d4e7f31e2f8102d92e64d989ca7cd1bdea1bea3a",
            "title": "Use large language models to promote equity",
            "abstract": "Advances in large language models (LLMs) have driven an explosion of interest about their societal impacts. Much of the discourse around how they will impact social equity has been cautionary or negative, focusing on questions like\"how might LLMs be biased and how would we mitigate those biases?\"This is a vital discussion: the ways in which AI generally, and LLMs specifically, can entrench biases have been well-documented. But equally vital, and much less discussed, is the more opportunity-focused counterpoint:\"what promising applications do LLMs enable that could promote equity?\"If LLMs are to enable a more equitable world, it is not enough just to play defense against their biases and failure modes. We must also go on offense, applying them positively to equity-enhancing use cases to increase opportunities for underserved groups and reduce societal discrimination. There are many choices which determine the impact of AI, and a fundamental choice very early in the pipeline is the problems we choose to apply it to. If we focus only later in the pipeline -- making LLMs marginally more fair as they facilitate use cases which intrinsically entrench power -- we will miss an important opportunity to guide them to equitable impacts. Here, we highlight the emerging potential of LLMs to promote equity by presenting four newly possible, promising research directions, while keeping risks and cautionary points in clear view.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276202987",
                    "name": "Emma Pierson"
                },
                {
                    "authorId": "2276205318",
                    "name": "Divya Shanmugam"
                },
                {
                    "authorId": "1405369173",
                    "name": "Rajiv Movva"
                },
                {
                    "authorId": "2238710364",
                    "name": "Jon Kleinberg"
                },
                {
                    "authorId": "2276204931",
                    "name": "Monica Agrawal"
                },
                {
                    "authorId": "1478928280",
                    "name": "Mark Dredze"
                },
                {
                    "authorId": "6745873",
                    "name": "Kadija Ferryman"
                },
                {
                    "authorId": "2268749951",
                    "name": "J. Gichoya"
                },
                {
                    "authorId": "2256674786",
                    "name": "Dan Jurafsky"
                },
                {
                    "authorId": "2276205042",
                    "name": "Pang Wei Koh"
                },
                {
                    "authorId": "2238709356",
                    "name": "Karen Levy"
                },
                {
                    "authorId": "2253742235",
                    "name": "Sendhil Mullainathan"
                },
                {
                    "authorId": "3797258",
                    "name": "Z. Obermeyer"
                },
                {
                    "authorId": "2276205059",
                    "name": "Harini Suresh"
                },
                {
                    "authorId": "70025184",
                    "name": "Keyon Vafa"
                }
            ]
        }
    ]
}