{
    "authorId": "144196238",
    "papers": [
        {
            "paperId": "387320f5321cf06d5e08b2fbb293bfcc41fe2ca9",
            "title": "Knowledge Graph Based RDM Solutions NFDI4Culture - NFDI-MatWerk - NFDI4DataScience",
            "abstract": "Based on our experience within the NFDI4Culture and NFDI-MatWerk projects we propose generalized knowledge graph based research data management solutions, which are applicable to other consortia. Our solution covers the construction of a common NFDI core ontology adapted to specific domains via domain extensions as a basis for a knowledge graph (KG) providing information about a consortium and its related research data and software resources. This KG serves as a backend for the web portal that enables interactive access and management of this data. Already implemented for NFDI4Culture and to be adapted by NFDI-MatWerk, this solution might serve as an example solution also for other consortia. We are synchronizing our efforts with ongoing work to implement knowledge graph based research data management in NFDI4DataScience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                },
                {
                    "authorId": "3421696",
                    "name": "Torsten Schrade"
                },
                {
                    "authorId": "2086790086",
                    "name": "O. Bruns"
                },
                {
                    "authorId": "3097980",
                    "name": "Etienne Posthumus"
                },
                {
                    "authorId": "2444947",
                    "name": "Tabea Tietz"
                },
                {
                    "authorId": "2238727014",
                    "name": "Ebrahim Norouzi"
                },
                {
                    "authorId": "2810514",
                    "name": "J. Waitelonis"
                },
                {
                    "authorId": "5665025",
                    "name": "Heike Fliegl"
                },
                {
                    "authorId": "2221225686",
                    "name": "Linnaea S\u00f6hn"
                },
                {
                    "authorId": "2030772",
                    "name": "Julia Tolksdorf"
                },
                {
                    "authorId": "2238725645",
                    "name": "Jonatan Jalle Steller"
                },
                {
                    "authorId": "2238728666",
                    "name": "Abril Az\u00b4ocar Guzm\u00b4an"
                },
                {
                    "authorId": "2238725225",
                    "name": "Said Fathalla"
                },
                {
                    "authorId": "2238727660",
                    "name": "Ahmad Zainul Ihsan"
                },
                {
                    "authorId": "2238734319",
                    "name": "Volker Hofmann"
                },
                {
                    "authorId": "2238727774",
                    "name": "Stefan Sandfeld"
                },
                {
                    "authorId": "8228603",
                    "name": "F. Fritzen"
                },
                {
                    "authorId": "2308617998",
                    "name": "Amir Laadhar"
                },
                {
                    "authorId": "2238644538",
                    "name": "Sonja Schimmler"
                },
                {
                    "authorId": "2238729279",
                    "name": "Peter Mutschke"
                }
            ]
        },
        {
            "paperId": "c5c4e08aba4c96100f86b1332f2dff4867af21b0",
            "title": "TRANSRAZ Data Model: Towards a Geosocial Representation of Historical Cities",
            "abstract": ". Preserving historical city architectures and making them (publicly) available has emerged as an important \ufb01eld of the cultural heritage and digital humanities research domain. In this context, the TRANSRAZ project is creating an interactive 3D environment of the historical city of Nuremberg which spans over different periods of time. Next to the exploration of the city\u2019s historical architecture, TRAN-SRAZ is also integrating information about its inhabitants, organizations, and important events, which are extracted from historical documents semi-automatically. Knowledge Graphs have proven useful and valuable to integrate and enrich these heterogeneous data. However, this task also comes with versatile data modeling challenges. This paper contributes the TRANSRAZ data model, which integrates agents, architectural objects, events, and historical documents into the 3D research environment by means of ontologies. Goal is to explore Nuremberg\u2019s multifaceted past in different time layers in the context of its architectural, social, economical, and cultural developments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2086790086",
                    "name": "O. Bruns"
                },
                {
                    "authorId": "2444947",
                    "name": "Tabea Tietz"
                },
                {
                    "authorId": "2093642599",
                    "name": "Sandra G\u00f6ller"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                }
            ]
        },
        {
            "paperId": "14b9a59c62862aec13ec7a30338c745aa458fb24",
            "title": "RAILD: Towards Leveraging Relation Features for Inductive Link Prediction In Knowledge Graphs",
            "abstract": "Due to the open world assumption, Knowledge Graphs (KGs) are never complete. In order to address this issue, various Link Prediction (LP) methods are proposed so far. Some of these methods are inductive LP models which are capable of learning representations for entities not seen during training. However, to the best of our knowledge, none of the existing inductive LP models focus on learning representations for unseen relations. In this work, a novel Relation Aware Inductive Link preDiction (RAILD) is proposed for KG completion which learns representations for both unseen entities and unseen relations. In addition to leveraging textual literals associated with both entities and relations by employing language models, RAILD also introduces a novel graph-based approach to generate features for relations. Experiments are conducted with different existing and newly created challenging benchmark datasets and the results indicate that RAILD leads to performance improvement over the state-of-the-art models. Moreover, since there are no existing inductive LP models which learn representations for unseen relations, we have created our own baselines and the results obtained with RAILD also outperform these baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "146797181",
                    "name": "Genet Asefa Gesese"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                },
                {
                    "authorId": "2109836049",
                    "name": "Mehwish Alam"
                }
            ]
        },
        {
            "paperId": "782a2dcece158023dd8cfd1c9f5e09b361c07b19",
            "title": "Entity Type Prediction Leveraging Graph Walks and Entity Descriptions",
            "abstract": "The entity type information in Knowledge Graphs (KGs) such as DBpedia, Freebase, etc. is often incomplete due to automated generation or human curation. Entity typing is the task of assigning or inferring the semantic type of an entity in a KG. This paper presents \\textit{GRAND}, a novel approach for entity typing leveraging different graph walk strategies in RDF2vec together with textual entity descriptions. RDF2vec first generates graph walks and then uses a language model to obtain embeddings for each node in the graph. This study shows that the walk generation strategy and the embedding model have a significant effect on the performance of the entity typing task. The proposed approach outperforms the baseline approaches on the benchmark datasets DBpedia and FIGER for entity typing in KGs for both fine-grained and coarse-grained classes. The results show that the combination of order-aware RDF2vec variants together with the contextual embeddings of the textual entity descriptions achieve the best results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51119656",
                    "name": "Russa Biswas"
                },
                {
                    "authorId": "27093239",
                    "name": "Jan Portisch"
                },
                {
                    "authorId": "1802726",
                    "name": "Heiko Paulheim"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                },
                {
                    "authorId": "2109836049",
                    "name": "Mehwish Alam"
                }
            ]
        },
        {
            "paperId": "f899e1c18b0eaf4614d0e675023031e9b253c01b",
            "title": "MADLINK: Attentive multihop and entity descriptions for link prediction in knowledge graphs",
            "abstract": "Knowledge Graphs (KGs) comprise of interlinked information in the form of entities and relations between them in a particular domain and provide the backbone for many applications. However, the KGs are often incomplete as the links between the entities are missing. Link Prediction is the task of predicting these missing links in a KG based on the existing links. Recent years have witnessed many studies on link prediction using KG embeddings which is one of the mainstream tasks in KG completion. To do so, most of the existing methods learn the latent representation of the entities and relations whereas only a few of them consider contextual information as well as the textual descriptions of the entities. This paper introduces an attentive encoder-decoder based link prediction approach considering both structural information of the KG and the textual entity descriptions. Random walk based path selection method is used to encapsulate the contextual information of an entity in a KG. The model explores a bidirectional Gated Recurrent Unit (GRU) based encoder-decoder to learn the representation of the paths whereas SBERT is used to generate the representation of the entity descriptions. The proposed approach outperforms most of the state-of-the-art models and achieves comparable results with the rest when evaluated with FB15K, FB15K-237, WN18, WN18RR, and YAGO3-10 datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51119656",
                    "name": "Russa Biswas"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                },
                {
                    "authorId": "2109836049",
                    "name": "Mehwish Alam"
                }
            ]
        },
        {
            "paperId": "1fa7a34a5c396d02206f54ea3ad9210709297637",
            "title": "Deep Learning meets Knowledge Graphs for Scholarly Data Classification",
            "abstract": "The amount of scientific literature continuously grows, which poses an increasing challenge for researchers to manage, find and explore research results. Therefore, the classification of scientific work is widely applied to enable the retrieval, support the search of suitable reviewers during the reviewing process, and in general to organize the existing literature according to a given schema. The automation of this classification process not only simplifies the submission process for authors, but also ensures the coherent assignment of classes. However, especially fine-grained classes and new research fields do not provide sufficient training data to automatize the process. Additionally, given the large number of not mutual exclusive classes, it is often difficult and computationally expensive to train models able to deal with multi-class multi-label settings. To overcome these issues, this work presents a preliminary Deep Learning framework as a solution for multi-label text classification for scholarly papers about Computer Science. The proposed model addresses the issue of insufficient data by utilizing the semantics of classes, which is explicitly provided by latent representations of class labels. This study uses Knowledge Graphs as a source of these required external class definitions by identifying corresponding entities in DBpedia to improve the overall classification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069898323",
                    "name": "Fabian Hoppe"
                },
                {
                    "authorId": "39876094",
                    "name": "D. Dess\u00ed"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                }
            ]
        },
        {
            "paperId": "4fc8c5bb734e89409559dbc60d45e68743aebfbc",
            "title": "HierClasSArt: Knowledge-Aware Hierarchical Classification of Scholarly Articles",
            "abstract": "A huge number of scholarly articles published every day in different domains makes it hard for the experts to organize and stay updated with the new research in a particular domain. This study gives an overview of a new approach, HierClasSArt, for knowledge aware hierarchical classification of the scholarly articles for mathematics into a predefined taxonomy. The method uses combination of neural networks and Knowledge Graphs for better document representation along with the meta-data information. This position paper further discusses the open problems about incorporation of new articles and evolving hierarchies in the pipeline. Mathematics domain has been used as a use-case.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "33973438",
                    "name": "Mehwish Alam"
                },
                {
                    "authorId": "51119656",
                    "name": "Russa Biswas"
                },
                {
                    "authorId": "2109208212",
                    "name": "Yiyi Chen"
                },
                {
                    "authorId": "39876094",
                    "name": "D. Dess\u00ed"
                },
                {
                    "authorId": "146797181",
                    "name": "Genet Asefa Gesese"
                },
                {
                    "authorId": "2069898323",
                    "name": "Fabian Hoppe"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                }
            ]
        },
        {
            "paperId": "5caacb05d9016225e6103127894841c31ec60776",
            "title": "Challenges of Applying Knowledge Graph and their Embeddings to a Real-world Use-case",
            "abstract": "Different Knowledge Graph Embedding (KGE) models have been proposed so far which are trained on some specific KG completion tasks such as link prediction and evaluated on datasets which are mainly created for such purpose. Mostly, the embeddings learnt on link prediction tasks are not applied for downstream tasks in real-world use-cases such as data available in different companies/organizations. In this paper, the challenges with enriching a KG which is generated from a real-world relational database (RDB) about companies, with information from external sources such as Wikidata and learning representations for the KG are presented. Moreover, a comparative analysis is presented between the KGEs and various text embeddings on some downstream clustering tasks. The results of experiments indicate that in use-cases like the one used in this paper, where the KG is highly skewed, it is beneficial to use text embeddings or language models instead of KGEs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2136618130",
                    "name": "Rick Petzold"
                },
                {
                    "authorId": "146797181",
                    "name": "Genet Asefa Gesese"
                },
                {
                    "authorId": "2053232934",
                    "name": "Viktoria Bogdanova"
                },
                {
                    "authorId": "2003816207",
                    "name": "Thorsten Zylowski"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                },
                {
                    "authorId": "2109836049",
                    "name": "Mehwish Alam"
                }
            ]
        },
        {
            "paperId": "7b8513bdf8d7be8250149a9bd7511587f65db92b",
            "title": "Contextual Language Models for Knowledge Graph Completion",
            "abstract": ". Knowledge Graphs (KGs) have become the backbone of various machine learning based applications over the past decade. However, the KGs are often incomplete and inconsistent. Several representation learning based approaches have been introduced to complete the missing information in KGs. Besides, Neural Language Models (NLMs) have gained huge momentum in NLP applications. However, exploiting the contextual NLMs to tackle the Knowledge Graph Completion (KGC) task is still an open research problem. In this paper, a GPT-2 based KGC model is proposed and is evaluated on two benchmark datasets. The initial results obtained from the \ufb01ne-tuning of the GPT-2 model for triple classi\ufb01cation strengthens the importance of usage of NLMs for KGC. Also, the impact of contextual language models for KGC has been discussed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51119656",
                    "name": "Russa Biswas"
                },
                {
                    "authorId": "1453582430",
                    "name": "Radina Sofronova"
                },
                {
                    "authorId": "2109836049",
                    "name": "Mehwish Alam"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                }
            ]
        },
        {
            "paperId": "7cc4f8f9f1c25c5c6b4aee805e7d48c79cd81624",
            "title": "MigrationsKB: A Knowledge Base of Public Attitudes towards Migrations and their Driving Factors",
            "abstract": "With the increasing trend in the topic of migration in Europe, the public is now more engaged in expressing their opinions through various platforms such as Twitter. Understanding the online discourses is therefore essential to capture the public opinion. The goal of this study is the analysis of social media platform to quantify public attitudes towards migrations and the identification of different factors causing these attitudes. The tweets spanning from 2013 to Jul-2021 in the European countries which are hosts to immigrants are collected, pre-processed, and filtered using advanced topic modeling technique. BERT-based entity linking and sentiment analysis, and attention-based hate speech detection are performed to annotate the curated tweets. Moreover, the external databases are used to identify the potential social and economic factors causing negative attitudes of the people about migration. To further promote research in the interdisciplinary fields of social science and computer science, the outcomes are integrated into a Knowledge Base (KB), i.e., MigrationsKB which significantly extends the existing models to take into account the public attitudes towards migrations and the economic indicators. This KB is made public using FAIR principles, which can be queried through SPARQL endpoint. Data dumps are made available on Zenodo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109208212",
                    "name": "Yiyi Chen"
                },
                {
                    "authorId": "144196238",
                    "name": "Harald Sack"
                },
                {
                    "authorId": "2109836049",
                    "name": "Mehwish Alam"
                }
            ]
        }
    ]
}