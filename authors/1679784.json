{
    "authorId": "1679784",
    "papers": [
        {
            "paperId": "0456bc829c199d5f8adf9ee5a3460c9dc5dc1453",
            "title": "YAGO 4.5: A Large and Clean Knowledge Base with a Rich Taxonomy",
            "abstract": "Knowledge Bases (KBs) find applications in many knowledge-intensive tasks and, most notably, in information retrieval. Wikidata is one of the largest public general-purpose KBs. Yet, its collaborative nature has led to a convoluted schema and taxonomy. The YAGO 4 KB cleaned up the taxonomy by incorporating the ontology of Schema.org, resulting in a cleaner structure amenable to automated reasoning. However, it also cut away large parts of the Wikidata taxonomy, which is essential for information retrieval. In this paper, we extend YAGO 4 with a large part of the Wikidata taxonomy - while respecting logical constraints and the distinction between classes and instances. This yields YAGO 4.5, a new, logically consistent version of YAGO that adds a rich layer of informative classes. An intrinsic and an extrinsic evaluation show the value of the new resource.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                },
                {
                    "authorId": "33973438",
                    "name": "Mehwish Alam"
                },
                {
                    "authorId": "1774132",
                    "name": "T. Bonald"
                },
                {
                    "authorId": "36560957",
                    "name": "Pierre-Henri Paris"
                },
                {
                    "authorId": "2233086268",
                    "name": "Jules Soria"
                }
            ]
        },
        {
            "paperId": "2fd5de4b4f75234f980157b00e4db8af7a228578",
            "title": "The Locality and Symmetry of Positional Encodings",
            "abstract": "Positional Encodings (PEs) are used to inject word-order information into transformer-based language models. While they can significantly enhance the quality of sentence representations, their specific contribution to language models is not fully understood, especially given recent findings that various positional encodings are insensitive to word order. In this work, we conduct a systematic study of positional encodings in \\textbf{Bidirectional Masked Language Models} (BERT-style) , which complements existing work in three aspects: (1) We uncover the core function of PEs by identifying two common properties, Locality and Symmetry; (2) We show that the two properties are closely correlated with the performances of downstream tasks; (3) We quantify the weakness of current PEs by introducing two new probing tasks, on which current PEs perform poorly. We believe that these results are the basis for developing better PEs for transformer-based language models. The code is available at \\faGithub~ \\url{https://github.com/tigerchen52/locality\\_symmetry}",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260594517",
                    "name": "Lihu Chen"
                },
                {
                    "authorId": "3025780",
                    "name": "G. Varoquaux"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "3a9129dc97b60f2ade7a1d29088d914cce2d7d17",
            "title": "BELLA: Black box model Explanations by Local Linear Approximations",
            "abstract": "In recent years, understanding the decision-making process of black-box models has become not only a legal requirement but also an additional way to assess their performance. However, the state of the art post-hoc interpretation approaches rely on synthetic data generation. This introduces uncertainty and can hurt the reliability of the interpretations. Furthermore, they tend to produce explanations that apply to only very few data points. This makes the explanations brittle and limited in scope. Finally, they provide scores that have no direct verifiable meaning. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. Thus, its coefficients can be used directly to compute the predicted value from the feature values. Furthermore, BELLA maximizes the size of the neighborhood to which the linear model applies, so that the explanations are accurate, simple, general, and robust. BELLA can produce both factual and counterfactual explanations. Our user study confirms the importance of the desiderata we optimize, and our experiments show that BELLA outperforms the state-of-the-art approaches on these desiderata.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1505817544",
                    "name": "N. Radulovic"
                },
                {
                    "authorId": "1762931",
                    "name": "A. Bifet"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "627b6f7687e122b5578f095221f66583850f0ea5",
            "title": "GLADIS: A General and Large Acronym Disambiguation Benchmark",
            "abstract": "Acronym Disambiguation (AD) is crucial for natural language understanding on various sources, including biomedical reports, scientific papers, and search engine queries. However, existing acronym disambiguationbenchmarks and tools are limited to specific domains, and the size of prior benchmarks is rather small. To accelerate the research on acronym disambiguation, we construct a new benchmark with three components: (1) a much larger acronym dictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus with 160 million sentences;(3) three datasets that cover thegeneral, scientific, and biomedical domains.We then pre-train a language model, {emph{AcroBERT}, on our constructed corpus for general acronym disambiguation, and show the challenges and values of our new benchmark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "94584806",
                    "name": "Lihu Chen"
                },
                {
                    "authorId": "3025780",
                    "name": "G. Varoquaux"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "c238c8df10846ef168a82a48d5e3208f1b617cb2",
            "title": "Completeness, Recall, and Negation in Open-world Knowledge Bases: A Survey",
            "abstract": "General-purpose knowledge bases (KBs) are a cornerstone of knowledge-centric AI. Many of them are constructed pragmatically from web sources and are thus far from complete. This poses challenges for the consumption as well as the curation of their content. While several surveys target the problem of completing incomplete KBs, the first problem is arguably to know whether and where the KB is incomplete in the first place, and to which degree. In this survey, we discuss how knowledge about completeness, recall, and negation in KBs can be expressed, extracted, and inferred. We cover (i) the logical foundations of knowledge representation and querying under partial closed-world semantics; (ii) the estimation of this information via statistical patterns; (iii) the extraction of information about recall from KBs and text; (iv) the identification of interesting negative statements; and (v) relaxed notions of relative recall. This survey is targeted at two types of audiences: (1) practitioners who are interested in tracking KB quality, focusing extraction efforts, and building quality-aware downstream applications; and (2) data management, knowledge base, and semantic web researchers who wish to understand the state-of-the-art of knowledge bases beyond the open-world assumption. Consequently, our survey presents both fundamental methodologies and the results that they have produced, and gives practice-oriented recommendations on how to choose between different approaches for a problem at hand.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2499758",
                    "name": "Simon Razniewski"
                },
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "2135976772",
                    "name": "Shrestha Ghosh"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "21ba26e871560d7101613125628af98cf32a78c8",
            "title": "TINA: Textual Inference with Negation Augmentation",
            "abstract": "Transformer-based language models achieve state-of-the-art results on several natural language processing tasks. One of these is textual entailment , i.e., the task of determining whether a premise logically entails a hypothesis. However, the models perform poorly on this task when the examples contain nega-tions. In this paper, we propose a new definition of textual entailment that captures also negation. This allows us to develop TINA (Textual Inference with Negation Augmentation), a principled technique for negated data augmentation that can be combined with the un-likelihood loss function. Our experiments with different transformer-based models show that our method can significantly improve the performance of the models on textual entailment datasets with negation \u2013 without sacrificing performance on datasets without negation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "17730355",
                    "name": "Chadi Helwe"
                },
                {
                    "authorId": "2119004939",
                    "name": "Simon Coumes"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "37b37b58c19f55c899e99eaa851f9fab0b19277e",
            "title": "LogiTorch: A PyTorch-based library for logical reasoning on natural language",
            "abstract": "Logical reasoning on natural language is one of the most challenging tasks for deep learning models. There has been an increasing interest in developing new benchmarks to evaluate the reasoning capabilities of language models such as BERT. In parallel, new models based on transformers have emerged to achieve ever better performance on these datasets. However, there is currently no library for logical reasoning that includes such benchmarks and models. This paper introduces LogiTorch, a PyTorch-based library that includes different logical reasoning benchmarks, different models, as well as utility functions such as co-reference resolution. This makes it easy to directly use the preprocessed datasets, to run the models, or to finetune them with different hyperparameters. LogiTorch is open source and can be found on GitHub 1 .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "17730355",
                    "name": "Chadi Helwe"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "5069cebd18c7584dc388c81d8e74344f1725b40f",
            "title": "Of Human Criteria and Automatic Metrics: A Benchmark of the Evaluation of Story Generation",
            "abstract": "Research on Automatic Story Generation (ASG) relies heavily on human and automatic evaluation. However, there is no consensus on which human evaluation criteria to use, and no analysis of how well automatic criteria correlate with them. In this paper, we propose to re-evaluate ASG evaluation. We introduce a set of 6 orthogonal and comprehensive human criteria, carefully motivated by the social sciences literature. We also present HANNA, an annotated dataset of 1,056 stories produced by 10 different ASG systems. HANNA allows us to quantitatively evaluate the correlations of 72 automatic metrics with human criteria. Our analysis highlights the weaknesses of current metrics for ASG and allows us to formulate practical recommendations for ASG evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2182520819",
                    "name": "Cyril Chhun"
                },
                {
                    "authorId": "46985469",
                    "name": "Pierre Colombo"
                },
                {
                    "authorId": "2049106",
                    "name": "C. Clavel"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        },
        {
            "paperId": "6f80d1ade43ae048763d65c6e8e913d9a31de4be",
            "title": "Accepted Tutorials at The Web Conference 2022",
            "abstract": "This paper summarizes the content of the 20 tutorials that have been given at The Web Conference 2022: 85% of these tutorials are lecture style, and 15% of these are hands on.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "2034201368",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2154990549",
                    "name": "Xuan Wang"
                },
                {
                    "authorId": "2108986527",
                    "name": "Hongwei Wang"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "134000266",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2528900",
                    "name": "Akash Bharadwaj"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "1819564",
                    "name": "Milan Dojchinovski"
                },
                {
                    "authorId": "37386609",
                    "name": "J. Forberg"
                },
                {
                    "authorId": "32114346",
                    "name": "Johannes Frey"
                },
                {
                    "authorId": "33122761",
                    "name": "P. Bonte"
                },
                {
                    "authorId": "50535911",
                    "name": "Marco Balduini"
                },
                {
                    "authorId": "2130209106",
                    "name": "Matteo Belcao"
                },
                {
                    "authorId": "1490541824",
                    "name": "Emanuele Della Valle"
                },
                {
                    "authorId": "28584977",
                    "name": "Junliang Yu"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "1390612725",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "1380259269",
                    "name": "Jamell Dacon"
                },
                {
                    "authorId": "95104850",
                    "name": "L. Lye"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "1682878",
                    "name": "A. Gionis"
                },
                {
                    "authorId": "2181680391",
                    "name": "Stefan Neumann"
                },
                {
                    "authorId": "35332118",
                    "name": "Bruno Ordozgoiti"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2064460784",
                    "name": "H. Arnaout"
                },
                {
                    "authorId": "2135976772",
                    "name": "Shrestha Ghosh"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2169468461",
                    "name": "Yu Chen"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2116441692",
                    "name": "Bang Liu"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "2284176",
                    "name": "Hans Chalupsky"
                },
                {
                    "authorId": "2628881",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "1637421061",
                    "name": "Ilias Kanellos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "2726036",
                    "name": "Nurendra Choudhary"
                },
                {
                    "authorId": "36724558",
                    "name": "N. Rao"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "51050025",
                    "name": "Friedhelm Victor"
                },
                {
                    "authorId": "1679379",
                    "name": "Bernhard Haslhofer"
                },
                {
                    "authorId": "2055401797",
                    "name": "George Katsogiannis-Meimarakis"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "28044622",
                    "name": "Shengmin Jin"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "143820870",
                    "name": "Vidhisha Balachandran"
                },
                {
                    "authorId": "51467955",
                    "name": "Sachin Kumar"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "47561503",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "87852047f1b76c66038d383cb2ebbe99423bc970",
            "title": "Combining Embeddings and Rules for Fact Prediction (Invited Paper)",
            "abstract": "Knowledge bases are typically incomplete, meaning that they are missing information that we would expect to be there. Recent years have seen two main approaches to guess missing facts: Rule Mining and Knowledge Graph Embeddings. The first approach is symbolic",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "136806596",
                    "name": "Armand Boschin"
                },
                {
                    "authorId": "1772598",
                    "name": "Nitisha Jain"
                },
                {
                    "authorId": "2166240706",
                    "name": "Gurami Keretchashvili"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                }
            ]
        }
    ]
}