{
    "authorId": "2775904",
    "papers": [
        {
            "paperId": "2944d825a465cb4fa76eee22bb314edb9c3ce60a",
            "title": "Threat Perception Captured by Emotion, Motor and Empathetic System Responses: A Systematic Review",
            "abstract": "The fight or flight phenomena is of evolutionary origin and responsible for the type of defensive behaviours enacted, when in the face of threat. This review attempts to draw the link between fear and aggression as motivational levers for fight or flight defensive behaviours. Furthermore, this review investigates whether human biological motion is modulated by the affective behaviours associated with the fight or flight phenomenon. It examines how threat informed emotion and motor systems have the potential to result in the modulation of empathetic appraisal. This is of interest to this systematic review, as empathetic modulation is crucial to prosocial drive, which has the potential to alleviate the perceived threat. Hence, this review investigates the role of affective computing in capturing the potential outcome of threat perception and associated empathetic responses. To gain a comprehensive understanding of the affective responses and biological motion evoked from threat scenarios, affective computing methods used to capture these neurophysiological and behavioural responses are discussed. A systematic review using Google Scholar and Web of Science was conducted as of 2023, and findings were supplemented by bibliographies of key articles. A total of 26 studies were analysed from initial web searches to explore the topics of empathy, threat perception, fight or flight, fear, aggression, and human motion. Relationships between affective behaviours (fear, aggression) and corresponding motor defensive behaviours (fight or flight) were examined within threat scenarios, and whether existing affective computing methods are effective in capturing these responses, identifying the varying consensus in the literature, challenges, and limitations of existing research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2319896153",
                    "name": "Elizabeth Michelle Jacobs"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                },
                {
                    "authorId": "2238566491",
                    "name": "Frank Pollick"
                }
            ]
        },
        {
            "paperId": "606b682129bc8c0c836f43ce7f201d458e0da60c",
            "title": "Glfnet: Global-Local (Frequency) Filter Networks for Efficient Medical Image Segmentation",
            "abstract": "We propose a novel transformer-style architecture called Global-Local Filter Network (GLFNet) for medical image segmentation and demonstrate its state-of-the-art performance. We replace the self-attention mechanism with a combination of global-local filter blocks to optimize model efficiency. The global filters extract features from the whole feature map whereas the local filters are being adaptively created as 4 \u00d7 4 patches of the same feature map and add restricted scale information. In particular, the feature extraction takes place in the frequency domain rather than the commonly used spatial (image) domain to facilitate faster computations. The fusion of information from both spatial and frequency spaces creates an efficient model with regards to complexity, required data and performance. We test GLFNet on three benchmark datasets achieving state-of-the-art performance on all of them while being almost twice as efficient in terms of GFLOP operations. Our code is available here\u2020.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2167320604",
                    "name": "Athanasios Tragakis"
                },
                {
                    "authorId": "2290138374",
                    "name": "Qianying Liu"
                },
                {
                    "authorId": "33330735",
                    "name": "Chaitanya Kaul"
                },
                {
                    "authorId": "1842981",
                    "name": "S. K. Roy"
                },
                {
                    "authorId": "2289612156",
                    "name": "Hang Dai"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                },
                {
                    "authorId": "1452854346",
                    "name": "Roderick Murray-Smith"
                },
                {
                    "authorId": "2289610948",
                    "name": "Daniele Faccio"
                }
            ]
        },
        {
            "paperId": "9e6e3bdf7295898dd7eb6ed00d2fdec9d45a7c22",
            "title": "Learning Semi-Supervised Medical Image Segmentation from Spatial Registration",
            "abstract": "Semi-supervised medical image segmentation has shown promise in training models with limited labeled data and abundant unlabeled data. However, state-of-the-art methods ignore a potentially valuable source of unsupervised semantic information -- spatial registration transforms between image volumes. To address this, we propose CCT-R, a contrastive cross-teaching framework incorporating registration information. To leverage the semantic information available in registrations between volume pairs, CCT-R incorporates two proposed modules: Registration Supervision Loss (RSL) and Registration-Enhanced Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from transforms between labeled and unlabeled volume pairs, providing an additional source of pseudo-labels. REPS enhances contrastive learning by identifying anatomically-corresponding positives across volumes using registration transforms. Experimental results on two challenging medical segmentation benchmarks demonstrate the effectiveness and superiority of CCT-R across various semi-supervised settings, with as few as one labeled case. Our code is available at https://github.com/kathyliu579/ContrastiveCross-teachingWithRegistration.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290138374",
                    "name": "Qianying Liu"
                },
                {
                    "authorId": "2321404509",
                    "name": "Paul Henderson"
                },
                {
                    "authorId": "2321428219",
                    "name": "Xiao Gu"
                },
                {
                    "authorId": "2289612156",
                    "name": "Hang Dai"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                }
            ]
        },
        {
            "paperId": "a3d05989c4c1d7322423b8eac2f882385a928c7e",
            "title": "Predictive Modelling of Cognitive Workload in VR: An Eye-Tracking Approach",
            "abstract": "Cognitive training can boost and sharpen the brain\u2019s abilities to remember, focus, and switch between different tasks. One of the key elements of cognitive training is cognitive load. It allows a manipulation of the intensity of the intervention to suit the participant\u2019s ability level and keep the session enjoyable, i.e. neither too frustrating/hard nor too boring/easy). However, measuring cognitive workload in an objective way is still under-researched and difficult. Here, we have developed a novel sustained attention Virtual Reality (VR) task, using Unity, that aims to predict load in a controlled manner. We demonstrate promising results in that machine learning algorithms can identify perceived as well as objective difficulty of the game accurately, using a combination of eye-tracking and physiological data obtained directly within the VR environment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2304208719",
                    "name": "Dominik Szczepaniak"
                },
                {
                    "authorId": "2270057631",
                    "name": "Monika Harvey"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                }
            ]
        },
        {
            "paperId": "8aa6ad95e1039829f2ee99e7d31566b2cdffd5dd",
            "title": "Controllable Chest X-Ray Report Generation from Longitudinal Representations",
            "abstract": "Radiology reports are detailed text descriptions of the content of medical scans. Each report describes the presence/absence and location of relevant clinical findings, commonly including comparison with prior exams of the same patient to describe how they evolved. Radiology reporting is a time-consuming process, and scan results are often subject to delays. One strategy to speed up reporting is to integrate automated reporting systems, however clinical deployment requires high accuracy and interpretability. Previous approaches to automated radiology reporting generally do not provide the prior study as input, precluding comparison which is required for clinical accuracy in some types of scans, and offer only unreliable methods of interpretability. Therefore, leveraging an existing visual input format of anatomical tokens, we introduce two novel aspects: (1) longitudinal representation learning -- we input the prior scan as an additional input, proposing a method to align, concatenate and fuse the current and prior visual information into a joint longitudinal representation which can be provided to the multimodal report generation model; (2) sentence-anatomy dropout -- a training strategy for controllability in which the report generator model is trained to predict only sentences from the original report which correspond to the subset of anatomical regions given as input. We show through in-depth experiments on the MIMIC-CXR dataset how the proposed approach achieves state-of-the-art results while enabling anatomy-wise controllable report generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "88768911",
                    "name": "F. Serra"
                },
                {
                    "authorId": "2257266289",
                    "name": "Chaoyang Wang"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                },
                {
                    "authorId": "2256995925",
                    "name": "Jeffrey Dalton"
                },
                {
                    "authorId": "2256995491",
                    "name": "Alison Q. O'Neil"
                }
            ]
        },
        {
            "paperId": "9783eb7bb5503c695827158bc8b3ddb91f40bef2",
            "title": "Multi-Scale Cross Contrastive Learning for Semi-Supervised Medical Image Segmentation",
            "abstract": "Semi-supervised learning has demonstrated great potential in medical image segmentation by utilizing knowledge from unlabeled data. However, most existing approaches do not explicitly capture high-level semantic relations between distant regions, which limits their performance. In this paper, we focus on representation learning for semi-supervised learning, by developing a novel Multi-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment structures in medical images. We jointly train CNN and Transformer models, regularising their features to be semantically consistent across different scales. Our approach contrasts multi-scale features based on ground-truth and cross-predicted labels, in order to extract robust feature representations that reflect intra- and inter-slice relationships across the whole dataset. To tackle class imbalance, we take into account the prevalence of each class to guide contrastive learning and ensure that features adequately capture infrequent classes. Extensive experiments on two multi-structure medical segmentation datasets demonstrate the effectiveness of MCSC. It not only outperforms state-of-the-art semi-supervised methods by more than 3.0% in Dice, but also greatly reduces the performance gap with fully supervised methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4289746",
                    "name": "Qianying Liu"
                },
                {
                    "authorId": "19083548",
                    "name": "Xiao Gu"
                },
                {
                    "authorId": "2071774114",
                    "name": "Paul Henderson"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                }
            ]
        },
        {
            "paperId": "9cbbc7673cb2c46fcb07ddbaa9ecec506f99bc08",
            "title": "Riemannian Prediction of Anatomical Diagnoses in Congenital Heart Disease Based on 12-Lead ECGS",
            "abstract": "Congenital heart disease (CHD) is a relatively rare disease that affects patients at birth and results in extremely heterogeneous anatomical and functional defects. 12-lead ECG signal is routinely collected in CHD patients because it provides significant biomarkers for disease prognosis. However, developing accurate machine learning models is challenging due to the lack of large available datasets. Here, we suggest exploiting the Riemannian geometry of the spatial covariance structure of the ECG signal to improve classification. Firstly, we use covariance augmentation to mix samples across the Riemannian geodesic between corresponding classes. Secondly, we suggest to project the covariance matrices to their respective class Riemannian mean to enhance the quality of feature extraction via tangent space projection. We perform several ablation experiments and demonstrate significant improvement compared to traditional machine learning models and deep learning on ECG time series data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2167443270",
                    "name": "Muhammet Alkan"
                },
                {
                    "authorId": "6208299",
                    "name": "G. Veldtman"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                }
            ]
        },
        {
            "paperId": "a13d7bf7f3192cc38ff497b8c6589fe305ad81e5",
            "title": "Finding-Aware Anatomical Tokens for Chest X-Ray Automated Reporting",
            "abstract": "The task of radiology reporting comprises describing and interpreting the medical findings in radiographic images, including description of their location and appearance. Automated approaches to radiology reporting require the image to be encoded into a suitable token representation for input to the language model. Previous methods commonly use convolutional neural networks to encode an image into a series of image-level feature map representations. However, the generated reports often exhibit realistic style but imperfect accuracy. Inspired by recent works for image captioning in the general domain in which each visual token corresponds to an object detected in an image, we investigate whether using local tokens corresponding to anatomical structures can improve the quality of the generated reports. We introduce a novel adaptation of Faster R-CNN in which finding detection is performed for the candidate bounding boxes extracted during anatomical structure localisation. We use the resulting bounding box feature representations as our set of finding-aware anatomical tokens. This encourages the extracted anatomical tokens to be informative about the findings they contain (required for the final task of radiology reporting). Evaluating on the MIMIC-CXR dataset of chest X-Ray images, we show that task-aware anatomical tokens give state-of-the-art performance when integrated into an automated reporting pipeline, yielding generated reports with improved clinical accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "88768911",
                    "name": "F. Serra"
                },
                {
                    "authorId": "50097023",
                    "name": "Chaoyang Wang"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                },
                {
                    "authorId": "49694325",
                    "name": "Jeffrey Stephen Dalton"
                },
                {
                    "authorId": "1404000098",
                    "name": "Alison Q. O'Neil"
                }
            ]
        },
        {
            "paperId": "abcf8789d6314f4eb24ae445563f5c9af6d6d141",
            "title": "Toward Personalized Music-Therapy: A Neurocomputational Modeling Perspective",
            "abstract": "Music therapy has emerged recently as a successful intervention that improves patient outcomes in a large range of neurological and mood disorders without adverse effects. Brain networks are entrained to music in ways that can be explained both via top-down and bottom-up processes. In particular, the direct interaction of auditory with the motor and the reward system via a predictive framework explains the efficacy of music-based interventions in motor rehabilitation. In this article, we provide a brief overview of current theories of music perception and processing. Subsequently, we summarize the evidence of music-based interventions primarily in motor, emotional, and cardiovascular regulation. We highlight opportunities to improve the quality of life and reduce the stress beyond the clinic environment and in healthy individuals. This relatively unexplored area requires an understanding of how we can personalize and automate music selection processes to fit individual needs and tasks via feedback loops mediated by measurements of neurophysiological responses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2222582778",
                    "name": "Nicole Lai-Tan"
                },
                {
                    "authorId": "9315222",
                    "name": "M. Philiastides"
                },
                {
                    "authorId": "1776175",
                    "name": "F. Kawsar"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                }
            ]
        },
        {
            "paperId": "cd7ef4872dbfbe45e73a4a7311a3ff989785b86d",
            "title": "Towards personalised music-therapy; a neurocomputational modelling perspective",
            "abstract": "Music therapy has emerged recently as a successful intervention that improves patient's outcome in a large range of neurological and mood disorders without adverse effects. Brain networks are entrained to music in ways that can be explained both via top-down and bottom-up processes. In particular, the direct interaction of auditory with the motor and the reward system via a predictive framework explains the efficacy of music-based interventions in motor rehabilitation. In this manuscript, we provide a brief overview of current theories of music perception and processing. Subsequently, we summarise evidence of music-based interventions primarily in motor, emotional and cardiovascular regulation. We highlight opportunities to improve quality of life and reduce stress beyond the clinic environment and in healthy individuals. This relatively unexplored area requires an understanding of how we can personalise and automate music selection processes to fit individuals needs and tasks via feedback loops mediated by measurements of neuro-physiological responses.",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051844544",
                    "name": "Nicole Y Lai"
                },
                {
                    "authorId": "9315222",
                    "name": "M. Philiastides"
                },
                {
                    "authorId": "1776175",
                    "name": "F. Kawsar"
                },
                {
                    "authorId": "2775904",
                    "name": "F. Deligianni"
                }
            ]
        }
    ]
}