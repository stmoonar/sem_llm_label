{
    "authorId": "35466544",
    "papers": [
        {
            "paperId": "1a4b9ceb3dbecd3ec08b93f68ba44bc3178b1df5",
            "title": "Simplifying and Empowering Transformers for Large-Graph Representations",
            "abstract": "Learning representations on large-sized graphs is a long-standing challenge due to the inter-dependence nature involved in massive data points. Transformers, as an emerging class of foundation encoders for graph-structured data, have shown promising performance on small graphs due to its global attention capable of capturing all-pair influence beyond neighboring nodes. Even so, existing approaches tend to inherit the spirit of Transformers in language and vision tasks, and embrace complicated models by stacking deep multi-head attentions. In this paper, we critically demonstrate that even using a one-layer attention can bring up surprisingly competitive performance across node property prediction benchmarks where node numbers range from thousand-level to billion-level. This encourages us to rethink the design philosophy for Transformers on large graphs, where the global attention is a computation overhead hindering the scalability. We frame the proposed scheme as Simplified Graph Transformers (SGFormer), which is empowered by a simple attention model that can efficiently propagate information among arbitrary nodes in one layer. SGFormer requires none of positional encodings, feature/graph pre-processing or augmented loss. Empirically, SGFormer successfully scales to the web-scale graph ogbn-papers100M and yields up to 141x inference acceleration over SOTA Transformers on medium-sized graphs. Beyond current results, we believe the proposed methodology alone enlightens a new technical path of independent interest for building Transformers on large graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51171144",
                    "name": "Qitian Wu"
                },
                {
                    "authorId": "49260917",
                    "name": "Wen-Long Zhao"
                },
                {
                    "authorId": null,
                    "name": "Chenxiao Yang"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "2163318329",
                    "name": "Fan Nie"
                },
                {
                    "authorId": "1557293815",
                    "name": "Haitian Jiang"
                },
                {
                    "authorId": "2419616",
                    "name": "Yatao Bian"
                },
                {
                    "authorId": "3063894",
                    "name": "Junchi Yan"
                }
            ]
        },
        {
            "paperId": "35544f161c8efa6134960bf0cc770defb13e6b56",
            "title": "Exploiting Intent Evolution in E-commercial Query Recommendation",
            "abstract": "Aiming at a better understanding of the search goals in the user search sessions, recent query recommender systems explicitly model the reformulations of queries, which hopes to estimate the intents behind these reformulations and thus benefit the next-query recommendation. However, in real-world e-commercial search scenarios, user intents are much more complicated and may evolve dynamically. Existing methods merely consider trivial reformulation intents from semantic aspects and fail to model dynamic reformulation intent flows in search sessions, leading to sub-optimal capacities to recommend desired queries. To deal with these limitations, we first explicitly define six types of query reformulation intents according to the desired products of two consecutive queries. We then apply two self-attentive encoders on top of two pre-trained large language models to learn the transition dynamics from semantic query and intent reformulation sequences, respectively. We develop an intent-aware query decoder to utilize the predicted intents for suggesting the next queries. We instantiate such a framework with an Intent-aware Variational AutoEncoder (IVAE) under deployment at Amazon. We conduct comprehensive experiments on two real-world e-commercial datasets from Amazon and one public dataset from BestBuy. Specifically, IVAE improves the Recall@15 by 25.44% and 60.47% on two Amazon datasets and 13.91% on BestBuy, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153606201",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "8492168",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "48784944",
                    "name": "Xianfeng Tang"
                },
                {
                    "authorId": "2107962433",
                    "name": "Yinghan Wang"
                },
                {
                    "authorId": "46334890",
                    "name": "Danqing Zhang"
                },
                {
                    "authorId": "3122003",
                    "name": "Limeng Cui"
                },
                {
                    "authorId": "2227491227",
                    "name": "M. Cheng"
                },
                {
                    "authorId": "2021632793",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2893721",
                    "name": "Suhang Wang"
                },
                {
                    "authorId": "2721708",
                    "name": "P. Yu"
                }
            ]
        },
        {
            "paperId": "5386782893891d8518901c93e231e7d403ec7723",
            "title": "Lexicographic Actor-Critic Deep Reinforcement Learning for Urban Autonomous Driving",
            "abstract": "Urban autonomous driving is a difficult task because of its complex road scenarios and the interaction between multiple vehicles. Autonomous vehicles need to balance multiple objectives in these complex scenarios, e.g., safety and speed. Traditional reinforcement learning methods deal with the multi-objective problem by optimizing agents with a single objective reward. However, these methods are sensitive to the reward scale and require huge experiments to design reward weights. In this paper, we propose the Lexicographical Proximal Policy Optimization algorithm (LPPO), which can express people's preference relationship through the lexicographical ordering between objectives. The proposed method has two main advantages. On the one hand, LPPO has a smaller parameter adjustment space, which makes it easy to find the optimal solution that satisfies the actual problem preference. On the other hand, the proposed method is less affected by the reward scale and easy to deploy in various driving scenarios. We evaluate our algorithm in two driving simulation environments, and the results show that the proposed method has better performance in urban driving tasks than previous reinforcement learning algorithms. In addition, we illustrate that the proposed method has better stability even if the reward scale changes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "2624174",
                    "name": "Youfang Lin"
                },
                {
                    "authorId": "2109749238",
                    "name": "Sheng Han"
                },
                {
                    "authorId": null,
                    "name": "Kai Lv"
                }
            ]
        },
        {
            "paperId": "5bf14dda76156d62a9b3b9ff59dba90ff7b9923d",
            "title": "OrthoReg: Improving Graph-regularized MLPs via Orthogonality Regularization",
            "abstract": "Graph Neural Networks (GNNs) are currently dominating in modeling graph-structure data, while their high reliance on graph structure for inference significantly impedes them from widespread applications. By contrast, Graph-regularized MLPs (GR-MLPs) implicitly inject the graph structure information into model weights, while their performance can hardly match that of GNNs in most tasks. This motivates us to study the causes of the limited performance of GR-MLPs. In this paper, we first demonstrate that node embeddings learned from conventional GR-MLPs suffer from dimensional collapse, a phenomenon in which the largest a few eigenvalues dominate the embedding space, through empirical observations and theoretical analysis. As a result, the expressive power of the learned node representations is constrained. We further propose OrthoReg, a novel GR-MLP model to mitigate the dimensional collapse issue. Through a soft regularization loss on the correlation matrix of node embeddings, OrthoReg explicitly encourages orthogonal node representations and thus can naturally avoid dimensionally collapsed representations. Experiments on traditional transductive semi-supervised classification tasks and inductive node classification for cold-start scenarios demonstrate its effectiveness and superiority.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "2151226033",
                    "name": "Shen Wang"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2121390172",
                    "name": "Soji Adeshina"
                },
                {
                    "authorId": "73329314",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2099585332",
                    "name": "Xiao Qin"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "122579067",
                    "name": "Da Zheng"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "78946f42ed58356c147caf747a9a82e0f2f5a562",
            "title": "DRL4Route: A Deep Reinforcement Learning Framework for Pick-up and Delivery Route Prediction",
            "abstract": "Pick-up and Delivery Route Prediction (PDRP), which aims to estimate the future service route of a worker given his current task pool, has received rising attention in recent years. Deep neural networks based on supervised learning have emerged as the dominant model for the task because of their powerful ability to capture workers' behavior patterns from massive historical data. Though promising, they fail to introduce the non-differentiable test criteria into the training process, leading to a mismatch in training and test criteria. Which considerably trims down their performance when applied in practical systems. To tackle the above issue, we present the first attempt to generalize Reinforcement Learning (RL) to the route prediction task, leading to a novel RL-based framework called DRL4Route. It combines the behavior-learning abilities of previous deep learning models with the non-differentiable objective optimization ability of reinforcement learning. DRL4Route can serve as a plug-and-play component to boost the existing deep learning models. Based on the framework, we further implement a model named DRL4Route-GAE for PDRP in logistic service. It follows the actor-critic architecture which is equipped with a Generalized Advantage Estimator that can balance the bias and variance of the policy gradient estimates, thus achieving a more optimal policy. Extensive offline experiments and the online deployment show that DRL4Route-GAE improves Location Square Deviation (LSD) by 0.9%-2.7%, and Accuracy@3 (ACC@3) by 2.4%-3.2% over existing methods on the real-world dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150466096",
                    "name": "Xiaowei Mao"
                },
                {
                    "authorId": "82286530",
                    "name": "Haomin Wen"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "39699556",
                    "name": "Huaiyu Wan"
                },
                {
                    "authorId": "47767924",
                    "name": "Lixia Wu"
                },
                {
                    "authorId": "2204750792",
                    "name": "Jianbin Zheng"
                },
                {
                    "authorId": "14724015",
                    "name": "Haoyuan Hu"
                },
                {
                    "authorId": "2624174",
                    "name": "Youfang Lin"
                }
            ]
        },
        {
            "paperId": "09786d7c155003841a256cce5c490787739b4221",
            "title": "ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation",
            "abstract": "Aiming at exploiting the rich information in user behaviour sequences, sequential recommendation has been widely adopted in real-world recommender systems. However, current methods suffer from the following issues: 1) sparsity of user-item interactions, 2) uncertainty of sequential records, 3) long-tail items. In this paper, we propose to incorporate contrastive learning into the framework of Variational AutoEncoders to address these challenges simultaneously. Firstly, we introduce ContrastELBO, a novel training objective that extends the conventional single-view ELBO to two-view case and theoretically builds a connection between VAE and contrastive learning from a two-view perspective. Then we propose Contrastive Variational AutoEncoder (ContrastVAE in short), a two-branched VAE model with contrastive regularization as an embodiment of ContrastELBO for sequential recommendation. We further introduce two simple yet effective augmentation strategies named model augmentation and variational augmentation to create a second view of a sequence and thus making contrastive learning possible. Experiments on four benchmark datasets demonstrate the effectiveness of ContrastVAE and the proposed augmentation methods. Codes are available at https://github.com/YuWang-1024/ContrastVAE",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153606201",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "1844299386",
                    "name": "Zhiwei Liu"
                },
                {
                    "authorId": "120378195",
                    "name": "Liangwei Yang"
                },
                {
                    "authorId": "2721708",
                    "name": "P. Yu"
                }
            ]
        },
        {
            "paperId": "0b088eced932de1d7cd5f2bcb64d0c71ec09a4b7",
            "title": "Localized Contrastive Learning on Graphs",
            "abstract": "Contrastive learning methods based on InfoNCE loss are popular in node representation learning tasks on graph-structured data. However, its reliance on data augmentation and its quadratic computational complexity might lead to inconsistency and inefficiency problems. To mitigate these limitations, in this paper, we introduce a simple yet effective contrastive model named Localized Graph Contrastive Learning (Local-GCL in short). Local-GCL consists of two key designs: 1) We fabricate the positive examples for each node directly using its first-order neighbors, which frees our method from the reliance on carefully-designed graph augmentations; 2) To improve the efficiency of contrastive learning on graphs, we devise a kernelized contrastive loss, which could be approximately computed in linear time and space complexity with respect to the graph size. We provide theoretical analysis to justify the effectiveness and rationality of the proposed methods. Experiments on various datasets with different scales and properties demonstrate that in spite of its simplicity, Local-GCL achieves quite competitive performance in self-supervised node representation learning tasks on graphs with various scales and properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "51171144",
                    "name": "Qitian Wu"
                },
                {
                    "authorId": "2153606201",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2116576240",
                    "name": "Shaofeng Zhang"
                },
                {
                    "authorId": "2112593570",
                    "name": "Junchi Yan"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "73cd0e2836711b5b31f8bfb0ee8aa2afd2d2f390",
            "title": "Heuristic adaptability to input dynamics for SpMM on GPUs",
            "abstract": "Sparse Matrix-Matrix Multiplication (SpMM) has served as fundamental components in various domains. Many previous studies exploit GPUs for SpMM acceleration because GPUs provide high bandwidth and parallelism. We point out that a static design does not always improve the performance of SpMM on different input data (e.g., >85% performance loss with a single algorithm). In this paper, we consider the challenge of input dynamics from a novel auto-tuning perspective, while following issues remain to be solved: (1) Orthogonal design principles considering sparsity. Orthogonal design principles for such a sparse problem should be extracted to form different algorithms, and further used for performance tuning. (2) Nontrivial implementations in the algorithm space. Combining orthogonal design principles to create new algorithms needs to tackle with new challenges like thread race handling. (3) Heuristic adaptability to input dynamics. The heuristic adaptability is required to dynamically optimize code for input dynamics. To tackle these challenges, we first propose a novel three-loop model to extract orthogonal design principles for SpMM on GPUs. The model not only covers previous SpMM designs, but also comes up with new designs absent from previous studies. We propose techniques like conditional reduction to implement algorithms missing in previous studies. We further propose DA-SpMM, a Data-Aware heuristic GPU kernel for SpMM. DA-SpMM adaptively optimizes code considering input dynamics. Extensive experimental results show that, DA-SpMM achieves 1.26X~1.37X speedup compared with the best NVIDIA cuSPARSE algorithm on average, and brings up to 5.59X end-to-end speedup to Graph Neural Networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144290348",
                    "name": "Guohao Dai"
                },
                {
                    "authorId": "1796329689",
                    "name": "Guyue Huang"
                },
                {
                    "authorId": "2154931483",
                    "name": "Shang Yang"
                },
                {
                    "authorId": "2143946373",
                    "name": "Zhongming Yu"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "119663869",
                    "name": "Yufei Ding"
                },
                {
                    "authorId": "1410066063",
                    "name": "Yuan Xie"
                },
                {
                    "authorId": "39150998",
                    "name": "Huazhong Yang"
                },
                {
                    "authorId": "2153604365",
                    "name": "Yu Wang"
                }
            ]
        },
        {
            "paperId": "99588393c3addda9048f1814ecdc77d4ce5e7063",
            "title": "Align Representations with Base: A New Approach to Self-Supervised Learning",
            "abstract": "Existing symmetric contrastive learning methods suffer from collapses (complete and dimensional) or quadratic complexity of objectives. Departure from these methods which maximize mutual information of two generated views, along either instance or feature dimension, the proposed paradigm introduces intermediate variables at the feature level, and maximizes the consistency between variables and representations of each view. Specifically, the proposed intermediate variables are the nearest group of base vectors to representations. Hence, we call the proposed method ARB (Align Representations with Base). Compared with other symmetric approaches, ARB 1) does not require negative pairs, which leads the complexity of the overall objective function is in linear order, 2) reduces feature redundancy, increasing the information density of training samples, 3) is more robust to output dimension size, which out-performs previous feature-wise arts over 28% Top-1 accuracy on ImageNet-100under low-dimension settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116576240",
                    "name": "Shaofeng Zhang"
                },
                {
                    "authorId": "2176292124",
                    "name": "Lyn Qiu"
                },
                {
                    "authorId": "2075369514",
                    "name": "Feng Zhu"
                },
                {
                    "authorId": "3063894",
                    "name": "Junchi Yan"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "145638781",
                    "name": "Rui Zhao"
                },
                {
                    "authorId": "46381640",
                    "name": "Hongyang Li"
                },
                {
                    "authorId": "2159107948",
                    "name": "Xiaokang Yang"
                }
            ]
        },
        {
            "paperId": "c559fd26624401e8bf1586c1f08e8de560b41a21",
            "title": "Handling Distribution Shifts on Graphs: An Invariance Perspective",
            "abstract": "There is increasing evidence suggesting neural networks' sensitivity to distribution shifts, so that research on out-of-distribution (OOD) generalization comes into the spotlight. Nonetheless, current endeavors mostly focus on Euclidean data, and its formulation for graph-structured data is not clear and remains under-explored, given two-fold fundamental challenges: 1) the inter-connection among nodes in one graph, which induces non-IID generation of data points even under the same environment, and 2) the structural information in the input graph, which is also informative for prediction. In this paper, we formulate the OOD problem on graphs and develop a new invariant learning approach, Explore-to-Extrapolate Risk Minimization (EERM), that facilitates graph neural networks to leverage invariance principles for prediction. EERM resorts to multiple context explorers (specified as graph structure editers in our case) that are adversarially trained to maximize the variance of risks from multiple virtual environments. Such a design enables the model to extrapolate from a single observed environment which is the common case for node-level prediction. We prove the validity of our method by theoretically showing its guarantee of a valid OOD solution and further demonstrate its power on various real-world datasets for handling distribution shifts from artificial spurious features, cross-domain transfers and dynamic graph evolution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51171144",
                    "name": "Qitian Wu"
                },
                {
                    "authorId": "35466544",
                    "name": "Hengrui Zhang"
                },
                {
                    "authorId": "3063894",
                    "name": "Junchi Yan"
                },
                {
                    "authorId": "2242717",
                    "name": "D. Wipf"
                }
            ]
        }
    ]
}