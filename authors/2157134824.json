{
    "authorId": "2157134824",
    "papers": [
        {
            "paperId": "dc14a498c21ca9dcb1c9f3622e969ac4eb2a1d27",
            "title": "A Cross-Attention Emotion Recognition Algorithm Based on Audio and Video Modalities",
            "abstract": "In recent years, emotion recognition has received significant attention. In this paper, multimodal information, including speech and facial expressions, is adopted to realize human emotion classification. Firstly, we propose a speech recognition model based on the Parallel convolutional module (Pconv), and an expression emotion recognition model based on the improved Inception-ResnetV2 network. The recognize futures of speech and expression will be further fused by using a cross-attention module coordinated with Bidirectional Long Short-Term Memory (BiLSTM). The experimental results organized on CH-SIMS and CMU-MOSI datasets have demonstrated that the proposed algorithm achieves high recognition accuracy. Each component of this model could contribute to performance improvement in the fair way.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157134824",
                    "name": "Xiao Wu"
                },
                {
                    "authorId": "2316397876",
                    "name": "Xuan Mu"
                },
                {
                    "authorId": "2316402828",
                    "name": "Wen Qi"
                },
                {
                    "authorId": "2316444347",
                    "name": "Xiaorui Liu"
                }
            ]
        },
        {
            "paperId": "0071604cdf29429e0fa3d8a58d66b3874eb5645f",
            "title": "Multimodal Emotion Recognition Based on Feature Fusion",
            "abstract": "In the field of human-computer interaction, human emotion recognition is a challenging problem, and it is also a key link to achieve barrier-free communication between human and machine. At present, most of the emotion recognition algorithms are constructed based on single modal social information, and the recognition results are one-sided and easily disturbed. The recognition accuracy is often difficult to meet the practical requirements after being separated from specific social environment conditions. Based on the above situation and problems, this paper adopts multimodal input and simultaneously includes three modal information of audio, text and facial expression to recognition emotion. Three single modal emotion recognition models are proposed based on three different input information, and the multimodal emotion recognition model are constructed by different feature fusion methods. The experimental results showed that the accuracy of multimodal model on the CH-SIMS dataset was 93.92%. In addition, compared with other emotion recognition models, the effectiveness of the proposed method is verified.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2182141797",
                    "name": "Yurui Xu"
                },
                {
                    "authorId": "2157134824",
                    "name": "Xiao Wu"
                },
                {
                    "authorId": "2087042688",
                    "name": "Hang Su"
                },
                {
                    "authorId": "1390612725",
                    "name": "Xiaorui Liu"
                }
            ]
        },
        {
            "paperId": "458b81d5d39421c4a208666434e4edfe065fab0c",
            "title": "Primary Study on the Face-recognition Framework with anti-spoofing function",
            "abstract": "In pracyical life scene, most access control systems (ACS) cannot solve the problem of various sproofing ways and mask-wearing recognition. In this paper, a new security classification framework based on face recognition is proposed. This framework uses face recognition algorithm with anti-spoofing function. In order to evaluate the performance of the framework, this paper employs the Chinese Academy of Science Institute of Automation-Face Anti-spoofing Datasets (CASIA-FASD) as benchmarks. Performance evaluation indicates that the Half Total Error Rate (HTER) is 9.7%, the Equal Error Rate (EER) is 5.5%. The results demonstrate that this framework has a high anti-spoofing capability and can be employed on the embedded system to complete the mask detection in real-time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157134824",
                    "name": "Xiao Wu"
                },
                {
                    "authorId": "2197879426",
                    "name": "Dekang Zhang"
                },
                {
                    "authorId": "1390612725",
                    "name": "Xiaorui Liu"
                }
            ]
        },
        {
            "paperId": "cd3fb528c1d5290811c3b35082d29c4db8296140",
            "title": "Research and Application on Bionic Pattern Recognition",
            "abstract": "Studies on biology basis from human being or other animals have attracted an ever increasing attention in pattern recognition. This paper describe a new model of pattern recognition principles, witch is based on \u201cmatter cognition\u201d instead of \u201cmatter classification\u201d in traditional statistical pattern recognition. This new model is better closer to the function of human being, rather than traditional statistical pattern recognition using \u201coptimal separating\u201d as its main principle. So the new model of pattern recognition is called the Bionic\uff08or cognitive\uff09 Pattern Recognition. In the support of this theory, the pulse coupled neural network (PCNN), an entirely different neural network from traditional artificial ones, is used for image target recognition. Through the contrast of the image, the linking strength of each pixel can be chosen adaptively. After the processing of PCNN with the adaptive linking strength, new fire mapping images are obtained for each image from sensor. The clear objects of each original image are decided by the compare-selection operator with the fire mapping images pixel by pixel and then all of them are merged into a new clear image. As a result, the target which was polluted by noise was recognized correctly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157134824",
                    "name": "Xiao Wu"
                },
                {
                    "authorId": "2111741294",
                    "name": "Qi-Chuan Tian"
                }
            ]
        }
    ]
}