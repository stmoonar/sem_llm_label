{
    "authorId": "46522098",
    "papers": [
        {
            "paperId": "a8ac328be01765c493f9ab91e166c27725a57f4f",
            "title": "IMTCN: An Interpretable Flight Safety Analysis and Prediction Model Based on Multi-Scale Temporal Convolutional Networks",
            "abstract": "Flight safety is a key issue in the aviation industry. Recently, with the prevalence of flight data recording systems, some deep learning-based studies have been devoted to predicting safety incidents based on flight data. However, these studies, although they exhibit higher prediction accuracy, have largely neglected the interpretability analysis of safety incidents which is of great concern to airlines and pilots. To address this issue, we define flight safety prediction as a multiscale time series classification problem and propose an interpretable model named IMTCN to provide both accurate predictions and high interpretability of flight safety. First, multiple temporal convolutional networks (TCNs) are utilized to capture local representations and long effective histories from multivariate flight data. Because different flight parameters are collected with diverse sampling frequencies, multiple TCNs are used to handle these parameters separately. Then, we creatively adapt the class activation mapping (CAM) method, which has been used for interpretation in image classification, and combine it with the TCN to provide flight data interpretability. The established model can pinpoint key flight parameters and corresponding moments that contribute most to safety incidents. Experimental results on a real-world dataset with 37,943 Airbus A320 aircraft flights show that our model outperforms the baselines on the task of exceedance classification and prediction 2 seconds and 4 seconds in advance, and case studies demonstrate its superb interpretability for flight safety analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116327254",
                    "name": "Xu Li"
                },
                {
                    "authorId": "145249849",
                    "name": "Jiaxing Shang"
                },
                {
                    "authorId": "2237121939",
                    "name": "Linjiang Zheng"
                },
                {
                    "authorId": "2241938226",
                    "name": "Qixing Wang"
                },
                {
                    "authorId": "2115507842",
                    "name": "Dajiang Liu"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2146328874",
                    "name": "Fan Li"
                },
                {
                    "authorId": "2150389845",
                    "name": "Weiwei Cao"
                },
                {
                    "authorId": "2152993403",
                    "name": "Hong Sun"
                }
            ]
        },
        {
            "paperId": "0496e8e32bb3c2d2d60b394bf812cdbc12ed2e49",
            "title": "CircularE: A Complex Space Circular Correlation Relational Model for Link Prediction in Knowledge Graph Embedding",
            "abstract": "Knowledge graphs are regarded as structured knowledge bases that embody various facts coming from the real world. Their completeness is still far from satisfactory. Relational learning models in link prediction can automatically find the missing relationships between entities to increase the integrality of the knowledge bases, which form two categories purely embedding-based and hybrid embedding-based. Several models including HolE and RotatE belong to purely embedding-based with inefficient performers and few element interactions. Based on the above, this article advances a novel Knowledge Graph Embedding relational model that leverages a circular correlation operation in the complex domain and dubs as CircularE, which increases interactions between entities and relations to a great extent by this compressed operator without expanding the dimension of space. It gives expression of the interactions between element semantics to achieve good performance in relational learning. Besides, a self-adaption adversarial negative sampling scheme is proposed on account of the KGs structure and the probability semantic of the triples. This negative sampler efficiently optimizes the knowledge representation capability of CircularE and far more than enhances the outputs of several relational original models in embedding-based. Experiments indicate that the competitive properties of CircularE on the four large-scale benchmarks of knowledge base completion task are superior to the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187757605",
                    "name": "Yan Fang"
                },
                {
                    "authorId": "2154002267",
                    "name": "Wei Lu"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2184502084",
                    "name": "W. Pedrycz"
                },
                {
                    "authorId": "1384395664",
                    "name": "Qi Lang"
                },
                {
                    "authorId": "152905588",
                    "name": "Jianhua Yang"
                },
                {
                    "authorId": "9373995",
                    "name": "Wenlin Jing"
                }
            ]
        },
        {
            "paperId": "0ad0e3e965318d83f53f8d5980f3a3d4cc81922f",
            "title": "Pre-training Transformers for Knowledge Graph Completion",
            "abstract": "Learning transferable representation of knowledge graphs (KGs) is challenging due to the heterogeneous, multi-relational nature of graph structures. Inspired by Transformer-based pretrained language models' success on learning transferable representation for texts, we introduce a novel inductive KG representation model (iHT) for KG completion by large-scale pre-training. iHT consists of a entity encoder (e.g., BERT) and a neighbor-aware relational scoring function both parameterized by Transformers. We first pre-train iHT on a large KG dataset, Wikidata5M. Our approach achieves new state-of-the-art results on matched evaluations, with a relative improvement of more than 25% in mean reciprocal rank over previous SOTA models. When further fine-tuned on smaller KGs with either entity and relational shifts, pre-trained iHT representations are shown to be transferable, significantly improving the performance on FB15K-237 and WN18RR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296722484",
                    "name": "Sanxing Chen"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "49097406",
                    "name": "Jian Jiao"
                },
                {
                    "authorId": "2114167577",
                    "name": "Yangfeng Ji"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                }
            ]
        },
        {
            "paperId": "103ee4ea6dd56890c517dadc07c6bd8f4d29a359",
            "title": "Bridging Discrete and Backpropagation: Straight-Through and Beyond",
            "abstract": "Backpropagation, the cornerstone of deep learning, is limited to computing gradients for continuous variables. This limitation poses challenges for problems involving discrete latent variables. To address this issue, we propose a novel approach to approximate the gradient of parameters involved in generating discrete latent variables. First, we examine the widely used Straight-Through (ST) heuristic and demonstrate that it works as a first-order approximation of the gradient. Guided by our findings, we propose ReinMax, which achieves second-order accuracy by integrating Heun's method, a second-order numerical method for solving ODEs. ReinMax does not require Hessian or other second-order derivatives, thus having negligible computation overheads. Extensive experimental results on various tasks demonstrate the superiority of ReinMax over the state of the art. Implementations are released at https://github.com/microsoft/ReinMax.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109392217",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2116416822",
                    "name": "Bin Yu"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                }
            ]
        },
        {
            "paperId": "1a0cf88e8e4a5cb74773d642b8cca8fde51c5f08",
            "title": "A Dynamic Effective Class Balanced Approach for Remote Sensing Imagery Semantic Segmentation of Imbalanced Data",
            "abstract": "The wide application and rapid development of satellite remote sensing technology have put higher requirements on remote sensing image segmentation methods. Because of its characteristics of large image size, large data volume, and complex segmentation background, not only are the traditional image segmentation methods difficult to apply effectively, but the image segmentation methods based on deep learning are faced with the problem of extremely unbalanced data between categories. In order to solve this problem, first of all, according to the existing effective sample theory, the effective sample calculation method in the context of semantic segmentation is firstly proposed in the highly unbalanced dataset. Then, a dynamic weighting method based on the effective sample concept is proposed, which can be applied to the semantic segmentation of remote sensing images. Finally, the applicability of this method to different loss functions and different network structures is verified on the self-built Landsat8-OLI remote sensing image-based tri-classified forest fire burning area dataset and the LoveDA dataset, which is for land-cover semantic segmentation. It has been concluded that this weighting algorithm can enhance the minimal-class segmentation accuracy while ensuring that the overall segmentation performance in multi-class segmentation tasks is verified in two different semantic segmentation tasks, including the land use and land cover (LULC) and the forest fire burning area segmentation In addition, this proposed method significantly improves the recall of forest fire burning area segmentation by as much as about 30%, which is of great reference value for forest fire research based on remote sensing images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157944675",
                    "name": "Zheng Zhou"
                },
                {
                    "authorId": "2153619472",
                    "name": "Change Zheng"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2143700164",
                    "name": "Ye Tian"
                },
                {
                    "authorId": "2213451789",
                    "name": "Xiaoyi Chen"
                },
                {
                    "authorId": "2214349913",
                    "name": "Xuexue Chen"
                },
                {
                    "authorId": "2185141892",
                    "name": "Zixun Dong"
                }
            ]
        },
        {
            "paperId": "26f7138641b1b66a37aeb4e3211b2c78c3548152",
            "title": "Forest Fire Monitoring Method Based on UAV Visual and Infrared Image Fusion",
            "abstract": "Forest fires have become a significant global threat, with many negative impacts on human habitats and forest ecosystems. This study proposed a forest fire identification method by fusing visual and infrared images, addressing the high false alarm and missed alarm rates of forest fire monitoring using single spectral imagery. A dataset suitable for image fusion was created using UAV aerial photography. An improved image fusion network model, the FF-Net, incorporating an attention mechanism, was proposed. The YOLOv5 network was used for target detection, and the results showed that using fused images achieved a higher accuracy, with a false alarm rate of 0.49% and a missed alarm rate of 0.21%. As such, using fused images has greater significance for the early warning of forest fires.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108996404",
                    "name": "Y. Liu"
                },
                {
                    "authorId": "2153619472",
                    "name": "Change Zheng"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2143700164",
                    "name": "Ye Tian"
                },
                {
                    "authorId": "2163437101",
                    "name": "Jianzhong Zhang"
                },
                {
                    "authorId": "8759340",
                    "name": "W. Cui"
                }
            ]
        },
        {
            "paperId": "2b0d96dccd07ebe8feb90951fe90d3aa81741097",
            "title": "Understand and Modularize Generator Optimization in ELECTRA-style Pretraining",
            "abstract": "Despite the effectiveness of ELECTRA-style pretraining, their performance is dependent on the careful selection of the model size for the auxiliary generator, leading to high trial-and-error costs. In this paper, we present the first systematic study of this problem. Our theoretical investigation highlights the importance of controlling the generator capacity in ELECTRA-style training. Meanwhile, we found it is not handled properly in the original ELECTRA design, leading to the sensitivity issue. Specifically, since adaptive optimizers like Adam will cripple the weighing of individual losses in the joint optimization, the original design fails to control the generator training effectively. To regain control over the generator, we modularize the generator optimization by decoupling the generator optimizer and discriminator optimizer completely, instead of simply relying on the weighted objective combination. Our simple technique reduced the sensitivity of ELECTRA training significantly and obtains considerable performance gain compared to the original design.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "2109392217",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                }
            ]
        },
        {
            "paperId": "31a806377776345f255b4bb8157296ea38bf7988",
            "title": "A Locating Approach for Small-Sized Components of Railway Catenary Based on Improved YOLO With Asymmetrically Effective Decoupled Head",
            "abstract": "In the routine inspection process of railway catenary systems, the primary task is to find out the locations of various components accurately. The complex composition of the components in the catenary system and their large dimensional differences make the inspection of small components considerably difficult. Aiming at the problem of the difficulty in locating small components, a new locating method, named asymmetrically effective decoupled head-you only look once (AED-YOLO), for locating small components of the catenary has been proposed in this study. In this method, firstly, a small object detection layer has been added to improve the detection accuracy of the small-sized components such as fastener nuts and bracing wire. Secondly, to reduce missed and false detection errors of small components, the improved bidirectional feature pyramid network with high-order spatial interactions and recursive gated convolution has been used to fuse the features of different scales to further enhance the ability to detect small objects. Finally, an asymmetrically effective decoupled head has been proposed using different decoupled branches to decouple the classification and localization processes, thus further reducing the error in small-sized object classification and location. Experiments performed on the railway catenary dataset collected on-site show that the proposed localization method can efficiently improve detection accuracy, achieving a mean average precision of 93.5%. Thus, compared to the other methods, the proposed method can accurately locate small-sized components.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214286622",
                    "name": "Shuai Xu"
                },
                {
                    "authorId": "2104469199",
                    "name": "Qian Feng"
                },
                {
                    "authorId": "8670289",
                    "name": "Jiyou Fei"
                },
                {
                    "authorId": "2213885109",
                    "name": "Geng Zhao"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2108841030",
                    "name": "Hua Li"
                },
                {
                    "authorId": "2153826113",
                    "name": "Chang Lu"
                },
                {
                    "authorId": "2212779018",
                    "name": "Qi Yang"
                }
            ]
        },
        {
            "paperId": "38aaf8a29df6deeff0bf64cc835d242a25b10337",
            "title": "Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers",
            "abstract": "This paper explores the effectiveness of model-generated signals in improving zero-shot generalization of text-to-text Transformers such as T5. We study various designs to pretrain T5 using an auxiliary model to construct more challenging token replacements for the main model to denoise. Key aspects under study include the decoding target, the location of the RTD head, and the masking pattern. Based on these studies, we develop a new model, METRO-T0, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters. Our analysis on model\u2019s neural activation and parameter sensitivity reveals that the effectiveness of METRO-T0 stems from more balanced contribution of parameters and better utilization of their capacity. The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32816503",
                    "name": "Linyuan Gong"
                },
                {
                    "authorId": "2139787803",
                    "name": "Chenyan Xiong"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "34765717",
                    "name": "Payal Bajaj"
                },
                {
                    "authorId": "1892794261",
                    "name": "Yiqing Xie"
                },
                {
                    "authorId": "2172244319",
                    "name": "Alvin Cheung"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "50706785",
                    "name": "Xia Song"
                }
            ]
        },
        {
            "paperId": "61354e45bca908ad08f24e44bd507b4e1c958e6f",
            "title": "Chain-of-Skills: A Configurable Model for Open-Domain Question Answering",
            "abstract": "The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22244290",
                    "name": "Kaixin Ma"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "46522098",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "144287919",
                    "name": "Eric Nyberg"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                }
            ]
        }
    ]
}