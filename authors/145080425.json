{
    "authorId": "145080425",
    "papers": [
        {
            "paperId": "b3580c1862e9d91d55b6db7c87dff30575efb493",
            "title": "On Finding Rank Regret Representatives",
            "abstract": "Selecting the best items in a dataset is a common task in data exploration. However, the concept of \u201cbest\u201d lies in the eyes of the beholder: Different users may consider different attributes more important and, hence, arrive at different rankings. Nevertheless, one can remove \u201cdominated\u201d items and create a \u201crepresentative\u201d subset of the data, comprising the \u201cbest items\u201d in it. A Pareto-optimal representative is guaranteed to contain the best item of each possible ranking, but it can be a large portion of data. A much smaller representative can be found if we relax the requirement of including the best item for each user and instead just limit the users\u2019 \u201cregret.\u201d Existing work defines regret as the loss in score by limiting consideration to the representative instead of the full dataset, for any chosen ranking function. However, the score is often not a meaningful number, and users may not understand its absolute value. Sometimes small ranges in score can include large fractions of the dataset. In contrast, users do understand the notion of rank ordering. Therefore, we consider items\u2019 positions in the ranked list in defining the regret and propose the rank-regret representative as the minimal subset of the data containing at least one of the top-k of any possible ranking function. This problem is polynomial time solvable in two-dimensional space but is NP-hard on three or more dimensions. We design a suite of algorithms to fulfill different purposes, such as whether relaxation is permitted on k, the result size, or both, whether a distribution is known, whether theoretical guarantees or practical efficiency is important, and so on. Experiments on real datasets demonstrate that we can efficiently find small subsets with small rank-regrets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                },
                {
                    "authorId": "1892337440",
                    "name": "Shangqi Lu"
                },
                {
                    "authorId": "3038200",
                    "name": "Azade Nazi"
                },
                {
                    "authorId": "144779196",
                    "name": "Yufei Tao"
                },
                {
                    "authorId": "36856144",
                    "name": "N. Zhang"
                },
                {
                    "authorId": "2130188380",
                    "name": "Jianwen Zhao"
                }
            ]
        },
        {
            "paperId": "00aadbd1b1e83ae19372af40ba86f35d7bf108b9",
            "title": "A Generalized Approach for Reducing Expensive Distance Calls for A Broad Class of Proximity Problems",
            "abstract": "In this paper, we revisit a suite of popular proximity problems (such as, KNN, clustering, minimum spanning tree) that repeatedly perform distance computations to compare distances during their execution. Our effort here is to design principled solutions to minimize distance computations for such problems in general metric spaces, especially for the scenarios where calling an expensive oracle to resolve unknown distances are the dominant cost of the algorithms for these problems. We present a suite of techniques, including a novel formulation of the problem, that studies how distance comparisons between objects could be modelled as a system of linear inequalities that assists in saving distance computations, multiple graph based solutions, as well as a practitioners guide to adopt our solution frameworks to proximity problems. We compare our designed solutions conceptually and empirically with respect to a broad range of existing works. We finally present a comprehensive set of experimental results using multiple large scale real-world datasets and a suite of popular proximity algorithms to demonstrate the effectiveness of our proposed approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51124778",
                    "name": "Jees Augustine"
                },
                {
                    "authorId": "1442194534",
                    "name": "Suraj Shetiya"
                },
                {
                    "authorId": "47224252",
                    "name": "M. Esfandiari"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "2f4ddfec2ad8e44e71cc1775d561f5c8bacc918b",
            "title": "Answering Complex Queries in an Online Community Network",
            "abstract": "\n \n An online community network such as Twitter or amazon.com links entities (e.g., users, products) with various relationships (e.g., friendship, co-purchase) and make such information available for access through a web interface. The web interfaces of these networks often support features such as keyword search and \"get-neighbors\" \u2014 so a visitor can quickly find entities (e.g., users/products) of interest. Nonetheless, the interface is usually too restrictive to answer complex queries such as (1) find 100 Twitter users from California with at least 100 followers who talked about ICWSM last year or (2) find 100 books with at least 200 5-star reviews at amazon.com. In this paper, we introduce the novel problem of answering complex queries that involve non-searchable attributes through the web interface of an online community network. We model such a network as a heterogeneous graph with two access channels, Content Search and Local Search. We propose a unified approach that transforms the complex query into a small number of supported ones based on a strategic query-selection process. We conduct comprehensive experiments on Twitter and amazon.com which demonstrate the efficacy of our proposed algorithms.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3038200",
                    "name": "Azade Nazi"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1754970",
                    "name": "Vagelis Hristidis"
                },
                {
                    "authorId": "47899254",
                    "name": "Nan Zhang"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "c61ab11d602e32f65e58774ca02452b93f795723",
            "title": "Scalable signal reconstruction for a broad range of applications",
            "abstract": "Signal reconstruction problem (SRP) is an important optimization problem where the objective is to identify a solution to an underdetermined system of linear equations that is closest to a given prior. It has a substantial number of applications in diverse areas, such as network traffic engineering, medical image reconstruction, acoustics, astronomy, and many more. Unfortunately, most of the common approaches for solving SRP do not scale to large problem sizes. We propose a novel and scalable algorithm for solving this critical problem. Specifically, we make four major contributions. First, we propose a dual formulation of the problem and develop the DIRECT algorithm that is significantly more efficient than the state of the art. Second, we show how adapting database techniques developed for scalable similarity joins provides a substantial speedup over DIRECT. Third, we describe several practical techniques that allow our algorithm to scale---on a single machine---to settings that are orders of magnitude larger than previously studied. Finally, we use the database techniques of materialization and reuse to extend our result to dynamic settings where the input to the SRP changes. Extensive experiments on real-world and synthetic data confirm the efficiency, effectiveness, and scalability of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "51124778",
                    "name": "Jees Augustine"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "3038200",
                    "name": "Azade Nazi"
                },
                {
                    "authorId": "2001017282",
                    "name": "Nan Zhang"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "145860176",
                    "name": "D. Srivastava"
                }
            ]
        },
        {
            "paperId": "480b7215ebfba27057b521e8a1fba88a2c15e8c7",
            "title": "Orca-SR",
            "abstract": "Reconstructing a high dimensional unknown signal, using lower dimensional observations is a challenging problem, known as signal reconstruction problem (SRP), with diverse applications including network traffic engineering, medical image reconstruction, and astronomy. Recently the database community has shown significant advancements in solving the SRP problem efficiently, effectively, and in scale by leveraging database techniques such as similarity joins. In this demo, we demonstrate Orca-SR that highlights the benefits of signal reconstruction in scale by demonstrating real-time network traffic flow analysis on large networks that were not possible before. Orca-SR is a web application that enables a user to generate network flow and load the network for interactive analysis of the impact of different traffic patterns on signal reconstruction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51124778",
                    "name": "Jees Augustine"
                },
                {
                    "authorId": "1442194534",
                    "name": "Suraj Shetiya"
                },
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "3038200",
                    "name": "Azade Nazi"
                },
                {
                    "authorId": "1596798563",
                    "name": "Nan Zhang"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "145860176",
                    "name": "D. Srivastava"
                }
            ]
        },
        {
            "paperId": "6aced7d7303fd82f8c4218aea2f3387efdf1d3c1",
            "title": "Making AI Machines Work for Humans in FoW",
            "abstract": "The Future of Work (FoW) is witnessing an evolution where AI systems (broadly machines or businesses) are used to the benefit of humans. Work here refers to all forms of paid and unpaid labor in both physical and virtual workplaces and that is enabled by AI systems. This covers crowdsourcing platforms such as Amazon Mechanical Turk, online labor marketplaces such as TaskRabbit and Qapa, but also regular jobs in physical workplaces. Bringing humans back to the frontier of FoW will increase their trust in AI systems and shift their perception to use them as a source of self-improvement, ensure better work performance, and positively shape social and economic outcomes of a society and a nation. To enable that, physical and virtual workplaces will need to capture human traits, behavior, evolving needs, and provide jobs to all. Attitudes, values, opinions regarding the processes and policies will need to be assessed and considered in the design of FoW ecosystems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2034201368",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2146072233",
                    "name": "Lei Chen"
                },
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                },
                {
                    "authorId": "2034202207",
                    "name": "James Abello Monedero"
                },
                {
                    "authorId": "1807924",
                    "name": "P. Bourhis"
                },
                {
                    "authorId": "2038513",
                    "name": "F. Charoy"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "1863248",
                    "name": "Shady Elbassuoni"
                },
                {
                    "authorId": "1403157540",
                    "name": "D. Gross-Amblard"
                },
                {
                    "authorId": "51493818",
                    "name": "Emilie Hoareau"
                },
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2034202198",
                    "name": "Jared Kenworthy"
                },
                {
                    "authorId": "7251192",
                    "name": "I. Kitahara"
                },
                {
                    "authorId": "2124213925",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "2069605832",
                    "name": "Raghav Rao"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "1734682",
                    "name": "P. Senellart"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1825255212",
                    "name": "M. Tommasi"
                },
                {
                    "authorId": "49697753",
                    "name": "Kazutoshi Umemoto"
                },
                {
                    "authorId": "144918359",
                    "name": "A. Wiggins"
                },
                {
                    "authorId": "2034178749",
                    "name": "Koichiro Yoshida"
                }
            ]
        },
        {
            "paperId": "f39fbfdeb4654fe78282adb0a5ef701efa955259",
            "title": "Deep Learning Models for Selectivity Estimation of Multi-Attribute Queries",
            "abstract": "Selectivity estimation - the problem of estimating the result size of queries - is a fundamental problem in databases. Accurate estimation of query selectivity involving multiple correlated attributes is especially challenging. Poor cardinality estimates could result in the selection of bad plans by the query optimizer. Recently, deep learning has been applied to this problem with promising results. However, many of the proposed approaches often struggle to provide accurate results for multi attribute queries involving large number of predicates and with low selectivity. In this paper, we propose two complementary approaches that are effective for this scenario. Our first approach models selectivity estimation as a density estimation problem where one seeks to estimate the joint probability distribution from a finite number of samples. We leverage techniques from neural density estimation to build an accurate selectivity estimator. The key idea is to decompose the joint distribution into a set of tractable conditional probability distributions such that they satisfy the autoregressive property. Our second approach formulates selectivity estimation as a supervised deep learning problem that predicts the selectivity of a given query. We describe how to extend our algorithms for range queries. We also introduce and address a number of practical challenges arising when adapting deep learning for relational data. These include query/data featurization, incorporating query workload information in a deep learning framework and the dynamic scenario where both data and workload queries could be updated. Our extensive experiments with a special emphasis on queries with a large number of predicates and/or small result sizes demonstrates that our proposed techniques provide fast and accurate selective estimates with minimal space overhead.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41177504",
                    "name": "Shohedul Hasan"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "51124778",
                    "name": "Jees Augustine"
                },
                {
                    "authorId": "1721062",
                    "name": "Nick Koudas"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "2f087ac94006b102d662b2a20525ca98d94caeff",
            "title": "A Unified Optimization Algorithm For Solving \"Regret-Minimizing Representative\" Problems",
            "abstract": "\n Given a database with numeric attributes, it is often of interest to rank the tuples according to linear scoring functions. For a scoring function and a subset of tuples, the\n regret\n of the subset is defined as the (relative) difference in scores between the top-1 tuple of the subset and the top-1 tuple of the entire database. Finding the\n regret-ratio minimizing set\n (RRMS), i.e., the subset of a required size\n k\n that minimizes the maximum regret-ratio across all possible ranking functions, has been a well-studied problem in recent years. This problem is known to be NP-complete and there are several approximation algorithms for it. Other NP-complete variants have also been investigated, e.g., finding the set of size\n k\n that minimizes the\n average regret ratio\n over all linear functions. Prior work have designed customized algorithms for different variants of the problem, and are unlikely to easily generalize to other variants.\n \n \n In this paper we take a different path towards tackling these problems. In contrast to the prior, we propose a unified algorithm for solving different problem variants. Unification is done by localizing the customization to the design of variant-specific subroutines or \"oracles\" that are called by our algorithm. Our unified algorithm takes inspiration from the seemingly unrelated problem of\n clustering\n from data mining, and the corresponding k-medoid algorithm. We make several innovative contributions in designing our algorithm, including various techniques such as linear programming, edge sampling in graphs, volume estimation of multi-dimensional convex polytopes, and several others. We provide rigorous theoretical analysis, as well as substantial experimental evaluations over real and synthetic data sets to demonstrate the practical feasibility of our approach.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1442194534",
                    "name": "Suraj Shetiya"
                },
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "2109248391",
                    "name": "Sadia Ahmed"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "3ec8dc534f86a69e079b360579ae6ac8f469c578",
            "title": "MithraRanking: A System for Responsible Ranking Design",
            "abstract": "Items from a database are often ranked based on a combination of criteria. The weight given to each criterion in the combination can greatly affect the ranking produced. Often, a user may have a general sense of the relative importance of the different criteria, but beyond this may have the flexibility, within limits, to choose combinations that weigh these criteria differently with an acceptable region. We demonstrate MithraRanking, a system that helps users choose criterion weights that lead to \"better'' rankings in terms of having desirable properties while remaining within the acceptable region. The goodness properties we focus on are stability and fairness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "148390943",
                    "name": "Yifan Guan"
                },
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                },
                {
                    "authorId": "147817633",
                    "name": "Pranav Mayuram"
                },
                {
                    "authorId": "145531067",
                    "name": "H. V. Jagadish"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "1729605",
                    "name": "G. Miklau"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "49ef2ab7502931e1cd7eb6c05600f697aa6d807f",
            "title": "A Human-in-the-loop Attribute Design Framework for Classification",
            "abstract": "In this paper, we present a semi-automated, \u201chuman-in-the-loop\u201d framework for attribute design that assists human analysts to transform raw attributes into effective derived attributes for classification problems. Our proposed framework is optimization guided and fully agnostic to the underlying classification model. We present an algebra with various operators (arithmetic, relational, and logical) to transform raw attributes into derived attributes and solve two technical problems: (a) the top-k buckets design problem aims at presenting human analysts with k buckets, each bucket containing promising choices of raw attributes that she can focus on only without having to look at all raw attributes; and (b) the top-l snippets generation problem, which iteratively aids human analysts with top-l derived attributes involving an attribute. For the former problem, we present an effective exact bottom-up algorithm that is empowered by pruning capability, as well as random walk based heuristic algorithms that are intuitive and work well in practice. For the latter, we present a greedy heuristic algorithm that is scalable and effective. Rigorous evaluations are conducted involving 6 different real world datasets to showcase that our framework generates effective derived attributes compared to fully manual or fully automated methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184184985",
                    "name": "Md. Abdus Salam"
                },
                {
                    "authorId": "1415163205",
                    "name": "Mary E. Koone"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1702973",
                    "name": "Senjuti Basu Roy"
                }
            ]
        }
    ]
}