{
    "authorId": "1793506",
    "papers": [
        {
            "paperId": "0c52a63de281d765b1b717cd91a099312251110f",
            "title": "Nested Fusion: A Method for Learning High Resolution Latent Structure of Multi-Scale Measurement Data on Mars",
            "abstract": "The Mars Perseverance Rover represents a generational change in the scale of measurements that can be taken on Mars, however this increased resolution introduces new challenges for techniques in exploratory data analysis. The multiple different instruments on the rover each measures specific properties of interest to scientists, so analyzing how underlying phenomena affect multiple different instruments together is important to understand the full picture. However each instrument has a unique resolution, making the mapping between overlapping layers of data non-trivial. In this work, we introduce Nested Fusion, a method to combine arbitrarily layered datasets of different resolutions and produce a latent distribution at the highest possible resolution, encoding complex interrelationships between different measurements and scales. Our method is efficient for large datasets, can perform inference even on unseen data, and outperforms existing methods of dimensionality reduction and latent analysis on real-world Mars rover data. We have deployed our method Nested Fusion within a Mars science team at NASA Jet Propulsion Laboratory (JPL) and through multiple rounds of participatory design enabled greatly enhanced exploratory analysis workflows for real scientists. To ensure the reproducibility of our work we have open sourced our code on GitHub at https://github.com/pixlise/NestedFusion.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2310415313",
                    "name": "Austin P. Wright"
                },
                {
                    "authorId": "1738513",
                    "name": "Scott Davidoff"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        },
        {
            "paperId": "2567248303c985014c4d5c8a1e86be2b8bfc8e05",
            "title": "LLM Attributor: Interactive Visual Attribution for LLM Generation",
            "abstract": "While large language models (LLMs) have shown remarkable capability to generate convincing text across diverse domains, concerns around its potential risks have highlighted the importance of understanding the rationale behind text generation. We present LLM Attributor, a Python library that provides interactive visualizations for training data attribution of an LLM's text generation. Our library offers a new way to quickly attribute an LLM's text generation to training data points to inspect model behaviors, enhance its trustworthiness, and compare model-generated text with user-provided text. We describe the visual and interactive design of our tool and highlight usage scenarios for LLaMA2 models fine-tuned with two different datasets: online articles about recent disasters and finance-related question-answer pairs. Thanks to LLM Attributor's broad support for computational notebooks, users can easily integrate it into their workflow to interactively visualize attributions of their models. For easier access and extensibility, we open-source LLM Attributor at https://github.com/poloclub/ LLM-Attribution. The video demo is available at https://youtu.be/mIG2MDQKQxM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284062521",
                    "name": "Seongmin Lee"
                },
                {
                    "authorId": "1390877819",
                    "name": "Zijie J. Wang"
                },
                {
                    "authorId": "2281636519",
                    "name": "Aishwarya Chakravarthy"
                },
                {
                    "authorId": "153223021",
                    "name": "Alec Helbling"
                },
                {
                    "authorId": "2131699192",
                    "name": "Sheng-Hsuan Peng"
                },
                {
                    "authorId": "2133413904",
                    "name": "Mansi Phute"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "1768057",
                    "name": "Minsuk Kahng"
                }
            ]
        },
        {
            "paperId": "4da54cfee0400707067c80fd23f8dafe523050c4",
            "title": "UniTable: Towards a Unified Framework for Table Recognition via Self-Supervised Pretraining",
            "abstract": "Tables convey factual and quantitative data with implicit conventions created by humans that are often challenging for machines to parse. Prior work on table recognition (TR) has mainly centered around complex task-specific combinations of available inputs and tools. We present UniTable, a training framework that unifies both the training paradigm and training objective of TR. Its training paradigm combines the simplicity of purely pixel-level inputs with the effectiveness and scalability empowered by self-supervised pretraining from diverse unannotated tabular images. Our framework unifies the training objectives of all three TR tasks - extracting table structure, cell content, and cell bounding box - into a unified task-agnostic training objective: language modeling. Extensive quantitative and qualitative analyses highlight UniTable's state-of-the-art (SOTA) performance on four of the largest TR datasets. UniTable's table parsing capability has surpassed both existing TR methods and general large vision-language models, e.g., GPT-4o, GPT-4-turbo with vision, and LLaVA. Our code is publicly available at https://github.com/poloclub/unitable, featuring a Jupyter Notebook that includes the complete inference pipeline, fine-tuned across multiple TR datasets, supporting all three TR tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131699192",
                    "name": "Sheng-Hsuan Peng"
                },
                {
                    "authorId": "2108642897",
                    "name": "Seongmin Lee"
                },
                {
                    "authorId": "2265796296",
                    "name": "Xiaojing Wang"
                },
                {
                    "authorId": "2243680191",
                    "name": "Rajarajeswari Balasubramaniyan"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        },
        {
            "paperId": "625e6a990b8ddc31c7bbb2731b36bdc242f2b040",
            "title": "Transformer Explainer: Interactive Learning of Text-Generative Models",
            "abstract": "Transformers have revolutionized machine learning, yet their inner workings remain opaque to many. We present Transformer Explainer, an interactive visualization tool designed for non-experts to learn about Transformers through the GPT-2 model. Our tool helps users understand complex Transformer concepts by integrating a model overview and enabling smooth transitions across abstraction levels of mathematical operations and model structures. It runs a live GPT-2 instance locally in the user's browser, empowering users to experiment with their own input and observe in real-time how the internal components and parameters of the Transformer work together to predict the next tokens. Our tool requires no installation or special hardware, broadening the public's education access to modern generative AI techniques. Our open-sourced tool is available at https://poloclub.github.io/transformer-explainer/. A video demo is available at https://youtu.be/ECR4oAwocjs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315298868",
                    "name": "Aeree Cho"
                },
                {
                    "authorId": "2315372268",
                    "name": "Grace C. Kim"
                },
                {
                    "authorId": "2315298044",
                    "name": "Alexander Karpekov"
                },
                {
                    "authorId": "153223021",
                    "name": "Alec Helbling"
                },
                {
                    "authorId": "1390877819",
                    "name": "Zijie J. Wang"
                },
                {
                    "authorId": "2284062521",
                    "name": "Seongmin Lee"
                },
                {
                    "authorId": "2315298895",
                    "name": "Benjamin Hoover"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        },
        {
            "paperId": "81b57d9d0fe41bec41d4a9d795dc2891ea438b20",
            "title": "Self-Supervised Pre-Training for Table Structure Recognition Transformer",
            "abstract": "Table structure recognition (TSR) aims to convert tabular images into a machine-readable format. Although hybrid convolutional neural network (CNN)-transformer architecture is widely used in existing approaches, linear projection transformer has outperformed the hybrid architecture in numerous vision tasks due to its simplicity and efficiency. However, existing research has demonstrated that a direct replacement of CNN backbone with linear projection leads to a marked performance drop. In this work, we resolve the issue by proposing a self-supervised pre-training (SSP) method for TSR transformers. We discover that the performance gap between the linear projection transformer and the hybrid CNN-transformer can be mitigated by SSP of the visual encoder in the TSR model. We conducted reproducible ablation studies and open-sourced our code at https://github.com/poloclub/unitable to enhance transparency, inspire innovations, and facilitate fair comparisons in our domain as tables are a promising modality for representation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131699192",
                    "name": "Sheng-Hsuan Peng"
                },
                {
                    "authorId": "2108642897",
                    "name": "Seongmin Lee"
                },
                {
                    "authorId": "2265796296",
                    "name": "Xiaojing Wang"
                },
                {
                    "authorId": "2243680191",
                    "name": "Rajarajeswari Balasubramaniyan"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        },
        {
            "paperId": "913ffd0a2e7f794e9b2e60b9728673044be47b2a",
            "title": "T-NET: Weakly Supervised Graph Learning for Combatting Human Trafficking",
            "abstract": "Human trafficking (HT) for forced sexual exploitation, often described as modern-day slavery, is a pervasive problem that affects millions of people worldwide. Perpetrators of this crime post advertisements (ads) on behalf of their victims on adult service websites (ASW). These websites typically contain hundreds of thousands of ads including those posted by independent escorts, massage parlor agencies and spammers (fake ads). Detecting suspicious activity in these ads is difficult and developing data-driven methods is challenging due to the hard-to-label, complex and sensitive nature of the data. \n\nIn this paper, we propose T-Net, which unlike previous solutions, formulates this problem as weakly supervised classification. Since it takes several months to years to investigate a case and obtain a single definitive label, we design domain-specific signals or indicators that provide weak labels. T-Net also looks into connections between ads and models the problem as a graph learning task instead of classifying ads independently. We show that T-Net outperforms all baselines on a real-world dataset of ads by 7% average weighted F1 score. Given that this data contains personally identifiable information, we also present a realistic data generator and provide the first publicly available dataset in this domain which may be leveraged by the wider research community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48761500",
                    "name": "Pratheeksha Nair"
                },
                {
                    "authorId": "2273909422",
                    "name": "Javin Liu"
                },
                {
                    "authorId": "46260548",
                    "name": "Catalina Vajiac"
                },
                {
                    "authorId": "3254065",
                    "name": "Andreas M. Olligschlaeger"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2115254512",
                    "name": "Cara Jones"
                },
                {
                    "authorId": "2256724188",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2490772",
                    "name": "Reihaneh Rabbany"
                }
            ]
        },
        {
            "paperId": "9c71f49f5bb6fb916423e36acd8be3155a6fddb6",
            "title": "Wordflow: Social Prompt Engineering for Large Language Models",
            "abstract": "Large language models (LLMs) require well-crafted prompts for effective use. Prompt engineering, the process of designing prompts, is challenging, particularly for non-experts who are less familiar with AI technologies. While researchers have proposed techniques and tools to assist LLM users in prompt design, these works primarily target AI application developers rather than non-experts. To address this research gap, we propose social prompt engineering, a novel paradigm that leverages social computing techniques to facilitate collaborative prompt design. To investigate social prompt engineering, we introduce Wordflow, an open-source and social text editor that enables everyday users to easily create, run, share, and discover LLM prompts. Additionally, by leveraging modern web technologies, Wordflow allows users to run LLMs locally and privately in their browsers. Two usage scenarios highlight how social prompt engineering and our tool can enhance laypeople's interaction with LLMs. Wordflow is publicly accessible at https://poloclub.github.io/wordflow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390877819",
                    "name": "Zijie J. Wang"
                },
                {
                    "authorId": "2281636519",
                    "name": "Aishwarya Chakravarthy"
                },
                {
                    "authorId": "2164382097",
                    "name": "David Munechika"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        },
        {
            "paperId": "a53732d81b53af703fc04d516cf197b8fd9b4ed2",
            "title": "An Interrogative Survey of Explainable AI in Manufacturing",
            "abstract": "Artificial intelligence (AI) is a driving force behind Industry 4.0 in manufacturing. Specifically, machine learning has been applied to all parts of the manufacturing process: from product design optimization to anomaly detection for quality control. Explainable AI (XAI) and interpretable AI (IAI) methods have been developed to provide transparency into how models make decisions. This survey presents a thorough review of who, what, when, where, why, and how both IAI and XAI methods have been used in manufacturing. Due to the multidisciplinary nature of manufacturing, this work provides the results from a systematic literature review that surveyed papers from highly rated venues in multiple manufacturing and AI-related fields to give the reader a holistic view of the space. This survey is intended to help both individuals from academia and industry quickly understand the applications, areas of research, and future work involved with creating explainable industrial solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186684045",
                    "name": "Zoe Alexander"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "2289555636",
                    "name": "Christopher Salda\u00f1a"
                }
            ]
        },
        {
            "paperId": "ab7b7d2e3330432f85978728ca68104bfe615f5b",
            "title": "MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation",
            "abstract": "Retrieval-augmented text generation (RAG) addresses the common limitations of large language models (LLMs), such as hallucination, by retrieving information from an updatable external knowledge base. However, existing approaches often require dedicated backend servers for data storage and retrieval, thereby limiting their applicability in use cases that require strict data privacy, such as personal finance, education, and medicine. To address the pressing need for client-side dense retrieval, we introduce MeMemo, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments. Developed with modern and native Web technologies, such as IndexedDB and Web Workers, our toolkit leverages client-side hardware capabilities to enable researchers and developers to efficiently search through millions of high-dimensional vectors in the browser. MeMemo enables exciting new design and research opportunities, such as private and personalized content creation and interactive prototyping, as demonstrated in our example application RAG Playground. Reflecting on our work, we discuss the opportunities and challenges for on-device dense retrieval. MeMemo is available at https://github.com/poloclub/mememo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390877819",
                    "name": "Zijie J. Wang"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        },
        {
            "paperId": "ce707711e8539d74fce82222e822eaf7f59b4b0a",
            "title": "Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models",
            "abstract": "Safety alignment is the key to guiding the behaviors of large language models (LLMs) that are in line with human preferences and restrict harmful behaviors at inference time, but recent studies show that it can be easily compromised by finetuning with only a few adversarially designed training examples. We aim to measure the risks in finetuning LLMs through navigating the LLM safety landscape. We discover a new phenomenon observed universally in the model parameter space of popular open-source LLMs, termed as\"safety basin\": randomly perturbing model weights maintains the safety level of the original aligned model in its local neighborhood. Our discovery inspires us to propose the new VISAGE safety metric that measures the safety in LLM finetuning by probing its safety landscape. Visualizing the safety landscape of the aligned model enables us to understand how finetuning compromises safety by dragging the model away from the safety basin. LLM safety landscape also highlights the system prompt's critical role in protecting a model, and that such protection transfers to its perturbed variants within the safety basin. These observations from our safety landscape research provide new insights for future work on LLM safety community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131699192",
                    "name": "Sheng-Hsuan Peng"
                },
                {
                    "authorId": "2303433297",
                    "name": "Pin-Yu Chen"
                },
                {
                    "authorId": "2070368863",
                    "name": "Matthew Hull"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                }
            ]
        }
    ]
}