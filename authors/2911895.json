{
    "authorId": "2911895",
    "papers": [
        {
            "paperId": "18cd294d4dff873a9bc22ae665cb95adecab8786",
            "title": "Compressed Interaction Graph based Framework for Multi-behavior Recommendation",
            "abstract": "Multi-types of user behavior data (e.g., clicking, adding to cart, and purchasing) are recorded in most real-world recommendation scenarios, which can help to learn users\u2019 multi-faceted preferences. However, it is challenging to explore multi-behavior data due to the unbalanced data distribution and sparse target behavior, which lead to the inadequate modeling of high-order relations when treating multi-behavior data \u201cas features\u201d and gradient conflict in multi-task learning when treating multi-behavior data \u201cas labels\u201d. In this paper, we propose CIGF, a Compressed Interaction Graph based Framework, to overcome the above limitations. Specifically, we design a novel Compressed Interaction Graph Convolution Network (CIGCN) to model instance-level high-order relations explicitly. To alleviate the potential gradient conflict when treating multi-behavior data \u201cas labels\u201d, we propose a Multi-Expert with Separate Input (MESI) network with separate input on the top of CIGCN for multi-task learning. Comprehensive experiments on three large-scale real-world datasets demonstrate the superiority of CIGF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109155646",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "2180167214",
                    "name": "Chang Meng"
                },
                {
                    "authorId": "1601384914",
                    "name": "Enming Yuan"
                },
                {
                    "authorId": "2175453540",
                    "name": "Zhicheng He"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2202596977",
                    "name": "Xiufeng Li"
                },
                {
                    "authorId": "144142354",
                    "name": "Rui Zhang"
                }
            ]
        },
        {
            "paperId": "227b5bfafb7e67cacc3cedc371c902c3c084a2c0",
            "title": "Preference and Concurrence Aware Bayesian Graph Neural Networks for Recommender Systems",
            "abstract": "Graph-based collaborative filtering methods have prevailing performance for recommender systems since they can capture high-order information between users and items, in which the graphs are constructed from the observed user-item interactions that might miss links or contain spurious positive interactions in industrial scenarios. The Bayesian Graph Neural Network framework approaches this issue with generative models for the interaction graphs. The critical problem is to devise a proper family of graph generative models tailored to recommender systems. We propose an efficient generative model that jointly considers the preferences of users, the concurrence of items and some important graph structure information. Experiments on four popular benchmark datasets demonstrate the effectiveness of our proposed graph generative methods for recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275157392",
                    "name": "Hongjian Gu"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2275529643",
                    "name": "Yingxue Zhang"
                }
            ]
        },
        {
            "paperId": "5fb82c52898e1721489a8e2fd8ff64ad6434ae72",
            "title": "A Survey on User Behavior Modeling in Recommender Systems",
            "abstract": "User Behavior Modeling (UBM) plays a critical role in user interest learning, which has been extensively used in recommender systems. Crucial interactive patterns between users and items have been exploited, which brings compelling improvements in many recommendation tasks. In this paper, we attempt to provide a thorough survey of this research topic. We start by reviewing the research background of UBM. Then, we provide a systematic taxonomy of existing UBM research works, which can be categorized into four different directions including Conventional UBM, Long-Sequence UBM, Multi-Type UBM, and UBM with Side Information. Within each direction, representative models and their strengths and weaknesses are comprehensively discussed. Besides, we elaborate on the industrial practices of UBM methods with the hope of providing insights into the application value of existing UBM solutions. Finally, we summarize the survey and discuss the future prospects of this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175453540",
                    "name": "Zhicheng He"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2109155646",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "79494403",
                    "name": "Jiarui Qin"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "a29b6af13601d6cf439c951a99808e2ba209ced6",
            "title": "Towards Automated Negative Sampling in Implicit Recommendation",
            "abstract": "Negative sampling methods are vital in implicit recommendation models as they allow us to obtain negative instances from massive unlabeled data. Most existing approaches focus on sampling hard negative samples in various ways. These studies are orthogonal to the recommendation model and implicit datasets. However, such an idea contradicts the common belief in AutoML that the model and dataset should be matched. Empirical experiments suggest that the best-performing negative sampler depends on the implicit dataset and the specific recommendation model. Hence, we propose a hypothesis that the negative sampler should align with the capacity of the recommendation models as well as the statistics of the datasets to achieve optimal performance. A mismatch between these three would result in sub-optimal outcomes. An intuitive idea to address the mismatch problem is to exhaustively select the best-performing negative sampler given the model and dataset. However, such an approach is computationally expensive and time-consuming, leaving the problem unsolved. In this work, we propose the AutoSample framework that adaptively selects the best-performing negative sampler among candidates. Specifically, we propose a loss-to-instance approximation to transform the negative sampler search task into the learning task over a weighted sum, enabling end-to-end training of the model. We also designed an adaptive search algorithm to extensively and efficiently explore the search space. A specific initialization approach is also obtained to better utilize the obtained model parameters during the search stage, which is similar to curriculum learning and leads to better performance and less computation resource consumption. We evaluate the proposed framework on four benchmarks over three models. Extensive experiments demonstrate the effectiveness and efficiency of our proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1704274486",
                    "name": "Fuyuan Lyu"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2274302690",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "2265583881",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2188246843",
                    "name": "Xue Liu"
                }
            ]
        },
        {
            "paperId": "1d67fee0219486ec076e85f1c94ba09969a9aa8f",
            "title": "Dual Path Graph Convolutional Networks",
            "abstract": "Graph Convolutional Networks (GCNs) are a powerful approach for learning graph representations and show promising results in various applications. Despite their success, they are usually limited to shallow architectures due to the vanishing gradients, over-smoothing, and over-squashing problems. As Convolutional Neural Networks benefit tremendously from stacking very deep layers, recently techniques such as various types of residual connections and dense connections are proposed to tackle these problems and make GCNs go deeper. In this work, we further study the problem of designing deep architectures for GCNs. Firstly, we introduce the Higher Order Graph Recurrent Networks (HOGRNs), which can unify most existing architectures of GCNs. Then we show that ResGCN and DenseGCN are special cases of HOGRNs. To enjoy the benefits from both residual connections and dense connections and compensate for the drawbacks from each other, we propose Dual Path Graph Convolutional Networks (DPGCNs), which exploit a new topology of connection paths internally. In DPGCNs, we maintain both a residual path and a densely connected path while learning the graph representations. Extensive experiments on OGB datasets demonstrate superior performances of the proposed DPGCNs over competitive baseline methods on the large-scale graph learning tasks of node property prediction and graph property prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110470358",
                    "name": "Yunhe Li"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2108467161",
                    "name": "Yingxue Zhang"
                }
            ]
        },
        {
            "paperId": "8ea804423af4e3d0d9f8486d477a89c334c1fcb6",
            "title": "EFLEC: Efficient Feature-LEakage Correction in GNN based Recommendation Systems",
            "abstract": "Graph Convolutional Neural Networks (GNN) based recommender systems are state-of-the-art since they can capture the high order collaborative signals between users and items. However, they suffer from the feature leakage problem since label information determined by edges can be leaked into node embeddings through the GNN aggregation procedure guided by the same set of edges, leading to poor generalization. We propose the accurate removal algorithm to generate the final embedding. For each edge, the embeddings of the two end nodes are evaluated on a graph with that edge removed. We devise an algebraic trick to efficiently compute this procedure without explicitly constructing separate graphs for the LightGCN model. Experiments on four datasets demonstrate that our algorithm can perform better on datasets with sparse interactions, while the training time is significantly reduced.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175277508",
                    "name": "I. Kumar"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                }
            ]
        },
        {
            "paperId": "dbe326f520423d4d8311acb9dcbedc3ef19ecc8d",
            "title": "SCL-Net: An End-to-End Supervised Contrastive Learning Network for Hyperspectral Image Classification",
            "abstract": "In recent years, deep learning (DL) presents a promising performance in hyperspectral image (HSI) classification, due to the powerful capability of automatically learning deep semantic characteristics of images. However, it is still difficult to learn highly discriminative features when limited samples are available for training a deep network. Focused on this issue, a novel end-to-end supervised contrastive learning network (SCL-Net) for spectral\u2013spatial classification is proposed, in this article. Instead of learning features of the individual sample, the supervised contrastive learning is introduced to capture the similarity and dissimilarity distribution properties of sample pairs in a feature representation space. In this way, the need for plenty of training samples will be alleviated while an effective network training mechanism is provided for learning highly separative features. Here, SCL-Net mainly consists of one pairwise contrastive learning (PCL) subnetwork and one multilevel spectral\u2013spatial information fusion (MLSIF) subnetwork. For the PCL subnetwork, spectral vectors are projected into deep spectral features based on convolutional operators, which are then followed by distance evaluation between \u201cpositive\u201d pairs of similar samples and \u201cnegative\u201d pairs of dissimilar ones. Then, a spectral distance matrix is constructed to push the network to gradually learn better features of higher intraclass compactness and interclass dispersion. For the MLSIF subnetwork, a hybrid feature-decision fusion strategy is designed, where spatial and spectral features are jointly exploited to further boost the classification performance. In specific, feature fusion is conducted by connecting low/mid/high-level spectral and spatial features via weighting, while multiple class estimations based on multilevel fusion features are adaptively integrated via probabilistic decision fusion. Overall, these two subnetworks are collaboratively trained in one framework, by optimizing a defined joint loss function consisting of a contrastive loss and a cross-entropy loss. Compared with several state-of-the-art methods, the proposed method yields a superior classification performance in terms of both objective metrics and visual performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144884678",
                    "name": "Ting Lu"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2068321912",
                    "name": "Wei Fu"
                },
                {
                    "authorId": "2128911389",
                    "name": "Kexin Ding"
                },
                {
                    "authorId": "2134716472",
                    "name": "Beifang Bai"
                },
                {
                    "authorId": "38140728",
                    "name": "Leyuan Fang"
                }
            ]
        },
        {
            "paperId": "6738227730044fedd76b98b335d542e242c01b9f",
            "title": "Graph Representation Learning via Adversarial Variational Bayes",
            "abstract": "Methods that learn representations of nodes in a graph play an important role in network analysis. Most of the existing methods of graph representation learning have focused on embedding each node in a graph as a single vector in a low-dimensional continuous space. However, these methods have a crucial limitation: the lack of modeling the uncertainty about the representation. In this work, inspired by Adversarial Variational Bayes (AVB) [22], we propose GraphAVB, a probabilistic generative model to learn node representations that preserve connectivity patterns and capture the uncertainties in the graph. Unlike Graph2Gauss [3] deep which embeds each node as a Gaussian distribution, we represent each node as an implicit distribution parameterized by a neural network in the latent space, which is more flexible and expressive to capture the complex uncertainties in real-world graph-structured datasets. To perform the designed variational inference algorithm with neural samplers, we introduce an auxiliary discriminative network that is used to infer the log probability ratio terms in the objective function and allows us to cast maximizing the objective function as a two-player game. Experimental results on multiple real-world graph datasets demonstrate the effectiveness of our proposed method GraphAVB, outperforming many competitive baselines on the task of link prediction. The superior performances of our proposed method GraphAVB also demonstrate that the downstream tasks can benefit from the captured uncertainty.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110470358",
                    "name": "Yunhe Li"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2135319291",
                    "name": "Yingxue Zhang"
                }
            ]
        },
        {
            "paperId": "6b65f02a0b4826b5b26ea0ed5fdefebeda76c597",
            "title": "A Framework for Recommending Accurate and Diverse Items Using Bayesian Graph Convolutional Neural Networks",
            "abstract": "Personalized recommender systems are playing an increasingly important role for online consumption platforms. Because of the multitude of relationships existing in recommender systems, Graph Neural Networks (GNNs) based approaches have been proposed to better characterize the various relationships between a user and items while modeling a user's preferences. Previous graph-based recommendation approaches process the observed user-item interaction graph as a ground-truth depiction of the relationships between users and items. However, especially in the implicit recommendation setting, all the unobserved user-item interactions are usually assumed to be negative samples. There are missing links that represent a user's future actions. In addition, there may be spurious or misleading positive interactions. To alleviate the above issue, in this work, we take a first step to introduce a principled way to model the uncertainty in the user-item interaction graph using the Bayesian Graph Convolutional Neural Network framework. We discuss how inference can be performed under our framework and provide a concrete formulation using the Bayesian Probabilistic Ranking training loss. We demonstrate the effectiveness of our proposed framework on four benchmark recommendation datasets. The proposed method outperforms state-of-the-art graph-based recommendation models. Furthermore, we conducted an offline evaluation on one industrial large-scale dataset. It shows that our proposed method outperforms the baselines, with the potential gain being more significant for cold-start users. This illustrates the potential practical benefit in real-world recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "121606808",
                    "name": "Jianing Sun"
                },
                {
                    "authorId": "2109155646",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "2109955353",
                    "name": "Dengcheng Zhang"
                },
                {
                    "authorId": "2108467161",
                    "name": "Yingxue Zhang"
                },
                {
                    "authorId": "1388386548",
                    "name": "Florence Regol"
                },
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2114129084",
                    "name": "Han Yuan"
                },
                {
                    "authorId": "1996703",
                    "name": "Xiuqiang He"
                },
                {
                    "authorId": "144819383",
                    "name": "M. Coates"
                }
            ]
        },
        {
            "paperId": "083c3f5b87c05c44ff92e04fdf1aba64fd1c290e",
            "title": "Learning Privately over Distributed Features: An ADMM Sharing Approach",
            "abstract": "Distributed machine learning has been widely studied in order to handle exploding amount of data. In this paper, we study an important yet less visited distributed learning problem where features are inherently distributed or vertically partitioned among multiple parties, and sharing of raw data or model parameters among parties is prohibited due to privacy concerns. We propose an ADMM sharing framework to approach risk minimization over distributed features, where each party only needs to share a single value for each sample in the training process, thus minimizing the data leakage risk. We establish convergence and iteration complexity results for the proposed parallel ADMM algorithm under non-convex loss. We further introduce a novel differentially private ADMM sharing algorithm and bound the privacy guarantee with carefully designed noise perturbation. The experiments based on a prototype system shows that the proposed ADMM algorithms converge efficiently in a robust fashion, demonstrating advantage over gradient based methods especially for data set with high dimensional feature spaces.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2911895",
                    "name": "Yaochen Hu"
                },
                {
                    "authorId": "2108283727",
                    "name": "Peng Liu"
                },
                {
                    "authorId": "2515229",
                    "name": "Linglong Kong"
                },
                {
                    "authorId": "1714907",
                    "name": "Di Niu"
                }
            ]
        }
    ]
}