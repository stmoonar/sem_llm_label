{
    "authorId": "1795727",
    "papers": [
        {
            "paperId": "282719c497bc3241727294db2a6f5d8131f77998",
            "title": "Detecting Intents of Fake News Using Uncertainty-Aware Deep Reinforcement Learning",
            "abstract": "Intent mining is critical for controlling the spread of false information across online social networks (OSNs). To this end, we develop deep reinforcement learning (DRL) agents guided by a delayed reward based on intent prediction using a classifier of long short-term memory (LSTM). Additionally, we incorporate an uncertainty-aware function that leverages subjective opinions derived from Subjective Logic (SL). Through evaluation using an annotated fake news tweet dataset, our results demonstrate that our intent classification framework surpasses competing methods in terms of intent accuracy. Our intent mining solutions using DRL algorithms can support effective and efficient intervention strategies for fake news spreading on OSNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149504682",
                    "name": "Zhen Guo"
                },
                {
                    "authorId": "2256972676",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2139528527",
                    "name": "Qisheng Zhang"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "9130998",
                    "name": "A. J\u00f8sang"
                },
                {
                    "authorId": "144180429",
                    "name": "F. Chen"
                },
                {
                    "authorId": "2147315661",
                    "name": "Dong-Ho Jeong"
                },
                {
                    "authorId": "2148374177",
                    "name": "Jin-Hee Cho"
                }
            ]
        },
        {
            "paperId": "46e6742894b6438ebe393999e7f2ce74e33c4aa6",
            "title": "A Survey on Uncertainty Reasoning and Quantification for Decision Making: Belief Theory Meets Deep Learning",
            "abstract": "An in-depth understanding of uncertainty is the first step to making effective decisions under uncertainty. Deep/machine learning (ML/DL) has been hugely leveraged to solve complex problems involved with processing high-dimensional data. However, reasoning and quantifying different types of uncertainties to achieve effective decision-making have been much less explored in ML/DL than in other Artificial Intelligence (AI) domains. In particular, belief/evidence theories have been studied in KRR since the 1960s to reason and measure uncertainties to enhance decision-making effectiveness. We found that only a few studies have leveraged the mature uncertainty research in belief/evidence theories in ML/DL to tackle complex problems under different types of uncertainty. In this survey paper, we discuss several popular belief theories and their core ideas dealing with uncertainty causes and types and quantifying them, along with the discussions of their applicability in ML/DL. In addition, we discuss three main approaches that leverage belief theories in Deep Neural Networks (DNNs), including Evidential DNNs, Fuzzy DNNs, and Rough DNNs, in terms of their uncertainty causes, types, and quantification methods along with their applicability in diverse problem domains. Based on our in-depth survey, we discuss insights, lessons learned, limitations of the current state-of-the-art bridging belief theories and ML/DL, and finally, future research directions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2149504682",
                    "name": "Zhen Guo"
                },
                {
                    "authorId": "116992328",
                    "name": "Zelin Wan"
                },
                {
                    "authorId": "2139528527",
                    "name": "Qisheng Zhang"
                },
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "144180429",
                    "name": "F. Chen"
                },
                {
                    "authorId": "2148374177",
                    "name": "Jin-Hee Cho"
                },
                {
                    "authorId": null,
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "2147315661",
                    "name": "Dong-Ho Jeong"
                },
                {
                    "authorId": "9130998",
                    "name": "A. J\u00f8sang"
                }
            ]
        },
        {
            "paperId": "ed40287323c835bb1047e384701d137a497c5b7f",
            "title": "Interactive Web-Based Visual Analysis on Network Traffic Data",
            "abstract": "Network traffic data analysis is important for securing our computing environment and data. However, analyzing network traffic data requires tremendous effort because of the complexity of continuously changing network traffic patterns. To assist the user in better understanding and analyzing the network traffic data, an interactive web-based visualization system is designed using multiple coordinated views, supporting a rich set of user interactions. For advancing the capability of analyzing network traffic data, feature extraction is considered along with uncertainty quantification to help the user make precise analyses. The system allows the user to perform a continuous visual analysis by requesting incrementally new subsets of data with updated visual representation. Case studies have been performed to determine the effectiveness of the system. The results from the case studies support that the system is well designed to understand network traffic data by identifying abnormal network traffic patterns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32106723",
                    "name": "D. Jeong"
                },
                {
                    "authorId": "2148374177",
                    "name": "Jin-Hee Cho"
                },
                {
                    "authorId": "144180429",
                    "name": "F. Chen"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "9130998",
                    "name": "A. J\u00f8sang"
                },
                {
                    "authorId": "2173335",
                    "name": "Soo-Yeon Ji"
                }
            ]
        },
        {
            "paperId": "542bc41d09daf8bf9dacd995634687d83626634d",
            "title": "Coalition situational understanding via explainable neuro-symbolic reasoning and learning",
            "abstract": "Recent years have seen significant advances in artificial intelligence (AI) and machine learning (ML) technologies applicable to coalition situational understanding (CSU). However, state-of-the-art ML techniques based on deep neural networks require large volumes of training data; unfortunately, representative training examples of situations of interest in CSU are usually sparse. Moreover, to be useful, ML-based analytic services must be capable of explaining their outputs. We describe an integrated CSU architecture that combines neural networks with symbolic learning and reasoning to address the problem of sparse training data. We also demonstrate how explainability can be achieved for deep neural networks operating on multimodal sensor feeds. The work focuses on real-time decision making settings at the tactical edge, with both the symbolic and neural network parts of the system --- including the explainabilty approaches --- able to deal with temporal features.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1762890",
                    "name": "A. Preece"
                },
                {
                    "authorId": "2215679",
                    "name": "Dave Braines"
                },
                {
                    "authorId": "133946249",
                    "name": "Federico Cerutti"
                },
                {
                    "authorId": "1944881984",
                    "name": "Jack Furby"
                },
                {
                    "authorId": "151473559",
                    "name": "Liam Hiley"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "46264950",
                    "name": "Mark Law"
                },
                {
                    "authorId": "145277911",
                    "name": "A. Russo"
                },
                {
                    "authorId": "1702254",
                    "name": "M. Srivastava"
                },
                {
                    "authorId": "147627782",
                    "name": "Marc Roig Vilamala"
                },
                {
                    "authorId": "2774212",
                    "name": "Tianwei Xing"
                }
            ]
        },
        {
            "paperId": "6604b23e6bdc014111abc837472462c830c6e981",
            "title": "DeepSQA: Understanding Sensor Data via Question Answering",
            "abstract": "The ubiquity of mobile, wearable, and IoT devices enhances humans with a network of environmental sensors. These devices capture raw, time-series measurements of scalar physical phenomena. To transform the data into human-digestible representations, deep learning methods have enabled high-level interpretations of the opaque raw sensory data. However, interfacing models with humans requires flexibility to support the vast database of human inquiries about sensor data. Deep learning models are usually trained to perform fixed tasks, limiting the inference outputs to a predefined set of high-level labels. To enable flexible inference, we introduce DeepSQA, a generalized Sensory Question Answering (SQA) framework that aims to enable natural language questions about raw sensory data in distributed and heterogeneous IoT networks. Given a sensory data context and a natural language question about the data, the task is to provide an accurate natural language answer. In addition to the DeepSQA, we create SQA-Gen, a software framework for generating SQA datasets using labeled source sensory data, and also generate OppQA with SQA-Gen for benchmarking different SQA models. We evaluate DeepSQA across several state-of-the-art QA models and lay the foundation and challenges for future SQA research. We further provide open-source implementations of the framework, the dataset generation tool, and access to the generated dataset, to help facilitate research on the SQA problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2774212",
                    "name": "Tianwei Xing"
                },
                {
                    "authorId": "2094951808",
                    "name": "L. Garcia"
                },
                {
                    "authorId": "133946249",
                    "name": "Federico Cerutti"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "1762890",
                    "name": "A. Preece"
                },
                {
                    "authorId": "1702254",
                    "name": "M. Srivastava"
                }
            ]
        },
        {
            "paperId": "69e270286adc4aa0d04770ca8ca17e93c1bcf6e2",
            "title": "Robust uncertainty representation in human-AI collaboration",
            "abstract": "Uncertainty represents the quantification of the spread of the distribution of possible ground truths that can be inferred from observed evidence. As such, uncertainty is one of the major factors in determining confidence when making decisions (i.e., uncertainty and confidence are in an inverse relationship). Bayesian statistics and subjective logic provide tools for Artificial Intelligence (AI) to derive uncertainty quantification. These processes require base rates, which are large-population determinations of probabilities that are not contextualized for the specific situation. The AI computes probabilities based upon the specific situation and context in light of historical (or training) data. As more evidence/training data is available for the context, the base rate gets washed out in the probability calculation. For most Army applications, an AI does not act or decide on its own with the rare exception of complete automaticity, but rather in collaboration with at least one human user. In this paper, we propose that the ways AI represents uncertainty ought to be optimally aligned with human preferences to provide best possible human-AI collaborative performance. Exploring this topic requires human-subjects experimentation to test how well users understand different representations of uncertainty that include base-rate information, which quantifies belief in predictions. Variations of these experiments could include different types of training to interpret uncertainty representations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2051193",
                    "name": "Daniel N. Cassenti"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                }
            ]
        },
        {
            "paperId": "800e273d2e122d81d576bec52d68b25283caaff0",
            "title": "Truth Discovery With Multi-Modal Data in Social Sensing",
            "abstract": "This article proposes unsupervised truth-finding algorithms that combine consideration of multi-modal content features with analysis of propagation patterns to evaluate the veracity of observations in social sensing applications. A key social sensing challenge is to develop effective algorithms for estimating both the reliability of sources and the veracity of their observations without prior knowledge. In contrast to prior solutions that use labeled examples to learn content features that are correlated with veracity, our approach is entirely unsupervised. Hence, given no prior training data, we jointly learn the importance of different content features together with the veracity of observations using propagation patterns as an indicator of perceived content reliability. A novel penalized expectation maximization (PEM) algorithm is proposed to improve the quality of estimation results for observations bolstered by multiple features. In addition, we develop a constrained expectation maximum likelihood with multiple features (CEM-MultiF) that introduces a novel constraint to boost the probability of correctness of some claims. Finally, we evaluate the performance of the proposed algorithms, called EM-Multi, CEM-Multi and PEM-MultiF, respectively, on real-world data sets collected from Twitter. The evaluation results demonstrate that the proposed algorithms outperform the existing fact-finding approaches, and offer tunable knobs for controlling robustness/performance trade-offs in the presence of malicious sources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3395273",
                    "name": "Huajie Shao"
                },
                {
                    "authorId": "1630209136",
                    "name": "Dachun Sun"
                },
                {
                    "authorId": "2325031",
                    "name": "Shuochao Yao"
                },
                {
                    "authorId": "143843304",
                    "name": "Lu Su"
                },
                {
                    "authorId": "3623271",
                    "name": "Zhibo Wang"
                },
                {
                    "authorId": "153626198",
                    "name": "Dongxin Liu"
                },
                {
                    "authorId": "1390628682",
                    "name": "Shengzhong Liu"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "1730531",
                    "name": "T. Abdelzaher"
                }
            ]
        },
        {
            "paperId": "c9c96bb4f2b0f3b6f29122affa977de75806f55a",
            "title": "Augmenting saliency maps with uncertainty",
            "abstract": "Explanations are generated to accompany a model decision indicating features of the input data that were the most relevant towards the model decision. Explanations are important not only for understanding the decisions of deep neural network, which in spite of their their huge success in multiple domains operate largely as abstract black boxes, but also for other model classes such as gradient boosted decision trees. In this work, we propose methods, using both Bayesian and Non-Bayesian approaches to augment explanations with uncertainty scores. We believe that uncertainty augmented saliency maps can help in better calibration of the trust between human analyst and the machine learning models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "144387904",
                    "name": "Supriyo Chakraborty"
                },
                {
                    "authorId": "1804334",
                    "name": "Prudhvi K. Gurram"
                },
                {
                    "authorId": "1678308",
                    "name": "Franck Le"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "50998197",
                    "name": "Richard J. Tomsett"
                }
            ]
        },
        {
            "paperId": "138283c516fbab3bec9fee5e2e75b9f7d10aa9f3",
            "title": "Neuroplex: learning to detect complex events in sensor networks through knowledge injection",
            "abstract": "Despite the remarkable success in a broad set of sensing applications, state-of-the-art deep learning techniques struggle with complex reasoning tasks across a distributed set of sensors. Unlike recognizing transient complex activities (e.g., human activities such as walking or running) from a single sensor, detecting more complex events with larger spatial and temporal dependencies across multiple sensors is extremely difficult, e.g., utilizing a hospital's sensor network to detect whether a nurse is following a sanitary protocol as they traverse from patient to patient. Training a more complicated model requires a larger amount of data-which is unrealistic considering complex events rarely happen in nature. Moreover, neural networks struggle with reasoning about serial, aperiodic events separated by large quantities in the spatial-temporal dimensions. We propose Neuroplex, a neural-symbolic framework that learns to perform complex reasoning on raw sensory data with the help of high-level, injected human knowledge. Neuroplex decomposes the entire complex learning space into explicit perception and reasoning layers, i.e., by maintaining neural networks to perform low-level perception tasks and neurally reconstructed reasoning models to perform high-level, explainable reasoning. After training the neurally reconstructed reasoning model using human knowledge, Neuroplex allows effective end-to-end training of perception models with an additional semantic loss using only sparse, high-level annotations. Our experiments and evaluation show that Neuroplex is capable of learning to efficiently and effectively detect complex events-which cannot be handled by state-of-the-art neural network models. During the training, Neuroplex not only reduces data annotation requirements by 100x, but also significantly speeds up the learning process for complex event detection by 4x.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2774212",
                    "name": "Tianwei Xing"
                },
                {
                    "authorId": "2094951808",
                    "name": "L. Garcia"
                },
                {
                    "authorId": "147627782",
                    "name": "Marc Roig Vilamala"
                },
                {
                    "authorId": "133946249",
                    "name": "Federico Cerutti"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "1762890",
                    "name": "A. Preece"
                },
                {
                    "authorId": "1702254",
                    "name": "M. Srivastava"
                }
            ]
        },
        {
            "paperId": "182c6dcfa94d2c4eac377ccbd35f5b20701520a3",
            "title": "A Hybrid Neuro-Symbolic Approach for Complex Event Processing",
            "abstract": "Training a model to detect patterns of interrelated events that form situations of interest can be a complex problem: such situations tend to be uncommon, and only sparse data is available. We propose a hybrid neuro-symbolic architecture based on Event Calculus that can perform Complex Event Processing (CEP). It leverages both a neural network to interpret inputs and logical rules that express the pattern of the complex event. Our approach is capable of training with much fewer labelled data than a pure neural network approach, and to learn to classify individual events even when training in an end-to-end manner. We demonstrate this comparing our approach against a pure neural network approach on a dataset based on Urban Sounds 8K.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "147627782",
                    "name": "Marc Roig Vilamala"
                },
                {
                    "authorId": "1944880380",
                    "name": "Harrison Taylor"
                },
                {
                    "authorId": "2774212",
                    "name": "Tianwei Xing"
                },
                {
                    "authorId": "2094951808",
                    "name": "L. Garcia"
                },
                {
                    "authorId": "1702254",
                    "name": "M. Srivastava"
                },
                {
                    "authorId": "1795727",
                    "name": "Lance M. Kaplan"
                },
                {
                    "authorId": "1762890",
                    "name": "A. Preece"
                },
                {
                    "authorId": "3294328",
                    "name": "Angelika Kimmig"
                },
                {
                    "authorId": "133946249",
                    "name": "Federico Cerutti"
                }
            ]
        }
    ]
}