{
    "authorId": "144063173",
    "papers": [
        {
            "paperId": "878bcd8fc2b41ac5d28a2c30ad02b9d6c62fe83b",
            "title": "Read between the lines - Functionality Extraction From READMEs",
            "abstract": "While text summarization is a well-known NLP task, in this paper, we introduce a novel and useful variant of it called functionality extraction from Git README files. Though this task is a text2text generation at an abstract level, it involves its own peculiarities and challenges making existing text2text generation systems not very useful. The motivation behind this task stems from a recent surge in research and development activities around the use of large language models for code-related tasks, such as code refactoring, code summarization, etc. We also release a human-annotated dataset called FuncRead, and develop a battery of models for the task. Our exhaustive experimentation shows that small size fine-tuned models beat any baseline models that can be designed using popular black-box or white-box large language models (LLMs) such as ChatGPT and Bard. Our best fine-tuned 7 Billion CodeLlama model exhibit 70% and 20% gain on the F1 score against ChatGPT and Bard respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2292159618",
                    "name": "Prince Kumar"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2291963747",
                    "name": "Dinesh Garg"
                }
            ]
        },
        {
            "paperId": "a5eda09ecb1dd3fd795edbbbb46b7f7e2dbd1f32",
            "title": "DocCGen: Document-based Controlled Code Generation",
            "abstract": "Recent developments show that Large Language Models (LLMs) produce state-of-the-art performance on natural language (NL) to code generation for resource-rich general-purpose languages like C++, Java, and Python. However, their practical usage for structured domain-specific languages (DSLs) such as YAML, JSON is limited due to domain-specific schema, grammar, and customizations generally unseen by LLMs during pre-training. Efforts have been made to mitigate this challenge via in-context learning through relevant examples or by fine-tuning. However, it suffers from problems, such as limited DSL samples and prompt sensitivity but enterprises maintain good documentation of the DSLs. Therefore, we propose DocCGen, a framework that can leverage such rich knowledge by breaking the NL-to-Code generation task for structured code languages into a two-step process. First, it detects the correct libraries using the library documentation that best matches the NL query. Then, it utilizes schema rules extracted from the documentation of these libraries to constrain the decoding. We evaluate our framework for two complex structured languages, Ansible YAML and Bash command, consisting of two settings: Out-of-domain (OOD) and In-domain (ID). Our extensive experiments show that DocCGen consistently improves different-sized language models across all six evaluation metrics, reducing syntactic and semantic errors in structured code. We plan to open-source the datasets and code to motivate research in constrained code generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149585734",
                    "name": "Sameer Pimparkhede"
                },
                {
                    "authorId": "2216600324",
                    "name": "Mehant Kammakomati"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2292159618",
                    "name": "Prince Kumar"
                },
                {
                    "authorId": "2307369948",
                    "name": "Ashok Pon Kumar"
                },
                {
                    "authorId": "2285485414",
                    "name": "Pushpak Bhattacharyya"
                }
            ]
        },
        {
            "paperId": "e4ec30875c43ae9ff7e0c4f2e91641c13e9492a9",
            "title": "ConCodeEval: Evaluating Large Language Models for Code Constraints in Domain-Specific Languages",
            "abstract": "Recent work shows Large Language Models (LLMs) struggle to understand natural language constraints for various text generation tasks in zero- and few-shot settings. While, in the code domain, there is wide usage of constraints in code format to maintain the integrity of code written in Domain-Specific Languages (DSLs) like JSON and YAML which are widely used for system-level programming tasks in enterprises. Given that LLMs are increasingly used for system-level code tasks, evaluating if they can comprehend these code constraints is crucial. However, no work has been done to evaluate their controllability over code constraints. Hence, we introduce ConCodeEval, a first-of-its-kind benchmark having two novel tasks for code constraints across five representations. Our findings suggest that language models struggle with code constraints. Code languages that perform excellently for normal code tasks do not perform well when the same languages represent fine-grained constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216600324",
                    "name": "Mehant Kammakomati"
                },
                {
                    "authorId": "2149585734",
                    "name": "Sameer Pimparkhede"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2292159618",
                    "name": "Prince Kumar"
                },
                {
                    "authorId": "2285485414",
                    "name": "Pushpak Bhattacharyya"
                }
            ]
        },
        {
            "paperId": "f61bb7cb688f68cb25ab9c87b353fe1377e879c8",
            "title": "Enabling Communication via APIs for Mainframe Applications",
            "abstract": "For decades, mainframe systems have been vital in enterprise computing, supporting essential applications across industries like banking, retail, and healthcare. To harness these legacy applications and facilitate their reuse, there is increasing interest in using Application Programming Interfaces (APIs) to expose their data and functionalities, enabling the creation of new applications. However, identifying and exposing APIs for various business use cases presents significant challenges, including understanding legacy code, separating dependent components, introducing new artifacts, and making changes without disrupting functionality or compromising key Service Level Agreements (SLAs) like Turnaround Time (TAT). We address these challenges by proposing a novel framework for creating APIs for legacy mainframe applications. Our approach involves identifying APIs by compiling artifacts such as transactions, screens, control flow blocks, inter-microservice calls, business rules, and data accesses. We use static analyses like liveness and reaching definitions to traverse the code and automatically compute API signatures, which include request/response fields. To evaluate our framework, we conducted a qualitative survey with nine mainframe developers, averaging 15 years of experience. This survey helped identify candidate APIs and estimate development time for coding these APIs on a public mainframe application, GENAPP, and two industry mainframe applications. The results showed that our framework effectively identified more candidate APIs and reduced implementation time. The API signature computation is integrated into IBM Watsonx Code Assistant for Z Refactoring Assistant. We verified the correctness of the identified APIs by executing them on an IBM Z mainframe system, demonstrating the practical viability of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2741860",
                    "name": "Vini Kanvar"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2149094478",
                    "name": "Keerthi Narayan Raghunath"
                }
            ]
        },
        {
            "paperId": "05526b42336c74298ca4ccbcb792107900574062",
            "title": "Prompting with Pseudo-Code Instructions",
            "abstract": "Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models. Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, such as the use of pseudo-code. In this paper we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset of pseudo-code prompts for 132 different tasks spanning classification, QA and generative language tasks, sourced from the Super-NaturalInstructions dataset. Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM and CodeGen. Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% in aggregate ROUGE-L scores across all tasks. We include detailed ablation studies which indicate that code comments, docstrings, and the structural clues encoded in pseudo-code all contribute towards the improvement in performance. To the best of our knowledge our work is the first to demonstrate how pseudo-code prompts can be helpful in improving the performance of pre-trained LMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1381446720",
                    "name": "Mayank Mishra"
                },
                {
                    "authorId": "2118921007",
                    "name": "Prince Kumar"
                },
                {
                    "authorId": "40578334",
                    "name": "Riyaz Ahmad Bhat"
                },
                {
                    "authorId": "2680174",
                    "name": "V. Rudramurthy"
                },
                {
                    "authorId": "2075459",
                    "name": "Danish Contractor"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                }
            ]
        },
        {
            "paperId": "65d44118b734afc659d36a623756f0b8646be763",
            "title": "COMEX: A Tool for Generating Customized Source Code Representations",
            "abstract": "Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree-sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2169805280",
                    "name": "Debeshee Das"
                },
                {
                    "authorId": "1736509572",
                    "name": "N. Mathews"
                },
                {
                    "authorId": "47569888",
                    "name": "Alex Mathai"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2205195340",
                    "name": "Kranthi Sedamaki"
                },
                {
                    "authorId": "1926332",
                    "name": "S. Chimalakonda"
                },
                {
                    "authorId": "2144870066",
                    "name": "Atul Kumar"
                }
            ]
        },
        {
            "paperId": "ac45edff44fb98ec257a67d8351737b8755a06e6",
            "title": "Handling Communication via APIs for Microservices",
            "abstract": "Enterprises in their journey to the cloud, want to decompose their monolith applications into microservices to maximize cloud benefits. Current research focuses a lot on how to partition the monolith into smaller clusters that perform well across standard metrics like coupling, cohesion etc. However, there is little research done on taking the partitions, identifying their dependencies between the microservices, exploring ways to further reduce the dependencies, and making appropriate code changes to enable robust communication without changing the application behaviour.In this work, we discuss the challenges with the conventional techniques of communication using JSON and propose an alternative way of ID-passing via APIs. We also devise an algorithm to reduce the number of APIs. For this, we construct subgraphs of methods and their associated variables in each class, and relocate them to their more functionally aligned microservices. Our quantitative and qualitative studies on five public Java applications clearly demonstrate that our refactored microservices using ID have decidedly better time and memory complexities than JSON. Our automation reduces 40-60% of the manual refactoring efforts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2741860",
                    "name": "Vini Kanvar"
                },
                {
                    "authorId": "2113688343",
                    "name": "Ridhi Jain"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                }
            ]
        },
        {
            "paperId": "e767b2dac61a2de50213683ff3ee6efe48103b4a",
            "title": "The Landscape of Source Code Representation Learning in AI-Driven Software Engineering Tasks",
            "abstract": "Appropriate representation of source code and its relevant properties form the backbone of Artificial Intelligence (AI)/ Machine Learning (ML) pipelines for various software engineering (SE) tasks such as code classification, bug prediction, code clone detection, and code summarization. In the literature, researchers have extensively experimented with different kinds of source code representations (syntactic, semantic, integrated, customized) and ML techniques such as pre-trained BERT models. In addition, it is common for researchers to create hand-crafted and customized source code representations for an appropriate SE task. In a 2018 survey [1], Allamanis et al. listed nearly 35 different ways of of representing source code for different SE tasks like Abstract Syntax Trees (ASTs), customized ASTs, Control Flow Graphs (CFGs), Data Flow Graphs (DFGs) and so on. The main goal of this tutorial is two-fold (i) Present an overview of the state-of-the-art of source code representations and corresponding ML pipelines with an explicit focus on the merits and demerits of each of the representations (ii) Practical challenges in infusing different code-views in the state-of-the-art ML models and future research directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1926332",
                    "name": "S. Chimalakonda"
                },
                {
                    "authorId": "2169805280",
                    "name": "Debeshee Das"
                },
                {
                    "authorId": "47569888",
                    "name": "Alex Mathai"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2144870066",
                    "name": "Atul Kumar"
                }
            ]
        },
        {
            "paperId": "9a1fd52a157d61992c26da645a48efd1c37d0bb7",
            "title": "Handling Memory Pointers in Communication between Microservices",
            "abstract": "When microservices are written from scratch, APIs are usually made stateless. However, when an existing monolith application is decomposed into microservices, it may not be possible to make all the APIs stateless. Therefore, objects transferred via APIs may contain pointers. Consequently, data transfer via an API i.e., from a client address space to a server address space, reconstruction at the server, and returning to the client become non-trivial operations.Conventionally, data transfer between microservices is done using JSON, which serializes pointers to values that they point to. Once the data in JSON reaches the server, deserialization creates objects of the original types on the server. However, deserialization is unable to return the same objects passed by the client because serialization leads to loss of pointer information. We propose to apply pointer swizzling to solve this problem. Pointer swizzling modifies the definition of the class by introducing ID of the object and by replacing all pointers with IDs of the objects it refers. These IDs help to maintain correct reference in the server. After the server API operates on the objects, the server returns new objects of the same types to the client. These new objects need to be plugged back in the client address space i.e., pointers to the old objects in the client need to now point to the corresponding new objects. This plugging back is non-trivial because we do not know how the old objects map to the new objects. We propose creating memory maps at runtime to overcome this challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2741860",
                    "name": "Vini Kanvar"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "1768474",
                    "name": "Raghavan Komondoor"
                }
            ]
        },
        {
            "paperId": "442be8dcb269fbfb604d7d1da91d0eab5c7d706c",
            "title": "Monolith to Microservice Candidates using Business Functionality Inference",
            "abstract": "In this paper, we propose a novel approach for monolith decomposition, that maps the implementation structure of a monolith application to a functional structure that in turn can be mapped to business functionality. First, we infer the classes in the monolith application that are distinctively representative of the business functionality in the application domain. This is done using formal concept analysis on statically determined code flow structures in a completely automated manner. Then, we apply a clustering technique, guided by the inferred representatives, on the classes belonging to the monolith to group them into different types of partitions, mainly: 1) functional groups representing microservice candidates, 2) a utility class group, and 3) a group of classes that require significant refactoring to enable a clean microservice architecture. This results in microservice candidates that are naturally aligned with the different business functions exposed by the application. A detailed evaluation on four publicly available applications show that our approach is able to determine better quality microservice candidates when compared to other existing state of the art techniques. We also conclusively show that clustering quality metrics like modularity are not reliable indicators of microservice candidate goodness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2012235",
                    "name": "Shivali Agarwal"
                },
                {
                    "authorId": "2054639680",
                    "name": "Raunak Sinha"
                },
                {
                    "authorId": "3023667",
                    "name": "G. Sridhara"
                },
                {
                    "authorId": "2153318610",
                    "name": "Pratap Das"
                },
                {
                    "authorId": "39664418",
                    "name": "Utkarsh Desai"
                },
                {
                    "authorId": "144063173",
                    "name": "Srikanth G. Tamilselvam"
                },
                {
                    "authorId": "2574648",
                    "name": "Amith Singhee"
                },
                {
                    "authorId": "2140227408",
                    "name": "Hiroaki Nakamuro"
                }
            ]
        }
    ]
}