{
    "authorId": "2041980",
    "papers": [
        {
            "paperId": "086916da1b23eb7dc03202f4a045b0be3cd49063",
            "title": "Investigating and Mitigating the Side Effects of Noisy Views in Multi-view Clustering in Practical Scenarios",
            "abstract": "\u2014Multi-view clustering (MvC) aims at exploring category structures among multi-view data without label supervision. Multiple views provide more information than single views and thus existing MvC methods can achieve satisfactory performance. However, their performance might seriously degenerate when the views are noisy in practical scenarios. In this paper, we \ufb01rst formally investigate the drawback of noisy views and then propose a theoretically grounded deep MvC method (namely MvCAN) to address this issue. Speci\ufb01cally, we propose a novel MvC objective that enables un-shared parameters and inconsistent clustering predictions across multiple views to reduce the side effects of noisy views. Furthermore, a non-parametric iterative process is designed to generate a robust learning target for mining multiple views\u2019 useful information. Theoretical analysis reveals that MvCAN works by achieving the multi-view consistency, complementarity, and noise robustness. Finally, experiments on extensive public datasets demonstrate that MvCAN outperforms state-of-the-art methods and is robust against the existence of noisy views.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145753839",
                    "name": "Jie Xu"
                },
                {
                    "authorId": "2052804040",
                    "name": "Gang Niu"
                },
                {
                    "authorId": "2145747476",
                    "name": "Xiaolong Wang"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "47010134",
                    "name": "Lei Feng"
                },
                {
                    "authorId": "2766473",
                    "name": "Xiaoshuang Shi"
                },
                {
                    "authorId": "2110685575",
                    "name": "H. Shen"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                }
            ]
        },
        {
            "paperId": "399c35dcde2eac017b875af1a21916a9ecb10434",
            "title": "Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering",
            "abstract": "As one of the most important research topics in the unsupervised learning field, Multi-View Clustering (MVC) has been widely studied in the past decade and numerous MVC methods have been developed. Among these methods, the recently emerged Graph Neural Networks (GNN) shine a light on modeling both topological structure and node attributes in the form of graphs, to guide unified embedding learning and clustering. However, the effectiveness of existing GNN-based MVC methods is still limited due to the insufficient consideration in utilizing the self-supervised information and graph information, which can be reflected from the following two aspects: 1) most of these models merely use the self-supervised information to guide the feature learning and fail to realize that such information can be also applied in graph learning and sample weighting; 2) the usage of graph information is generally limited to the feature aggregation in these models, yet it also provides valuable evidence in detecting noisy samples. To this end, in this paper we propose Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering (SGDMC), which promotes the performance of GNN-based deep MVC models by making full use of the self-supervised information and graph information. Specifically, a novel attention-allocating approach that considers both the similarity of node attributes and the self-supervised information is developed to comprehensively evaluate the relevance among different nodes. Meanwhile, to alleviate the negative impact caused by noisy samples and the discrepancy of cluster structures, we further design a sample-weighting strategy based on the attention graph as well as the discrepancy between the global pseudo-labels and the local cluster assignment. Experimental results on multiple real-world datasets demonstrate the effectiveness of our method over existing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1443734032",
                    "name": "Zongmo Huang"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2712233",
                    "name": "Shudong Huang"
                },
                {
                    "authorId": "1683510",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "455c2c883b31a7fb4e608c4870ce376751ae9716",
            "title": "Deep Multi-View Subspace Clustering with Anchor Graph",
            "abstract": "Deep multi-view subspace clustering (DMVSC) has recently attracted increasing attention due to its promising performance. However, existing DMVSC methods still have two issues: (1) they mainly focus on using autoencoders to nonlinearly embed the data, while the embedding may be suboptimal for clustering because the clustering objective is rarely considered in autoencoders, and (2) existing methods typically have a quadratic or even cubic complexity, which makes it challenging to deal with large-scale data. To address these issues, in this paper we propose a novel deep multi-view subspace clustering method with anchor graph (DMCAG). To be specific, DMCAG firstly learns the embedded features for each view independently, which are used to obtain the subspace representations. To significantly reduce the complexity, we construct an anchor graph with small size for each view. Then, spectral clustering is performed on an integrated anchor graph to obtain pseudo-labels. To overcome the negative impact caused by suboptimal embedded features, we use pseudo-labels to refine the embedding process to make it more suitable for the clustering task. Pseudo-labels and embedded features are updated alternately. Furthermore, we design a strategy to keep the consistency of the labels based on contrastive learning to enhance the clustering performance. Empirical studies on real-world datasets show that our method achieves superior clustering performance over other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216785845",
                    "name": "Chenhang Cui"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2004864336",
                    "name": "Jingyu Pu"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "571e7262ea7b3c6be881a5383215c6dfb2f5a50c",
            "title": "Adaptive Feature Projection With Distribution Alignment for Deep Incomplete Multi-View Clustering",
            "abstract": "Incomplete multi-view clustering (IMVC) analysis, where some views of multi-view data usually have missing data, has attracted increasing attention. However, existing IMVC methods still have two issues: 1) they pay much attention to imputing or recovering the missing data, without considering the fact that the imputed values might be inaccurate due to the unknown label information, 2) the common features of multiple views are always learned from the complete data, while ignoring the feature distribution discrepancy between the complete and incomplete data. To address these issues, we propose an imputation-free deep IMVC method and consider distribution alignment in feature learning. Concretely, the proposed method learns the features for each view by autoencoders and utilizes an adaptive feature projection to avoid the imputation for missing data. All available data are projected into a common feature space, where the common cluster information is explored by maximizing mutual information and the distribution alignment is achieved by minimizing mean discrepancy. Additionally, we design a new mean discrepancy loss for incomplete multi-view learning and make it applicable in mini-batch optimization. Extensive experiments demonstrate that our method achieves the comparable or superior performance compared with state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2145753839",
                    "name": "Jie Xu"
                },
                {
                    "authorId": "2150358656",
                    "name": "Chao Li"
                },
                {
                    "authorId": "144454465",
                    "name": "Liang Peng"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2766473",
                    "name": "Xiaoshuang Shi"
                },
                {
                    "authorId": "2110685575",
                    "name": "H. Shen"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                }
            ]
        },
        {
            "paperId": "7eaef7398c0ef82529d8d9b7077380acaf859aea",
            "title": "Self-Paced Neutral Expression-Disentangled Learning for Facial Expression Recognition",
            "abstract": "The accuracy of facial expression recognition is typically influenced by the following factors: high similarities across different expressions, disturbing factors, and the subtle and rapid micro-movements of the face. One potential solution to overcome these obstacles is to leverage the hidden neutral information present in neutral expression images. In this paper, we propose a Self-Paced Neutral Expression-Disentangled Learning (SPNDL) model, which aims to disentangle the neutral information from facial expressions, facilitating the extraction of crucial features and variations. This approach enables the capture of discriminative details within similar expressions and the detection of micro-facial movements. To enhance the learning of these neutral expression-disentangled features (NDFs) and mitigate the challenges posed by non-convex optimization, we propose a self-paced learning (SPL) strategy based on NDFs during the training phase. SPL learns samples from easy to complex by increasing the number of samples selected into the training process, which enables to effectively suppress the negative impacts caused by low-quality samples and inconsistently distributed NDFs. Experiments on three popular databases (i.e., CK+, Oulu-CASIA, and RAF-DB) show the effectiveness of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187384062",
                    "name": "Zhenqian Wu"
                },
                {
                    "authorId": "2212116478",
                    "name": "Xiaoyuan Li"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "89fdbaa025a339558438160fbcca2e0812abfb56",
            "title": "Dual Label-Guided Graph Refinement for Multi-View Graph Clustering",
            "abstract": "With the increase of multi-view graph data, multi-view graph clustering (MVGC) that can discover the hidden clusters without label supervision has attracted growing attention from researchers. Existing MVGC methods are often sensitive to the given graphs, especially influenced by the low quality graphs, i.e., they tend to be limited by the homophily assumption. However, the widespread real-world data hardly satisfy the homophily assumption. This gap limits the performance of existing MVGC methods on low homophilous graphs. To mitigate this limitation, our motivation is to extract high-level view-common information which is used to refine each view's graph, and reduce the influence of non-homophilous edges. To this end, we propose dual label-guided graph refinement for multi-view graph clustering (DuaLGR), to alleviate the vulnerability in facing low homophilous graphs. Specifically, DuaLGR consists of two modules named dual label-guided graph refinement module and graph encoder module. The first module is designed to extract the soft label from node features and graphs, and then learn a refinement matrix. In cooperation with the pseudo label from the second module, these graphs are refined and aggregated adaptively with different orders. Subsequently, a consensus graph can be generated in the guidance of the pseudo label. Finally, the graph encoder module encodes the consensus graph along with node features to produce the high-level pseudo label for iteratively clustering. The experimental results show the superior performance on coping with low homophilous graph data. The source code for DuaLGR is available at https://github.com/YwL-zhufeng/DuaLGR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47396038",
                    "name": "Yawen Ling"
                },
                {
                    "authorId": "2135294453",
                    "name": "Jianpeng Chen"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2145753839",
                    "name": "Jie Xu"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "8a7dd67c52fc81ed3e7224cd718ec7ef18785922",
            "title": "A Novel Approach for Effective Multi-View Clustering with Information-Theoretic Perspective",
            "abstract": "Multi-view clustering (MVC) is a popular technique for improving clustering performance using various data sources. However, existing methods primarily focus on acquiring consistent information while often neglecting the issue of redundancy across multiple views. This study presents a new approach called Sufficient Multi-View Clustering (SUMVC) that examines the multi-view clustering framework from an information-theoretic standpoint. Our proposed method consists of two parts. Firstly, we develop a simple and reliable multi-view clustering method SCMVC (simple consistent multi-view clustering) that employs variational analysis to generate consistent information. Secondly, we propose a sufficient representation lower bound to enhance consistent information and minimise unnecessary information among views. The proposed SUMVC method offers a promising solution to the problem of multi-view clustering and provides a new perspective for analyzing multi-view data. To verify the effectiveness of our model, we conducted a theoretical analysis based on the Bayes Error Rate, and experiments on multiple multi-view datasets demonstrate the superior performance of SUMVC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216785845",
                    "name": "Chenhang Cui"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2004864336",
                    "name": "Jingyu Pu"
                },
                {
                    "authorId": "2240920683",
                    "name": "Jiawei Li"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "144637279",
                    "name": "Tianyi Wu"
                },
                {
                    "authorId": "8064665",
                    "name": "Yutao Shi"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "a4cdc08236322aea953ea6f1612a6ccb713206a8",
            "title": "Federated Deep Multi-View Clustering with Global Self-Supervision",
            "abstract": "Federated multi-view clustering has the potential to learn a global clustering model from data distributed across multiple devices. In this setting, label information is unknown and data privacy must be preserved, leading to two major challenges. First, views on different clients often have feature heterogeneity, and mining their complementary cluster information is not trivial. Second, the storage and usage of data from multiple clients in a distributed environment can lead to incompleteness of multi-view data. To address these challenges, we propose a novel federated deep multi-view clustering method that can mine complementary cluster structures from multiple clients, while dealing with data incompleteness and privacy concerns. Specifically, in the server environment, we propose sample alignment and data extension techniques to explore the complementary cluster structures of multiple views. The server then distributes global prototypes and global pseudo-labels to each client as global self-supervised information. In the client environment, multiple clients use the global self-supervised information and deep autoencoders to learn view-specific cluster assignments and embedded features, which are then uploaded to the server for refining the global self-supervised information. Finally, the results of our extensive experiments demonstrate that our proposed method exhibits superior performance in addressing the challenges of incomplete multi-view data in distributed environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142843615",
                    "name": "Xinyue Chen"
                },
                {
                    "authorId": "2145753839",
                    "name": "Jie Xu"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2195624415",
                    "name": "Ce Zhu"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                },
                {
                    "authorId": "2068654977",
                    "name": "Zhifeng Hao"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "0242e25ffb7fe83351ec06d286d7effceca4eb44",
            "title": "ViLPAct: A Benchmark for Compositional Generalization on Multimodal Human Activities",
            "abstract": "We introduce {dataset, a novel vision-language benchmark for human activity planning. It is designed for a task where embodied AI agents can reason and forecast future actions of humans based on video clips about their initial activities and intents in text. The dataset consists of 2.9k videos from {charades extended with intents via crowdsourcing, a multi-choice question test set, and four strong baselines. One of the baselines implements a neurosymbolic approach based on a multi-modal knowledge base (MKB), while the other ones are deep generative models adapted from recent state-of-the-art (SOTA) methods. According to our extensive experiments, the key challenges are compositional generalization and effective use of information from both modalities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080123731",
                    "name": "Terry Yue Zhuo"
                },
                {
                    "authorId": "2114122093",
                    "name": "Yaqing Liao"
                },
                {
                    "authorId": "2187557239",
                    "name": "Yuecheng Lei"
                },
                {
                    "authorId": "14564042",
                    "name": "Lizhen Qu"
                },
                {
                    "authorId": "144608002",
                    "name": "Gerard de Melo"
                },
                {
                    "authorId": "144950946",
                    "name": "Xiaojun Chang"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1683510",
                    "name": "Zenglin Xu"
                }
            ]
        },
        {
            "paperId": "21b3f7eac2e6a4ebe72f49634152a11291e3d93c",
            "title": "Self-Paced Label Distribution Learning for In-The-Wild Facial Expression Recognition",
            "abstract": "Label distribution learning (LDL) has achieved great progress in facial expression recognition (FER), where the generating label distribution is a key procedure for LDL-based FER. However, many existing researches have shown the common problem with noisy samples in FER, especially on in-the-wild datasets. This issue may lead to generating unreliable label distributions (which can be seen as label noise), and will further negatively affect the FER model. To this end, we propose a play-and-plug method of self-paced label distribution learning (SPLDL) for in-the-wild FER. Specifically, a simple yet efficient label distribution generator is adopted to generate label distributions to guide label distribution learning. We then introduce self-paced learning (SPL) paradigm and develop a novel self-paced label distribution learning strategy, which considers both classification losses and distribution losses. SPLDL first learns easy samples with reliable label distributions and gradually steps to complex ones, effectively suppressing the negative impact introduced by noisy samples and unreliable label distributions. Extensive experiments on in-the-wild FER datasets (\\emphi.e., RAF-DB and AffectNet) based on three backbone networks demonstrate the effectiveness of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187309119",
                    "name": "Jianjian Shao"
                },
                {
                    "authorId": "2187384062",
                    "name": "Zhenqian Wu"
                },
                {
                    "authorId": "97685409",
                    "name": "Yuanyan Luo"
                },
                {
                    "authorId": "2712233",
                    "name": "Shudong Huang"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                }
            ]
        }
    ]
}