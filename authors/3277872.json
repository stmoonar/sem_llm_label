{
    "authorId": "3277872",
    "papers": [
        {
            "paperId": "c6783ed95372a8f6be668dd01aed628c01be9a5e",
            "title": "Differentially Private Publication of Electricity Time Series Data in Smart Grids",
            "abstract": "Smart grids are a valuable data source to study consumer behavior and guide energy policy decisions. In particular, time-series of power consumption over geographical areas are essential in deciding the optimal placement of expensive resources (e.g., transformers, storage elements) and their activation schedules. However, publication of such data raises significant privacy issues, as it may reveal sensitive details about personal habits and lifestyles. Differential privacy (DP) is well-suited for sanitization of individual data, but current DP techniques for time series lead to significant loss in utility, due to the existence of temporal correlation between data readings. We introduce {\\em STPT (Spatio-Temporal Private Timeseries)}, a novel method for DP-compliant publication of electricity consumption data that analyzes spatio-temporal attributes and captures both micro and macro patterns by leveraging RNNs. Additionally, it employs a partitioning method for releasing electricity consumption time series based on identified patterns. We demonstrate through extensive experiments, on both real-world and synthetic datasets, that STPT significantly outperforms existing benchmarks, providing a well-balanced trade-off between data utility and user privacy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "2174866863",
                    "name": "Bhaskar Krishnamachari"
                },
                {
                    "authorId": "2258957849",
                    "name": "Cyrus Shahabi"
                }
            ]
        },
        {
            "paperId": "11c26cfcee4adeb81fd3c0ea81fc27877128352a",
            "title": "Towards Mobility Data Science (Vision Paper)",
            "abstract": "Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of GPS-equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated significant impact in various domains including traffic management, urban planning, and health sciences. In this paper, we present the emerging domain of mobility data science. Towards a unified approach to mobility data science, we envision a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state of the art and describe open challenges for the research community in the coming years.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                },
                {
                    "authorId": "152843469",
                    "name": "M. Sakr"
                },
                {
                    "authorId": "47607633",
                    "name": "Li-Qiong Xiong"
                },
                {
                    "authorId": "1393273470",
                    "name": "Andreas Zufle"
                },
                {
                    "authorId": "2223124284",
                    "name": "Jussara Almeida"
                },
                {
                    "authorId": "1709661",
                    "name": "W. Aref"
                },
                {
                    "authorId": "50663909",
                    "name": "G. Andrienko"
                },
                {
                    "authorId": "1780833",
                    "name": "N. Andrienko"
                },
                {
                    "authorId": "1596101114",
                    "name": "Yang Cao"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "2073538844",
                    "name": "R. Cheng"
                },
                {
                    "authorId": "1728643",
                    "name": "Panos K. Chrysanthis"
                },
                {
                    "authorId": "48055813",
                    "name": "Xiqi Fei"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "32324949",
                    "name": "A. Graser"
                },
                {
                    "authorId": "1736832",
                    "name": "D. Gunopulos"
                },
                {
                    "authorId": "144572233",
                    "name": "C. Jensen"
                },
                {
                    "authorId": "2183485901",
                    "name": "Joon-Sook Kim"
                },
                {
                    "authorId": "2144390213",
                    "name": "Kyoung-Sook Kim"
                },
                {
                    "authorId": "152431109",
                    "name": "Peer Kr\u0151ger"
                },
                {
                    "authorId": "79027713",
                    "name": "John Krumm"
                },
                {
                    "authorId": "2381835",
                    "name": "Johannes Lauer"
                },
                {
                    "authorId": "143811079",
                    "name": "A. Magdy"
                },
                {
                    "authorId": "144977963",
                    "name": "M. Nascimento"
                },
                {
                    "authorId": "1797879",
                    "name": "S. Ravada"
                },
                {
                    "authorId": "1723035",
                    "name": "M. Renz"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                },
                {
                    "authorId": "144954586",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "1769421",
                    "name": "Mohamed Sarwat"
                },
                {
                    "authorId": "30749282",
                    "name": "Maxime Schoemans"
                },
                {
                    "authorId": "1699605",
                    "name": "B. Speckmann"
                },
                {
                    "authorId": "3346327",
                    "name": "E. Tanin"
                },
                {
                    "authorId": "1714996",
                    "name": "Y. Theodoridis"
                },
                {
                    "authorId": "2380832",
                    "name": "K. Torp"
                },
                {
                    "authorId": "1776969",
                    "name": "Goce Trajcevski"
                },
                {
                    "authorId": "1796774",
                    "name": "M. V. Kreveld"
                },
                {
                    "authorId": "1711445",
                    "name": "C. Wenk"
                },
                {
                    "authorId": "2183364647",
                    "name": "Martin Werner"
                },
                {
                    "authorId": "2223022273",
                    "name": "Raymond E. Wong"
                },
                {
                    "authorId": "2182962401",
                    "name": "Song Wu"
                },
                {
                    "authorId": "46372740",
                    "name": "Jianqiu Xu"
                },
                {
                    "authorId": "144711492",
                    "name": "M. Youssef"
                },
                {
                    "authorId": "66975603",
                    "name": "Demetris Zeinalipour"
                },
                {
                    "authorId": "3451341",
                    "name": "Mengxuan Zhang"
                },
                {
                    "authorId": "2223118920",
                    "name": "Esteban Zim'anyi"
                }
            ]
        },
        {
            "paperId": "30efcb0dab0ea353ee50e1d9ca55713acffde627",
            "title": "Fair Spatial Indexing: A paradigm for Group Spatial Fairness",
            "abstract": "Machine learning (ML) is playing an increasing role in decision-making tasks that directly affect individuals, e.g., loan approvals, or job applicant screening. Significant concerns arise that, without special provisions, individuals from under-privileged backgrounds may not get equitable access to services and opportunities. Existing research studies fairness with respect to protected attributes such as gender, race or income, but the impact of location data on fairness has been largely overlooked. With the widespread adoption of mobile apps, geospatial attributes are increasingly used in ML, and their potential to introduce unfair bias is significant, given their high correlation with protected attributes. We propose techniques to mitigate location bias in machine learning. Specifically, we consider the issue of miscalibration when dealing with geospatial attributes. We focus on spatial group fairness and we propose a spatial indexing algorithm that accounts for fairness. Our KD-tree inspired approach significantly improves fairness while maintaining high learning accuracy, as shown by extensive experimental results on real data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                }
            ]
        },
        {
            "paperId": "7224620ed1823739986b14778d750ec65e82eaca",
            "title": "VPASS: Voice Privacy Assistant System for Monitoring In-home Voice Commands",
            "abstract": "Voice assistant systems (VAS), such as Google Assistant or Amazon Alexa, provide convenient means for users to interact verbally with online services. VAS is particularly important for users with severe health conditions or motor skills impairment. At the same time, voice commands may contain highly-sensitive information about individuals. Therefore, sharing such data with service providers must be done in a carefully controlled and transparent manner in order to prevent privacy breaches. One important challenge is identifying which voice commands contain sensitive information. Different individuals are likely to have distinct interpretations of what is sensitive and what must be kept private, depending on gender, age, cultural background, etc. Furthermore, even for the same individual, the context in which a command is issued can result in significantly different sensitivity perceptions. We introduce a framework named VPASS that supports the management of personalized privacy requirements for VAS systems. Specifically, we propose mechanisms to quantify two key aspects: the amount of information disclosure and the level of privacy sensitivity that each voice command has. Our mechanisms employ deep transfer learning techniques for processing voice commands and can accurately detect privacy-sensitive commands based on an individual\u2019s prior history of VAS interaction. Finally, VPASS generates monthly reports or immediate privacy alerts based on the privacy policies pre-defined by users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2078693286",
                    "name": "Bang Tran"
                },
                {
                    "authorId": "2273097010",
                    "name": "Sai Harshavardhan Reddy Kona"
                },
                {
                    "authorId": "2153398177",
                    "name": "Xiaohui Liang"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "2267754831",
                    "name": "Caroline Summerour"
                },
                {
                    "authorId": "2243291635",
                    "name": "John A. Batsis"
                }
            ]
        },
        {
            "paperId": "e140384789f4dbe7f1e7e876c6713d2a0795cc22",
            "title": "Holistic Survey of Privacy and Fairness in Machine Learning",
            "abstract": "Privacy and fairness are two crucial pillars of responsible Artificial Intelligence (AI) and trustworthy Machine Learning (ML). Each objective has been independently studied in the literature with the aim of reducing utility loss in achieving them. Despite the significant interest attracted from both academia and industry, there remains an immediate demand for more in-depth research to unravel how these two objectives can be simultaneously integrated into ML models. As opposed to well-accepted trade-offs, i.e., privacy-utility and fairness-utility, the interrelation between privacy and fairness is not well-understood. While some works suggest a trade-off between the two objective functions, there are others that demonstrate the alignment of these functions in certain scenarios. To fill this research gap, we provide a thorough review of privacy and fairness in ML, including supervised, unsupervised, semi-supervised, and reinforcement learning. After examining and consolidating the literature on both objectives, we present a holistic survey on the impact of privacy on fairness, the impact of fairness on privacy, existing architectures, their interaction in application domains, and algorithms that aim to achieve both objectives while minimizing the utility sacrificed. Finally, we identify research challenges in achieving privacy and fairness concurrently in ML, particularly focusing on large language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "2209222310",
                    "name": "Arash Hajisafi"
                },
                {
                    "authorId": "2155747501",
                    "name": "Min Quan"
                },
                {
                    "authorId": "123547055",
                    "name": "Dinh C. Nguyen"
                },
                {
                    "authorId": "2174866863",
                    "name": "Bhaskar Krishnamachari"
                },
                {
                    "authorId": "102648923",
                    "name": "Charith Peris"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                },
                {
                    "authorId": "2301180",
                    "name": "P. Pathirana"
                }
            ]
        },
        {
            "paperId": "e1835dd778a6117a033b069daabb6f97e9f1d6ca",
            "title": "Supporting Secure Dynamic Alert Zones Using Searchable Encryption and Graph Embedding",
            "abstract": "Location-based alerts have gained increasing popularity in recent years, whether in the context of healthcare (e.g., COVID-19 contact tracing), marketing (e.g., location-based advertising), or public safety. However, serious privacy concerns arise when location data are used in clear in the process. Several solutions employ searchable encryption (SE) to achieve secure alerts directly on encrypted locations. While doing so preserves privacy, the performance overhead incurred is high. We focus on a prominent SE technique in the public-key setting\u2013hidden vector encryption, and propose a graph embedding technique to encode location data in a way that significantly boosts the performance of processing on ciphertexts. We show that the optimal encoding is NP-hard, and we provide three heuristics that obtain significant performance gains: gray optimizer, multi-seed gray optimizer and scaled gray optimizer. Furthermore, we investigate the more challenging case of dynamic alert zones, where the area of interest changes over time. Our extensive experimental evaluation shows that our solutions can significantly improve computational overhead compared to existing baselines.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                }
            ]
        },
        {
            "paperId": "07d73d0acf5ca7b66b856c08a0eaee4b4bbf75c6",
            "title": "Models and Mechanisms for Spatial Data Fairness",
            "abstract": "Fairness in data-driven decision-making studies scenarios where individuals from certain population segments may be unfairly treated when being considered for loan or job applications, access to public resources, or other types of services. In location-based applications, decisions are based on individual whereabouts, which often correlate with sensitive attributes such as race, income, and education. While fairness has received significant attention recently, e.g., in machine learning, there is little focus on achieving fairness when dealing with location data. Due to their characteristics and specific type of processing algorithms, location data pose important fairness challenges. We introduce the concept of spatial data fairness to address the specific challenges of location data and spatial queries. We devise a novel building block to achieve fairness in the form of fair polynomials. Next, we propose two mechanisms based on fair polynomials that achieve individual spatial fairness, corresponding to two common location-based decision-making types: distance-based and zone-based. Extensive experimental results on real data show that the proposed mechanisms achieve spatial fairness without sacrificing utility.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                }
            ]
        },
        {
            "paperId": "40fc4c4e7ce07c79ffd133f65871916deb24f39a",
            "title": "Models and Mechanisms for Fairness in Location Data Processing",
            "abstract": "Location data use has become pervasive in the last decade due to the advent of mobile apps, as well as novel areas such as smart health, smart cities, etc. At the same time, significant concerns have sur-faced with respect to fairness in data processing. Individuals from certain population segments may be unfairly treated when being considered for loan or job applications, access to public resources, or other types of services. In the case of location data, fairness is an important concern, given that an individual\u2019s whereabouts are often correlated with sensitive attributes, e.g., race, income, education. Whilefairness has received significant attention recently, e.g., in the case of machine learning, there is little focus on the challenges of achieving fairness when dealing with location data. Due to their characteristics and specific type of processing algorithms, location data pose important fairness challenges that must be addressed in a comprehensive and effective manner. In this paper, we adapt existing fairness models to suit the specific properties of location data and spatial processing. We focus on individual fairness, which is more difficult to achieve, and more relevant for most location data processing scenarios. First, we devise a novel building block to achieve fairness in the form of fair polynomials . Then, we propose two mechanisms based on fair polynomials that achieve individual fairness, corresponding to two common interaction types based on location data. Extensive experimental results on real data show that the proposed mechanisms achieve individual location fairness without sacrificing utility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                }
            ]
        },
        {
            "paperId": "5d8660e7728bde33ad7b951c83b4151bba8601b1",
            "title": "Differentially-Private Publication of Origin-Destination Matrices with Intermediate Stops",
            "abstract": "Conventional origin-destination (OD) matrices record the count of trips between pairs of start and end locations, and have been extensively used in transportation, traffic planning, etc. More recently, due to use case scenarios such as COVID-19 pandemic spread modeling, it is increasingly important to also record intermediate points along an individual's path, rather than only the trip start and end points. This can be achieved by using a multi-dimensional frequency matrix over a data space partitioning at the desired level of granularity. However, serious privacy constraints occur when releasing OD matrix data, and especially when adding multiple intermediate points, which makes individual trajectories more distinguishable to an attacker. To address this threat, we propose a technique for privacy-preserving publication of multi-dimensional OD matrices that achieves differential privacy (DP), the de-facto standard in private data release. We propose a family of approaches that factor in important data properties such as data density and homogeneity in order to build OD matrices that provide provable protection guarantees while preserving query accuracy. Extensive experiments on real and synthetic datasets show that the proposed approaches clearly outperform existing state-of-the-art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                }
            ]
        },
        {
            "paperId": "ccfddae5204b07d57a0ff7c36dd77c1ffd092741",
            "title": "HTF: Homogeneous Tree Framework for Differentially Private Release of Large Geospatial Datasets with Self-tuning Structure Height",
            "abstract": "Mobile apps that use location data are pervasive, spanning domains such as transportation, urban planning, and healthcare. Important use cases for location data rely on statistical queries, e.g., identifying hotspots where users work and travel. Such queries can be answered efficiently by building histograms. However, precise histograms can expose sensitive details about individual users. Differential privacy (DP) is a mature and widely adopted protection model, but most approaches for DP-compliant histograms work in a data-independent fashion, leading to poor accuracy. The few proposed data-dependent techniques attempt to adjust histogram partitions based on dataset characteristics, but they do not perform well due to the addition of noise required to achieve DP. In addition, they use ad hoc criteria to decide the depth of the partitioning. We identify density homogeneity as a main factor driving the accuracy of DP-compliant histograms, and we build a data structure that splits the space such that data density is homogeneous within each resulting partition. We propose a self-tuning approach to decide the depth of the partitioning structure that optimizes the use of privacy budget. Furthermore, we provide an optimization that scales the proposed split approach to large datasets while maintaining accuracy. We show through extensive experiments on large-scale real-world data that the proposed approach achieves superior accuracy compared to existing approaches.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "40221713",
                    "name": "Sina Shaham"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "1939822",
                    "name": "Ritesh Ahuja"
                },
                {
                    "authorId": "79027713",
                    "name": "John Krumm"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                }
            ]
        }
    ]
}