{
    "authorId": "2284823063",
    "papers": [
        {
            "paperId": "2c6638f6c817b7dc94365e217138d5b60cc699fa",
            "title": "A Chinese Dataset for Evaluating the Safeguards in Large Language Models",
            "abstract": "Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks when LLMs are deployed. Previous studies have proposed comprehensive taxonomies of the risks posed by LLMs, as well as corresponding prompts that can be used to examine the safety mechanisms of LLMs. However, the focus has been almost exclusively on English, and little has been explored for other languages. Here we aim to bridge this gap. We first introduce a dataset for the safety evaluation of Chinese LLMs, and then extend it to two other scenarios that can be used to better identify false negative and false positive examples in terms of risky prompt rejections. We further present a set of fine-grained safety assessment criteria for each risk type, facilitating both manual annotation and automatic evaluation in terms of LLM response harmfulness. Our experiments on five LLMs show that region-specific risks are the prevalent type of risk, presenting the major issue with all Chinese LLMs we experimented with. Our data is available at https://github.com/Libr-AI/do-not-answer. Warning: this paper contains example data that may be offensive, harmful, or biased.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275119551",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "51230252",
                    "name": "Zenan Zhai"
                },
                {
                    "authorId": "49404498",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2110982198",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2284823063",
                    "name": "Lizhi Lin"
                },
                {
                    "authorId": "2284691442",
                    "name": "Zhenxuan Zhang"
                },
                {
                    "authorId": "2284725378",
                    "name": "Jingru Zhao"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "ed24b6814946c1975b0d86736055fa528b6419c0",
            "title": "Against The Achilles' Heel: A Survey on Red Teaming for Generative Models",
            "abstract": "Generative models are rapidly gaining popularity and being integrated into everyday applications, raising concerns over their safety issues as various vulnerabilities are exposed. Faced with the problem, the field of red teaming is experiencing fast-paced growth, which highlights the need for a comprehensive organization covering the entire pipeline and addressing emerging topics for the community. Our extensive survey, which examines over 120 papers, introduces a taxonomy of fine-grained attack strategies grounded in the inherent capabilities of language models. Additionally, we have developed the searcher framework that unifies various automatic red teaming approaches. Moreover, our survey covers novel areas including multimodal attacks and defenses, risks around multilingual models, overkill of harmless queries, and safety of downstream applications. We hope this survey can provide a systematic perspective on the field and unlock new areas of research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284823063",
                    "name": "Lizhi Lin"
                },
                {
                    "authorId": "2292039878",
                    "name": "Honglin Mu"
                },
                {
                    "authorId": "51230252",
                    "name": "Zenan Zhai"
                },
                {
                    "authorId": "2242189619",
                    "name": "Minghan Wang"
                },
                {
                    "authorId": "2275119551",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "2215688800",
                    "name": "Renxi Wang"
                },
                {
                    "authorId": "2294509423",
                    "name": "Junjie Gao"
                },
                {
                    "authorId": "2266000475",
                    "name": "Yixuan Zhang"
                },
                {
                    "authorId": "2292032004",
                    "name": "Wanxiang Che"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                },
                {
                    "authorId": "2110982198",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2266086775",
                    "name": "Haonan Li"
                }
            ]
        }
    ]
}