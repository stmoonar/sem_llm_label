{
    "authorId": "31026404",
    "papers": [
        {
            "paperId": "2907e8e322af55b7d06d57786d456c034fc89e05",
            "title": "GunStance: Stance Detection for Gun Control and Gun Regulation",
            "abstract": "The debate surrounding gun control and gun regulation in the United States has intensified in the wake of numerous mass shooting events. As perspectives on this matter vary, it becomes increasingly important to comprehend individuals\u2019 positions. Stance detection, the task of determining an author\u2019s position towards a proposition or target, has gained attention for its potential use in understanding public perceptions towards controversial topics and identifying the best strategies to address public concerns. In this paper, we present G UN S TANCE , a dataset of tweets pertaining to shooting events, focusing specifically on the controversial topics of \u201cbanning guns\u201d and \u201cregulating guns.\u201d The tweets in the dataset are sourced from discussions on Twitter following various shooting incidents in the United States. Amazon Mechanical Turk was used to manually annotate a subset of the tweets relevant to the targets of interest (\u201cbanning guns\u201d and \u201cregulating guns\u201d) into three classes: In-Favor , Against , and Neutral . The remaining unlabeled tweets are included in the dataset to facilitate studies on semi-supervised learning (SSL) approaches that can help address the scarcity of the labeled data in stance detection tasks. Furthermore, we propose a hybrid approach that combines curriculum-based SSL and Large Language Models (LLM), and show that the proposed approach outperforms supervised, semi-supervised, and LLM-based zero-shot models in most experiments on our assembled dataset. The dataset and code are available on GitHub. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1906359346",
                    "name": "Nikesh Gyawali"
                },
                {
                    "authorId": "2187455696",
                    "name": "Iustin Sirbu"
                },
                {
                    "authorId": "2008183567",
                    "name": "Tiberiu Sosea"
                },
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                },
                {
                    "authorId": "2796756",
                    "name": "Traian Rebedea"
                },
                {
                    "authorId": "2316579314",
                    "name": "Cornelia Caragea"
                }
            ]
        },
        {
            "paperId": "77b20188da592c7c2b913039e2bfcbb842e71ce5",
            "title": "Contrastive Learning for Multimodal Classification of Crisis related Tweets",
            "abstract": "Multimodal tasks require learning a joint representation of the constituent modalities of data. Contrastive learning learns a joint representation by using a contrastive loss. For example, CLIP takes as input image-caption pairs and is trained to maximize the similarity between an image and its corresponding caption in actual image-caption pairs, while minimizing the similarity for arbitrary image-caption pairs. This approach operates on the premise that the caption depicts the image's content. However, this assumption does not always hold true for tweets that contain both text and images. Previous studies have indicated that the connection between the image and the text in a tweet is more intricate and complex. We study the effectiveness of pre-trained multimodal contrastive learning models, specifically, CLIP, and ALIGN, on the task of classifying multimodal crisis related tweets. Our experiments using two publicly available datasets, CrisisMMD and DMD, show that despite the intricate relationships in tweets, pre-trained contrastive learning models fine-tuned with task-specific data produce better results than prior approaches used for the multimodal classification of crisis related tweets. Additionally, the experiments show that the contrastive learning models are effective in low-data few-shot and cross-domain settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1379987324",
                    "name": "Bishwas Mandal"
                },
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                }
            ]
        },
        {
            "paperId": "fbf52bb0fe6ac2c74d89f3c6debcc3872186f141",
            "title": "Leveraging Existing Literature on the Web and Deep Neural Models to Build a Knowledge Graph Focused on Water Quality and Health Risks",
            "abstract": "A knowledge graph focusing on water quality in relation to health risks posed by water activities (such as diving or swimming) is not currently available. To address this limitation, we first use existing resources to construct a knowledge graph relevant to water quality and health risks using KNowledge Acquisition and Representation Methodology (KNARM). Subsequently, we explore knowledge graph completion approaches for maintaining and updating the graph. Specifically, we manually identify a set of domain-specific UMLS concepts and use them to extract a graph of approximately 75,000 semantic triples from the Semantic MEDLINE database (which contains head-relation-tail triples extracted from PubMed). Using the resulting knowledge graph, we experiment with the KG-BERT approach for graph completion by employing pre-trained BERT/RoBERTa models and also models fine-tuned on a collection of water quality and health risks abstracts retrieved from the Web of Science. Experimental results show that KG-BERT with BERT/RoBERTa models fine-tuned on a domain-specific corpus improves the performance of KG-BERT with pre-trained models. Furthermore, KG-BERT gives better results than several translational distance or semantic matching baseline models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215549551",
                    "name": "Nikita Gautam"
                },
                {
                    "authorId": "2077244590",
                    "name": "David Shumway"
                },
                {
                    "authorId": "2215547288",
                    "name": "Megan Kowalcyk"
                },
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                },
                {
                    "authorId": "1690656",
                    "name": "Cornelia Caragea"
                },
                {
                    "authorId": "153612944",
                    "name": "H. Mcginty"
                },
                {
                    "authorId": "5524986",
                    "name": "S. Dorevitch"
                }
            ]
        },
        {
            "paperId": "56aca8daa848ceaa3932fe8441090f9c5e9aa005",
            "title": "Identification of Fine-Grained Location Mentions in Crisis Tweets",
            "abstract": "Identification of fine-grained location mentions in crisis tweets is central in transforming situational awareness information extracted from social media into actionable information. Most prior works have focused on identifying generic locations, without considering their specific types. To facilitate progress on the fine-grained location identification task, we assemble two tweet crisis datasets and manually annotate them with specific location types. The first dataset contains tweets from a mixed set of crisis events, while the second dataset contains tweets from the global COVID-19 pandemic. We investigate the performance of state-of-the-art deep learning models for sequence tagging on these datasets, in both in-domain and cross-domain settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "2140018304",
                    "name": "Maria Traskowsky"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                }
            ]
        },
        {
            "paperId": "7f0a0ffa78123c49beb50a405d7461b3a2ccbd61",
            "title": "Multi-task Learning to Enable Location Mention Identification in the Early Hours of a Crisis Event",
            "abstract": "Training a robust and reliable deep learning model requires a large amount of data. In the crisis domain, building deep learning models to identify actionable information from the huge influx of data posted by eyewitnesses of crisis events on social media, in a time-critical manner, is central for fast response and relief operations. However, building a large, annotated dataset to train deep learning models is not always feasible in a crisis situation. In this paper, we investigate a multi-task learning approach to concurrently leverage available annotated data for several related tasks from the crisis domain to improve the performance on a main task with limited annotated data. Specifically, we focus on using multi-task learning to improve the performance on the task of identifying location mentions in crisis tweets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                }
            ]
        },
        {
            "paperId": "9d97b26877c51030ff7d89abae491803651320ed",
            "title": "Stance Detection in COVID-19 Tweets",
            "abstract": "The prevalence of the COVID-19 pandemic in day-to-day life has yielded large amounts of stance detection data on social media sites, as users turn to social media to share their views regarding various issues related to the pandemic, e.g. stay at home mandates and wearing face masks when out in public. We set out to make use of this data by collecting the stance expressed by Twitter users, with respect to topics revolving around the pandemic. We annotate a new stance detection dataset, called COVID-19-Stance. Using this newly annotated dataset, we train several established stance detection models to ascertain a baseline performance for this specific task. To further improve the performance, we employ self-training and domain adaptation approaches to take advantage of large amounts of unlabeled data and existing stance detection datasets. The dataset, code, and other resources are available on GitHub.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059008842",
                    "name": "Kyle Glandt"
                },
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "50820271",
                    "name": "Yingjie Li"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                },
                {
                    "authorId": "1690656",
                    "name": "Cornelia Caragea"
                }
            ]
        },
        {
            "paperId": "d4e419898cbd39a43a15ecb7ed6d512bc44895e8",
            "title": "Using Content Analysis and Machine Learning to Identify COVID-19 Information Relevant to Low-income Households on Social Media",
            "abstract": "COVID-19 pandemic has caused great distress in the lives of many populations. Low-income households are among the most severely impacted groups in the United States and across the globe. Using social media, this paper aims to identify and organize the information about the impact of the pandemic on low-income households. We use content analysis to derive an annotation protocol and manually annotate a tweet dataset using this protocol. Furthermore, we use machine learning to learn models from the annotated dataset. We also employ a human-in-the-loop data augmentation procedure to improve the model\u2019s performance for the underrepresented classes. Our results show that using carefully annotated data, automated machine learning models can be trained and employed to identify information relevant to low income households, potentially in real time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "2146732874",
                    "name": "Rus Refati"
                },
                {
                    "authorId": "2059008842",
                    "name": "Kyle Glandt"
                },
                {
                    "authorId": "151505506",
                    "name": "Doina Caragea"
                },
                {
                    "authorId": "48923076",
                    "name": "Sifan Xu"
                },
                {
                    "authorId": "2118014651",
                    "name": "Chien-Fei Chen"
                }
            ]
        },
        {
            "paperId": "bfcdcd43d0f279159a8dfbf80e35c5978d89c2c1",
            "title": "Multi-stage rejection sampling (MSRS): A robust SRP-PHAT peak detection algorithm for localization of cocktail-party talkers",
            "abstract": "The Steered Response Power using the Phase Transform weight (SRP-PHAT) has been shown to be robust in noisy and reverberant conditions. Also, volume contraction has been applied effectively to trap the global maximum for densely-hilly 3-D spaces like the SRP. However, previous methods have suffered from the presence of peaks representing multiple talkers in close proximity as is likely in a conversational cocktail-party setting. We present a volume contraction algorithm called Multi-Stage Rejection Sampling (MSRS) for detection of multiple peaks in the SRP-PHAT space. Our method not only circumvents sorting - a computationally expensive step in volume contraction algorithms - but also automatically divides a search volume into sub-volumes for robust detection of multiple peaks. We discuss some modifications to the standard SRP-PHAT functional and present results using all real-room data for baseline white-noise, an eight-speaker teleconferencing setup and a fully unconstrained cocktail-party situation containing about 21 persons in the room.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "1748100",
                    "name": "H. Silverman"
                }
            ]
        },
        {
            "paperId": "9f32125df44fe9dab7d5efa6ddad7e97883f2530",
            "title": "A Free-Source Method (FrSM) for Calibrating a Large-Aperture Microphone Array",
            "abstract": "Large-aperture microphone arrays can be used to capture and enhance speech from individual talkers in noisy, multi-talker, and reverberant environments. However, they must be calibrated, often more than once, to obtain accurate 3-dimensional coordinates for all microphones. Direct-measurement techniques, such as using a measuring tape or a laser-based tool are cumbersome and time-consuming. Some previous methods that used acoustic signals for array calibration required bulky hardware and/or fixed, known source locations. Others, which allowed more flexible source placement, often have issues with real data, have reported results for 2D only, or work only for small arrays. This paper describes a complete and robust method for automatic calibration using acoustic signals which is simple, repeatable, accurate, and has been shown to work for a real system. The method requires only a single transducer (speaker) with a microphone attached above its center. The unit is freely moved around the focal volume of the microphone array generating a single long recording from all the microphones. After that, the system is completely automatic. We describe the free source method (FrSM), validate its effectiveness and present accuracy results against measured ground truth. The performance of FrSM is compared to that from several other methods for a real 128-microphone array.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31026404",
                    "name": "Sarthak Khanal"
                },
                {
                    "authorId": "1748100",
                    "name": "H. Silverman"
                },
                {
                    "authorId": "3287434",
                    "name": "Rahul R. Shakya"
                }
            ]
        }
    ]
}