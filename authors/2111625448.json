{
    "authorId": "2111625448",
    "papers": [
        {
            "paperId": "a8bea1c8c5f1d581d6ac78415fa1492e95f8b01a",
            "title": "On the Generalization Capability of Temporal Graph Learning Algorithms: Theoretical Insights and a Simpler Method",
            "abstract": "Temporal Graph Learning (TGL) has become a prevalent technique across diverse real-world applications, especially in domains where data can be represented as a graph and evolves over time. Although TGL has recently seen notable progress in algorithmic solutions, its theoretical foundations remain largely unexplored. This paper aims at bridging this gap by investigating the generalization ability of different TGL algorithms (e.g., GNN-based, RNN-based, and memory-based methods) under the finite-wide over-parameterized regime. We establish the connection between the generalization error of TGL algorithms and\"the number of layers/steps\"in the GNN-/RNN-based TGL methods and\"the feature-label alignment (FLA) score\", where FLA can be used as a proxy for the expressive power and explains the performance of memory-based methods. Guided by our theoretical analysis, we propose Simplified-Temporal-Graph-Network, which enjoys a small generalization error, improved overall performance, and lower model complexity. Extensive experiments on real-world datasets demonstrate the effectiveness of our method. Our theoretical findings and proposed algorithm offer essential insights into TGL from a theoretical standpoint, laying the groundwork for the designing practical TGL algorithms in future studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22244104",
                    "name": "Weilin Cong"
                },
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "2256983432",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "2075280868",
                    "name": "Mehrdad Mahdavi"
                }
            ]
        },
        {
            "paperId": "8cdadf2c186a63528d2094de7d48e4635147a66c",
            "title": "Ensuring User-side Fairness in Dynamic Recommender Systems",
            "abstract": "User-side group fairness is crucial for modern recommender systems, alleviating performance disparities among user groups defined by sensitive attributes like gender, race, or age. In the everevolving landscape of user-item interactions, continual adaptation to newly collected data is crucial for recommender systems to stay aligned with the latest user preferences. However, we observe that such continual adaptation often worsen performance disparities. This necessitates a thorough investigation into user-side fairness in dynamic recommender systems. This problem is challenging due to distribution shifts, frequent model updates, and nondifferentiability of ranking metrics. To our knowledge, this paper presents the first principled study on ensuring user-side fairness in dynamic recommender systems. We start with theoretical analyses on fine-tuning v.s. retraining, showing that the best practice is incremental fine-tuning with restart. Guided by our theoretical analyses, we propose FAir Dynamic rEcommender (FADE), an end-to-end fine-tuning framework to dynamically ensure user-side fairness over time. To overcome the non-differentiability of recommendation metrics in the fairness loss, we further introduce Differentiable Hit (DH) as an improvement over the recent NeuralNDCG method, not only alleviating its gradient vanishing issue but also achieving higher efficiency. Besides that, we also address the instability issue of the fairness loss by leveraging the competing nature between the recommendation loss and the fairness loss. Through extensive experiments on real-world datasets, we demonstrate that FADE effectively and efficiently reduces performance disparities with little sacrifice in the overall recommendation performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154454915",
                    "name": "Hyunsik Yoo"
                },
                {
                    "authorId": "2215437587",
                    "name": "Zhichen Zeng"
                },
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "4691481",
                    "name": "Zhining Liu"
                },
                {
                    "authorId": "2235338301",
                    "name": "David Zhou"
                },
                {
                    "authorId": "1682816",
                    "name": "Fei Wang"
                },
                {
                    "authorId": "2235777469",
                    "name": "Eunice Chan"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "a78da05384191d8a9b1d6b6f04a9d7de591ed367",
            "title": "Deceptive Fairness Attacks on Graphs via Meta Learning",
            "abstract": "We study deceptive fairness attacks on graphs to answer the following question: How can we achieve poisoning attacks on a graph learning model to exacerbate the bias deceptively? We answer this question via a bi-level optimization problem and propose a meta learning-based framework named FATE. FATE is broadly applicable with respect to various fairness definitions and graph learning models, as well as arbitrary choices of manipulation operations. We further instantiate FATE to attack statistical parity and individual fairness on graph neural networks. We conduct extensive experimental evaluations on real-world datasets in the task of semi-supervised node classification. The experimental results demonstrate that FATE could amplify the bias of graph neural networks with or without fairness consideration while maintaining the utility on the downstream task. We hope this paper provides insights into the adversarial robustness of fair graph learning and can shed light on designing robust and fair graph learning in future studies.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "2258547648",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "2261389328",
                    "name": "Ross Maciejewski"
                },
                {
                    "authorId": "2261491659",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "2256983432",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "c90f9a23ccb2b2b671f72e656a914c30c5381ab0",
            "title": "BeMap: Balanced Message Passing for Fair Graph Neural Network",
            "abstract": "Fairness in graph neural networks has been actively studied recently. However, existing works often do not explicitly consider the role of message passing in introducing or amplifying the bias. In this paper, we first investigate the problem of bias amplification in message passing. We empirically and theoretically demonstrate that message passing could amplify the bias when the 1-hop neighbors from different demographic groups are unbalanced. Guided by such analyses, we propose BeMap, a fair message passing method, that leverages a balance-aware sampling strategy to balance the number of the 1-hop neighbors of each node among different demographic groups. Extensive experiments on node classification demonstrate the efficacy of BeMap in mitigating bias while maintaining classification accuracy. The code is available at https://github.com/xiaolin-cs/BeMap.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2219728040",
                    "name": "Xiao Lin"
                },
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "22244104",
                    "name": "Weilin Cong"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "ed23b5871365c873f3958210f2accce353c20db6",
            "title": "Do We Really Need Complicated Model Architectures For Temporal Networks?",
            "abstract": "Recurrent neural network (RNN) and self-attention mechanism (SAM) are the de facto methods to extract spatial-temporal information for temporal graph learning. Interestingly, we found that although both RNN and SAM could lead to a good performance, in practice neither of them is always necessary. In this paper, we propose GraphMixer, a conceptually and technically simple architecture that consists of three components: (1) a link-encoder that is only based on multi-layer perceptrons (MLP) to summarize the information from temporal links, (2) a node-encoder that is only based on neighbor mean-pooling to summarize node information, and (3) an MLP-based link classifier that performs link prediction based on the outputs of the encoders. Despite its simplicity, GraphMixer attains an outstanding performance on temporal link prediction benchmarks with faster convergence and better generalization performance. These results motivate us to rethink the importance of simpler model architecture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22244104",
                    "name": "Weilin Cong"
                },
                {
                    "authorId": "2108336397",
                    "name": "Si Zhang"
                },
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "36088463",
                    "name": "Baichuan Yuan"
                },
                {
                    "authorId": "2119798365",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2148929404",
                    "name": "Xin Zhou"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                },
                {
                    "authorId": "2075280868",
                    "name": "Mehrdad Mahdavi"
                }
            ]
        },
        {
            "paperId": "20f83c85fb694a77ff8050699e2f85aa68f1b5f4",
            "title": "RawlsGCN: Towards Rawlsian Difference Principle on Graph Convolutional Network",
            "abstract": "Graph Convolutional Network (GCN) plays pivotal roles in many real-world applications. Despite the successes of GCN deployment, GCN often exhibits performance disparity with respect to node degrees, resulting in worse predictive accuracy for low-degree nodes. We formulate the problem of mitigating the degree-related performance disparity in GCN from the perspective of the Rawlsian difference principle, which is originated from the theory of distributive justice. Mathematically, we aim to balance the utility between low-degree nodes and high-degree nodes while minimizing the task-specific loss. Specifically, we reveal the root cause of this degree-related unfairness by analyzing the gradients of weight matrices in GCN. Guided by the gradients of weight matrices, we further propose a pre-processing method RawlsGCN-Graph and an in-processing method RawlsGCN-Grad that achieves fair predictive accuracy in low-degree nodes without modification on the GCN architecture or introduction of additional parameters. Extensive experiments on real-world graphs demonstrate the effectiveness of our proposed RawlsGCN methods in significantly reducing degree-related bias while retaining comparable overall performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "2116782926",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "632372a8f86305a8de242edb47588467e9f783e2",
            "title": "JuryGCN: Quantifying Jackknife Uncertainty on Graph Convolutional Networks",
            "abstract": "Graph Convolutional Network (GCN) has exhibited strong empirical performance in many real-world applications. The vast majority of existing works on GCN primarily focus on the accuracy while ignoring how confident or uncertain a GCN is with respect to its predictions. Despite being a cornerstone of trustworthy graph mining, uncertainty quantification on GCN has not been well studied and the scarce existing efforts either fail to provide deterministic quantification or have to change the training procedure of GCN by introducing additional parameters or architectures. In this paper, we propose the first frequentist-based approach named JuryGCN in quantifying the uncertainty of GCN, where the key idea is to quantify the uncertainty of a node as the width of confidence interval by a jackknife estimator. Moreover, we leverage the influence functions to estimate the change in GCN parameters without re-training to scale up the computation. The proposed JuryGCN is capable of quantifying uncertainty deterministically without modifying the GCN architecture or introducing additional parameters. We perform extensive experimental evaluation on real-world datasets in the tasks of both active learning and semi-supervised node classification, which demonstrate the efficacy of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "1491243049",
                    "name": "Qinghai Zhou"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "90cb5bd3ed1963d9469cd187dd825385caac168f",
            "title": "Algorithmic Fairness on Graphs: Methods and Trends",
            "abstract": "Graph is a ubiquitous type of data that appears in many real-world applications, including social network analysis, recommendations and financial security. Important as it is, decades of research have developed plentiful computational models to mine graphs. Despite its prosperity, concerns with respect to the potential algorithmic discrimination have been grown recently. Algorithmic fairness on graphs, which aims to mitigate bias introduced or amplified during the graph mining process, is an attractive yet challenging research topic. The first challenge corresponds to the theoretical challenge, where the non-IID nature of graph data may not only invalidate the basic assumption behind many existing studies in fair machine learning, but also introduce new fairness definition(s) based on the inter-correlation between nodes rather than the existing fairness definition(s) in fair machine learning. The second challenge regarding its algorithmic aspect aims to understand how to balance the trade-off between model accuracy and fairness. This tutorial aims to (1) comprehensively review the state-of-the-art techniques to enforce algorithmic fairness on graphs and (2) enlighten the open challenges and future directions. We believe this tutorial could benefit researchers and practitioners from the areas of data mining, artificial intelligence and social science.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "a1700923cff56e2babb12fab55fe47545bd8d07b",
            "title": "iFiG: Individually Fair Multi-view Graph Clustering",
            "abstract": "A multi-view graph comprises multiple single-view graphs with the same set of nodes but different types of edges. In many real-world applications, graphs are often collected from multiple sources, forming multi-view graphs. For example, users could have accounts on numerous social platforms like Facebook and Twitter; the infrastructure network of cities exhibits different topologies considering different types of infrastructures (e.g., power grid, road network). Up to now, researchers have proposed a variety of multi-view graph mining models, including clustering [1] , embedding [2] , and graph neural networks [3] .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203125551",
                    "name": "Yian Wang"
                },
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "33642939",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                }
            ]
        },
        {
            "paperId": "ec7fca842668bfec92f762b6eba0ebf61b2369d2",
            "title": "TrustLOG: The First Workshop on Trustworthy Learning on Graphs",
            "abstract": "Learning on graphs (LOG) plays a pivotal role in various high-impact application domains. The past decades have developed tremendous theories, algorithms, and open-source systems in answering what/who questions on graphs. However, recent studies reveal that the state-of-the-art techniques for learning on graphs (LOG) are often not trustworthy in practice with respect to several social aspects (e.g., fairness, transparency, security). A natural research question to ask is: how can we make learning algorithms on graphs trustworthy? To answer this question, we propose a paradigm shift, from answering what and who LOG questions to understanding how and why LOG questions. The TrustLOG workshop provides a venue for presenting, discussing, and promoting frontier research on trustworthy learning on graphs. Moreover, TrustLOG will serve as an impulse for the LOG community to identify novel research problems and shed new light on future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111625448",
                    "name": "Jian Kang"
                },
                {
                    "authorId": "2108433254",
                    "name": "Shuaicheng Zhang"
                },
                {
                    "authorId": "2155883057",
                    "name": "Bo Li"
                },
                {
                    "authorId": "31108652",
                    "name": "Jingrui He"
                },
                {
                    "authorId": "2143385183",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "49407567",
                    "name": "Dawei Zhou"
                }
            ]
        }
    ]
}