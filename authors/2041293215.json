{
    "authorId": "2041293215",
    "papers": [
        {
            "paperId": "0ec8701ea9c7c88278aa2289602806aa8d956c9c",
            "title": "Operationalizing the Blueprint for an AI Bill of Rights: Recommendations for Practitioners, Researchers, and Policy Makers",
            "abstract": "As Artificial Intelligence (AI) tools are increasingly employed in diverse real-world applications, there has been significant interest in regulating these tools. To this end, several regulatory frameworks have been introduced by different countries worldwide. For example, the European Union recently passed the AI Act, the White House issued an Executive Order on safe, secure, and trustworthy AI, and the White House Office of Science and Technology Policy issued the Blueprint for an AI Bill of Rights (AI BoR). Many of these frameworks emphasize the need for auditing and improving the trustworthiness of AI tools, underscoring the importance of safety, privacy, explainability, fairness, and human fallback options. Although these regulatory frameworks highlight the necessity of enforcement, practitioners often lack detailed guidance on implementing them. Furthermore, the extensive research on operationalizing each of these aspects is frequently buried in technical papers that are difficult for practitioners to parse. In this write-up, we address this shortcoming by providing an accessible overview of existing literature related to operationalizing regulatory principles. We provide easy-to-understand summaries of state-of-the-art literature and highlight various gaps that exist between regulatory guidelines and existing AI research, including the trade-offs that emerge during operationalization. We hope that this work not only serves as a starting point for practitioners interested in learning more about operationalizing the regulatory guidelines outlined in the Blueprint for an AI BoR but also provides researchers with a list of critical open problems and gaps between regulations and state-of-the-art AI research. Finally, we note that this is a working paper and we invite feedback in line with the purpose of this document as described in the introduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "2160885489",
                    "name": "Usha Bhalla"
                },
                {
                    "authorId": "2310700639",
                    "name": "Suresh Venkatasubramanian"
                },
                {
                    "authorId": "2310699647",
                    "name": "Himabindu Lakkaraju"
                }
            ]
        },
        {
            "paperId": "44e77bdc6dd8c2e039daf1d6b537f304f75b362d",
            "title": "All Roads Lead to Rome? Exploring Representational Similarities Between Latent Spaces of Generative Image Models",
            "abstract": "Do different generative image models secretly learn similar underlying representations? We investigate this by measuring the latent space similarity of four different models: VAEs, GANs, Normalizing Flows (NFs), and Diffusion Models (DMs). Our methodology involves training linear maps between frozen latent spaces to\"stitch\"arbitrary pairs of encoders and decoders and measuring output-based and probe-based metrics on the resulting\"stitched'' models. Our main findings are that linear maps between latent spaces of performant models preserve most visual information even when latent sizes differ; for CelebA models, gender is the most similarly represented probe-able attribute. Finally we show on an NF that latent space representations converge early in training.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2224843950",
                    "name": "Charumathi Badrinath"
                },
                {
                    "authorId": "2160885489",
                    "name": "Usha Bhalla"
                },
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "2822290",
                    "name": "Suraj Srinivas"
                },
                {
                    "authorId": "2310699647",
                    "name": "Himabindu Lakkaraju"
                }
            ]
        },
        {
            "paperId": "8362c45885738f5246e163a9763e0270d229ca6b",
            "title": "Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE)",
            "abstract": "CLIP embeddings have demonstrated remarkable performance across a wide range of computer vision tasks. However, these high-dimensional, dense vector representations are not easily interpretable, restricting their usefulness in downstream applications that require transparency. In this work, we empirically show that CLIP's latent space is highly structured, and consequently that CLIP representations can be decomposed into their underlying semantic components. We leverage this understanding to propose a novel method, Sparse Linear Concept Embeddings (SpLiCE), for transforming CLIP representations into sparse linear combinations of human-interpretable concepts. Distinct from previous work, SpLiCE does not require concept labels and can be applied post hoc. Through extensive experimentation with multiple real-world datasets, we validate that the representations output by SpLiCE can explain and even replace traditional dense CLIP representations, maintaining equivalent downstream performance while significantly improving their interpretability. We also demonstrate several use cases of SpLiCE representations including detecting spurious correlations, model editing, and quantifying semantic shifts in datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2160885489",
                    "name": "Usha Bhalla"
                },
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "2822290",
                    "name": "Suraj Srinivas"
                },
                {
                    "authorId": "144717568",
                    "name": "F. Calmon"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                }
            ]
        },
        {
            "paperId": "a5380c02128f9210d680a042d0c0ab1c48a60d4c",
            "title": "Multi-Group Proportional Representation",
            "abstract": "Image search and retrieval tasks can perpetuate harmful stereotypes, erase cultural identities, and amplify social disparities. Current approaches to mitigate these representational harms balance the number of retrieved items across population groups defined by a small number of (often binary) attributes. However, most existing methods overlook intersectional groups determined by combinations of group attributes, such as gender, race, and ethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel metric that measures representation across intersectional groups. We develop practical methods for estimating MPR, provide theoretical guarantees, and propose optimization algorithms to ensure MPR in retrieval. We demonstrate that existing methods optimizing for equal and proportional representation metrics may fail to promote MPR. Crucially, our work shows that optimizing MPR yields more proportional representation across multiple intersectional groups specified by a rich function class, often with minimal compromise in retrieval accuracy.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "52015628",
                    "name": "C. M. Verdun"
                },
                {
                    "authorId": "2220214891",
                    "name": "Carol Xuan Long"
                },
                {
                    "authorId": "2310697251",
                    "name": "Alex Glynn"
                },
                {
                    "authorId": "153835786",
                    "name": "Lucas Monteiro Paes"
                },
                {
                    "authorId": "1598458883",
                    "name": "Sajani Vithana"
                },
                {
                    "authorId": "2310697237",
                    "name": "Martina Cardone"
                },
                {
                    "authorId": "144717568",
                    "name": "F. Calmon"
                }
            ]
        },
        {
            "paperId": "c3aa2ccd6b260a90e8d8b95d1dd794bb2b48e474",
            "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities",
            "abstract": "The Right to be Forgotten is a core principle outlined by regulatory frameworks such as the EU's General Data Protection Regulation (GDPR). This principle allows individuals to request that their personal data be deleted from deployed machine learning models. While\"forgetting\"can be naively achieved by retraining on the remaining dataset, it is computationally expensive to do to so with each new request. As such, several machine unlearning methods have been proposed as efficient alternatives to retraining. These methods aim to approximate the predictive performance of retraining, but fail to consider how unlearning impacts other properties critical to real-world applications such as fairness. In this work, we demonstrate that most efficient unlearning methods cannot accommodate popular fairness interventions, and we propose the first fair machine unlearning method that can efficiently unlearn data instances from a fair objective. We derive theoretical results which demonstrate that our method can provably unlearn data and provably maintain fairness performance. Extensive experimentation with real-world datasets highlight the efficacy of our method at unlearning data instances while preserving fairness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "47793019",
                    "name": "Jiaqi Ma"
                },
                {
                    "authorId": "144717568",
                    "name": "F. Calmon"
                },
                {
                    "authorId": "2310699647",
                    "name": "Himabindu Lakkaraju"
                }
            ]
        },
        {
            "paperId": "093000d09d7f69790cc2e67a9f57219474387866",
            "title": "Distributionally Robust Group Backwards Compatibility",
            "abstract": "Machine learning models are updated as new data is acquired or new architectures are developed. These updates usually increase model performance, but may introduce backward compatibility errors, where individual users or groups of users see their performance on the updated model adversely affected. This problem can also be present when training datasets do not accurately reflect overall population demographics, with some groups having overall lower participation in the data collection process, posing a significant fairness concern. We analyze how ideas from distributional robustness and minimax fairness can aid backward compatibility in this scenario, and propose two methods to directly address this issue. Our theoretical analysis is backed by experimental results on CIFAR-10, CelebA, and Waterbirds, three standard image classification datasets. Code available at github.com/natalialmg/GroupBC",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37335063",
                    "name": "Mart\u00edn Bertr\u00e1n"
                },
                {
                    "authorId": "144323649",
                    "name": "Natalia Mart\u00ednez"
                },
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "1699339",
                    "name": "G. Sapiro"
                }
            ]
        },
        {
            "paperId": "227351021378ccc442dfa48391a8d59668a20750",
            "title": "Multitask Learning for Citation Purpose Classification",
            "abstract": "We present our entry into the 2021 3C Shared Task Citation Context Classification based on Purpose competition. The goal of the competition is to classify a citation in a scientific article based on its purpose. This task is important because it could potentially lead to more comprehensive ways of summarizing the purpose and uses of scientific articles, but it is also difficult, mainly due to the limited amount of available training data in which the purposes of each citation have been hand-labeled, along with the subjectivity of these labels. Our entry in the competition is a multi-task model that combines multiple modules designed to handle the problem from different perspectives, including hand-generated linguistic features, TF-IDF features, and an LSTM-with-attention model. We also provide an ablation study and feature analysis whose insights could lead to future work.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "2045172206",
                    "name": "Angikar Ghosal"
                },
                {
                    "authorId": "145353937",
                    "name": "Haoyang Yu"
                },
                {
                    "authorId": "2115140387",
                    "name": "Rui Xin"
                },
                {
                    "authorId": "2115146339",
                    "name": "Yasa Baig"
                },
                {
                    "authorId": "151489878",
                    "name": "Lesia Semenova"
                },
                {
                    "authorId": "48395540",
                    "name": "C. Rudin"
                }
            ]
        },
        {
            "paperId": "ec9a78394049682ea25c7e9260b92b119f4fd948",
            "title": "Detecting Motion in a Room Using a Dynamic Metasurface Antenna",
            "abstract": "Sensing motion and distinguishing its source as human or nonhuman, with high precision, has tremendous applications in a variety of areas from health monitoring to energy efficiency. One strategy to achieve this goal is to detect the small motion of breathing, which is a consistent indicator of human presence. Among the many smart sensing schemes proposed, microwave and RF sensors have shown great promise due to their simplicity, privacy, and effective range. In this paper, we propose the use of a dynamic metasurface antenna (DMAs) as an alternative hardware platform for sensing motion inside a residential setting using microwave signals. The proposed device is a single-port planar cavity that excites an array of electronically-tunable metamaterial elements. The DMA can generate spatially diverse patterns at a single frequency, avoiding complexities related to wideband operation or high hardware costs of antenna arrays. We demonstrate that it is capable of detecting minute movements, such as breathing emulated by a mannequin, to distinguish human presence. This motion can be detected whether the target is in the the sensor\u2019s direct line of sight or out of the direct line of sight. Furthermore, we show that the DMA sensing platform requires a single noise-floor calibration and can operate in different room geometries or configurations (e.g. when furniture is displaced). The proposed DMA-sensor with its single frequency operation and simple hardware is an appealing alternative hardware for intruder detection, human presence detection/activity recognition in smart homes, or seamless health monitoring.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2041293215",
                    "name": "Alexander X. Oesterling"
                },
                {
                    "authorId": "2199764",
                    "name": "M. Imani"
                },
                {
                    "authorId": "1557391652",
                    "name": "O. Mizrahi"
                },
                {
                    "authorId": "3417666",
                    "name": "J. Gollub"
                },
                {
                    "authorId": "144297348",
                    "name": "David R. Smith"
                }
            ]
        }
    ]
}