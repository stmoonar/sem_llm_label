{
    "authorId": "144540186",
    "papers": [
        {
            "paperId": "1a207a15fccb9a83f1331f7e2d0205606ce7dd0f",
            "title": "An Extensive Investigation of Machine Learning Techniques for Sleep Apnea Screening",
            "abstract": "The identification of Obstructive Sleep Apnea (OSA) relies on laborious and expensive polysomnography (PSG) exams. However, it is known that other factors, easier to measure, can be good indicators of OSA and its severity. In this work, we extensively investigate the use of Machine Learning techniques in the task of determining which factors are more revealing with respect to OSA along with a discussion of the challenges to perform such a task. We ran extensive experiments over 1,042 patients from the Centre Hospitalier Universitaire of the city of Grenoble, France. The data included ordinary clinical information, and PSG results as baseline. We employed data preparation techniques including cleaning of outliers, imputation of missing values, and synthetic data generation. Following, we performed an exhaustive attribute selection scheme to find the most representative features. We found that the prediction of OSA depends largely on variables related to age, body mass, and sleep habits more than the ones related to alcoholism, tabagism, and depression. Next, we tested 60 regression/classification algorithms to predict the Apnea-Hypopnea Index (AHI), and the AHI-based severity of OSA. We achieved performances significantly superior to the state of the art both for AHI regression and classification. Our results can benefit the development of tools for the automatic screening of patients who should go through polysomnography and further treatments of OSA -- currently, our work in under consideration for production by the Centre Hospitalier Universitaire of Grenoble. Our thorough methodology enables experimental reproducibility on similar OSA-detection problems, and more generally, on other problems with similar data models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "143780405",
                    "name": "J. P\u00e9pin"
                },
                {
                    "authorId": "144354285",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "edee78a4e5d93b0255f81500476a03965e0060ff",
            "title": "Transforming Two Decades of ePR Data to OMOP CDM for Clinical Research",
            "abstract": "This paper presents the extract-transform-and-load (ETL) process from the Electronic Patient Records (ePR) at the Heart Institute (InCor) to the OMOP Common Data Model (CDM) format. We describe the initial database characterization, relational source mappings, selection filters, data transformations and patient de-identification using the open-source OHDSI tools and SQL scripts. We evaluate the resulting InCor-CDM database by recreating the same patient cohort from a previous reference study (over the original data source) and comparing the cohorts' descriptive statistics and inclusion reports. The results exhibit that up to 91% of the reference patients were retrieved by our method from the ePR through InCor-CDM, with AUC=0.938. The results indicate that the method that we employed was able to produce a new database that was both consistent with the original data and in accordance to the OMOP CDM standard.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2220935",
                    "name": "D. M. Lima"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "31777914",
                    "name": "F. A. Pires"
                },
                {
                    "authorId": "144381171",
                    "name": "M. A. Gutierrez"
                }
            ]
        },
        {
            "paperId": "d3a2c332b79a759a8e8286e734bdaf93bdc33d13",
            "title": "A Computational Method for Interactive Design of Marbling Patterns",
            "abstract": "Paper marbling is a painting process where the artist makes use of special tools to carefully interact with paints deposited on an aqueous surface to produce marblelike paintings transferred to an absorbent paper. In this work, we present an interactive and intuitive application that simulates the marbling process digitally in real-time. To this end, we first map the artist tools into a simple and intuitive user interface. Secondly, we employ a Navier-Stokes equations solver on the GPU with a multi-layer approach to handling multiple colored paints with support to lighting and paints undulations. Our system accomplishes interactive frame-rates while manipulating tens of distinct colored paints, a requisite to applications like digital games. Results show the effectiveness of our real-time digital marbling system, providing to the artists an intuitive work interface.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2586825",
                    "name": "M. Gazziro"
                },
                {
                    "authorId": "2979908",
                    "name": "J. P. Gois"
                },
                {
                    "authorId": "49621281",
                    "name": "Candy Gonzales"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "eccea26d9183fac3ce184a92ef1be96755f385c5",
            "title": "TendeR-Sims - Similarity Retrieval System for Public Tenders",
            "abstract": "TendeR-Sims (Tender Retrieval by Similarity) is a system that helps to search for satisfiable request for tender\u2019s lots in a database by filtering irrelevant lots, so companies can easily discover the contracts they can win. The system implements the Similarity-aware Relational Division Operator in a commercial Relational Database Management System (RDBMS), and compares products by combining a path distance in a preprocessed ontology with a textual distance. Tender-Sims focuses on answering the following query: select the lots where a company has a similar enough item for each of all required items. We evaluated our proposed system employing a dataset composed of product catologs of Brazilian companies in the food market and real requests for tenders with known results. In the presented experiments, TendeR Sims achieved up to 66% cost reduction at 90% recall when compared to the ground truth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40990317",
                    "name": "Guilherme Q. Vasconcelos"
                },
                {
                    "authorId": "40991665",
                    "name": "Guilherme F. Zabot"
                },
                {
                    "authorId": "2220935",
                    "name": "D. M. Lima"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "3149323",
                    "name": "D. S. Kaster"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                }
            ]
        },
        {
            "paperId": "f5f6c2206e269a001095b84e3de2de7e00d95d63",
            "title": "A comparative analysis of the automatic modeling of Learning Styles through Machine Learning techniques",
            "abstract": "This Research Full Paper introduces a machine learning methodology to automatically identify the learning style of students interacting with a Learning Management System. Studies in Cognitive Psychology and Pedagogy have already reported that each individual has a specific Learning Style, which describes her/his best means of perceiving and acquiring knowledge. The detection of the personal Learning Style of each student has long been made by using questionnaires; an analysis that demands too much effort, mainly in courses with hundreds of students. Therefore, the automatic modeling of learning styles has gained attention in the computing and education areas. This study compares different Machine Learning algorithms for the detection of students\u2019 Learning Styles. As such, a dataset is extracted from a real course in the Moodle learning platform. This course had 105 students interacting with 252 learning objects during 12 months. The learning styles were described using the classic model of Felder-Silverman. According to the experimental results using these data, a single machine learning algorithm was not able to induce models with predictive accuracy comparable to those from existing alternatives. However, when models from different algorithms were combined, it was possible to obtain a predictive accuracy superior to those reported in the related literature.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144243979",
                    "name": "Lucas D. Ferreira"
                },
                {
                    "authorId": "8167068",
                    "name": "Gabriel Spadon"
                },
                {
                    "authorId": "143618972",
                    "name": "A. Carvalho"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "ff745139c1869ab3f3899b83a0c8e2b3be0606db",
            "title": "RAFIKI: Retrieval-Based Application for Imaging and Knowledge Investigation",
            "abstract": "Medical exams, such as CT scans and mammograms, are obtained and stored every day in hospitals all over the world, including images, patient data, and medical reports. It is paramount to have tools and systems to improve computer-aided diagnoses based on such huge volumes of stored information. The Content-Based Image Retrieval (CBIR) is a powerful paradigm to help reaching such a goal, providing physicians with intelligent retrieval tools to present him/her with similar or complementary cases, in which visual characteristics improve textual data. Employing comparative inspection on previous cases, the physician can obtain a more comprehensive understanding of the case he/she is working on. Current hospital systems do not carry native CBIR functionalities yet, relying on add-on subsystems, which often do not adhere to the existing relational database infrastructures. In this work, we propose RAFIKI, a software prototype that extends the Relational Database Management System (RDBMS) PostgreSQL, providing native support for CBIR functionalities, modular extensibility, and seamless integration for data science tools, such as Python and R. We show the applicability of our system by evaluating three clinical scenarios, performing queries over a real-world image dataset of lung exams. Our results spot actual potential in promoting informed decision-making from the physician's perspective. Besides, the system exhibited a higher performance when compared to previous systems found in the literature. Moreover, RAFIKI contributes with a model to establish how to put together CBIR concepts and relational data, providing a powerful design for further development of theoretical and practical concepts and tools.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29343183",
                    "name": "Marcos Roberto Nesso Junior"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "3440669",
                    "name": "L. C. Scabora"
                },
                {
                    "authorId": "144646435",
                    "name": "Paulo H. Oliveira"
                },
                {
                    "authorId": "8167068",
                    "name": "Gabriel Spadon"
                },
                {
                    "authorId": "3023434",
                    "name": "J. D. Souza"
                },
                {
                    "authorId": "143771906",
                    "name": "Willian D. Oliveira"
                },
                {
                    "authorId": "39159322",
                    "name": "D. Y. T. Chino"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "0393d755050c9fe735f841a863c28f4225535f8c",
            "title": "Fire Detection on Unconstrained Videos Using Color-Aware Spatial Modeling and Motion Flow",
            "abstract": "The semantic segmentation of events on emergency contexts involves the identification of previously defined events of interest. In this work, the focused semantic event is the presence of fire in videos. The literature presents several methods for automatic video fire detection, but these methods were built under assumptions, such as stationary cameras and controlled lightening conditions that are often in contrast to the videos acquired by hand-held devices. To fulfill this gap, we propose a fire detection method, called SPATFIRE. Our method innovates on three aspects: (1) it relies on a specifically tailored color model named Fire-like Pixel Detector able to improve the accuracy of fire detection, (2) it employs a new technique for motion compensation, diminishing the problems observed in videos captured with non-stationary cameras, and, (3) it defines a segmentation method able to identify, not only the presence of fire in a video, but also the segments in the video where fire occurs. We experimented our proposal on two video datasets with different characteristics and summarize the results to demonstrate the superior efficacy, in terms of true positives and negatives, as compared to state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1931515",
                    "name": "Letricia P. S. Avalhais"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "36e146bf6429c1a6281f84236be4c047ffc86cad",
            "title": "Unveiling smoke in social images with the SmokeBlock approach",
            "abstract": "Can we use information from social media and crowdsourced images to detect smoke and assist rescue forces? While there are computer vision methods for detecting smoke, they require movement information extracted from video data. In this paper we propose SmokeBlock: a method that is able to segment and detect smoke in still images. SmokeBlock uses superpixel segmentation and extracts local color and texture features from images to spot smoke. We used real data from Flickr and compared SmokeBlock against state-of-the-art methods for feature extraction. Our method achieved performance superior than the competitors, for the task of smoke detection. Our findings shall support further investigations in the field of image analysis, in particular, concerning images captured with mobile devices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "2407470",
                    "name": "M. Bedo"
                },
                {
                    "authorId": "1819014",
                    "name": "Alceu Ferraz Costa"
                },
                {
                    "authorId": "3023434",
                    "name": "J. D. Souza"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "643db77a4eda365f7cf516b7dbf9036eff2f4218",
            "title": "Vertex Centric Asynchronous Belief Propagation Algorithm for Large-Scale Graphs",
            "abstract": "Inference problems on networks and their algorithms were always important subjects, but more so now with so much data available and so little time to make sense of it. Common applications range from product recommendation to social networks and protein interaction. One of the main inferences in this types of networks is the guilty-by-association method, where labeled nodes propagate their information throughout the network, towards unlabeled nodes. While there is a widely used algorithm for this context, called Belief Propagation, it lacks the necessary convergence guarantees for loopy-networks. More recently, a new alternative method was proposed, called LinBP and while it solved the convergence issue, the scalability for large graphs that do not fit memory remains a challenge. Additionally, most works that try to use BP considering large scale graphs rely on specific infrastructure such as supercomputers and computational clusters. Therefore we propose a new algorithm, that leverages state-of-the-art asynchronous vertex-centric parallel processing techniques in conjunction with the state-of-the-art BP alternative LinBP, to provide a scalable framework for large graph inference that runs on a single commodity machine. Our results show that our algorithm is up to 200 times faster than LinBP's SQL implementation on tested networks, while achieving the same accuracy rate. We also show that due to the asynchronous processing, our algorithm actually needs less iterations to converge when compared to LinBP when using the same parameters. Finally, we believe that our methodology highlights the yet not fully explored parallelism available on commodity machines, leaning towards a more cost-efficient computational paradigm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3347704",
                    "name": "Gabriel P. Gimenes"
                },
                {
                    "authorId": "1752441",
                    "name": "H. Gualdron"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "ad1a27868a204fbf142b458c9323980f5a34533f",
            "title": "Effective and Unsupervised Fractal-Based Feature Selection for Very Large Datasets: Removing Linear and Non-linear Attribute Correlations",
            "abstract": "Given a very large dataset of moderate-to-high dimensionality, how to mine useful patterns from it? In such cases, dimensionality reduction is essential to overcome the \"curse of dimensionality\". Although there exist algorithms to reduce the dimensionality of Big Data, unfortunately, they all fail to identify/eliminate non-linear correlations between attributes. This paper tackles the problem by exploring concepts of the Fractal Theory and massive parallel processing to present Curl-Remover, a novel dimensionality reduction technique for very large datasets. Our contributions are: Curl-Remover eliminates linear and non-linear attribute correlations as well as irrelevant ones, it is unsupervised and suits for analytical tasks in general \u2013 not only classification, it presents linear scale-up, it does not require the user to guess the number of attributes to be removed, and, it preserves the attributes' semantics. We performed experiments on synthetic and real data spanning up to 1.1 billion points and Curl-Remover outperformed a PCA-based algorithm, being up to 8% more accurate.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3440056",
                    "name": "Antonio C. Fraideinberze"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                }
            ]
        },
        {
            "paperId": "c6cde2c85d01bc69ffe4f67fe3365bb79d8a0915",
            "title": "On the Support of a Similarity-enabled Relational Database Management System in Civilian Crisis Situations",
            "abstract": "Crowdsourcing solutions can be helpful to extract information from disaster-related data during crisis management. However, certain information can only be obtained through similarity operations. Some of them also depend on additional data stored in a Relational Database Management System (RDBMS). In this context, several works focus on crisis management supported by data. Nevertheless, none of them provide a methodology for employing a similarity-enabled RDBMS in disaster-relief tasks. To fill this gap, we introduce a methodology together with the Data-Centric Crisis Management (DCCM) architecture, which employs our methods over a similarity-enabled RDBMS. We evaluate our proposal through three tasks: classification of incoming data regarding current events, identifying relevant information to guide rescue teams; filtering of incoming data, enhancing the decision support by removing near-duplicate data; and similarity retrieval of historical data, supporting analytical comprehension of the crisis context. To make it possible, similarity-based operations were implemented within one popular, open-source RDBMS. Results using real data from Flickr show that our proposal is feasible for real-time applications. In addition to high performance, accurate results were obtained with a proper combination of techniques for each task. Hence, we expect our work to provide a framework for further developments on crisis management solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144646435",
                    "name": "Paulo H. Oliveira"
                },
                {
                    "authorId": "3440056",
                    "name": "Antonio C. Fraideinberze"
                },
                {
                    "authorId": "3440212",
                    "name": "Natan A. Laverde"
                },
                {
                    "authorId": "1752441",
                    "name": "H. Gualdron"
                },
                {
                    "authorId": "10400583",
                    "name": "A. Gonzaga"
                },
                {
                    "authorId": "144243979",
                    "name": "Lucas D. Ferreira"
                },
                {
                    "authorId": "143771906",
                    "name": "Willian D. Oliveira"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "143732518",
                    "name": "Elaine P. M. de Sousa"
                }
            ]
        },
        {
            "paperId": "410f71d4637683819587a115c4a7430ffe3d8259",
            "title": "Techniques for Effective and Efficient Fire Detection from Social Media Images",
            "abstract": "Crowdsourcing and social media could provide valuable information to support decision making in crisis management, such as in accidents, explosions and fires. However, much of the data from social media are images, which are uploaded in a rate that makes it impossible for human beings to analyze them. Despite the many works on image analysis, there are no fire detection studies on social media. To fill this gap, we propose the use and evaluation of a broad set of content-based image retrieval and classification techniques for fire detection. Our main contributions are: (i) the development of the Fast-Fire Detection method (FFireDt), which combines feature extractor and evaluation functions to support instance-based learning; (ii) the construction of an annotated set of images with ground-truth depicting fire occurrences \u00e2\u0080\u0093 the Flickr-Fire dataset; and (iii) the evaluation of 36 efficient image descriptors for fire detection. Using real data from Flickr, our results showed that FFireDt was able to achieve a precision for fire detection that was comparable to that of human annotators. Therefore, our work shall provide a solid basis for further developments on monitoring images from social media and crowdsourcing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2407470",
                    "name": "M. Bedo"
                },
                {
                    "authorId": "144286937",
                    "name": "G. Blanco"
                },
                {
                    "authorId": "143771906",
                    "name": "Willian D. Oliveira"
                },
                {
                    "authorId": "2647968",
                    "name": "M. Cazzolato"
                },
                {
                    "authorId": "1819014",
                    "name": "Alceu Ferraz Costa"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "56a6d2d37ffc619078e0af249a5e542716904f30",
            "title": "ORFEL: super-fast detection of defamation and illegitimate promotion in online recommendation",
            "abstract": "What if a successful company starts to receive a torrent of low-valued (one or two stars) recommendations in its mobile apps from multiple users within a short (say one month) period? Is it legitimate evidence that the apps have lost quality, or an intentional plan (via lockstep behavior) to steal market share through defamation? In case of a systematic attack to one's reputation, it might not be possible to manually discern between legitimate and fraudulent interaction in the immense universe of possibilities of user-product recommendation. Previous works have focused on this issue, but none of them has considered the context, modeling, and scale that we work with in this paper. We propose one novel method named Online-Recommendation Fraud ExcLuder (\\ORFEL) to detect defamation and/or illegitimate promotion of online products using vertex-centric asynchronous parallel processing of bipartite (users-products) graphs. With an innovative algorithm, our results demonstrate efficacy -- detecting over $95\\%$ of potential attacks; and efficiency -- at least two orders of magnitude faster than the state-of-the-art. Over our new methodology, we introduce three contributions: (1) a new algorithmic solution; (2) a scalable approach; and (3) a novel context and modeling of the problem, which now addresses both defamation and illegitimate promotion. Our work deals with relevant issues of the Web 2.0, potentially augmenting the credibility of online recommendation to prevent losses to both customers and vendors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3347704",
                    "name": "Gabriel P. Gimenes"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                }
            ]
        },
        {
            "paperId": "65ae5f82063e111a79a2837ce3d15e112625a0ec",
            "title": "Multimodal graph-based analysis over the DBLP repository: critical discoveries and hypotheses",
            "abstract": "The use of graph theory for analyzing network-like data has gained central importance with the rise of the Web 2.0. However, many graph-based techniques are not well-disseminated and neither explored at their full potential, what might depend on a complimentary approach achieved with the combination of multiple techniques. This paper describes the systematic use of graph-based techniques of different types (multimodal) combining the resultant analytical insights around a common domain, the Digital Bibliography & Library Project (DBLP). To do so, we introduce an analytical ensemble based on statistical (degree, and weakly-connected components distribution), topological (average clustering coefficient, and effective diameter evolution), algorithmic (link prediction/machine learning), and algebraic techniques to inspect non-evident features of DBLP at the same time that we interpret the heterogeneous discoveries found along the work. As a result, we have put together a set of techniques demonstrating over DBLP what we call multimodal analysis, an innovative process of information understanding that demands a wide technical knowledge and a deep understanding of the data domain. We expect that our methodology and our findings will foster other multimodal analyses and also that they will bring light over the Computer Science research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3347704",
                    "name": "Gabriel P. Gimenes"
                },
                {
                    "authorId": "1752441",
                    "name": "H. Gualdron"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "2586825",
                    "name": "M. Gazziro"
                }
            ]
        },
        {
            "paperId": "6f02a2e02110f223adc54cbfaf84df4898c359cb",
            "title": "A survey on Information Visualization in light of Vision and Cognitive sciences",
            "abstract": "Information visualization techniques are built on a context with too many factors, making it di cult to systematically deal with their underlying bases. In the intent of promoting a better comprehension, here, we survey concepts on vision, cognition, and Information Visualization organized in a theorization named Visual Expression Model. With a reduced level of complexity, our model organizes the bases of visualization techniques; nevertheless, it is complete enough to discuss guidelines related to design and analytical tasks. Organized in a coherent account, our work introduces the following contributions: (1) Theoretical compilation of vision, cognition, and Information Visualization; (2) Meticulous discussions supported by vast literature; and (3) Recommendations to have visualizations satisfy visualcognitive aspects. We expect our contributions will improve the practice of InfoVis by promoting comprehension and by proposing the use of simple recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                },
                {
                    "authorId": "2110928516",
                    "name": "Maria Cristina Ferreira de Oliveira"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "76ff506549a686142ef6f4ec8bb1a8bf24bb27c7",
            "title": "M-Flash: Fast Billion-scale Graph Computation Using Block Partition Model",
            "abstract": "Recent graph computation approaches such as GraphChi, X-Stream, TurboGraph and MMap demonstrated that a single PC can perform ecient computation on billion scale graphs. While they use dierent techniques to achieve scalability through opti- mizing I/O operations, such optimization often does not fully exploit the capabilities of modern hard drives. We contribute: (1) a novel and scalable graph computation framework called M-Flash that uses a block partition model to boost computation speed and reduce disk ac- cesses, by logically dividing a graph and its node data into blocks that can fully t in RAM for reuse; (2) a exible and deliberatively simple programming model, as part of M-Flash, that enables us to implement pop- ular and essential graph algorithms, including the rst single-machine billion-scale eigensolver; and (3) exten- sive experiments on real graphs with up to 6.6 billion edges, demonstrating M-Flash's consistent and signi- cant speed-up against state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1752441",
                    "name": "H. Gualdron"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1793506",
                    "name": "Duen Horng Chau"
                },
                {
                    "authorId": "1768057",
                    "name": "Minsuk Kahng"
                },
                {
                    "authorId": "23987228",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "8c375552224ddf1b4ff9d53eeeb44410fd0e7d24",
            "title": "Large Graph Analysis in the GMine System",
            "abstract": "Current applications have produced graphs on the order of hundreds of thousands of nodes and millions of edges. To take advantage of such graphs, one must be able to find patterns, outliers, and communities. These tasks are better performed in an interactive environment, where human expertise can guide the process. For large graphs, though, there are some challenges: the excessive processing requirements are prohibitive, and drawing hundred-thousand nodes results in cluttered images hard to comprehend. To cope with these problems, we propose an innovative framework suited for any kind of tree-like graph visual design. GMine integrates 1) a representation for graphs organized as hierarchies of partitions-the concepts of SuperGraph and Graph-Tree; and 2) a graph summarization methodology-CEPS. Our graph representation deals with the problem of tracing the connection aspects of a graph hierarchy with sub linear complexity, allowing one to grasp the neighborhood of a single node or of a group of nodes in a single click. As a proof of concept, the visual environment of GMine is instantiated as a system in which large graphs can be investigated globally and locally.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "1943594",
                    "name": "Jia-Yu Pan"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                }
            ]
        },
        {
            "paperId": "e9c1abddace818f7a7a090bc263aa5e1aef8caec",
            "title": "StructMatrix: Large-Scale Visualization of Graphs by Means of Structure Detection and Dense Matrices",
            "abstract": "Given a large-scale graph with millions of nodes and edges, how to reveal macro patterns of interest, like cliques, bi-partite cores, stars, and chains? Furthermore, how to visualize such patterns altogether getting insights from the graph to support wise decision-making? Although there are many algorithmic and visual techniques to analyze graphs, none of the existing approaches is able to present the structural information of graphs at large-scale. Hence, this paper describes StructMatrix, a methodology aimed at high-scalable visual inspection of graph structures with the goal of revealing macro patterns of interest. StructMatrix combines algorithmic structure detection and adjacency matrix visualization to present cardinality, distribution, and relationship features of the structures found in a given graph. We performed experiments in real, large-scale graphs with up to one million nodes and millions of edges. StructMatrix revealed that graphs of high relevance (e.g., Web, Wikipedia and DBLP) have characterizations that reflect the nature of their corresponding domains, our findings have not been seen in the literature so far. We expect that our technique will bring deeper insights into large graph mining, leveraging their use for decision making.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1752441",
                    "name": "H. Gualdron"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "f0e888edfa52580c866360a45494e78ccdf14ffc",
            "title": "BoWFire: Detection of Fire in Still Images by Integrating Pixel Color and Texture Analysis",
            "abstract": "Emergency events involving fire are potentially harmful, demanding a fast and precise decision making. The use of crowd sourcing image and videos on crisis management systems can aid in these situations by providing more information than verbal/textual descriptions. Due to the usual high volume of data, automatic solutions need to discard non-relevant content without losing relevant information. There are several methods for fire detection on video using color-based models. However, they are not adequate for still image processing, because they can suffer on high false-positive results. These methods also suffer from parameters with little physical meaning, which makes fine tuning a difficult task. In this context, we propose a novel fire detection method for still images that uses classification based on color features combined with texture classification on super pixel regions. Our method uses a reduced number of parameters if compared to previous works, easing the process of fine tuning the method. Results show the effectiveness of our method of reducing false-positives while its precision remains compatible with the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39159322",
                    "name": "D. Y. T. Chino"
                },
                {
                    "authorId": "1931515",
                    "name": "Letricia P. S. Avalhais"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "19612986cc2b4f1cbaac54b4cf413e290e8898e5",
            "title": "Cataloguing of learning objects using social tagging",
            "abstract": "Social tagging has been recognized as an important solution to the description of resources available on the Web. In the context of e-learning it is presented as an auxiliary mechanism to the composition of learning object metadata. This article aims to present the results of a study on the state of the art of works related to social tagging and learning objects, promoting a discussion about the main elements related to the concepts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2956248",
                    "name": "Anderson Roque do Amaral"
                },
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "477fd3464a676b5cdb75094768e68b7076abb829",
            "title": "Spectral analysis and text processing over the computer science literature: patterns and discoveries",
            "abstract": "We defend the thesis that the use of text analytics can boost the results of analyses based on Singular Value Decomposition (SVD). To demonstrate our supposition, first we model the Digital Bibliography & Library Project (DBLP) as a relational schema; over this schema we use text analytics applied to the terms extracted from the titles of the articles. Then, we apply SVD on the relationships defined between these terms, publication vehicles, and authors; accordingly, we were able to identify the more representative communities and the more active authors relating them to the most meaningful terms and topics found in their respective publications. The results were semantically dense and concise, also leading to performance gains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1700265",
                    "name": "Rosa Virginia Encinas Quille"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "b6e9db48cc6764cbbd7e485138a3366136418cd3",
            "title": "Supervised-learning link recommendation in the DBLP co-authoring network",
            "abstract": "Currently, link recommendation has gained more attention as networked data becomes abundant in several scenarios. However, existing methods for this task have failed in considering solely the structure of dynamic networks for improved performance and accuracy. Hence, in this work, we present a methodology based on the use of multiple topological metrics in order to achieve prospective link recommendations considering time constraints. The combination of such metrics is used as input to binary classification algorithms that state whether two pairs of authors will/should define a link. We experimented with five algorithms, what allowed us to reach high rates of accuracy and to evaluate the different classification paradigms. Our results also demonstrated that time parameters and the activity profile of the authors can significantly influence the recommendation. In the context of DBLP, this research is strategic as it may assist on identifying potential partners, research groups with similar themes, research competition (absence of obvious links), and related work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3347704",
                    "name": "Gabriel P. Gimenes"
                },
                {
                    "authorId": "1752441",
                    "name": "H. Gualdron"
                },
                {
                    "authorId": "3127663",
                    "name": "T. Raddo"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "5cd9ae0696e91ed18c4cbcaab71a05e4de618d41",
            "title": "The Images and Data Bases Group at University of S\u00e3o Paulo",
            "abstract": "reated in the middle of the 1990s, the Images and Data Bases Group (Grupo de Bases de Dados e de Imagens) at the Institute of Mathematics and Computer Science of the University of Sao Paulo at Sao Carlos -- GBdI-ICMC-USP -- has since the start worked in the development of core databases and data analysis techniques to handle large databases for scientific applications involving complex data. Its research activities include applying Fractal Theory concepts to improve analysis and search operations over very large datasets, development of search algorithms, indexing structures and optimization techniques for similarity-based queries, development of data mining and data warehousing techniques aimed at dealing with datasets with large cardinality and dimensionality, information visualization for data stored in relational databases and techniques to allow data integration from diverse sources including those maintained in complex structures. Derived from those basic research activities, the research group has generated several tools released for the community in general, including\u00a0 tools for computer-assisted medical diagnosis and for climate change analysis, libraries to help the development of efficient and efficacious biological applications, and software libraries to help including similarity queries into existing DBMS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "1709113",
                    "name": "C. D. Ciferri"
                },
                {
                    "authorId": "143732518",
                    "name": "Elaine P. M. de Sousa"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "8631174",
                    "name": "R. Cordeiro"
                }
            ]
        },
        {
            "paperId": "976fecd7c8231c08f1a8e0a79d79ebf86cf1200c",
            "title": "Hierarchical visual filtering, pragmatic and epistemic actions for database visualization",
            "abstract": "Visualization techniques of all sorts suffer from visual cluttering, the occlusion of visual information due to the overlap of graphical items; and from excessive complexity in analytical tasks due to multiple parallel perspectives. To cope with these problems, we introduce Hierarchical Visual Filtering, a novel interaction principle based on pragmatic and epistemic actions. Pragmatic actions here mean that the analyst is able to visually select and filter information, determining visual configurations that reveal different perspectives; epistemic actions mean that the analyst can record, annotate, and recall intermediate visualizations created pragmatically. To do so, we use a tree-like organization to keep multiple visualization workspaces linked according to the analytical decisions took by the user. Our goal is to promote an innovative systematization that can augment the potential for database visual inspection, and for visualization systems in general. It is our contention that Hierarchical Visual Filtering can inspire a novel scheme of visualization environments in which space limitations and complexity are treated by means of interactive tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "144725759",
                    "name": "Carlos E. Cirilo"
                },
                {
                    "authorId": "2195798",
                    "name": "A. F. Prado"
                },
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                }
            ]
        },
        {
            "paperId": "f3269b2a45353533838f90f65eb75c137146f9bf",
            "title": "Graph-Based Relational Data Visualization",
            "abstract": "Relational databases are rigid-structured data sources characterized by complex relationships among a set of relations (tables). Making sense of such relationships is a challenging problem because users must consider multiple relations, understand their ensemble of integrity constraints, interpret dozens of attributes, and draw complex SQL queries for each desired data exploration. In this scenario, we introduce a twofold methodology, we use a hierarchical graph representation to efficiently model the database relationships and, on top of it, we designed a visualization technique for rapidly relational exploration. Our results demonstrate that the exploration of databases is deeply simplified as the user is able to visually browse the data with little or no knowledge about its structure, dismissing the need for complex SQL queries. We believe our findings will bring a novel paradigm in what concerns relational data comprehension.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220935",
                    "name": "D. M. Lima"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "1798193ae013c50138f0ff3f223d5bea4b6b75fc",
            "title": "Towards a Hybrid Approach for Adapting Web Graphical User Interfaces to Heterogeneous Devices using Context",
            "abstract": "Ubiquitous Computing promises seamless access to a wide range of applications and Internet-based services from anywhere, at anytime, and using any device. In this scenario, new challenges for the practice of software development arise: Applications and services must keep a coherent behavior, a proper appearance, and must adapt to a plenty of contextual usage requirements and hardware aspects. Especially, due to its interactive nature, the interface content of Web applications must adapt to a large diversity of devices and contexts. In order to overcome such obstacles, this work introduces an innovative methodology for content adaptation of Web 2.0 interfaces. The basis of our work is to combine static adaption \u2014 the implementation of static Web interfaces; and dynamic adaptation \u2014 the alteration, during execution time, of static interfaces so as for adapting to different contexts of use. In hybrid fashion, our methodology benefits from the advantages of both adaptation strategies \u2014 static and dynamic. In this line, we designed and implemented UbiCon, a framework over which we tested our concepts through a case study and through a development experiment. Our results show that the hybrid methodology over UbiCon leads to broader and more accessible interfaces, and to faster and less costly software development. We believe that the UbiCon hybrid methodology can foster more efficient and accurate interface engineering in the industry and in the academy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144725759",
                    "name": "Carlos E. Cirilo"
                },
                {
                    "authorId": "2195798",
                    "name": "A. F. Prado"
                },
                {
                    "authorId": "145081902",
                    "name": "W. L. Souza"
                },
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                }
            ]
        },
        {
            "paperId": "2cb7ed9036b3203fb8d917b5a62a50a4d18fc7b6",
            "title": "H-Metric: Characterizing Image Datasets via Homogenization Based on KNN-Queries",
            "abstract": "Precision-Recall is one of the main metrics for evaluating content-based image retrieval techniques. However, it does not provide an ample perception of the properties of an image dataset immersed in a metric space. In this work, we describe an alternative metric named H-Metric, which is determined along a sequence of controlled modifications in the image dataset. The process is named homogenization and works by altering the homogeneity characteristics of the classes of the images. The result is a process that measures how hard it is to deal with a set of images in respect to content-based retrieval, offering support in the task of analyzing configurations of distance functions and of features extractors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2068959886",
                    "name": "Welington M. da Silva"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "1879656",
                    "name": "S. F. D. Silva"
                }
            ]
        },
        {
            "paperId": "5a6c378f019ed40818a21f96c68a79d627244dcf",
            "title": "Feature space optimization for content-based image retrieval",
            "abstract": "Substantial benefits can be gained from effective Relevance Feedback techniques in content-based image retrieval. However, existing techniques are limited due to computational cost and/or by being restricted to linear transformations on the data. In this study we analyze the role of nonlinear transformations in relevance feedback. We present two promising Relevance Feedback methods based on Genetic Algorithms used to enhance the performance on the task of image retrieval according to the user's interests. The first method adjusts the dissimilarity function by using weighting functions while the second method redefines the features space by means of linear and nonlinear transformation functions. Experimental results on real data sets demonstrate that our methods are effective and the results show that the transformation approach outperforms the weighting approach, achieving a precision gain of up to 70%. Our results indicate that nonlinear transformations have a great potential in capturing the user's interests in image retrieval and should be further analyzed employing other learning/optimization mechanisms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1931515",
                    "name": "Letricia P. S. Avalhais"
                },
                {
                    "authorId": "2139376579",
                    "name": "S\u00e9rgio F Da Silva"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "83c32eea9191a7a95db9e0d4536de372e37173e4",
            "title": "Image retrieval employing genetic dissimilarity weighting and feature space transformation functions",
            "abstract": "We present two promising Relevance Feedback methods based on Genetic Algorithms used to enhance the performance on the task of image retrieval according to the user's interests. The first method adjusts the dissimilarity function by using weighting functions while the second method redefines the feature space by means of linear and nonlinear transformation functions. Experimental results on real datasets demonstrate that our methods are effective and the results show that the transformation approach outperforms the weighting approach, achieving a precision gain of up to 70%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1931515",
                    "name": "Letricia P. S. Avalhais"
                },
                {
                    "authorId": "1879656",
                    "name": "S. F. D. Silva"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "470673c795c08c7a7b270e24b2a8b9f16479e805",
            "title": "Adaptive learning in the educational e-LORS system: an approach based on preference categories",
            "abstract": "In the field of electronic education, the recommendation of contents with higher levels of relevance may potentially attract the students' attention. In this context, this work considers students' learning styles, delineated with structured questionnaires, as a means of selecting the best content as for the learning-teaching process. The goal is to present a complete systematisation the e-LORS system, which is able to recommend electronic educational content based on the relationship between detected learning styles and stored learning objects. Our contributions include the e-LORS system its multiple-criteria architecture and study case, the methodology based on the Felder-Silverman learning style model and on the IEEE learning object metadata (LOM), and the reporting of experiments conducted in an actual educational context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "2104599207",
                    "name": "Maria Ang\u00e9lica C. De Andrade Cardieri"
                },
                {
                    "authorId": "2032364",
                    "name": "G. Bressan"
                }
            ]
        },
        {
            "paperId": "4855fc8ad8d725a4b3de4a91fefb326d2fc13ebc",
            "title": "Combining Visual Analytics and Content Based Data Retrieval Technology for Efficient Data Analysis",
            "abstract": "One of the most useful techniques to help visual data analysis systems is interactive filtering (brushing). However, visualization techniques often suffer from overlap of graphical items and multiple attributes complexity, making visual selection inefficient. In these situations, the benefits of data visualization are not fully observable because the graphical items do not pop up as comprehensive patterns. In this work we propose the use of content-based data retrieval technology combined with visual analytics. The idea is to use the similarity query functionalities provided by metric space systems in order to select regions of the data domain according to user-guidance and interests. After that, the data found in such regions feed multiple visualization workspaces so that the user can inspect the correspondent datasets. Our experiments showed that the methodology can break the visual analysis process into smaller problems (views) and that the views hold the expectations of the analyst according to his/her similarity query selection, improving data perception and analytical possibilities. Our contribution introduces a principle that can be used in all sorts of visualization techniques and systems, this principle can be extended with different kinds of integration visualization-metric-space, and with different metrics, expanding the possibilities of visual data analysis in aspects such as semantics and scalability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1738299",
                    "name": "L. A. Romani"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "741df805bab6899f3a10bb871d8df712ae2f5a22",
            "title": "An approach to design the student interaction based on the recommendation of e-learning objects",
            "abstract": "In the last years, the adoption of recommender systems for improving user interaction has increased in e-learning applications. In the educational area, the recommendation of relevant and interesting content can attract the student's attention, motivating her/him during the learning-teaching process. It is very important, thus, to know learner preferences to suggest suitable contents to the students. The goal of this work is to present an approach to design the student interaction based on the recommendation of e-learning content, determining a more suitable relationship between learning objects and learning profiles. In our proposal, the learning profile is split into categories to attend different student preferences during the teaching-learning process: perception, presentation-format and participation. Our recommendation uses these categories to filter out the most suitable learning objects organized according to the IEEE LOM standard. We present a prototype architecture named e-LORS, over which we perform demonstrative experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                },
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "2032364",
                    "name": "G. Bressan"
                }
            ]
        },
        {
            "paperId": "aeae57e10d05e449cd1ffa5660afd70a8ee46e67",
            "title": "A Survey on Distributed Visualization Techniques over Clusters of Personal Computers",
            "abstract": "In the last years, Distributed Visualization over Personal Computer (PC) clusters has become important for research and industrial communities. They have made large-scale visualizations practical and more accessible. In this work we survey Distributed Visualization techniques aiming at compiling last decade's literature on the use of PC clusters as suitable alternatives to high-end workstations. We review the topic by defining basic concepts, enumerating system requirements and implementation challenges, and presenting up-to-date methodologies. Our work fulfills the needs of newcomers and seasoned professionals as an introductory compilation at the same time that it can help experienced personnel by organizing ideas.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "37607720",
                    "name": "Andr\u00e9 G. R. Balan"
                },
                {
                    "authorId": "145200127",
                    "name": "L. Zaina"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        },
        {
            "paperId": "3c994bc0a2381301ecf9df359be554677875b62b",
            "title": "Reviewing Data Visualization: an Analytical Taxonomical Study",
            "abstract": "This paper presents an analytical taxonomy that can suitably describe, rather than simply classify, techniques for data presentation. Unlike previous works, we do not consider particular aspects of visualization techniques, but their mechanisms and foundational vision perception. Instead of just adjusting visualization research to a classification system, our aim is to better understand its process. For doing so, we depart from elementary concepts to reach a model that can describe how visualization techniques work and how they convey meaning",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "2110928516",
                    "name": "Maria Cristina Ferreira de Oliveira"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "730606c2566d04f10a3bcdb6091319203fb5e451",
            "title": "GMine: a system for scalable, interactive graph visualization and mining",
            "abstract": "Several graph visualization tools exist. However, they are not able to handle large graphs, and/or they do not allow interaction. We are interested on large graphs, with hundreds of thousands of nodes. Such graphs bring two challenges: the first one is that any straightforward interactive manipulation will be prohibitively slow. The second one is sensory overload: even if we could plot and replot the graph quickly, the user would be overwhelmed with the vast volume of information because the screen would be too cluttered as nodes and edges overlap each other.Our GMine system addresses both these issues, by using summarization and multi-resolution. GMine offers multi-resolution graph exploration by partitioning a given graph into a hierarchy of communities-within-communities and storing it into a novel R-treelike structure which we name G-Tree. GMine offers summarization by implementing an innovative subgraph extraction algorithm and then visualizing its output.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                }
            ]
        },
        {
            "paperId": "e805b3e8d0d73f2e9ff1820294476497f3ff59ce",
            "title": "Enhanced visual evaluation of feature extractors for image mining",
            "abstract": "Summary form only given. This paper introduces a novel approach to evaluate, timely and effectively, the suitability of new image feature extraction techniques concerning similarity queries using CBIR systems. The proposed approach is based on two measurements derived from spatial properties intuitively and naturally perceived in spatial domains, and that can also be verified in multidimensional spaces. To bear out our proposal, we show that the insights obtained by the proposed measurements comply with the well-known analysis methods based on the precision and recall approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "61d9f642a259cbcd13e232c8a0d110cf5f66ac8c",
            "title": "Frequency plot and relevance plot to enhance visual data exploration",
            "abstract": "We present two techniques aiming at exploring databases through multivariate visualizations. Both techniques intend to deal with the problem caused by the limited amount of elements that can be presented simultaneously in traditional visual exploration procedures. The first technique, the Frequency Plot, combines data frequency with interactive filtering to identify clusters and trends in subsets of the database. Thus, graphical elements (lines, pixels, icons, or graphical marks) are color differentiated proportionally to how frequent the value being represented is, while interactive filtering allows the selection of interesting partitions of the database. The second technique, the Relevance Plot, corresponds to assigning different levels of color distinguishably to visual elements according to their relevance to a user's specified data properties set, which can be chosen visually and dynamically.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                }
            ]
        },
        {
            "paperId": "ba8ec9447f17f6c9f788a30b11c38c0c8058f264",
            "title": "Using efficient visual exploration techniques to evaluate features for content-based image retrieval",
            "abstract": "We present a novel visual approach to evaluate, in a fast and effective way, the development of new image feature extraction techniques concerning content-based image retrieval. This new approach takes advantage of an interactive 3-dimensional visualization fed by the image features obtained through a given extraction technique under analysis. Using controlled test image datasets, the researcher can literally \"see\" the discrimination power of the image features. This new approach gives a very good insight of the behavior of a given image feature extractor algorithm, which are confirmed by the well-known precision and recall measurements. We applied the visual approach proposed onto a wavelet-based image retrieval system, which is supporting the development of a Picture Archiving and Communication System that allows one to retrieve images by content.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144540186",
                    "name": "J. F. Rodrigues"
                },
                {
                    "authorId": "50413060",
                    "name": "C. B. Casta\u00f1\u00f3n"
                },
                {
                    "authorId": "104501789",
                    "name": "C. Traina"
                },
                {
                    "authorId": "1745003",
                    "name": "A. Traina"
                }
            ]
        }
    ]
}