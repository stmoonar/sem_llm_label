{
    "authorId": "1724523030",
    "papers": [
        {
            "paperId": "4f452e6a453f4ccd8f6c1960a8291a0ad8e4c2ee",
            "title": "Exploring the Limitations of Detecting Machine-Generated Text",
            "abstract": "Recent improvements in the quality of the generations by large language models have spurred research into identifying machine-generated text. Systems proposed for the task often achieve high performance. However, humans and machines can produce text in different styles and in different domains, and it remains unclear whether machine generated-text detection models favour particular styles or domains. In this paper, we critically examine the classification performance for detecting machine-generated text by evaluating on texts with varying writing styles. We find that classifiers are highly sensitive to stylistic changes and differences in text complexity, and in some cases degrade entirely to random classifiers. We further find that detection systems are particularly susceptible to misclassify easy-to-read texts while they have high performance for complex texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2261493094",
                    "name": "Hawau Olamide Toyin"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2138053020",
                    "name": "Zeerak Talat"
                }
            ]
        },
        {
            "paperId": "9ff25b04f81d21f700deb5b386857840b81a1f23",
            "title": "ArabicMMLU: Assessing Massive Multitask Language Understanding in Arabic",
            "abstract": "The focus of language model evaluation has transitioned towards reasoning and knowledge-intensive tasks, driven by advancements in pretraining large models. While state-of-the-art models are partially trained on large Arabic texts, evaluating their performance in Arabic remains challenging due to the limited availability of relevant datasets. To bridge this gap, we present \\datasetname{}, the first multi-task language understanding benchmark for the Arabic language, sourced from school exams across diverse educational levels in different countries spanning North Africa, the Levant, and the Gulf regions. Our data comprises 40 tasks and 14,575 multiple-choice questions in Modern Standard Arabic (MSA) and is carefully constructed by collaborating with native speakers in the region. Our comprehensive evaluations of 35 models reveal substantial room for improvement, particularly among the best open-source models. Notably, BLOOMZ, mT0, LLaMA2, and Falcon struggle to achieve a score of 50%, while even the top-performing Arabic-centric model only achieves a score of 62.3%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2274084215",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2210193043",
                    "name": "Sara Shatnawi"
                },
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "2233498337",
                    "name": "Abdelrahman Boda Sadallah"
                },
                {
                    "authorId": "2284767001",
                    "name": "Aisha Alraeesi"
                },
                {
                    "authorId": "2284765679",
                    "name": "Khalid Almubarak"
                },
                {
                    "authorId": "25098419",
                    "name": "Zaid Alyafeai"
                },
                {
                    "authorId": "2284771123",
                    "name": "Neha Sengupta"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "114aefa57df10504967f23841f9c5f46271d8fca",
            "title": "FairGauge: A Modularized Evaluation of Bias in Masked Language Models",
            "abstract": "Prejudice is a pre-conceived depiction of an entity within a person's mind. It tends to devalue people as a consequence of their perceived membership in a social group. The origin of prejudice can be traced back to the categorization process people use to form a plausible perception of their surroundings. The process of constructing these perceptions generally results in prejudices, which authorizes inequalities to develop across a variety of social groups. In all their forms, biases can be relayed in language by generalizing a negative adjective onto an social group as a function of prejudgement. Using this reduced linguistic formulation, we set out to (1) create a benchmark of 23,736 prejudiced sentences that encompass a plethora of bias types including racism, sexism, classism, ethnic discrimination, and religious discrimination; (2) propose a prejudice score that incorporates both the masked prediction probability and the top-k index (rank) of the matched word; (3) conduct a case study, using our benchmark, to evaluate bias in three pre-trained language models: BERT, DistilBERT, and Context-Debias DistilBERT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2264150375",
                    "name": "Fakhri Karray"
                }
            ]
        },
        {
            "paperId": "8a53a8be83f1472b1f8c9bec04bc430d2bebda81",
            "title": "Can a Prediction\u2019s Rank Offer a More Accurate Quantification of Bias? A Case Study Measuring Sexism in Debiased Language Models",
            "abstract": "Pre-trained language models are known to inherit a plethora of contextual biases from their training data. These biases have proven to be projected onto a variety of downstream applications, making their detection and mitigation imminent. Limited research has been conducted to quantify specific bias types, such as benevolent sexism, which may be subtly present within the inferred connotations of a sentence. To this extent, our work aims to: (1) provide a benchmark of sexism sentences; (2) adapt two bias metrics: mean probability score and mean normalized rank; (3) conduct a case study to quantify and analyze sexism in base and de-biased masked language models. We find that debiasing, even in its most effective form (Auto-Debias), solely nullifies the probability score of biasing tokens, while retaining them in high ranks. Auto-Debias illustrates a 90%-96% reduction in mean probability scores from base to debiased models, while only a 3%-16% reduction in mean normalized ranks. Similar to the application of non-parametric statistical tests for data that does not follow a normal distribution, operating on the ranks of predictions rather than their probability scores offers a more representative bias measure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "1452348515",
                    "name": "Leen Al Qadi"
                },
                {
                    "authorId": "2292591921",
                    "name": "Youssef Nafea"
                },
                {
                    "authorId": "1696863",
                    "name": "F. Karray"
                }
            ]
        },
        {
            "paperId": "18f09fcf7255c3512f2e27ca4db61ae44d578703",
            "title": "Gender Bias in Text: Labeled Datasets and Lexicons",
            "abstract": "Language has a profound impact on our thoughts, perceptions, and conceptions of gender roles. Gender-inclusive language is, therefore, a key tool to promote social inclusion and contribute to achieving gender equality. Consequently, detecting and mitigating gender bias in texts is instrumental in halting its propagation and societal implications. However, there is a lack of gender bias datasets and lexicons for automating the detection of gender bias using supervised and unsupervised machine learning (ML) and natural language processing (NLP) techniques. Therefore, the main contribution of this work is to publicly provide labeled datasets and exhaustive lexicons by collecting, annotating, and augmenting relevant sentences to facilitate the detection of gender bias in English text. Towards this end, we present an updated version of our previously proposed taxonomy by re-formalizing its structure, adding a new bias type, and mapping each bias subtype to an appropriate detection methodology. The released datasets and lexicons span multiple bias subtypes including: Generic He, Generic She, Explicit Marking of Sex, and Gendered Neologisms. We leveraged the use of word embedding models to further augment the collected lexicons.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "1754731",
                    "name": "Wael Khreich"
                }
            ]
        },
        {
            "paperId": "51470a264e7019d572507d84dab86f5ae2ae7647",
            "title": "Time-Aware Word Embeddings for Three Lebanese News Archives",
            "abstract": "Word embeddings have proven to be an effective method for capturing semantic relations among distinct terms within a large corpus. In this paper, we present a set of word embeddings learnt from three large Lebanese news archives, which collectively consist of 609,386 scanned newspaper images and spanning a total of 151 years, ranging from 1933 till 2011. The diversified ideological nature of the news archives alongside the temporal variability of the embeddings offer a rare glimpse onto the variation of word representation across the left-right political spectrum. To train the word embeddings, Google\u2019s Tesseract 4.0 OCR engine was employed to transcribe the scanned news archives, and various archive-level as well as decade-level word embeddings were learnt. To evaluate the accuracy of the learnt word embeddings, a benchmark of analogy tasks was used. Finally, we demonstrate an interactive system that allows the end user to visualize for a given word of interest, the variation of the top-k closest words in the embedding space as a function of time and across news archives using an animated scatter plot.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "34884946",
                    "name": "Fatima K. Abu Salem"
                },
                {
                    "authorId": "1863248",
                    "name": "Shady Elbassuoni"
                }
            ]
        },
        {
            "paperId": "9bdb6f01a9cb5c91ccb503e75ab7f884adf13600",
            "title": "DiaLex: A Benchmark for Evaluating Multidialectal Arabic Word Embeddings",
            "abstract": "Word embeddings are a core component of modern natural language processing systems, making the ability to thoroughly evaluate them a vital task. We describe DiaLex, a benchmark for intrinsic evaluation of dialectal Arabic word embeddings. DiaLex covers five important Arabic dialects: Algerian, Egyptian, Lebanese, Syrian, and Tunisian. Across these dialects, DiaLex provides a testbank for six syntactic and semantic relations, namely male to female, singular to dual, singular to plural, antonym, comparative, and genitive to past tense. DiaLex thus consists of a collection of word pairs representing each of the six relations in each of the five dialects. To demonstrate the utility of DiaLex, we use it to evaluate a set of existing and new Arabic word embeddings that we developed. Beyond evaluation of word embeddings, DiaLex supports efforts to integrate dialects into the Arabic language curriculum. It can be easily translated into Modern Standard Arabic and English, which can be useful for evaluating word translation. Our benchmark, evaluation code, and new word embedding models will be publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1388437494",
                    "name": "Muhammad Abdul-Mageed"
                },
                {
                    "authorId": "1863248",
                    "name": "Shady Elbassuoni"
                },
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "1397289779",
                    "name": "AbdelRahim Elmadany"
                },
                {
                    "authorId": "17771023",
                    "name": "El Moatez Billah Nagoudi"
                },
                {
                    "authorId": "1752711629",
                    "name": "Yorgo Zoughby"
                },
                {
                    "authorId": "2028188802",
                    "name": "Ahmad Shaher Iskander Gaba"
                },
                {
                    "authorId": "2063959424",
                    "name": "Ahmed E. Helal"
                },
                {
                    "authorId": "22184519",
                    "name": "Mohammed Elrazzaz"
                }
            ]
        }
    ]
}