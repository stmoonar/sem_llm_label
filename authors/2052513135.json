{
    "authorId": "2052513135",
    "papers": [
        {
            "paperId": "9cab8c423d9c13d4f35beb97a7f823c250e8f059",
            "title": "RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation",
            "abstract": "Endowing chatbots with a consistent persona is essential to an engaging conversation, yet it remains an unresolved challenge. In this work, we propose a new retrieval-enhanced approach for personalized response generation. Specifically, we design a hierarchical transformer retriever trained on dialogue domain data to perform personalized retrieval and a context-aware prefix encoder that fuses the retrieved information to the decoder more effectively. Extensive experiments on a real-world dataset demonstrate the effectiveness of our model at generating more fluent and personalized responses. We quantitatively evaluate our model\u2019s performance under a suite of human and automatic metrics and find it to be superior compared to state-of-the-art baselines on English Reddit conversations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2156268596",
                    "name": "Shuai Liu"
                },
                {
                    "authorId": "91009922",
                    "name": "Hyundong Justin Cho"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "2378954",
                    "name": "Xuezhe Ma"
                },
                {
                    "authorId": "143823227",
                    "name": "Jonathan May"
                }
            ]
        },
        {
            "paperId": "043be77042bd718c7918906ec2cbdcb816e18092",
            "title": "Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals",
            "abstract": "The ability to sequence unordered events is evidence of comprehension and reasoning about real world tasks/procedures. It is essential for applications such as task planning and multi-source instruction summarization.It often requires thorough understanding of temporal common sense and multimodal information, since these procedures are often conveyed by a combination of texts and images.While humans are capable of reasoning about and sequencing unordered procedural instructions, the extent to which the current machine learning methods possess such capability is still an open question.In this work, we benchmark models\u2019 capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from online instructional manuals and collecting comprehensive human annotations.We find current state-of-the-art models not only perform significantly worse than humans but also seem incapable of efficiently utilizing multimodal information.To improve machines\u2019 performance on multimodal event sequencing, we propose sequence-aware pretraining techniques exploiting the sequential alignment properties of both texts and images, resulting in > 5% improvements on perfect match ratio.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2015467",
                    "name": "Te-Lin Wu"
                },
                {
                    "authorId": "51444076",
                    "name": "Alexander Spangher"
                },
                {
                    "authorId": "1805993128",
                    "name": "Pegah Alipoormolabashi"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "1732071",
                    "name": "R. Weischedel"
                },
                {
                    "authorId": "3157053",
                    "name": "Nanyun Peng"
                }
            ]
        },
        {
            "paperId": "31ebb27950388f7daa7c9c9618e9141be4119237",
            "title": "Understanding Procedural Knowledge by Sequencing Multimodal Instructional Manuals",
            "abstract": "The ability to sequence unordered events is an essential skill to comprehend and reason about real world task procedures, which often requires thorough understanding of temporal common sense and multimodal information, as these procedures are often communicated through a combination of texts and images. Such capability is essential for applications such as sequential task planning and multi-source instruction summarization. While humans are capable of reasoning about and sequencing unordered multimodal procedural instructions, whether current machine learning models have such essential capability is still an open question. In this work, we benchmark models\u2019 capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from popular online instructional manuals and collecting comprehensive human annotations. We \ufb01nd models not only perform signi\ufb01cantly worse than humans but also seem incapable of ef\ufb01ciently utilizing the multimodal information. To improve ma-chines\u2019 performance on multimodal event sequencing, we propose sequentiality-aware pre-training techniques that exploit the sequential alignment properties of both texts and images, resulting in >5% signi\ufb01cant improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134514770",
                    "name": "Te-Lin Wu"
                },
                {
                    "authorId": "51444076",
                    "name": "Alexander Spangher"
                },
                {
                    "authorId": "1805993128",
                    "name": "Pegah Alipoormolabashi"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "1732071",
                    "name": "R. Weischedel"
                },
                {
                    "authorId": "3157053",
                    "name": "Nanyun Peng"
                }
            ]
        },
        {
            "paperId": "4563a3a0fa8a1bad759c63ae6427ba7cad9f8d16",
            "title": "Machine-Assisted Script Curation",
            "abstract": "We describe Machine-Aided Script Curator (MASC), a system for human-machine collaborative script authoring. Scripts produced with MASC include (1) English descriptions of sub-events that comprise a larger, complex event; (2) event types for each of those events; (3) a record of entities expected to participate in multiple sub-events; and (4) temporal sequencing between the sub-events. MASC automates portions of the script creation process with suggestions for event types, links to Wikidata, and sub-events that may have been forgotten. We illustrate how these automations are useful to the script writer with a few case-study scripts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3451493",
                    "name": "Manuel R. Ciosici"
                },
                {
                    "authorId": "49519539",
                    "name": "Joseph Cummings"
                },
                {
                    "authorId": "2046875291",
                    "name": "Mitchell DeHaven"
                },
                {
                    "authorId": "2046633188",
                    "name": "Alex Hedges"
                },
                {
                    "authorId": "2029668178",
                    "name": "Yash Kankanampati"
                },
                {
                    "authorId": "73037511",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "1732071",
                    "name": "R. Weischedel"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                }
            ]
        },
        {
            "paperId": "81f38f044b8d7b5904b1fc7efd921dfdcabc6abc",
            "title": "Agenda Pushing in Email to Thwart Phishing",
            "abstract": "In this work, we draw parallels between automatically responding to emails for combating social-engineering attacks and document-grounded response generation and lay out the blueprint of our approach. Phishing emails are longer than dialogue utterances and often contain multiple intents. Hence, we need to make decisions similar to those for document-grounded responses in deciding what parts of long text to use and how to address each intent to generate a knowledgeable multi-component response that pushes scammers towards agendas that aid in attribution and linking attacks. We propose , a hybrid system that uses customizable probabilistic finite state transducers to orchestrate pushing agendas coupled with neural dialogue systems that generate responses to unexpected prompts, as a promising solution to this end. We emphasize the need for this system by highlighting each component\u2019s strengths and weaknesses and show how they complement each other.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "91009922",
                    "name": "Hyundong Justin Cho"
                },
                {
                    "authorId": "145287807",
                    "name": "G. Bartlett"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                }
            ]
        },
        {
            "paperId": "aba37c82e52cb19eaca5348b05cdc0d417d91af8",
            "title": "A Grounded Approach to Modeling Generic Knowledge Acquisition",
            "abstract": "We introduce and implement a cognitively plausible model for learning from generic language, statements that express generalizations about members of a category and are an important aspect of concept development in language acquisition (Carlson&Pelletier, 1995; Gelman, 2009). We extend a computational framework designed to model grounded language acquisition by introducing the concept network. This new layer of abstraction enables the system to encode knowledge learned from generic statements and represent the associations between concepts learned by the system. Through three tasks that utilize the concept network, we demonstrate that our extensions to ADAM can acquire generic information and provide an example of how ADAM can be used to model language acquisition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41135722",
                    "name": "Deniz Beser"
                },
                {
                    "authorId": "2088874465",
                    "name": "Joe Cecil"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "2088879679",
                    "name": "Jacob A. Lichtefeld"
                },
                {
                    "authorId": "1734174",
                    "name": "Mitchell P. Marcus"
                },
                {
                    "authorId": "50023668",
                    "name": "Sarah Payne"
                },
                {
                    "authorId": "145575781",
                    "name": "Charles D. Yang"
                }
            ]
        },
        {
            "paperId": "ccc12c7a53269072355879a11a8f89f8b6780014",
            "title": "ADAM: A Sandbox for Implementing Language Learning",
            "abstract": "We present ADAM, a software system for designing and running child language learning experiments in Python. The system uses a virtual world to simulate a grounded language acquisition process in which the language learner utilizes cognitively plausible learning algorithms to form perceptual and linguistic representations of the observed world. The modular nature of ADAM makes it easy to design and test different language learning curricula as well as learning algorithms. In this report, we describe the architecture of the ADAM system in detail, and illustrate its components with examples. We provide our code.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50543673",
                    "name": "Ryan Gabbard"
                },
                {
                    "authorId": "41135722",
                    "name": "Deniz Beser"
                },
                {
                    "authorId": "2088879679",
                    "name": "Jacob A. Lichtefeld"
                },
                {
                    "authorId": "2088874465",
                    "name": "Joe Cecil"
                },
                {
                    "authorId": "1734174",
                    "name": "Mitchell P. Marcus"
                },
                {
                    "authorId": "50023668",
                    "name": "Sarah Payne"
                },
                {
                    "authorId": "145575781",
                    "name": "Charles D. Yang"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                }
            ]
        },
        {
            "paperId": "ef5a79368dddf07a368347c64c289bfaaa587fa5",
            "title": "Perhaps PTLMs Should Go to School \u2013 A Task to Assess Open Book and Closed Book QA",
            "abstract": "Our goal is to deliver a new task and leaderboard to stimulate research on question answering and pre-trained language models (PTLMs) to understand a significant instructional document, e.g., an introductory college textbook or a manual. PTLMs have shown great success in many question-answering tasks, given significant supervised training, but much less so in zero-shot settings. We propose a new task that includes two college-level introductory texts in the social sciences (American Government 2e) and humanities (U.S. History), hundreds of true/false statements based on review questions written by the textbook authors, validation/development tests based on the first eight chapters of the textbooks, blind tests based on the remaining textbook chapters, and baseline results given state-of-the-art PTLMs. Since the questions are balanced, random performance should be ~50%. T5, fine-tuned with BoolQ achieves the same performance, suggesting that the textbook\u2019s content is not pre-represented in the PTLM. Taking the exam closed book, but having read the textbook (i.e., adding the textbook to T5\u2019s pre-training), yields at best minor improvement (56%), suggesting that the PTLM may not have \u201cunderstood\u201d the textbook (or perhaps misunderstood the questions). Performance is better (~60%) when the exam is taken open-book (i.e., allowing the machine to automatically retrieve a paragraph and use it to answer the question).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3451493",
                    "name": "Manuel R. Ciosici"
                },
                {
                    "authorId": "2088874465",
                    "name": "Joe Cecil"
                },
                {
                    "authorId": "2046633188",
                    "name": "Alex Hedges"
                },
                {
                    "authorId": "2115475530",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "1732071",
                    "name": "R. Weischedel"
                }
            ]
        },
        {
            "paperId": "274680226175259293189914105debcb02613f27",
            "title": "SEARCHER: Shared Embedding Architecture for Effective Retrieval",
            "abstract": "We describe an approach to cross lingual information retrieval that does not rely on explicit translation of either document or query terms. Instead, both queries and documents are mapped into a shared embedding space where retrieval is performed. We discuss potential advantages of the approach in handling polysemy and synonymy. We present a method for training the model, and give details of the model implementation. We present experimental results for two cases: Somali-English and Bulgarian-English CLIR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153077114",
                    "name": "Joel Barry"
                },
                {
                    "authorId": "3256207",
                    "name": "Elizabeth Boschee"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                },
                {
                    "authorId": "123937952",
                    "name": "Scott Miller"
                }
            ]
        },
        {
            "paperId": "51c8975d88aa66781300e8ca88272ab3112445c0",
            "title": "GAIA: A Fine-grained Multimedia Knowledge Extraction System",
            "abstract": "We present the first comprehensive, open source multimedia knowledge extraction system that takes a massive stream of unstructured, heterogeneous multimedia data from various sources and languages as input, and creates a coherent, structured knowledge base, indexing entities, relations, and events, following a rich, fine-grained ontology. Our system, GAIA, enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos. GAIA achieves top performance at the recent NIST TAC SM-KBP2019 evaluation. The system is publicly available at GitHub and DockerHub, with a narrated video that documents the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3361240",
                    "name": "Manling Li"
                },
                {
                    "authorId": "2778637",
                    "name": "Alireza Zareian"
                },
                {
                    "authorId": "2117032681",
                    "name": "Ying Lin"
                },
                {
                    "authorId": "34741133",
                    "name": "Xiaoman Pan"
                },
                {
                    "authorId": "153188991",
                    "name": "Spencer Whitehead"
                },
                {
                    "authorId": "2108342501",
                    "name": "Brian Chen"
                },
                {
                    "authorId": "1993581583",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2113323573",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "9546964",
                    "name": "Shih-Fu Chang"
                },
                {
                    "authorId": "1817166",
                    "name": "Clare R. Voss"
                },
                {
                    "authorId": "1413386261",
                    "name": "Dan Napierski"
                },
                {
                    "authorId": "2052513135",
                    "name": "Marjorie Freedman"
                }
            ]
        }
    ]
}