{
    "authorId": "2052687617",
    "papers": [
        {
            "paperId": "09c47cf6e0b173057ebd28c60086db627c1b4bf3",
            "title": "Continuous Input Embedding Size Search For Recommender Systems",
            "abstract": "Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a given memory budget. In this paper, we propose continuous input embedding size search (CIESS), a novel RL-based method that operates on a continuous search space with arbitrary embedding sizes to choose from. In CIESS, we further present an innovative random walk-based exploration strategy to allow the RL policy to efficiently explore more candidate embedding sizes and converge to a better decision. CIESS is also model-agnostic and hence generalizable to a variety of latent factor RSs, whilst experiments on two real-world datasets have shown state-of-the-art performance of CIESS under different memory budgets when paired with three popular recommendation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2147288412",
                    "name": "Yunke Qu"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "0e2ceeefed09223da44dde153e23512baba59581",
            "title": "Model-Agnostic Decentralized Collaborative Learning for On-Device POI Recommendation",
            "abstract": "As an indispensable personalized service in Location-based Social Networks (LBSNs), the next Point-of-Interest (POI) recommendation aims to help people discover attractive and interesting places. Currently, most POI recommenders are based on the conventional centralized paradigm that heavily relies on the cloud to train the recommendation models with large volumes of collected users' sensitive check-in data. Although a few recent works have explored on-device frameworks for resilient and privacy-preserving POI recommendations, they invariably hold the assumption of model homogeneity for parameters/gradients aggregation and collaboration. However, users' mobile devices in the real world have various hardware configurations (e.g., compute resources), leading to heterogeneous on-device models with different architectures and sizes. In light of this, We propose a novel on-device POI recommendation framework, namely Model-Agnostic Collaborative learning for on-device POI recommendation (MAC), allowing users to customize their own model structures (e.g., dimension & number of hidden layers). To counteract the sparsity of on-device user data, we propose to pre-select neighbors for collaboration based on physical distances, category-level preferences, and social networks. To assimilate knowledge from the above-selected neighbors in an efficient and secure way, we adopt the knowledge distillation framework with mutual information maximization. Instead of sharing sensitive models/gradients, clients in MAC only share their soft decisions on a preloaded reference dataset. To filter out low-quality neighbors, we propose two sampling strategies, performance-triggered sampling and similarity-based sampling, to speed up the training process and obtain optimal recommenders. In addition, we design two novel approaches to generate more effective reference datasets while protecting users' privacy. Extensive experiments on two datasets have shown the superiority of MAC over advanced baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161605203",
                    "name": "Jing Long"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "1925773",
                    "name": "Nguyen Quoc Viet Hung"
                },
                {
                    "authorId": "2149131224",
                    "name": "Guandong Xu"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "168e785ea1d721e6f32728498ec45deffd5c7f81",
            "title": "Personalized Elastic Embedding Learning for On-Device Recommendation",
            "abstract": "To address privacy concerns and reduce network latency, there has been a recent trend of compressing cumbersome recommendation models trained on the cloud and deploying compact recommender models to resource-limited devices for the real-time recommendation. Existing solutions generally overlook device heterogeneity and user heterogeneity. They require devices with the same budget to share the same model and assume the available device resources (e.g., memory) are constant, which is not reflective of reality. Considering device and user heterogeneities as well as dynamic resource constraints, this article proposes a Personalized Elastic Embedding Learning framework (PEEL) for the on-device recommendation, which generates Personalized Elastic Embeddings (PEEs) for devices with various memory budgets in a once-for-all manner, adapting to new or dynamic budgets, and addressing user preference diversity by assigning personalized embeddings for different groups of users. Specifically, it pretrains a global embedding table with collected user-item interaction instances and clusters users into groups. Then, it refines the embedding tables with local interaction instances within each group. PEEs are generated from the group-wise embedding blocks and their weights that indicate the contribution of each embedding block to the local recommendation performance. Given a memory budget, PEEL efficiently generates PEEs by selecting embedding blocks with the largest weights, making it adaptable to dynamic memory budgets on devices. Furthermore, a diversity-driven regularizer is implemented to encourage the expressiveness of embedding blocks, and a controller is utilized to optimize the weights. Extensive experiments are conducted on two public datasets, and the results show that PEEL yields superior performance on devices with heterogeneous and dynamic memory budgets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1811416884",
                    "name": "Ruiqi Zheng"
                },
                {
                    "authorId": "2056322340",
                    "name": "Liang Qu"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2152862030",
                    "name": "Yuhui Shi"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "277797fee15cd21d0db75f00dceb1cf092f83bde",
            "title": "Multi-behavior Self-supervised Learning for Recommendation",
            "abstract": "Modern recommender systems often deal with a variety of user interactions, e.g., click, forward, purchase, etc., which requires the underlying recommender engines to fully understand and leverage multi-behavior data from users. Despite recent efforts towards making use of heterogeneous data, multi-behavior recommendation still faces great challenges. Firstly, sparse target signals and noisy auxiliary interactions remain an issue. Secondly, existing methods utilizing self-supervised learning (SSL) to tackle the data sparsity neglect the serious optimization imbalance between the SSL task and the target task. Hence, we propose a Multi-Behavior Self-Supervised Learning (MBSSL) framework together with an adaptive optimization method. Specifically, we devise a behavior-aware graph neural network incorporating the self-attention mechanism to capture behavior multiplicity and dependencies. To increase the robustness to data sparsity under the target behavior and noisy interactions from auxiliary behaviors, we propose a novel self-supervised learning paradigm to conduct node self-discrimination at both inter-behavior and intra-behavior levels. In addition, we develop a customized optimization strategy through hybrid manipulation on gradients to adaptively balance the self-supervised learning task and the main supervised recommendation task. Extensive experiments on five real-world datasets demonstrate the consistent improvements obtained by MBSSL over ten state-of-the-art (SOTA) baselines. We release our model implementation at: https://github.com/Scofield666/MBSSL.git.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2180607307",
                    "name": "Jingcao Xu"
                },
                {
                    "authorId": "121900345",
                    "name": "Chaokun Wang"
                },
                {
                    "authorId": "2151102586",
                    "name": "Cheng Wu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2218644324",
                    "name": "Xiaowei Wang"
                },
                {
                    "authorId": "35656765",
                    "name": "Changping Wang"
                },
                {
                    "authorId": "35066946",
                    "name": "Guorui Zhou"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "6f850b3ba54b5aa12ec6e7c7085c5638e7a4c4e7",
            "title": "Instant Representation Learning for Recommendation over Large Dynamic Graphs",
            "abstract": "Recommender systems are able to learn user preferences based on user and item representations via their historical behaviors. To improve representation learning, recent recommendation models start leveraging information from various behavior types exhibited by users. In real-world scenarios, the user behavioral graph is not only multiplex but also dynamic, i.e., the graph evolves rapidly over time, with various types of nodes and edges added or deleted, which causes the Neighborhood Disturbance. Nevertheless, most existing methods neglect such streaming dynamics and thus need to be retrained once the graph has significantly evolved, making them unsuitable in the online learning environment. Furthermore, the Neighborhood Disturbance existing in dynamic graphs deteriorates the performance of neighbor-aggregation based graph models. To this end, we propose SUPA, a novel graph neural network for dynamic multiplex heterogeneous graphs. Compared to neighbor-aggregation architecture, SUPA develops a sample-update-propagate architecture to alleviate neighborhood disturbance. Specifically, for each new edge, SUPA samples an influenced subgraph, updates the representations of the two interactive nodes, and propagates the interaction information to the sampled subgraph. Furthermore, to train SUPA incrementally online, we propose InsLearn, an efficient workflow for single-pass training of large dynamic graphs. Extensive experimental results on six real-world datasets show that SUPA has a good generalization ability and is superior to sixteen state-of-the-art baseline methods. The source code is available at https://github.com/shatter15/SUPA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151102586",
                    "name": "Cheng Wu"
                },
                {
                    "authorId": "2135743383",
                    "name": "Chao-Hong Wang"
                },
                {
                    "authorId": "2180607307",
                    "name": "Jingcao Xu"
                },
                {
                    "authorId": "2219040914",
                    "name": "Ziwei Fang"
                },
                {
                    "authorId": "2124439726",
                    "name": "Tiankai Gu"
                },
                {
                    "authorId": "35656765",
                    "name": "Changping Wang"
                },
                {
                    "authorId": "144404428",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2218644324",
                    "name": "Xiaowei Wang"
                },
                {
                    "authorId": "35066946",
                    "name": "Guorui Zhou"
                }
            ]
        },
        {
            "paperId": "e43b1f4f8e20cb90e4437e5aef3f3323417eac11",
            "title": "PANE-GNN: Unifying Positive and Negative Edges in Graph Neural Networks for Recommendation",
            "abstract": "Recommender systems play a crucial role in addressing the issue of information overload by delivering personalized recommendations to users. In recent years, there has been a growing interest in leveraging graph neural networks (GNNs) for recommender systems, capitalizing on advancements in graph representation learning. These GNN-based models primarily focus on analyzing users' positive feedback while overlooking the valuable insights provided by their negative feedback. In this paper, we propose PANE-GNN, an innovative recommendation model that unifies Positive And Negative Edges in Graph Neural Networks for recommendation. By incorporating user preferences and dispreferences, our approach enhances the capability of recommender systems to offer personalized suggestions. PANE-GNN first partitions the raw rating graph into two distinct bipartite graphs based on positive and negative feedback. Subsequently, we employ two separate embeddings, the interest embedding and the disinterest embedding, to capture users' likes and dislikes, respectively. To facilitate effective information propagation, we design distinct message-passing mechanisms for positive and negative feedback. Furthermore, we introduce a distortion to the negative graph, which exclusively consists of negative feedback edges, for contrastive training. This distortion plays a crucial role in effectively denoising the negative feedback. The experimental results provide compelling evidence that PANE-GNN surpasses the existing state-of-the-art benchmark methods across four real-world datasets. These datasets include three commonly used recommender system datasets and one open-source short video recommendation dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39789747",
                    "name": "Ziyang Liu"
                },
                {
                    "authorId": "2135743383",
                    "name": "Chao-Hong Wang"
                },
                {
                    "authorId": "2180607307",
                    "name": "Jingcao Xu"
                },
                {
                    "authorId": "2151102586",
                    "name": "Cheng Wu"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "144404428",
                    "name": "Yang Song"
                },
                {
                    "authorId": "51431610",
                    "name": "Na Mou"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "ff43970c754c27b6808053d9de8e2c64f468c25e",
            "title": "Network Representation Lightening From Hashing to Quantization",
            "abstract": "Information network embedding is an important way to enable efficient graph analytics. However, it still faces with computational challenges in problems such as link prediction and node recommendation, particularly with the increasing scale of networks. Both hashing and quantization are promising approaches for accelerating these problems by orders of magnitude. In the preliminary work, we have proposed to learn binary codes for information networks, but graph analytics may suffer from large accuracy degradation. To reduce information loss while achieving memory and search efficiency, we further propose to learn quantized codes for information networks. In particular, each node is represented by compositing multiple latent vectors, each of which is optimally selected from a distinct set. Since (generalized) matrix factorization unifies several well-known embedding methods with high-order proximity preserved, we propose a Network Representation Lightening framework based on Matrix Factorization (NRL-MF) to learn binary and quantized codes. We also propose an alternating optimization algorithm for efficient parameter learning, even for the generalized matrix factorization case. We finally evaluate NRL-MF on four real-world information network datasets with respect to the tasks of node classification and node recommendation. The results show that NRL-MF significantly outperforms competing baselines in both tasks, and that quantized representations indeed incur much smaller information loss than binarized codes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2118353327",
                    "name": "Zhihao Zhu"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "144143228",
                    "name": "Yong Ge"
                },
                {
                    "authorId": "2110972323",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "2227868312",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "217d59f6dce10cae6a008d69960ed0c2f839d534",
            "title": "Cache-Augmented Inbatch Importance Resampling for Training Recommender Retriever",
            "abstract": "Recommender retrievers aim to rapidly retrieve a fraction of items from the entire item corpus when a user query requests, with the representative two-tower model trained with the log softmax loss. For efficiently training recommender retrievers on modern hardwares, inbatch sampling, where the items in the mini-batch are shared as negatives to estimate the softmax function, has attained growing interest. However, existing inbatch sampling based strategies just correct the sampling bias of inbatch items with item frequency, being unable to distinguish the user queries within the mini-batch and still incurring significant bias from the softmax. In this paper, we propose a Cache-Augmented Inbatch Importance Resampling (XIR) for training recommender retrievers, which not only offers different negatives to user queries with inbatch items, but also adaptively achieves a more accurate estimation of the softmax distribution. Specifically, XIR resamples items for the given mini-batch training pairs based on certain probabilities, where a cache with more frequently sampled items is adopted to augment the candidate item set, with the purpose of reusing the historical informative samples. XIR enables to sample query-dependent negatives based on inbatch items and to capture dynamic changes of model training, which leads to a better approximation of the softmax and further contributes to better convergence. Finally, we conduct experiments to validate the superior performance of the proposed XIR compared with competitive approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108459889",
                    "name": "Jin Chen"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": null,
                    "name": "Yucheng Li"
                },
                {
                    "authorId": "49292171",
                    "name": "Baoyun Wang"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2227868312",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "4e30c242f2bbcd4ed5a4fc18e3fa1c60d45a952b",
            "title": "Learning Recommenders for Implicit Feedback with Importance Resampling",
            "abstract": "Recommendation is prevalently studied for implicit feedback recently, but it seriously suffers from the lack of negative samples, which has a significant impact on the training of recommendation models. Existing negative sampling is based on the static or adaptive probability distributions. Sampling from the adaptive probability receives more attention, since it tends to generate more hard examples, to make recommender training faster to converge. However, item sampling becomes much more time-consuming particularly for complex recommendation models. In this paper, we propose an Adaptive Sampling method based on Importance Resampling (AdaSIR for short), which is not only almost equally efficient and accurate for any recommender models, but also can robustly accommodate arbitrary proposal distributions. More concretely, AdaSIR maintains a contextualized sample pool of fixed-size with importance resampling, from which items are only uniformly sampled. Such a simple sampling method can be proved to provide approximately accurate adaptive sampling under some conditions. The sample pool plays two extra important roles in (1) reusing historical hard samples with certain probabilities; (2) estimating the rank of positive samples for weighting, such that recommender training can concentrate more on difficult positive samples. Extensive empirical experiments demonstrate that AdaSIR outperforms state-of-the-art methods in terms of sampling efficiency and effectiveness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108459889",
                    "name": "Jin Chen"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "6594353",
                    "name": "Binbin Jin"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2227868312",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "a3bc9636905d573ccc46b298571f7675d4428088",
            "title": "Ranking-Based Implicit Regularization for One-Class Collaborative Filtering",
            "abstract": "One-class collaborative filtering (OCCF) problems are ubiquitous in real-world recommendation systems, such as news recommendation, but suffer from data sparsity and lack of negative items. To address the challenge, the state-of-the-art algorithm assigns uninteracted items with smaller weights of being negative and performs low-rank approximation over the user-item interaction matrix. However, the prior ratings are usually suggested to be zero but may not be well-defined. To avert the direct utilization of prior ratings for uninteracted items, we propose a novel ranking-based implicit regularizer by hypothesizing that users\u2019 preference scores for uninteracted items should not deviate a lot from each other. The regularizer is then used in a ranking-based OCCF framework to penalize large differences of preference scores between uninteracted items. To efficiently optimize model parameters in this framework, we develop the scalable alternating least square algorithm and coordinate descent algorithm, whose time complexity is linearly proportional to the data size. Finally, we extensively evaluate the proposed algorithms on six public real-world datasets. The results show that the proposed regularizer significantly improves the recommendation quality of ranking-based OCCF algorithms, such as BPRMF and RankALS. Moreover, the ranking-based framework with the proposed regularizer outperforms the state-of-the-art recommendation algorithms for implicit feedback.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2108459889",
                    "name": "Jin Chen"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2227868312",
                    "name": "Enhong Chen"
                },
                {
                    "authorId": "48667278",
                    "name": "Xiaofang Zhou"
                }
            ]
        }
    ]
}