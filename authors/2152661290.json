{
    "authorId": "2152661290",
    "papers": [
        {
            "paperId": "5ecf12c1aa8e986ee458451feec93012b379e30d",
            "title": "Collaborative Multi-Task Representation for Natural Language Understanding",
            "abstract": "Multi-task learning has shown large benefits in Natural Language Understanding (NLU). However, current state-of-the-arts (SOTAs) like MT-DNN and MMoE do not model task relationships explicitly and fail to obtain effective task alignment. In this paper, we propose a Collaborative Multi-Task Representation (CMTR) framework to tackle this problem. We capture instance-level task relations through a task interaction layer, which helps guide the fusion of task-oriented representations into the final representation. Moreover, tailored loss functions are proposed to facilitate the learning of task alignment. Specifically, we leverage knowledge distillation as an auxiliary loss to assist the adaptation layers in generating task-oriented representations. We also introduce a regularization loss to learn better gating functions for multi-task fusion. Empirically, CMTR outperforms SOTA multi-task learning frameworks on most natural language understanding tasks in the GLUE benchmark. Furthermore, it achieves better task alignment and demonstrates good interpretability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "2320630587",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2055977348",
                    "name": "Ming Zeng"
                },
                {
                    "authorId": "2320580025",
                    "name": "Jing Yu"
                },
                {
                    "authorId": "2320718906",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2290004506",
                    "name": "Yunhai Tong"
                },
                {
                    "authorId": "2290065421",
                    "name": "Yujing Wang"
                }
            ]
        },
        {
            "paperId": "b043a9640b789d5e90ef409730c26ac5ccb884db",
            "title": "You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning",
            "abstract": "Recent research on the robustness of Graph Neural Networks (GNNs) under noises or attacks has attracted great attention due to its importance in real-world applications. Most previous methods explore a single noise source, recovering corrupt node embedding by reliable structures bias or developing structure learning with reliable node features. However, the noises and attacks may come from both structures and features in graphs, making the graph denoising a dilemma and challenging problem. In this paper, we develop a unified graph denoising (UGD) framework to unravel the deadlock between structure and feature denoising. Specifically, a high-order neighborhood proximity evaluation method is proposed to recognize noisy edges, considering features may be perturbed simultaneously. Moreover, we propose to refine noisy features with reconstruction based on a graph auto-encoder. An iterative updating algorithm is further designed to optimize the framework and acquire a clean graph, thus enabling robust graph learning for downstream tasks. Our UGD framework is self-supervised and can be easily implemented as a plug-and-play module. We carry out extensive experiments, which proves the effectiveness and advantages of our method. Code is avalaible at https://github.com/YoungTimmy/UGD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2306954810",
                    "name": "Tianmeng Yang"
                },
                {
                    "authorId": "2307088145",
                    "name": "Jiahao Meng"
                },
                {
                    "authorId": "2314827647",
                    "name": "Min Zhou"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "92385001",
                    "name": "Xiangtai Li"
                },
                {
                    "authorId": "2253401742",
                    "name": "Yunhai Tong"
                }
            ]
        },
        {
            "paperId": "e1e0f8990b44ed7bf8fe6935802c4cec41b9e977",
            "title": "Characteristic-Aware Time-Series Representation Learning for Unsupervised Anomaly Detection",
            "abstract": "Time-series anomaly detection is an important research topic in data mining, popular in both academia and industry. Recently, unsupervised anomaly detection draws considerable attention, since it can detect anomalies without parameter tuning on labels and meets the demands of industrial applications. Time-series representation learning plays a vital role in addressing unsupervised anomaly detection. However, it remains challenging to learn a unified representation model with diverse distributions and handle multivariate times-series with various features.To alleviate these challenges, we propose a novel representation strategy, termed CAT-AD, for unsupervised time-series anomaly detection. It learns characteristic-aware priors for representations of time-series by incorporating embeddings of broad characteristics and is capable of handling diverse anomaly detection tasks, regardless of their lengths and dimensions.Our proposed strategy is simple yet effective, which has been verified on two univariate datasets and five multivariate datasets from public sources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "2290143132",
                    "name": "Zhuo Li"
                },
                {
                    "authorId": "2290132976",
                    "name": "Pingping Lin"
                },
                {
                    "authorId": "2104164",
                    "name": "Juanyong Duan"
                },
                {
                    "authorId": "2320838476",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2306954810",
                    "name": "Tianmeng Yang"
                },
                {
                    "authorId": "3261801",
                    "name": "Congrui Huang"
                },
                {
                    "authorId": "2112752675",
                    "name": "Zhe-Min Lin"
                },
                {
                    "authorId": "2290004506",
                    "name": "Yunhai Tong"
                },
                {
                    "authorId": "2290065421",
                    "name": "Yujing Wang"
                }
            ]
        },
        {
            "paperId": "8a66786c38e4bddb4ff5ae73ccd1dcf6e5e3b78f",
            "title": "Multiple Connectivity Views for Session-based Recommendation",
            "abstract": "Session-based recommendation (SBR), which makes the next-item recommendation based on previous anonymous actions, has drawn increasing attention. The last decade has seen multiple deep learning-based modeling choices applied on SBR successfully, e.g., recurrent neural networks (RNNs), convolutional neural networks (CNNs), graph neural networks (GNNs), and each modeling choice has its intrinsic superiority and limitation. We argue that these modeling choices differentiate from each other by (1) the way they capture the interactions between items within a session and (2) the operators they adopt for composing the neural network, e.g., convolutional operator or self-attention operator. In this work, we dive deep into the former as it is relatively unique to the SBR scenario, while the latter is shared by general neural network modeling techniques. We first introduce the concept of connectivity view to describe the different item interaction patterns at the input level. Then, we develop the Multiple Connectivity Views for Session-based Recommendation (MCV-SBR), a unified framework that incorporates different modeling choices in a single model through the lens of connectivity view. In addition, MCV-SBR allows us to effectively and efficiently explore the search space of the combinations of connectivity views by the Tree-structured Parzen Estimator (TPE) algorithm. Finally, on three widely used SBR datasets, we verify the superiority of MCV-SBR by comparing the searched models with state-of-the-art baselines. We also conduct a series of studies to demonstrate the efficacy and practicability of the proposed connectivity view search algorithm, as well as other components in MCV-SBR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "47540245",
                    "name": "Jieyu Zhang"
                },
                {
                    "authorId": "46394401",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2240552790",
                    "name": "Zheng Miao"
                },
                {
                    "authorId": "2054671931",
                    "name": "Yu Tong"
                }
            ]
        },
        {
            "paperId": "86f190a4b54c678a88d49639613e82f41462fab1",
            "title": "Binary Classification with Positive Labeling Sources",
            "abstract": "To create a large amount of training labels for machine learning models effectively and efficiently, researchers have turned to Weak Supervision (WS), which uses programmatic labeling sources rather than manual annotation. Existing works of WS for binary classification typically assume the presence of labeling sources that are able to assign both positive and negative labels to data in roughly balanced proportions. However, for many tasks of interest where there is a minority positive class, negative examples could be too diverse for developers to generate indicative labeling sources. Thus, in this work, we study the application of WS on binary classification tasks with positive labeling sources only. We propose WEAPO, a simple yet competitive WS method for producing training labels without negative labeling sources. On 10 benchmark datasets, we show WEAPO achieves the highest averaged performance in terms of both the quality of synthesized labels and the performance of the final classifier supervised with these labels. We incorporated the implementation of WEAPO into WRENCH, an existing benchmarking platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47540245",
                    "name": "Jieyu Zhang"
                },
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "2158951748",
                    "name": "Yang Luo"
                },
                {
                    "authorId": "143711421",
                    "name": "Alexander J. Ratner"
                }
            ]
        },
        {
            "paperId": "a28191fe486ee49bbcd3ede75fe7001b0cf9e511",
            "title": "Enhancing Self-Attention with Knowledge-Assisted Attention Maps",
            "abstract": "Large-scale pre-trained language models have attracted extensive attentions in the research community and shown promising results on various tasks of natural language processing. However, the attention maps, which record the attention scores between tokens in self-attention mechanism, are sometimes ineffective as they are learned implicitly without the guidance of explicit semantic knowledge. Thus, we aim to infuse explicit external knowledge into pre-trained language models to further boost their performance. Existing works of knowledge infusion largely depend on multi-task learning frameworks, which are inefficient and require large-scale re-training when new knowledge is considered. In this paper, we propose a novel and generic solution, KAM-BERT, which directly incorporates knowledge-generated attention maps into the self-attention mechanism. It requires only a few extra parameters and supports efficient fine-tuning once new knowledge is added. KAM-BERT achieves consistent improvements on various academic datasets for natural language understanding. It also outperforms other state-of-the-art methods which conduct knowledge infusion into transformer-based architectures. Moreover, we apply our model to an industry-scale ad relevance application and show its advantages in the real-world scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152770689",
                    "name": "Jiangang Bai"
                },
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2152993452",
                    "name": "Hong Sun"
                },
                {
                    "authorId": "2116926074",
                    "name": "Ruonan Wu"
                },
                {
                    "authorId": "40047504",
                    "name": "Tianmeng Yang"
                },
                {
                    "authorId": "48475903",
                    "name": "Pengfei Tang"
                },
                {
                    "authorId": "120783624",
                    "name": "Defu Cao"
                },
                {
                    "authorId": "2175481206",
                    "name": "Mingliang Zhang1"
                },
                {
                    "authorId": "2054671931",
                    "name": "Yu Tong"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "2113829510",
                    "name": "Jing Bai"
                },
                {
                    "authorId": "2124601065",
                    "name": "Ruofei Zhang"
                },
                {
                    "authorId": "2118180377",
                    "name": "Hao Sun"
                },
                {
                    "authorId": null,
                    "name": "Wei Shen"
                }
            ]
        },
        {
            "paperId": "a4bc9b74604eb94f225f8100bc919ab3e2c1233c",
            "title": "Heat-RL: Online Model Selection for Streaming Time-Series Anomaly Detection",
            "abstract": "Time-series",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "41159120",
                    "name": "Luoxing Xiong"
                },
                {
                    "authorId": "2129402731",
                    "name": "Mingliang Zhang"
                },
                {
                    "authorId": "2053313632",
                    "name": "Hui Xue"
                },
                {
                    "authorId": "2115813040",
                    "name": "Qi Chen"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "2054671931",
                    "name": "Yu Tong"
                },
                {
                    "authorId": "3261801",
                    "name": "Congrui Huang"
                },
                {
                    "authorId": "1388682473",
                    "name": "Bixiong Xu"
                }
            ]
        },
        {
            "paperId": "df6e42e06d77ebc28b50492b1fd26b39c1bd4277",
            "title": "Convolution-Enhanced Evolving Attention Networks",
            "abstract": "Attention-based neural networks, such as Transformers, have become ubiquitous in numerous applications, including computer vision, natural language processing, and time-series analysis. In all kinds of attention networks, the attention maps are crucial as they encode semantic dependencies between input tokens. However, most existing attention networks perform modeling or reasoning based on representations, wherein the attention maps of different layers are learned separately without explicit interactions. In this paper, we propose a novel and generic evolving attention mechanism, which directly models the evolution of inter-token relationships through a chain of residual convolutional modules. The major motivations are twofold. On the one hand, the attention maps in different layers share transferable knowledge, thus adding a residual connection can facilitate the information flow of inter-token relationships across layers. On the other hand, there is naturally an evolutionary trend among attention maps at different abstraction levels, so it is beneficial to exploit a dedicated convolution-based module to capture this process. Equipped with the proposed mechanism, the convolution-enhanced evolving attention networks achieve superior performance in various applications, including time-series representation, natural language understanding, machine translation, and image classification. Especially on time-series representation tasks, Evolving Attention-enhanced Dilated Convolutional (EA-DC-) Transformer outperforms state-of-the-art models significantly, achieving an average of 17% improvement compared to the best SOTA. To the best of our knowledge, this is the first work that explicitly models the layer-wise evolution of attention maps. Our implementation is available at https://github.com/pkuyym/EvolvingAttention.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "80389349",
                    "name": "Zhuowan Li"
                },
                {
                    "authorId": "152770689",
                    "name": "Jiangang Bai"
                },
                {
                    "authorId": "2129402731",
                    "name": "Mingliang Zhang"
                },
                {
                    "authorId": "92385001",
                    "name": "Xiangtai Li"
                },
                {
                    "authorId": "119883573",
                    "name": "J. Yu"
                },
                {
                    "authorId": "2109269339",
                    "name": "Ce Zhang"
                },
                {
                    "authorId": "2115218570",
                    "name": "Gao Huang"
                },
                {
                    "authorId": "2054671931",
                    "name": "Yu Tong"
                }
            ]
        },
        {
            "paperId": "0fe8b49369d70a2be473435a82b01544704b3c9f",
            "title": "Evolving Attention with Residual Convolutions",
            "abstract": "Transformer is a ubiquitous model for natural language processing and has attracted wide attentions in computer vision. The attention maps are indispensable for a transformer model to encode the dependencies among input tokens. However, they are learned independently in each layer and sometimes fail to capture precise patterns. In this paper, we propose a novel and generic mechanism based on evolving attention to improve the performance of transformers. On one hand, the attention maps in different layers share common knowledge, thus the ones in preceding layers can instruct the attention in succeeding layers through residual connections. On the other hand, low-level and high-level attentions vary in the level of abstraction, so we adopt convolutional layers to model the evolutionary process of attention maps. The proposed evolving attention mechanism achieves significant performance improvement over various state-of-the-art models for multiple tasks, including image classification, natural language understanding and machine translation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "152770689",
                    "name": "Jiangang Bai"
                },
                {
                    "authorId": "2129402731",
                    "name": "Mingliang Zhang"
                },
                {
                    "authorId": "2113829510",
                    "name": "Jing Bai"
                },
                {
                    "authorId": "119883573",
                    "name": "J. Yu"
                },
                {
                    "authorId": "1776014",
                    "name": "Ce Zhang"
                },
                {
                    "authorId": "143983679",
                    "name": "Gao Huang"
                },
                {
                    "authorId": "8230405",
                    "name": "Yunhai Tong"
                }
            ]
        },
        {
            "paperId": "20fdafb68d0e69d193527a9a1cbe64e7e69a3798",
            "title": "Learning Multi-granularity Consecutive User Intent Unit for Session-based Recommendation",
            "abstract": "Session-based recommendation aims to predict a user's next action based on previous actions in the current session. The major challenge is to capture authentic and complete user preferences in the entire session. Recent work utilizes graph structure to represent the entire session and adopts Graph Neural Network (GNN) to encode session information. This modeling choice has been proved to be effective and achieved remarkable results. However, most of the existing studies only consider each item within the session independently and do not capture session semantics from a high-level perspective. Such limitation often leads to severe information loss and increases the difficulty of capturing long-range dependencies within a session. Intuitively, compared with individual items, a session snippet, i.e., a group of locally consecutive items, is able to provide supplemental user intents which are hardly captured by existing methods. In this work, we propose to learn multi-granularity consecutive user intent unit to improve the recommendation performance. Specifically, we creatively propose Multi-granularity Intent Heterogeneous Session Graph (MIHSG) which captures the interactions between different granularity intent units and relieves the burden of long-dependency. Moreover, we propose the Intent Fusion Ranking (IFR) module to compose the recommendation results from various granularity user intents. Compared with current methods that only leverage intents from individual items, IFR benefits from different granularity user intents to generate more accurate and comprehensive session representation, thus eventually boosting recommendation performance. We conduct extensive experiments on five session-based recommendation datasets and the results demonstrate the effectiveness of our method. Compared to current state-of-the-art methods, we achieve as large as 10.21% gain on HR@20 and 15.53% gain on MRR@20.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "5765645",
                    "name": "Jiayan Guo"
                },
                {
                    "authorId": "2152661290",
                    "name": "Yaming Yang"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "2156008371",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2115657798",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2113829510",
                    "name": "Jing Bai"
                },
                {
                    "authorId": "34721188",
                    "name": "Yan Zhang"
                }
            ]
        }
    ]
}