{
    "authorId": "2152602955",
    "papers": [
        {
            "paperId": "0acc62dc2cf996a9fb0acb4cc08965f7d8059c19",
            "title": "ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation",
            "abstract": "This study introduces an approach to optimize Parameter Efficient Fine Tuning (PEFT) for Pretrained Language Models (PLMs) by implementing a Shared Low Rank Adaptation (ShareLoRA). By strategically deploying ShareLoRA across different layers and adapting it for the Query, Key, and Value components of self-attention layers, we achieve a substantial reduction in the number of training parameters and memory usage. Importantly, ShareLoRA not only maintains model performance but also exhibits robustness in both classification and generation tasks across a variety of models, including RoBERTa, GPT-2, LLaMA and LLaMA2. It demonstrates superior transfer learning capabilities compared to standard LoRA applications and mitigates overfitting by sharing weights across layers. Our findings affirm that ShareLoRA effectively boosts parameter efficiency while ensuring scalable and high-quality performance across different language model architectures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152602955",
                    "name": "Yurun Song"
                },
                {
                    "authorId": "120246321",
                    "name": "Junchen Zhao"
                },
                {
                    "authorId": "2269144659",
                    "name": "Ian G. Harris"
                },
                {
                    "authorId": "37541666",
                    "name": "S. Jyothi"
                }
            ]
        },
        {
            "paperId": "049288e68caeadf7842df6977e140b47a8a2f89d",
            "title": "MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling",
            "abstract": "We present MatSci-NLP, a natural language benchmark for evaluating the performance of natural language processing (NLP) models on materials science text. We construct the benchmark from publicly available materials science text data to encompass seven different NLP tasks, including conventional NLP tasks like named entity recognition and relation classification, as well as NLP tasks specific to materials science, such as synthesis action retrieval which relates to creating synthesis procedures for materials. We study various BERT-based models pretrained on different scientific text corpora on MatSci-NLP to understand the impact of pretraining strategies on understanding materials science text. Given the scarcity of high-quality annotated data in the materials science domain, we perform our fine-tuning experiments with limited training data to encourage the generalize across MatSci-NLP tasks.Our experiments in this low-resource training setting show that language models pretrained on scientific text outperform BERT trained on general text. MatBERT, a model pretrained specifically on materials science journals, generally performs best for most tasks. Moreover, we propose a unified text-to-schema for multitask learning on {pasted macro \u2018BENCHMARK\u2019} and compare its performance with traditional fine-tuning methods. In our analysis of different training methods, we find that our proposed text-to-schema methods inspired by question-answering consistently outperform single and multitask NLP fine-tuning methods. The code and datasets are publicly available https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2152602955",
                    "name": "Yurun Song"
                },
                {
                    "authorId": "51895312",
                    "name": "Santiago Miret"
                },
                {
                    "authorId": "2116441692",
                    "name": "Bang Liu"
                }
            ]
        },
        {
            "paperId": "146e6b3e22f89aead3eba595f3b61a07bfa124c7",
            "title": "PCMID: Multi-Intent Detection through Supervised Prototypical Contrastive Learning",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152602955",
                    "name": "Yurun Song"
                },
                {
                    "authorId": "120246321",
                    "name": "Junchen Zhao"
                },
                {
                    "authorId": "2273707448",
                    "name": "Spencer Koehler"
                },
                {
                    "authorId": "2273666196",
                    "name": "Amir Abdullah"
                },
                {
                    "authorId": "2269144659",
                    "name": "Ian G. Harris"
                }
            ]
        },
        {
            "paperId": "cde19e90b461f6c5f6cb8cde74931abf6c0d56c9",
            "title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices",
            "abstract": "Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of $1.11\\times$ to $1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of $1.29\\times$ to $1.32\\times$.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120246321",
                    "name": "Junchen Zhao"
                },
                {
                    "authorId": "2152602955",
                    "name": "Yurun Song"
                },
                {
                    "authorId": "2269687280",
                    "name": "Simeng Liu"
                },
                {
                    "authorId": "2269144659",
                    "name": "Ian G. Harris"
                },
                {
                    "authorId": "37541666",
                    "name": "S. Jyothi"
                }
            ]
        },
        {
            "paperId": "ab9f73bd3f941ab2713293cefeb23cff9696207e",
            "title": "GAP-Gen: Guided Automatic Python Code Generation",
            "abstract": "Automatic code generation from natural language descriptions can be highly beneficial during the process of software development. In this work, we propose GAP-Gen, a Guided Automatic Python Code Generation method based on Python syntactic constraints and semantic constraints. We first introduce Python syntactic constraints in the form of Syntax-Flow, which is a simplified version of Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract Syntax Tree but maintaining crucial syntactic information of Python code. In addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable and function names consistently through out the code. In our work, rather than pretraining, we focus on modifying the finetuning process which reduces computational requirements but retains high generation performance on automatic Python code generation task. GAP-Gen fine-tunes the transformer based language models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet, CodeSearchNet AdvTest and Code-Docstring Corpus from EdinburghNLP. Our experiments show that GAP-Gen achieves better results on automatic Python code generation task than previous works",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120246321",
                    "name": "Junchen Zhao"
                },
                {
                    "authorId": "2152602955",
                    "name": "Yurun Song"
                },
                {
                    "authorId": "49606614",
                    "name": "Junlin Wang"
                },
                {
                    "authorId": "1781062",
                    "name": "I. Harris"
                }
            ]
        },
        {
            "paperId": "aeff47b65c8e311a7282918c90be633fb516fae0",
            "title": "SentSim: Crosslingual Semantic Evaluation of Machine Translation",
            "abstract": "Machine translation (MT) is currently evaluated in one of two ways: in a monolingual fashion, by comparison with the system output to one or more human reference translations, or in a trained crosslingual fashion, by building a supervised model to predict quality scores from human-labeled data. In this paper, we propose a more cost-effective, yet well performing unsupervised alternative SentSim: relying on strong pretrained multilingual word and sentence representations, we directly compare the source with the machine translated sentence, thus avoiding the need for both reference translations and labelled training data. The metric builds on state-of-the-art embedding-based approaches \u2013 namely BERTScore and Word Mover\u2019s Distance \u2013 by incorporating a notion of sentence semantic similarity. By doing so, it achieves better correlation with human scores on different datasets. We show that it outperforms these and other metrics in the standard monolingual setting (MT-reference translation), a well as in the source-MT bilingual setting, where it performs on par with glass-box approaches to quality estimation that rely on MT model information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152602955",
                    "name": "Yurun Song"
                },
                {
                    "authorId": "120246321",
                    "name": "Junchen Zhao"
                },
                {
                    "authorId": "1702974",
                    "name": "Lucia Specia"
                }
            ]
        }
    ]
}