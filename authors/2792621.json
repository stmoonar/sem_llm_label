{
    "authorId": "2792621",
    "papers": [
        {
            "paperId": "0da669eb156de8569b88cc1c8d3e58cd5ad1b25c",
            "title": "Real-World Popularity Estimation from Community Structure of Followers on SNS",
            "abstract": "In this paper, we propose methods of estimating the offline real-world popularity of users of online social network services (SNSs). Because their followers on an SNS are biased sampling from their offline real-world fans, we cannot estimate their real-world popularity simply by the number of their online followers. Our methods are based on the following hypothesis: SNS users with followers more distributed over many communities are likely to have more real-world popularity. We developed four methods, three of which use variations of the clustering coefficients of the followers to measure how much they are distributed, and one of which uses a metric we newly designed. Through the evaluation of our methods on the data from nine Ms/Mr university competitions, we validated our hypothesis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110064062",
                    "name": "Shuhei Kobayashi"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "29dd0a69daff6dd0be585a73c3c959e0be5553dd",
            "title": "MIAIS: A Multimedia Recipe Dataset with Ingredient Annotation at Each Instructional Step",
            "abstract": "In this paper, we introduce a multimedia recipe dataset with annotation of ingredients at every instructional step, named MIAIS (Multimedia recipe dataset with Ingredient Annotation at every Instructional Step). One unique feature of recipe data is that it is usually presented in a sequential and multimedia form. However, few publicly available recipe datasets contain multimedia text-image paired data for every cooking step. Our goal is to construct a recipe dataset that contains sufficient multimedia data and the annotations to them for every cooking step, which is important for many research topics, such as cooking flow graph generation, recipe text generation, and cooking action recognition. MIAIS contains 12,000 recipes; each recipe has 9.13 cooking instruction steps on average, each of which is a tuple of a text description and an image. The text descriptions and images are collected from the NII Cookpad Dataset and Cookpad Image Dataset, respectively. We have already released our annotation data and related information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124824354",
                    "name": "Yixin Zhang"
                },
                {
                    "authorId": "2936312",
                    "name": "Yoko Yamakata"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "ee8f7af23f41aed5658c2d1d1ee3653406491124",
            "title": "Active Learning Strategies Based on Text Informativeness",
            "abstract": "In this paper, we propose strategies for selecting the next item to label in active learning for text data. Text data have several text-specific features, such as TF-IDF vectors and document embeddings. These features have correlation with the informativeness of the text data, so our methods select the next item to label by using these text-specific features. We evaluate the performance of our strategies in two problem settings: the standard active learning setting, where we focus on the improvement of the model accuracy, and the learning-to-enumerate setting, where we focus on the efficiency in enumerating all instances of a given target class. We also combine our strategies with two existing strategies: uncertainty sampling, a well-known strategy for active learning, and the exploitation-only strategy, a strategy used in learning-to-enumerate problems. Our experiment on two publicly available English text datasets show that our method outperforms the baseline methods in both problem settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215315820",
                    "name": "Ruide Li"
                },
                {
                    "authorId": "2936312",
                    "name": "Yoko Yamakata"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "431ef3a9999ac309ac5cb8242f520ceeae249cf0",
            "title": "Supplementing Omitted Named Entities in Cooking Procedural Text with Attached Images",
            "abstract": "In this research, we aim at supplementing named entities, such as food, omitted in the procedural text of recipe data. It helps users understand the recipe and is also necessary for the machine to understand the recipe data automatically. The contribution of this research is as follows. (1) We construct a dataset of Chinese recipes consisting of 12,548 recipes. To detect sentences in which food entities are omitted, we label named entities such as food, tool, and cooking actions in the procedural text by using the automatic recipe named entity recognition method. (2) We propose a method of recognizing food from the attached images. A procedural text of recipe data is often associated with an image, and the attached image often contains the food even when it is omitted in the procedural text. Tool entities in images in recipe data can be identified with high accuracy by conventional general object recognition techniques. On the other hand, the general object recognition methods in the literature, which assume that the properties of an object are constant, perform not well for food in recipe image data because food states change during cooking procedures. To solve this problem, we propose a method of obtaining food entity candidates from other steps that are similar to the target step, both in sentence similarity and image feature similarity. Among all the 246,195 procedural steps in our dataset, there are 16,593 steps in which the food entity is omitted in the procedural text. Our method is applied to supplement the food entities in these steps and achieves the accuracy of 67.55%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124824354",
                    "name": "Yixin Zhang"
                },
                {
                    "authorId": "2936312",
                    "name": "Yoko Yamakata"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "78e52f8d8fa162b5acc45e4a1caf1eba8006fa55",
            "title": "Spammer Detection Based on Task Completion Time Variation in Crowdsourcing",
            "abstract": "Many existing spammer detection methods uses dependency between workers\u2019 answers and the true answers. These methods may regard a diligent but low-skilled worker as a spammer. Our method uses correlation between workers\u2019 task completion time and the difficulty of the tasks. Our experimental result suggests that this approach is potentially useful, but the selection of tasks seems a key for success.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1572239996",
                    "name": "Ayato Watanabe"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "92e5e088d4298427ba896779cb86fbc2a42f6b91",
            "title": "MIRecipe: A Recipe Dataset for Stage-Aware Recognition of Changes in Appearance of Ingredients",
            "abstract": "In this paper, we introduce a new recipe dataset MIRecipe (Multimedia-Instructional Recipe). It has both text and image data for every cooking step, while the conventional recipe datasets only contain final dish images, and/or images only for some of the steps. It consists of 26,725 recipes, which include 239,973 steps in total. The recognition of ingredients in images associated with cooking steps poses a new challenge: Since ingredients are processed during cooking, the appearance of the same ingredient is very different in the beginning and finishing stages of the cooking. The general object recognition methods, which assume the constant appearance of objects, do not perform well for such objects. To solve the problem, we propose two stage-aware techniques: stage-wise model learning, which trains a separate model for each stage, and stage-aware curriculum learning, which starts with the training data from the beginning stage and proceeds to the later stages. Our experiment with our dataset shows that our method achieves higher accuracy than the model trained using all the data without considering the stages. Our dataset is available at our GitHub repository.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124824354",
                    "name": "Yixin Zhang"
                },
                {
                    "authorId": "2936312",
                    "name": "Yoko Yamakata"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "6aced7d7303fd82f8c4218aea2f3387efdf1d3c1",
            "title": "Making AI Machines Work for Humans in FoW",
            "abstract": "The Future of Work (FoW) is witnessing an evolution where AI systems (broadly machines or businesses) are used to the benefit of humans. Work here refers to all forms of paid and unpaid labor in both physical and virtual workplaces and that is enabled by AI systems. This covers crowdsourcing platforms such as Amazon Mechanical Turk, online labor marketplaces such as TaskRabbit and Qapa, but also regular jobs in physical workplaces. Bringing humans back to the frontier of FoW will increase their trust in AI systems and shift their perception to use them as a source of self-improvement, ensure better work performance, and positively shape social and economic outcomes of a society and a nation. To enable that, physical and virtual workplaces will need to capture human traits, behavior, evolving needs, and provide jobs to all. Attitudes, values, opinions regarding the processes and policies will need to be assessed and considered in the design of FoW ecosystems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2034201368",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2146072233",
                    "name": "Lei Chen"
                },
                {
                    "authorId": "34573158",
                    "name": "Atsuyuki Morishima"
                },
                {
                    "authorId": "2034202207",
                    "name": "James Abello Monedero"
                },
                {
                    "authorId": "1807924",
                    "name": "P. Bourhis"
                },
                {
                    "authorId": "2038513",
                    "name": "F. Charoy"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "1863248",
                    "name": "Shady Elbassuoni"
                },
                {
                    "authorId": "1403157540",
                    "name": "D. Gross-Amblard"
                },
                {
                    "authorId": "51493818",
                    "name": "Emilie Hoareau"
                },
                {
                    "authorId": "2808778",
                    "name": "M. Inoguchi"
                },
                {
                    "authorId": "2034202198",
                    "name": "Jared Kenworthy"
                },
                {
                    "authorId": "7251192",
                    "name": "I. Kitahara"
                },
                {
                    "authorId": "2124213925",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "3039205",
                    "name": "R. M. Borromeo"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "2069605832",
                    "name": "Raghav Rao"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "1734682",
                    "name": "P. Senellart"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "1825255212",
                    "name": "M. Tommasi"
                },
                {
                    "authorId": "49697753",
                    "name": "Kazutoshi Umemoto"
                },
                {
                    "authorId": "144918359",
                    "name": "A. Wiggins"
                },
                {
                    "authorId": "2034178749",
                    "name": "Koichiro Yoshida"
                }
            ]
        },
        {
            "paperId": "34665979a04acbfa3fe890e6e412018d0df7a1cd",
            "title": "Categorization of Cooking Actions Based on Textual/Visual Similarity",
            "abstract": "In this paper, we propose a method of automatically categorizing cooking actions appearing in recipe data. We extract verbs from textual descriptions of cooking procedures in recipe data, and vectorize them by using word embedding. These vectors provide a way to compute contextual similarity between verbs. We also extract images associated with each step of the procedures, and vectorize them by using a standard feature extraction method. For each verb, we collect images associated with the steps whose description includes the verb, and calculate the average of their vectors. These vectors provide a way to compute visual similarity between verbs. However, one type of action is sometimes represented by several types of images in recipe data. In such cases, the average of the associated image vectors is not appropriate representation of the action. To mitigate this problem, we propose a yet another way to vectorize verbs. We first cluster all the images in the recipe data into 20 clusters. For each verb, we calculate the ratio of each cluster within the set of images associated with the verb, and create a 20-dimensional vector representing the distribution over the 20 classes. We calculate similarity of verbs by using these three kinds of vector representations. We conducted a preliminary experiment for comparing these three ways, and the result shows that each of them are useful for categorizing cooking actions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124824354",
                    "name": "Yixin Zhang"
                },
                {
                    "authorId": "2936312",
                    "name": "Yoko Yamakata"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "3a94b0df6b28eee51a94eaa576f026c83520203d",
            "title": "A proposal of spatial operators for a collaborative map search system",
            "abstract": "We proposed a new query language that expresses complex spatial queries in a concise and intuitive way. The language can express conditions on the range, direction and time distance within a spatial search query by using the proposed spatial operators and \"space character\". We also show how a collaborative map search system supporting this query language can be implemented and describe several applications to highlight how the language can be put into practice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146024513",
                    "name": "Yuanyuan Wang"
                },
                {
                    "authorId": "145325410",
                    "name": "Panote Siriaraya"
                },
                {
                    "authorId": "36113293",
                    "name": "Yukiko Kawai"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        },
        {
            "paperId": "468cc717d0ba43e01a60ffe4a45d64ee8422cd31",
            "title": "Improving Multiclass Classification in Crowdsourcing by Using Hierarchical Schemes",
            "abstract": "In this paper, we propose a method of improving accuracy of multiclass classification tasks in crowdsourcing. In crowdsourcing, it is important to assign appropriate workers to appropriate tasks. In multiclass classification, different workers are good at different subcategories. In our method, we reorganize a given flat classification task into a hierarchical classification task consisting of several subtasks, and assign each worker to an appropriate subtask. In this approach, it is important to choose a good hierarchy. In our method, we first post a flat classification task with a part of data and collect statistics on each worker's ability. Based on the obtained statistics, we simulate all candidate hierarchical schemes, estimate their expected accuracy, choose the best scheme, and post it with the rest of data. In our method, it is also important to allocate workers to appropriate subtasks. We designed several greedy worker allocation algorithms. The results of our experiments show that our method improves the accuracy of multiclass classification tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067779606",
                    "name": "Xiaoni Duan"
                },
                {
                    "authorId": "2792621",
                    "name": "Keishi Tajima"
                }
            ]
        }
    ]
}