{
    "authorId": "2158624285",
    "papers": [
        {
            "paperId": "cfdaf06f93d53e045006a087d8cac70ad142c631",
            "title": "Mixture of In-Context Prompters for Tabular PFNs",
            "abstract": "Recent benchmarks found In-Context Learning (ICL) outperforms both deep learning and tree-based algorithms on small tabular datasets. However, on larger datasets, ICL for tabular learning cannot run without severely compromising performance, due to its quadratic space and time complexity w.r.t. dataset size. We propose MIXTUREPFN, which both extends nearest-neighbor sampling to the state-of-the-art ICL for tabular learning model and uses bootstrapping to finetune said model on the inference-time dataset. MIXTUREPFN is the Condorcet winner across 36 diverse tabular datasets against 19 strong deep learning and tree-based baselines, achieving the highest mean rank among Top-10 aforementioned algorithms with statistical significance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46697020",
                    "name": "Derek Xu"
                },
                {
                    "authorId": "2168271656",
                    "name": "Olcay Cirit"
                },
                {
                    "authorId": "2303406424",
                    "name": "Reza Asadi"
                },
                {
                    "authorId": "2244171114",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "de5a8512657eef30811ca471160f38e79f8c147c",
            "title": "Hierarchical Attention Models for Multi-Relational Graphs",
            "abstract": "We present Bi-Level Attention-Based Relational Graph Convolutional Networks (BR-GCN), unique neural network architectures that utilize masked self-attentional layers with relational graph convolutions, to effectively operate on highly multi-relational data. BR-GCN models use bi-level attention to learn node embeddings through (1) node-level attention, and (2) relation-level attention. The node-level self-attentional layers use intra-relational graph interactions to learn relation-specific node embeddings using a weighted aggregation of neighborhood features in a sparse subgraph region. The relation-level self-attentional layers use inter-relational graph interactions to learn the final node embeddings using a weighted aggregation of relation-specific node embeddings. The BR-GCN bi-level attention mechanism extends Transformer-based multiplicative attention from the natural language processing (NLP) domain, and Graph Attention Networks (GAT)-based attention, to large-scale heterogeneous graphs (HGs). On node classification, BR-GCN outperforms baselines from 0.29% to 14.95% as a stand-alone model, and on link prediction, BR-GCN outperforms baselines from 0.02% to 7.40% as an auto-encoder model. We also conduct ablation studies to evaluate the quality of BR-GCN's relation-level attention and discuss how its learning of graph structure may be transferred to enrich other graph neural networks (GNNs). Through various experiments, we show that BR-GCN's attention mechanism is both scalable and more effective in learning compared to state-of-the-art GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2068005212",
                    "name": "Roshni G. Iyer"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "2244171114",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "06b7a5e3f9487def152d032575867ceca143f4f7",
            "title": "Generalizing Graph ODE for Learning Complex System Dynamics across Environments",
            "abstract": "Learning multi-agent system dynamics have been extensively studied for various real-world applications, such as molecular dynamics in biology, multi-body system prediction in physics, and particle dynamics in material science. Most of the existing models are built to learn single system dynamics, which learn the dynamics from observed historical data and predict the future trajectory. In practice, however, we might observe multiple systems that are generated across different environments, which differ in latent exogenous factors such as temperature and gravity. One simple solution is to learn multiple environment-specific models, but it fails to exploit the potential commonalities among the dynamics across environments and offers poor prediction results where per-environment data is sparse or limited. Here, we present GG-ODE (Generalized Graph Ordinary Differential Equations), a machine learning framework for learning continuous multi-agent system dynamics across environments. Our model learns system dynamics using neural ordinary differential equations (ODE) parameterized by Graph Neural Networks (GNNs) to capture the continuous interaction among agents. We achieve the model generalization by assuming the dynamics across different environments are governed by common physics laws that can be captured via learning a shared ODE function. The distinct latent exogenous factors learned for each environment are incorporated into the ODE function to account for their differences. To improve model performance, we additionally design two regularization losses to (1) enforce the orthogonality between the learned initial states and exogenous factors via mutual information minimization; and (2) reduce the temporal variance of learned exogenous factors within the same system via contrastive learning. Experiments over various physical simulations show that our model can accurately predict system dynamics, especially in the long range, and can generalize well to new systems with few observations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "4993258852711c4e3d0011325ac3db680eae84f4",
            "title": "SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models",
            "abstract": "Most of the existing Large Language Model (LLM) benchmarks on scientific problem reasoning focus on problems grounded in high-school subjects and are confined to elementary algebraic operations. To systematically examine the reasoning capabilities required for solving complex scientific problems, we introduce an expansive benchmark suite SciBench for LLMs. SciBench contains a carefully curated dataset featuring a range of collegiate-level scientific problems from mathematics, chemistry, and physics domains. Based on the dataset, we conduct an in-depth benchmarking study of representative open-source and proprietary LLMs with various prompting strategies. The results reveal that the current LLMs fall short of delivering satisfactory performance, with the best overall score of merely 43.22%. Furthermore, through a detailed user study, we categorize the errors made by LLMs into ten problem-solving abilities. Our analysis indicates that no single prompting strategy significantly outperforms the others and some strategies that demonstrate improvements in certain problem-solving skills could result in declines in other skills. We envision that SciBench will catalyze further developments in the reasoning abilities of LLMs, thereby ultimately contributing to scientific research and discovery.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2224092326",
                    "name": "Xiaoxuan Wang"
                },
                {
                    "authorId": "3407296",
                    "name": "Ziniu Hu"
                },
                {
                    "authorId": "2887562",
                    "name": "Pan Lu"
                },
                {
                    "authorId": "2653121",
                    "name": "Yanqiao Zhu"
                },
                {
                    "authorId": "47540245",
                    "name": "Jieyu Zhang"
                },
                {
                    "authorId": "2224018745",
                    "name": "Satyen Subramaniam"
                },
                {
                    "authorId": "2224017080",
                    "name": "Arjun R. Loomba"
                },
                {
                    "authorId": "2145408511",
                    "name": "Shichang Zhang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "a0c2052ea02e1916263841db5b9ca3b13e10ccd1",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts' granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts' granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "9544714",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2987847",
                    "name": "Yangkexin Liang"
                },
                {
                    "authorId": "1879297505",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2157096355",
                    "name": "Xian Li"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "1af547c9de369b4bacd7a4724e5a9ff3d3fb3b99",
            "title": "Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs",
            "abstract": "Two-view knowledge graphs (KGs) jointly represent two components: an ontology view for abstract and commonsense concepts, and an instance view for specific entities that are instantiated from ontological concepts. As such, these KGs contain heterogeneous structures that are hierarchical, from the ontology-view, and cyclical, from the instance-view. Despite these various structures in KGs, recent works on embedding KGs assume that the entire KG belongs to only one of the two views but not both simultaneously. For works that seek to put both views of the KG together, the instance and ontology views are assumed to belong to the same geometric space, such as all nodes embedded in the same Euclidean space or non-Euclidean product space, an assumption no longer reasonable for two-view KGs where different portions of the graph exhibit different structures. To address this issue, we define and construct a dual-geometric space embedding model (DGS) that models two-view KGs using a complex non-Euclidean geometric space, by embedding different portions of the KG in different geometric spaces. DGS utilizes the spherical space, hyperbolic space, and their intersecting space in a unified framework for learning embeddings. Furthermore, for the spherical space, we propose novel closed spherical space operators that directly decompose to using properties of the spherical space without the need for mapping to an approximate tangent space. Experiments on public datasets show that DGS significantly outperforms previous state-of-the-art baseline models on KG completion tasks, demonstrating its ability to better model heterogeneous structures in KGs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2068005212",
                    "name": "Roshni G. Iyer"
                },
                {
                    "authorId": "51228791",
                    "name": "Yunsheng Bai"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "28a6cb70e2e8982ddcba55b7fbac509ee92c8074",
            "title": "Detecting Small Query Graphs in A Large Graph via Neural Subgraph Search",
            "abstract": "Recent advances have shown the success of using reinforcement learning and search to solve NP-hard graph-related tasks, such as Traveling Salesman Optimization, Graph Edit Distance computation, etc. However, it remains unclear how one can efficiently and accurately detect the occurrences of a small query graph in a large target graph, which is a core operation in graph database search, biomedical analysis, social group finding, etc. This task is called Subgraph Matching which essentially performs subgraph isomorphism check between a query graph and a large target graph. One promising approach to this classical problem is the\"learning-to-search\"paradigm, where a reinforcement learning (RL) agent is designed with a learned policy to guide a search algorithm to quickly find the solution without any solved instances for supervision. However, for the specific task of Subgraph Matching, though the query graph is usually small given by the user as input, the target graph is often orders-of-magnitude larger. It poses challenges to the neural network design and can lead to solution and reward sparsity. In this paper, we propose NSUBS with two innovations to tackle the challenges: (1) A novel encoder-decoder neural network architecture to dynamically compute the matching information between the query and the target graphs at each search state; (2) A novel look-ahead loss function for training the policy network. Experiments on six large real-world target graphs show that NSUBS can significantly improve the subgraph matching performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51228791",
                    "name": "Yunsheng Bai"
                },
                {
                    "authorId": "46697020",
                    "name": "Derek Xu"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "2bf8373861ec34b9443e76f09d5b00a8256cd213",
            "title": "A Mobility-Aware Deep Learning Model for Long-Term COVID-19 Pandemic Prediction and Policy Impact Analysis",
            "abstract": "Pandemic(epidemic) modeling, aiming at disease spreading analysis, has always been a popular research topic especially following the outbreak of COVID-19 in 2019. Some representative models including SIR-based deep learning prediction models have shown satisfactory performance. However, one major drawback for them is that they fall short in their long-term predictive ability. Although graph convolutional networks (GCN) also perform well, their edge representations do not contain complete information and it can lead to biases. Another drawback is that they usually use input features which they are unable to predict. Hence, those models are unable to predict further future. We propose a model that can propagate predictions further into the future and it has better edge representations. In particular, we model the pandemic as a spatial-temporal graph whose edges represent the transition of infections and are learned by our model. We use a two-stream framework that contains GCN and recursive structures (GRU) with an attention mechanism. Our model enables mobility analysis that provides an effective toolbox for public health researchers and policy makers to predict how different lock-down strategies that actively control mobility can influence the spread of pandemics. Experiments show that our model outperforms others in its long-term predictive power. Moreover, we simulate the effects of certain policies and predict their impacts on infection control.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2068107537",
                    "name": "Danfeng Guo"
                },
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "7182462",
                    "name": "Junheng Hao"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "70287739",
                    "name": "D. Terzopoulos"
                }
            ]
        },
        {
            "paperId": "4eab717336bea4ca438e9c5ccb3a58ce859b081e",
            "title": "Code Recommendation for Open Source Software Developers",
            "abstract": "Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers\u2019 interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. We introduce CODER, a novel graph-based CODE Recommendation framework for open source software developers, which accounts for the complex interactions among multiple parties within the system. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, to overcome the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087723977",
                    "name": "Yiqiao Jin"
                },
                {
                    "authorId": "51228791",
                    "name": "Yunsheng Bai"
                },
                {
                    "authorId": "2653121",
                    "name": "Yanqiao Zhu"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "af277778904463965c60626e22783d3e1740058b",
            "title": "Introducing Semantics into Speech Encoders",
            "abstract": "Recent studies find existing self-supervised speech encoders contain primarily acoustic rather than semantic information. As a result, pipelined supervised automatic speech recognition (ASR) to large language model (LLM) systems achieve state-of-the-art results on semantic spoken language tasks by utilizing rich semantic representations from the LLM. These systems come at the cost of labeled audio transcriptions, which is expensive and time-consuming to obtain. We propose a task-agnostic unsupervised way of incorporating semantic information from LLMs into self-supervised speech encoders without labeled audio transcriptions. By introducing semantics, we improve existing speech encoder spoken language understanding (SLU) performance by over 5% on intent classification (IC), with modest gains in named entity resolution (NER) and slot filling (SF), and spoken question answering (SQA) FF1 score by over 2%. Our approach, which uses no ASR data, achieves similar performance as methods trained on over 100 hours of labeled audio transcripts, demonstrating the feasibility of unsupervised semantic augmentations to existing speech encoders.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "46697020",
                    "name": "Derek Xu"
                },
                {
                    "authorId": "50549275",
                    "name": "Shuyan Dong"
                },
                {
                    "authorId": "20132361",
                    "name": "Changhan Wang"
                },
                {
                    "authorId": "2678842",
                    "name": "Suyoun Kim"
                },
                {
                    "authorId": "2146396528",
                    "name": "Zhaojiang Lin"
                },
                {
                    "authorId": "1519979046",
                    "name": "Akshat Shrivastava"
                },
                {
                    "authorId": "2530311",
                    "name": "Shang-Wen Li"
                },
                {
                    "authorId": "2132626257",
                    "name": "Liang-Hsuan Tseng"
                },
                {
                    "authorId": "14667698",
                    "name": "Alexei Baevski"
                },
                {
                    "authorId": "5857492",
                    "name": "Guan-Ting Lin"
                },
                {
                    "authorId": "1706104",
                    "name": "Hung-yi Lee"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        }
    ]
}