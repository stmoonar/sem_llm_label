{
    "authorId": "2283085",
    "papers": [
        {
            "paperId": "4b5073caf272209f1e39ea06a0313907a7976f08",
            "title": "ChARLES: Change-Aware Recovery of Latent Evolution Semantics in Relational Data",
            "abstract": "Data-driven decision-making is at the core of many modern applications, and understanding the data is critical in supporting trust in these decisions. However, data is dynamic and evolving, just like the real-world entities it represents. Thus, an important component of understanding data is analyzing and drawing insights from the changes it undergoes. Existing methods for exploring data change list differences exhaustively, which are not interpretable by humans and lack salient insights regarding change trends. For example, an explanation that semantically summarizes changes to highlight gender disparities in performance rewards is more human-consumable than a long list of employee salary changes. We demonstrate ChARLES, a system that derives semantic summaries of changes between two snapshots of an evolving database, in an effective, concise, and interpretable way. Our key observation is that, while datasets often evolve through point and other small-batch updates, rich data features can reveal latent semantics that can intuitively summarize the changes. Under the hood, ChARLES compares database versions, infers feasible transformations by fitting multiple regression lines over different data partitions to derive change summaries, and ranks them. ChARLES allows users to customize it to obtain their preferred explanation by navigating the accuracy-interpretability tradeoff, and offers a proof of concept for reasoning about data evolution over real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2323523490",
                    "name": "Shiyi He"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                },
                {
                    "authorId": "3071906",
                    "name": "Anna Fariha"
                }
            ]
        },
        {
            "paperId": "0949018c490ed3cdbe65ed3e396642b43c437c98",
            "title": "Scaling Package Queries to a Billion Tuples via Hierarchical Partitioning and Customized Optimization",
            "abstract": "A package query returns a package---a multiset of tuples---that maximizes or minimizes a linear objective function subject to linear constraints, thereby enabling in-database decision support. Prior work has established the equivalence of package queries to Integer Linear Programs (ILPs) and developed the SketchRefine algorithm for package query processing. While this algorithm was an important first step toward supporting prescriptive analytics scalably inside a relational database, it struggles when the data size grows beyond a few hundred million tuples or when the constraints become very tight. In this paper, we present Progressive Shading, a novel algorithm for processing package queries that can scale efficiently to billions of tuples and gracefully handle tight constraints. Progressive Shading solves a sequence of optimization problems over a hierarchy of relations, each resulting from an ever-finer partitioning of the original tuples into homogeneous groups until the original relation is obtained. This strategy avoids the premature discarding of high-quality tuples that can occur with SketchRefine. Our novel partitioning scheme, Dynamic Low Variance, can handle very large relations with multiple attributes and can dynamically adapt to both concentrated and spread-out sets of attribute values, provably outperforming traditional partitioning schemes such as kd-tree. We further optimize our system by replacing our off-the-shelf optimization software with customized ILP and LP solvers, called Dual Reducer and Parallel Dual Simplex respectively, that are highly accurate and orders of magnitude faster.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059902793",
                    "name": "Anh Mai"
                },
                {
                    "authorId": "2176695",
                    "name": "Matteo Brucato"
                },
                {
                    "authorId": "1698925",
                    "name": "A. Abouzeid"
                },
                {
                    "authorId": "2192778653",
                    "name": "Peter J. Haas"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                }
            ]
        },
        {
            "paperId": "dd55ea06ede00589c9e08a7bd1a40f6d1aff8724",
            "title": "Non-Invasive Fairness in Learning Through the Lens of Data Drift",
            "abstract": "Machine Learning models are widely employed to drive many modern data systems. While they are undeniably powerful tools, ML models often demonstrate imbalanced performance and unfair behaviors. The root of this problem often lies in the fact that different subpopulations commonly display divergent trends: as a learning algorithm tries to identify trends in the data, it naturally favors the trends of the majority groups, leading to a model that performs poorly and unfairly for minority populations. Our goal is to improve the fairness and trustworthiness of ML models by applying only non-invasive interventions, which don't alter the data or the learning algorithm. We use a simple but key insight: the divergence of trends between different popu-lations, and, consecutively, between a learned model and minority populations, is analogous to data drift, which indicates poor conformance between parts of the data and the trained model. We explore two strategies (model-splitting and reweighing) to resolve this drift, aiming to improve the overall conformance of models to the underlying data. Both our methods introduce novel ways to employ the recently-proposed data profiling primitive of Conformance Constraints. Our splitting approach is based on a simple data drift strategy: training separate models for different populations. Our DifFair algorithm enhances this simple strategy by employing conformance constraints, learned over the data partitions, to select the appropriate model to use for predictions on each serving tuple. However, the performance of such a multi-model strategy can degrade severely under poor representation of some groups in the data. We thus propose a single-model, reweighing strategy, ConFair, to overcome this limitation. ConFair employs conformance constraints in a novel way to derive weights for training data, which are then used to build a single model. Our experimental evaluation over 7 real-world datasets shows that both DifFair and ConFair improve the fairness of ML models. We demonstrate scenarios where DifFair has an edge, though ConFair has the greatest practical impact and outperforms other baselines. Moreover, as a model-agnostic technique, ConFairstays robust when used against different models than the ones on which the weights have been learned, which is not the case for other states of the art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119301078",
                    "name": "Ke Yang"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                }
            ]
        },
        {
            "paperId": "19adc8994240a0063895bd73f9f84abd04a6790e",
            "title": "Improved Approximation and Scalability for Fair Max-Min Diversification",
            "abstract": "Given an $n$-point metric space $(\\mathcal{X},d)$ where each point belongs to one of $m=O(1)$ different categories or groups and a set of integers $k_1, \\ldots, k_m$, the fair Max-Min diversification problem is to select $k_i$ points belonging to category $i\\in [m]$, such that the minimum pairwise distance between selected points is maximized. The problem was introduced by Moumoulidou et al. [ICDT 2021] and is motivated by the need to down-sample large data sets in various applications so that the derived sample achieves a balance over diversity, i.e., the minimum distance between a pair of selected points, and fairness, i.e., ensuring enough points of each category are included. We prove the following results: 1. We first consider general metric spaces. We present a randomized polynomial time algorithm that returns a factor $2$-approximation to the diversity but only satisfies the fairness constraints in expectation. Building upon this result, we present a $6$-approximation that is guaranteed to satisfy the fairness constraints up to a factor $1-\\epsilon$ for any constant $\\epsilon$. We also present a linear time algorithm returning an $m+1$ approximation with exact fairness. The best previous result was a $3m-1$ approximation. 2. We then focus on Euclidean metrics. We first show that the problem can be solved exactly in one dimension. For constant dimensions, categories and any constant $\\epsilon>0$, we present a $1+\\epsilon$ approximation algorithm that runs in $O(nk) + 2^{O(k)}$ time where $k=k_1+\\ldots+k_m$. We can improve the running time to $O(nk)+ poly(k)$ at the expense of only picking $(1-\\epsilon) k_i$ points from category $i\\in [m]$. Finally, we present algorithms suitable to processing massive data sets including single-pass data stream algorithms and composable coresets for the distributed processing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40897986",
                    "name": "Raghavendra Addanki"
                },
                {
                    "authorId": "144078750",
                    "name": "A. Mcgregor"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                },
                {
                    "authorId": "1999182528",
                    "name": "Zafeiria Moumoulidou"
                }
            ]
        },
        {
            "paperId": "478a1cae14e62f57a47ce8424c1b664d69f6aa27",
            "title": "DataPrism: Exposing Disconnect between Data and Systems",
            "abstract": "As data is a central component of many modern systems, the cause of a system malfunction may reside in the data, and, specifically, particular properties of data. E.g., a health-monitoring system that is designed under the assumption that weight is reported in lbs will malfunction when encountering weight reported in kilograms. Like software debugging, which aims to find bugs in the source code or runtime conditions, our goal is to debug data to identify potential sources of disconnect between the assumptions about some data and systems that operate on that data. We propose DataPrism, a framework to identify data properties (profiles) that are the root causes of performance degradation or failure of a data-driven system. Such identification is necessary to repair data and resolve the disconnect between data and systems. Our technique is based on causal reasoning through interventions: when a system malfunctions for a dataset, DataPrism alters the data profiles and observes changes in the system's behavior due to the alteration. Unlike statistical observational analysis that reports mere correlations, DataPrism reports causally verified root causes -- in terms of data profiles -- of the system malfunction. We empirically evaluate DataPrism on seven real-world and several synthetic data-driven systems that fail on certain datasets due to a diverse set of reasons. In all cases, DataPrism identifies the root causes precisely while requiring orders of magnitude fewer interventions than prior techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2663974",
                    "name": "Sainyam Galhotra"
                },
                {
                    "authorId": "144162611",
                    "name": "J. Freire"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                },
                {
                    "authorId": "145860176",
                    "name": "D. Srivastava"
                }
            ]
        },
        {
            "paperId": "ca55492c38d2539a09e2b24a7720f108c54fca50",
            "title": "In-Database Decision Support: Opportunities and Challenges",
            "abstract": "Decision makers in a broad range of domains, such as finance, transportation, manufacturing, and healthcare, often need to derive optimal decisions given a set of constraints and objectives . Traditional solutions to such constrained optimization problems are typically application-specific, complex, and do not generalize. Further, the usual workflow requires slow, cumbersome, and error-prone data movement between a database and predictive-modeling and optimization packages. All of these problems are exacerbated by the unprecedented size of modern data-intensive optimization problems. The emerging research area of in-database prescriptive analytics aims to provide seamless domain-independent, declarative, and scalable approaches powered by the system where the data typically resides: the database. Integrating optimization with database technology opens up prescriptive analytics to a much broader community, amplifying its benefits. In the context of our prior and ongoing work in this area, we discuss some strategies for addressing key challenges related to usability, scalability, data uncertainty, dynamic environments with changing data and models, and the need to support decision-making agents. We indicate how deep integration between the DBMS, predictive models, and optimization software creates opportunities for rich prescriptive-query functionality with good scalability and performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1698925",
                    "name": "A. Abouzeid"
                },
                {
                    "authorId": "37810307",
                    "name": "P. Haas"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                }
            ]
        },
        {
            "paperId": "fda47a974d2d6d9f56f612b50e4667e0316594a9",
            "title": "Diversity and Inclusion Activities in Database Conferences",
            "abstract": "Diversity and Inclusion (D&I) are core to fostering innovative thinking. Existing theories demonstrate that to facilitate inclusion, multiple types of exclusionary dynamics, such as self-segregation, communication apprehension, and stereotyping and stigmatizing, must be overcome [11]. A diverse group of people tends to surface different perspectives, which help to understand and address D&I. Fostering D&I in research communities must address issues related to inclusive interpersonal and small group dynamics, rules and codes of conduct, increasing diversity in under-represented groups and disciplines, and organizing D&I events, and longterm efforts to champion change [15].",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1710637",
                    "name": "Yael Amsterdamer"
                },
                {
                    "authorId": "1730344",
                    "name": "S. Bhowmick"
                },
                {
                    "authorId": "1699192",
                    "name": "A. Bonifati"
                },
                {
                    "authorId": "2180077845",
                    "name": "Philippe"
                },
                {
                    "authorId": "2180077328",
                    "name": "Bonnet"
                },
                {
                    "authorId": "1404555727",
                    "name": "Renata Borovica-Gajic"
                },
                {
                    "authorId": "1726425",
                    "name": "B. Catania"
                },
                {
                    "authorId": "1684646",
                    "name": "T. Cerquitelli"
                },
                {
                    "authorId": "1694792",
                    "name": "S. Chiusano"
                },
                {
                    "authorId": "1728643",
                    "name": "Panos K. Chrysanthis"
                },
                {
                    "authorId": "1692732",
                    "name": "C. Curino"
                },
                {
                    "authorId": "145025853",
                    "name": "J. Darmont"
                },
                {
                    "authorId": "1709353",
                    "name": "A. El Abbadi"
                },
                {
                    "authorId": "2327080",
                    "name": "Avrilia Floratou"
                },
                {
                    "authorId": "2178387374",
                    "name": "Juliana Freire"
                },
                {
                    "authorId": "2153832",
                    "name": "Alekh Jindal"
                },
                {
                    "authorId": "1685532",
                    "name": "V. Kalogeraki"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "2155077042",
                    "name": "Arun Kumar"
                },
                {
                    "authorId": "2178928944",
                    "name": "Sujaya"
                },
                {
                    "authorId": "2180077715",
                    "name": "Maiyya"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                },
                {
                    "authorId": "37168010",
                    "name": "Madhulika Mohanty"
                },
                {
                    "authorId": "1683688",
                    "name": "Felix Naumann"
                },
                {
                    "authorId": "50404914",
                    "name": "N. Noack"
                },
                {
                    "authorId": "2083390868",
                    "name": "Fatma"
                },
                {
                    "authorId": "2097987002",
                    "name": "\u00d6zcan"
                },
                {
                    "authorId": "3139922",
                    "name": "L. Peterfreund"
                },
                {
                    "authorId": "145492472",
                    "name": "W. Rahayu"
                },
                {
                    "authorId": "2131764025",
                    "name": "Wang-Chiew Tan"
                },
                {
                    "authorId": "2098950927",
                    "name": "P\u0131nar"
                },
                {
                    "authorId": "2180077114",
                    "name": "T\u00f6z\u00fcn"
                },
                {
                    "authorId": "2397000",
                    "name": "N. Yadwadkar"
                },
                {
                    "authorId": "2117848168",
                    "name": "Meihui Zhang"
                }
            ]
        },
        {
            "paperId": "4916685fa0cd17204380b1554d232af214cf4bd1",
            "title": "Conformance Constraint Discovery: Measuring Trust in Data-Driven Systems",
            "abstract": "The reliability of inferences made by data-driven systems hinges on the data's continued conformance to the systems' initial settings and assumptions. When serving data (on which we want to apply inference) deviates from the profile of the initial training data, the outcome of inference becomes unreliable. We introduce conformance constraints, a new data profiling primitive tailored towards quantifying the degree of non-conformance, which can effectively characterize if inference over that tuple is untrustworthy. Conformance constraints are constraints over certain arithmetic expressions (called projections) involving the numerical attributes of a dataset, which existing data profiling primitives such as functional dependencies and denial constraints cannot model. Our key finding is that projections that incur low variance on a dataset construct effective conformance constraints. This principle yields the surprising result that low-variance components of a principal component analysis, which are usually discarded for dimensionality reduction, generate stronger conformance constraints than the high-variance components. Based on this result, we provide a highly scalable and efficient technique--linear in data size and cubic in the number of attributes--for discovering conformance constraints for a dataset. To measure the degree of a tuple's non-conformance with respect to a dataset, we propose a quantitative semantics that captures how much a tuple violates the conformance constraints of that dataset. We demonstrate the value of conformance constraints on two applications: trusted machine learning and data drift. We empirically show that conformance constraints offer mechanisms to (1) reliably detect tuples on which the inference of a machine-learned model should not be trusted, and (2) quantify data drift more accurately than the state of the art.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3071906",
                    "name": "Anna Fariha"
                },
                {
                    "authorId": "145219494",
                    "name": "A. Tiwari"
                },
                {
                    "authorId": "93750354",
                    "name": "Arjun Radhakrishna"
                },
                {
                    "authorId": "2108314",
                    "name": "Sumit Gulwani"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                }
            ]
        },
        {
            "paperId": "53546bba4e31a56c663d6c6499229c4ea863e3de",
            "title": "DataExposer: Exposing Disconnect between Data and Systems",
            "abstract": "As data is a central component of many modern systems, the cause of a system malfunction may reside in the data, and, specifically, particular properties of the data. For example, a health-monitoring system that is designed under the assumption that weight is reported in imperial units (lbs) will malfunction when encountering weight reported in metric units (kilograms). Similar to software debugging, which aims to find bugs in the mechanism (source code or runtime conditions), our goal is to debug the data to identify potential sources of disconnect between the assumptions about the data and the systems that operate on that data. Specifically, we seek which properties of the data cause a data-driven system to malfunction. We propose DataExposer, a framework to identify data properties, called profiles, that are the root causes of performance degradation or failure of a system that operates on the data. Such identification is necessary to repair the system and resolve the disconnect between data and system. Our technique is based on causal reasoning through interventions: when a system malfunctions for a dataset, DataExposer alters the data profiles and observes changes in the system's behavior due to the alteration. Unlike statistical observational analysis that reports mere correlations, DataExposer reports causally verified root causes, in terms of data profiles, of the system malfunction. We empirically evaluate DataExposer on three real-world and several synthetic data-driven systems that fail on datasets due to a diverse set of reasons. In all cases, DataExposer identifies the root causes precisely while requiring orders of magnitude fewer interventions than prior techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2663974",
                    "name": "Sainyam Galhotra"
                },
                {
                    "authorId": "3071906",
                    "name": "Anna Fariha"
                },
                {
                    "authorId": "144162611",
                    "name": "J. Freire"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                },
                {
                    "authorId": "145860176",
                    "name": "D. Srivastava"
                }
            ]
        },
        {
            "paperId": "875ae40d8b42733d4b22764fc3591b410a326596",
            "title": "CoCo: Interactive Exploration of Conformance Constraints for Data Understanding and Data Cleaning",
            "abstract": "Data profiling refers to the task of extracting technical metadata or profiles and has numerous applications such as data understanding, validation, integration, and cleaning. While a number of data profiling primitives exist in the literature, most of them are limited to categorical attributes. A few techniques consider numerical attributes; but, they either focus on simple relationships involving a pair of attributes (e.g., correlations) or convert the continuous semantics of numerical attributes to a discrete semantics, which results in information loss. To capture more complex relationships involving the numerical attributes, we developed a new data-profiling primitive called conformance constraints, which can model linear arithmetic relationships involving multiple numerical attributes. We present CoCo, a system that allows interactive discovery and exploration of Conformance Constraints for understanding trends involving the numerical attributes of a dataset, with a particular focus on the application of data cleaning. Through a simple interface, CoCo enables the user to guide conformance constraint discovery according to their preferences. The user can examine to what extent a new, possibly dirty, dataset satisfies or violates the discovered conformance constraints. Further, CoCo provides useful suggestions for cleaning dirty data tuples, where the user can interactively alter cell values, and verify by checking change in conformance constraint violation due to the alteration. We demonstrate how CoCo can help in understanding trends in the data and assist the users in interactive data cleaning, using conformance constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3071906",
                    "name": "Anna Fariha"
                },
                {
                    "authorId": "145219494",
                    "name": "A. Tiwari"
                },
                {
                    "authorId": "2283085",
                    "name": "A. Meliou"
                },
                {
                    "authorId": "93750354",
                    "name": "Arjun Radhakrishna"
                },
                {
                    "authorId": "2108314",
                    "name": "Sumit Gulwani"
                }
            ]
        }
    ]
}