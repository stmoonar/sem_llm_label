{
    "authorId": "1860892",
    "papers": [
        {
            "paperId": "0a56515adb8489d4693f489d4a903410525a9632",
            "title": "KGTrust: Evaluating Trustworthiness of SIoT via Knowledge Enhanced Graph Neural Networks",
            "abstract": "Social Internet of Things (SIoT), a promising and emerging paradigm that injects the notion of social networking into smart objects (i.e., things), paving the way for the next generation of Internet of Things. However, due to the risks and uncertainty, a crucial and urgent problem to be settled is establishing reliable relationships within SIoT, that is, trust evaluation. Graph neural networks for trust evaluation typically adopt a straightforward way such as one-hot or node2vec to comprehend node characteristics, which ignores the valuable semantic knowledge attached to nodes. Moreover, the underlying structure of SIoT is usually complex, including both the heterogeneous graph structure and pairwise trust relationships, which renders hard to preserve the properties of SIoT trust during information propagation. To address these aforementioned problems, we propose a novel knowledge-enhanced graph neural network (KGTrust) for better trust evaluation in SIoT. Specifically, we first extract useful knowledge from users\u2019 comment behaviors and external structured triples related to object descriptions, in order to gain a deeper insight into the semantics of users and objects. Furthermore, we introduce a discriminative convolutional layer that utilizes heterogeneous graph structure, node semantics, and augmented trust relationships to learn node embeddings from the perspective of a user as a trustor or a trustee, effectively capturing multi-aspect properties of SIoT trust during information propagation. Finally, a trust prediction layer is developed to estimate the trust relationships between pairwise nodes. Extensive experiments on three public datasets illustrate the superior performance of KGTrust over state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12073135",
                    "name": "Zhizhi Yu"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2106771001",
                    "name": "Cuiying Huo"
                },
                {
                    "authorId": "2163669096",
                    "name": "Zhiqiang Wang"
                },
                {
                    "authorId": "1500522513",
                    "name": "Xiulong Liu"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "153171583",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                }
            ]
        },
        {
            "paperId": "0c7ce5898dab92da540457b754254d72b8592fc2",
            "title": "Parameter-efficient Tuning of Large-scale Multimodal Foundation Model",
            "abstract": "Driven by the progress of large-scale pre-training, parameter-efficient transfer learning has gained immense popularity across different subfields of Artificial Intelligence. The core is to adapt the model to downstream tasks with only a small set of parameters. Recently, researchers have leveraged such proven techniques in multimodal tasks and achieve promising results. However, two critical issues remain unresolved: how to further reduce the complexity with lightweight design and how to boost alignment between modalities under extremely low parameters. In this paper, we propose A graceful prompt framework for cross-modal transfer (Aurora) to overcome these challenges. Considering the redundancy in existing architectures, we first utilize the mode approximation to generate 0.1M trainable parameters to implement the multimodal prompt tuning, which explores the low intrinsic dimension with only 0.04% parameters of the pre-trained model. Then, for better modality alignment, we propose the Informative Context Enhancement and Gated Query Transformation module under extremely few parameters scenes. A thorough evaluation on six cross-modal benchmarks shows that it not only outperforms the state-of-the-art but even outperforms the full fine-tuning approach. Our code is available at: https://github.com/WillDreamer/Aurora.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109591599",
                    "name": "Haixin Wang"
                },
                {
                    "authorId": "2150441370",
                    "name": "Xinlong Yang"
                },
                {
                    "authorId": "2364376",
                    "name": "Jianlong Chang"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2262309",
                    "name": "Jinan Sun"
                },
                {
                    "authorId": "2184249162",
                    "name": "Shikun Zhang"
                },
                {
                    "authorId": "2168258085",
                    "name": "Xiao Luo"
                },
                {
                    "authorId": "2149898830",
                    "name": "Qi Tian"
                }
            ]
        },
        {
            "paperId": "4330568c6af6c3b3b519b7e05705c82845a49bd1",
            "title": "Learning Distinct Relationship in Package Recommendation With Graph Attention Networks",
            "abstract": "Recommendation systems have been widely developed and extensively used in various websites and platforms to promote products or services to interested users. However, in quite a few sale scenarios, the platform has the necessity to display users a series of items, which is called package recommendation. There is very little research in this area. This article develops a novel and realistic package recommendation system named package graph attention network (PGAT) based on graph neural network. PGAT integrates users, items, and packages to build a unified heterogeneous graph and treat them as a whole. PGAT incorporates an attention mechanism in the first-order neighborhood aggregation operation, which can differentiate the weight of different neighbor nodes to the center node. By performing graph attention and graph convolution operations on the tripartite graph, PGAT can learn node embeddings more expressively and address the problem of data sparse to a large extent. Extensive experiment results on two real-world datasets validate the outstanding performance of PGAT, which is superior to the state-of-the-art baselines by 0.77%\u201310.12%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154002448",
                    "name": "Wei Lu"
                },
                {
                    "authorId": "2089088719",
                    "name": "Nan Jiang"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "7315005",
                    "name": "Honglong Chen"
                },
                {
                    "authorId": "2154487593",
                    "name": "Ximeng Liu"
                }
            ]
        },
        {
            "paperId": "47d819f79d44d9cb5145b92e438f7b2a773451e8",
            "title": "A Survey on Fairness-aware Recommender Systems",
            "abstract": "As information filtering services, recommender systems have extremely enriched our daily life by providing personalized suggestions and facilitating people in decision-making, which makes them vital and indispensable to human society in the information era. However, as people become more dependent on them, recent studies show that recommender systems potentially own unintentional impacts on society and individuals because of their unfairness (e.g., gender discrimination in job recommendations). To develop trustworthy services, it is crucial to devise fairness-aware recommender systems that can mitigate these bias issues. In this survey, we summarise existing methodologies and practices of fairness in recommender systems. Firstly, we present concepts of fairness in different recommendation scenarios, comprehensively categorize current advances, and introduce typical methods to promote fairness in different stages of recommender systems. Next, after introducing datasets and evaluation metrics applied to assess the fairness of recommender systems, we will delve into the significant influence that fairness-aware recommender systems exert on real-world industrial applications. Subsequently, we highlight the connection between fairness and other principles of trustworthy recommender systems, aiming to consider trustworthiness principles holistically while advocating for fairness. Finally, we summarize this review, spotlighting promising opportunities in comprehending concepts, frameworks, the balance between accuracy and fairness, and the ties with trustworthiness, with the ultimate goal of fostering the development of fairness-aware recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "82527705",
                    "name": "Luzhi Wang"
                },
                {
                    "authorId": "2156713249",
                    "name": "He Zhang"
                },
                {
                    "authorId": "26956796",
                    "name": "Yizhen Zheng"
                },
                {
                    "authorId": "2218582225",
                    "name": "Weiping Ding"
                },
                {
                    "authorId": "2218637525",
                    "name": "Feng Xia"
                },
                {
                    "authorId": "2153326034",
                    "name": "Shirui Pan"
                }
            ]
        },
        {
            "paperId": "4885a3f1bb3aceea208df1b92af5025ea72158df",
            "title": "Contrastive Graph Similarity Networks",
            "abstract": "Graph similarity learning is a significant and fundamental issue in the theory and analysis of graphs, which has been applied in a variety of fields, including object tracking, recommender systems, similarity search, and so on. Recent methods for graph similarity learning that utilize deep learning typically share two deficiencies: (1) they leverage graph neural networks as backbones for learning graph representations but have not well captured the complex information inside data, and (2) they employ a cross-graph attention mechanism for graph similarity learning, which is computationally expensive. Taking these limitations into consideration, a method for graph similarity learning is devised in this study, namely, Contrastive Graph Similarity Network (CGSim). To enhance graph similarity learning, CGSim makes use of the complementary information of two input graphs and captures pairwise relations in a contrastive learning framework. By developing a dual contrastive learning module with a node-graph matching and a graph-graph matching mechanism, our method significantly reduces the quadratic time complexity for cross-graph interaction modeling to linear time complexity. Jointly learning in an end-to-end framework, the graph representation embedding module and the well-designed contrastive learning module can be beneficial to one another. A comprehensive series of experiments indicate that CGSim outperforms state-of-the-art baselines on six datasets and significantly reduces the computational cost, which demonstrates our CGSim model\u2019s superiority over other baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "82527705",
                    "name": "Luzhi Wang"
                },
                {
                    "authorId": "26956796",
                    "name": "Yizhen Zheng"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2203372264",
                    "name": "Fuyi Li"
                },
                {
                    "authorId": "2786889",
                    "name": "Yongliang Qiao"
                },
                {
                    "authorId": "2153326034",
                    "name": "Shirui Pan"
                }
            ]
        },
        {
            "paperId": "54d29a4cf71eabb6b17fbeca46e19084bc46ef55",
            "title": "Contrastive Learning Meets Homophily: Two Birds with One Stone",
            "abstract": "Graph Contrastive Learning (GCL) has recently enjoyed great success as an efficient self-supervised representation learning approach. However, the existing methods have focused on designing of contrastive modes and used data augmentation with a rigid and inefficient one-to-one sampling strategy. We adopted node neighborhoods to extend positive samplings and made avoided resorting to data augmentation to create different views. We also considered the homophily problem in Graph Neural Networks (GNNs) between the inter-class node pairs. The key novelty of our method hinged upon analyzing this GNNs problem and integrating the GCL sampling strategy with homophily discrimination, where we solved these two significant problems using one approach. We introduced a new parameterized neighbor sampling component to replace the conventional sub-optimal samplings. By keeping and updating the neighbor sets, both the positive sampling of GCL and the message passing of GNNs can be optimized. Moreover, we theoretically proved that the new method provided a lower bound of mutual information for unsupervised semantic learning, and it can also keep the lower bound with downstream tasks. In essence, our method is a new self-supervised approach, which we refer to as group discrimination, and it can make the downstream fine-tuning efficient. Our extensive empirical results demonstrate that the new method can significantly outperform the existing GCL methods because the former can solve the homophily problem in a self-supervised",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2230259009",
                    "name": "Jitao Zhao"
                },
                {
                    "authorId": "47630357",
                    "name": "Ruixing Guo"
                },
                {
                    "authorId": "2152084654",
                    "name": "Zhiyong Feng"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2108728683",
                    "name": "Yuxiao Huang"
                },
                {
                    "authorId": "2188012894",
                    "name": "Zhen Wang"
                },
                {
                    "authorId": "49039416",
                    "name": "Weixiong Zhang"
                }
            ]
        },
        {
            "paperId": "686d6ca32a2797c24f327a9923be1fd4bfab20f9",
            "title": "Clustering-based improved adaptive synthetic minority oversampling technique for imbalanced data classification",
            "abstract": "Synthetic Minority Oversampling Technique (SMOTE) and some extensions based on it are popularly used to balance imbalanced data. In this study, we concentrate on solving overfitting of the classification model caused by choosing instances to oversample that increase the occurrence of overlaps with the majority class. Our method called Clustering-based Improved Adaptive Synthetic Minority Oversampling Technique (CI-ASMOTE1) decomposes minority instances into sub-clusters according to their connectivity in the feature space and then selects minority sub-clusters which are relatively close to the decision boundary as the candidate regions to oversample. After application of CI-ASMOTE1, new minority instances are only synthesized within each connected region of the selected sub-clusters. Considering the diversity of the synthetic instances in each selected sub-cluster, CI-ASMOTE2 is put forward to extend CI-ASMOTE1 by keeping all features of those instances in the feature space as different as possible. The experimental evaluation shows that CI-ASMOTE1 and CI-ASMOTE2 improve SMOTE and its extensions, especially in the occurrence of overlaps between the minority instances and the majority instances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "50322055",
                    "name": "Dehong Xie"
                },
                {
                    "authorId": "2146082564",
                    "name": "Di Liu"
                },
                {
                    "authorId": "2217102735",
                    "name": "Murong Gong"
                }
            ]
        },
        {
            "paperId": "a96762ae0ac80206f33657d2941beae41c09b16b",
            "title": "MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems",
            "abstract": "Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models\u2019 performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics\u2019 unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3022427",
                    "name": "Sarik Ghazarian"
                },
                {
                    "authorId": "2127328167",
                    "name": "Behnam Hedayatnia"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "30986714",
                    "name": "Sijia Liu"
                },
                {
                    "authorId": "2239906544",
                    "name": "Violet Peng"
                },
                {
                    "authorId": "2240100316",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        },
        {
            "paperId": "c3ed333a37a6d9a0fcf1dad3106a114f66a45b99",
            "title": "WebCPM: Interactive Web Search for Chinese Long-form Question Answering",
            "abstract": "Long-form question answering (LFQA) aims at answering complex, open-ended questions with detailed, paragraph-length responses. The de facto paradigm of LFQA necessitates two procedures: information retrieval, which searches for relevant supporting facts, and information synthesis, which integrates these facts into a coherent answer. In this paper, we introduce WebCPM, the first Chinese LFQA dataset. One unique feature of WebCPM is that its information retrieval is based on interactive web search, which engages with a search engine in real time. Following WebGPT, we develop a web search interface. We recruit annotators to search for relevant information using our interface and then answer questions. Meanwhile, the web search behaviors of our annotators would be recorded. In total, we collect 5,500 high-quality question-answer pairs, together with 15,372 supporting facts and 125,954 web search actions. We fine-tune pre-trained language models to imitate human behaviors for web search and to generate answers based on the collected facts. Our LFQA pipeline, built on these fine-tuned models, generates answers that are no worse than human-written ones in 32.5% and 47.5% of the cases on our dataset and DuReader, respectively. The interface, dataset, and codes are publicly available at https://github.com/thunlp/WebCPM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "2113441349",
                    "name": "Zihan Cai"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2214613855",
                    "name": "Lan Yan"
                },
                {
                    "authorId": "2163374235",
                    "name": "Shi Liang"
                },
                {
                    "authorId": "2214586034",
                    "name": "Kunlun Zhu"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "3360722",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "51466208",
                    "name": "Fanchao Qi"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                },
                {
                    "authorId": "49640256",
                    "name": "Jie Zhou"
                }
            ]
        },
        {
            "paperId": "e65f6420f0876d4681dc11a0163e12a8a236dc5a",
            "title": "Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning",
            "abstract": "Dialogue state tracking (DST) is an important step in dialogue management to keep track of users' beliefs. Existing works fine-tune all language model (LM) parameters to tackle the DST task, which requires significant data and computing resources for training and hosting. The cost grows exponentially in the real-world deployment where dozens of fine-tuned LM are used for different domains and tasks. To reduce parameter size and better utilize cross-task shared information, we propose to use soft prompt token embeddings to learn task properties. Without tuning LM parameters, our method drastically reduces the number of parameters needed to less than 0.5% of prior works while achieves better low-resource DST performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144592155",
                    "name": "Mingyu Derek Ma"
                },
                {
                    "authorId": "38705864",
                    "name": "Jiun-Yu Kao"
                },
                {
                    "authorId": "3092863",
                    "name": "Shuyang Gao"
                },
                {
                    "authorId": "32174480",
                    "name": "Arpit Gupta"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2878984",
                    "name": "Tagyoung Chung"
                },
                {
                    "authorId": "3157053",
                    "name": "Nanyun Peng"
                }
            ]
        }
    ]
}