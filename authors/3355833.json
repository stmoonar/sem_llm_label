{
    "authorId": "3355833",
    "papers": [
        {
            "paperId": "0ac64a7a244687bb8d1b0d114ba80bbc418a2b03",
            "title": "A 50Gb/s CMOS Optical Receiver With Si-Photonics PD for High-Speed Low-Latency Chiplet I/O",
            "abstract": "This paper presents a 50-Gb/s optical receiver (ORX) chipset, consisting of a transimpedance amplifier (TIA) and a clock and data recovery (CDR) circuit in a 45-nm silicon-on-insulator CMOS. The proposed inverter-based TIA employs hybrid shunt-series peaking inductors to extend the bandwidth (BW). A baud-rate CDR is proposed to reduce the sampling phases and clocking power by half. To optimise the ORX for in- package integration, a compact-size digital loop is adopted in each channel, and the clock is recovered by phase interpolation from a shared reference. A complete optical-to-electrical (OE) link is built by integrating the proposed ORX with a high-speed Silicon Photonics (SiP) photodetector (PD). Measurements show that the proposed TIA has a transimpedance gain of 53 dB<inline-formula> <tex-math notation=\"LaTeX\">$\\Omega $ </tex-math></inline-formula> and a BW of 27 GHz. By integrating it with the SiP PD, the OE front-end (PD+TIA) achieves an input sensitivity of \u22127.7 dBm at 50 Gb/s and BER<inline-formula> <tex-math notation=\"LaTeX\">$ < 10^{-12}$ </tex-math></inline-formula>. It features a power efficiency of 1.61 pJ/bit at a data rate of 64 Gb/s. The complete 50 Gb/s ORX achieves data recovery at a quarter rate of 12.5 Gb/s with an output jitter of 1.6 psrms, and has a 3.125 GHz clock with phase noise of \u2212115.22 dBc/Hz at an offset frequency of 1 MHz.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111638449",
                    "name": "Sikai Chen"
                },
                {
                    "authorId": "145760693",
                    "name": "Mingyang You"
                },
                {
                    "authorId": "2244133120",
                    "name": "Yunqi Yang"
                },
                {
                    "authorId": "2244142370",
                    "name": "Ye Jin"
                },
                {
                    "authorId": "2193143144",
                    "name": "Ziyi Lin"
                },
                {
                    "authorId": "2206283302",
                    "name": "Yihong Li"
                },
                {
                    "authorId": "2151529075",
                    "name": "Leliang Li"
                },
                {
                    "authorId": "30852596",
                    "name": "Guike Li"
                },
                {
                    "authorId": "2244145134",
                    "name": "Yujun Xie"
                },
                {
                    "authorId": "2156119771",
                    "name": "Zhao Zhang"
                },
                {
                    "authorId": "2244251406",
                    "name": "Binhao Wang"
                },
                {
                    "authorId": "2244066285",
                    "name": "Ningfeng Tang"
                },
                {
                    "authorId": "2244136436",
                    "name": "Faju Liu"
                },
                {
                    "authorId": "2169703829",
                    "name": "Zheyu Fang"
                },
                {
                    "authorId": "37536536",
                    "name": "Jian Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "2115839260",
                    "name": "Yong Chen"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "2244031112",
                    "name": "Ninghua Zhu"
                },
                {
                    "authorId": "2150654510",
                    "name": "Ming Li"
                },
                {
                    "authorId": "40327975",
                    "name": "Nan Qi"
                }
            ]
        },
        {
            "paperId": "205b16cd4e5acd6f9681e353e9be228503be7331",
            "title": "An 8-T Processing-in-Memory SRAM Cell-Based Pixel-Parallel Array Processor for Vision Chips",
            "abstract": "Vision chip is a high-speed image processing device, featuring a massively-parallel pixel-level processing element (PE) array to boost pixel processing speed. However, the collocated processing unit and fine-grained data memory unit inside each PE impose a huge requirement on memory access bandwidth as well as big area and energy consumption. To overcome this bottleneck, this paper proposes a full custom 8T SRAM-based Processing-in-Memory (PIM) architecture together with a multiplexer-based arithmetic-logic unit (mux-based ALU) to realize pixel-parallel array processor for energy-efficient vision chips. The proposed PIM architecture is constructed by embroidering each dual-port 8T SRAM cell with mux-based ALU, so as to form a PIM PE array. Each PIM PE holds a 130-bit 8T SRAM cell block embedding in-memory logic functions, of which 128-bit 8T SRAM cells serve as the PE memory, and 2-bit 8T SRAM cells act as a buffer register in the PE. A full custom physical layout of a $128\\times128$ prototyping PIM PE array is designed and evaluated using a 65 nm CMOS technology. The simulation results demonstrate that our proposed PIM PE architecture could operate under a 200 MHz clock frequency with a 1.0 V power supply, and reach a high energy efficiency of 512 GOPS/W and a high area efficiency of 29 GOPS/mm2.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214406369",
                    "name": "Leyi Chen"
                },
                {
                    "authorId": "1491631816",
                    "name": "Cong Shi"
                },
                {
                    "authorId": "2109931604",
                    "name": "Junxian He"
                },
                {
                    "authorId": "2215230968",
                    "name": "Jianyi Yu"
                },
                {
                    "authorId": "2155569060",
                    "name": "Haibing Wang"
                },
                {
                    "authorId": "2199913811",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "2114270879",
                    "name": "Min Tian"
                }
            ]
        },
        {
            "paperId": "2a00a2f5c492538ed2a6686c6ffb28871e153eb2",
            "title": "Live Demonstration: Face Recognition at The Edge Using Fast On-Chip Deep Learning Neuromorphic Chip",
            "abstract": "Spiking neural networks (SNNs) and neuromorphic systems have attracted ever increasing interests recently, due to their high computational and energy efficiencies originated from closely imitating the functional mechanism of cerebral cortex, which adopts sparse spikes for information processing. In this work, we present a low-cost real-time face recognition system for potential edge-side intelligent applications. This system is mainly built upon our prior reported MorphBungee neuromorphic chip, which is capable of fast on-chip deep learning for fully-connected (FC) SNN of up to 4 layers, 1K spiking neurons and 256K synapses, under a low power consumption of about 100 mW. Our face recognition system achieves 20-fps and 30-fps image frame rates for real-life human face learning and inference, respectively, and obtains a high face recognition accuracy of 100% among 6 persons. It demonstrates that our face recognition system with the neuromorphic chip is suitable for resource-limited real-time intelligent edge applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114198059",
                    "name": "Zhengqing Zhong"
                },
                {
                    "authorId": "1898436662",
                    "name": "Tengxiao Wang"
                },
                {
                    "authorId": "2155569060",
                    "name": "Haibing Wang"
                },
                {
                    "authorId": "2221268686",
                    "name": "Zhihua Zhou"
                },
                {
                    "authorId": "2109931604",
                    "name": "Junxian He"
                },
                {
                    "authorId": "2140487440",
                    "name": "Fang Tang"
                },
                {
                    "authorId": "1951640",
                    "name": "Xichuan Zhou"
                },
                {
                    "authorId": "150311591",
                    "name": "Shuangming Yu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "2114270879",
                    "name": "Min Tian"
                },
                {
                    "authorId": "2086996153",
                    "name": "Cong Shi"
                }
            ]
        },
        {
            "paperId": "51164e09d44961af4db73b3809c8009dbba0c9bb",
            "title": "Hierarchical Parallel Vision Processor for High-Speed Ship Detection",
            "abstract": "Ship detection is essential in ship rescue and marine traffic safety. However, high-speed real-time ship detection has become problematic in practical applications. In this brief, we propose a high-performance ship detection system utilizing the co-design of algorithm and hardware. First, the proposed Coarse-to-Fine Classification and Segmentation algorithm contains a two-stage convolutional neural network. It quickly locates the Region of Interest (RoI) and then accurately locates the ship\u2019s position in the RoI without low-parallelism non-maximum suppression (NMS) post-processing. Second, we proposed a Hierarchical Parallel Vision Processor, including a pixel-parallel processing unit, a patch-parallel processing unit, and a global micro-processing unit, ensuring high-speed processing with different parallelism. Finally, we designed a high-speed real-time ship detection system. The experimental results show that our ship detection system based on the frequency of 100Mhz on Arria 10 FPGA can achieve a speed of 4778FPS, which is beneficial in practical applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110682031",
                    "name": "Mengmeng Xu"
                },
                {
                    "authorId": "47294212",
                    "name": "Zhongxing Zhang"
                },
                {
                    "authorId": "2115563614",
                    "name": "Honglong Li"
                },
                {
                    "authorId": "2074294973",
                    "name": "Qian Luo"
                },
                {
                    "authorId": "2235468",
                    "name": "Runjiang Dou"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "37536536",
                    "name": "Jian Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                }
            ]
        },
        {
            "paperId": "6cab0cc07cea85fc40fb442b141c32aa06014db3",
            "title": "A 24.3 \u03bcJ/Image SNN Accelerator for DVS-Gesture With WS-LOS Dataflow and Sparse Methods",
            "abstract": "Spiking Neural Networks (SNNs), inspired by the biological brain, attract extensive attention for their simplified computation and the ability to process spatiotemporal data. With the development of retina-like sensors, there is a growing demand for edge SNN accelerators. The structural dataflow and great spiking sparsity of SNNs provide much exploration space for energy-efficient accelerators. However, current SNN accelerators did not co-optimize the two features together. This brief proposes an energy-efficient edge accelerator architecture to support typical spiking neural networks. We propose a Weight Stationary-Local Output Stationary (WS-LOS) dataflow for SNNs and maximize the data reuse with a hierarchical memory structure. Three methods, including address skipping (AS), dynamic workload scheduling (DWS), and reconfigurable adder tree (RAT), are proposed to exploit the spiking sparsity. The accelerator is synthesized under 65nm technology, running at 250MHz. We prove our accelerator\u2019s ability to process spatiotemporal data based on the DVS-Gesture dataset, achieving 92.7% accuracy and $24.3~\\mu \\text{J}$ /image energy. This design achieves 349.6KFPS recognition throughput on the MNIST dataset and $0.52~\\mu \\text{J}$ /image energy, which realizes top performance among edge SNN accelerators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193199144",
                    "name": "Lei Kang"
                },
                {
                    "authorId": "1934473004",
                    "name": "Xu Yang"
                },
                {
                    "authorId": "2115813186",
                    "name": "Chi Zhang"
                },
                {
                    "authorId": "150311591",
                    "name": "Shuangming Yu"
                },
                {
                    "authorId": "2235468",
                    "name": "Runjiang Dou"
                },
                {
                    "authorId": "2108689075",
                    "name": "Wenchang Li"
                },
                {
                    "authorId": "2086996153",
                    "name": "Cong Shi"
                },
                {
                    "authorId": "2150168221",
                    "name": "Jian Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                }
            ]
        },
        {
            "paperId": "fb15ab1f86ab1b5417415210ebbc675e616e57a8",
            "title": "Parallel Data Compression Techniques",
            "abstract": "With endless amounts of data and very limited bandwidth, fast data compression is one solution for the growing datasharing problem. Compression helps lower transfer times and save memory, but if the compression takes too long, this no longer seems viable. Multi-core processors enable parallel data compression; however, parallelizing the algorithms is anything but straightforward since compression is inherently serial. This paper explores techniques to parallelize three compression schemes: Huffman coding, LZSS, and MP3 coding",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076525538",
                    "name": "David Noel"
                },
                {
                    "authorId": "2220293670",
                    "name": "Elizabeth Graham"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                }
            ]
        },
        {
            "paperId": "019cb62ec0e5192d9950a21ead39afc4c70e8045",
            "title": "P4E: Few-Shot Event Detection as Prompt-Guided Identification and Localization",
            "abstract": "We propose P4E, an identify-and-localize event detection framework that integrates the best of few-shot prompting and structured prediction. Our framework decomposes event detection into an identification task and a localization task. For the identification task, which we formulate as multi-label classification, we leverage cloze-based prompting to align our objective with the pre-training task of language models, allowing our model to quickly adapt to new event types. We then employ an event type-agnostic sequence labeling model to localize the event trigger conditioned on the identification output. This heterogeneous model design allows P4E to quickly learn new event types without sacrificing the ability to make structured predictions. Our experiments demonstrate the effectiveness of our proposed design, and P4E shows superior performance for few-shot event detection on benchmark datasets FewEvent and MAVEN and comparable performance to SOTA for fully-supervised event detection on ACE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109154767",
                    "name": "Sha Li"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "1892794261",
                    "name": "Yiqing Xie"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "12dec94c19d9dcd47e218f295d494b1c94ff0e57",
            "title": "MorphBungee: An Edge Neuromorphic Chip for High-Accuracy On-Chip Learning of Multiple-Layer Spiking Neural Networks",
            "abstract": "Spiking neural networks and neuromorphic systems have attracted ever increasing interests recently, due to their high computational efficiency by imitating the functional mechanism of cerebral cortex. However, endowing low-cost neuromorphic chips with real-time high-accuracy on-chip learning plasticity for edge applications is still challenging. In this work, we present a digital edge neuromorphic chip for real-time high-accuracy on-chip multi-layer SNN learning in visual recognition tasks. It employs a hierarchical multi-core architecture, a dynamically reconfigurable array parallelism and a quasi-event-driven scheme to improve processing speed. A prototype chip with a core area of 10.39 mm2 was fabricated using a 65-nm 1P9M CMOS process, and typically achieved a real-time speed of 87 frames/s and a power dissipation of 106 mW at an 83 MHz clock rate when training a 4-layer fully-connected SNN. Our chip attained comparably high recognition accuracies of 96.29%, 84.95%, 86.13%, 85.07% and 100% on the MNIST, Fashion-MNIST, ETH-80, MNIST-DVS and Poker-DVS datasets, respectively, with an energy efficiency of 97 pJ/SOP for learning and 30 pJ/SOP for inference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1898436662",
                    "name": "Tengxiao Wang"
                },
                {
                    "authorId": "2155569060",
                    "name": "Haibing Wang"
                },
                {
                    "authorId": "2109931604",
                    "name": "Junxian He"
                },
                {
                    "authorId": "2114198059",
                    "name": "Zhengqing Zhong"
                },
                {
                    "authorId": "2140487440",
                    "name": "Fang Tang"
                },
                {
                    "authorId": "2109054962",
                    "name": "Xichuan Zhou"
                },
                {
                    "authorId": "150311591",
                    "name": "Shuangming Yu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "2114270879",
                    "name": "Min Tian"
                },
                {
                    "authorId": "1491631816",
                    "name": "Cong Shi"
                }
            ]
        },
        {
            "paperId": "3dc58a391d32567ba978f383c3182dfd0d2962c8",
            "title": "An 8-T Processing-in-Memory SRAM Cell-Based Pixel-Parallel Array Processor for Vision Chips",
            "abstract": "Vision chip is a high-speed image processing device, featuring a massively-parallel pixel-level processing element (PE) array to boost pixel processing speed. However, the collocated processing unit and fine-grained data memory unit inside each PE impose a huge requirement on memory access bandwidth as well as big area and energy consumption. To overcome this bottleneck, this paper proposes a full custom $\\mathbf{8T}$ SRAM-based Processing-in-memory (PIM) architecture to realize pixel-parallel array processor for high-speed energy-efficient vision chips. The proposed PIM architecture is constructed by emending multiplexer-based computing circuits into a dual port 8T SRAM array, so as to form a PIM PE array. Each PIM PE holds a 66-bit 8T SRAM cell block embedding in-memory logic functions, of which 64-bit 8T SRAM cells serving as the PE memory, 2-bit 8T SRAM cells acting as a buffer register in the PE. A full custom physical layout of a 16 $\\times \\boldsymbol{16}$ prototyping PIM PE array is designed and simulated using a 65 nm CMOS technology. The simulation results demonstrate that our proposed PIM PE architecture can achieve 200 MHz operation at 1.2 V, and reach a high energy efficiency of 3.97 TOPS/W while keeping a compact area of 0.129 $\\mathbf{mm}^{2}$.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214406369",
                    "name": "Leyi Chen"
                },
                {
                    "authorId": "2109931604",
                    "name": "Junxian He"
                },
                {
                    "authorId": "2215230968",
                    "name": "Jianyi Yu"
                },
                {
                    "authorId": "2155569060",
                    "name": "Haibing Wang"
                },
                {
                    "authorId": "2199913811",
                    "name": "Jing Lu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "2086996153",
                    "name": "Cong Shi"
                },
                {
                    "authorId": "2214070831",
                    "name": "Tian Min"
                }
            ]
        },
        {
            "paperId": "42b315130d06bf088d9c67d7fac0d693f3efab7a",
            "title": "A Programmable and Flexible Vision Processor",
            "abstract": "Vision chips perform image capture and real-time intelligent image processing by integrating an imager and a vision processor on a single chip, having broad application prospects. This paper proposes a programmable and flexible vision processor with a dual-issue micro-architecture. The processor consists of a reconfigurable vector unit, a flexible memory access network, and a non-maximum suppression (NMS) block. It can efficiently implement both deep neural network (DNN) and traditional computer vision (CV) algorithms. The vector unit performs single-instruction multiple-vector (SIMV) parallel operations with reconfigurable vector width. The flexible memory access network adaptively supports multiple vector operations under different vector widths. A four-MAC processing element (PE) in the vector unit is designed to increase computational power and data reuse rate. The NMS block can speed up the object location processing of the detection networks. The chip is fabricated in a 28nm process. The experimental results show that the maximum clock frequency, peak performance, and peak energy efficiency are 600MHz, 1.2TOPS, and 2.03TOPS/W, respectively. The Mobilenet-V1 processing achieves a throughput of 404 fps under a 256\u00d7224 image size and an 87.15%(top-5) accuracy on the ImageNet dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2074294973",
                    "name": "Qian Luo"
                },
                {
                    "authorId": "2093201490",
                    "name": "Chunhe Yao"
                },
                {
                    "authorId": "2065663281",
                    "name": "K. Ning"
                },
                {
                    "authorId": "1515281538",
                    "name": "Xuemin Zheng"
                },
                {
                    "authorId": "2152528595",
                    "name": "Mingxin Zhao"
                },
                {
                    "authorId": "2150207941",
                    "name": "Li Cheng"
                },
                {
                    "authorId": "150311591",
                    "name": "Shuangming Yu"
                },
                {
                    "authorId": "37536536",
                    "name": "Jian Liu"
                },
                {
                    "authorId": "40658072",
                    "name": "N. Wu"
                },
                {
                    "authorId": "3355833",
                    "name": "Liyuan Liu"
                }
            ]
        }
    ]
}