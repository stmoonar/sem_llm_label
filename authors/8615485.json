{
    "authorId": "8615485",
    "papers": [
        {
            "paperId": "81e1ec6b6155523655772826dd39f32a44d59cbd",
            "title": "Cultural Commonsense Knowledge for Intercultural Dialogues",
            "abstract": "Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions. This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge. We judiciously and iteratively prompt LLMs for this purpose from two entry points, concepts and cultures. Outputs are consolidated via clustering and generative summarization. Running the MANGO method with GPT-3.5 as underlying LLM yields 167K high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior resources by a large margin in quality and size. In an extrinsic evaluation for intercultural dialogues, we explore augmenting dialogue systems with cultural knowledge assertions. Notably, despite LLMs inherently possessing cultural knowledge, we find that adding knowledge from MANGO improves the overall quality, specificity, and cultural sensitivity of dialogue responses, as judged by human annotators. Data and code are available for download.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "1c86c5793c150a62d5f6581af2f79454f26faa20",
            "title": "UnCommonSense in Action! Informative Negations for Commonsense Knowledge Bases",
            "abstract": "Knowledge bases about commonsense knowledge i.e., CSKBs, are crucial in applications such as search and question answering. Prominent CSKBs mostly focus on positive statements. In this paper we show that materializing important negations increases the usability of CSKBs. We present Uncommonsense, a web portal to explore informative negations about everyday concepts: (i) in a research-focused interface, users get a glimpse into results-per-steps of the methodology; (ii) in a trivia interface, users can browse fun negative trivia about concepts of their choice; and (iii) in a query interface, users can submit triple-pattern queries with explicit negated relations and compare results with significantly less relevant answers from the positive-only baseline. It can be accessed at:https://uncommonsense.mpi-inf.mpg.de/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "1d9086a0d98d50812c175baa0911472713e399ab",
            "title": "Extracting Cultural Commonsense Knowledge at Scale",
            "abstract": "Structured knowledge is important for many AI applications. Commonsense knowledge, which is crucial for robust human-centric AI, is covered by a small number of structured knowledge projects. However, they lack knowledge about human traits and behaviors conditioned on socio-cultural contexts, which is crucial for situative AI. This paper presents Candle, an end-to-end methodology for extracting high-quality cultural commonsense knowledge (CCSK) at scale. Candle extracts CCSK assertions from a huge web corpus and organizes them into coherent clusters, for 3 domains of subjects (geography, religion, occupation) and several cultural facets (food, drinks, clothing, traditions, rituals, behaviors). Candle includes judicious techniques for classification-based filtering and scoring of interestingness. Experimental evaluations show the superiority of the Candle CCSK collection over prior works, and an extrinsic use case demonstrates the benefits of CCSK for the GPT-3 language model. Code and data can be accessed at https://candle.mpi-inf.mpg.de/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2154252",
                    "name": "A. Varde"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "489ffd70cb2afd550ab809bc90f5a766eb07aa80",
            "title": "Inside ASCENT: Exploring a Deep Commonsense Knowledge Base and its Usage in Question Answering",
            "abstract": "ASCENT is a fully automated methodology for extracting and consolidating commonsense assertions from web contents (Nguyen et al., 2021). It advances traditional triple-based commonsense knowledge representation by capturing semantic facets like locations and purposes, and composite concepts, i.e., subgroups and related aspects of subjects. In this demo, we present a web portal that allows users to understand its construction process, explore its content, and observe its impact in the use case of question answering. The demo website (https://ascent.mpi-inf.mpg.de) and an introductory video (https://youtu.be/qMkJXqu_Yd4) are both available online.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2499758",
                    "name": "Simon Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "66a660bc912fd212db40ded34d34f28e4860a676",
            "title": "Materialized Knowledge Bases from Commonsense Transformers",
            "abstract": "Starting from the COMET methodology by Bosselut et al. (2019), generating commonsense knowledge directly from pre-trained language models has recently received significant attention. Surprisingly, up to now no materialized resource of commonsense knowledge generated this way is publicly available. This paper fills this gap, and uses the materialized resources to perform a detailed analysis of the potential of this approach in terms of precision and recall. Furthermore, we identify common problem cases, and outline use cases enabled by materialized resources. We posit that the availability of these resources is important for the advancement of the field, as it enables an off-the-shelf-use of the resulting knowledge, as well as further analyses on its strengths and weaknesses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2499758",
                    "name": "Simon Razniewski"
                }
            ]
        },
        {
            "paperId": "e44cccc3cba72de45740ed2d1e09bfb2d1ed57b2",
            "title": "Refined Commonsense Knowledge From Large-Scale Web Contents",
            "abstract": "Commonsense knowledge (CSK) about concepts and their properties is helpful for AI applications. Prior works, such as ConceptNet, have compiled large CSK collections. However, they are restricted in their expressiveness to subject-predicate-object (SPO) triples with simple concepts for S and strings for P and O. This paper presents a method called Ascent++ to automatically build a large-scale knowledge base (KB) of CSK assertions, with refined expressiveness and both better precision and recall than prior works. Ascent++ goes beyond SPO triples by capturing composite concepts with subgroups and aspects, and by refining assertions with semantic facets. The latter is essential to express the temporal and spatial validity of assertions and further qualifiers. Furthermore, Ascent++ combines open information extraction (OpenIE) with judicious cleaning and ranking by typicality and saliency scores. For high coverage, our method taps into the large-scale crawl C4 with broad web contents. The evaluation with human judgments shows the superior quality of the Ascent++ KB, and an extrinsic evaluation for QA-support tasks underlines the benefits of Ascent++. A web interface, data, and code can be accessed at https://ascentpp.mpi-inf.mpg.de/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "119889381",
                    "name": "Julien Romero"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "ca4a945b4b1a4c799abd71731c286440f81af997",
            "title": "Advanced Semantics for Commonsense Knowledge Extraction",
            "abstract": "Commonsense knowledge (CSK) about concepts and their properties is useful for AI applications such as robust chatbots. Prior works like ConceptNet, TupleKB and others compiled large CSK collections, but are restricted in their expressiveness to subject-predicate-object (SPO) triples with simple concepts for S and monolithic strings for P and O. Also, these projects have either prioritized precision or recall, but hardly reconcile these complementary goals. This paper presents a methodology, called Ascent, to automatically build a large-scale knowledge base (KB) of CSK assertions, with advanced expressiveness and both better precision and recall than prior works. Ascent goes beyond triples by capturing composite concepts with subgroups and aspects, and by refining assertions with semantic facets. The latter are important to express temporal and spatial validity of assertions and further qualifiers. Ascent combines open information extraction with judicious cleaning using language models. Intrinsic evaluation shows the superior size and quality of the Ascent KB, and an extrinsic evaluation for QA-support tasks underlines the benefits of Ascent. A web interface, data and code can be found at https://www.mpi-inf.mpg.de/ascent.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2499758",
                    "name": "Simon Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "37c035d58a2007d230bade6628c7ab35312aba1f",
            "title": "Integrating Word Embeddings into IBM Word Alignment Models",
            "abstract": "Word alignment models are used to generate word-aligned parallel text which is used in statistical machine translation systems. Currently, the most popular word alignment models are IBM models which have been widely applied in a large number of translation systems. The parameters of IBM models are estimated by using Maximum Likelihood principle, i.e. by counting the co-occurrence of words in the parallel text. This way of parameter estimation leads to the \u201cambiguity\u201d problem when some words stand together in many sentence pairs but each of them is not translation of any other. Additionally, this method requires large amount of training data to achieve good results. However, parallel text which is used to train the IBM models is usually limited for low-resource languages. In this work, we try to solve these two problems by adding semantic information to the models. Our semantic information is derived from word embeddings which only need monolingual data to train. We deploy evaluation on a language pair that has great differences in grammar structure, English-Vietnamese. Even with this challenged task, our proposed models gain significant improvements in word alignment result and help increasing translation quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1788292",
                    "name": "Anh-Cuong Le"
                },
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "3285873",
                    "name": "Quoc-Long Tran"
                },
                {
                    "authorId": "52184429",
                    "name": "Dao Bao Linh"
                }
            ]
        },
        {
            "paperId": "8ad303d7d0e8540ef7b434bef3bbcab424a1b6a2",
            "title": "An Experimental Investigation of Part-Of-Speech Taggers for Vietnamese",
            "abstract": "Part-of-speech (POS) tagging plays an important role in Natural Language Processing (NLP). Its applications can be found in many other NLP tasks such as named entity recognition, syntactic parsing and text chunking. Recent studies for common languages such as English and French gain very high precision for this core NLP task. However, current results for less common language like Vietnamese are not as good as for those languages. In our investigation, we utilized the techniques of two widely used toolkits, ClearNLP and Stanford POS Tagger, and made two new taggers to compare with three well-known Vietnamese taggers, namely JVnTagger, vnTagger and RDRPOSTagger. We created a unique evaluation scheme to make a systematic comparison and investigate that which tagger has the best accuracy and speed. The comparison revealed that our two new taggers built from ClearNLP and Stanford POS Tagger make overall accuracies of 94.50% and 94.39%, respectively, and outperform all other toolkits. Moreover, in our speed testing, RDRPOSTagger produces an impressive tagging speed and performs signi\ufb01cantly faster than any other stochastic taggers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "39603708",
                    "name": "Quoc-Tuan Truong"
                },
                {
                    "authorId": "1879284",
                    "name": "X. Nguyen"
                },
                {
                    "authorId": "1788292",
                    "name": "Anh-Cuong Le"
                }
            ]
        },
        {
            "paperId": "c20dd07c09bdbff9e554853ade4174d2cf9faa8b",
            "title": "A hybrid approach to Vietnamese word segmentation",
            "abstract": "Word segmentation is the very first task for Vietnamese language processing. Word-segmented text is the input of almost other NLP tasks. This task faces some challenges due to specific characteristics of the language. As in many other Asian languages such as Japanese, Korean and Chinese, white spaces in Vietnamese are not always used as word separators and a word may contain one or more syllables. In this paper, we propose an efficient hybrid approach to detect word boundary for Vietnamese texts using logistic regression as a binary classifier combining with longest matching algorithm. First, longest matching algorithm is used to catch words that contain more than two syllables in input sentence. Next, the system utilizes the classifier to determine the boundary of 2-syllable words and proper names. Then, the predictions having low confidence conducted by the classifier are verified by a dictionary to get the final result. Our system can achieve an F-measure of 98.82% which is the most accurate result for Vietnamese word segmentation to the best of our knowledge. Moreover, the system also has a high speed. It can run word segmentation for nearly 34k tokens per second.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "1788292",
                    "name": "Anh-Cuong Le"
                }
            ]
        }
    ]
}