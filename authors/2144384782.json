{
    "authorId": "2144384782",
    "papers": [
        {
            "paperId": "1725ad1d8cc0e539ac5d0a85657d5c95b4538c5e",
            "title": "Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects",
            "abstract": "Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages and disadvantages. To facilitate the experiments and validation of time series SSL methods, we also summarize datasets commonly used in time series forecasting, classification, anomaly detection, and clustering tasks. Finally, we present the future directions of SSL for time series analysis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2119059780",
                    "name": "Kexin Zhang"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2152737103",
                    "name": "Chaoli Zhang"
                },
                {
                    "authorId": "2136700261",
                    "name": "Rongyao Cai"
                },
                {
                    "authorId": "2072905592",
                    "name": "Ming Jin"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "72322304",
                    "name": "Y. Liang"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2585415",
                    "name": "Shirui Pan"
                }
            ]
        },
        {
            "paperId": "5483dd664748876edf2b5237d20257c8e1781fe4",
            "title": "Semi-Supervised Learning for Visual Bird\u2019s Eye View Semantic Segmentation",
            "abstract": "Visual bird\u2019s eye view (BEV) semantic segmentation helps autonomous vehicles understand the surrounding environment only from front-view (FV) images, including static elements (e.g., roads) and dynamic elements (e.g., vehicles, pedestrians). However, the high cost of annotation procedures of full-supervised methods limits the capability of the visual BEV semantic segmentation, which usually needs HD maps, 3D object bounding boxes, and camera extrinsic matrixes. In this paper, we present a novel semi-supervised framework for visual BEV semantic segmentation to boost performance by exploiting unlabeled images during the training. A consistency loss that makes full use of unlabeled data is then proposed to constrain the model on not only semantic prediction but also the BEV feature. Furthermore, we propose a novel and effective data augmentation method named conjoint rotation which reasonably augments the dataset while maintaining the geometric relationship between the FV images and the BEV semantic segmentation. Extensive experiments on the nuScenes dataset show that our semi-supervised framework can effectively improve prediction accuracy. To the best of our knowledge, this is the first work that explores improving visual BEV semantic segmentation performance using unlabeled data. The code is available at https://github.com/Junyu-Z/Semi-BEVseg.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3310631",
                    "name": "Junyu Zhu"
                },
                {
                    "authorId": "2145314984",
                    "name": "Lina Liu"
                },
                {
                    "authorId": "2152993032",
                    "name": "Yu Tang"
                },
                {
                    "authorId": "2052575443",
                    "name": "Feng Wen"
                },
                {
                    "authorId": "48624792",
                    "name": "Wanlong Li"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                }
            ]
        },
        {
            "paperId": "916bc9ed62113ad7a5bb8096051593df4ebb2061",
            "title": "Unsupervised Representation Learning for Time Series: A Review",
            "abstract": "Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103236149",
                    "name": "Qianwen Meng"
                },
                {
                    "authorId": "1732549",
                    "name": "Hangwei Qian"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "153018970",
                    "name": "Yonghui Xu"
                },
                {
                    "authorId": "2111639168",
                    "name": "Zhiqi Shen"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                }
            ]
        },
        {
            "paperId": "e1b2d702b13d1d455865268b99daefdd59e4e800",
            "title": "Supervised preserving projection for learning scene information based on time-of-flight imaging sensor.",
            "abstract": "In this paper, we propose a new supervised manifold learning approach, supervised preserving projection (SPP), for the depth images of a 3D imaging sensor based on the time-of-flight (TOF) principle. We present a novel manifold sense to learn scene information produced by the TOF camera along with depth images. First, we use a local surface patch to approximate the underlying manifold structures represented by the scene information. The fundamental idea is that, because TOF data have nonstatic noise and distance ambiguity problems, the surface patches can more efficiently approximate the local neighborhood structures of the underlying manifold than TOF data points, and they are robust to the nonstatic noise of TOF data. Second, we propose SPP to preserve the pairwise similarity between the local neighboring patches in TOF depth images. Moreover, SPP accomplishes the low-dimensional embedding by adding the scene region class label information accompanying the training samples and obtains the predictive mapping by incorporating the local geometrical properties of the dataset. The proposed approach has advantages of both classical linear and nonlinear manifold learning, and real-time estimation results of the test samples are obtained by the low-dimensional embedding and the predictive mapping. Experiments show that our approach obtains information effectively from three scenes and is robust to the nonstatic noise of 3D imaging sensor data.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146417365",
                    "name": "Yi Jiang"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2171697",
                    "name": "Yunqi Lei"
                },
                {
                    "authorId": "123451944",
                    "name": "Qicong Wang"
                }
            ]
        }
    ]
}