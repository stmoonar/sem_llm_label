{
    "authorId": "2273816798",
    "papers": [
        {
            "paperId": "69e5ecd0468aba4543bb14327e9769abb3f01ce9",
            "title": "RNR: Teaching Large Language Models to Follow Roles and Rules",
            "abstract": "Instruction fine-tuning (IFT) elicits instruction following capabilities and steers the behavior of large language models (LLMs) via supervised learning. However, existing models trained on open-source IFT datasets only have the ability to follow instructions from users, and often fail to follow complex role and rules specified by developers, a.k.a. system prompts. The ability to follow these roles and rules is essential for deployment, as it ensures that the model safely interacts with users within developer defined guidelines. To improve such role and rule following ability, we propose \\model, an automated data generation pipeline that generates diverse roles and rules from existing IFT instructions, along with corresponding responses. This data can then be used to train models that follow complex system prompts. The models are evaluated on our newly created benchmarks for role and rule following ability, as well as standard instruction-following benchmarks and general NLP tasks. Our framework significantly improves role and rule following capability in LLMs, as evidenced by over 25% increase in pass-rate on rule adherence, i.e. following all requirements, in our experiments with the Alpaca and Ultrachat datasets. Moreover, our models achieves this increase without any regression on popular instruction following benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2322605701",
                    "name": "Kuan Wang"
                },
                {
                    "authorId": "1645394981",
                    "name": "Alexander Bukharin"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2322450899",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2312598740",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2323319914",
                    "name": "Tuo Zhao"
                },
                {
                    "authorId": "2316717970",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2322453332",
                    "name": "Jianshu Chen"
                },
                {
                    "authorId": "2314348843",
                    "name": "Shiyang Li"
                }
            ]
        },
        {
            "paperId": "f42b97cdfbf1a78c02e78cfce6f8b0e277766ae2",
            "title": "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs",
            "abstract": "Reasoning encompasses two typical types: deductive reasoning and inductive reasoning. Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning, leading to a blending of the two. This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? While the deductive reasoning capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning tasks), have received considerable attention, their abilities in true inductive reasoning remain largely unexplored. To investigate into the true inductive reasoning capabilities of LLMs, we propose a novel framework, SolverLearner. This framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$), that maps input data points $(x)$ to their corresponding output values $(y)$, using only in-context examples. By focusing on inductive reasoning and separating it from LLM-based deductive reasoning, we can isolate and investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our observations reveal that LLMs demonstrate remarkable inductive reasoning capabilities through SolverLearner, achieving near-perfect performance with ACC of 1 in most cases. Surprisingly, despite their strong inductive reasoning abilities, LLMs tend to relatively lack deductive reasoning capabilities, particularly in tasks involving ``counterfactual'' reasoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260755600",
                    "name": "Kewei Cheng"
                },
                {
                    "authorId": "2276746186",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2312598740",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2315087538",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "2257590787",
                    "name": "Ruirui Li"
                },
                {
                    "authorId": "2314348843",
                    "name": "Shiyang Li"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2261083995",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "af6da5e89b61e43bf9af2233cb003deea3d4bff1",
            "title": "Knowledge-Selective Pretraining for Attribute Value Extraction",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275053439",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2274037416",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2273814369",
                    "name": "William Wang"
                },
                {
                    "authorId": "2274054096",
                    "name": "Xiao-Dan Zhu"
                }
            ]
        }
    ]
}