{
    "authorId": "2257013410",
    "papers": [
        {
            "paperId": "06bdd91951dc1c6160a51c01426ad1d661b03ab2",
            "title": "Stance and Hate Event Detection in Tweets Related to Climate Activism - Shared Task at CASE 2024",
            "abstract": "Social media plays a pivotal role in global discussions, including on climate change. The variety of opinions expressed range from supportive to oppositional, with some instances of hate speech. Recognizing the importance of understanding these varied perspectives, the 7th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) at EACL 2024 hosted a shared task focused on detecting stances and hate speech in climate activism-related tweets. This task was divided into three subtasks: subtasks A and B concentrated on identifying hate speech and its targets, while subtask C focused on stance detection. Participants\u2019 performance was evaluated using the macro F1-score. With over 100 teams participating, the highest F1 scores achieved were 91.44% in subtask C, 78.58% in subtask B, and 74.83% in subtask A. This paper details the methodologies of 24 teams that submitted their results to the competition\u2019s leaderboard.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1978790638",
                    "name": "Surendrabikram Thapa"
                },
                {
                    "authorId": "2122028151",
                    "name": "Kritesh Rauniyar"
                },
                {
                    "authorId": "2203790077",
                    "name": "F. Jafri"
                },
                {
                    "authorId": "2223096295",
                    "name": "Shuvam Shiwakoti"
                },
                {
                    "authorId": "2223516354",
                    "name": "Hariram Veeramani"
                },
                {
                    "authorId": "2291389700",
                    "name": "Raghav Jain"
                },
                {
                    "authorId": "2266470288",
                    "name": "Guneet Singh Kohli"
                },
                {
                    "authorId": "79828215",
                    "name": "Ali H\u00fcrriyeto\u01e7lu"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "0bf8644294c43b7684122a33a4af4f409c9a7899",
            "title": "Structural Representation Learning and Disentanglement for Evidential Chinese Patent Approval Prediction",
            "abstract": "Automatic Chinese patent approval prediction is an emerging and valuable task in patent analysis. However, it involves a rigorous and transparent decision-making process that includes patent comparison and examination to assess its innovation and correctness. This resultant necessity of decision evidentiality, coupled with intricate patent comprehension presents significant challenges and obstacles for the patent analysis community. Consequently, few existing studies are addressing this task. This paper presents the pioneering effort on this task using a retrieval-based classification approach. We propose a novel framework called DiSPat, which focuses on structural representation learning and disentanglement to predict the approval of Chinese patents and offer decision-making evidence. DiSPat comprises three main components: base reference retrieval to retrieve the Top-k most similar patents as a reference base; structural patent representation to exploit the inherent claim hierarchy in patents for learning a structural patent representation; disentangled representation learning to learn disentangled patent representations that enable the establishment of an evidential decision-making process. To ensure a thorough evaluation, we have meticulously constructed three datasets of Chinese patents. Extensive experiments on these datasets unequivocally demonstrate our DiSPat surpasses state-of-the-art baselines on patent approval prediction, while also exhibiting enhanced evidentiality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2316860742",
                    "name": "Jinzhi Shan"
                },
                {
                    "authorId": "2283510486",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2316868749",
                    "name": "Mengting Gui"
                },
                {
                    "authorId": "2266355264",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "2e7a50224daed11049bca7e6c96e4d4d599f1a48",
            "title": "MSynFD: Multi-hop Syntax Aware Fake News Detection",
            "abstract": "The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists1 in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical dependency graph and design a multi-hop subgraph aggregation mechanism to capture multi-hop syntax. It extends the effect of word perception, leading to effective noise filtering and adjacent relation enhancement. Subsequently, a sequential relative position-aware Transformer is designed to capture the sequential information, together with an elaborate keyword debiasing module to mitigate the prior bias. Extensive experimental results on two public benchmark datasets verify the effectiveness and superior performance of our proposed MSynFD over state-of-the-art detection models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274029674",
                    "name": "Liang Xiao"
                },
                {
                    "authorId": "2271885943",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "2266355264",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                }
            ]
        },
        {
            "paperId": "344891c6d7c0f05db90731dc163deb2fed7534c5",
            "title": "Enhancing ESG Impact Type Identification through Early Fusion and Multilingual Models",
            "abstract": "In the evolving landscape of Environmental, Social, and Corporate Governance (ESG) impact assessment, the ML-ESG-2 shared task proposes identifying ESG impact types. To address this challenge, we present a comprehensive system leveraging ensemble learning techniques, capitalizing on early and late fusion approaches. Our approach employs four distinct models: mBERT, FlauBERT-base, ALBERT-base-v2, and a Multi-Layer Perceptron (MLP) incorporating Latent Semantic Analysis (LSA) and Term Frequency-Inverse Document Frequency (TF-IDF) features. Through extensive experimentation, we find that our early fusion ensemble approach, featuring the integration of LSA, TF-IDF, mBERT, FlauBERT-base, and ALBERT-base-v2, delivers the best performance. Our system offers a comprehensive ESG impact type identification solution, contributing to the responsible and sustainable decision-making processes vital in today's financial and corporate governance landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223516354",
                    "name": "Hariram Veeramani"
                },
                {
                    "authorId": "1978790638",
                    "name": "Surendrabikram Thapa"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "7409cf3526af0f4fdf08cb93df77ec0971b29635",
            "title": "MultiHateClip: A Multilingual Benchmark Dataset for Hateful Video Detection on YouTube and Bilibili",
            "abstract": "Hate speech is a pressing issue in modern society, with significant effects both online and offline. Recent research in hate speech detection has primarily centered on text-based media, largely overlooking multimodal content such as videos. Existing studies on hateful video datasets have predominantly focused on English content within a Western context and have been limited to binary labels (hateful or non-hateful), lacking detailed contextual information. This study presents MultiHateClip1 , an novel multilingual dataset created through hate lexicons and human annotation. It aims to enhance the detection of hateful videos on platforms such as YouTube and Bilibili, including content in both English and Chinese languages. Comprising 2,000 videos annotated for hatefulness, offensiveness, and normalcy, this dataset provides a cross-cultural perspective on gender-based hate speech. Through a detailed examination of human annotation results, we discuss the differences between Chinese and English hateful videos and underscore the importance of different modalities in hateful and offensive video analysis. Evaluations of state-of-the-art video classification models, such as VLM, GPT-4V and Qwen-VL, on MultiHateClip highlight the existing challenges in accurately distinguishing between hateful and offensive content and the urgent need for models that are both multimodally and culturally nuanced. MultiHateClip represents a foundational advance in enhancing hateful video detection by underscoring the necessity of a multimodal and culturally sensitive approach in combating online hate speech.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262111802",
                    "name": "Han Wang"
                },
                {
                    "authorId": "2315257588",
                    "name": "Tan Rui Yang"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "2266006388",
                    "name": "Roy Ka-Wei Lee"
                }
            ]
        },
        {
            "paperId": "aa68d008918c16f092981b1e8f1b74ed86be9dc8",
            "title": "RUHate-MM: Identification of Hate Speech and Targets using Multimodal Data from Russia-Ukraine Crisis",
            "abstract": "During the conflict between Ukraine and Russia, hate speech targeted toward specific groups was widespread on different social media platforms. With most social platforms allowing multimodal content, the use of multimodal content to express hate speech is widespread on the Internet. Although there has been considerable research in detecting hate speech within unimodal content, the investigation into multimodal content remains insufficient. The limited availability of annotated multimodal datasets further restricts our ability to explore new methods to interpret and identify hate speech and its targets. The availability of annotated datasets for hate speech detection during political events, such as invasions, are even limited. To fill this gap, we introduce a comprehensive multimodal dataset consisting of 20,675 posts related to the Russia-Ukraine crisis, which were manually annotated as either 'Hate Speech' or 'No Hate Speech'. Additionally, we categorize the hate speech data into three targets: 'Individual', 'Organization', and 'Community'. Our benchmarked evaluations show that there is still room for improvement in accurately identifying hate speech and its targets. We hope that the availability of this dataset and the evaluations performed on it will encourage the development of new methods for identifying hate speech and its targets during political events like invasions and wars. The dataset and resources are made available at https://github.com/Farhan-jafri/Russia-Ukraine.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1978790638",
                    "name": "Surendrabikram Thapa"
                },
                {
                    "authorId": "2203790077",
                    "name": "F. Jafri"
                },
                {
                    "authorId": "2122028151",
                    "name": "Kritesh Rauniyar"
                },
                {
                    "authorId": "2257013473",
                    "name": "Mehwish Nasim"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "aacba5367cdac82e57e171c61db5f0a2cf8c899f",
            "title": "Analyzing the Dynamics of Climate Change Discourse on Twitter: A New Annotated Corpus and Multi-Aspect Classification",
            "abstract": "The discourse surrounding climate change on social media platforms has emerged as a significant avenue for understanding public sentiments, perspectives, and engagement with this critical global issue. The unavailability of publicly available datasets, coupled with ignoring the multi-aspect analysis of climate discourse on social media platforms, has underscored the necessity for further advancement in this area. To address this gap, in this paper, we present an extensive exploration of the intricate realm of climate change discourse on Twitter, leveraging a meticulously annotated ClimaConvo dataset comprising 15,309 tweets. Our annotations encompass a rich spectrum, including aspects like relevance, stance, hate speech, the direction of hate, and humor, offering a nuanced understanding of the discourse dynamics. We address the challenges inherent in dissecting online climate discussions and detail our comprehensive annotation methodology. In addition to annotations, we conduct benchmarking assessments across various algorithms for six tasks: relevance detection, stance detection, hate speech identification, direction and target, and humor analysis. This assessment enhances our grasp of sentiment fluctuations and linguistic subtleties within the discourse. Our analysis extends to exploratory data examination, unveiling tweet distribution patterns, stance prevalence, and hate speech trends. Employing sophisticated topic modeling techniques uncovers underlying thematic clusters, providing insights into the diverse narrative threads woven within the discourse. The findings present a valuable resource for researchers, policymakers, and communicators seeking to navigate the intricacies of climate change discussions. The dataset and resources for this paper are available at https://github.com/shucoll/ClimaConvo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223096295",
                    "name": "Shuvam Shiwakoti"
                },
                {
                    "authorId": "1978790638",
                    "name": "Surendrabikram Thapa"
                },
                {
                    "authorId": "2122028151",
                    "name": "Kritesh Rauniyar"
                },
                {
                    "authorId": "2302291042",
                    "name": "Akshyat Shah"
                },
                {
                    "authorId": "2301583854",
                    "name": "Aashish Bhandari"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "ac71e2342836d32f026c111be832a8579b7d2654",
            "title": "Wills Aligner: A Robust Multi-Subject Brain Representation Learner",
            "abstract": "Decoding visual information from human brain activity has seen remarkable advancements in recent research. However, due to the significant variability in cortical parcellation and cognition patterns across subjects, current approaches personalized deep models for each subject, constraining the practicality of this technology in real-world contexts. To tackle the challenges, we introduce Wills Aligner, a robust multi-subject brain representation learner. Our Wills Aligner initially aligns different subjects' brains at the anatomical level. Subsequently, it incorporates a mixture of brain experts to learn individual cognition patterns. Additionally, it decouples the multi-subject learning task into a two-stage training, propelling the deep model and its plugin network to learn inter-subject commonality knowledge and various cognition patterns, respectively. Wills Aligner enables us to overcome anatomical differences and to efficiently leverage a single model for multi-subject brain representation learning. We meticulously evaluate the performance of our approach across coarse-grained and fine-grained visual decoding tasks. The experimental results demonstrate that our Wills Aligner achieves state-of-the-art performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2272047108",
                    "name": "Guangyin Bao"
                },
                {
                    "authorId": "2271636340",
                    "name": "Zixuan Gong"
                },
                {
                    "authorId": "2271885943",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2297829449",
                    "name": "Jialei Zhou"
                },
                {
                    "authorId": "2297844284",
                    "name": "Wei Fan"
                },
                {
                    "authorId": "2265619390",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "2274216292",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2273073533",
                    "name": "Duoqian Miao"
                }
            ]
        },
        {
            "paperId": "e3d38aba7579c5130df1c3ca59b607dab291dd8d",
            "title": "Foreword for the First International Workshop on Multimodal Content Analysis for Social Good (MM4SG 2024)",
            "abstract": "The first international workshop on multimedia content analysis for social good (MM4SG) was held in conjunction with the Web Conference 2024. The workshop aimed to address the challenge of effectively analyzing and moderating multimodal content across digital platforms. In an era where multimodal data including memes, text-embedded images, and fabricated content swiftly capture the public's attention and influence societal discourse, the need for advanced content moderation strategies is more pressing than ever. This workshop serves as a platform for research and collaboration between experts in natural language processing, machine learning, computational social science, and ethics. In this paper, we describe the inaugural edition of the MM4SG workshop. We also include the future directions for our workshop's upcoming editions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1978790638",
                    "name": "Surendrabikram Thapa"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "2282413929",
                    "name": "Roy Ka-Wei Lee"
                },
                {
                    "authorId": "2257013473",
                    "name": "Mehwish Nasim"
                }
            ]
        },
        {
            "paperId": "e4d5b74c6efd33feab22e8a3b96cda9a63b7041a",
            "title": "Extended Multimodal Hate Speech Event Detection During Russia-Ukraine Crisis - Shared Task at CASE 2024",
            "abstract": "Addressing the need for effective hate speech moderation in contemporary digital discourse, the Multimodal Hate Speech Event Detection Shared Task made its debut at CASE 2023, co-located with RANLP 2023. Building upon its success, an extended version of the shared task was organized at the CASE workshop in EACL 2024. Similar to the earlier iteration, in this shared task, participants address hate speech detection through two subtasks. Subtask A is a binary classification problem, assessing whether text-embedded images contain hate speech. Subtask B goes further, demanding the identification of hate speech targets, such as individuals, communities, and organizations within text-embedded images. Performance is evaluated using the macro F1-score metric in both subtasks. With a total of 73 registered participants, the shared task witnessed remarkable achievements, with the best F1-scores in Subtask A and Subtask B reaching 87.27% and 80.05%, respectively, surpassing the leaderboard of the previous CASE 2023 shared task. This paper provides a comprehensive overview of the performance of seven teams that submitted results for Subtask A and five teams for Subtask B.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1978790638",
                    "name": "Surendrabikram Thapa"
                },
                {
                    "authorId": "2122028151",
                    "name": "Kritesh Rauniyar"
                },
                {
                    "authorId": "2203790077",
                    "name": "F. Jafri"
                },
                {
                    "authorId": "2223516354",
                    "name": "Hariram Veeramani"
                },
                {
                    "authorId": "2291389700",
                    "name": "Raghav Jain"
                },
                {
                    "authorId": "2291875939",
                    "name": "Sandesh Jain"
                },
                {
                    "authorId": "2291361319",
                    "name": "Francielle Vargas"
                },
                {
                    "authorId": "79828215",
                    "name": "Ali H\u00fcrriyeto\u01e7lu"
                },
                {
                    "authorId": "2257013410",
                    "name": "Usman Naseem"
                }
            ]
        }
    ]
}