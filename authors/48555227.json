{
    "authorId": "48555227",
    "papers": [
        {
            "paperId": "353e624e19a491fca67a2cce1118944de5786981",
            "title": "Efficient Use of DALICC in Data Processing Pipelines with Fuzzy License Information",
            "abstract": "Integration of huge amounts of data from various sources forms the basis for many of today\u2019s (web) applications and use cases. In order to be able to reuse, transform, process, analyze, aggregate and re-publish such data, terms of use and license information are particularly important. DALICC provides a very comprehensive database for licenses and offers viable services for license handling that have been made available as open source. In this paper, we outline how DALICC can be used in (web) applications (represented by the project COYPU) in which heterogeneous data from various data sources with different usage conditions are processed. The paper aims to provide feedback on DALICC, to discuss necessary adjustments and present extensions that have been made by us. The overarching objective is to further activate and cooperatively develop the DALICC ecosystem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                },
                {
                    "authorId": "2216105617",
                    "name": "Michael Martin"
                },
                {
                    "authorId": "2096905450",
                    "name": "Norman Radtke"
                },
                {
                    "authorId": "1414031652",
                    "name": "Sabine Gr\u00fcnder-Fahrer"
                }
            ]
        },
        {
            "paperId": "412e1d19dd28b3da42ba47ba5a9ababc62255482",
            "title": "Base Platform for Knowledge Graphs with Free Software",
            "abstract": "We present an Open Source base platform for the C oyPuknowledge graph project in the resilience domain. We report on our experiences with several tools which are used to create, maintain, serve, view and explore a modular large-scale knowledge graph, as well as the adaptions that were necessary to enable frictionless interaction from both performance and usability perspectives. For this purpose, several adjustments had to be made. We provide a broad view of different programs which are of relevance to this domain. We demonstrate that while it is already possible to achieve good results with free software, there are still several pain points that need to be addressed. Resolution of these issues is often not only a matter of configuration but requires modification of the source code as well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7703724",
                    "name": "Simon Bin"
                },
                {
                    "authorId": "2390605",
                    "name": "Claus Stadler"
                },
                {
                    "authorId": "2096905450",
                    "name": "Norman Radtke"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                },
                {
                    "authorId": "1414031652",
                    "name": "Sabine Gr\u00fcnder-Fahrer"
                },
                {
                    "authorId": "2110607609",
                    "name": "Michael Martin"
                }
            ]
        },
        {
            "paperId": "d0e3af5f20a451c04770929979d7a8406a1a2466",
            "title": "Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering",
            "abstract": "As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "34886987",
                    "name": "Lars-Peter Meyer"
                },
                {
                    "authorId": "32114346",
                    "name": "Johannes Frey"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                },
                {
                    "authorId": "2236686278",
                    "name": "Felix Brei"
                },
                {
                    "authorId": "2108312",
                    "name": "Kirill Bulert"
                },
                {
                    "authorId": "1411787759",
                    "name": "Sabine Grunder-Fahrer"
                },
                {
                    "authorId": "2216105617",
                    "name": "Michael Martin"
                }
            ]
        },
        {
            "paperId": "ce5fb212c75cd3fd76e30f0e28216457beb8c8ad",
            "title": "Semantification of Geospatial Information for Enriched Knowledge Representation in Context of Crisis Informatics",
            "abstract": "In the context of crisis informatics, the integration and exploitation of high volumes of heterogeneous data from multiple sources is one of the big chances as well as challenges up to now. Semantic Web technologies have proven a valuable means to integrate and represent knowledge on the basis of domain concepts which improves interoperability and interpretability of information resources and allows deriving more knowledge via semantic relations and reasoning. In this paper, we investigate the potential of representing and processing geospatial information within the semantic paradigm. We show, on the technical level, how existing open source means can be used and supplemented as to efficiently handle geographic information and to convey exemplary results highly relevant in context of crisis management applications. When given semantic resources get enriched with geospatial information, new information can be retrieved combining the concepts of multi-polygons and geo-coordinates and using the power of GeoSPARQL queries. Custom SPARQL extension functions and data types for JSON, XML and CSV as well as for dialects such as GeoJSON and GML allow for succinct integration of heterogeneous data. We implemented these features for the Apache Jena Semantic Web framework by leveraging its plugin systems. Furthermore, significant improvements w.r.t. GeoSPARQL query performance have been contributed to the framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2390605",
                    "name": "Claus Stadler"
                },
                {
                    "authorId": "7703724",
                    "name": "Simon Bin"
                },
                {
                    "authorId": "2625507",
                    "name": "Lorenz B\u00fchmann"
                },
                {
                    "authorId": "2096905450",
                    "name": "Norman Radtke"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                },
                {
                    "authorId": "1414031652",
                    "name": "Sabine Gr\u00fcnder-Fahrer"
                },
                {
                    "authorId": "2216105617",
                    "name": "Michael Martin"
                }
            ]
        },
        {
            "paperId": "c9963cb3f66385d0daada6fb402a4060b27a4dc2",
            "title": "RDF-based Deployment Pipelining for Efficient Dataset Release Management",
            "abstract": "Open Data portals often struggle to provide release features (i.e., stable versioning, up-to-date download links, rich metadata descriptions) for their datasets. By this means, wide adoption of publicly available data collections is hindered, since consuming applications cannot access fresh data sources or might break due to data quality issues. While there exists a variety of tools to efficiently control release processes in software development, the management of dataset releases is not as clear. This paper proposes a deployment pipeline for efficient dataset releases that is based on automated enrichment of DCAT/DataID metadata and is a first step towards efficient deployment pipelining for Open Data publishing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2390605",
                    "name": "Claus Stadler"
                },
                {
                    "authorId": "2486262",
                    "name": "L. Wenige"
                },
                {
                    "authorId": "2110607609",
                    "name": "Michael Martin"
                },
                {
                    "authorId": "2574714",
                    "name": "Sebastian Tramp"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                }
            ]
        },
        {
            "paperId": "ad2a497ba380e228451a304ac3a047322e643c45",
            "title": "A Decentralized and Remote Controlled Webinar Approach, Utilizing Client-side Capabilities: To Increase Participant Limits and Reduce Operating Costs",
            "abstract": ": We present a concept and implementation on increasing the ef\ufb01ciency of webinar software by a remote control approach using the technology WebRTC. This technology enables strong security and privacy, is cross-device usable, uses open-source technology and enables a new level of interactiveness to webinars. We used SlideWiki, WebRTC, and browser speech to text engines to provide innovative accessibility features like multilingual presentations and live subtitles. Our solution was rated for real world usage aspects, tested within the SlideWiki project and we determined technological limits. Such measurements are currently not available and show that our approach outperforms open-source market competitors by ef\ufb01ciency and costs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36476994",
                    "name": "R. Meissner"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                },
                {
                    "authorId": "2110607609",
                    "name": "Michael Martin"
                }
            ]
        },
        {
            "paperId": "5a3627b54cc3f109d7f02d59cdca0ee6b6a279b2",
            "title": "Using DevOps Principles to Continuously Monitor RDF Data Quality",
            "abstract": "One approach to continuously achieve a certain data quality level is to use an integration pipeline that continuously checks and monitors the quality of a data set according to defined metrics. This approach is inspired by Continuous Integration pipelines, that have been introduced in the area of software development and DevOps to perform continuous source code checks. By investigating in possible tools to use and discussing the specific requirements for RDF data sets, an integration pipeline is derived that joins current approaches of the areas of software-development and semantic-web as well as reuses existing tools. As these tools have not been built explicitly for CI usage, we evaluate their usability and propose possible workarounds and improvements. Furthermore, a real-world usage scenario is discussed, outlining the benefit of the usage of such a pipeline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36476994",
                    "name": "R. Meissner"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                }
            ]
        },
        {
            "paperId": "b4630e124d7853c8eef410c66c0dedf42d5f3784",
            "title": "Structured Feedback: A Distributed Protocol for Feedback and Patches on the Web of Data",
            "abstract": "The World Wide Web is an infrastructure to publish and retrieve information through web resources. It evolved from a static Web 1.0 to a multimodal and interactive communication and information space which is used to collaboratively contribute and discuss web resources, which is better known as Web 2.0. The evolution into a Semantic Web (Web 3.0) proceeds. One of its remarkable advantages is the decentralized and interlinked data composition. Hence, in contrast to its data distribution, workflows and technologies for decentralized collaborative contribution are missing. In this paper we propose the Structured Feedback protocol as an interactive addition to the Web of Data. It offers support for users to contribute to the evolution of web resources, by providing structured data artifacts as patches for web resources, as well as simple plain text comments. Based on this approach it enables crowd-supported quality assessment and web data cleansing processes in an ad-hoc fashion most web users are familiar with.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258592",
                    "name": "Natanael Arndt"
                },
                {
                    "authorId": "48555227",
                    "name": "K. Junghanns"
                },
                {
                    "authorId": "36476994",
                    "name": "R. Meissner"
                },
                {
                    "authorId": "3191004",
                    "name": "Philipp Frischmuth"
                },
                {
                    "authorId": "2096905450",
                    "name": "Norman Radtke"
                },
                {
                    "authorId": "2614811",
                    "name": "M. Frommhold"
                },
                {
                    "authorId": "2110607609",
                    "name": "Michael Martin"
                }
            ]
        }
    ]
}