{
    "authorId": "39772097",
    "papers": [
        {
            "paperId": "44bfa85742aff2175a50aeb3d928682d76a0fc2b",
            "title": "Dynamic Embedding-based Retrieval for Personalized Item Recommendations at Instacart",
            "abstract": "Personalization is essential in e-commerce, with item recommendation as a critical task. In this paper, we describe a hybrid embedding-based retrieval system for real-time personalized item recommendations on Instacart. Our system addresses unique challenges in the multi-source retrieval system, and includes several key components to make it highly personalized and dynamic. Specifically, our system features a hybrid embedding model that includes a long-term user interests embedding model and a real-time session-based model, which are combined to capture users\u2019 immediate intents and historical interactions. Additionally, we have developed a contextual bandit solution to dynamically adjust the number of candidates from each source and optimally allocate retrieval slots given a limited computational budget. Our modeling and system optimization efforts have enabled us to provide highly personalized item recommendations in real-time at scale to all our customers, including new and long-standing users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                },
                {
                    "authorId": "2203094914",
                    "name": "Allan Stewart"
                },
                {
                    "authorId": "2215791829",
                    "name": "Han Li"
                },
                {
                    "authorId": "2215623820",
                    "name": "Ryan Ye"
                },
                {
                    "authorId": "2880503",
                    "name": "D. Vengerov"
                },
                {
                    "authorId": "2109590665",
                    "name": "Haixun Wang"
                }
            ]
        },
        {
            "paperId": "4632bc6ac648ed2587f1d325300f4735413da230",
            "title": "Modern Theoretical Tools for Designing Information Retrieval System",
            "abstract": "In the past decade, deep learning has significantly reshaped the landscape of information retrieval (IR). The community has recently begun to notice the potential dangers of overusing less-understood mechanisms and over-simplified assumptions to learn patterns and make decisions. In particular, there is growing concerns on the interpretation, reliability, social impact, and long-term utility of real-world IR systems. Therefore, it has become a pressing issue to bring the IR community comprehensive and systematic tools to understand empirical domain solutions and motivate principled design ideas. We focus on the three pillar stones of modern IR systems: pattern recognition with deep learning, causal inference analysis, and online decision making (with bandits and reinforcement learning). Our objectives are as follows. For pattern recognition, we introduce theoretical tools that address the expressivity, optimization, generalization, and model diagnostic for widespread domain practices, including models from unsupervised, (semi-)supervised, meta-learning, and online learning. For causal inference analysis, we emphasize both learning from observational studies and optimizing online experiment design, leveraging the recent theoretical advancements from various domains. Finally, for online decision making (with bandits and reinforcement learning), we aim to resolve both the conceptual and practical learning, evaluation and deployment challenges by introducing powerful tools from robust optimization and optimal control. Our tutorial is inclusive: we not only cover a broad range of heating topics, more importantly, we substantiate our discussion with the production examples at Walmart and Instacart such that audiences with different backgrounds can learn to leverage the tools as instructed. Our tutorial can serve as a guideline for practitioners seeking justifications and principled design ideas, a playbook for researchers landing their innovations on IR productions, and an introductory course for those interested in learning the advanced topics and tools of IR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                }
            ]
        },
        {
            "paperId": "588b41d7a6d97fbf52fc7d4086752e6330951fc9",
            "title": "From Intervention to Domain Transportation: A Novel Perspective to Optimize Recommendation",
            "abstract": "The interventional nature of recommendation has attracted increasing attention in recent years. It particularly motivates researchers to formulate learning and evaluating recommendation as causal inference and data missing-not-at-random problems. However, few take seriously the consequence of violating the critical assumption of overlapping, which we prove can significantly threaten the validity and interpretation of the outcome. We find a critical piece missing in the current understanding of information retrieval (IR) systems: as interventions, recommendation not only affects the already observed data, but it also interferes with the target domain (distribution) of interest. We then rephrase optimizing recommendation as finding an intervention that best transports the patterns it learns from the observed domain to its intervention domain. Towards this end, we use domain transportation to characterize the learning-intervention mechanism of recommendation. We design a principled transportation-constraint risk minimization objective and convert it to a two-player minimax game. We prove the consistency, generalization, and excessive risk bounds for the proposed objective, and elaborate how they compare to the current results. Finally, we carry out extensive real-data and semi-synthetic experiments to demonstrate the advantage of our approach, and launch online testing with a real-world IR system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "2114058439",
                    "name": "Y. Ye"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                }
            ]
        },
        {
            "paperId": "c9c7519d69798523fd0c42a27b54918840b673c2",
            "title": "Modern Theoretical Tools for Understanding and Designing Next-generation Information Retrieval System",
            "abstract": "In the relatively short history of machine learning, the subtle balance between engineering and theoretical progress has been proved critical at various stages. The most recent wave of AI has brought to the IR community powerful techniques, particularly for pattern recognition. While many benefits from the burst of ideas as numerous tasks become algorithmically feasible, the balance is tilting toward the application side. The existing theoretical tools in IR can no longer explain, guide, and justify the newly-established methodologies. With no choices, we have to bet our design on black-box mechanisms that we only empirically understand. The consequences can be suffering: in stark contrast to how the IR industry has envisioned modern AI making life easier, many are experiencing increased confusion and costs in data manipulation, model selection, monitoring, censoring, and decision making. This reality is not surprising: without handy theoretical tools, we often lack principled knowledge of the pattern recognition model's expressivity, optimization property, generalization guarantee, and our decision-making process has to rely on over-simplified assumptions and human judgments from time to time. Facing all the challenges, we started researching advanced theoretical tools emerging from various domains that can potentially resolve modern IR problems. We encountered many impactful ideas and made several independent publications emphasizing different pieces. Time is now to bring the community a systematic tutorial on how we successfully adapt those tools and make significant progress in understanding, designing, and eventually productionize impactful IR systems. We emphasize systematicity because IR is a comprehensive discipline that touches upon particular aspects of learning, causal inference analysis, interactive (online) decision-making, etc. It thus requires systematic calibrations to render the actual usefulness of the imported theoretical tools to serve IR problems, as they usually exhibit unique structures and definitions. Therefore, we plan this tutorial to systematically demonstrate our learning and successful experience of using advanced theoretical tools for understanding and designing IR systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                }
            ]
        },
        {
            "paperId": "f7ae0a0a8d36ae99368aafff53240c69aa1cf680",
            "title": "Towards Robust Off-policy Learning for Runtime Uncertainty",
            "abstract": "Off-policy learning plays a pivotal role in optimizing and evaluating policies prior to the online deployment. However, during the real-time serving, we observe varieties of interventions and constraints that cause inconsistency between the online and offline setting, which we summarize and term as runtime uncertainty. Such uncertainty cannot be learned from the logged data due to its abnormality and rareness nature. To assert a certain level of robustness, we perturb the off-policy estimators along an adversarial direction in view of the runtime uncertainty. It allows the resulting estimators to be robust not only to observed but also unexpected runtime uncertainties. Leveraging this idea, we bring runtime-uncertainty robustness to three major off-policy learning methods: the inverse propensity score method, reward-model method, and doubly robust method. We theoretically justify the robustness of our methods to runtime uncertainty, and demonstrate their effectiveness using both the simulation and the real-world online experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "40508248",
                    "name": "Yuting Ye"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                },
                {
                    "authorId": "2156653838",
                    "name": "Bo Yang"
                }
            ]
        },
        {
            "paperId": "0f43fd68c211467371fb1398879042b303a5c359",
            "title": "Rethinking Neural vs. Matrix-Factorization Collaborative Filtering: the Theoretical Perspectives",
            "abstract": "The recent work by Rendle et al. (2020), based on empirical observations, argues that matrix-factorization collaborative filtering (MCF) compares favorably to neural collaborative filtering (NCF), and conjectures the dot product's superiority over the feed-forward neural network as similarity function. In this paper, we address the comparison rigorously by answering the following questions: 1. what is the limiting expressivity of each model; 2. under the practical gradient descent, to which solution does each optimization path converge; 3. how would the models generalize under the inductive and transductive learning setting. Our results highlight the similar expressivity for the overparameterized NCF and MCF as kernelized predictors, and reveal the relation between their optimization paths. We further show their different generalization behaviors, where MCF and NCF experience specific tradeoff and comparison in the transductive and inductive collaborative filtering setting. Lastly, by showing a novel generalization result, we reveal the critical role of correcting exposure bias for model evaluation in the inductive setting. Our results explain some of the previously observed conflicts, and we provide synthetic and real-data experiments to shed further insights to this topic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                },
                {
                    "authorId": "3064955",
                    "name": "Evren K\u00f6rpeoglu"
                },
                {
                    "authorId": "2119163223",
                    "name": "Sushant Kumar"
                },
                {
                    "authorId": "1684085",
                    "name": "Kannan Achan"
                }
            ]
        },
        {
            "paperId": "50180c7a80f78e76af4a924844fce9452ec9d200",
            "title": "Theoretical Understandings of Product Embedding for E-commerce Machine Learning",
            "abstract": "Product embeddings have been heavily investigated in the past few years, serving as the cornerstone for a broad range of machine learning applications in e-commerce. Despite the empirical success of product embeddings, little is known on how and why they work from the theoretical standpoint. Analogous results from the natural language processing (NLP) often rely on domain-specific properties that are not transferable to the e-commerce setting, and the downstream tasks often focus on different aspects of the embeddings. We take an e-commerce-oriented view of the product embeddings and reveal a complete theoretical view from both the representation learning and the learning theory perspective. We prove that product embeddings trained by the widely-adopted skip-gram negative sampling algorithm and its variants are sufficient dimension reduction regarding a critical product relatedness measure. The generalization performance in the downstream machine learning task is controlled by the alignment between the embeddings and the product relatedness measure. Following the theoretical discoveries, we conduct exploratory experiments that supports our theoretical insights for the product embeddings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                },
                {
                    "authorId": "81014296",
                    "name": "Evren Korpeoglu"
                },
                {
                    "authorId": "2119163223",
                    "name": "Sushant Kumar"
                },
                {
                    "authorId": "1684085",
                    "name": "Kannan Achan"
                }
            ]
        },
        {
            "paperId": "689d3394c674b8cb2906fa8ffb1c80ecc76e69d0",
            "title": "Understanding the role of importance weighting for deep learning",
            "abstract": "The recent paper by Byrd&Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justifications on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "40508248",
                    "name": "Yuting Ye"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                }
            ]
        },
        {
            "paperId": "ad594fcaf59b705180466c14df1aefcdab009dbd",
            "title": "A Temporal Kernel Approach for Deep Learning with Continuous-time Information",
            "abstract": "Sequential deep learning models such as RNN, causal CNN and attention mechanism do not readily consume continuous-time information. Discretizing the temporal data, as we show, causes inconsistency even for simple continuous-time processes. Current approaches often handle time in a heuristic manner to be consistent with the existing deep learning architectures and implementations. In this paper, we provide a principled way to characterize continuous-time systems using deep learning tools. Notably, the proposed approach applies to all the major deep learning architectures and requires little modifications to the implementation. The critical insight is to represent the continuous-time system by composing neural networks with a temporal kernel, where we gain our intuition from the recent advancements in understanding deep learning with Gaussian process and neural tangent kernel. To represent the temporal kernel, we introduce the random feature approach and convert the kernel learning problem to spectral density estimation under reparameterization. We further prove the convergence and consistency results even when the temporal kernel is non-stationary, and the spectral density is misspecified. The simulations and real-data experiments demonstrate the empirical effectiveness of our temporal kernel approach in a broad range of settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                },
                {
                    "authorId": "81014296",
                    "name": "Evren Korpeoglu"
                },
                {
                    "authorId": "2119163223",
                    "name": "Sushant Kumar"
                },
                {
                    "authorId": "1684085",
                    "name": "Kannan Achan"
                }
            ]
        },
        {
            "paperId": "d3b49c3dc4e81867160c84fac66368afc433ae90",
            "title": "Towards the D-Optimal Online Experiment Design for Recommender Selection",
            "abstract": "Selecting the optimal recommender via online exploration-exploitation is catching increasing attention where the traditional A/B testing can be slow and costly, and offline evaluations are prone to the bias of history data. Finding the optimal online experiment is nontrivial since both the users and displayed recommendations carry contextual features that are informative to the reward. While the problem can be formalized via the lens of multi-armed bandits, the existing solutions are found less satisfactorily because the general methodologies do not account for the case-specific structures, particularly for the e-commerce recommendation we study. To fill in the gap, we leverage the D-optimal design from the classical statistics literature to achieve the maximum information gain during exploration, and reveal how it fits seamlessly with the modern infrastructure of online inference. To demonstrate the effectiveness of the optimal designs, we provide semi-synthetic simulation studies with published code and data for reproducibility purposes. We then use our deployment example on Walmart.com to fully illustrate the practical insights and effectiveness of the proposed methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2118285164",
                    "name": "Da Xu"
                },
                {
                    "authorId": "39772097",
                    "name": "Chuanwei Ruan"
                },
                {
                    "authorId": "81014296",
                    "name": "Evren Korpeoglu"
                },
                {
                    "authorId": "2119163223",
                    "name": "Sushant Kumar"
                },
                {
                    "authorId": "2120209935",
                    "name": "Kannan Achan"
                }
            ]
        }
    ]
}