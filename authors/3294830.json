{
    "authorId": "3294830",
    "papers": [
        {
            "paperId": "0c6a9ddaa0fef4138a03625beb927faec3d4760d",
            "title": "Multi-Modal Attribute Extraction for E-Commerce",
            "abstract": "To improve users' experience as they navigate the myriad of options offered by online marketplaces, it is essential to have well-organized product catalogs. One key ingredient to that is the availability of product attributes such as color or material. However, on some marketplaces such as Rakuten-Ichiba, which we focus on, attribute information is often incomplete or even missing. One promising solution to this problem is to rely on deep models pre-trained on large corpora to predict attributes from unstructured data, such as product descriptive texts and images (referred to as modalities in this paper). However, we find that achieving satisfactory performance with this approach is not straightforward but rather the result of several refinements, which we discuss in this paper. We provide a detailed description of our approach to attribute extraction, from investigating strong single-modality methods, to building a solid multimodal model combining textual and visual information. One key component of our multimodal architecture is a novel approach to seamlessly combine modalities, which is inspired by our single-modality investigations. In practice, we notice that this new modality-merging method may suffer from a modality collapse issue, i.e., it neglects one modality. Hence, we further propose a mitigation to this problem based on a principled regularization scheme. Experiments on Rakuten-Ichiba data provide empirical evidence for the benefits of our approach, which has been also successfully deployed to Rakuten-Ichiba. We also report results on publicly available datasets showing that our model is competitive compared to several recent multimodal and unimodal baselines.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2124421551",
                    "name": "Alo\u00efs de La Comble"
                },
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                },
                {
                    "authorId": "2057535114",
                    "name": "Pablo Montalvo"
                },
                {
                    "authorId": "2911888",
                    "name": "Aghiles Salah"
                }
            ]
        },
        {
            "paperId": "aa2fdbaf895bbaa72526eadbcf226e4d34d187a1",
            "title": "Continual learning for image classification",
            "abstract": "This thesis deals with deep learning applied to image classification tasks. The primary motivation for the work is to make current deep learning techniques more efficient and to deal with changes in the data distribution. We work in the broad framework of continual learning, with the aim to have in the future machine learning models that can continuously improve.We first look at change in label space of a data set, with the data samples themselves remaining the same. We consider a semantic label hierarchy to which the labels belong. We investigate how we can utilise this hierarchy for obtaining improvements in models which were trained on different levels of this hierarchy.The second and third contribution involve continual learning using a generative model. We analyse the usability of samples from a generative model in the case of training good discriminative classifiers. We propose techniques to improve the selection and generation of samples from a generative model. Following this, we observe that continual learning algorithms do undergo some loss in performance when trained on several tasks sequentially. We analyse the training dynamics in this scenario and compare with training on several tasks simultaneously. We make observations that point to potential difficulties in the learning of models in a continual learning scenario.Finally, we propose a new design template for convolutional networks. This architecture leads to training of smaller models without compromising performance. In addition the design lends itself to easy parallelisation, leading to efficient distributed training.In conclusion, we look at two different types of continual learning scenarios. We propose methods that lead to improvements. Our analysis also points to greater issues, to over come which we might need changes in our current neural network training procedure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                }
            ]
        },
        {
            "paperId": "cc43a9b7edf160cf2ce87dbe903fa4de1f3ec07f",
            "title": "Classifier Training from a Generative Model",
            "abstract": "We investigate the samples derived from generative adversarial networks (GAN) from a classification perspective. We train a classifier on generated samples and on real data and see how they compared on a held out validation set. We see that recent GAN models which produce visually convincing samples are not yet able to match the training on real data. To analyse this we compare training a classifier on generated samples and various sizes of the real training set. We propose architectural and algorithmic changes to reduce this gap. First, we show that a modification to the GAN architecture is needed, which leads to improve generation of samples. Second, we use multiple GAN models as a way to cover the real data distribution, again leading to improvement in classifier training. We also show that in the case of training on small number of samples, a GAN model provides better compression in terms of storage requirements as compared to the real data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066842526",
                    "name": "Pham Thanh Dat"
                },
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                },
                {
                    "authorId": "31617713",
                    "name": "D. Pellerin"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "22edae24dc3b492579ed4c1aa0297a259fa5e2f2",
            "title": "Towards Incremental Learning with Deep Convolutional Networks",
            "abstract": "Deep neural networks are a powerful class of machine learning models. However they require a lot of time and computational resources to train. We propose to apply an incremental learning approach to train models by utilizing the information present in pre-trained models. We build towards this goal by studying the relationship between network architecture, categories in training data, the amount of training data, and the \u2018nature\u2019 of the data. We present our findings on the effect of varying network architectures with respect to the data. We investigate training models in scenarios where the discriminatory power of a model has to be increased, even for the same data set on which it has already been trained. The results are pointers towards having an optimal architecture for a specific task. The work is done in the context of convolutional neural networks and the performance is measured in terms of accuracy on an image classification task. MOTS-CL\u00c9S : l\u2019Apprentissage en Profondeur, Indexation Multim\u00e9dia Apprentissage Progressif Vision par Ordinateur",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                }
            ]
        },
        {
            "paperId": "822011134d2ae73c7ad5df8ae1ef345d01a90f6f",
            "title": "Improving Image Classification using Coarse and Fine Labels",
            "abstract": "The performance of classifiers is in general improved by designing models with a large number of parameters or by ensembles. We tackle the problem of classification of coarse and fine grained categories, which share a semantic relationship. On being given the predictions that a classifier has for a given test sample, we adjust the probabilities according to the semantics of the categories, on which the classifier was trained. We present an algorithm for doing such an adjustment and we demonstrate improvement for both coarse and fine grained classification. We evaluate our method using convolutional neural networks. However, the algorithm can be applied to any classifier which outputs category wise probabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                },
                {
                    "authorId": "31617713",
                    "name": "D. Pellerin"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "cf41558802e944b52306037ebf4e21989526193c",
            "title": "Improving Hierarchical Image Classification with Merged CNN Architectures",
            "abstract": "We consider the problem of image classification using deep convolutional networks, with respect to hierarchical relationships among classes. We investigate if the semantic hierarchy is captured by CNN models or not. For this we analyze the confidence of the model for a category and its sub-categories. Based on the results, we propose an algorithm for improving the model performance at test time by adapting the classifier to each test sample and without any re-training. Secondly, we propose a strategy for merging models for jointly learning two levels of hierarchy. This reduces the total training time as compared to training models separately, and also gives improved classification performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                },
                {
                    "authorId": "31617713",
                    "name": "D. Pellerin"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        },
        {
            "paperId": "f1c55047a7b8f177f874e7968186e5915e061aa1",
            "title": "Coupled Ensembles of Neural Networks",
            "abstract": "We investigate in this paper architectures of deep convolutional networks. Building on existing state of the art models, we propose a reconfiguration of the model parameters into several parallel branches at the global network level, each branch being a standalone CNN. We show that this arrangement is an efficient way to significantly reduce the number of parameters while at the same time improving the performance. The use of branches brings an additional form of regularization. In addition to splitting the parameters into parallel branches, we propose a tighter coupling of these branches by averaging their log-probabilities. The tighter coupling favours the learning of better representations, even at the level of the individual branches, as compared to when each branch is trained independently. We refer to this branched architecture as \u201ccoupled ensembles\u201d. The approach is generic and can be applied to almost any neural network architecture. With coupled ensembles of DenseNet-BC networks and a 25M-parameter budget, we obtain error rates of 2.92%, 15.68% and 1.50% on CIFAR-10, CIFAR-100 and SVHN respectively. For the same parameter budget, DenseNet-Bchas an error rate of 3.46%, 17.18%, and 1.8% respectively. With ensembles of coupled ensembles of DenseNet-BC networks with a 50M-parameter budget, we obtain error rates of 2.72%, 15.13% and 1.42 % respectively on these tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3294830",
                    "name": "Anuvabh Dutt"
                },
                {
                    "authorId": "31617713",
                    "name": "D. Pellerin"
                },
                {
                    "authorId": "1693391",
                    "name": "G. Qu\u00e9not"
                }
            ]
        }
    ]
}