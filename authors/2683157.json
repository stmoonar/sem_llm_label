{
    "authorId": "2683157",
    "papers": [
        {
            "paperId": "1234d66132d12694d2f0b074fca6149eba139bf2",
            "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
            "abstract": "Spatial reasoning, an important faculty of human cognition with many practical applications, is one of the core commonsense skills that is not purely language-based and, for satisfying (as opposed to optimal) solutions, requires some minimum degree of planning. Existing benchmarks of Commonsense Spatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs) interpret text-based spatial descriptions rather than directly evaluate a plan produced by the LLM in response to a spatial reasoning scenario. In this paper, we construct a large-scale benchmark called $\\textbf{GRASP}$, which consists of 16,000 grid-based environments where the agent is tasked with an energy collection problem. These environments include 100 grid instances instantiated using each of the 160 different grid settings, involving five different energy distributions, two modes of agent starting position, and two distinct obstacle configurations, as well as three kinds of agent constraints. Using GRASP, we compare classic baseline approaches, such as random walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo and GPT-4o. The experimental results indicate that even these advanced LLMs struggle to consistently achieve satisfactory solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184288151",
                    "name": "Zhi\u2013Bin Tang"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        },
        {
            "paperId": "21452f60e63d312366221f8c998d12923ba8bbff",
            "title": "Designing Social Good Semantic Computing Architectures for the Long Tail: Case Studies, Evaluation, and Challenges",
            "abstract": "Many real-world systems, especially systems characterized by high social activity (such as the Web), tend to obey power law distributions and thereby have a significant \u2018long tail\u2019. We argue that researching, developing and designing semantic computing systems for the long tail, especially dependent on inductive AI, constitutes an important class of problems, not least because the long tail is challenging both technically and socially. By its very nature, the long tail is irregular, testing the generalization capabilities of the state-of-the-art, especially in architectures and interfaces that are built on some form of machine learning or statistical inference (including large language models). As machine learning and generative AI continues to be integrated into more front facing systems, the issue of the long tail cannot be ignored by either the systems engineering or the AI communities. We present two case studies with important social consequences (fighting human trafficking online, and managing information effectively and in real-time during humanitarian crises) where semantic computing and AI platforms specifically designed to handle long-tail challenges find critical application, and sometimes with drastically different design choices compared to designing only for the short tail (with the main goal of maximizing average accuracy).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        },
        {
            "paperId": "277807da936c0de0043d133e27ed4adf8fe68eab",
            "title": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference",
            "abstract": "Despite their impressive performance, large language models (LLMs) such as ChatGPT are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the models have in their inference. While the former is well studied, the latter is not, leading to an asymmetry in understanding the comprehensive risk of the model based on misplaced confidence. In this paper, we address this asymmetry by defining two types of risk (decision and composite risk), and proposing an experimental framework consisting of a two-level inference architecture and appropriate metrics for measuring such risks in both discriminative and generative LLMs. The first level relies on a decision rule that determines whether the underlying language model should abstain from inference. The second level (which applies if the model does not abstain) is the model's inference. Detailed experiments on four natural language commonsense reasoning datasets using both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate the practical utility of the evaluation framework. For example, our results show that our framework can get an LLM to confidently respond to an extra 20.1% of low-risk inference tasks that other methods might misclassify as high-risk, and skip 19.8% of high-risk tasks, which would have been answered incorrectly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2006106789",
                    "name": "Ke Shen"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        },
        {
            "paperId": "7aee8805ef91275dc720a0322c47e217d6a7eaec",
            "title": "SelECT-SQL: Self-correcting ensemble Chain-of-Thought for Text-to-SQL",
            "abstract": "In recent years,Text-to-SQL, the problem of automatically converting questions posed in natural language to formal SQL queries, has emerged as an important problem at the intersection of natural language processing and data management research. Large language models (LLMs) have delivered impressive performance when used in an off-the-shelf performance, but still fall significantly short of expected expert-level performance. Errors are especially probable when a nuanced understanding is needed of database schemas, questions, and SQL clauses to do proper Text-to-SQL conversion. We introduce SelECT-SQL, a novel in-context learning solution that uses an algorithmic combination of chain-of-thought (CoT) prompting, self-correction, and ensemble methods to yield a new state-of-the-art result on challenging Text-to-SQL benchmarks. Specifically, when configured using GPT-3.5-Turbo as the base LLM, SelECT-SQL achieves 84.2% execution accuracy on the Spider leaderboard's development set, exceeding both the best results of other baseline GPT-3.5-Turbo-based solutions (81.1%), and the peak performance (83.5%) of the GPT-4 result reported on the leaderboard.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2006106789",
                    "name": "Ke Shen"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        },
        {
            "paperId": "8814506879539da0c50b0b6611c3830ec17e7706",
            "title": "An Evaluation of Estimative Uncertainty in Large Language Models",
            "abstract": "Words of estimative probability (WEPs), such as ''maybe'' or ''probably not'' are ubiquitous in natural language for communicating estimative uncertainty, compared with direct statements involving numerical probability. Human estimative uncertainty, and its calibration with numerical estimates, has long been an area of study -- including by intelligence agencies like the CIA. This study compares estimative uncertainty in commonly used large language models (LLMs) like GPT-4 and ERNIE-4 to that of humans, and to each other. Here we show that LLMs like GPT-3.5 and GPT-4 align with human estimates for some, but not all, WEPs presented in English. Divergence is also observed when the LLM is presented with gendered roles and Chinese contexts. Further study shows that an advanced LLM like GPT-4 can consistently map between statistical and estimative uncertainty, but a significant performance gap remains. The results contribute to a growing body of research on human-LLM alignment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184288151",
                    "name": "Zhi\u2013Bin Tang"
                },
                {
                    "authorId": "2006106789",
                    "name": "Ke Shen"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        },
        {
            "paperId": "d990e55827d5fd53a753a7247e2020f830225751",
            "title": "Is persona enough for personality? Using ChatGPT to reconstruct an agent's latent personality from simple descriptions",
            "abstract": "Personality, a fundamental aspect of human cognition, contains a range of traits that influence behaviors, thoughts, and emotions. This paper explores the capabilities of large language models (LLMs) in reconstructing these complex cognitive attributes based only on simple descriptions containing socio-demographic and personality type information. Utilizing the HEXACO personality framework, our study examines the consistency of LLMs in recovering and predicting underlying (latent) personality dimensions from simple descriptions. Our experiments reveal a significant degree of consistency in personality reconstruction, although some inconsistencies and biases, such as a tendency to default to positive traits in the absence of explicit information, are also observed. Additionally, socio-demographic factors like age and number of children were found to influence the reconstructed personality dimensions. These findings have implications for building sophisticated agent-based simulacra using LLMs and highlight the need for further research on robust personality generation in LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2308011388",
                    "name": "Yongyi Ji"
                },
                {
                    "authorId": "2184288151",
                    "name": "Zhi\u2013Bin Tang"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        },
        {
            "paperId": "feb29a0618b030856b9b22ef24a9d62e38371d53",
            "title": "Multipartite Entity Resolution: Motivating a K-Tuple Perspective (Student Abstract)",
            "abstract": "Entity Resolution (ER) is the problem of algorithmically matching records, mentions, or entries that refer to the same underlying real-world entity. Traditionally, the problem assumes (at most) two datasets, between which records need to be matched. There is considerably less research in ER when k > 2 datasets are involved. The evaluation of such multipartite ER (M-ER) is especially complex, since the usual ER metrics assume (whether implicitly or explicitly) k < 3. This paper takes the first step towards motivating a k-tuple approach for evaluating M-ER. Using standard algorithms and k-tuple versions of metrics like precision and recall, our preliminary results suggest a significant difference compared to aggregated pairwise evaluation, which would first decompose the M-ER problem into independent bipartite problems and then aggregate their metrics. Hence, M-ER may be more challenging and warrant more novel approaches than current decomposition-based pairwise approaches would suggest.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280154852",
                    "name": "Adin Aberbach"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                },
                {
                    "authorId": "2006106789",
                    "name": "Ke Shen"
                }
            ]
        },
        {
            "paperId": "05d8475641dfb996c5d979c200a0756b096b590e",
            "title": "A Knowledge Graph-Based Search Engine for Robustly Finding Doctors and Locations in the Healthcare Domain",
            "abstract": "Efficiently finding doctors and locations is an important search problem for patients in the healthcare domain, for which traditional information retrieval methods tend not to work optimally. In the last ten years, knowledge graphs (KGs) have emerged as a powerful way to combine the benefits of gleaning insights from semi-structured data using semantic modeling, natural language processing techniques like information extraction, and robust querying using structured query languages like SPARQL and Cypher. In this short paper, we present a KG-based search engine architecture for robustly finding doctors and locations in the healthcare domain. Early results demonstrate that our approach can lead to significantly higher coverage for complex queries without degrading quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                },
                {
                    "authorId": "2233087223",
                    "name": "Hamid Haidarian"
                },
                {
                    "authorId": "2256995535",
                    "name": "Min-Hsueh Chiu"
                },
                {
                    "authorId": "2233087213",
                    "name": "Andy Xiang"
                },
                {
                    "authorId": "2233087257",
                    "name": "Deep Shrestha"
                },
                {
                    "authorId": "2256995575",
                    "name": "Faizan Javed"
                }
            ]
        },
        {
            "paperId": "2c9ff3d79df969a3b5df6b22c47f782f9be250c7",
            "title": "Understanding and Estimating Domain Complexity Across Domains",
            "abstract": "Artificial Intelligence (AI) systems, trained in controlled environments, often struggle in real-world complexities. We propose a general framework for estimating domain complexity across diverse environments, like open-world learning and real-world applications. This framework distinguishes between intrinsic complexity (inherent to the domain) and extrinsic complexity (dependent on the AI agent). By analyzing dimensionality, sparsity, and diversity within these categories, we offer a comprehensive view of domain challenges. This approach enables quantitative predictions of AI difficulty during environment transitions, avoids bias in novel situations, and helps navigate the vast search spaces of open-world domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275599884",
                    "name": "Katarina Doctor"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                },
                {
                    "authorId": "2275596001",
                    "name": "Lawrence Holder"
                },
                {
                    "authorId": "47784913",
                    "name": "Eric J. Kildebeck"
                },
                {
                    "authorId": "108587053",
                    "name": "Emma Resmini"
                },
                {
                    "authorId": "118235535",
                    "name": "Christopher Pereyda"
                },
                {
                    "authorId": "49004376",
                    "name": "Robert J. Steininger"
                },
                {
                    "authorId": "35781507",
                    "name": "Daniel V. Oliven\u00e7a"
                }
            ]
        },
        {
            "paperId": "30669080bc6652f0466fba618b7c59317a346fb2",
            "title": "A Formalism and Approach for Improving Robustness of Large Language Models Using Risk-Adjusted Confidence Scores",
            "abstract": "Large Language Models (LLMs), such as ChatGPT, have achieved impressive milestones in natural language processing (NLP). Despite their impressive performance, the models are known to pose important risks. As these models are deployed in real-world applications, a systematic understanding of different risks posed by these models on tasks such as natural language inference (NLI), is much needed. In this paper, we define and formalize two distinct types of risk: decision risk and composite risk. We also propose a risk-centric evaluation framework, and four novel metrics, for assessing LLMs on these risks in both in-domain and out-of-domain settings. Finally, we propose a risk-adjusted calibration method called DwD for helping LLMs minimize these risks in an overall NLI architecture. Detailed experiments, using four NLI benchmarks, three baselines and two LLMs, including ChatGPT, show both the practical utility of the evaluation framework, and the efficacy of DwD in reducing decision and composite risk. For instance, when using DwD, an underlying LLM is able to address an extra 20.1% of low-risk inference tasks (but which the LLM erroneously deems high-risk without risk adjustment) and skip a further 19.8% of high-risk tasks, which would have been answered incorrectly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2006106789",
                    "name": "Ke Shen"
                },
                {
                    "authorId": "2683157",
                    "name": "M. Kejriwal"
                }
            ]
        }
    ]
}