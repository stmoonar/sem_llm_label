{
    "authorId": "46649145",
    "papers": [
        {
            "paperId": "49873ee415619efd9e1e4c16f73ee066ff008c1f",
            "title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies",
            "abstract": "The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This scenario underscores the importance of exploring the potential of Small Language Models (SLMs) as a resource-efficient alternative. In this context, we introduce MiniCPM, specifically the 1.2B and 2.4B non-embedding parameter variants, not only excel in their respective categories but also demonstrate capabilities on par with 7B-13B LLMs. While focusing on SLMs, our approach exhibits scalability in both model and data dimensions for future LLM research. Regarding model scaling, we employ extensive model wind tunnel experiments for stable and optimal scaling. For data scaling, we introduce a Warmup-Stable-Decay (WSD) learning rate scheduler (LRS), conducive to continuous training and domain adaptation. We present an in-depth analysis of the intriguing training dynamics that occurred in the WSD LRS. With WSD LRS, we are now able to efficiently study data-model scaling law without extensive retraining experiments on both axes of model and data, from which we derive the much higher compute optimal data-model ratio than Chinchilla Optimal. Additionally, we introduce MiniCPM family, including MiniCPM-DPO, MiniCPM-MoE and MiniCPM-128K, whose excellent performance further cementing MiniCPM's foundation in diverse SLM applications. MiniCPM models are available publicly at https://github.com/OpenBMB/MiniCPM .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1576223501",
                    "name": "Shengding Hu"
                },
                {
                    "authorId": "2295757664",
                    "name": "Yuge Tu"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2256951801",
                    "name": "Chaoqun He"
                },
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "2295733503",
                    "name": "Xiang Long"
                },
                {
                    "authorId": "2295929465",
                    "name": "Zhi Zheng"
                },
                {
                    "authorId": "2295846809",
                    "name": "Yewei Fang"
                },
                {
                    "authorId": "2214586078",
                    "name": "Yuxiang Huang"
                },
                {
                    "authorId": "2150606888",
                    "name": "Weilin Zhao"
                },
                {
                    "authorId": "2254576790",
                    "name": "Xinrong Zhang"
                },
                {
                    "authorId": "2284862784",
                    "name": "Zhen Leng Thai"
                },
                {
                    "authorId": "2295817905",
                    "name": "Kaihuo Zhang"
                },
                {
                    "authorId": "2249899670",
                    "name": "Chongyi Wang"
                },
                {
                    "authorId": "1390925224",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "2267866399",
                    "name": "Chenyang Zhao"
                },
                {
                    "authorId": "2295789325",
                    "name": "Jie Zhou"
                },
                {
                    "authorId": "2295809950",
                    "name": "Jie Cai"
                },
                {
                    "authorId": "2295733180",
                    "name": "Zhongwu Zhai"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2279190843",
                    "name": "Chaochao Jia"
                },
                {
                    "authorId": "1398454307",
                    "name": "Guoyang Zeng"
                },
                {
                    "authorId": "2144118403",
                    "name": "Dahai Li"
                },
                {
                    "authorId": "2269703458",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2273551430",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "5ba130279094e4766d0bbac5b4915d595cc84ed7",
            "title": "UltraMedical: Building Specialized Generalists in Biomedicine",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains and are moving towards more specialized areas. Recent advanced proprietary models such as GPT-4 and Gemini have achieved significant advancements in biomedicine, which have also raised privacy and security challenges. The construction of specialized generalists hinges largely on high-quality datasets, enhanced by techniques like supervised fine-tuning and reinforcement learning from human or AI feedback, and direct preference optimization. However, these leading technologies (e.g., preference learning) are still significantly limited in the open source community due to the scarcity of specialized data. In this paper, we present the UltraMedical collections, which consist of high-quality manual and synthetic datasets in the biomedicine domain, featuring preference annotations across multiple advanced LLMs. By utilizing these datasets, we fine-tune a suite of specialized medical models based on Llama-3 series, demonstrating breathtaking capabilities across various medical benchmarks. Moreover, we develop powerful reward models skilled in biomedical and general reward benchmark, enhancing further online preference learning within the biomedical LLM community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153281320",
                    "name": "Kaiyan Zhang"
                },
                {
                    "authorId": "2266239265",
                    "name": "Sihang Zeng"
                },
                {
                    "authorId": "2290020564",
                    "name": "Ermo Hua"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2266267133",
                    "name": "Zhang-Ren Chen"
                },
                {
                    "authorId": "2274219908",
                    "name": "Zhiyuan Ma"
                },
                {
                    "authorId": "2305255487",
                    "name": "Haoxin Li"
                },
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "66242399",
                    "name": "Biqing Qi"
                },
                {
                    "authorId": "2145238612",
                    "name": "Xuekai Zhu"
                },
                {
                    "authorId": "2221271501",
                    "name": "Xingtai Lv"
                },
                {
                    "authorId": "2304951738",
                    "name": "Jinfang Hu"
                },
                {
                    "authorId": "2273470196",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2218723159",
                    "name": "Bowen Zhou"
                }
            ]
        },
        {
            "paperId": "a8b1484d3ee6b9ad6e4c48d6bcdbd1048493599d",
            "title": "Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models",
            "abstract": "Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a high-quality supervised instruction tuning dataset, UltraChat 2, which includes text, code, and mathematical content. This dataset comprises approximately 300,000 instructions and covers a wide range of topics in each domain. Experiments show that our model could simultaneously achieve mastery of the three crucial domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2135835258",
                    "name": "Yulin Chen"
                },
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "2221271501",
                    "name": "Xingtai Lv"
                },
                {
                    "authorId": "2257007994",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "2218723159",
                    "name": "Bowen Zhou"
                },
                {
                    "authorId": "2273470196",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2273551430",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "ac2848656e68b60665e6bc3e28eb6c7d5bebb4b0",
            "title": "Advancing LLM Reasoning Generalists with Preference Trees",
            "abstract": "We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning. Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve state-of-the-art results among open-source models on a diverse set of benchmarks covering mathematics, code generation, and logical reasoning problems. Notably, Eurus-70B beats GPT-3.5 Turbo in reasoning through a comprehensive benchmarking across 12 tests covering five tasks, and achieves a 33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging benchmarks, substantially outperforming existing open-source models by margins more than 13.3%. The strong performance of Eurus can be primarily attributed to UltraInteract, our newly-curated large-scale, high-quality alignment dataset specifically designed for complex reasoning tasks. UltraInteract can be used in both supervised fine-tuning and preference learning. For each instruction, it includes a preference tree consisting of (1) reasoning chains with diverse planning strategies in a unified format, (2) multi-turn interaction trajectories with the environment and the critique, and (3) pairwise data to facilitate preference learning. UltraInteract allows us to conduct an in-depth exploration of preference learning for reasoning tasks. Our investigation reveals that some well-established preference learning algorithms may be less suitable for reasoning tasks compared to their effectiveness in general conversations. Inspired by this, we derive a novel reward modeling objective which, together with UltraInteract, leads to a strong reward model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152195191",
                    "name": "Lifan Yuan"
                },
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "2267230996",
                    "name": "Hanbin Wang"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2144803999",
                    "name": "Xingyao Wang"
                },
                {
                    "authorId": "2284299688",
                    "name": "Jia Deng"
                },
                {
                    "authorId": "2294571512",
                    "name": "Boji Shan"
                },
                {
                    "authorId": "2155553997",
                    "name": "Huimin Chen"
                },
                {
                    "authorId": "2257007994",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "2427350",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "49047064",
                    "name": "Zhenghao Liu"
                },
                {
                    "authorId": "2218723159",
                    "name": "Bowen Zhou"
                },
                {
                    "authorId": "2254026935",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2273470196",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2273551430",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "c21022a4dca7b1a32d2f79818cb7e51df712372f",
            "title": "UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset",
            "abstract": "Open-source large language models (LLMs) have gained significant strength across diverse fields. Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual abilities. In this work, we therefore construct an open-source multilingual supervised fine-tuning dataset. Different from previous works that simply translate English instructions, we consider both the language-specific and language-agnostic abilities of LLMs. Firstly, we introduce a knowledge-grounded data augmentation approach to elicit more language-specific knowledge of LLMs, improving their ability to serve users from different countries. Moreover, we find modern LLMs possess strong cross-lingual transfer capabilities, thus repeatedly learning identical content in various languages is not necessary. Consequently, we can substantially prune the language-agnostic supervised fine-tuning (SFT) data without any performance degradation, making multilingual SFT more efficient. The resulting UltraLink dataset comprises approximately 1 million samples across five languages (i.e., En, Zh, Ru, Fr, Es), and the proposed data construction method can be easily extended to other languages. UltraLink-LM, which is trained on UltraLink, outperforms several representative baselines across many tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283173813",
                    "name": "Haoyu Wang"
                },
                {
                    "authorId": "2267033597",
                    "name": "Shuo Wang"
                },
                {
                    "authorId": "2277242040",
                    "name": "Yukun Yan"
                },
                {
                    "authorId": "2283197093",
                    "name": "Xujia Wang"
                },
                {
                    "authorId": "2283302531",
                    "name": "Zhiyu Yang"
                },
                {
                    "authorId": "2239055610",
                    "name": "Yuzhuang Xu"
                },
                {
                    "authorId": "49047064",
                    "name": "Zhenghao Liu"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2273551430",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "352420ee61a8da783ca7750170793613b18b8d9c",
            "title": "Tool Learning with Foundation Models",
            "abstract": "Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool learning framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate the generalization in tool learning. Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 18 representative tools and show the potential of current foundation models in skillfully utilizing tools. Finally, we discuss several open problems that require further investigation for tool learning. In general, we hope this paper could inspire future research in integrating tools with foundation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "1576223501",
                    "name": "Shengding Hu"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "2109136284",
                    "name": "Weize Chen"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "1633538428",
                    "name": "Zheni Zeng"
                },
                {
                    "authorId": "2115640120",
                    "name": "Yufei Huang"
                },
                {
                    "authorId": "51131083",
                    "name": "Chaojun Xiao"
                },
                {
                    "authorId": "2118642562",
                    "name": "Chi Han"
                },
                {
                    "authorId": "51135899",
                    "name": "Y. Fung"
                },
                {
                    "authorId": "48576745",
                    "name": "Yusheng Su"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "2082473972",
                    "name": "Cheng Qian"
                },
                {
                    "authorId": "2214603370",
                    "name": "Runchu Tian"
                },
                {
                    "authorId": "2214586034",
                    "name": "Kunlun Zhu"
                },
                {
                    "authorId": "2163374235",
                    "name": "Shi Liang"
                },
                {
                    "authorId": "145781166",
                    "name": "Xingyu Shen"
                },
                {
                    "authorId": "2052218689",
                    "name": "Bokai Xu"
                },
                {
                    "authorId": "2170500945",
                    "name": "Zhen Zhang"
                },
                {
                    "authorId": "2114059497",
                    "name": "Yining Ye"
                },
                {
                    "authorId": "2155882844",
                    "name": "Bo Li"
                },
                {
                    "authorId": "2214664440",
                    "name": "Ziwei Tang"
                },
                {
                    "authorId": "2106388389",
                    "name": "Jing Yi"
                },
                {
                    "authorId": "2109388429",
                    "name": "Yu Zhu"
                },
                {
                    "authorId": "2146517842",
                    "name": "Zhenning Dai"
                },
                {
                    "authorId": "2214613855",
                    "name": "Lan Yan"
                },
                {
                    "authorId": "2214579778",
                    "name": "Xin Cong"
                },
                {
                    "authorId": "2191753738",
                    "name": "Ya-Ting Lu"
                },
                {
                    "authorId": "2150606888",
                    "name": "Weilin Zhao"
                },
                {
                    "authorId": "2214586078",
                    "name": "Yuxiang Huang"
                },
                {
                    "authorId": "2213334016",
                    "name": "Jun-Han Yan"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2143570016",
                    "name": "Xian Sun"
                },
                {
                    "authorId": "2144118403",
                    "name": "Dahai Li"
                },
                {
                    "authorId": "80842917",
                    "name": "Jason Phang"
                },
                {
                    "authorId": "3443627",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "2116417519",
                    "name": "Tongshuang Wu"
                },
                {
                    "authorId": "2072975663",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "3e826e52754d0876611c8cf2fa7a781a701c39e6",
            "title": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models",
            "abstract": "The unprecedented performance of large language models (LLMs) necessitates improvements in evaluations. Rather than merely exploring the breadth of LLM abilities, we believe meticulous and thoughtful designs are essential to thorough, unbiased, and applicable evaluations. Given the importance of world knowledge to LLMs, we construct a Knowledge-oriented LLM Assessment benchmark (KoLA), in which we carefully design three crucial factors: (1) For \\textbf{ability modeling}, we mimic human cognition to form a four-level taxonomy of knowledge-related abilities, covering $19$ tasks. (2) For \\textbf{data}, to ensure fair comparisons, we use both Wikipedia, a corpus prevalently pre-trained by LLMs, along with continuously collected emerging corpora, aiming to evaluate the capacity to handle unseen data and evolving knowledge. (3) For \\textbf{evaluation criteria}, we adopt a contrastive system, including overall standard scores for better numerical comparability across tasks and models and a unique self-contrast metric for automatically evaluating knowledge-creating ability. We evaluate $28$ open-source and commercial LLMs and obtain some intriguing findings. The KoLA dataset and open-participation leaderboard are publicly released at https://kola.xlore.cn and will be continuously updated to provide references for developing LLMs and knowledge-related systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116034394",
                    "name": "Jifan Yu"
                },
                {
                    "authorId": "48631777",
                    "name": "Xiaozhi Wang"
                },
                {
                    "authorId": "2116520118",
                    "name": "Shangqing Tu"
                },
                {
                    "authorId": "1712738522",
                    "name": "S. Cao"
                },
                {
                    "authorId": "2165225735",
                    "name": "Daniel Zhang-li"
                },
                {
                    "authorId": "48574888",
                    "name": "Xin Lv"
                },
                {
                    "authorId": "47837854",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "1423719712",
                    "name": "Zijun Yao"
                },
                {
                    "authorId": "2181337399",
                    "name": "Xiaohan Zhang"
                },
                {
                    "authorId": "2188777141",
                    "name": "Hanming Li"
                },
                {
                    "authorId": "2118001750",
                    "name": "Chun-yan Li"
                },
                {
                    "authorId": "2257434341",
                    "name": "Zheyuan Zhang"
                },
                {
                    "authorId": "2141377570",
                    "name": "Yushi Bai"
                },
                {
                    "authorId": "2211723524",
                    "name": "Yantao Liu"
                },
                {
                    "authorId": "2220101512",
                    "name": "Amy Xin"
                },
                {
                    "authorId": "2210119346",
                    "name": "Nianyi Lin"
                },
                {
                    "authorId": "2220099357",
                    "name": "Kaifeng Yun"
                },
                {
                    "authorId": "2220092688",
                    "name": "Linlu Gong"
                },
                {
                    "authorId": "2220188202",
                    "name": "Jianhui Chen"
                },
                {
                    "authorId": "2220655963",
                    "name": "Zhili Wu"
                },
                {
                    "authorId": "121817444",
                    "name": "Y. Qi"
                },
                {
                    "authorId": "2143447165",
                    "name": "Weikai Li"
                },
                {
                    "authorId": "2069570219",
                    "name": "Yong Guan"
                },
                {
                    "authorId": "10673612",
                    "name": "Kaisheng Zeng"
                },
                {
                    "authorId": "2091076497",
                    "name": "Ji Qi"
                },
                {
                    "authorId": "2109790016",
                    "name": "Hailong Jin"
                },
                {
                    "authorId": "2108499570",
                    "name": "Jinxin Liu"
                },
                {
                    "authorId": "2116405624",
                    "name": "Yuxian Gu"
                },
                {
                    "authorId": "2022231256",
                    "name": "Yu Gu"
                },
                {
                    "authorId": "1390925224",
                    "name": "Yuan Yao"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2055765060",
                    "name": "Lei Hou"
                },
                {
                    "authorId": null,
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2113744169",
                    "name": "Bin Xu"
                },
                {
                    "authorId": "2148911975",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2133353675",
                    "name": "Juanzi Li"
                }
            ]
        },
        {
            "paperId": "45cbff3a7e803dd949628a91bedef52b28bd63c7",
            "title": "Unlock Predictable Scaling from Emergent Abilities",
            "abstract": "The scientific scale-up of large language models (LLMs) necessitates a comprehensive understanding of their scaling properties. However, the existing literature on the scaling properties only yields an incomplete answer: optimization loss decreases predictably as the model size increases, in line with established scaling law; yet no scaling law for task has been established and the task performances are far from predictable during scaling. Task performances typically show minor gains on small models until they improve dramatically once models exceed a size threshold, exemplifying the \u201cemergent abilities\u201d. In this study, we discover that small models, although they exhibit minor performance, demonstrate critical and consistent task performance improvements that are not captured by conventional evaluation strategies due to insufficient measurement resolution. To measure such improvements, we introduce PASSUNTIL, an evaluation strategy with theoretically infinite resolution, through massive sampling in the decoding phase. With PASSUNTIL, we conduct a quantitative investigation into the scaling law of task performance. The investigation contains two parts. Firstly, a strict task scaling law that is not conventionally known to exist, is identified, enhancing the predictability of task performances. Remarkably, we are able to predict the performance of the 2.4B model on code generation with merely 0.05% deviation before training starts, which is the first systematic attempt to verify predictable scaling proposed by GPT-4\u2019s report (OpenAI, 2023). Secondly, underpinned by PASSUNTIL, we observe concrete evidence of emergent abilities and ascertain that they are not in conflict with the continuity of performance improvement. Their semblance to break-through is that their scaling curve cannot be fitted by standard scaling law function. We then introduce a mathematical definition for the emergent abilities. Through the definition, we refute a prevalent \u201cmulti-step reasoning hypothesis\u201d regarding the genesis of emergent abilities and propose a new hypothesis with a satisfying fit to the observed scaling curve. \u201cSee the world in a grain of sand\u201d",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1576223501",
                    "name": "Shengding Hu"
                },
                {
                    "authorId": "2254831849",
                    "name": "Xin Liu"
                },
                {
                    "authorId": "2284728053",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2254576790",
                    "name": "Xinrong Zhang"
                },
                {
                    "authorId": "2256951801",
                    "name": "Chaoqun He"
                },
                {
                    "authorId": "2150606888",
                    "name": "Weilin Zhao"
                },
                {
                    "authorId": "2427350",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2254268950",
                    "name": "Zebin Ou"
                },
                {
                    "authorId": "1398454307",
                    "name": "Guoyang Zeng"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2273551430",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "4c8cc2383cec93bd9ea0758692f01b98a035215b",
            "title": "UltraFeedback: Boosting Language Models with High-quality Feedback",
            "abstract": "Reinforcement learning from human feedback (RLHF) has become a pivot technique in aligning large language models (LLMs) with human preferences. In RLHF practice, preference data plays a crucial role in bridging human proclivity and LLMs. However, the scarcity of diverse, naturalistic datasets of human preferences on LLM outputs at scale poses a great challenge to RLHF as well as feedback learning research within the open-source community. Current preference datasets, either proprietary or limited in size and prompt variety, result in limited RLHF adoption in open-source models and hinder further exploration. In this study, we propose ULTRAFEEDBACK, a large-scale, high-quality, and diversified preference dataset designed to overcome these limitations and foster RLHF development. To create ULTRAFEEDBACK, we compile a diverse array of instructions and models from multiple sources to produce comparative data. We meticulously devise annotation instructions and employ GPT-4 to offer detailed feedback in both numerical and textual forms. ULTRAFEEDBACK establishes a reproducible and expandable preference data construction pipeline, serving as a solid foundation for future RLHF and feedback learning research. Utilizing ULTRAFEEDBACK, we train various models to demonstrate its effectiveness, including the reward model UltraRM, chat language model UltraLM-13B-PPO, and critique model UltraCM. Experimental results indicate that our models outperform existing open-source models, achieving top performance across multiple benchmarks. Our data and models are available at https://github.com/thunlp/UltraFeedback.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "2152195191",
                    "name": "Lifan Yuan"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2253396591",
                    "name": "Guanming Yao"
                },
                {
                    "authorId": "2239666474",
                    "name": "Wei Zhu"
                },
                {
                    "authorId": "2072724069",
                    "name": "Yuan Ni"
                },
                {
                    "authorId": "2239568222",
                    "name": "Guotong Xie"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "6e08eec2f487c092a86db6e9666e47d152eb97d6",
            "title": "Exploring the Impact of Model Scaling on Parameter-Efficient Tuning",
            "abstract": "Parameter-efficient tuning (PET) methods can effectively drive extremely large pre-trained language models (PLMs) by training only minimal parameters. Different PET methods utilize different manually designed tunable modules. In small PLMs, there are usually noticeable performance differences among PET methods. Nevertheless, as the model scale increases, the performance differences become marginal. Hence, we hypothesize that model scaling mitigates the impact of design differences on PET methods. To investigate this hypothesis, we introduce a more flexible PET method called Arbitrary PET (APET) method. The APET method is compatible with a tunable module, which consists of any number of parameters distributed in arbitrary positions. Then, we utilize it and conduct experiments on 11 NLP tasks across 3 representative PLMs. Our investigations reveal that model scaling (1) mitigates the effects of the positions of tunable parameters on performance, and (2) enables tuning methods to achieve performance comparable to full-parameter fine-tuning by optimizing fewer tunable parameters. Intriguingly, we also observe that tuning methods optimize the similar number of tunable parameters to exceed random guess performance on different tasks. We collectively discuss this phenomenon and the two aforementioned findings from an optimization perspective to understand the underlying mechanisms. These conclusions enhance our understanding of the impact of model scaling on PET and assist in designing more effective and efficient PET methods for PLMs of different scales. The source code can be obtained from this GitHub repository: \\url{https://github.com/yushengsu-thu/PET_Scaling}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48576745",
                    "name": "Yusheng Su"
                },
                {
                    "authorId": "2151547817",
                    "name": "Chi-Min Chan"
                },
                {
                    "authorId": "2210063335",
                    "name": "Jiali Cheng"
                },
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "1576223501",
                    "name": "Shengding Hu"
                },
                {
                    "authorId": "19343873",
                    "name": "Zonghan Yang"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                }
            ]
        }
    ]
}