{
    "authorId": "2199317976",
    "papers": [
        {
            "paperId": "b230545fbf276b6f6e01c6662a62bc2c01ca4b9f",
            "title": "From Intentions to Techniques: A Comprehensive Taxonomy and Challenges in Text Watermarking for Large Language Models",
            "abstract": "With the rapid growth of Large Language Models (LLMs), safeguarding textual content against unauthorized use is crucial. Text watermarking offers a vital solution, protecting both - LLM-generated and plain text sources. This paper presents a unified overview of different perspectives behind designing watermarking techniques, through a comprehensive survey of the research literature. Our work has two key advantages, (1) we analyze research based on the specific intentions behind different watermarking techniques, evaluation datasets used, watermarking addition, and removal methods to construct a cohesive taxonomy. (2) We highlight the gaps and open challenges in text watermarking to promote research in protecting text authorship. This extensive coverage and detailed analysis sets our work apart, offering valuable insights into the evolving landscape of text watermarking in language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2307010253",
                    "name": "Harsh Nishant Lalai"
                },
                {
                    "authorId": "2199317976",
                    "name": "Aashish Anantha Ramakrishnan"
                },
                {
                    "authorId": "2051264008",
                    "name": "Raj Sanjay Shah"
                },
                {
                    "authorId": "2296856289",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "fc4b0bf3a5baf8ac683e0fe3156257945614b847",
            "title": "ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis",
            "abstract": "Text-to-Image (T2I) Synthesis has made tremendous strides in enhancing synthesized image quality, but current datasets evaluate model performance only on descriptive, instruction-based prompts. Real-world news image captions take a more pragmatic approach, providing high-level situational and Named-Entity (NE) information and limited physical object descriptions, making them abstractive. To evaluate the ability of T2I models to capture intended subjects from news captions, we introduce the Abstractive News Captions with High-level cOntext Representation (ANCHOR) dataset, containing 70K+ samples sourced from 5 different news media organizations. With Large Language Models (LLM) achieving success in language and commonsense reasoning tasks, we explore the ability of different LLMs to identify and understand key subjects from abstractive captions. Our proposed method Subject-Aware Finetuning (SAFE), selects and enhances the representation of key subjects in synthesized images by leveraging LLM-generated subject weights. It also adapts to the domain distribution of news images and captions through custom Domain Fine-tuning, outperforming current T2I baselines on ANCHOR. By launching the ANCHOR dataset, we hope to motivate research in furthering the Natural Language Understanding (NLU) capabilities of T2I models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2199317976",
                    "name": "Aashish Anantha Ramakrishnan"
                },
                {
                    "authorId": "2296949451",
                    "name": "Sharon X. Huang"
                },
                {
                    "authorId": "2296856289",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "0b5b54b7326eff71505a8ff8f3dd587d9b9ac530",
            "title": "ANNA: Abstractive Text-to-Image Synthesis with Filtered News Captions",
            "abstract": "Advancements in Text-to-Image synthesis over recent years have focused more on improving the quality of generated samples using datasets with descriptive prompts. However, real-world image-caption pairs present in domains such as news data do not use simple and directly descriptive captions. With captions containing information on both the image content and underlying contextual cues, they become abstractive in nature. In this paper, we launch ANNA, an Abstractive News captioNs dAtaset extracted from online news articles in a variety of different contexts. We explore the capabilities of current Text-to-Image synthesis models to generate news domain-specific images using abstractive captions by benchmarking them on ANNA, in both standard training and transfer learning settings. The generated images are judged on the basis of contextual relevance, visual quality, and perceptual similarity to ground-truth image-caption pairs. Through our experiments, we show that techniques such as transfer learning achieve limited success in understanding abstractive captions but still fail to consistently learn the relationships between content and context features. The Dataset is available at https://github.com/aashish2000/ANNA .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2199317976",
                    "name": "Aashish Anantha Ramakrishnan"
                },
                {
                    "authorId": "122132149",
                    "name": "Sharon X. Huang"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        }
    ]
}