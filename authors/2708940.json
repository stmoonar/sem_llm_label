{
    "authorId": "2708940",
    "papers": [
        {
            "paperId": "05389d52e77a69c37b197a4b77aee65128a9666a",
            "title": "ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning",
            "abstract": "Charts provide visual representations of data and are widely used for analyzing information, addressing queries, and conveying insights to others. Various chart-related downstream tasks have emerged recently, such as question-answering and summarization. A common strategy to solve these tasks is to fine-tune various models originally trained on vision tasks language. However, such task-specific models are not capable of solving a wide range of chart-related tasks, constraining their real-world applicability. To overcome these challenges, we introduce ChartInstruct: a novel chart-specific vision-language Instruction-following dataset comprising 191K instructions generated with 71K charts. We then present two distinct systems for instruction tuning on such datasets: (1) an end-to-end model that connects a vision encoder for chart understanding with a LLM; and (2) a pipeline model that employs a two-step approach to extract chart data tables and input them into the LLM. In experiments on four downstream tasks, we first show the effectiveness of our model--achieving a new set of state-of-the-art results. Further evaluation shows that our instruction-tuning approach supports a wide array of real-world chart comprehension and reasoning scenarios, thereby expanding the scope and applicability of our models to new kinds of tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "100832735",
                    "name": "Ahmed Masry"
                },
                {
                    "authorId": "2291134806",
                    "name": "Mehrad Shahmohammadi"
                },
                {
                    "authorId": "3405393",
                    "name": "Md. Rizwan Parvez"
                },
                {
                    "authorId": "2274022429",
                    "name": "Enamul Hoque"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "0d53dcd8ebe1dd44b43c71bbfbe9076b4ed12dd8",
            "title": "Prompt Leakage effect and defense strategies for multi-turn LLM interactions",
            "abstract": "Prompt leakage poses a compelling security and privacy threat in LLM applications. Leakage of system prompts may compromise intellectual property, and act as adversarial reconnaissance for an attacker. A systematic evaluation of prompt leakage threats and mitigation strategies is lacking, especially for multi-turn LLM interactions. In this paper, we systematically investigate LLM vulnerabilities against prompt leakage for 10 closed- and open-source LLMs, across four domains. We design a unique threat model which leverages the LLM sycophancy effect and elevates the average attack success rate (ASR) from 17.7% to 86.2% in a multi-turn setting. Our standardized setup further allows dissecting leakage of specific prompt contents such as task instructions and knowledge documents. We measure the mitigation effect of 7 black-box defense strategies, along with finetuning an open-source model to defend against leakage attempts. We present different combination of defenses against our threat model, including a cost analysis. Our study highlights key takeaways for building secure LLM applications and provides directions for research in multi-turn LLM interactions",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273350810",
                    "name": "Divyansh Agarwal"
                },
                {
                    "authorId": "22281632",
                    "name": "A. R. Fabbri"
                },
                {
                    "authorId": "46180754",
                    "name": "Philippe Laban"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2266753302",
                    "name": "Caiming Xiong"
                },
                {
                    "authorId": "2267031643",
                    "name": "Chien-Sheng Wu"
                }
            ]
        },
        {
            "paperId": "0eb8d2e9cdee108b500726d18eaa59fc48ec959b",
            "title": "From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models",
            "abstract": "Data visualization in the form of charts plays a pivotal role in data analysis, offering critical insights and aiding in informed decision-making. Automatic chart understanding has witnessed significant advancements with the rise of large foundation models in recent years. Foundation models, such as large language models, have revolutionized various natural language processing tasks and are increasingly being applied to chart understanding tasks. This survey paper provides a comprehensive overview of the recent developments, challenges, and future directions in chart understanding within the context of these foundation models. We review fundamental building blocks crucial for studying chart understanding tasks. Additionally, we explore various tasks and their evaluation metrics and sources of both charts and textual inputs. Various modeling strategies are then examined, encompassing both classification-based and generation-based approaches, along with tool augmentation techniques that enhance chart understanding performance. Furthermore, we discuss the state-of-the-art performance of each task and discuss how we can improve the performance. Challenges and future directions are addressed, highlighting the importance of several topics, such as domain-specific charts, lack of efforts in developing evaluation metrics, and agent-oriented settings. This survey paper serves as a comprehensive resource for researchers and practitioners in the fields of natural language processing, computer vision, and data analysis, providing valuable insights and directions for future research in chart understanding leveraging large foundation models. The studies mentioned in this paper, along with emerging new research, will be continually updated at: https://github.com/khuangaf/Awesome-Chart-Understanding.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1420116116",
                    "name": "Kung-Hsiang Huang"
                },
                {
                    "authorId": "2261082492",
                    "name": "Hou Pong Chan"
                },
                {
                    "authorId": "51135899",
                    "name": "Y. Fung"
                },
                {
                    "authorId": "2261278256",
                    "name": "Haoyi Qiu"
                },
                {
                    "authorId": "2275279474",
                    "name": "Mingyang Zhou"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2275193330",
                    "name": "Shih-Fu Chang"
                },
                {
                    "authorId": "2277409745",
                    "name": "Heng Ji"
                }
            ]
        },
        {
            "paperId": "13dc9eb9cf36c5bb287671a41cb31b7de2a4cee7",
            "title": "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing",
            "abstract": "Large Language Models (LLMs) have demonstrated significant potential in handling complex reasoning tasks through step-by-step rationale generation. However, recent studies have raised concerns regarding the hallucination and flaws in their reasoning process. Substantial efforts are being made to improve the reliability and faithfulness of the generated rationales. Some approaches model reasoning as planning, while others focus on annotating for process supervision. Nevertheless, the planning-based search process often results in high latency due to the frequent assessment of intermediate reasoning states and the extensive exploration space. Additionally, supervising the reasoning process with human annotation is costly and challenging to scale for LLM training. To address these issues, in this paper, we propose a framework to learn planning-based reasoning through Direct Preference Optimization (DPO) on collected trajectories, which are ranked according to synthesized process rewards. Our results on challenging logical reasoning benchmarks demonstrate the effectiveness of our learning framework, showing that our 7B model can surpass the strong counterparts like GPT-3.5-Turbo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1689176705",
                    "name": "Fangkai Jiao"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "49293155",
                    "name": "Zhengyuan Liu"
                },
                {
                    "authorId": "2271409954",
                    "name": "Nancy F. Chen"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "2e05c50d3a93b6007d72e1e4466e7105e1266b29",
            "title": "LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs",
            "abstract": "We present the first systematic evaluation examining format bias in performance of large language models (LLMs). Our approach distinguishes between two categories of an evaluation metric under format constraints to reliably and accurately assess performance: one measures performance when format constraints are adhered to, while the other evaluates performance regardless of constraint adherence. We then define a metric for measuring the format bias of LLMs and establish effective strategies to reduce it. Subsequently, we present our empirical format bias evaluation spanning four commonly used categories -- multiple-choice question-answer, wrapping, list, and mapping -- covering 15 widely-used formats. Our evaluation on eight generation tasks uncovers significant format bias across state-of-the-art LLMs. We further discover that improving the format-instruction following capabilities of LLMs across formats potentially reduces format bias. Based on our evaluation findings, we study prompting and fine-tuning with synthesized format data techniques to mitigate format bias. Our methods successfully reduce the variance in ChatGPT's performance among wrapping formats from 235.33 to 0.71 (%$^2$).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2060491855",
                    "name": "Do Xuan Long"
                },
                {
                    "authorId": "2316326111",
                    "name": "Hai Nguyen Ngoc"
                },
                {
                    "authorId": "2290755637",
                    "name": "Tiviatis Sim"
                },
                {
                    "authorId": "2316325840",
                    "name": "Hieu Dao"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2266466003",
                    "name": "Kenji Kawaguchi"
                },
                {
                    "authorId": "2266471203",
                    "name": "Nancy F. Chen"
                },
                {
                    "authorId": "2257033898",
                    "name": "Min-Yen Kan"
                }
            ]
        },
        {
            "paperId": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
            "title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey",
            "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD detection, and OD in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. In addition, we also highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection, including the discussion over other related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude this survey with open challenges and future directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188735058",
                    "name": "Atsuyuki Miyai"
                },
                {
                    "authorId": "2295601",
                    "name": "Jingkang Yang"
                },
                {
                    "authorId": "2267788653",
                    "name": "Jingyang Zhang"
                },
                {
                    "authorId": "2143847067",
                    "name": "Yifei Ming"
                },
                {
                    "authorId": "2223973348",
                    "name": "Yueqian Lin"
                },
                {
                    "authorId": "2314915693",
                    "name": "Qing Yu"
                },
                {
                    "authorId": "2240003271",
                    "name": "Go Irie"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2273756302",
                    "name": "Yixuan Li"
                },
                {
                    "authorId": "2294901591",
                    "name": "Hai Li"
                },
                {
                    "authorId": "2279869111",
                    "name": "Ziwei Liu"
                },
                {
                    "authorId": "145572097",
                    "name": "T. Yamasaki"
                },
                {
                    "authorId": "2237794190",
                    "name": "Kiyoharu Aizawa"
                }
            ]
        },
        {
            "paperId": "334d7fba900eab258cd4fbb5152539e83678b9c4",
            "title": "ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild",
            "abstract": "Given the ubiquity of charts as a data analysis, visualization, and decision-making tool across industries and sciences, there has been a growing interest in developing pre-trained foundation models as well as general purpose instruction-tuned models for chart understanding and reasoning. However, existing methods suffer crucial drawbacks across two critical axes affecting the performance of chart representation models: they are trained on data generated from underlying data tables of the charts, ignoring the visual trends and patterns in chart images, and use weakly aligned vision-language backbone models for domain-specific training, limiting their generalizability when encountering charts in the wild. We address these important drawbacks and introduce ChartGemma, a novel chart understanding and reasoning model developed over PaliGemma. Rather than relying on underlying data tables, ChartGemma is trained on instruction-tuning data generated directly from chart images, thus capturing both high-level trends and low-level visual information from a diverse set of charts. Our simple approach achieves state-of-the-art results across $5$ benchmarks spanning chart summarization, question answering, and fact-checking, and our elaborate qualitative studies on real-world charts show that ChartGemma generates more realistic and factually correct summaries compared to its contemporaries. We release the code, model checkpoints, dataset, and demos at https://github.com/vis-nlp/ChartGemma.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "100832735",
                    "name": "Ahmed Masry"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2310230414",
                    "name": "Aayush Bajaj"
                },
                {
                    "authorId": "2310228208",
                    "name": "Aaryaman Kartha"
                },
                {
                    "authorId": "2274022429",
                    "name": "Enamul Hoque"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "3a4eb7540a7dc371f3814ed4b57e001b5b288456",
            "title": "Explaining Language Model Predictions with High-Impact Concepts",
            "abstract": "To encourage fairness and transparency, there exists an urgent demand for deriving reliable explanations for large language models (LLMs). One promising solution is concept-based explanations, i.e., human-understandable concepts from internal representations. However, due to the compositional nature of languages, current methods mostly discover correlational explanations instead of causal features. Therefore, we propose a novel framework to provide impact-aware explanations for users to understand the LLM\u2019s behavior, which are robust to feature changes and influential to the model\u2019s predictions. Specifically, we extract predictive high-level features (concepts) from the model\u2019s hidden layer activations. Then, we innovatively optimize for features whose existence causes the output predictions to change substantially. Extensive experiments on real and synthetic tasks demonstrate that our method achieves superior results on predictive impact, explainability, and faithfulness compared to the baselines, especially for LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2298015346",
                    "name": "Tan Wang"
                },
                {
                    "authorId": "2291439162",
                    "name": "Yongjie Wang"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        },
        {
            "paperId": "3c3ed4f438930ee01b5d2812f3df578ceb36fa7f",
            "title": "BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models",
            "abstract": "Recent text-to-image generation models have demonstrated incredible success in generating images that faithfully follow input prompts. However, the requirement of using words to describe a desired concept provides limited control over the appearance of the generated concepts. In this work, we address this shortcoming by proposing an approach to enable personalization capabilities in existing text-to-image diffusion models. We propose a novel architecture (BootPIG) that allows a user to provide reference images of an object in order to guide the appearance of a concept in the generated images. The proposed BootPIG architecture makes minimal modifications to a pretrained text-to-image diffusion model and utilizes a separate UNet model to steer the generations toward the desired appearance. We introduce a training procedure that allows us to bootstrap personalization capabilities in the BootPIG architecture using data generated from pretrained text-to-image models, LLM chat agents, and image segmentation models. In contrast to existing methods that require several days of pretraining, the BootPIG architecture can be trained in approximately 1 hour. Experiments on the DreamBooth dataset demonstrate that BootPIG outperforms existing zero-shot methods while being comparable with test-time finetuning approaches. Through a user study, we validate the preference for BootPIG generations over existing methods both in maintaining fidelity to the reference object's appearance and aligning with textual prompts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3234247",
                    "name": "Senthil Purushwalkam"
                },
                {
                    "authorId": "1752893100",
                    "name": "Akash Gokul"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                },
                {
                    "authorId": "2265756339",
                    "name": "Nikhil Naik"
                }
            ]
        },
        {
            "paperId": "3edc37be7ffe4647f8f271c0f0aa1861d98a11be",
            "title": "Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges",
            "abstract": "In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transfor-mative impact of LLMs on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From both data and learning perspectives, we examine various strategies that utilize LLMs for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for diverse forms of further training. Additionally, this paper highlights the primary open challenges faced in this domain, ranging from controllable data augmentation to multi-modal data augmentation. This survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve as a comprehensive guide for researchers and practitioners.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064493724",
                    "name": "Bosheng Ding"
                },
                {
                    "authorId": "2084609980",
                    "name": "Chengwei Qin"
                },
                {
                    "authorId": "2091437375",
                    "name": "Ruochen Zhao"
                },
                {
                    "authorId": "2290030532",
                    "name": "Tianze Luo"
                },
                {
                    "authorId": "2290023354",
                    "name": "Xinze Li"
                },
                {
                    "authorId": "2290026474",
                    "name": "Guizhen Chen"
                },
                {
                    "authorId": "2276610995",
                    "name": "Wenhan Xia"
                },
                {
                    "authorId": "2290145274",
                    "name": "Junjie Hu"
                },
                {
                    "authorId": "1755919",
                    "name": "A. Luu"
                },
                {
                    "authorId": "2708940",
                    "name": "Shafiq R. Joty"
                }
            ]
        }
    ]
}