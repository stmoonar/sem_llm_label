{
    "authorId": "1718694",
    "papers": [
        {
            "paperId": "2b054eb2be8fbb261503370323e4442602eddeed",
            "title": "Fact Ranking over Large-Scale Knowledge Graphs with Reasoning Embedding Models",
            "abstract": "Knowledge graphs (KGs) serve as the backbone of many applications such as recommendation systems and question answering. All these applications require reasoning about the relevance of facts in a KG to downstream applications. In this work, we describe our efforts in building a solution to reason about the importance of facts over continuously updated industry-scale KGs. We focus on the problem of fact ranking and evaluate to what extent modern knowledge graph embedding (KGE) models provide a representation for addressing this problem. To this end, we discuss unique challenges associated with solving this task in industrial settings and evaluate how accurately different KGE models and text-based embedding models can solve the problem of fact ranking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40046694",
                    "name": "Hongyu Ren"
                },
                {
                    "authorId": "143661472",
                    "name": "A. Mousavi"
                },
                {
                    "authorId": "4047075",
                    "name": "Anil Pacaci"
                },
                {
                    "authorId": "2087061163",
                    "name": "S. R. Chowdhury"
                },
                {
                    "authorId": "2047146404",
                    "name": "J. Mohoney"
                },
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                }
            ]
        },
        {
            "paperId": "b6f229681cf0a3ba38884d281d89b2d498a853a8",
            "title": "Growing and Serving Large Open-domain Knowledge Graphs",
            "abstract": "Applications of large open-domain knowledge graphs (KGs) to real-world problems pose many unique challenges. In this paper, we present extensions to Saga our platform for continuous construction and serving of knowledge at scale. In particular, we describe a pipeline for training knowledge graph embeddings that powers key capabilities such as fact ranking, fact verification, a related entities service, and support for entity linking. We then describe how our platform, including graph embeddings, can be leveraged to create a Semantic Annotation service that links unstructured Web documents to entities in our KG. Semantic annotation of the Web effectively expands our knowledge graph with edges to open-domain Web content which can be used in various search and ranking problems. Finally, we leverage annotated Web documents to drive Open-domain Knowledge Extraction. This targeted extraction framework identifies important coverage issues in the KG, then finds relevant data sources for target entities on the Web and extracts missing information to enrich the KG. Finally, we describe adaptations to our knowledge platform needed to construct and serve private personal knowledge on-device. This includes private incremental KG construction, cross- device knowledge sync, and global knowledge enrichment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1743316",
                    "name": "Ihab F. Ilyas"
                },
                {
                    "authorId": "2217340760",
                    "name": "JP Lacerda"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "1856878",
                    "name": "U. F. Minhas"
                },
                {
                    "authorId": "143661472",
                    "name": "A. Mousavi"
                },
                {
                    "authorId": "32546616",
                    "name": "Jeffrey Pound"
                },
                {
                    "authorId": "145071799",
                    "name": "Theodoros Rekatsinas"
                },
                {
                    "authorId": "3308088",
                    "name": "C. Sumanth"
                }
            ]
        },
        {
            "paperId": "bb86a2592e9efa196aefd6bbc39bf62a3202e9db",
            "title": "Construction of Paired Knowledge Graph - Text Datasets Informed by Cyclic Evaluation",
            "abstract": "Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Informed by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2243337763",
                    "name": "Xin Zhan"
                },
                {
                    "authorId": "37374479",
                    "name": "Richard He Bai"
                },
                {
                    "authorId": "2243340600",
                    "name": "Peng Shi"
                },
                {
                    "authorId": "2243336634",
                    "name": "Theo Rekatsinas"
                },
                {
                    "authorId": "2243377351",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2243336030",
                    "name": "Jeff Pound"
                },
                {
                    "authorId": "2243336902",
                    "name": "Josh Susskind"
                },
                {
                    "authorId": "2243335295",
                    "name": "Natalie Schluter"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "3111912",
                    "name": "N. Jaitly"
                }
            ]
        },
        {
            "paperId": "de06aa33693a910c51d4cd76873296c302eaf476",
            "title": "Deep Knowledge Tracking Based on Double Attention Mechanism and Cognitive Difficulty",
            "abstract": "Knowledge tracking is a key technique of artificial intelligence-assisted education to predict learners' future answers based on their historical learning interaction data. Current studies on knowledge-tracking models are well-established, but often with limited accuracy in tracking learners' knowledge acquisition. This paper proposes a knowledge tracking model based on double attention mechanism and cognitive difficulty, to achieve a better understanding of the relationships among knowledge concepts, their influence on learners' knowledge acquisition and the impact of absolute difficulty and the relative difficulty of the exercises based on learners' cognitive levels. We designed a mechanism to explore the correlation between exercises-knowledge concepts and knowledge concepts-knowledge concepts, and dynamically analyze the cognitive difficulty of exercises. The model also introduces a multi-headed self-attentive mechanism to capture the long-term dependence of learners' knowledge acquisition. The results suggest that the model can effectively track learners' knowledge acquisition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2235912039",
                    "name": "Junhong Guo"
                },
                {
                    "authorId": "2217872884",
                    "name": "Yonggang Ding"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2149971282",
                    "name": "Lingling Zheng"
                },
                {
                    "authorId": "2115762336",
                    "name": "Xinyue Ma"
                },
                {
                    "authorId": "2235990026",
                    "name": "Lingyun Xiao"
                }
            ]
        },
        {
            "paperId": "eb8db286e1f6fb618ce4e1165a27a5c7ce11a0c9",
            "title": "Deep Homography Estimation With Feature Correlation Transformer",
            "abstract": "Homography estimation is an important image alignment method that has been widely used in computer vision applications. Traditional methods heavily rely on the distribution of features and usually fail in low-texture and large-baseline scenes. Most learning-based methods use convolutional neural networks(CNNs) to extract features. However, the dense features extracted in this way have a limited receptive field, leading to poor accuracy of results. In this paper, we propose a novel method for homography estimation. We first estimate the projective transformation between the reference image and the target image at a coarse level and then refine the estimated homography at the fine level. Unlike approaches that use simple CNNs or global correlations to search correspondences, we add self- and cross-attention layers in the transformer to enhance the feature correlations. The experiments show that our method significantly outperforms the existing solutions in challenging large-baseline scenes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111824941",
                    "name": "Haoyu Zhou"
                },
                {
                    "authorId": "1486300471",
                    "name": "Wei Hu"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2158534066",
                    "name": "Chu He"
                },
                {
                    "authorId": "1683647",
                    "name": "X. Chen"
                }
            ]
        },
        {
            "paperId": "6cb99af50b91fed276b7b6cee4c91cea5d222ae3",
            "title": "PriMeSRL-Eval: A Practical Quality Metric for Semantic Role Labeling Systems Evaluation",
            "abstract": "Semantic role labeling (SRL) identifies the predicate-argument structure in a sentence. This task is usually accomplished in four steps: predicate identification, predicate sense disambiguation, argument identification, and argument classification. Errors introduced at one step propagate to later steps. Unfortunately, the existing SRL evaluation scripts do not consider the full effect of this error propagation aspect. They either evaluate arguments independent of predicate sense (CoNLL09) or do not evaluate predicate sense at all (CoNLL05), yielding an inaccurate SRL model performance on the argument classification task. In this paper, we address key practical issues with existing evaluation scripts and propose a more strict SRL evaluation metric PriMeSRL. We observe that by employing PriMeSRL, the quality evaluation of all SoTA SRL models drops significantly, and their relative rankings also change. We also show that PriMeSRLsuccessfully penalizes actual failures in SoTA SRL models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "13836343",
                    "name": "Alexandre Rademaker"
                },
                {
                    "authorId": "1399212475",
                    "name": "Khoi-Nguyen Tran"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "35562751",
                    "name": "H. Kanayama"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "6f80d1ade43ae048763d65c6e8e913d9a31de4be",
            "title": "Accepted Tutorials at The Web Conference 2022",
            "abstract": "This paper summarizes the content of the 20 tutorials that have been given at The Web Conference 2022: 85% of these tutorials are lecture style, and 15% of these are hands on.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "2034201368",
                    "name": "Senjuti Basu Roy"
                },
                {
                    "authorId": "2154990549",
                    "name": "Xuan Wang"
                },
                {
                    "authorId": "2108986527",
                    "name": "Hongwei Wang"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "134000266",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "3124784",
                    "name": "E. Lex"
                },
                {
                    "authorId": "2528900",
                    "name": "Akash Bharadwaj"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "1819564",
                    "name": "Milan Dojchinovski"
                },
                {
                    "authorId": "37386609",
                    "name": "J. Forberg"
                },
                {
                    "authorId": "32114346",
                    "name": "Johannes Frey"
                },
                {
                    "authorId": "33122761",
                    "name": "P. Bonte"
                },
                {
                    "authorId": "50535911",
                    "name": "Marco Balduini"
                },
                {
                    "authorId": "2130209106",
                    "name": "Matteo Belcao"
                },
                {
                    "authorId": "1490541824",
                    "name": "Emanuele Della Valle"
                },
                {
                    "authorId": "28584977",
                    "name": "Junliang Yu"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "1390612725",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "1380259269",
                    "name": "Jamell Dacon"
                },
                {
                    "authorId": "95104850",
                    "name": "L. Lye"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "1682878",
                    "name": "A. Gionis"
                },
                {
                    "authorId": "2181680391",
                    "name": "Stefan Neumann"
                },
                {
                    "authorId": "35332118",
                    "name": "Bruno Ordozgoiti"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2064460784",
                    "name": "H. Arnaout"
                },
                {
                    "authorId": "2135976772",
                    "name": "Shrestha Ghosh"
                },
                {
                    "authorId": "1679784",
                    "name": "Fabian M. Suchanek"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2169468461",
                    "name": "Yu Chen"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2116441692",
                    "name": "Bang Liu"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "2284176",
                    "name": "Hans Chalupsky"
                },
                {
                    "authorId": "2628881",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "1637421061",
                    "name": "Ilias Kanellos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "2726036",
                    "name": "Nurendra Choudhary"
                },
                {
                    "authorId": "36724558",
                    "name": "N. Rao"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                },
                {
                    "authorId": "51050025",
                    "name": "Friedhelm Victor"
                },
                {
                    "authorId": "1679379",
                    "name": "Bernhard Haslhofer"
                },
                {
                    "authorId": "2055401797",
                    "name": "George Katsogiannis-Meimarakis"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "28044622",
                    "name": "Shengmin Jin"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "143820870",
                    "name": "Vidhisha Balachandran"
                },
                {
                    "authorId": "51467955",
                    "name": "Sachin Kumar"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "47561503",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "83e3b3b19bbe92a85265bcee6634738206662f03",
            "title": "Universal Proposition Bank 2.0",
            "abstract": "Semantic role labeling (SRL) represents the meaning of a sentence in the form of predicate-argument structures. Such shallow semantic analysis is helpful in a wide range of downstream NLP tasks and real-world applications. As treebanks enabled the development of powerful syntactic parsers, the accurate predicate-argument analysis demands training data in the form of propbanks. Unfortunately, most languages simply do not have corresponding propbanks due to the high cost required to construct such resources. To overcome such challenges, Universal Proposition Bank 1.0 (UP1.0) was released in 2017, with high-quality propbank data generated via a two-stage method exploiting monolingual SRL and multilingual parallel data. In this paper, we introduce Universal Proposition Bank 2.0 (UP2.0), with significant enhancements over UP1.0: (1) propbanks with higher quality by using a state-of-the-art monolingual SRL and improved auto-generation of annotations; (2) expanded language coverage (from 7 to 9 languages); (3) span annotation for the decoupling of syntactic analysis; and (4) Gold data for a subset of the languages. We also share our experimental results that confirm the significant quality improvements of the generated propbanks. In addition, we present a comprehensive experimental evaluation on how different implementation choices impact the quality of the resulting data. We release these resources to the research community and hope to encourage more research on cross-lingual SRL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "13836343",
                    "name": "Alexandre Rademaker"
                },
                {
                    "authorId": "2185433526",
                    "name": "Micha\u0142 Ulewicz"
                },
                {
                    "authorId": "2180951336",
                    "name": "Linh H. Ha"
                },
                {
                    "authorId": "145199659",
                    "name": "Huyen Nguyen"
                },
                {
                    "authorId": "1399212475",
                    "name": "Khoi-Nguyen Tran"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "e7ac9ea2ae42a7a9125da69de1ff295efebfaff5",
            "title": "Label Definitions Improve Semantic Role Labeling",
            "abstract": "Argument classification is at the core of Semantic Role Labeling. Given a sentence and the predicate, a semantic role label is assigned to each argument of the predicate. While semantic roles come with meaningful definitions, existing work has treated them as symbolic. Learning symbolic labels usually requires ample training data, which is frequently unavailable due to the cost of annotation. We instead propose to retrieve and leverage the definitions of these labels from the annotation guidelines. For example, the verb predicate \u201cwork\u201d has arguments defined as \u201cworker\u201d, \u201cjob\u201d, \u201cemployer\u201d, etc. Our model achieves state-of-the-art performance on the CoNLL09 dataset injected with label definitions given the predicate senses. The performance improvement is even more pronounced in low-resource settings when training data is scarce.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "9dbb26e4f04f38aa2a11289cbc82a2d9ed533741",
            "title": "TableLab: An Interactive Table Extraction System with Adaptive Deep Learning",
            "abstract": "Table extraction from PDF and image documents is a ubiquitous task in the real-world. Perfect extraction quality is difficult to achieve with one single out-of-box model due to (1) the wide variety of table styles, (2) the lack of training data representing this variety and (3) the inherent ambiguity and subjectivity of table definitions between end-users. Meanwhile, building customized models from scratch can be difficult due to the expensive nature of annotating table data. We attempt to solve these challenges with TableLab by providing a system where users and models seamlessly work together to quickly customize high-quality extraction models with a few labelled examples for the user\u2019s document collection, which contains pages with tables. Given an input document collection, TableLab first detects tables with similar structures (templates) by clustering embeddings from the extraction model. Document collections often contain tables created with a limited set of templates or similar structures. It then selects a few representative table examples already extracted with a pre-trained base deep learning model. Via an easy-to-use user interface, users provide feedback to these selections without necessarily having to identify every single error. TableLab then applies such feedback to finetune the pre-trained model and returns the results of the finetuned model back to the user. The user can choose to repeat this process iteratively until obtaining a customized model with satisfactory performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31856827",
                    "name": "N. Wang"
                },
                {
                    "authorId": "143894459",
                    "name": "D. Burdick"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        }
    ]
}