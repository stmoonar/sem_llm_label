{
    "authorId": "2144273636",
    "papers": [
        {
            "paperId": "04f87c405cf8814dcd9185e6ef9751086a4b916c",
            "title": "EMO2-DETR: Efficient-Matching Oriented Object Detection With Transformers",
            "abstract": "Object detection in remote sensing is a challenging task due to the arbitrary orientations of objects and the vast variation in the number of objects within a single image. For instance, one image may contain hundreds of small vehicles, while another may only have a single football field. Recently, DEtection TRansformer (DETR) and its variants have achieved great success in object detection by setting a fixed number of object queries and using bipartite graph matching for one-to-one label assignment. However, we have observed that bipartite graph matching can result in relative redundancy of object queries when the number of objects changes dramatically in an image. This relative redundancy can cause two problems: slower convergence during training and redundant bounding boxes during inference. To analyze the aforementioned problems, we proposed a metric, redundancy of object query (ROQ), to quantitatively analyze the redundancy. Through experiments, we discovered that the reason for the two issues is the difficulty in distinguishing between high-quality negative samples and positive samples. In this article, we proposed efficient-matching oriented object detection with transformers (EMO2-DETR) consisting of three dedicated components to address the aforementioned issues. Specifically, reassign bipartite graph matching (RBGM) is proposed to extract high-quality negative samples from the negative samples. And ignored sample predicted head (ISPH) is proposed to predict high-quality negative samples. Then, reassigned Hungarian loss is used to better involve high-quality negative samples in the update of model parameters. Extensive experiments on DOTAv1 and DOTAv1.5 datasets demonstrated that our proposed method achieves the competitive results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2320516419",
                    "name": "Chenrui Li"
                },
                {
                    "authorId": "122009001",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "bb7d86f4315e85b68ba509c47e76daf954174e98",
            "title": "Transformer and CNN Hybrid Network for Super-Resolution Semantic Segmentation of Remote Sensing Imagery",
            "abstract": "Super-resolution semantic segmentation (SRSS) based on Convolutional neural network (CNN) cannot establish long-range dependencies due to limited receptive field, which limits the SRSS to obtain accurate high-resolution (HR) segmentation results from the low-resolution (LR) input images. In this paper, we design a Transformer and CNN hybrid SRSS network that consists of two branches: Transformer and CNN hybrid SRSS branch and super-resolution guided branch. In the Transformer and CNN hybrid SRSS branch, Transformer extracts global context information from the feature map of the CNN, while skip connection is used to retain the local context information extracted from the CNN and combines both features to further improve the segmentation performance. In addition, the super-resolution guided branch is designed to supplement rich structure information and guide the semantic segmentation (SS). We test the proposed method on the ISPRS Vaihingen benchmark data set, and our network is superior to other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2260820793",
                    "name": "Pengyu Wang"
                },
                {
                    "authorId": "2154742573",
                    "name": "Shuzhong Li"
                }
            ]
        },
        {
            "paperId": "d7f29f1d6a7ad4a612c17282ac17645085f81d20",
            "title": "Pixel- And Patch-Wise Context-Aware Learning with CNN and GCN Collaboration for Hyperspectral Image Classification",
            "abstract": "Graph convolutional network (GCN) gains increasing attention in the hyperspectral image (HSI) classification by the ability to flexibly capture arbitrarily irregular objects. However, due to expensive computation, the graph construction is usually based on superpixel-wise nodes, which ignore the subtle pixel-wise features. In contrast, the convolution neural network (CNN) can mine pixel-wise spectral-spatial features but is limited to capturing local features in small square windows. In this paper, we design a new CNN and GCN collaborative network to simultaneously introduce pixel- and patch-wise contextual information. Concretely, we use the depthwise separable convolution to perform pixel-wise local feature extraction. To further mine the long-range contextual information between land covers, we concatenate a GCN. Finally, we further fuse the complementary features and decode them to obtain the classification map. Extensive experiments reveal that our method achieves competitive performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "f74ebbd4860ee84e1e7257994194828cf1308eb6",
            "title": "PM2.5 Estimation in Day/Night-Time from Himawari-8 Infrared Bands via a Deep Learning Neural Network",
            "abstract": "Satellite-based PM2.5 estimation is an effective means to achieve large-scale and long-term PM2.5 monitoring and investigation. Currently, most of methods retrieve PM2.5 from satellite-derived aerosol optical depth (AOD) or top-of-atmosphere reflectance (TOAR) during daytime. A few algorithms are also developed to retrieve nighttime PM2.5 from the satellite day\u2013night band and the accuracy is greatly limited by moonlight and artificial light sources. In this study, we utilize the properties of absorption pollutants in infrared spectrum to estimate PM2.5 concentrations from satellite infrared data, thus achieve the PM2.5 estimation in both day and night. Himawari-8 infrared bands data are used for PM2.5 estimation by a specifically designed neural network and loss function. Quantitative results show the satellite derived PM2.5 concentrations correlates with ground-based data well with R2 of 0.79 and RMSE of 15.43 \u03bcg \u00b7 m\u22123 for hourly PM2.5 estimation. Spatiotemporal distributions of model-estimated PM2.5 over China are also analyzed, and exhibit a highly consistent with ground-based measurements. Dust storms, heavy air pollution and fire smoke events are examined to further demonstrate the efficacy of our model. Our method not only circumvents the intermediate retrievals of AOD, but also enables consistent estimation of PM2.5 concentrations during daytime and nighttime in real-time monitoring.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2256306487",
                    "name": "Xiuqing Hu"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2249665454",
                    "name": "Peng Zhang"
                }
            ]
        },
        {
            "paperId": "58815d046026f2996e38a23b1cd47b7c1e75195e",
            "title": "Siamese Network Ensembles for Hyperspectral Target Detection with Pseudo Data Generation",
            "abstract": "Target detection in hyperspectral images (HSIs) aims to distinguish target pixels from the background using knowledge gleaned from prior spectra. Most traditional methods are based on certain assumptions and utilize handcrafted classifiers. These simple models and assumptions\u2019 failure restrict the detection performance under complicated background interference. Recently, based on the convolutional networks, many supervised deep learning detectors have outperformed the traditional methods. However, these methods suffer from unstable detection, heavy computation burden, and optimization difficulty. This paper proposes a Siamese fully connected based target detector (SFCTD) that comprises nonlinear feature extraction modules (NFEMs) and cosine distance classifiers. Two NFEMs, which extract discriminative spectral features of input spectra-pairs, are based on fully connected layers for efficient computing and share the parameters to ease the optimization. To solve the few samples problem, we propose a pseudo data generation method based on the linear mixed model and the assumption that background pixels are dominant in HSIs. For mitigating the impact of stochastic suboptimal initialization, we parallelly optimize several Siamese detectors with small computation burdens and aggregate them as ensembles in the inference time. The network ensembles outperform every detector in terms of stability and achieve an outstanding balance between background suppression and detection rate. Experiments on multiple data sets demonstrate that the proposed detector is superior to the state-of-the-art detectors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2260820793",
                    "name": "Pengyu Wang"
                }
            ]
        },
        {
            "paperId": "8fc2548ae8f31a148b29281e359ea3151d2115ed",
            "title": "Triplet-Metric-Guided Multi-Scale Attention for Remote Sensing Image Scene Classification with a Convolutional Neural Network",
            "abstract": "Remote sensing image scene classification (RSISC) plays a vital role in remote sensing applications. Recent methods based on convolutional neural networks (CNNs) have driven the development of RSISC. However, these approaches are not adequate considering the contributions of different features to the global decision. In this paper, triplet-metric-guided multi-scale attention (TMGMA) is proposed to enhance task-related salient features and suppress task-unrelated salient and redundant features. Firstly, we design the multi-scale attention module (MAM) guided by multi-scale feature maps to adaptively emphasize salient features and simultaneously fuse multi-scale and contextual information. Secondly, to capture task-related salient features, we use the triplet metric (TM) to optimize the learning of MAM under the constraint that the distance of the negative pair is supposed to be larger than the distance of the positive pair. Notably, the MAM and TM collaboration can enforce learning a more discriminative model. As such, our TMGMA can avoid the classification confusion caused by only using the attention mechanism and the excessive correction of features caused by only using the metric learning. Extensive experiments demonstrate that our TMGMA outperforms the ResNet50 baseline by 0.47% on the UC Merced, 1.46% on the AID, and 1.55% on the NWPU-RESISC45 dataset, respectively, and achieves performance that is competitive with other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "ce6de5bee4aa5b47db468cfbcbbd0340b84e2cde",
            "title": "Probability Differential-Based Class Label Noise Purification for Object Detection in Aerial Images",
            "abstract": "Modern object detection for aerial images requires numerous annotated data. However, the data annotation process inevitably introduces noise due to the bird\u2019s eye view perspective of aerial images and the professional requirements of annotations. While recent noise-robust object detection methods achieved great success, the noise side effect during the early training stage was still a problem. As demonstrated in this letter, noise during the early training stage will cumulatively affect the final performance. Based on the abovementioned observations, we propose a training strategy called correction maximization training to purify the noisy annotations and then train models. In particular, we design a novel noise filter called the probability differential (PD) to identify and revise wrong labels. After purification, we train the detector with the revised dataset. Compared with the existing works, the proposed method could be adapted in most modern object detectors (e.g., Faster RCNN and RetinaNet) and requires little hyperparameter tuning across different datasets and models. Extensive experiments on DOTA show that the proposed method achieves the state-of-the-art results with both symmetric and asymmetric noise.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "1d493b2d2407222ab20742889b4a0a79ba958a1d",
            "title": "Image Reconstruction Using Variable Exponential Function Regularization for Wide-Field Polarization Modulation Imaging",
            "abstract": "Polarization modulation imaging technology plays an important role in microscopic super-resolution imaging. However, the specimen medium contains retardancy, while charge-coupled devices may provide discrete under-sampling, and the coupled wavefronts consisting of the polarization state of the light and the anisotropic distribution of the specimen can lead to vectorial phase fitting degradation. Considering that the point spread function (PSF) of the main degradation parts can be regarded as an asymmetric generalized Gaussian distribution with uncertain parameters, an adaptive image reconstruction method is proposed based on variable exponential function regularization. The proposed method concentrates on the diversity of the PSF and uses a variable exponent regularization to improve flexibility of the kernel. Moreover, it can balance image edge preservation and provide staircase artifact suppression, which reduces the over- and under-reconstruction of the microscopic images effectively. By optimizing the Split\u2013Bregman algorithm, we create an efficient method that minimizes the iterative loss function under the premise of achieving high estimation accuracy. Compared with other methods, the experimental results reveal better effectiveness and robustness of the proposed method, with improvements of 18% in the peak signal-to-noise ratio, 21% in the structural similarity index measurement, and 337% in the mean structural similarity index measurement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112259345",
                    "name": "Qiong Wu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2112144548",
                    "name": "Mu Li"
                },
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "70159791",
                    "name": "Hanwen Zhao"
                },
                {
                    "authorId": "14988841",
                    "name": "Jichuan Xiong"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2027169833",
                    "name": "Peilin Yu"
                }
            ]
        },
        {
            "paperId": "9c3aff9e2faa7177875f13e73fa383a601653cac",
            "title": "Single-Image Dehazing Using Extreme Reflectance Channel Prior",
            "abstract": "Image dehazing algorithms based on dark channel prior principle have achieved good results for most scenes. However, the popular dark channel prior tends to underestimate transmissions of bright areas or objects, such as the skies, white areas and self-luminous bodies, which may cause color distortions during dehazing. A complementary prior called the extreme reflectance channel prior (ERC), which combines the dark channel prior with the bright channel prior, is proposed to estimate the transmission map. The extreme reflectance channel is the union of dark and bright channel\u2019s pixels which satisfy the corresponding channel. Based on the scattering analysis results that the intensities of pixels in ERC are often close to 0 or 1 for the natural haze-free images or close to global atmospheric light if hazes occur in the air, the pixels in a hazy image can be recovered according to ERC to calculate the transmission map and then solve the haze imaging mode. Experiments show that ERC method outperforms state-of-the-art methods in PSNR, SSIM and visual perception effects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116534877",
                    "name": "Yutong Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2112259345",
                    "name": "Qiong Wu"
                }
            ]
        },
        {
            "paperId": "bfdd1515f9f19810efcc1a6984b3175522b50064",
            "title": "Band Selection of Hyperspectral Images Using Attention-Based Autoencoders",
            "abstract": "Band selection is an effective method to reduce redundancy in a hyperspectral image (HSI) without compromising the original contents. Popular band selection methods usually use strong assumptions, such as linear or nonlinear assumptions with simple predefined Kernel functions, to model the correlations between bands. However, this kind of strong assumption may not valid in the real environment due to the complex interactions between bands. In this letter, we treat hyperspectral band selection as a spectral reconstruction task. By assuming that an HSI can be sparsely reconstructed from a few informative bands, we propose an attention-based autoencoder to model the underlying nonlinear interdependencies between bands. The proposed model consists of two parts: an attention module and an autoencoder. The attention module is used to produce the attention mask which selects the most informative bands for every pixel. The autoencoder uses these informative bands to reconstruct the raw HSI. The final band selection is conducted via clustering column vectors of the attention mask and exploring the most representative band for each cluster. Different from most of the existing band selection methods, the proposed method directly learns global nonlinear correlations between bands without strong assumptions. The proposed model is easy to implement and all the parameters can be jointly optimized using the stochastic gradient descend algorithm. Experiments on three open public data sets show that the proposed method offers the promising results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2112708387",
                    "name": "Lu Han"
                }
            ]
        }
    ]
}