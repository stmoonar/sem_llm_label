{
    "authorId": "2120292868",
    "papers": [
        {
            "paperId": "bc78ffe2e9fcf89f7aae2e8b5c0960ae419e919f",
            "title": "Target Detection Adapting to Spectral Variability in Multi-Temporal Hyperspectral Images Using Implicit Contrastive Learning",
            "abstract": "Hyperspectral target detection (HTD) is a crucial aspect of remote sensing applications, aiming to identify targets in hyperspectral images (HSIs) based on their known prior spectral signatures. However, the spectral variability resulting from various imaging conditions in multi-temporal hyperspectral images poses a challenge to both classical and deep learning (DL) methods. To overcome the limitations imposed by spectral variability, an implicit contrastive learning-based target detector (ICLTD) is proposed to exploit in-scene spectra in an unsupervised way. First, only prior spectra are utilized for explicit supervision, while an implicit contrastive learning module (ICLM) is designed to normalize the feature distributions of prior and in-scene spectra. This paper theoretically demonstrates that the ICLM can transfer the gradients from prior spectral features to those of in-scene spectra based on their feature similarities and differences. Because of transferred gradient signals, the ICLTD is regularized to extract similar representations for the prior and in-scene target spectra, while augmenting feature differences between the target and background spectra. Additionally, a local spectral similarity constraint (LSSC) is proposed to enhance the capability of scene adaptation by leveraging the spectral similarities among in-scene targets. To validate the performance of the ICLTD under spectral variability, multi-temporal HSIs captured under various imaging conditions are collected to generate prior spectra and in-scene spectra. Comparative evaluations against several DL detectors and classical methods reveal the superior performance of the ICLTD in achieving a balance between target detectability and background suppressibility under spectral variability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2260820793",
                    "name": "Pengyu Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2051261924",
                    "name": "Xiaobin Zhao"
                },
                {
                    "authorId": "2260839254",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "04f87c405cf8814dcd9185e6ef9751086a4b916c",
            "title": "EMO2-DETR: Efficient-Matching Oriented Object Detection With Transformers",
            "abstract": "Object detection in remote sensing is a challenging task due to the arbitrary orientations of objects and the vast variation in the number of objects within a single image. For instance, one image may contain hundreds of small vehicles, while another may only have a single football field. Recently, DEtection TRansformer (DETR) and its variants have achieved great success in object detection by setting a fixed number of object queries and using bipartite graph matching for one-to-one label assignment. However, we have observed that bipartite graph matching can result in relative redundancy of object queries when the number of objects changes dramatically in an image. This relative redundancy can cause two problems: slower convergence during training and redundant bounding boxes during inference. To analyze the aforementioned problems, we proposed a metric, redundancy of object query (ROQ), to quantitatively analyze the redundancy. Through experiments, we discovered that the reason for the two issues is the difficulty in distinguishing between high-quality negative samples and positive samples. In this article, we proposed efficient-matching oriented object detection with transformers (EMO2-DETR) consisting of three dedicated components to address the aforementioned issues. Specifically, reassign bipartite graph matching (RBGM) is proposed to extract high-quality negative samples from the negative samples. And ignored sample predicted head (ISPH) is proposed to predict high-quality negative samples. Then, reassigned Hungarian loss is used to better involve high-quality negative samples in the update of model parameters. Extensive experiments on DOTAv1 and DOTAv1.5 datasets demonstrated that our proposed method achieves the competitive results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2320516419",
                    "name": "Chenrui Li"
                },
                {
                    "authorId": "122009001",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "d7f29f1d6a7ad4a612c17282ac17645085f81d20",
            "title": "Pixel- And Patch-Wise Context-Aware Learning with CNN and GCN Collaboration for Hyperspectral Image Classification",
            "abstract": "Graph convolutional network (GCN) gains increasing attention in the hyperspectral image (HSI) classification by the ability to flexibly capture arbitrarily irregular objects. However, due to expensive computation, the graph construction is usually based on superpixel-wise nodes, which ignore the subtle pixel-wise features. In contrast, the convolution neural network (CNN) can mine pixel-wise spectral-spatial features but is limited to capturing local features in small square windows. In this paper, we design a new CNN and GCN collaborative network to simultaneously introduce pixel- and patch-wise contextual information. Concretely, we use the depthwise separable convolution to perform pixel-wise local feature extraction. To further mine the long-range contextual information between land covers, we concatenate a GCN. Finally, we further fuse the complementary features and decode them to obtain the classification map. Extensive experiments reveal that our method achieves competitive performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "f74ebbd4860ee84e1e7257994194828cf1308eb6",
            "title": "PM2.5 Estimation in Day/Night-Time from Himawari-8 Infrared Bands via a Deep Learning Neural Network",
            "abstract": "Satellite-based PM2.5 estimation is an effective means to achieve large-scale and long-term PM2.5 monitoring and investigation. Currently, most of methods retrieve PM2.5 from satellite-derived aerosol optical depth (AOD) or top-of-atmosphere reflectance (TOAR) during daytime. A few algorithms are also developed to retrieve nighttime PM2.5 from the satellite day\u2013night band and the accuracy is greatly limited by moonlight and artificial light sources. In this study, we utilize the properties of absorption pollutants in infrared spectrum to estimate PM2.5 concentrations from satellite infrared data, thus achieve the PM2.5 estimation in both day and night. Himawari-8 infrared bands data are used for PM2.5 estimation by a specifically designed neural network and loss function. Quantitative results show the satellite derived PM2.5 concentrations correlates with ground-based data well with R2 of 0.79 and RMSE of 15.43 \u03bcg \u00b7 m\u22123 for hourly PM2.5 estimation. Spatiotemporal distributions of model-estimated PM2.5 over China are also analyzed, and exhibit a highly consistent with ground-based measurements. Dust storms, heavy air pollution and fire smoke events are examined to further demonstrate the efficacy of our model. Our method not only circumvents the intermediate retrievals of AOD, but also enables consistent estimation of PM2.5 concentrations during daytime and nighttime in real-time monitoring.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2256840110",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2256306487",
                    "name": "Xiuqing Hu"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2256946083",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2249665454",
                    "name": "Peng Zhang"
                }
            ]
        },
        {
            "paperId": "1787c87af9407810b3d549de27313ce3dd559190",
            "title": "An improved kernelized-correlation-filter spatial target tracking method using variable regularization and spatio-temporal context model",
            "abstract": "The dim target tracking is essential for the spatial surveillance system. Considering that the starry image sequences acquired by imaging sensors often has low Signal-to-Noise Ratio (SNR), the brightness of a spatial target is often susceptible to the background interferences, such as the night clouds and the atmospheric turbulence, etc, and become dim and instable, its shape and profile is also blurred and lack of texture information. In order to extract the target from background, Spatio-Temporal Context Model (STCM) based filtering theory is applied in this paper and used to improve the traditional Kernelized-Correlation-Filter (KCF) target tracking method. It introduces a spatial weighting function that can pre-enhance the point target and suppresses the background interferences. So the tracking drift phenomenon is relieved when the moving object being obstructed temporarily. Considering that L1 regularization is easier to obtain sparse solutions and L2 regularization has smoothness property, the regularization function of the regressive classifiers in KCF target tracking method is renewed by using variable L1 or L2 regularization instead. The index of regularization in the improved regression model is a piecewise function, which is determined by the cost function during learning period that can distinguish the target star point from the background point by using the characteristics of points (such as brightness, etc.)The numeral simulation and actual processing results show that, comparing with the traditional Kernelized- Correlation-Filter (KCF) methods, the proposed method owns more robustness and precision in the starry images with low signal-to-noise ratio and complex background.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "50615889",
                    "name": "Tinghua Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                }
            ]
        },
        {
            "paperId": "87f03bc740c224217f7b4e6c0d2a1c998555898a",
            "title": "Starry image matching method based on the description of multi-scale geometric invariant features",
            "abstract": "In the spatial target surveillance and astronomical observation applications, image matching processing is the key procedure for the multi-temporal starry images or the multi-channel starry images acquired by different imaging sensors. However, the starry images obtained often have low Signal-to-Noise Ratios (SNR), the light intensities of the target stars or spacecrafts in them are vulnerable to background interferences, such as the atmospheric turbulence and the night clouds, etc., and become dim and instable. With the weak texture information of the target stars, all the influences make the feature point extraction quite difficult. In this paper, a new type of image matching method based on the description of Multi-scale Geometric Invariant Features (MGIF) is proposed, which uses the Rolling Guidance Filter (RGF) to perform preprocessing for the input images. By virtue of the excellent edge-preserving performance of the Joint Bilateral Filter in RGF, the integrities of contour profile of the star points are guaranteed effectively while the interference and other noise in the background are suppressed. Then the segmented and morphology methods are applied to extract star points and get the centroid of star points to form the feature point constellation. Considering the cross ratio of two lines in projection transformation model of image matching is a geometric invariant, a multi-scale geometric invariants based function, which uses the scaling of RGF as a reference to describe the relative spatial positions of matching points more accurately, is constructed to evaluate the level of similarity between star points according to the relative position of each points in the constellation. Subsequently, Random Sample Consensus\uff08RANSAC\uff09method is adopted to remove the mismatching star points and calculate the rigid transform matrix and other registration parameters. Digital simulation and practical processing results demonstrate that the proposed method can achieve higher matching accuracy and robustness for the starry images with low SNR and complex backgrounds.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "50615889",
                    "name": "Tinghua Zhang"
                }
            ]
        },
        {
            "paperId": "be84165c8f8924941defc5dc912c2b64d94ed5d6",
            "title": "A method of posture monitoring and falling detection based on physiological and behavioral characteristics of the elderly",
            "abstract": "At present, the problem of population aging has become a hot spot of international concern, especially in China, and the international community urgently needs a universally applicable health care system for the elderly. Recent research shows that falling is the biggest threat to the health of the elderly. Based on thihe physiological and behavioral characteristics of the elderly, the paper discusses an algorithm for the recognition of motion state and fall detection of elderly applied to wearable devices to ensure timely rescue after a fall. The algorithm continuously acquires acceleration information during the movement of the elderly through a six-axis acceleration sensor. Firstly, the acceleration data is filtered, then the combined acceleration is calculated, and multiple features of the continuous data are extracted, and then the softmax method is used to classify the different motion states to realize the alarm of the fall. The algorithm extracts the feature vector by the magnitude of the combined acceleration, which solves the problem that the single acceleration in the traditional algorithm must solves the coordinate axis, which may waste much calculating time. The algorithm is validated by using the existing data set, and the accuracy of the algorithm is up to 89%. It is an effective way to detect falls.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2210199951",
                    "name": "Shiyun Zhou"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "1575167527",
                    "name": "Haisong Tang"
                },
                {
                    "authorId": "2108082593",
                    "name": "Yanchen Liu"
                },
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "32693617",
                    "name": "Liquan Dong"
                }
            ]
        },
        {
            "paperId": "c4af35a3c200207a200fbf72d38ceeee75a39214",
            "title": "A mosaic method for multichannel sequence starry images via multiscale edge-preserving spatio-temporal context filtering",
            "abstract": "Astronomical observation and spatial target surveillance applications often require mosaic processing of starry images acquired by multiple image sensors to expand the Fields of View (FOV) or improve the resolutions. Due to the low SNR (Signal-to-Noise Ratio), lack of star point texture information and vulnerability of atmospheric turbulence of the starry image properties, traditional mosaic methods are prone to failures during feature point extraction. In this paper, Spatio-Temporal Context (STC) filtering is introduced as the preprocessing procedure to suppress the background interferences. We have improved the classical STC filtering and expands it into multi-scale space combining with Rolling-Guidance Filtering Algorithm (RGFA). Making full use of the fine edge-preserving feature of RGFA, the time-variant or spatial variant interference and noise in the background, such as glimmer stars, night clouds, sensor response noise, etc, are suppressed while the profiles of the target star points are enhanced and easy to extract their centroids. Then, we produced the feature description of the star-point sets via threshold segmentation and morphological algorithms based on geometric invariant cost function for the input image pairs to be stitched. After Random Sample Consensus (RANSAC) processing, the mismatched feature point pairs in the star-point sets are excluded. The subsequent procedures of the registration parameter calculation, image fusion and parallax correction processing are adopted to complete the mosaic processing. The results of digital simulation and practical processing show that the proposed method for the multichannel sequence starry images with the low SNR and complex backgrounds can extract feature points more precisely and more robustly comparing with the traditional methods. So, it is suitable for the large FOV spatial observation or surveillance applications.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2109052567",
                    "name": "Xiaozheng Liu"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "50615889",
                    "name": "Tinghua Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                }
            ]
        },
        {
            "paperId": "b7965b32af7db53e5d123a0797f6661764e3dd11",
            "title": "Study on Ground Penetrating Radar Signal Denoising Method Based on Surfacelet Transform and 3D Context Model",
            "abstract": "The ground penetrating radar and radar wave propagation in the subsurface environment is very complex. All kinds of noise and clutter interference is very serious, and detection echo data is a variety of with clutter. Therefore, the key techniques of data processing is to suppress clutter processing of ground penetrating radar record data. Surfacelet transform can efficiently capture and represent local surface singularities with different sizes. In order to improve the reliability of 3D ground penetrating radar detection results and accuracy, this paper presents a three-dimensional ground penetrating radar signal denoising method based on Surfacelet transform. Using Surfacelet transform and 3D context model for ground penetrating radar (GPR) analog signal to denoising, the noise in the case of low signal noise ratio (SNR) still can obtain a better result, and the simulations prove the effectiveness of the method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2217916434",
                    "name": "Dan-dan Liu"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "9322868",
                    "name": "C. Tang"
                }
            ]
        }
    ]
}