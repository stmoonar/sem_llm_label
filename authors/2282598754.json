{
    "authorId": "2282598754",
    "papers": [
        {
            "paperId": "3a55568a1d1a7e37faad1ca4e259a98e3f97027f",
            "title": "3MVRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding",
            "abstract": "This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation between token and entity representations, addressing the complexities inherent in form documents. Additionally, we introduce new inter-grained and cross-grained loss functions to further refine diverse multi-teacher knowledge distillation transfer process, presenting distribution gaps and a harmonised understanding of form documents. Through a comprehensive evaluation across publicly available form document understanding datasets, our proposed model consistently outperforms existing baselines, showcasing its efficacy in handling the intricate structures and content of visually complex form documents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166956722",
                    "name": "Yihao Ding"
                },
                {
                    "authorId": "30079913",
                    "name": "Lorenzo Vaiani"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "1712027",
                    "name": "P. Garza"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2237783897",
                    "name": "Luca Cagliero"
                }
            ]
        },
        {
            "paperId": "b80693b6402eae6b945c606cef7b9d4dc7e1bcad",
            "title": "Deep Learning based Visually Rich Document Content Understanding: A Survey",
            "abstract": "Visually Rich Documents (VRDs) are essential in academia, finance, medical fields, and marketing due to their multimodal information content. Traditional methods for extracting information from VRDs depend on expert knowledge and manual labor, making them costly and inefficient. The advent of deep learning has revolutionized this process, introducing models that leverage multimodal information vision, text, and layout along with pretraining tasks to develop comprehensive document representations. These models have achieved state-of-the-art performance across various downstream tasks, significantly enhancing the efficiency and accuracy of information extraction from VRDs. In response to the growing demands and rapid developments in Visually Rich Document Understanding (VRDU), this paper provides a comprehensive review of deep learning-based VRDU frameworks. We systematically survey and analyze existing methods and benchmark datasets, categorizing them based on adopted strategies and downstream tasks. Furthermore, we compare different techniques used in VRDU models, focusing on feature representation and fusion, model architecture, and pretraining methods, while highlighting their strengths, limitations, and appropriate scenarios. Finally, we identify emerging trends and challenges in VRDU, offering insights into future research directions and practical applications. This survey aims to provide a thorough understanding of VRDU advancements, benefiting both academic and industrial sectors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2166956722",
                    "name": "Yihao Ding"
                },
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        },
        {
            "paperId": "d80a87f3624461b36acdeb809c50979ba89fb1be",
            "title": "A Survey of Large Language Models in Finance (FinLLMs)",
            "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across a wide variety of Natural Language Processing (NLP) tasks and have attracted attention from multiple domains, including financial services. Despite the extensive research into general-domain LLMs, and their immense potential in finance, Financial LLM (FinLLM) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, performance, and opportunities and challenges. Firstly, we present a chronological overview of general-domain Pre-trained Language Models (PLMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across financial PLMs and FinLLMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets. In addition, we provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and evaluation benchmarks on GitHub.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "2111682436",
                    "name": "Nicholas Stevens"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "2282551469",
                    "name": "Minseok Song"
                }
            ]
        },
        {
            "paperId": "13e4e72303a630c4b7e581d59facfc014c846a24",
            "title": "StockEmotions: Discover Investor Emotions for Financial Sentiment Analysis and Multivariate Time Series",
            "abstract": "There has been growing interest in applying NLP techniques in the financial domain, however, resources are extremely limited. This paper introduces StockEmotions, a new dataset for detecting emotions in the stock market that consists of 10,000 English comments collected from StockTwits, a financial social media platform. Inspired by behavioral finance, it proposes 12 fine-grained emotion classes that span the roller coaster of investor emotion. Unlike existing financial sentiment datasets, StockEmotions presents granular features such as investor sentiment classes, fine-grained emotions, emojis, and time series data. To demonstrate the usability of the dataset, we perform a dataset analysis and conduct experimental downstream tasks. For financial sentiment/emotion classification tasks, DistilBERT outperforms other baselines, and for multivariate time series forecasting, a Temporal Attention LSTM model combining price index, text, and emotion features achieves the best performance than using a single feature.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "2111682494",
                    "name": "Hoyoul Luis Youn"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        },
        {
            "paperId": "37fa3a28ecddac6f38d4aace04290ffa80ba8f32",
            "title": "K-MHaS: A Multi-label Hate Speech Detection Dataset in Korean Online News Comment",
            "abstract": "Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "152997328",
                    "name": "Taejun Lim"
                },
                {
                    "authorId": "2116624870",
                    "name": "Hee-Youn Lee"
                },
                {
                    "authorId": "2182379492",
                    "name": "Bogeun Jo"
                },
                {
                    "authorId": "2182465849",
                    "name": "Yangsok Kim"
                },
                {
                    "authorId": "2182382891",
                    "name": "Heegeun Yoon"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        },
        {
            "paperId": "3c2f9375571839176a7dbe63ecaf5701b3842cfd",
            "title": "FedNLP: An Interpretable NLP System to Decode Federal Reserve Communications",
            "abstract": "The Federal Reserve System (the Fed) plays a significant role in affecting monetary policy and financial conditions worldwide. Although it is important to analyse the Fed's communications to extract useful information, it is generally long-form and complex due to the ambiguous and esoteric nature of content. In this paper, we present FedNLP, an interpretable multi-component Natural Language Processing (NLP) system to decode Federal Reserve communications. This system is designed for end-users to explore how NLP techniques can assist their holistic understanding of the Fed's communications with NO coding. Behind the scenes, FedNLP uses multiple NLP models from traditional machine learning algorithms to deep neural network architectures in each downstream task. The demonstration shows multiple results at once including sentiment analysis, summary of the document, prediction of the Federal Funds Rate movement and visualization for interpreting the prediction model's result. Our application system and demonstration are available at https://fednlp.net.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "2111682494",
                    "name": "Hoyoul Luis Youn"
                },
                {
                    "authorId": "2111682436",
                    "name": "Nicholas Stevens"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        },
        {
            "paperId": "5bc32a8f9a6245ae7f0761d539074dc7623ff61e",
            "title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection",
            "abstract": "Traditional toxicity detection models have focused on the single utterance level without deeper understanding of context. We introduce CONDA, a new dataset for in-game toxic language detection enabling joint intent classification and slot filling analysis, which is the core task of Natural Language Understanding (NLU). The dataset consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed Dota 2 matches. We propose a robust dual semantic-level toxicity framework, which handles utterance and token-level patterns, and rich contextual chatting history. Accompanying the dataset is a thorough in-game toxicity analysis, which provides comprehensive understanding of context at utterance, token, and dual levels. Inspired by NLU, we also apply its metrics to the toxicity detection tasks for assessing toxicity and game-specific aspects. We evaluate strong NLU models on CONDA, providing fine-grained results for different intent classes and slot classes. Furthermore, we examine the coverage of toxicity nature in our dataset by comparing it with other toxicity datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "69047048",
                    "name": "H. Weld"
                },
                {
                    "authorId": "123914136",
                    "name": "Guanghao Huang"
                },
                {
                    "authorId": "2282598754",
                    "name": "Jean Lee"
                },
                {
                    "authorId": "38144094",
                    "name": "T. Zhang"
                },
                {
                    "authorId": "1990752926",
                    "name": "Kunze Wang"
                },
                {
                    "authorId": "2157818919",
                    "name": "Xinghong Guo"
                },
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                }
            ]
        }
    ]
}