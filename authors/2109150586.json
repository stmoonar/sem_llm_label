{
    "authorId": "2109150586",
    "papers": [
        {
            "paperId": "34509b045b625bab87f5d3747fcae0736ea4f880",
            "title": "DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models",
            "abstract": "Even though trained mainly on images, we discover that pretrained diffusion models show impressive power in guiding sketch synthesis. In this paper, we present DiffSketcher, an innovative algorithm that creates \\textit{vectorized} free-hand sketches using natural language input. DiffSketcher is developed based on a pre-trained text-to-image diffusion model. It performs the task by directly optimizing a set of B\\'ezier curves with an extended version of the score distillation sampling (SDS) loss, which allows us to use a raster-level diffusion model as a prior for optimizing a parametric vectorized sketch generator. Furthermore, we explore attention maps embedded in the diffusion model for effective stroke initialization to speed up the generation process. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual details of the subject drawn. Our experiments show that DiffSketcher achieves greater quality than prior work. The code and demo of DiffSketcher can be found at https://ximinng.github.io/DiffSketcher-project/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "73224627",
                    "name": "Ximing Xing"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2111826724",
                    "name": "Haitao Zhou"
                },
                {
                    "authorId": "47539715",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "144873019",
                    "name": "Qian Yu"
                },
                {
                    "authorId": "2154712594",
                    "name": "Dong Xu"
                }
            ]
        },
        {
            "paperId": "3eb3cb33d2c807b88c78c12d48041ffeba2ef096",
            "title": "Graph Neural Networks without Propagation",
            "abstract": "Due to the simplicity, intuition and explanation, most Graph Neural Networks (GNNs) are proposed by following the pipeline of message passing. Although they achieve superior performances in many tasks, propagation-based GNNs possess three essential drawbacks. Firstly, the propagation tends to produce smooth effect, which meets the inductive bias of homophily, and causes two serious issues: over-smoothing issue and performance drop on networks with heterophily. Secondly, the propagations to each node are irrelevant, which prevents GNNs from modeling high-order relation, and cause the GNNs fragile to the attributes noises. Thirdly, propagation-based GNNs may be fragile to topology noise, since they heavily relay on propagation over the topology. Therefore, the propagation, as the key component of most GNNs, may be the essence of some serious issues in GNNs. To get to the root of these issue, this paper attempts to replace the propagation with a novel local operation. Quantitative experimental analysis reveals: 1) the existence of low-rank characteristic in the node attributes from ego-networks and 2) the performance improvement by reducing its rank. Motivated by this finding, this paper propose the Low-Rank GNNs, whose key component is the low-rank attribute matrix approximation in ego-network. The graph topology is employed to construct the ego-networks instead of message propagation, which is sensitive to topology noises. The proposed Low-Rank GNNs posses some attractive characteristics, including robust to topology and attribute noises, parameter-free and parallelizable. Experimental evaluations demonstrate the superior performance, robustness to noises and universality of the proposed Low-Rank GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "2215584803",
                    "name": "Qiuliang Zhang"
                },
                {
                    "authorId": "2215543502",
                    "name": "Runjie Shi"
                },
                {
                    "authorId": "2160390715",
                    "name": "Wenmiao Zhou"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2149214322",
                    "name": "Xiaochun Cao"
                },
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2188012894",
                    "name": "Zhen Wang"
                },
                {
                    "authorId": "2613860",
                    "name": "Yuanfang Guo"
                }
            ]
        },
        {
            "paperId": "6a8ebe4d640a1b3107c602bb9aa35ad0e63b8439",
            "title": "LSGNN: Towards General Graph Neural Network in Node Classification by Local Similarity",
            "abstract": "Heterophily has been considered as an issue that hurts the performance of Graph Neural Networks (GNNs). To address this issue, some existing work uses a graph-level weighted fusion of the information of multi-hop neighbors to include more nodes with homophily. However, the heterophily might differ among nodes, which requires to consider the local topology. Motivated by it, we propose to use the local similarity (LocalSim) to learn node-level weighted fusion, which can also serve as a plug-and-play module. For better fusion, we propose a novel and efficient Initial Residual Difference Connection (IRDC) to extract more informative multi-hop information. Moreover, we provide theoretical analysis on the effectiveness of LocalSim representing node homophily on synthetic graphs. Extensive evaluations over real benchmark datasets show that our proposed method, namely Local Similarity Graph Neural Network (LSGNN), can offer comparable or superior state-of-the-art performance on both homophilic and heterophilic graphs. Meanwhile, the plug-and-play model can significantly boost the performance of existing GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183577021",
                    "name": "Yuhan Chen"
                },
                {
                    "authorId": "2265724299",
                    "name": "Yihong Luo"
                },
                {
                    "authorId": "2152930282",
                    "name": "Jing Tang"
                },
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "30499006",
                    "name": "Si-Huang Qiu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2149214322",
                    "name": "Xiaochun Cao"
                }
            ]
        },
        {
            "paperId": "9853a216a0b2ec104eaba7c240a5ece8a2275110",
            "title": "Inversion-by-Inversion: Exemplar-based Sketch-to-Photo Synthesis via Stochastic Differential Equations without Training",
            "abstract": "Exemplar-based sketch-to-photo synthesis allows users to generate photo-realistic images based on sketches. Recently, diffusion-based methods have achieved impressive performance on image generation tasks, enabling highly-flexible control through text-driven generation or energy functions. However, generating photo-realistic images with color and texture from sketch images remains challenging for diffusion models. Sketches typically consist of only a few strokes, with most regions left blank, making it difficult for diffusion-based methods to produce photo-realistic images. In this work, we propose a two-stage method named ``Inversion-by-Inversion\"for exemplar-based sketch-to-photo synthesis. This approach includes shape-enhancing inversion and full-control inversion. During the shape-enhancing inversion process, an uncolored photo is generated with the guidance of a shape-energy function. This step is essential to ensure control over the shape of the generated photo. In the full-control inversion process, we propose an appearance-energy function to control the color and texture of the final generated photo.Importantly, our Inversion-by-Inversion pipeline is training-free and can accept different types of exemplars for color and texture control. We conducted extensive experiments to evaluate our proposed method, and the results demonstrate its effectiveness. The code and project can be found at https://ximinng.github.io/inversion-by-inversion-project/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "73224627",
                    "name": "Ximing Xing"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2111826724",
                    "name": "Haitao Zhou"
                },
                {
                    "authorId": "48430950",
                    "name": "Zhihao Hu"
                },
                {
                    "authorId": "2399563",
                    "name": "Chongxuan Li"
                },
                {
                    "authorId": "2154712594",
                    "name": "Dong Xu"
                },
                {
                    "authorId": "144873019",
                    "name": "Qian Yu"
                }
            ]
        },
        {
            "paperId": "bc4970fea6a84d8c719b0567cdac40de63228265",
            "title": "SketchInverter: Multi-Class Sketch-Based Image Generation via GAN Inversion",
            "abstract": "This paper proposes the first GAN inversion-based method for multi-class sketch-based image generation (MCSBIG). MC-SBIG is a challenging task that requires strong prior knowledge due to the significant domain gap between sketches and natural images. Existing learning-based approaches rely on a large-scale paired dataset to learn the mapping between these two image modalities. However, since the public paired sketch-photo data are scarce, it is struggling for learning-based methods to achieve satisfactory results. In this work, we introduce a new approach based on GAN inversion, which can utilize a powerful pretrained generator to facilitate image generation from a given sketch. Our GAN inversion-based method has two advantages: 1. it can freely take advantage of the prior knowledge of a pretrained image generator; 2. it allows the proposed model to focus on learning the mapping from a sketch to a low-dimension latent code, which is a much easier task than directly mapping to a high-dimension natural image. We also present a novel shape loss to improve generation quality further. Extensive experiments are conducted to show that our method can produce sketch-faithful and photo-realistic images and significantly outperform the baseline methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204713219",
                    "name": "Zirui An"
                },
                {
                    "authorId": "2204730897",
                    "name": "Jingbo Yu"
                },
                {
                    "authorId": "9326827",
                    "name": "Runtao Liu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2087411164",
                    "name": "Qian Yu"
                }
            ]
        },
        {
            "paperId": "ca052c254fef9d7121638daf5fe6df582f451d19",
            "title": "A Fabric Defect Detection Method Based on Deep Learning",
            "abstract": "Fabric defect detection is a challenging task in the fabric industry because of the complex shapes and large variety of fabric defects. Many methods have been proposed to solve this problem, but their detection speed and accuracy were very low. As a classic deep learning method and end-to-end target detection algorithm, YOLOv4 has evolved rapidly and has been applied in many industries, showing good performance. This paper proposes an improved YOLOv4 algorithm with higher accuracy for fabric defect detection, in which a new SPP structure that uses SoftPool instead of MaxPool is adopted. The improved YOLOv4 algorithm with three SoftPools can process the feature map effectively, which has a significant advantage in reducing the negative side effects of the SPP structure and improving the detection accuracy. The improved SPP structure is used by the three outputs of Backbone, and in order to ensure that the output can be inputted into the subsequent PANet successfully, the network structure is improved that a series of convolution layers after the SPP structure is added for reducing the channel numbers of feature map to an appropriate value. In addition, contrast-limited adaptive histogram equalization is adopted in advance to improve the image quality, which results in strong anti-interference abilities and can slightly increase the mAP. Experimental results show that, compared with the original YOLOV4, the improved YOLOv4 increases the mAP effectively by 6%, while the FPS only decreases by 2. The improved YOLOv4 can identify the location of defects accurately and quickly, and can also be applied in other defect detection industries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146553893",
                    "name": "Qiang Liu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2116186236",
                    "name": "Yusheng Li"
                },
                {
                    "authorId": "2106685814",
                    "name": "Mingwang Gao"
                },
                {
                    "authorId": "2108960592",
                    "name": "Jingao Li"
                }
            ]
        },
        {
            "paperId": "1163c29ae6a26b1cd8d85280740410e99001a959",
            "title": "Self-Supervised Graph Neural Networks via Diverse and Interactive Message Passing",
            "abstract": "By interpreting Graph Neural Networks (GNNs) as the message passing from the spatial perspective, their success is attributed to Laplacian smoothing. However, it also leads to serious over-smoothing issue by stacking many layers. Recently, many efforts have been paid to overcome this issue in semi-supervised learning. Unfortunately, it is more serious in unsupervised node representation learning task due to the lack of supervision information. Thus, most of the unsupervised or self-supervised GNNs often employ \\textit{one-layer GCN} as the encoder. Essentially, the over-smoothing issue is caused by the over-simplification of the existing message passing, which possesses two intrinsic limits: blind message and uniform passing. In this paper, a novel Diverse and Interactive Message Passing (DIMP) is proposed for self-supervised learning by overcoming these limits. Firstly, to prevent the message from blindness and make it interactive between two connected nodes, the message is determined by both the two connected nodes instead of the attributes of one node. Secondly, to prevent the passing from uniformness and make it diverse over different attribute channels, different propagation weights are assigned to different elements in the message. To this end, a natural implementation of the message in DIMP is the element-wise product of the representations of two connected nodes. From the perspective of numerical optimization, the proposed DIMP is equivalent to performing an overlapping community detection via expectation-maximization (EM). Both the objective function of the community detection and the convergence of EM algorithm guarantee that DMIP can prevent from over-smoothing issue. Extensive evaluations on node-level and graph-level tasks demonstrate the superiority of DIMP on improving performance and overcoming over-smoothing issue.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "2145775206",
                    "name": "Cheng Chen"
                },
                {
                    "authorId": "1409858224",
                    "name": "Weixun Li"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "6413344",
                    "name": "Junhua Gu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2613860",
                    "name": "Yuanfang Guo"
                },
                {
                    "authorId": "1719250",
                    "name": "Xiaochun Cao"
                }
            ]
        },
        {
            "paperId": "370fb0f5dfb590fad83705e1afc2ba3570335542",
            "title": "Difference Residual Graph Neural Networks",
            "abstract": "Graph Neural Networks have been widely employed for multimodal fusion and embedding. To overcome over-smoothing issue, residual connections, which are designed for alleviating vanishing gradient problem in NNs, are adopted in Graph Neural Networks (GNNs) to incorporate local node information. However, these simple residual connections are ineffective on networks with heterophily, since the roles of both convolutional operations and residual connections in GNNs are significantly different from those in classic NNs. By considering the specific smoothing characteristic of graph convolutional operation, deep layers in GNNs are expected to focus on the data which can't be properly handled in shallow layers. To this end, a novel and universal Difference Residual Connections (DRC), which feed the difference of the output and input of previous layer as the input of the next layer, is proposed. Essentially, Difference Residual Connections is equivalent to inserting layers with opposite effect (e.g., sharpening) into the network to prevent the excessive effect (e.g., over-smoothing issue) induced by too many layers with the similar role (e.g., smoothing) in GNNs. From the perspective of optimization, DRC is the gradient descent method to minimize an objective function with both smoothing and sharpening terms. The analytic solution to this objective function is determined by both graph topology and node attributes, which theoretically proves that DRC can prevent over-smoothing issue. Extensive experiments demonstrate the superiority of DRC on real networks with both homophily and heterophily, and show that DRC can automatically determine the model depth and be adaptive to both shallow and deep models with two complementary components.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "118103314",
                    "name": "Weihang Peng"
                },
                {
                    "authorId": "2160390715",
                    "name": "Wenmiao Zhou"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "6413344",
                    "name": "Junhua Gu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2613860",
                    "name": "Yuanfang Guo"
                },
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2149214322",
                    "name": "Xiaochun Cao"
                }
            ]
        },
        {
            "paperId": "93dd8137cc33cca8ca3982da6873ff2aa1ee1467",
            "title": "OPEN: Orthogonal Propagation with Ego-Network Modeling",
            "abstract": "To alleviate the unfavorable effect of noisy topology in Graph Neural networks (GNNs), some efforts perform the local topology re\ufb01nement through the pairwise propagation weight learning and the multi-channel extension. Unfortunately, most of them suffer a common and fatal drawback: irrelevant propagation to one node and in multi-channels. These two kinds of irrelevances make propagation weights in multi-channels free to be determined by the labeled data, and thus the GNNs are exposed to over\ufb01tting. To tackle this issue, a novel Orthogonal Propagation with Ego-Network modeling (OPEN) is proposed by modeling relevances between propagations. Speci\ufb01cally, the relevance between propagations to one node is modeled by whole ego-network modeling, while the relevance between propagations in multi-channels is modeled via diversity requirement. By interpreting the propagations to one node from the perspective of dimension reduction, propagation weights are inferred from principal components of the ego-network, which are orthogonal to each other. Theoretical analysis and experimental evaluations reveal four attractive characteristics of OPEN as modeling high-order relationships beyond pairwise one, preventing over\ufb01tting, robustness, and high ef\ufb01ciency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "2216273694",
                    "name": "Lina Kang"
                },
                {
                    "authorId": "2112667898",
                    "name": "Qiuliang Zhang"
                },
                {
                    "authorId": "2004582449",
                    "name": "Mengzhe Li"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2188012894",
                    "name": "Zhen Wang"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2149214322",
                    "name": "Xiaochun Cao"
                },
                {
                    "authorId": "2613860",
                    "name": "Yuanfang Guo"
                }
            ]
        },
        {
            "paperId": "f8b8d4db4334303aa2e432af9bffca56b85ca4c3",
            "title": "Graph Neural Networks Beyond Compromise Between Attribute and Topology",
            "abstract": "Although existing Graph Neural Networks (GNNs) based on message passing achieve state-of-the-art, the over-smoothing issue, node similarity distortion issue and dissatisfactory link prediction performance can\u2019t be ignored. This paper summarizes these issues as the interference between topology and attribute for the first time. By leveraging the recently proposed optimization perspective of GNNs, this interference is analyzed and ascribed to that the learned representation in GNNs essentially compromises between the topology and node attribute. To alleviate the interference, this paper attempts to break this compromise by proposing a novel objective function, which fits node attribute and topology with different representations and introduces mutual exclusion constraints to reduce the redundancy in both representations. The mutual exclusion employs the statistical dependence, which regards the representations from topology and attribute as the observations of two random variables, and is implemented with Hilbert-Schmidt Independence Criterion. Derived from the novel objective function, a novel GNN, i.e., Graph Neural Network Beyond Compromise (GNN-BC), is proposed to iteratively updates the representations of topology and attribute by simultaneously capturing semantic information and removing the common information, and the final representation is the concatenation of them. The performance improvements on node classification and link prediction demonstrate the superiority of GNN-BC on relieving the interference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "2160390715",
                    "name": "Wenmiao Zhou"
                },
                {
                    "authorId": "118103314",
                    "name": "Weihang Peng"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "6413344",
                    "name": "Junhua Gu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2149214322",
                    "name": "Xiaochun Cao"
                },
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                }
            ]
        }
    ]
}