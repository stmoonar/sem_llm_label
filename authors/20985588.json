{
    "authorId": "20985588",
    "papers": [
        {
            "paperId": "4af2fb6dc09f88eff19e681d51e2aa61a6ebf50c",
            "title": "Using Voice Data to Facilitate Depression Risk Assessment in Primary Health Care",
            "abstract": "Voice-only telehealth is often more practical for lower-income patients who may lack stable internet connections. Thus, our study focused on using voice data to predict depression risk. The objectives were to: 1) Collect voice data from 24 people (12 with depression and 12 without mental health or major health condition diagnoses); 2) Build a machine learning model to predict depression risk. TPOT, an autoML tool, was used to select the best machine learning algorithm, which was the K-nearest neighbors classifier. The selected model had high performance in classifying depression risk (Precision: 0.98, Recall: 0.93, F1-Score: 0.96), compared to previous models. These findings may lead to a range of tools to help screen for and treat depression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9126017",
                    "name": "Abhay Goyal"
                },
                {
                    "authorId": "1742319448",
                    "name": "Roger Ho Chun Man"
                },
                {
                    "authorId": "2282413929",
                    "name": "Roy Ka-Wei Lee"
                },
                {
                    "authorId": "2279735851",
                    "name": "Koustuv Saha"
                },
                {
                    "authorId": "2256044605",
                    "name": "Frederick L. Altice"
                },
                {
                    "authorId": "2253698630",
                    "name": "Christian Poellabauer"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "2256062685",
                    "name": "Lam Yin Cheung"
                },
                {
                    "authorId": "117633375",
                    "name": "M. de Choudhury"
                },
                {
                    "authorId": "2306272346",
                    "name": "Kanica Allagh"
                },
                {
                    "authorId": "2256319943",
                    "name": "Navin Kumar"
                }
            ]
        },
        {
            "paperId": "6bf86c2c339303f2f68395e789b2a4cbaa34ec7f",
            "title": "Position: Measure Dataset Diversity, Don't Just Claim It",
            "abstract": "Machine learning (ML) datasets, often perceived as neutral, inherently encapsulate abstract and disputed social constructs. Dataset curators frequently employ value-laden terms such as diversity, bias, and quality to characterize datasets. Despite their prevalence, these terms lack clear definitions and validation. Our research explores the implications of this issue by analyzing\"diversity\"across 135 image and text datasets. Drawing from social sciences, we apply principles from measurement theory to identify considerations and offer recommendations for conceptualizing, operationalizing, and evaluating diversity in datasets. Our findings have broader implications for ML research, advocating for a more nuanced and precise approach to handling value-laden properties in dataset construction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305652683",
                    "name": "Dora Zhao"
                },
                {
                    "authorId": "50819534",
                    "name": "Jerone T. A. Andrews"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "2282530695",
                    "name": "Alice Xiang"
                }
            ]
        },
        {
            "paperId": "9c70b8ca18bc38ac3ebf22129aa0ed33b2c25e89",
            "title": "Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech Generators",
            "abstract": "The rapid and wide-scale adoption of AI to generate human speech poses a range of significant ethical and safety risks to society that need to be addressed. For example, a growing number of speech generation incidents are associated with swatting attacks in the United States, where anonymous perpetrators create synthetic voices that call police officers to close down schools and hospitals, or to violently gain access to innocent citizens\u2019 homes. Incidents like this demonstrate that multimodal generative AI risks and harms do not exist in isolation, but arise from the interactions of multiple stakeholders and technical AI systems. In this paper we analyse speech generation incidents to study how patterns of specific harms arise. We find that specific harms can be categorised according to the exposure of affected individuals, that is to say whether they are a subject of, interact with, suffer due to, or are excluded from speech generation systems. Similarly, specific harms are also a consequence of the motives of the creators and deployers of the systems. Based on these insights we propose a conceptual framework for modelling pathways to ethical and safety harms of AI, which we use to develop a taxonomy of harms of speech generators. Our relational approach captures the complexity of risks and harms in sociotechnical AI systems, and yields a taxonomy that can support appropriate policy interventions and decision making for the responsible development and release of speech generation models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2297187154",
                    "name": "Wiebke Hutiri"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "2282530695",
                    "name": "Alice Xiang"
                }
            ]
        },
        {
            "paperId": "b7403fa955e09500f141e852106df59d98aa2239",
            "title": "Mapping the Landscape of Independent Food Delivery Platforms in the United States",
            "abstract": "Beyond the well-known giants like Uber Eats and DoorDash, there are hundreds of independent food delivery platforms in the United States. However, little is known about the sociotechnical landscape of these \"indie'' platforms. In this paper, we analyzed these platforms to understand why they were created, how they operate, and what technologies they use. We collected data on 495 indie platforms and detailed survey responses from 29 platforms. We found that personalized, timely service is a central value of indie platforms, as is a sense of responsibility to the local community they serve. Indie platforms are motivated to provide fair rates for restaurants and couriers. These alternative business practices differentiate them from mainstream platforms. Though indie platforms have plans to expand, a lack of customizability in off-the-shelf software prevents independent platforms from personalizing services for their local communities. We show that these platforms are a widespread and longstanding fixture of the food delivery market. We illustrate the diversity of motivations and values to explain why a one-size-fits-all support is insufficient, and we discuss the siloing of technology that inhibits platforms' growth. Through these insights, we aim to promote future HCI research into the potential development of public-interest technologies for local food delivery.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183719691",
                    "name": "Yuhan Liu"
                },
                {
                    "authorId": "12561665",
                    "name": "Amna Liaqat"
                },
                {
                    "authorId": "2284982927",
                    "name": "Owen Xingjian Zhang"
                },
                {
                    "authorId": "2284991152",
                    "name": "Mariana Consuelo Fern'andez Espinosa"
                },
                {
                    "authorId": "2284990944",
                    "name": "Ankhitha Manjunatha"
                },
                {
                    "authorId": "2285081401",
                    "name": "Alexander Yang"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "2266397659",
                    "name": "Andr'es Monroy-Hern'andez"
                }
            ]
        },
        {
            "paperId": "d67d3373264980cba126b9bf84d8667fc6680805",
            "title": "Attitudes Toward Facial Analysis AI: A Cross-National Study Comparing Argentina, Kenya, Japan, and the USA",
            "abstract": "Computer vision AI systems present one of the most radical technical transformations of our time. Such systems are given unparalleled epistemic power to impose meaning on visual data, despite their inherent semantic ambiguity. This epistemic power is particularly evident in computer vision AI that interprets the meaning of human faces. The goal of this work is to empirically document laypeople\u2019s perceptions of the epistemic and ethical complexity of computer vision AI through a large-scale qualitative study with participants in Argentina, Japan, Kenya, and the USA (N=4,468). We developed a vignette scenario about a fictitious company that analyzes people\u2019s portraits using computer vision AI to make a variety of inferences about people based on their faces. For each inference that the fictitious company draws (e.g., age, skin color, intelligence), we ask participants from all countries to reason about how they evaluate computer vision AI inference-making. In a series of workshops, we collaborated as a multinational research team to develop a codebook that captures people\u2019s different justifications of facial analysis AI inferences to create a comprehensive justification portfolio. Our study reveals similarities in justification patterns, but also significant intra-country and inter-country diversity in response to different facial inferences. For example, participants from Argentina, Japan, Kenya, and the USA vastly disagree over the reasonableness of AI classifications such as beautiful or skin color. They tend to agree in their opposition to AI-drawn inferences intelligence and trustworthiness. Adding much-needed non-Western perspectives to debates on computer vision ethics, our results suggest that, contrary to popular justifications for facial classification technologies, there is no such thing as a \u201ccommon sense\u201d facial classification that accords simply with a general, homogeneous \u201chuman intuition.\u201d",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2171365830",
                    "name": "Chiara Ullstein"
                },
                {
                    "authorId": "66181683",
                    "name": "Severin Engelmann"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "4450558",
                    "name": "Yuko Ikkatai"
                },
                {
                    "authorId": "2304956988",
                    "name": "Naira Paola Arnez-Jordan"
                },
                {
                    "authorId": "2304982926",
                    "name": "Rose Caleno"
                },
                {
                    "authorId": "2304958777",
                    "name": "Brian Mboya"
                },
                {
                    "authorId": "2039830116",
                    "name": "Shuichiro Higuma"
                },
                {
                    "authorId": "2149731561",
                    "name": "Tilman Hartwig"
                },
                {
                    "authorId": "28841949",
                    "name": "Hiromi M. Yokoyama"
                },
                {
                    "authorId": "2150711523",
                    "name": "Jens Grossklags"
                }
            ]
        },
        {
            "paperId": "eac8c19f0c7bcce7ff24dc70fd9dc8efdc73f0ce",
            "title": "Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes",
            "abstract": "We tackle societal bias in image-text datasets by removing spurious correlations between protected groups and image attributes. Traditional methods only target labeled attributes, ignoring biases from unlabeled ones. Using text-guided inpainting models, our approach ensures protected group independence from all attributes and mitigates inpainting biases through data filtering. Evaluations on multi-label image classification and image captioning tasks show our method effectively reduces bias without compromising performance across various models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294876537",
                    "name": "Yusuke Hirota"
                },
                {
                    "authorId": "50819534",
                    "name": "Jerone T. A. Andrews"
                },
                {
                    "authorId": "2305652683",
                    "name": "Dora Zhao"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "2618576",
                    "name": "Apostolos Modas"
                },
                {
                    "authorId": "2307472725",
                    "name": "Yuta Nakashima"
                },
                {
                    "authorId": "2282530695",
                    "name": "Alice Xiang"
                }
            ]
        },
        {
            "paperId": "04c041ca2ed809580e680b6d810cb58f893c1246",
            "title": "A Reflection on How Cross-Cultural Perspectives on the Ethics of Facial Analysis AI Can Inform EU Policymaking",
            "abstract": "The EU AI Act proposal addresses, among other applications, AI systems that enable facial classification and emotion recognition. As part of previous work, we have investigated how citizens deliberate about the validity of AI-based facial classifications in the advertisement and the hiring contexts (N = 3745). In our current research, we extend this investigation by collecting laypeople\u2019s ethical evaluations of facial analysis AI in Japan, Argentina, Kenya and the United States (N ~4000). Our project serves as a motivation to ask how such cross-cultural AI ethics perspectives can inform EU policymaking regarding AI systems, which enable facial classification and emotion recognition. We refer to suggestions on achieving policy impact and aim to discuss this topic space with workshop participants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2171365830",
                    "name": "Chiara Ullstein"
                },
                {
                    "authorId": "66181683",
                    "name": "Severin Engelmann"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "2150711523",
                    "name": "Jens Grossklags"
                }
            ]
        },
        {
            "paperId": "2e57b4704088507f93c0a92b2d79ab814f59ff2b",
            "title": "Ethical Considerations for Responsible Data Curation",
            "abstract": "Human-centric computer vision (HCCV) data curation practices often neglect privacy and bias concerns, leading to dataset retractions and unfair models. HCCV datasets constructed through nonconsensual web scraping lack crucial metadata for comprehensive fairness and robustness evaluations. Current remedies are post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application. Our research focuses on proactive, domain-specific recommendations, covering purpose, privacy and consent, and diversity, for curating HCCV evaluation datasets, addressing privacy and bias concerns. We adopt an ante hoc reflective perspective, drawing from current practices, guidelines, dataset withdrawals, and audits, to inform our considerations and recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50819534",
                    "name": "Jerone T. A. Andrews"
                },
                {
                    "authorId": "2116403497",
                    "name": "Dora Zhao"
                },
                {
                    "authorId": "2067103717",
                    "name": "William Thong"
                },
                {
                    "authorId": "2618576",
                    "name": "Apostolos Modas"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "4990825",
                    "name": "Alice Xiang"
                }
            ]
        },
        {
            "paperId": "2f918e0232d3b7c2cabecaaa7edc976e068ce0c6",
            "title": "Upvotes? Downvotes? No Votes? Understanding the relationship between reaction mechanisms and political discourse on Reddit",
            "abstract": "A significant share of political discourse occurs online on social media platforms. Policymakers and researchers try to understand the role of social media design in shaping the quality of political discourse around the globe. In the past decades, scholarship on political discourse theory has produced distinct characteristics of different types of prominent political rhetoric such as deliberative, civic, or demagogic discourse. This study investigates the relationship between social media reaction mechanisms (i.e., upvotes, downvotes) and political rhetoric in user discussions by engaging in an in-depth conceptual analysis of political discourse theory. First, we analyze 155 million user comments in 55 political subforums on Reddit between 2010 and 2018 to explore whether users\u2019 style of political discussion aligns with the essential components of deliberative, civic, and demagogic discourse. Second, we perform a quantitative study that combines confirmatory factor analysis with difference in differences models to explore whether different reaction mechanism schemes (e.g., upvotes only, upvotes and downvotes, no reaction mechanisms) correspond with political user discussion that is more or less characteristic of deliberative, civic, or demagogic discourse. We produce three main takeaways. First, despite being \u201cideal constructs of political rhetoric,\u201d we find that political discourse theories describe political discussions on Reddit to a large extent. Second, we find that discussions in subforums with only upvotes, or both up- and downvotes are associated with user discourse that is more deliberate and civic. Third, and perhaps most strikingly, social media discussions are most demagogic in subreddits with no reaction mechanisms at all. These findings offer valuable contributions for ongoing policy discussions on the relationship between social media interface design and respectful political discussion among users.1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "66181683",
                    "name": "Severin Engelmann"
                },
                {
                    "authorId": "2143255336",
                    "name": "Amy Winecoff"
                }
            ]
        },
        {
            "paperId": "46c6ec05a04d220f96476654ea206963d4de0e62",
            "title": "Ethical Considerations for Collecting Human-Centric Image Datasets",
            "abstract": "Human-centric image datasets are critical to the development of computer vision technologies. However, recent investigations have foregrounded signi\ufb01cant ethical issues related to privacy and bias, which have resulted in the complete retraction, or modi\ufb01cation, of several prominent datasets. Recent works have tried to reverse this trend, for example, by proposing analytical frameworks for ethi-cally evaluating datasets, the standardization of dataset documentation and curation practices, privacy preservation methodologies, as well as tools for surfacing and mitigating representational biases. Little attention, however, has been paid to the realities of operationalizing ethical data collection. To \ufb01ll this gap, we present a set of key ethical considerations and practical recommendations for collecting more ethically-minded human-centric image data. Our research directly addresses issues of privacy and bias by contributing to the research community best practices for ethical data collection, covering purpose, privacy and consent, as well as diversity. We motivate each consideration by drawing on lessons from current practices, dataset withdrawals and audits, and analytical ethical frameworks. Our research is intended to augment recent scholarship, representing an important step toward more responsible data curation practices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50819534",
                    "name": "Jerone T. A. Andrews"
                },
                {
                    "authorId": "2116403497",
                    "name": "Dora Zhao"
                },
                {
                    "authorId": "2067103717",
                    "name": "William Thong"
                },
                {
                    "authorId": "2618576",
                    "name": "Apostolos Modas"
                },
                {
                    "authorId": "20985588",
                    "name": "Orestis Papakyriakopoulos"
                },
                {
                    "authorId": "1925017",
                    "name": "Shruti Nagpal"
                },
                {
                    "authorId": "4990825",
                    "name": "Alice Xiang"
                }
            ]
        }
    ]
}