{
    "authorId": "2111191142",
    "papers": [
        {
            "paperId": "84420e4bef77c95963d1496914dab796465b641c",
            "title": "Modeling Co-Evolution of Attributed and Structural Information in Graph Sequence",
            "abstract": "Most graph neural network models learn embeddings of nodes in static attributed graphs for predictive analysis. Recent attempts have been made to learn temporal proximity of the nodes. We find that real dynamic attributed graphs exhibit complex phenomenon of co-evolution between node attributes and graph structure. Learning node embeddings for forecasting change of node attributes and evolution of graph structure over time remains an open problem. In this work, we present a novel framework called CoEvoGNN for modeling dynamic attributed graph sequence. It preserves the impact of earlier graphs on the current graph by embedding generation through the sequence of attributed graphs. It has a temporal self-attention architecture to model long-range dependencies in the evolution. Moreover, CoEvoGNN optimizes model parameters jointly on two dynamic tasks, attribute inference and link prediction over time. So the model can capture the co-evolutionary patterns of attribute change and link formation. This framework can adapt to any graph neural algorithms so we implemented and investigated three methods based on it: CoEvoGCN, CoEvoGAT, and CoEvoSAGE. Experiments demonstrate the framework (and its methods) outperforms strong baseline methods on predicting an entire unseen graph snapshot of personal attributes and interpersonal links in dynamic social graphs and financial graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "72871419",
                    "name": "Zhihan Zhang"
                },
                {
                    "authorId": "2146276586",
                    "name": "Yihong Ma"
                },
                {
                    "authorId": "1742573",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "26888084",
                    "name": "Tianwen Jiang"
                },
                {
                    "authorId": "144539424",
                    "name": "N. Chawla"
                },
                {
                    "authorId": "1470716407",
                    "name": "Meng Jiang"
                }
            ]
        },
        {
            "paperId": "a0c2052ea02e1916263841db5b9ca3b13e10ccd1",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts' granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts' granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12318198",
                    "name": "Zijie Huang"
                },
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "9544714",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2987847",
                    "name": "Yangkexin Liang"
                },
                {
                    "authorId": "1879297505",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2157096355",
                    "name": "Xian Li"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2158624285",
                    "name": "Wei Wang"
                }
            ]
        },
        {
            "paperId": "61f737d6317c2c6b6386efe5188ad5a5017318fa",
            "title": "Deep Multimodal Complementarity Learning",
            "abstract": "Complementarity plays a significant role in the synergistic effect created by different components of a complex data object. Complementarity learning on multimodal data has fundamental challenges of representation learning because the complementarity exists along with multiple modalities and one or multiple items of each modality. Also, an appropriate metric is needed for measuring the complementarity in the representation space. Existing methods that rely on similarity-based metrics cannot adequately capture the complementarity. In this work, we propose a novel deep architecture for systematically learning the complementarity of components from multimodal multi-item data. The proposed model consists of three major modules: 1) unimodal aggregation for extracting the intramodal complementarity; 2) cross-modal fusion for extracting the intermodal complementarity at the modality level; and 3) interactive aggregation for extracting the intermodal complementarity at the item level. To quantify complementarity, we utilize the TUBE distance metric to measure the difference between the composited data object and its label in the representation space. Experiments on three real datasets show that our model outperforms the state-of-the-art by +6.8% of mean reciprocal rank (MRR) on object classification and +3.0% of MRR on hold-out item prediction. Qualitative analyses reveal that complementarity is significantly different from similarity.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "1742573",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "70461341",
                    "name": "Wenhao Yu"
                },
                {
                    "authorId": "144539424",
                    "name": "N. Chawla"
                },
                {
                    "authorId": "144812586",
                    "name": "Meng Jiang"
                }
            ]
        },
        {
            "paperId": "153a4c7272ebf4883746d2629f98749a857c8018",
            "title": "TCN: Table Convolutional Network for Web Table Interpretation",
            "abstract": "Information extraction from semi-structured webpages provides valuable long-tailed facts for augmenting knowledge graph. Relational Web tables are a critical component containing additional entities and attributes of rich and diverse knowledge. However, extracting knowledge from relational tables is challenging because of sparse contextual information. Existing work linearize table cells and heavily rely on modifying deep language models such as BERT which only captures related cells information in the same table. In this work, we propose a novel relational table representation learning approach considering both the intra- and inter-table contextual information. On one hand, the proposed Table Convolutional Network model employs the attention mechanism to adaptively focus on the most informative intra-table cells of the same row or column; and, on the other hand, it aggregates inter-table contextual information from various types of implicit connections between cells across different tables. Specifically, we propose three novel aggregation modules for (i) cells of the same value, (ii) cells of the same schema position, and (iii) cells linked to the same page topic. We further devise a supervised multi-task training objective for jointly predicting column type and pairwise column relation, as well as a table cell recovery objective for pre-training. Experiments on real Web table datasets demonstrate our method can outperform competitive baselines by of F1 for column type prediction and by of F1 for pairwise column relation prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "3310534",
                    "name": "Prashant Shiralkar"
                },
                {
                    "authorId": "144182018",
                    "name": "Colin Lockard"
                },
                {
                    "authorId": "9544714",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                },
                {
                    "authorId": "144812586",
                    "name": "Meng Jiang"
                }
            ]
        },
        {
            "paperId": "1abea3a08c56da8bf4930796317a3d0fdd0518fb",
            "title": "Learning from Counterfactual Links for Link Prediction",
            "abstract": "Learning to predict missing links is important for many graph-based applications. Existing methods were designed to learn the association between observed graph structure and existence of link between a pair of nodes. However, the causal relationship between the two variables was largely ignored for learning to predict links on a graph. In this work, we visit this factor by asking a counterfactual question:\"would the link still exist if the graph structure became different from observation?\"Its answer, counterfactual links, will be able to augment the graph data for representation learning. To create these links, we employ causal models that consider the information (i.e., learned representations) of node pairs as context, global graph structural properties as treatment, and link existence as outcome. We propose a novel data augmentation-based link prediction method that creates counterfactual links and learns representations from both the observed and counterfactual links. Experiments on benchmark data show that our graph learning method achieves state-of-the-art performance on the task of link prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1742573",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "2146562364",
                    "name": "Gang Liu"
                },
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "70461341",
                    "name": "Wenhao Yu"
                },
                {
                    "authorId": "144812586",
                    "name": "Meng Jiang"
                }
            ]
        },
        {
            "paperId": "6ea7a339f2b64f6b1853146fad36f78b0fc68865",
            "title": "Counterfactual Graph Learning for Link Prediction",
            "abstract": "Learning to predict missing links is important for many graph-based applications. Existing methods were designed to learn the observed association between two sets of variables: (1) the observed graph structure and (2) the existence of link between a pair of nodes. However, the causal relationship between these variables was ignored and we visit the possibility of learning it by simply asking a counterfactual question: \u201c would the link exist or not if the observed graph structure became different? \u201d To answer this question by causal inference, we consider the information of the node pair as context, global graph structural properties as treatment, and link existence as outcome. In this work, we propose a novel link prediction method that enhances graph learning by the counterfactual inference. It creates counterfactual links from the observed ones, and our method learns representations from both of them. Experiments on a number of benchmark datasets show that our proposed method achieves the state-of-the-art performance on link prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1742573",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "2146562364",
                    "name": "Gang Liu"
                },
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "38767143",
                    "name": "W. Yu"
                },
                {
                    "authorId": "144812586",
                    "name": "Meng Jiang"
                }
            ]
        },
        {
            "paperId": "a7fb10bd01a76c01573cba5d67ce63d2c17593bb",
            "title": "Unified Representation of Twitter and Online News Using Graph and Entities",
            "abstract": "To improve consumer engagement and satisfaction, online news services employ strategies for personalizing and recommending articles to their users based on their interests. In addition to news agencies\u2019 own digital platforms, they also leverage social media to reach out to a broad user base. These engagement efforts are often disconnected with each other, but present a compelling opportunity to incorporate engagement data from social media to inform their digital news platform and vice-versa, leading to a more personalized experience for users. While this idea seems intuitive, there are several challenges due to the disparate nature of the two sources. In this paper, we propose a model to build a generalized graph of news articles and tweets that can be used for different downstream tasks such as identifying sentiment, trending topics, and misinformation, as well as sharing relevant articles on social media in a timely fashion. We evaluate our framework on a downstream task of identifying related pairs of news articles and tweets with promising results. The content unification problem addressed by our model is not unique to the domain of news, and thus can be applicable to other problems linking different content platforms.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "3445530",
                    "name": "Munira Syed"
                },
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "1470716407",
                    "name": "Meng Jiang"
                },
                {
                    "authorId": "2095106340",
                    "name": "Oliver Conway"
                },
                {
                    "authorId": "48656952",
                    "name": "Vishal Juneja"
                },
                {
                    "authorId": "2069607150",
                    "name": "Sriram Subramanian"
                },
                {
                    "authorId": "144539424",
                    "name": "N. Chawla"
                }
            ]
        },
        {
            "paperId": "cb996f0ba055286e61720435cc1023f66e4705c7",
            "title": "Modeling Complementarity in Behavior Data with Multi-Type Itemset Embedding",
            "abstract": "People are looking for complementary contexts, such as team members of complementary skills for project team building and/or reading materials of complementary knowledge for effective student learning, to make their behaviors more likely to be successful. Complementarity has been revealed by behavioral sciences as one of the most important factors in decision making. Existing computational models that learn low-dimensional context representations from behavior data have poor scalability and recent network embedding methods only focus on preserving the similarity between the contexts. In this work, we formulate a behavior entry as a set of context items and propose a novel representation learning method, Multi-type Itemset Embedding, to learn the context representations preserving the itemset structures. We propose a measurement of complementarity between context items in the embedding space. Experiments demonstrate both effectiveness and efficiency of the proposed method over the state-of-the-art methods on behavior prediction and context recommendation. We discover that the complementary contexts and similar contexts are significantly different in human behaviors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "1694209",
                    "name": "Qingkai Zeng"
                },
                {
                    "authorId": "144539424",
                    "name": "N. Chawla"
                },
                {
                    "authorId": "1470716407",
                    "name": "Meng Jiang"
                }
            ]
        },
        {
            "paperId": "e8ed6314eb446dc23ab8153d3c58e05e9ef5a6ef",
            "title": "Dynamic Attributed Graph Prediction with Conditional Normalizing Flows",
            "abstract": "Graph representation learning aims at preserving structural and attributed information in latent representations. It has been studied mostly in the setting of static graph. In this work, we propose a novel approach for representation learning over dynamic attributed graph using the tool of normalizing flows for exact density estimation. Our approach has three components: (1) a time-aware graph neural component for aggregating graph information at each time step, (2) an adapted graph recurrent component for updating graph temporal contexts, and (3) a conditional normalizing flows component for capturing the evolution of node representations in latent space along time. Particularly, the third component has two sub-models of normalizing flows. One is used to capture the distribution of node representations of arbitrary complexity by considering graph temporal contexts as conditions. It learns invertible transformations to map node representations into simple priors conditioning on temporal contexts. The other one is dedicated to capture the evolutionary patterns of prior distributions. Extensive experiments demonstrate the proposed approach can outperform competitive baselines by a significant margin for dynamic link prediction on future graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111191142",
                    "name": "Daheng Wang"
                },
                {
                    "authorId": "1742573",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "144539424",
                    "name": "N. Chawla"
                },
                {
                    "authorId": "1470716407",
                    "name": "Meng Jiang"
                }
            ]
        }
    ]
}