{
    "authorId": "2263543517",
    "papers": [
        {
            "paperId": "0130f2fab75c30c26635be32fdafa6a03c35af6a",
            "title": "GraphStorm: all-in-one graph machine learning framework for industry applications",
            "abstract": "Graph machine learning (GML) is effective in many business applications. However, making GML easy to use and applicable to industry applications with massive datasets remain challenging. We developed GraphStorm, which provides an end-to-end solution for scalable graph construction, graph model training and inference. GraphStorm has the following desirable properties: (a) Easy to use: it can perform graph construction and model training and inference with just a single command; (b) Expert-friendly: GraphStorm contains many advanced GML modeling techniques to handle complex graph data and improve model performance; (c) Scalable: every component in GraphStorm can operate on graphs with billions of nodes and can scale model training and inference to different hardware without changing any code. GraphStorm has been used and deployed for over a dozen billion-scale industry applications after its release in May 2023. It is open-sourced in Github: https://github.com/awslabs/graphstorm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283934850",
                    "name": "Da Zheng"
                },
                {
                    "authorId": "2284037254",
                    "name": "Xiang Song"
                },
                {
                    "authorId": "2299062897",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2284069643",
                    "name": "Jian Zhang"
                },
                {
                    "authorId": "1812965",
                    "name": "Theodore Vasiloudis"
                },
                {
                    "authorId": "2146354747",
                    "name": "Runjie Ma"
                },
                {
                    "authorId": "2280741034",
                    "name": "Houyu Zhang"
                },
                {
                    "authorId": "2255392614",
                    "name": "Zichen Wang"
                },
                {
                    "authorId": "2121390172",
                    "name": "Soji Adeshina"
                },
                {
                    "authorId": "10429687",
                    "name": "Israt Nisa"
                },
                {
                    "authorId": "3125115",
                    "name": "Alejandro Mottini"
                },
                {
                    "authorId": "2305618086",
                    "name": "Qingjun Cui"
                },
                {
                    "authorId": "145344187",
                    "name": "H. Rangwala"
                },
                {
                    "authorId": "2305616323",
                    "name": "Belinda Zeng"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                }
            ]
        },
        {
            "paperId": "06b5a815283b6124249c87fc1b99801d1b68ad08",
            "title": "GLEMOS: Benchmark for Instantaneous Graph Learning Model Selection",
            "abstract": "The choice of a graph learning (GL) model (i.e., a GL algorithm and its hyperparameter settings) has a significant impact on the performance of downstream tasks. However, selecting the right GL model becomes increasingly difficult and time consuming as more and more GL models are developed. Accordingly, it is of great significance and practical value to equip users of GL with the ability to perform a near-instantaneous selection of an effective GL model without manual intervention. Despite the recent attempts to tackle this important problem, there has been no comprehensive benchmark environment to evaluate the performance of GL model selection methods. To bridge this gap, we present GLEMOS in this work, a comprehensive benchmark for instantaneous GL model selection that makes the following contributions. (i) GLEMOS provides extensive benchmark data for fundamental GL tasks, i.e., link prediction and node classification, including the performances of 366 models on 457 graphs on these tasks. (ii) GLEMOS designs multiple evaluation settings, and assesses how effectively representative model selection techniques perform in these different settings. (iii) GLEMOS is designed to be easily extended with new models, new graphs, and new performance records. (iv) Based on the experimental results, we discuss the limitations of existing approaches and highlight future research directions. To promote research on this significant problem, we make the benchmark data and code publicly available at https://github.com/facebookresearch/glemos.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268675415",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "2288277670",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2289802183",
                    "name": "Xing Wang"
                },
                {
                    "authorId": "2288274423",
                    "name": "Antoine Simoulin"
                },
                {
                    "authorId": "2280742578",
                    "name": "Nesreen K. Ahmed"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                }
            ]
        },
        {
            "paperId": "2046b2da23eb2f79744eb391d902da9cedf87947",
            "title": "Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey",
            "abstract": "Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2288381545",
                    "name": "Xi Fang"
                },
                {
                    "authorId": "2110546424",
                    "name": "Weijie Xu"
                },
                {
                    "authorId": "2287992265",
                    "name": "Fiona Anting Tan"
                },
                {
                    "authorId": "2258747730",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2287978009",
                    "name": "Ziqing Hu"
                },
                {
                    "authorId": "2288038766",
                    "name": "Yanjun Qi"
                },
                {
                    "authorId": "2287927391",
                    "name": "Scott Nickleach"
                },
                {
                    "authorId": "2287926360",
                    "name": "Diego Socolinsky"
                },
                {
                    "authorId": "2287927370",
                    "name": "Srinivasan H. Sengamedu"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                }
            ]
        },
        {
            "paperId": "2dc0c0a00544cd306abec905a98e4701e2401ba2",
            "title": "OpenTab: Advancing Large Language Models as Open-domain Table Reasoners",
            "abstract": "Large Language Models (LLMs) trained on large volumes of data excel at various natural language tasks, but they cannot handle tasks requiring knowledge that has not been trained on previously. One solution is to use a retriever that fetches relevant information to expand LLM's knowledge scope. However, existing textual-oriented retrieval-based LLMs are not ideal on structured table data due to diversified data modalities and large table sizes. In this work, we propose OpenTab, an open-domain table reasoning framework powered by LLMs. Overall, OpenTab leverages table retriever to fetch relevant tables and then generates SQL programs to parse the retrieved tables efficiently. Utilizing the intermediate data derived from the SQL executions, it conducts grounded inference to produce accurate response. Extensive experimental evaluation shows that OpenTab significantly outperforms baselines in both open- and closed-domain settings, achieving up to 21.5% higher accuracy. We further run ablation studies to validate the efficacy of our proposed designs of the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284981676",
                    "name": "Kezhi Kong"
                },
                {
                    "authorId": "2258747730",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2223163421",
                    "name": "Zhengyuan Shen"
                },
                {
                    "authorId": "2057595515",
                    "name": "Balasubramaniam Srinivasan"
                },
                {
                    "authorId": "2223137915",
                    "name": "Chuan Lei"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "145344187",
                    "name": "H. Rangwala"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                }
            ]
        },
        {
            "paperId": "834dd2110e19c4b8aa36585742d13848d10d97dd",
            "title": "DATALORE: Can a Large Language Model Find All Lost Scrolls in a Data Repository?",
            "abstract": "How can we effectively generate missing data transformations among tables in a data repository? Multiple versions of the same tables are generated from the iterative process when data scientists and machine learning engineers fine-tune their ML pipelines, making incremental improvements. This process often involves data transformation and augmentation that produces an augmented table based on its base version and related tables. However, data transformations are often not well-documented or completely missing, resulting in poor traceability, reproducibility and explainability of ML pipelines. In this paper, we propose DATALoRE, a framework that explains data changes between an initial dataset and its augmented version to improves traceability. Given a base table, DATALoRE first discovers its potentially related tables from the data repository using a variety of data discovery techniques. DATALoRE then effectively leverages a large language model (LLM) to generate a variety of data transformations that lead to the augmented table. DATALoRE validates these transformations and selects the minimum number of related tables to ensure traceability and reproducibility of the ML pipelines. A preliminary experiment shows that DATALoRE is able to effectively recovery data transformations on two benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2312764528",
                    "name": "Yuze Lou"
                },
                {
                    "authorId": "2223137915",
                    "name": "Chuan Lei"
                },
                {
                    "authorId": "2258942704",
                    "name": "Xiao Qin"
                },
                {
                    "authorId": "2255392614",
                    "name": "Zichen Wang"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2432216",
                    "name": "Rishita Anubhai"
                },
                {
                    "authorId": "145344187",
                    "name": "H. Rangwala"
                }
            ]
        },
        {
            "paperId": "856fb319c712ee510882be3e11909ca1742ef122",
            "title": "EBV: Electronic Bee-Veterinarian for Principled Mining and Forecasting of Honeybee Time Series",
            "abstract": "Honeybees are vital for pollination and food production. Among many factors, extreme temperature (e.g., due to climate change) is particularly dangerous for bee health. Anticipating such extremities would allow beekeepers to take early preventive action. Thus, given sensor (temperature) time series data from beehives, how can we find patterns and do forecasting? Forecasting is crucial as it helps spot unexpected behavior and thus issue warnings to the beekeepers. In that case, what are the right models for forecasting? ARIMA, RNNs, or something else? We propose the EBV (Electronic Bee-Veterinarian) method, which has the following desirable properties: (i) principled: it is based on a) diffusion equations from physics and b) control theory for feedback-loop controllers; (ii) effective: it works well on multiple, real-world time sequences, (iii) explainable: it needs only a handful of parameters (e.g., bee strength) that beekeepers can easily understand and trust, and (iv) scalable: it performs linearly in time. We applied our method to multiple real-world time sequences, and found that it yields accurate forecasting (up to 49% improvement in RMSE compared to baselines), and segmentation. Specifically, discontinuities detected by EBV mostly coincide with domain expert's opinions, showcasing our approach's potential and practical feasibility. Moreover, EBV is scalable and fast, taking about 20 minutes on a stock laptop for reconstructing two months of sensor data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283491059",
                    "name": "Shamima Hossain"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2282540480",
                    "name": "Boris Baer"
                },
                {
                    "authorId": "2283131770",
                    "name": "Hyoseung Kim"
                },
                {
                    "authorId": "1761528",
                    "name": "V. Tsotras"
                }
            ]
        },
        {
            "paperId": "a6d2eb2e7bf518e93595e80e61127176f36204f5",
            "title": "Hierarchical Compression of Text-Rich Graphs via Large Language Models",
            "abstract": "Text-rich graphs, prevalent in data mining contexts like e-commerce and academic graphs, consist of nodes with textual features linked by various relations. Traditional graph machine learning models, such as Graph Neural Networks (GNNs), excel in encoding the graph structural information, but have limited capability in handling rich text on graph nodes. Large Language Models (LLMs), noted for their superior text understanding abilities, offer a solution for processing the text in graphs but face integration challenges due to their limitation for encoding graph structures and their computational complexities when dealing with extensive text in large neighborhoods of interconnected nodes. This paper introduces ``Hierarchical Compression'' (HiCom), a novel method to align the capabilities of LLMs with the structure of text-rich graphs. HiCom processes text in a node's neighborhood in a structured manner by organizing the extensive textual information into a more manageable hierarchy and compressing node text step by step. Therefore, HiCom not only preserves the contextual richness of the text but also addresses the computational challenges of LLMs, which presents an advancement in integrating the text processing power of LLMs with the structural complexities of text-rich graphs. Empirical results show that HiCom can outperform both GNNs and LLM backbones for node classification on e-commerce and citation graphs. HiCom is especially effective for nodes from a dense region in a graph, where it achieves a 3.48% average performance improvement on five datasets while being more efficient than LLM backbones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145408511",
                    "name": "Shichang Zhang"
                },
                {
                    "authorId": "2283934850",
                    "name": "Da Zheng"
                },
                {
                    "authorId": "2258747730",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2299062897",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2284037254",
                    "name": "Xiang Song"
                },
                {
                    "authorId": "2121390172",
                    "name": "Soji Adeshina"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2064547804",
                    "name": "George Karypis"
                },
                {
                    "authorId": "2279734673",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "b7c6c2d3841e8533b27581e81c590d0ab59d3ad8",
            "title": "OmniMatch: Effective Self-Supervised Any-Join Discovery in Tabular Data Repositories",
            "abstract": "How can we discover join relationships among columns of tabular data in a data repository? Can this be done effectively when metadata is missing? Traditional column matching works mainly rely on similarity measures based on exact value overlaps, hence missing important semantics or failing to handle noise in the data. At the same time, recent dataset discovery methods focusing on deep table representation learning techniques, do not take into consideration the rich set of column similarity signals found in prior matching and discovery methods. Finally, existing methods heavily depend on user-provided similarity thresholds, hindering their deployability in real-world settings. In this paper, we propose OmniMatch, a novel join discovery technique that detects equi-joins and fuzzy-joins betwen columns by combining column-pair similarity measures with Graph Neural Networks (GNNs). OmniMatch's GNN can capture column relatedness leveraging graph transitivity, significantly improving the recall of join discovery tasks. At the same time, OmniMatch also increases the precision by augmenting its training data with negative column join examples through an automated negative example generation process. Most importantly, compared to the state-of-the-art matching and discovery methods, OmniMatch exhibits up to 14% higher effectiveness in F1 score and AUC without relying on metadata or user-provided thresholds for each similarity metric.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2073886702",
                    "name": "Christos Koutras"
                },
                {
                    "authorId": "2258747730",
                    "name": "Jiani Zhang"
                },
                {
                    "authorId": "2258942704",
                    "name": "Xiao Qin"
                },
                {
                    "authorId": "2223137915",
                    "name": "Chuan Lei"
                },
                {
                    "authorId": "28310338",
                    "name": "Vasileios Ioannidis"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2064547804",
                    "name": "George Karypis"
                },
                {
                    "authorId": "2138521152",
                    "name": "Asterios Katsifodimos"
                }
            ]
        },
        {
            "paperId": "c7589078b6d71ae959f1a9d2f68fe117c4073300",
            "title": "Automatic Question-Answer Generation for Long-Tail Knowledge",
            "abstract": "Pretrained Large Language Models (LLMs) have gained significant attention for addressing open-domain Question Answering (QA). While they exhibit high accuracy in answering questions related to common knowledge, LLMs encounter difficulties in learning about uncommon long-tail knowledge (tail entities). Since manually constructing QA datasets demands substantial human resources, the types of existing QA datasets are limited, leaving us with a scarcity of datasets to study the performance of LLMs on tail entities. In this paper, we propose an automatic approach to generate specialized QA datasets for tail entities and present the associated research challenges. We conduct extensive experiments by employing pretrained LLMs on our newly generated long-tail QA datasets, comparing their performance with and without external resources including Wikipedia and Wikidata knowledge graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290027387",
                    "name": "Rohan Kumar"
                },
                {
                    "authorId": "2289998851",
                    "name": "Youngmin Kim"
                },
                {
                    "authorId": "2290012562",
                    "name": "Sunitha Ravi"
                },
                {
                    "authorId": "3456820",
                    "name": "Haitian Sun"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2257253563",
                    "name": "Ruslan Salakhutdinov"
                },
                {
                    "authorId": "50736424",
                    "name": "Minji Yoon"
                }
            ]
        },
        {
            "paperId": "cd4af2a6fdfc85b9fb514989a41551186cf303dc",
            "title": "4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on Relational DBs",
            "abstract": "Although RDBs store vast amounts of rich, informative data spread across interconnected tables, the progress of predictive machine learning models as applied to such tasks arguably falls well behind advances in other domains such as computer vision or natural language processing. This deficit stems, at least in part, from the lack of established/public RDB benchmarks as needed for training and evaluation purposes. As a result, related model development thus far often defaults to tabular approaches trained on ubiquitous single-table benchmarks, or on the relational side, graph-based alternatives such as GNNs applied to a completely different set of graph datasets devoid of tabular characteristics. To more precisely target RDBs lying at the nexus of these two complementary regimes, we explore a broad class of baseline models predicated on: (i) converting multi-table datasets into graphs using various strategies equipped with efficient subsampling, while preserving tabular characteristics; and (ii) trainable models with well-matched inductive biases that output predictions based on these input subgraphs. Then, to address the dearth of suitable public benchmarks and reduce siloed comparisons, we assemble a diverse collection of (i) large-scale RDB datasets and (ii) coincident predictive tasks. From a delivery standpoint, we operationalize the above four dimensions (4D) of exploration within a unified, scalable open-source toolbox called 4DBInfer. We conclude by presenting evaluations using 4DBInfer, the results of which highlight the importance of considering each such dimension in the design of RDB predictive models, as well as the limitations of more naive approaches such as simply joining adjacent tables. Our source code is released at https://github.com/awslabs/multi-table-benchmark .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2244248914",
                    "name": "Minjie Wang"
                },
                {
                    "authorId": "2257302315",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "2256992062",
                    "name": "David Wipf"
                },
                {
                    "authorId": "35349851",
                    "name": "Zhenkun Cai"
                },
                {
                    "authorId": "2298888654",
                    "name": "Ning Li"
                },
                {
                    "authorId": "2299152040",
                    "name": "Jianheng Tang"
                },
                {
                    "authorId": "2295790287",
                    "name": "Yanlin Zhang"
                },
                {
                    "authorId": "2275613451",
                    "name": "Zizhao Zhang"
                },
                {
                    "authorId": "2298905319",
                    "name": "Zunyao Mao"
                },
                {
                    "authorId": "2298974245",
                    "name": "Yakun Song"
                },
                {
                    "authorId": "2298929357",
                    "name": "Yanbo Wang"
                },
                {
                    "authorId": "2298940011",
                    "name": "Jiahang Li"
                },
                {
                    "authorId": "2269699052",
                    "name": "Han Zhang"
                },
                {
                    "authorId": "2299189130",
                    "name": "Guang Yang"
                },
                {
                    "authorId": "2268022441",
                    "name": "Xiao Qin"
                },
                {
                    "authorId": "2223137915",
                    "name": "Chuan Lei"
                },
                {
                    "authorId": "2279927888",
                    "name": "Mu-Nan Zhang"
                },
                {
                    "authorId": "2257343831",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2263543517",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2148906289",
                    "name": "Zheng Zhang"
                }
            ]
        }
    ]
}