{
    "authorId": "2290642943",
    "papers": [
        {
            "paperId": "38d7d45a8e90ad2fdd0a33494fa3d7b57c11bcb2",
            "title": "Entity6K: A Large Open-Domain Evaluation Dataset for Real-World Entity Recognition",
            "abstract": "Open-domain real-world entity recognition is essential yet challenging, involving identifying various entities in diverse environments. The lack of a suitable evaluation dataset has been a major obstacle in this field due to the vast number of entities and the extensive human effort required for data curation. We introduce Entity6K, a comprehensive dataset for real-world entity recognition, featuring 5,700 entities across 26 categories, each supported by 5 human-verified images with annotations. Entity6K offers a diverse range of entity names and categorizations, addressing a gap in existing datasets. We conducted benchmarks with existing models on tasks like image captioning, object detection, zero-shot classification, and dense captioning to demonstrate Entity6K's effectiveness in evaluating models' entity recognition capabilities. We believe Entity6K will be a valuable resource for advancing accurate entity recognition in open-domain settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2267397829",
                    "name": "Jielin Qiu"
                },
                {
                    "authorId": "119119640",
                    "name": "William Jongwon Han"
                },
                {
                    "authorId": "2292207626",
                    "name": "Winfred Wang"
                },
                {
                    "authorId": "2149231840",
                    "name": "Zhengyuan Yang"
                },
                {
                    "authorId": "50703697",
                    "name": "Linjie Li"
                },
                {
                    "authorId": "2261062142",
                    "name": "Jianfeng Wang"
                },
                {
                    "authorId": "2290179598",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2290642943",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2273909761",
                    "name": "Lijuan Wang"
                }
            ]
        },
        {
            "paperId": "419fc40f4c9e929e90a3a6c7e7aca6d58ecace8e",
            "title": "Evaluating Durability: Benchmark Insights into Multimodal Watermarking",
            "abstract": "With the development of large models, watermarks are increasingly employed to assert copyright, verify authenticity, or monitor content distribution. As applications become more multimodal, the utility of watermarking techniques becomes even more critical. The effectiveness and reliability of these watermarks largely depend on their robustness to various disturbances. However, the robustness of these watermarks in real-world scenarios, particularly under perturbations and corruption, is not well understood. To highlight the significance of robustness in watermarking techniques, our study evaluated the robustness of watermarked content generated by image and text generation models against common real-world image corruptions and text perturbations. Our results could pave the way for the development of more robust watermarking techniques in the future. Our project website can be found at \\url{https://mmwatermark-robustness.github.io/}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2267397829",
                    "name": "Jielin Qiu"
                },
                {
                    "authorId": "119119640",
                    "name": "William Jongwon Han"
                },
                {
                    "authorId": "150345512",
                    "name": "Xuandong Zhao"
                },
                {
                    "authorId": "2304955927",
                    "name": "Shangbang Long"
                },
                {
                    "authorId": "2290179598",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2290642943",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "6d9690ab7674d70a3d8e41870186acba7325485b",
            "title": "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM",
            "abstract": "Vision-extended LLMs have made significant strides in Visual Question Answering (VQA). Despite these advancements, VLLMs still encounter substantial difficulties in handling queries involving long-tail entities, with a tendency to produce erroneous or hallucinated responses. In this work, we introduce a novel evaluative benchmark named \\textbf{SnapNTell}, specifically tailored for entity-centric VQA. This task aims to test the models' capabilities in identifying entities and providing detailed, entity-specific knowledge. We have developed the \\textbf{SnapNTell Dataset}, distinct from traditional VQA datasets: (1) It encompasses a wide range of categorized entities, each represented by images and explicitly named in the answers; (2) It features QA pairs that require extensive knowledge for accurate responses. The dataset is organized into 22 major categories, containing 7,568 unique entities in total. For each entity, we curated 10 illustrative images and crafted 10 knowledge-intensive QA pairs. To address this novel task, we devised a scalable, efficient, and transparent retrieval-augmented multimodal LLM. Our approach markedly outperforms existing methods on the SnapNTell dataset, achieving a 66.5\\% improvement in the BELURT score. We will soon make the dataset and the source code publicly accessible.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2267397829",
                    "name": "Jielin Qiu"
                },
                {
                    "authorId": "2111680936",
                    "name": "Andrea Madotto"
                },
                {
                    "authorId": "2146396528",
                    "name": "Zhaojiang Lin"
                },
                {
                    "authorId": "34963487",
                    "name": "Paul A. Crook"
                },
                {
                    "authorId": "2290243809",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2215596266",
                    "name": "Xin Luna Dong"
                },
                {
                    "authorId": "2290179598",
                    "name": "Christos Faloutsos"
                },
                {
                    "authorId": "2290642943",
                    "name": "Lei Li"
                },
                {
                    "authorId": "3057557",
                    "name": "Babak Damavandi"
                },
                {
                    "authorId": "2256132624",
                    "name": "Seungwhan Moon"
                }
            ]
        }
    ]
}