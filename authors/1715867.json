{
    "authorId": "1715867",
    "papers": [
        {
            "paperId": "8489bf3ccdda5ac8e26e47ae1dda7409d0cf11a1",
            "title": "Diversity-aware clustering: Computational Complexity and Approximation Algorithms",
            "abstract": "In this work, we study diversity-aware clustering problems where the data points are associated with multiple attributes resulting in intersecting groups. A clustering solution need to ensure that a minimum number of cluster centers are chosen from each group while simultaneously minimizing the clustering objective, which can be either $k$-median, $k$-means or $k$-supplier. We present parameterized approximation algorithms with approximation ratios $1+ \\frac{2}{e}$, $1+\\frac{8}{e}$ and $3$ for diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware $k$-supplier, respectively. The approximation ratios are tight assuming Gap-ETH and FPT $\\neq$ W[2]. For fair $k$-median and fair $k$-means with disjoint faicility groups, we present parameterized approximation algorithm with approximation ratios $1+\\frac{2}{e}$ and $1+\\frac{8}{e}$, respectively. For fair $k$-supplier with disjoint facility groups, we present a polynomial-time approximation algorithm with factor $3$, improving the previous best known approximation ratio of factor $5$.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50821331",
                    "name": "Suhas Thejaswi"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "35332118",
                    "name": "Bruno Ordozgoiti"
                },
                {
                    "authorId": "1682878",
                    "name": "A. Gionis"
                }
            ]
        },
        {
            "paperId": "8e30a6291b486fa468fad1196e4e9a203c3c5810",
            "title": "FPT approximations for Capacitated Sum of Radii and Diameters",
            "abstract": "The Capacitated Sum of Radii problem involves partitioning a set of points $P$, where each point $p\\in P$ has capacity $U_p$, into $k$ clusters that minimize the sum of cluster radii, such that the number of points in the cluster centered at point $p$ is at most $U_p$. We begin by showing that the problem is APX-hard, and that under gap-ETH there is no parameterized approximation scheme (FPT-AS). We then construct a $\\approx5.83$-approximation algorithm in FPT time (improving a previous $\\approx7.61$ approximation in FPT time). Our results also hold when the objective is a general monotone symmetric norm of radii. We also improve the approximation factors for the uniform capacity case, and for the closely related problem of Capacitated Sum of Diameters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1810078",
                    "name": "Arnold Filtser"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                }
            ]
        },
        {
            "paperId": "b40665f40e80e287b6c9778e4ad2b2681e20570d",
            "title": "Parameterized Approximation Schemes for Clustering with General Norm Objectives",
            "abstract": "This paper considers the well-studied algorithmic regime of designing a $(1+\\epsilon)$-approximation algorithm for a k-clustering problem that runs in time $f(k,\\epsilon)poly(n)$ (sometimes called an efficient parameterized approximation scheme or EPAS for short1). Notable results of this kind include EPASes in the high-dimensional Euclidean setting for k-center [Bad\u014fiu, Har-Peled, Indyk; STOC\u201902] as well as k-median, and k-means [Kumar, Sabharwal, Sen; J. ACM 2010]. Our main contribution is a clean and simple EPAS that settles more than ten clustering problems (across multiple well-studied objectives as well as metric spaces) and unifies well-known EPASes. More specifically, our algorithm gives EPASes in the following settings:\u2022Clustering objectives: k-means, k-center, k-median, priority k-center, $\\ell$-centrum, ordered k-median, socially fair k-median (aka robust k-median), or any other objective that can be formulated as minimizing a monotone (not necessarily symmetric!) norm of the distances of the points from the solution (generalizing the symmetric formulation introduced by Chakrabarty and Swamy [STOC\u201919]).\u2022Metric spaces: Continuous high-dimensional Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth metrics, and planar metrics. Prior to our results, EPASes were only known for vanilla clustering objectives (k-means, k-median, and k-center) and each such algorithm is tailored to work for the specific input metric and clustering objective (e.g., EPASes for k means and k-center in $\\mathbb{R}^{d}$ are conceptually very different). In contrast, our algorithmic framework is applicable to a wide range of well-studied objective functions in a uniform way, and is (almost) entirely oblivious to any specific metric structures and yet is able to effectively exploit those unknown structures. In particular, our algorithm is not based on the (metric- and objective-specific) technique of coresets. Key to our analysis is a new concept that we call bounded $\\epsilon$-scatter dimension\u2014an intrinsic complexity measure of a metric space that is a relaxation of the standard notion of bounded doubling dimension(often used as a source of algorithmic tractability for geometric problems). Our main technical result shows that two conditions are essentially sufficient for our algorithm to yield an EPAS on the input metric M for any clustering objective:(i)The objective is described by a monotone norm, and(ii)the $\\epsilon$-scatter dimension of M is upper bounded by a function of $\\epsilon$.1Quick remarks: (i) An EPAS is not comparable to polynomial time approximation schemes (PTAS), (ii) before the term EPAS was invented some researchers call this type of approximation schemes a PTAS or simply an approximation scheme (in clustering, it is often assumed that k is small) [1], [2], and (iii) both EPAS and PTAS are implied by the existence of efficient polynomial time approximation schemes (EPTAS).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059605410",
                    "name": "F. Abbasi"
                },
                {
                    "authorId": "2110879013",
                    "name": "Sandip Banerjee"
                },
                {
                    "authorId": "1800005",
                    "name": "J. Byrka"
                },
                {
                    "authorId": "3154315",
                    "name": "Parinya Chalermsook"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "3035428",
                    "name": "K. Khodamoradi"
                },
                {
                    "authorId": "145722890",
                    "name": "D. Marx"
                },
                {
                    "authorId": "2199730582",
                    "name": "Roohani Sharma"
                },
                {
                    "authorId": "2089098",
                    "name": "J. Spoerhase"
                }
            ]
        },
        {
            "paperId": "b6474d152f6401c30e34d707613d79a30445cdc0",
            "title": "Independent set in k-Claw-Free Graphs: Conditional \u03c7-boundedness and the Power of LP/SDP Relaxations",
            "abstract": "This paper studies $k$-claw-free graphs, exploring the connection between an extremal combinatorics question and the power of a convex program in approximating the maximum-weight independent set in this graph class. For the extremal question, we consider the notion, that we call \\textit{conditional $\\chi$-boundedness} of a graph: Given a graph $G$ that is assumed to contain an independent set of a certain (constant) size, we are interested in upper bounding the chromatic number in terms of the clique number of $G$. This question, besides being interesting on its own, has algorithmic implications (which have been relatively neglected in the literature) on the performance of SDP relaxations in estimating the value of maximum-weight independent set. For $k=3$, Chudnovsky and Seymour (JCTB 2010) prove that any $3$-claw-free graph $G$ with an independent set of size three must satisfy $\\chi(G) \\leq 2 \\omega(G)$. Their result implies a factor $2$-estimation algorithm for the maximum weight independent set via an SDP relaxation (providing the first non-trivial result for maximum-weight independent set in such graphs via a convex relaxation). An obvious open question is whether a similar conditional $\\chi$-boundedness phenomenon holds for any $k$-claw-free graph. Our main result answers this question negatively. We further present some evidence that our construction could be useful in studying more broadly the power of convex relaxations in the context of approximating maximum weight independent set in $k$-claw free graphs. In particular, we prove a lower bound on families of convex programs that are stronger than known convex relaxations used algorithmically in this context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3154315",
                    "name": "Parinya Chalermsook"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "3035428",
                    "name": "K. Khodamoradi"
                },
                {
                    "authorId": "2089098",
                    "name": "J. Spoerhase"
                }
            ]
        },
        {
            "paperId": "ee947976d91486aac367b5d15ca4826541ee6ce9",
            "title": "Parameterized Approximation for Robust Clustering in Discrete Geometric Spaces",
            "abstract": "We consider the well-studied Robust $(k, z)$-Clustering problem, which generalizes the classic $k$-Median, $k$-Means, and $k$-Center problems. Given a constant $z\\ge 1$, the input to Robust $(k, z)$-Clustering is a set $P$ of $n$ weighted points in a metric space $(M,\\delta)$ and a positive integer $k$. Further, each point belongs to one (or more) of the $m$ many different groups $S_1,S_2,\\ldots,S_m$. Our goal is to find a set $X$ of $k$ centers such that $\\max_{i \\in [m]} \\sum_{p \\in S_i} w(p) \\delta(p,X)^z$ is minimized. This problem arises in the domains of robust optimization [Anthony, Goyal, Gupta, Nagarajan, Math. Oper. Res. 2010] and in algorithmic fairness. For polynomial time computation, an approximation factor of $O(\\log m/\\log\\log m)$ is known [Makarychev, Vakilian, COLT $2021$], which is tight under a plausible complexity assumption even in the line metrics. For FPT time, there is a $(3^z+\\epsilon)$-approximation algorithm, which is tight under GAP-ETH [Goyal, Jaiswal, Inf. Proc. Letters, 2023]. Motivated by the tight lower bounds for general discrete metrics, we focus on \\emph{geometric} spaces such as the (discrete) high-dimensional Euclidean setting and metrics of low doubling dimension, which play an important role in data analysis applications. First, for a universal constant $\\eta_0>0.0006$, we devise a $3^z(1-\\eta_{0})$-factor FPT approximation algorithm for discrete high-dimensional Euclidean spaces thereby bypassing the lower bound for general metrics. We complement this result by showing that even the special case of $k$-Center in dimension $\\Theta(\\log n)$ is $(\\sqrt{3/2}- o(1))$-hard to approximate for FPT algorithms. Finally, we complete the FPT approximation landscape by designing an FPT $(1+\\epsilon)$-approximation scheme (EPAS) for the metric of sub-logarithmic doubling dimension.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059605410",
                    "name": "F. Abbasi"
                },
                {
                    "authorId": "2110879013",
                    "name": "Sandip Banerjee"
                },
                {
                    "authorId": "1800005",
                    "name": "J. Byrka"
                },
                {
                    "authorId": "3154315",
                    "name": "Parinya Chalermsook"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "3035428",
                    "name": "K. Khodamoradi"
                },
                {
                    "authorId": "145722890",
                    "name": "D. Marx"
                },
                {
                    "authorId": "2199730582",
                    "name": "Roohani Sharma"
                },
                {
                    "authorId": "2089098",
                    "name": "J. Spoerhase"
                }
            ]
        },
        {
            "paperId": "82d2348cc9041491e690db884a6014a553c7bcd0",
            "title": "Clustering with Fair-Center Representation: Parameterized Approximation Algorithms and Heuristics",
            "abstract": "We study a variant of classical clustering formulations in the context of algorithmic fairness, known as diversity-aware clustering. In this variant we are given a collection of facility subsets, and a solution must contain at least a specified number of facilities from each subset while simultaneously minimizing the clustering objective (k-median or k-means). We investigate the fixed-parameter tractability of these problems and show several negative hardness and inapproximability results, even when we afford exponential running time with respect to some parameters. Motivated by these results we identify natural parameters of the problem, and present fixed-parameter approximation algorithms with approximation ratios (1 + 2 over e + \u2208) and (1 + 8 over e + \u2208) for diversity-aware k-median and diversity-aware k-means respectively, and argue that these ratios are essentially tight assuming the gap-exponential time hypothesis. We also present a simple and more practical bicriteria approximation algorithm with better running time bounds. We finally propose efficient and practical heuristics. We evaluate the scalability and effectiveness of our methods in a wide variety of rigorously conducted experiments, on both real and synthetic data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "50821331",
                    "name": "Suhas Thejaswi"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "35332118",
                    "name": "Bruno Ordozgoiti"
                },
                {
                    "authorId": "100592338",
                    "name": "M. Osadnik"
                }
            ]
        },
        {
            "paperId": "8ca8777afc8e2b85b391518e10ba20b5a3c04ca4",
            "title": "Approximation algorithms for k-median with lower-bound constraints",
            "abstract": "We study a variant of the classical k -median problem known as diversity-aware k -median (introduced by Thejaswi et al. 2021), where we are given a collection of facility subsets, and a solution must contain at least a speci\ufb01ed number of facilities from each subset. We investigate the \ufb01xed-parameter tractability of this problem and show several negative hardness and inapproximability results, even when we a\ufb00ord exponential running time with respect to some parameters of the problem. Motivated by these results we present a \ufb01xed parameter approximation algorithm with approximation ratio (1 + 2 e + (cid:15) ), and argue that this ratio is essentially tight assuming the gap-exponential time hypothesis. We also present a simple, practical local-search algorithm that gives a bicriteria (2 k, 3 + (cid:15) ) approximation with better running time bounds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "35332118",
                    "name": "Bruno Ordozgoiti"
                },
                {
                    "authorId": "50821331",
                    "name": "Suhas Thejaswi"
                }
            ]
        },
        {
            "paperId": "5a757bc7be5cdb554194550a8a73bb2cc5f5911d",
            "title": "On the hardness of learning sparse parities",
            "abstract": "This work investigates the hardness of computing sparse solutions to systems of linear equations over F_2. Consider the k-EvenSet problem: given a homogeneous system of linear equations over F_2 on n variables, decide if there exists a nonzero solution of Hamming weight at most k (i.e. a k-sparse solution). While there is a simple O(n^{k/2})-time algorithm for it, establishing fixed parameter intractability for k-EvenSet has been a notorious open problem. Towards this goal, we show that unless k-Clique can be solved in n^{o(k)} time, k-EvenSet has no poly(n)2^{o(sqrt{k})} time algorithm and no polynomial time algorithm when k = (log n)^{2+eta} for any eta > 0. \nOur work also shows that the non-homogeneous generalization of the problem -- which we call k-VectorSum -- is W[1]-hard on instances where the number of equations is O(k log n), improving on previous reductions which produced Omega(n) equations. We also show that for any constant eps > 0, given a system of O(exp(O(k))log n) linear equations, it is W[1]-hard to decide if there is a k-sparse linear form satisfying all the equations or if every function on at most k-variables (k-junta) satisfies at most (1/2 + eps)-fraction of the equations. In the setting of computational learning, this shows hardness of approximate non-proper learning of k-parities. In a similar vein, we use the hardness of k-EvenSet to show that that for any constant d, unless k-Clique can be solved in n^{o(k)} time there is no poly(m, n)2^{o(sqrt{k}) time algorithm to decide whether a given set of m points in F_2^n satisfies: (i) there exists a non-trivial k-sparse homogeneous linear form evaluating to 0 on all the points, or (ii) any non-trivial degree d polynomial P supported on at most k variables evaluates to zero on approx. Pr_{F_2^n}[P(z) = 0] fraction of the points i.e., P is fooled by the set of points.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1751082",
                    "name": "Arnab Bhattacharyya"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "33522856",
                    "name": "Suprovat Ghoshal"
                },
                {
                    "authorId": "1789770",
                    "name": "Rishi Saket"
                }
            ]
        },
        {
            "paperId": "919107af1fde4520397e083935e2b98d7833ca88",
            "title": "On learning k-parities with and without noise",
            "abstract": "We first consider the problem of learning k-parities in the on-line mistake-bound model: given a hidden vector x \u2208 {0,1} n with |x| = k and a sequence of \u201cquestions\u201d a1,a2,\u00b7\u00b7\u00b7 \u2208 {0,1} n , where the algorithm must reply to each question with hai,xi (mod 2), what is the best tradeoff between the number of mistakes made by the algorithm and its time complexity? We improve the previous best result of Buhrman et. al. [BGM10] by an exp(k) factor in the time complexity. Second, we consider the problem of learning k-parities in the presence of classification noise of rate \ufffd \u2208 (0, 1/2). A polynomial time algorithm for this problem (when \ufffd > 0 and k = !(1)) is a longstanding challenge in learning theory. Grigorescu et al. [GRV11] showed an algorithm running in time n k/2",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1751082",
                    "name": "Arnab Bhattacharyya"
                },
                {
                    "authorId": "1715867",
                    "name": "Ameet Gadekar"
                },
                {
                    "authorId": "1744960",
                    "name": "Ninad Rajgopal"
                }
            ]
        }
    ]
}