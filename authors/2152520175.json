{
    "authorId": "2152520175",
    "papers": [
        {
            "paperId": "2aa2a31a642329db9dd5d86e4c4ad8237cae2896",
            "title": "Leveraging Large Models for Crafting Narrative Visualization: A Survey",
            "abstract": "Narrative visualization effectively transforms data into engaging stories, making complex information accessible to a broad audience. Large models, essential for narrative visualization, inherently facilitate this process through their superior ability to handle natural language queries and answers, generate cohesive narratives, and enhance visual communication. Inspired by previous work in narrative visualization and recent advances in large models, we synthesized potential tasks and opportunities for large models at various stages of narrative visualization. In our study, we surveyed 79 papers to explore the role of large models in automating narrative visualization creation. We propose a comprehensive pipeline that leverages large models for crafting narrative visualization, categorizing the reviewed literature into four essential phases: Data, Narration, Visualization, and Presentation. Additionally, we identify nine specific tasks where large models are applied across these stages. This study maps out the landscape of challenges and opportunities in the LM4NV process, providing insightful directions for future research and valuable guidance for scholars in the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2262088669",
                    "name": "Yi He"
                },
                {
                    "authorId": "2251057280",
                    "name": "Shixiong Cao"
                },
                {
                    "authorId": "2119036803",
                    "name": "Yang Shi"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2262197720",
                    "name": "Ke Xu"
                },
                {
                    "authorId": "2163708412",
                    "name": "Nan Cao"
                }
            ]
        },
        {
            "paperId": "c897d0664cec04252d4c106a656a8383b9dd79c5",
            "title": "Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI",
            "abstract": "Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2281946312",
                    "name": "Wei Shuai"
                },
                {
                    "authorId": "2282081700",
                    "name": "Jiyao Zhang"
                },
                {
                    "authorId": "2301045597",
                    "name": "Zhida Sun"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                }
            ]
        },
        {
            "paperId": "0c65dfacc858102af978debc10b56536fa186f20",
            "title": "Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration",
            "abstract": "Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel data-aware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2155699322",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "4e10e2e77d2dee62bc8496adc4753b973ce497ce",
            "title": "Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition",
            "abstract": "Datamation is designed to animate an analysis pipeline step by step, which is an intuitive and effective way to interpret the results from data analysis. However, creating a datamation is not easy. A qualified datamation needs to not only provide a correct analysis result but also ensure that the data flow and animation are coherent. Existing animation authoring tools focus on either leveraging algorithms to automatically generate an animation based on user-provided charts or building graphical user interfaces to provide a programming-free authoring environment for users. None of them are able to help users translate an analysis task into a series of data operations to form an analysis pipeline and visualize them as a datamation. To fill this gap, we introduce Datamator, an intelligent authoring tool developed to support datamation design and generation. It leverages a novel data query decomposition model to allow users to generate an initial datamation by simply inputting a data query in natural language. The initial datamation can be refined via rich interactions and a feedback mechanism is utilized to update the decomposition model based on user knowledge and preferences. Our system produces an animated sequence of visualizations driven by a set of low-level data actions. It supports unit visualizations, which provide a mapping from each data item to a unique visual mark. We demonstrate the effectiveness of Datamator via a series of evaluations including case studies, performance validation, and a controlled user study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "1410503485",
                    "name": "Ligan Cai"
                },
                {
                    "authorId": "2134152070",
                    "name": "Yanqiu Wu"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                }
            ]
        },
        {
            "paperId": "6d1d4c3d591a9a6cc020082ff588107c4a6ae450",
            "title": "Calliope-Net: Automatic Generation of Graph Data Facts via Annotated Node-Link Diagrams",
            "abstract": "Graph or network data are widely studied in both data mining and visualization communities to review the relationship among different entities and groups. The data facts derived from graph visual analysis are important to help understand the social structures of complex data, especially for data journalism. However, it is challenging for data journalists to discover graph data facts and manually organize correlated facts around a meaningful topic due to the complexity of graph data and the difficulty to interpret graph narratives. Therefore, we present an automatic graph facts generation system, Calliope-Net, which consists of a fact discovery module, a fact organization module, and a visualization module. It creates annotated node-link diagrams with facts automatically discovered and organized from network data. A novel layout algorithm is designed to present meaningful and visually appealing annotated graphs. We evaluate the proposed system with two case studies and an in-lab user study. The results show that Calliope-Net can benefit users in discovering and understanding graph data facts with visually pleasing annotated visualizations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2118768185",
                    "name": "Nan Chen"
                },
                {
                    "authorId": "2005512798",
                    "name": "W. Shuai"
                },
                {
                    "authorId": "2153300135",
                    "name": "Guande Wu"
                },
                {
                    "authorId": "2149237236",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                }
            ]
        },
        {
            "paperId": "c831f34da8cfa38c08861e6914fe3b83196bd96b",
            "title": "Chart2Vec: A Universal Embedding of Context-Aware Visualizations",
            "abstract": "The advances in AI-enabled techniques have accelerated the creation and automation of visualizations in the past decade. However, presenting visualizations in a descriptive and generative format remains a challenge. Moreover, current visualization embedding methods focus on standalone visualizations, neglecting the importance of contextual information for multi-view visualizations. To address this issue, we propose a new representation model, Chart2Vec, to learn a universal embedding of visualizations with context-aware information. Chart2Vec aims to support a wide range of downstream visualization tasks such as recommendation and storytelling. Our model considers both structural and semantic information of visualizations in declarative specifications. To enhance the context-aware capability, Chart2Vec employs multi-task learning on both supervised and unsupervised tasks concerning the cooccurrence of visualizations. We evaluate our method through an ablation study, a user study, and a quantitative comparison. The results verified the consistency of our embedding method with human cognition and showed its advantages over existing methods.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2261944198",
                    "name": "Ying Chen"
                },
                {
                    "authorId": "152570557",
                    "name": "Wei Shuai"
                },
                {
                    "authorId": "2220099450",
                    "name": "Ruishi Zou"
                },
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2124913650",
                    "name": "Jiazhe Wang"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                }
            ]
        },
        {
            "paperId": "0eab4992c6995dc537671b0df4cf85c671a011a4",
            "title": "The Chart Excites Me! Exploring How Data Visualization Design Influences Affective Arousal",
            "abstract": "As data visualizations have been increasingly applied in mass communication, designers often seek to grasp viewers immediately and motivate them to read more. Such goals, as suggested by previous research, are closely associated with the activation of emotion, namely affective arousal. Given this motivation, this work takes initial steps toward understanding the arousal-related factors in data visualization design. We collected a corpus of 265 data visualizations and conducted a crowdsourcing study with 184 participants during which the participants were asked to rate the affective arousal elicited by data visualization design (all texts were blurred to exclude the influence of semantics) and provide their reasons. Based on the collected data, first, we identified a set of arousal-related design features by analyzing user comments qualitatively. Then, we mapped these features to computable variables and constructed regression models to infer which features are significant contributors to affective arousal quantitatively. Through this exploratory study, we finally identified four design features (e.g., colorfulness, the number of different visual channels) cross-validated as important features correlated with affective arousal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080042495",
                    "name": "Xingyu Lan"
                },
                {
                    "authorId": "2134152070",
                    "name": "Yanqiu Wu"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2163708412",
                    "name": "Nan Cao"
                }
            ]
        },
        {
            "paperId": "0f9e34230cb90535b0bcfead1defbdbd1703d8fe",
            "title": "How Does Automation Shape the Process of Narrative Visualization: A Survey of Tools",
            "abstract": "In recent years, narrative visualization has gained much attention. Researchers have proposed different design spaces for various narrative visualization genres and scenarios to facilitate the creation process. As users\u2019 needs grow and automation technologies advance, increasingly more tools have been designed and developed. In this study, we summarized six genres of narrative visualization (annotated charts, infographics, timelines & storylines, data comics, scrollytelling & slideshow, and data videos) based on previous research and four types of tools (design spaces, authoring tools, ML/AI-supported tools and ML/AI-generator tools) based on the intelligence and automation level of the tools. We surveyed 105 papers and tools to study how automation can progressively engage in visualization design and narrative processes to help users easily create narrative visualizations. This research aims to provide an overview of current research and development in the automation involvement of narrative visualization tools. We discuss key research problems in each category and suggest new opportunities to encourage further research in the related domain.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2072593582",
                    "name": "Shixiong Cao"
                },
                {
                    "authorId": "2124913650",
                    "name": "Jiazhe Wang"
                },
                {
                    "authorId": "2163708412",
                    "name": "Nan Cao"
                }
            ]
        },
        {
            "paperId": "289fe1edf5bcdf3ef6225a3a1432206ac3b04207",
            "title": "Negative Emotions, Positive Outcomes? Exploring the Communication of Negativity in Serious Data Stories",
            "abstract": "Recent work has highlighted that emotion is key to the user experience with data stories. However, limited attention has been paid to negative emotions specifically. This work investigates the outcomes of negative emotions in the context of serious data stories and examines how they can be augmented by design methods from the perspectives of both storytellers and viewers. First, we conducted a workshop with 9 data story experts to understand the possible benefits of eliciting negative emotions in serious data stories and 19 potential design methods that contribute to negative emotions. Based on the findings from the workshop, we then conducted a lab study with 35 participants to explore the outcomes of eliciting negative emotions as well as the effectiveness of the design methods. The results indicated that negative emotions mainly facilitated contemplative experiences and long-term memory. Besides, the design methods showed varied effectiveness in augmenting negative emotions and being recalled.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080042495",
                    "name": "Xingyu Lan"
                },
                {
                    "authorId": "2134152070",
                    "name": "Yanqiu Wu"
                },
                {
                    "authorId": "2119036803",
                    "name": "Yang Shi"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2163708412",
                    "name": "Nan Cao"
                }
            ]
        },
        {
            "paperId": "adafcaa27e6397a581b512226e8ba8162d6caf62",
            "title": "VizBelle: A Design Space of Embellishments for Data Visualization",
            "abstract": "Visual embellishments, as a form of non-linguistic rhetorical figures, are used to help convey abstract concepts or attract readers' attention. Creating data visualizations with appropriate and visually pleasing embellishments is challenging since this process largely depends on the experience and the aesthetic taste of designers. To help facilitate designers in the ideation and creation process, we propose a design space, VizBelle, based on the analysis of 361 classified visualizations from online sources. VizBelle consists of four dimensions, namely, communication goal to fit user intention, object to select the target area, strategy and technique to offer potential approaches. We further provide a website to present detailed explanations and examples of various techniques. We conducted a within-subject study with 20 professional and amateur design enthusiasts to evaluate the effectiveness of our design space. Results show that our design space is illuminating and useful for designers to create data visualizations with embellishments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2145254118",
                    "name": "Ziyang Liu"
                },
                {
                    "authorId": "2168865304",
                    "name": "Cheng-jui Wang"
                },
                {
                    "authorId": "2080042495",
                    "name": "Xingyu Lan"
                },
                {
                    "authorId": "2118426910",
                    "name": "Y. Chen"
                },
                {
                    "authorId": "1685793922",
                    "name": "Siming Chen"
                },
                {
                    "authorId": "2163708412",
                    "name": "Nan Cao"
                }
            ]
        }
    ]
}