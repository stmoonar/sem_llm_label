{
    "authorId": "2238022819",
    "papers": [
        {
            "paperId": "179f98764407881167b90ee2d42dffdd28a697f8",
            "title": "Inside Out or Not: Privacy Implications of Emotional Disclosure",
            "abstract": "Privacy is dynamic, sensitive, and contextual, much like our emotions. Previous studies have explored the interplay between privacy and context, privacy and emotion, and emotion and context. However, there remains a significant gap in understanding the interplay of these aspects simultaneously. In this paper, we present a preliminary study investigating the role of emotions in driving individuals' information sharing behaviour, particularly in relation to urban locations and social ties. We adopt a novel methodology that integrates context (location and time), emotion, and personal information sharing behaviour, providing a comprehensive analysis of how contextual emotions affect privacy. The emotions are assessed with both self-reporting and electrodermal activity (EDA). Our findings reveal that self-reported emotions influence personal information-sharing behaviour with distant social groups, while neutral emotions lead individuals to share less precise information with close social circles, a pattern is potentially detectable with wrist-worn EDA. Our study helps lay the foundation for personalised emotion-aware strategies to mitigate oversharing risks and enhance user privacy in the digital age.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2321555214",
                    "name": "Elham Naghizade"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2244619392",
                    "name": "Benjamin Tag"
                },
                {
                    "authorId": "2293006761",
                    "name": "Flora D. Salim"
                }
            ]
        },
        {
            "paperId": "5468a398cbb91b0f126e10e6a827a46ee1eefc9b",
            "title": "Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot",
            "abstract": "Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals\u2019 practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2279801138",
                    "name": "Lin Tian"
                },
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2279785688",
                    "name": "Halil Ali"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "5d750b51dd5371998dfea27f391b4113a7c9aa62",
            "title": "Towards Detecting and Mitigating Cognitive Bias in Spoken Conversational Search",
            "abstract": "Instruments such as eye-tracking devices have contributed to understanding how users interact with screen-based search engines. However, user-system interactions in audio-only channels -- as is the case for Spoken Conversational Search (SCS) -- are harder to characterize, given the lack of instruments to effectively and precisely capture interactions. Furthermore, in this era of information overload, cognitive bias can significantly impact how we seek and consume information -- especially in the context of controversial topics or multiple viewpoints. This paper draws upon insights from multiple disciplines (including information seeking, psychology, cognitive science, and wearable sensors) to provoke novel conversations in the community. To this end, we discuss future opportunities and propose a framework including multimodal instruments and methods for experimental designs and settings. We demonstrate preliminary results as an example. We also outline the challenges and offer suggestions for adopting this multimodal approach, including ethical considerations, to assist future researchers and practitioners in exploring cognitive biases in SCS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2285470234",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "b2aa89f30b4fa8a012cb6f5f485b4632a6555351",
            "title": "Characterizing Information Seeking Processes with Multiple Physiological Signals",
            "abstract": "Information access systems are getting complex, and our understanding of user behavior during information seeking processes is mainly drawn from qualitative methods, such as observational studies or surveys. Leveraging the advances in sensing technologies, our study aims to characterize user behaviors with physiological signals, particularly in relation to cognitive load, affective arousal, and valence. We conduct a controlled lab study with 26 participants, and collect data including Electrodermal Activities, Photoplethysmogram, Electroencephalogram, and Pupillary Responses. This study examines informational search with four stages: the realization of Information Need (IN), Query Formulation (QF), Query Submission (QS), and Relevance Judgment (RJ). We also include different interaction modalities to represent modern systems, e.g., QS by text-typing or verbalizing, and RJ with text or audio information. We analyze the physiological signals across these stages and report outcomes of pairwise non-parametric repeated-measure statistical tests. The results show that participants experience significantly higher cognitive loads at IN with a subtle increase in alertness, while QF requires higher attention. QS involves demanding cognitive loads than QF. Affective responses are more pronounced at RJ than QS or IN, suggesting greater interest and engagement as knowledge gaps are resolved. To the best of our knowledge, this is the first study that explores user behaviors in a search process employing a more nuanced quantitative analysis of physiological signals. Our findings offer valuable insights into user behavior and emotional responses in information seeking processes. We believe our proposed methodology can inform the characterization of more complex processes, such as conversational information seeking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "6769f8aa26fd083d030019ca18e1af63de351c44",
            "title": "Quantifying and Measuring Confirmation Bias in Information Retrieval Using Sensors",
            "abstract": "It is well-known that cognitive bias influences information retrievers to receive information fairly. Among all the biases, we focus on confirmation bias, which is the most impactful and sometimes leads to polarization. Numerous projects have been working on improving search systems to provide fair results, while little work has been done on enhancing fairness from the user\u2019s side. Thus, this project aims to investigate a quantifiable approach to make the systems aware that retrievers carry confirmation bias and perform biased behaviors. Besides, some works have attempted to detect confirmation bias using web-logging or eye-tracking but failed to find differences between the search behaviors. In this regard, other quantifiable and objective measures should be applied. This project aims to collect multi-modal behavioral and physiological data using wearable sensors, and used as the input for machine learning techniques and build a bias-aware model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                }
            ]
        },
        {
            "paperId": "8e8737c80dbb333541577949175f3c0f5f782cd8",
            "title": "Towards Detecting Tonic Information Processing Activities with Physiological Data",
            "abstract": "Characterizing Information Processing Activities (IPAs) such as reading, listening, speaking, and writing, with physiological signals captured by wearable sensors can broaden the understanding of how people produce and consume information. However, sensors are highly sensitive to external conditions that are not trivial to control \u2013 not even in lab user studies. We conducted a pilot study (N = 7) to assess the robustness and sensitivity of physiological signals across four IPAs (READ, LISTEN, SPEAK, and WRITE) using multiple sensors. The collected signals include Electrodermal Activities, Blood Volume Pulse, gaze, and head motion. We observed consistent trends across participants, and ten features with statistically significant differences across the four IPAs. Our results provide preliminary quantitative evidence of differences in physiological responses when users encounter IPAs, revealing the necessity to inspect the signals separately according to the IPAs. The next step of this study moves into a specific context, information retrieval, and the IPAs are considered as the interaction modalities with the search system, for instance, submitting the search query by speaking or typing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        },
        {
            "paperId": "f555cbe1abcfbcf7e68fc31b5b19fb5c15890764",
            "title": "\"Living Within Four Walls\": Exploring Emotional and Social Dynamics in Mobile Usage During Home Confinement",
            "abstract": "Home confinement, a situation experienced by individuals for reasons ranging from medical quarantines, rehabilitation needs, disability accommodations, and remote working, is a common yet impactful aspect of modern life. While essential in various scenarios, confinement within the home environment can profoundly influence psychological well-being and digital device usage. In this study, we delve into these effects, utilising the COVID-19 lockdown as a special case study to draw insights extending to various homebound situations. We conducted an in-situ study with 32 participants living in states affected by COVID-19 lockdowns for three weeks and analysed their emotions, well-being, social roles, and mobile usage behaviours. We extracted user activity from app usage records in an unsupervised manner, and experimental results revealed that app usage behaviours are effective indicators of emotional well-being in confined environments. Our research has great potential for developing supportive strategies and remote programs, not only for people facing similar medical isolation situations, but also for individuals in long-term home confinement, such as those with chronic illnesses, recovering from surgery, or adapting to permanent remote work arrangements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1738321965",
                    "name": "Nan Gao"
                },
                {
                    "authorId": "2013992418",
                    "name": "Samuel C. Nolan"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "77650429",
                    "name": "Shakila Khan Rumi"
                },
                {
                    "authorId": "51940080",
                    "name": "Judith S. Heinisch"
                },
                {
                    "authorId": "30241647",
                    "name": "Christoph Anderson"
                },
                {
                    "authorId": "2107687827",
                    "name": "Klaus David"
                },
                {
                    "authorId": "2253483164",
                    "name": "Flora D. Salim"
                }
            ]
        }
    ]
}