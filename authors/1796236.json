{
    "authorId": "1796236",
    "papers": [
        {
            "paperId": "b0356c6593ba8b524fca9666419156aa9d9eea73",
            "title": "OBDF: OBDA + Data Federation \u2013 Extended Abstract",
            "abstract": "Ontology-Based Data Access (OBDA) has emerged as a well-established approach to information management, facilitating access to a sole relational relational database via a high-level ontology and declarative mappings. In response to the challenges posed by Big Data, we propose the Ontology-Based Data Federation (OBDF) framework, which merges OBDA with Data Federation. This merging allows for the integration of numerous, distributed, and heterogeneous data sources in a virtual, uniform, and semantically coherent fashion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2286851137",
                    "name": "Zhenzhen Gu"
                },
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                },
                {
                    "authorId": "2239506190",
                    "name": "Marco Di Panfilo"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2239509397",
                    "name": "Alessandro Mosca"
                },
                {
                    "authorId": "2238220229",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "8ce8cd5f6a2bbfa97a58e66b3d93ac7d0aeccd00",
            "title": "Ontology-Based Data Federation - A Framework Proposal",
            "abstract": "Ontology-based data access (OBDA) is a well established approach to information management that facilitates the access to relational data sources through the mediation of a conceptual domain view, given in terms of an ontology, and the use of a declarative mapping between the data layer and the ontology. We formally introduce here the notion of ontology-based data federation (OBDF) to denote a framework that combines OBDA with a data federation layer where multiple heterogeneous sources are virtually exposed as a single relational database. We discuss opportunities and challenges of OBDF, and propose novel techniques to make query answering in the OBDF setting more efficient. Our techniques are validated through an extensive experimental evaluation based on the Berlin SPARQL Benchmark. This work is an abridged version of [1].",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39188049",
                    "name": "Zhenzhen Gu"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "2239506190",
                    "name": "Marco Di Panfilo"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2239509397",
                    "name": "Alessandro Mosca"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "ed3a106c1add091e4c50a5ca4f1eba451d52bbf9",
            "title": "Direct Mappings under the Lens of Information Capacity (Extended Abstract)",
            "abstract": "With the rising popularity of graph-based approaches to data management, exposing the content of traditional, often relational, sources as (knowledge) graphs becomes more and more relevant. In such scenarios, Direct Mapping approaches are often used to automatically transform such sources into graph-like formats. A \u201cfundamental\u201d property of these transformations is to be information preserving , that is, it should be always possible to (algorithmically) reconstruct the content of the original database. Information preservation, along with other \u201cfundamental\u201d or \u201cdesirable\u201d properties proposed in the Semantic Web literature, has never been put into correspondence with over 40 years of extended literature coming from the traditional database perspective. In particular, to the best of our knowledge, it is unknown how classical results on information capacity, dominance, and equivalence, tailored towards specific tasks such as query answering or data update, relate to the results and definitions from the Semantic Web world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2239509397",
                    "name": "Alessandro Mosca"
                },
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                },
                {
                    "authorId": "1699914",
                    "name": "M. Montali"
                }
            ]
        },
        {
            "paperId": "138291f571ddfc3bf41c88d4895513d8a66aff29",
            "title": "Ontology-based Data Federation",
            "abstract": "Ontology-based data access (OBDA) is a well-established approach to information management which facilitates the access to a (single) relational data source through the mediation of a high-level ontology, and the use of a declarative mapping linking the data layer to the ontology. We formally introduce here the notion of ontology-based data federation (OBDF) to denote a framework that combines OBDA with a data federation layer where multiple, possibly heterogeneous sources are virtually exposed as a single relational database. We discuss opportunities and challenges of OBDF, and provide techniques to deliver efficient query answering in an OBDF setting. Such techniques are validated through an extensive experimental evaluation based on the Berlin SPARQL Benchmark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39188049",
                    "name": "Zhenzhen Gu"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "1806182",
                    "name": "A. Mosca"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "2185174421",
                    "name": "Jingliu Xiong"
                },
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                }
            ]
        },
        {
            "paperId": "5b20b0f1c045d3a9d0efe79f6d01997bc4bc25f7",
            "title": "Conceptually-grounded Mapping Patterns for Virtual Knowledge Graphs",
            "abstract": "Knowledge Graphs (KGs) have been gaining momentum recently in both academia and industry, due to the flexibility of their data model, allowing one to access and integrate collections of data of different forms. Virtual Knowledge Graphs (VKGs), a variant of KGs originating from the field of Ontology-based Data Access (OBDA), are a promising paradigm for integrating and accessing legacy data sources. The main idea of VKGs is that the KG remains virtual: the end-user interacts with a KG, but queries are reformulated on-the-fly as queries over the data source(s). To enable the paradigm, one needs to define declarative mappings specifying the link between the data sources and the elements in the VKG. In this work, we try to investigate common patterns that arise when specifying such mappings, building on well-established methodologies from the area of conceptual modeling and database design.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                },
                {
                    "authorId": "19468416",
                    "name": "A. Gal"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "1699914",
                    "name": "M. Montali"
                },
                {
                    "authorId": "1806182",
                    "name": "A. Mosca"
                },
                {
                    "authorId": "14398962",
                    "name": "Roee Shraga"
                }
            ]
        },
        {
            "paperId": "63dea65e4e1418cdee4d448c04660a9db657a793",
            "title": "A systematic overview of data federation systems",
            "abstract": "Data federation addresses the problem of uniformly accessing multiple, possibly heterogeneous data sources, by mapping them into a unified schema, such as an RDF(S)/OWL ontology or a relational schema, and by supporting the execution of queries, like SPARQL or SQL queries, over that unified schema. Data explosion in volume and variety has made data federation increasingly popular in many application domains. Hence, many data federation systems have been developed in industry and academia, and it has become challenging for users to select suitable systems to achieve their objectives. In order to systematically analyze and compare these systems, we propose an evaluation framework comprising four dimensions: (i) federation capabilities, i.e., query language, data source, and federation techniques; (ii) data security, i.e., authentication, authorization, auditing, encryption, and data masking; (iii) interface, i.e., graphical interface, command line interface, and application programming interface; and (iv) development, i.e., main development language, deployment, commercial support, open source, and release. Using this framework, we thoroughly studied 51 data federation systems from the Semantic Web and Database communities. This paper shares the results of our investigation and aims to provide reference material and insights for users, developers and researchers selecting or further developing data federation systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39188049",
                    "name": "Zhenzhen Gu"
                },
                {
                    "authorId": "2650912",
                    "name": "F. Corcoglioniti"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "1806182",
                    "name": "A. Mosca"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "2185174421",
                    "name": "Jingliu Xiong"
                },
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                }
            ]
        },
        {
            "paperId": "9ac0a85b5420f3a4684b46ebceb5d1a09e7a77ad",
            "title": "Ontology-based Data Federation (Extended Abstract)",
            "abstract": "We formally introduce ontology-based data federation (OBDF), to denote a framework combining ontology-based data access (OBDA) with a data federation layer, which virtually exposes multiple heterogeneous sources as a single relational database. In this setting, the SQL queries generated by the OBDA component by translating user SPARQL queries are further transformed by the data federation layer so as to be efficiently executed over the data sources. The structure of these SQL queries directly affects their execution time in the data federation layer and their optimization is crucial for performance. We propose here novel optimizations specific for OBDF, which are based on \u201chints\u201d about existing data redundancies in the sources, empty join operations, and the need for materialized views. Such hints can be systematically inferred by analyzing the OBDA mappings and ontology and exploited to simplify the query structure. We also carry out an experimental evaluation in which we show the effectiveness of our optimizations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39188049",
                    "name": "Zhenzhen Gu"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "1806182",
                    "name": "A. Mosca"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "2185174421",
                    "name": "Jingliu Xiong"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "e80aba67e92aec3ef06ed31193832c6f81e9a2ed",
            "title": "INODE",
            "abstract": "A full-fledged data exploration system must combine different access modalities with a powerful concept of guiding the user in the exploration process, by being reactive and anticipative both for data discovery and for data linking. Such systems are a real opportunity for our community to cater to users with different domain and data science expertise. We introduce INODE - an end-to-end data exploration system - that leverages, on the one hand, Machine Learning and, on the other hand, semantics for the purpose of Data Management (DM). Our vision is to develop a classic unified, comprehensive platform that provides extensive access to open datasets, and we demonstrate it in three significant use cases in the fields of Cancer Biomarker Research, Research and Innovation Policy Making, and Astrophysics. INODE offers sustainable services in (a) data modeling and linking, (b) integrated query processing using natural language, (c) guidance, and (d) data exploration through visualization, thus facilitating the user in discovering new insights. We demonstrate that our system is uniquely accessible to a wide range of users from larger scientific communities to the public. Finally, we briefly illustrate how this work paves the way for new research opportunities in DM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1680709",
                    "name": "Georgia Koutrika"
                },
                {
                    "authorId": "2463025",
                    "name": "Fr\u00e9d\u00e9ric B. Bastian"
                },
                {
                    "authorId": "1726022751",
                    "name": "Theofilos Belmpas"
                },
                {
                    "authorId": "3075644",
                    "name": "Martin Braschler"
                },
                {
                    "authorId": "151240818",
                    "name": "Ursin Brunner"
                },
                {
                    "authorId": "2072276517",
                    "name": "D. Calvanese"
                },
                {
                    "authorId": "14469238",
                    "name": "M. Fabricius"
                },
                {
                    "authorId": "1726045725",
                    "name": "Orest Gkini"
                },
                {
                    "authorId": "2072251887",
                    "name": "Catherine Kosten"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "40469553",
                    "name": "Antonis Litke"
                },
                {
                    "authorId": "1403433652",
                    "name": "Hendrik L\u00fccke-Tieke"
                },
                {
                    "authorId": "1970432",
                    "name": "F. Massucci"
                },
                {
                    "authorId": "1725471",
                    "name": "T. M. Farias"
                },
                {
                    "authorId": "1806182",
                    "name": "A. Mosca"
                },
                {
                    "authorId": "2072251867",
                    "name": "Francesco Multari"
                },
                {
                    "authorId": "145679608",
                    "name": "N. Papadakis"
                },
                {
                    "authorId": "153516669",
                    "name": "D. Papadopoulos"
                },
                {
                    "authorId": "2061639772",
                    "name": "Yogendra Patil"
                },
                {
                    "authorId": "2072259106",
                    "name": "Aur\u00e9lien Personnaz"
                },
                {
                    "authorId": "3235045",
                    "name": "Guillem Rull"
                },
                {
                    "authorId": "2723088",
                    "name": "A. Sima"
                },
                {
                    "authorId": "153437025",
                    "name": "Ellery Smith"
                },
                {
                    "authorId": "1807115",
                    "name": "Dimitrios Skoutas"
                },
                {
                    "authorId": "2075402169",
                    "name": "S. Subramanian"
                },
                {
                    "authorId": "2055961473",
                    "name": "G. Xiao"
                },
                {
                    "authorId": "2113917675",
                    "name": "Kurt Stockinger"
                }
            ]
        },
        {
            "paperId": "64b67c058dc4fd9af973a0be32098a823ac4488a",
            "title": "Counting Query Answers over a DL-Lite Knowledge Base",
            "abstract": "Counting answers to a query is an operation supported by virtually all database management systems.\n\nIn this paper we focus on counting answers over a Knowledge Base (KB), which may be viewed as a database enriched with background knowledge about the domain under consideration.\n\nIn particular, we place our work in the context of Ontology-Mediated Query Answering/Ontology-based Data Access (OMQA/OBDA), where the language used for the ontology is a member of the DL-Lite family and the data is a (usually virtual) set of assertions.\n\nWe study the data complexity of query answering, for different members of the DL-Lite family that include number restrictions, and for variants of conjunctive queries with counting that differ with respect to their shape (connected, branching, rooted).\n\nWe improve upon existing results by providing PTIME and coNP lower bounds, and upper bounds in PTIME and LOGSPACE.\n\nFor the LOGSPACE case, we have devised a novel query rewriting technique into first-order logic with counting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "3179212",
                    "name": "Julien Corman"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2499758",
                    "name": "Simon Razniewski"
                }
            ]
        },
        {
            "paperId": "dc186626861877e33a462211d7ed41cc26dd3d77",
            "title": "Rewriting Count Queries over DL-Lite TBoxes with Number Restrictions",
            "abstract": ". We propose a query rewriting algorithm for a restricted class of conjunctive queries evaluated under count semantics over a DL-Lite knowledge base. The target query language is an extension of relational algebra with aggregation and arithmetic functions, which can be translated into SQL. The algorithm supports number restrictions on the RHS of axioms in the input TBox, which can be used to encode statistics. The size of the output query remains linear in the binary encoding of these numbers, which improves upon previously proposed approaches",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "3179212",
                    "name": "Julien Corman"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2499758",
                    "name": "Simon Razniewski"
                }
            ]
        },
        {
            "paperId": "b3d5999551054230ba95808e068db80421b41a4d",
            "title": "VIG: Data scaling for OBDA benchmarks",
            "abstract": "In this paper we describe VIG, a data scaler for Ontology-Based Data Access (OBDA) benchmarks. Data scaling is a relatively recent approach, proposed in the database community, that allows for quickly scaling an input data instance to s times its size, while preserving certain application-specific characteristics. The advantages of the scaling approach are that the same generator is general, in the sense that it can be re-used on different database schemas, and that users are not required to manually input the data characteristics. In the VIG system, we lift the scaling approach from the pure database level to the OBDA level, where the domain information of ontologies and mappings has to be taken into account as well. VIG is efficient and notably each tuple is generated in constant time. To evaluate VIG, we have carried out an extensive set of experiments with three datasets (BSBM, DBLP, and NPD), using two OBDA systems (Ontop and D2RQ), backed by two relational database engines (MySQL and PostgreSQL), and compared with real-world data, ad-hoc data generators, and random data generators. The encouraging results show that the data scaling performed by VIG is efficient and that the scaled data are suitable for benchmarking OBDA systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "cc493ba2a621d453603aaffb6f9ad8137fb21193",
            "title": "Enriching Ontology-based Data Access with Provenance (Extended Version)",
            "abstract": "Ontology-based data access (OBDA) is a popular paradigm for querying heterogeneous data sources by connecting them through mappings to an ontology. In OBDA, it is often difficult to reconstruct why a tuple occurs in the answer of a query. We address this challenge by enriching OBDA with provenance semirings, taking inspiration from database theory. In particular, we investigate the problems of (i) deciding whether a provenance annotated OBDA instance entails a provenance annotated conjunctive query, and (ii) computing a polynomial representing the provenance of a query entailed by a provenance annotated OBDA instance. Differently from pure databases, in our case, these polynomials may be infinite. To regain finiteness, we consider idempotent semirings, and study the complexity in the case of DL-LiteR ontologies. We implement Task (ii) in a state-of-the-art OBDA system and show the practical feasibility of the approach through an extensive evaluation against two popular benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2383803",
                    "name": "A. Ozaki"
                },
                {
                    "authorId": "144138457",
                    "name": "R. Pe\u00f1aloza"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "2aefe3a0938044e47242c763c284ecc6948e4d0b",
            "title": "Cost-Driven Ontology-Based Data Access (Extended Version)",
            "abstract": "In ontology-based data access (OBDA), users are provided with a conceptual view of a (relational) data source that abstracts away details about data storage. This conceptual view is realized through an ontology that is connected to the data source through declarative mappings, and query answering is carried out by translating the user queries over the conceptual view into SQL queries over the data source. Standard translation techniques in OBDA try to transform the user query into a union of conjunctive queries (UCQ), following the heuristic argument that UCQs can be efficiently evaluated by modern relational database engines. In this work, we show that translating to UCQs is not always the best choice, and that, under certain conditions on the interplay between the ontology, the map- pings, and the statistics of the data, alternative translations can be evaluated much more efficiently. To find the best translation, we devise a cost model together with a novel cardinality estimation that takes into account all such OBDA components. Our experiments confirm that (i) alternatives to the UCQ translation might produce queries that are orders of magnitude more efficient, and (ii) the cost model we propose is faithful to the actual query evaluation cost, and hence is well suited to select the best translation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "3c4068b41b4f177df123ab5068c3969ca9efa412",
            "title": "Data Scaling in OBDA Benchmarks: The VIG Approach",
            "abstract": "In this paper we describe VIG, a data scaler for benchmarks in the context of ontology-based data access (OBDA). Data scaling is a relatively recent approach, proposed in the database community, that allows for quickly scaling up an input data instance to s times its size, while preserving certain application-specific characteristics. The advantage of the approach is that the user is not required to manually input the characteristics of the data to be produced, making it particularly suitable for OBDA benchmarks, where the complexity of database schemas might pose a challenge for manual input (e.g., the NPD benchmark contains 70 tables with some containing more than 60 columns). As opposed to a traditional data scaler, VIG includes domain information provided by the OBDA mappings and the ontology in order to produce data. VIG is currently used in the NPD benchmark, but it is not NPD-specific and can be seeded with any data instance. The distinguishing features of VIG are (1) its simple and clear generation strategy; (2) its efficiency, as each value is generated in constant time, without accesses to the disk or to RAM to retrieve previously generated values; (3) and its generality, as the data is exported in CSV files that can be easily imported by any RDBMS system. VIG is a java implementation licensed under Apache 2.0, and its source code is available on GitHub (this https URL) in the form of a Maven project. The code is being maintained since two years by the -ontop- team at the Free University of Bozen-Bolzano.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "87d28a7df2d2f8738a7df1430954481843165509",
            "title": "Fast and Simple Data Scaling for OBDA Benchmarks",
            "abstract": "In this paper we describe VIG, a data scaler for OBDA benchmarks. Data scaling is a relatively recent approach, proposed in the database community, that allows for quickly scaling an input data instance to n times its size, while preserving certain application-specific characteristics. The advantages of the scaling approach are that the same generator is general, in the sense that it can be re-used on different database schemas, and that users are not required to manually input the data characteristics. In the VIG system, we lift the scaling approach from the pure database level to the OBDA level, where the domain information of ontologies and mappings has to be taken into account as well. VIG is efficient and notably each tuple is generated in constant time. VIG has been successfully used in the NPD benchmark, but it provides a general approach that can be re-used to scale any data instance in any OBDA setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "9c9d3d988cbd4f8c0318030786dede1cb64b90ae",
            "title": "Ontop: Answering SPARQL queries over relational databases",
            "abstract": "We present Ontop, an open-source Ontology-Based Data Access (OBDA) system that allows for querying relational data sources through a conceptual representation of the domain of interest, provided in terms of an ontology, to which the data sources are mapped. Key features of Ontop are its solid theoretical foundations, a virtual approach to OBDA, which avoids materializing triples and is implemented through the query rewriting technique, extensive optimizations exploiting all elements of the OBDA architecture, its compliance to all relevant W3C recommendations (including SPARQL queries, R2RML mappings, and OWL2QL and RDFS ontologies), and its support for all major relational databases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "2705754",
                    "name": "Benjamin Cogrel"
                },
                {
                    "authorId": "1404601426",
                    "name": "Sarah Komla-Ebri"
                },
                {
                    "authorId": "1721171",
                    "name": "R. Kontchakov"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "1402993601",
                    "name": "M. Rodriguez-Muro"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "be46e7b45d8527329d3d5371a8e9b3c95fb27a1f",
            "title": "OBDA Constraints for Effective Query Answering (Extended Version)",
            "abstract": "In Ontology Based Data Access (OBDA) users pose SPARQL queries over an ontology that lies on top of relational datasources. These queries are translated on-the-fly into SQL queries by OBDA systems. Standard SPARQL-to-SQL translation techniques in OBDA often produce SQL queries containing redundant joins and unions, even after a number of semantic and structural optimizations. These redundancies are detrimental to the performance of query answering, especially in complex industrial OBDA scenarios with large enterprise databases. To address this issue, we introduce two novel notions of OBDA constraints and show how to exploit them for efficient query answering. We conduct an extensive set of experiments on large datasets using real world data and queries, showing that these techniques strongly improve the performance of query answering up to orders of magnitude.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1945088",
                    "name": "D. Hovland"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "dc16ea1df27fbeaf618fea325aad63a90d4e71fc",
            "title": "An Evaluation of VIG with the BSBM Benchmark",
            "abstract": "We present an experimental evaluation of VIG, a data scaler for OBDA benchmarks. Data scaling is a relatively recent approach, proposed in the database community, that allows for scaling an input data instance to s times its size, while preserving certain application-specific characteristics. A data scaler is a \u201cgeneral\u201d generator, in the sense that it can be re-used on different database schemas, and that users are not required to manually input the data characteristics. VIG lifts the scaling approach from the database level to the OBDA level, where the domain information of ontologies and mappings has to be taken into account as well. To evaluate VIG, in this paper we use it to generate data for the Berlin SPARQL Benchmark (BSBM), and compare it with the official BSBM data generator.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "14e849aa215e9d3dbbddc0dac9bac9849cf1f967",
            "title": "The NPD Benchmark: Reality Check for OBDA Systems",
            "abstract": "In the last decades we moved from a world in which an enterprise had one central database\u2014rather small for todays\u2019 standards\u2014to a world in which many different\u2014and big\u2014databases must interact and operate, providing the user an integrated and understandable view of the data. Ontology-Based Data Access (OBDA) is becoming a popular approach to cope with this new scenario. OBDA separates the user from the data sources by means of a conceptual view of the data (ontology) that provides clients with a convenient query vocabulary. The ontology is connected to the data sources through a declarative specification given in terms of mappings. Although prototype OBDA systems providing the ability to answer SPARQL queries over the ontology are available, a significant challenge remains when it comes to use these systems in industrial environments: performance. To properly evaluate OBDA systems, benchmarks tailored towards the requirements in this setting are needed. In this work, we propose a novel benchmark for OBDA systems based on real data coming from the oil industry: the Norwegian Petroleum Directorate (NPD) FactPages. Our benchmark comes with novel techniques to generate, from the NPD data, datasets of increasing size, taking into account the requirements dictated by the OBDA setting. We validate our benchmark on significant OBDA systems, showing that it is more adequate than previous benchmarks not tailored for OBDA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "4a3a2f8ccaf34909ba6b60c51e83c0f0d9f3d30b",
            "title": "Optique: Zooming in on Big Data",
            "abstract": "Optique overcomes problems in current ontology-based data access systems pertaining to installation overhead, usability, scalability, and scope by integrating a user-oriented query interface, semi-automated managing methods, new query rewriting techniques, and temporal and streaming data processing in one platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144911780",
                    "name": "M. Giese"
                },
                {
                    "authorId": "153750193",
                    "name": "A. Soylu"
                },
                {
                    "authorId": "1401967715",
                    "name": "Guillermo Vega-Gorgojo"
                },
                {
                    "authorId": "2033382",
                    "name": "A. Waaler"
                },
                {
                    "authorId": "49817869",
                    "name": "P. Haase"
                },
                {
                    "authorId": "1402158435",
                    "name": "Ernesto Jim\u00e9nez-Ruiz"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "3342377",
                    "name": "\u00d6zg\u00fcr L. \u00d6z\u00e7ep"
                },
                {
                    "authorId": "1731107",
                    "name": "R. Rosati"
                }
            ]
        },
        {
            "paperId": "77f1fd7c215fbca118622dd9c8e1c1dde7af4bf7",
            "title": "OBDA with the Ontop Framework",
            "abstract": "Ontology-based data access (OBDA) has become a popular paradigm for accessing data stored in legacy sources using Semantic Web technologies. In the OBDA setting, users access the data through a conceptual layer, which provides a convenient query vocabulary abstracting from specific aspects related to the data sources. This conceptual layer is typically expressed as an RDF(S) or OWL ontology, and it is connected to the underlying relational databases using R2RML mappings. When the ontology is queried in SPARQL, the OBDA system exploits the mappings to retrieve elements from the data sources and construct the answers expected by the user. Different approaches for query processing in OBDA have been proposed. We focus here on the virtual approach, which avoids materializing triples retrieved through mappings and answers the SPARQL queries by translating them into SQL queries over the data sources. In this paper we present our mature open-source OBDA framework Ontop, which supports all W3C standards related to OBDA, and which produces efficiently executable SQL queries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "2705754",
                    "name": "Benjamin Cogrel"
                },
                {
                    "authorId": "3449760",
                    "name": "E. G. Kalayci"
                },
                {
                    "authorId": "1404601426",
                    "name": "Sarah Komla-Ebri"
                },
                {
                    "authorId": "1721171",
                    "name": "R. Kontchakov"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "1402993601",
                    "name": "M. Rodriguez-Muro"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "57c402f7faa352a707f68d43f196389d3c9118f9",
            "title": "A Scalable Benchmark for OBDA Systems: Preliminary Report",
            "abstract": "In ontology-based data access (OBDA), the aim is to provide a highlevel conceptual view over potentially very large (relational) data sources by means of a mediating ontology. The ontology is connected to the data sources through a declarative specification given in terms of mappings that relate each (class and property) symbol in the ontology to an (SQL) view over the data. Although prototype OBDA systems providing the ability to answer SPARQL queries over the ontology are available, a significant challenge remains: performance. To properly evaluate OBDA systems, benchmarks tailored towards the requirements in this setting are needed. OWL benchmarks, which have been developed to test the performance of generic SPARQL query engines, however, fail at 1) exhibiting a complex real-world ontology, 2) providing challenging real world queries, 3) providing large amounts of real-world data, and the possibility to test a system over data of increasing size, and 4) capturing important OBDA-specific measures related to the rewriting-based query answering approach in OBDA. In this work, we propose a novel benchmark for OBDA systems based on a real world use-case adopted in the EU project Optique. We validate our benchmark on the system Ontop, showing that it is more adequate than previous benchmarks not tailored for OBDA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "3242320",
                    "name": "Mindaugas Slusnys"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                }
            ]
        },
        {
            "paperId": "6f6c5dc5c374ecfb35f20664f2c8c18027ee2276",
            "title": "The NPD Benchmark for OBDA Systems",
            "abstract": "In Ontology-Based Data Access (OBDA), queries are posed over a high-level conceptual view, and then translated into queries over a potentially very large (usually relational) data source. The ontology is connected to the data sources through a declarative specification given in terms of mappings. Although prototype OBDA systems providing the ability to answer SPARQL queries over the ontology are available, a significant challenge remains: performance. To properly evaluate OBDA systems, benchmarks tailored towards the requirements in this setting are needed. OWL benchmarks, which have been developed to test the performance of generic SPARQL query engines, however, fail to evaluate OBDA specific features. In this work, we propose a novel benchmark for OBDA systems based on the Norwegian Petroleum Directorate (NPD). Our benchmark comes with novel techniques to generate, from available data, datasets of increasing size, taking into account the requirements dictated by the OBDA setting. We validate our benchmark on significant OBDA systems, showing that it is more adequate than previous benchmarks not tailored for OBDA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "2511068",
                    "name": "Mart\u00edn Rezk"
                },
                {
                    "authorId": "3242320",
                    "name": "Mindaugas Slusnys"
                },
                {
                    "authorId": "47490276",
                    "name": "Guohui Xiao"
                },
                {
                    "authorId": "1733846",
                    "name": "Diego Calvanese"
                }
            ]
        },
        {
            "paperId": "fe4b2cfdc7f1c040a48a6aa7094813d80f10507d",
            "title": "Modern Cooperative Parallel SAT Solving",
            "abstract": "Nowadays, powerful parallel SAT solvers are based on an algorithm portfolio. The alternative approach, (iterative) search space partitioning, cannot keep up, although, according to the literature, iterative partitioning systems should scale better than portfolio solvers. This rises often! In this paper we identify key problems in current parallel cooperative SAT solving approaches, most importantly communication, how to partition the search space, and how to utilize the sequential search engine. First, we improve on each problem separately. In a further step, we show that combining all the improvements leads to a state-of-the-art parallel SAT solver, which does not use the portfolio approach, but instead relies on iterative partitioning. The experimental evaluation of this system completely changes the picture about the performance of search space partitioning SAT solvers: on instances of a combined benchmark of recent SAT competitions, the presented approach can keep up with the winners of last years SAT competition. The combined improvements improve the existing cooperative solver splitter by 24%: instead of 561 out of 880 instances, the new solver Pcasso can solve 696 instances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1809560",
                    "name": "Norbert Manthey"
                },
                {
                    "authorId": "1796236",
                    "name": "D. Lanti"
                },
                {
                    "authorId": "143962849",
                    "name": "A. Irfan"
                }
            ]
        }
    ]
}