{
    "authorId": "2118681612",
    "papers": [
        {
            "paperId": "855eccdb127c2987a825275d1afa6f55dcc02cb9",
            "title": "Flow-Edge-Net: Video Saliency Detection Based on Optical Flow and Edge-Weighted Balance Loss",
            "abstract": "Optical flow networks have been widely utilized for video saliency detection (VSD) due to their effective performance in capturing the motion of objects. However, the use of optical flow blurs the edges of salient objects and leads to the problems of poorly defined object boundaries. To address this issue, we propose an optical flow-based edge-weighted loss function, to train a network called Flow-Edge-Net, which can balance the weights of the foreground and background information at the edges of video frames. It has achieved superior performance in detecting salient boundaries. Specifically, we propose two complementary encoding and decoding networks based on the concept of decoupling. That is, the optical flow network focuses on moving objects, while the edge network, based on the encoder-decoder structure, focuses on edge information. As the two networks output features of the same dimension and are from the same input, our proposed self-designed adaptive weighted feature fusion module can compare and integrate the edge information and location information from the two networks through adaptive weighting. The proposed method has been evaluated on five widely used databases. Experiment results demonstrate the superior performance of the proposed Flow-Edge-Net in locating salient objects, with accurate and refined edges. The proposed method achieves superior performance over the state-of-the-art methods in detecting salient objects in videos.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1783889",
                    "name": "Muwei Jian"
                },
                {
                    "authorId": "2127330241",
                    "name": "Xiangwei Lu"
                },
                {
                    "authorId": "2139780382",
                    "name": "Xiaoyang Yu"
                },
                {
                    "authorId": "144904672",
                    "name": "Yakun Ju"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                },
                {
                    "authorId": "145412853",
                    "name": "K. Lam"
                }
            ]
        },
        {
            "paperId": "5d8b32393a89a2c0999980c0ddc56b6a34d676bb",
            "title": "Face hallucination using multisource references and cross\u2010scale dual residual fusion mechanism",
            "abstract": "There is an increasing interest in enhancing the quality of low\u2010resolution (LR) facial images for various social life applications. Existing methods often use domain\u2010specific prior knowledge, which is effective in improving the face super\u2010resolution model's performance. However, it is challenging to obtain rich and accurate prior information from LR inputs in real\u2010world scenarios, which can limit the robustness and generalization ability of the developed face super\u2010resolution model. In this paper, a multisource reference\u2010based face super\u2010resolution Network, namely MSRNet, is proposed. Without considering the prior knowledge of faces, the network can reconstruct a LR face image with a magnitude factor of 8 under the guidance of multiple reference face images of different identities. By constructing an \u201cappearance\u2010alike\u201d reference data set Face_Ref, the designed MSRNet aims to fully exploit the local and spatially similar high frequency information between the distinct references and the current face. More specifically, to effectively combine the information from multiple references, a cross\u2010scale and cross\u2010space feature fusion mechanism is introduced for external and internal references, and then the enhanced local semantics are finally incorporated into the high\u2010resolution face reconstruction. The robustness of face image super\u2010resolution is increased compared to current correlation approaches, since it not only eliminates the need for face prior knowledge but also avoids performing alignment operations on reference faces with multiple expressions and different poses. Experimental results show that the proposed model is able to produce results for face super\u2010resolution that are satisfying and dependable and outperforms the state\u2010of\u2010the\u2010art methods in terms of visual perceptual quality and quantity evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151039189",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "1783889",
                    "name": "Muwei Jian"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                }
            ]
        },
        {
            "paperId": "a6dde85998abcea91090f2a4218dfe32bd6f03d8",
            "title": "Face Super-resolution Based on Multi-source References",
            "abstract": "This paper proposes a multi-source references (MSR) based face super-resolution (FSR) model. More specifically, to enhance the low-quality large-scale reconstruction of faces without the involvement of face prior knowledge, we propose a multi-source references based FSR framework exploiting a constructed reference library of nonidentity faces and an information mining module for external and internal references. Experimental results show that the proposed model can provide more satisfactory and reliable face super-resolution results than the-state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151039177",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "1783889",
                    "name": "Muwei Jian"
                },
                {
                    "authorId": "2183577986",
                    "name": "Paul Smith"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                }
            ]
        },
        {
            "paperId": "0db434abf6759be054fea9f07d9b3c11b742e0ae",
            "title": "Inverse Domain Adaptation for Remote Sensing Images Using Wasserstein Distance",
            "abstract": "In this work, an inverse domain adaptation (IDA) method is proposed to cope with the distributional mismatch between the training images in the source domain and the test images in the target domain in remote sensing. More specifically, a cycleGAN structure using the Wasserstein distance is developed to learn the distribution of the remote sensing images in the source domain before the images in the target domain are transformed into similar distribution while preserving the image details and semantic consistency of the target images via style transfer. Extensive experiments using the GF1 data are performed to confirm the effectiveness of the proposed IDA method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119132314",
                    "name": "Ziyao Li"
                },
                {
                    "authorId": "2151036308",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "144305489",
                    "name": "Man-On Pun"
                },
                {
                    "authorId": "2145078072",
                    "name": "Zhiguo Wang"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                }
            ]
        },
        {
            "paperId": "a2d47bd46301493fc4c8034e8cf3912b6605ab99",
            "title": "Semi-Supervised Land-Use Classification Using Weakly Labeled Remote Sensing Data",
            "abstract": "This work develops robust semi -supervised classifiers to tackle three most challenging problems in land-use classification using remote sensing data, namely mixed pixels, weak labels and imbalanced data. Specifically, this work proposes to first divide the pixels in remote sensing images into two groups, namely the pixels with accurate labels and pixels with weak labels. To cope with the imbalanced data problem in the pixels with accurate labels, an improved cross entropy-based cost function is proposed to weigh the contributions from data of different classes based on its importance by exploiting the term frequency-inverse document frequency (TF-IDF) algorithm. Furthermore, for the pixels with weak labels, a nuclear norm-based cost function is developed to direct the training process without requiring data labels. To cope with the interference due to weakly labeled data with unrepresentative spatial features, an artificial class called \u201cUnknown\u201d is proposed. Extensive experiments validate the effectiveness of the proposed semi-supervised classifier.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151036308",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "144305489",
                    "name": "Man-On Pun"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                }
            ]
        },
        {
            "paperId": "f97aaa26e94a44339afee84bb8f6d8b36e14e276",
            "title": "Video saliency detection based on temporal difference and pixel gradient",
            "abstract": "Even though temporal information matters for the quality of video saliency detection, many problems such as bad performance in time-space coherence and edge continuity still face present network frameworks. In response to these problems, this paper designs a full convolutional neural network, which integrates temporal differential and pixel gradient to fine tune the edges of targets. Meanwhile, the changes of pixel gradients of original images are used to recursively improve the continuity of target edges and details of central areas. The method presented in the paper has been tested with two available public datasets and its effectiveness been proved after it being compared with 6 other widely accepted methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2127330241",
                    "name": "Xiangwei Lu"
                },
                {
                    "authorId": "1783889",
                    "name": "Muwei Jian"
                },
                {
                    "authorId": "2151038776",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "2214745437",
                    "name": "Zhichao Yun"
                },
                {
                    "authorId": "2016279",
                    "name": "Peiguang Lin"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                }
            ]
        },
        {
            "paperId": "478d1df91f76c7d564df8e9b713ce8248efc853e",
            "title": "A Novel Approach to Remote Sensing Image Retrieval with Multi-feature VP-Tree Indexing and Online Feature Selection",
            "abstract": "With the development of remote sensing (RS) techniques, the amount of RS images increases dramatically. It is a challenge to utilize those RS big data efficiently. Content-based Image Retrieval (CBIR) is a typical approximate similarity search problem, which needs to establish an effective index structure to reduce the time of retrieval. By analyzing the limitations of commonly-used indexing mechanisms in the current CBIR system, we propose a novel scheme that dynamically combines vantage point tree (vp-tree) indexes to CBIR by using spacing-correlation strategies to determine the vantage points. Borrowing ideas from feature selection, we have also put forward a new measure to adaptively online select proper vp-tree indexing in different feature spaces, the distance-contrast-based indexing validity index (DCIVI). And we then employ vp-tree index structure in each feature space, which can properly describe the content of the RS image by the chosen features. Experimental results on various typical land covers retrieval validate that the proposed method is effective and not only is the response speed increased by 70~100 times, but also the retrieval quality (in terms of precision and recall) is improved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8087867",
                    "name": "Shijin Li"
                },
                {
                    "authorId": "2118681612",
                    "name": "Hui Yu"
                },
                {
                    "authorId": "46762631",
                    "name": "Lixin Yuan"
                }
            ]
        }
    ]
}