{
    "authorId": "143999398",
    "papers": [
        {
            "paperId": "011c3417b6f70b7ca8c866157259abb0c84beb4d",
            "title": "Dynamic fairness-aware recommendation through multi-agent social choice",
            "abstract": "Algorithmic fairness in the context of personalized recommendation presents significantly different challenges to those commonly encountered in classification tasks. Researchers studying classification have generally considered fairness to be a matter of achieving equality of outcomes (or some other metric) between a protected and unprotected group, and built algorithmic interventions on this basis. We argue that fairness in real-world application settings in general, and especially in the context of personalized recommendation, is much more complex and multi-faceted, requiring a more general approach. To address the fundamental problem of fairness in the presence of multiple stakeholders, with different definitions of fairness, we propose the Social Choice for Recommendation Under Fairness \u2013 Dynamic (SCRUF-D) architecture, which formalizes multistakeholder fairness in recommender systems as a two-stage social choice problem. In particular, we express recommendation fairness as a combination of an allocation and an aggregation problem, which integrate both fairness concerns and personalized recommendation provisions, and derive new recommendation techniques based on this formulation. We demonstrate the ability of our framework to dynamically incorporate multiple fairness concerns using both real-world and synthetic datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72509562",
                    "name": "Amanda Aird"
                },
                {
                    "authorId": "103553571",
                    "name": "Paresha Farastu"
                },
                {
                    "authorId": "2210382585",
                    "name": "Joshua Sun"
                },
                {
                    "authorId": "1805040",
                    "name": "A. Voida"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                },
                {
                    "authorId": "2056064458",
                    "name": "R. Burke"
                }
            ]
        },
        {
            "paperId": "1f22d986eca360b46c6cde8c72e605524c72570f",
            "title": "Online Reviews Are Leading Indicators of Changes in K-12 School Attributes",
            "abstract": "School rating websites are increasingly used by parents to assess the quality and fit of U.S. K-12 schools for their children. These online reviews often contain detailed descriptions of a school\u2019s strengths and weaknesses, which both reflect and inform perceptions of a school. Existing work on these text reviews has focused on finding words or themes that underlie these perceptions, but has stopped short of using the textual reviews as leading indicators of school performance. In this paper, we investigate to what extent the language used in online reviews of a school is predictive of changes in the attributes of that school, such as its socio-economic makeup and student test scores. Using over 300K reviews of 70K U.S. schools from a popular ratings website, we apply language processing models to predict whether schools will significantly increase or decrease in an attribute of interest over a future time horizon. We find that using the text improves predictive performance significantly over a baseline model that does not include text but only the historical time-series of the indicators themselves, suggesting that the review text carries predictive power. A qualitative analysis of the most predictive terms and phrases used in the text reviews indicates a number of topics that serve as leading indicators, such as diversity, changes in school leadership, a focus on testing, and school safety.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107918726",
                    "name": "Linsen Li"
                },
                {
                    "authorId": "1741453",
                    "name": "A. Culotta"
                },
                {
                    "authorId": "2496741",
                    "name": "Douglas N. Harris"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                }
            ]
        },
        {
            "paperId": "5ce899aa65eb639668cfb4f2b1341294c494d290",
            "title": "The Many Faces of Fairness: Exploring the Institutional Logics of Multistakeholder Microlending Recommendation",
            "abstract": "Recommender systems have a variety of stakeholders. Applying concepts of fairness in such systems requires attention to stakeholders\u2019 complex and often-conflicting needs. Since fairness is socially constructed, there are numerous definitions, both in the social science and machine learning literatures. Still, it is rare for machine learning researchers to develop their metrics in close consideration of their social context. More often, standard definitions are adopted and assumed to be applicable across contexts and stakeholders. Our research starts with a recommendation context and then seeks to understand the breadth of the fairness considerations of associated stakeholders. In this paper, we report on the results of a semi-structured interview study with 23 employees who work for the Kiva microlending platform. We characterize the many different ways in which they enact and strive toward fairness for microlending recommendations in their own work, uncover the ways in which these different enactments of fairness are in tension with each other, and identify how stakeholders are differentially prioritized. Finally, we reflect on the implications of this study for future research and for the design of multistakeholder recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109849714",
                    "name": "Jessie J. Smith"
                },
                {
                    "authorId": "1506759334",
                    "name": "Anas Buhayh"
                },
                {
                    "authorId": "2219930188",
                    "name": "Anushka Kathait"
                },
                {
                    "authorId": "2219930216",
                    "name": "Pradeep Ragothaman"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                },
                {
                    "authorId": "2056064458",
                    "name": "R. Burke"
                },
                {
                    "authorId": "1805040",
                    "name": "A. Voida"
                }
            ]
        },
        {
            "paperId": "5ec3a111f63cd6c5edb28fbdc0641b214f45e2c5",
            "title": "Does Delegating Votes Protect Against Pandering Candidates?",
            "abstract": "The election of representatives in regular election cycles ostensibly prevents misbehavior by elected officials and keeps them accountable in service of the \u201cwill of the people.\" This democratic ideal can be undermined if candidates campaign dishonestly when seeking office over one or more election cycles or \u2018rounds\u2019. We introduce a novel formal model of pandering , or strategic preference reporting by electoral candidates, and examine the resilience of two democratic voting systems to such pandering. The two voting systems we compare are Representative Democracy (RD) and Flexible Representative Democracy (FRD). For each voting system, our analysis centers on the types of strategies candidates employ and how voters update their views of candidates across rounds based on how the candidates have pandered in the past. We provide theoretical results on the complexity of pandering for a single round, formulate our problem for multiple rounds as a Markov Decision Process, and use reinforcement learning to study the effects of pandering by sets of candidates across a number of rounds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144859796",
                    "name": "Xiaolin Sun"
                },
                {
                    "authorId": "2191521524",
                    "name": "Jacob Masur"
                },
                {
                    "authorId": "48444317",
                    "name": "Ben Abramowitz"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                },
                {
                    "authorId": "2109673975",
                    "name": "Zizhan Zheng"
                }
            ]
        },
        {
            "paperId": "ea0cc64772b86f2db53cb3844c13a5cb70dbb3a3",
            "title": "Social Mechanism Design: A Low-Level Introduction",
            "abstract": "How do we deal with the fact that agents have preferences over both decision outcomes and the rules or procedures used to make decisions? If we create rules for aggregating preferences over rules, it would appear that we run into in\ufb01nite regress with preferences and rules at successively higher \u201clevels.\u201d The starting point of our analysis is the claim that in\ufb01nite regress should not be a problem in practice, as any such preferences will necessarily be bounded in complexity and structured coherently in accordance with some (possibly latent) normative principles. Our core contributions are (1) the identi\ufb01cation of simple, intuitive preference structures at low levels that can be generalized to form the building blocks of preferences at higher levels, and (2) the development of algorithms for maximizing the number of agents with such low-level preferences who will \u201caccept\u201d a decision. We analyze algorithms for acceptance maximization in two di\ufb00erent domains: asymmetric dichotomous choice and constitutional amendment. In both settings we study the worst-case performance of the appropriate algorithms, and reveal circumstances under which universal acceptance is possible. In particular, we show that constitutional amendment procedures proposed recently by [1] can achieve universal acceptance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48444317",
                    "name": "Ben Abramowitz"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                }
            ]
        },
        {
            "paperId": "13fa9dfb9204c34c1c30c14f66f13c62d6833072",
            "title": "Who Reviews The Reviewers? A Multi-Level Jury Problem",
            "abstract": "We consider the problem of determining a binary ground truth using advice from a group of independent reviewers (experts) who express their guess about a ground truth correctly with some independent probability (competence). In this setting, when all reviewers are competent (competence greater than one-half), the Condorcet Jury Theorem tells us that adding more reviewers increases the overall accuracy, and if all competences are known, then there exists an optimal weighting of the reviewers. However, in practical settings, reviewers may be noisy or incompetent, i.e., competence below half, and the number of experts may be small, so the asymptotic Condorcet Jury Theorem is not practically relevant. In such cases we explore appointing one or more chairs (judges) who determine the weight of each reviewer for aggregation, creating multiple levels. However, these chairs may be unable to correctly identify the competence of the reviewers they oversee, and therefore unable to compute the optimal weighting. We give conditions when a set of chairs is able to weight the reviewers optimally, and depending on the competence distribution of the agents, give results about when it is better to have more chairs or more reviewers. Through numerical simulations we show that in some cases it is better to have more chairs, but in many cases it is better to have more reviewers.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "48444317",
                    "name": "Ben Abramowitz"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                }
            ]
        },
        {
            "paperId": "4c697bf40e3dc9b060642d8bf623f68ac85ad7e8",
            "title": "Pandering in a Flexible Representative Democracy",
            "abstract": "In representative democracies, the election of new representatives in regular election cycles is meant to prevent corruption and other misbehavior by elected officials and to keep them accountable in service of the ``will of the people.\"This democratic ideal can be undermined when candidates are dishonest when campaigning for election over these multiple cycles or rounds of voting. Much of the work on COMSOC to date has investigated strategic actions in only a single round. We introduce a novel formal model of \\emph{pandering}, or strategic preference reporting by candidates seeking to be elected, and examine the resilience of two democratic voting systems to pandering within a single round and across multiple rounds. The two voting systems we compare are Representative Democracy (RD) and Flexible Representative Democracy (FRD). For each voting system, our analysis centers on the types of strategies candidates employ and how voters update their views of candidates based on how the candidates have pandered in the past. We provide theoretical results on the complexity of pandering in our setting for a single cycle, formulate our problem for multiple cycles as a Markov Decision Process, and use reinforcement learning to study the effects of pandering by both single candidates and groups of candidates across a number of rounds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144859796",
                    "name": "Xiaolin Sun"
                },
                {
                    "authorId": "2191521524",
                    "name": "Jacob Masur"
                },
                {
                    "authorId": "48444317",
                    "name": "Ben Abramowitz"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                },
                {
                    "authorId": "1723278",
                    "name": "Zizhan Zheng"
                }
            ]
        },
        {
            "paperId": "4de0047da3cc4f267d41f0ea57e0a6596108ac52",
            "title": "Teaching Computer Science Ethics Using Science Fiction",
            "abstract": "This workshop will introduce participants interested in teaching a full-term computer science ethics course to the tools and techniques of using science fiction to teach that course. The workshop will consist of three hourlong parts, each of which will draw heavily on science fiction as a teaching tool: (1) an introduction to and tips for teaching with multiple ethical frameworks including virtue ethics, deontology, communitarianism, and utilitarianism; (2) A deep dive on teaching about personhood and privacy by focusing on what's at stake, using multiple viewpoints; and (3) an overview and interactive workshop on the practical logistics of teaching a full term ethics course including example syllabi and teaching materials. This course will equip participants to make rich use of science fiction in their course and to incorporate multiple ethical perspectives into classroom discussion. Participants will have an opportunity to work on course structure and teaching modules in small groups and will receive example teaching materials.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38946638",
                    "name": "Emanuelle Burton"
                },
                {
                    "authorId": "1715289",
                    "name": "J. Goldsmith"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                },
                {
                    "authorId": "1767119",
                    "name": "Cory Siler"
                },
                {
                    "authorId": "2210803110",
                    "name": "Sara-Jo Swiatek"
                }
            ]
        },
        {
            "paperId": "6852aa260121eca7ffa9090d70573c5ff504b460",
            "title": "Who Pays? Personalization, Bossiness and the Cost of Fairness",
            "abstract": "Fairness-aware recommender systems that have a provider-side fairness concern seek to ensure that protected group(s) of providers have a fair opportunity to promote their items or products. There is a ``cost of fairness'' borne by the consumer side of the interaction when such a solution is implemented. This consumer-side cost raises its own questions of fairness, particularly when personalization is used to control the impact of the fairness constraint. In adopting a personalized approach to the fairness objective, researchers may be opening their systems up to strategic behavior on the part of users. This type of incentive has been studied in the computational social choice literature under the terminology of ``bossiness''. The concern is that a bossy user may be able to shift the cost of fairness to others, improving their own outcomes and worsening those for others. This position paper introduces the concept of bossiness, shows its application in fairness-aware recommendation and discusses strategies for reducing this strategic incentive.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103553571",
                    "name": "Paresha Farastu"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                },
                {
                    "authorId": "2056064458",
                    "name": "R. Burke"
                }
            ]
        },
        {
            "paperId": "6fbffee83168dea70cec1e4d342816f62502baca",
            "title": "Towards Group Learning: Distributed Weighting of Experts",
            "abstract": "Aggregating signals from a collection of noisy sources is a fundamental problem in many domains including crowd-sourcing, multi-agent planning, sensor networks, signal processing, voting, ensemble learning, and federated learning. The core question is how to aggregate signals from multiple sources (e.g. experts) in order to reveal an underlying ground truth. While a full answer depends on the type of signal, correlation of signals, and desired output, a problem common to all of these applications is that of differentiating sources based on their quality and weighting them accordingly. It is often assumed that this differentiation and aggregation is done by a single, accurate central mechanism or agent (e.g. judge). We complicate this model in two ways. First, we investigate the setting with both a single judge, and one with multiple judges. Second, given this multi-agent interaction of judges, we investigate various constraints on the judges' reporting space. We build on known results for the optimal weighting of experts and prove that an ensemble of sub-optimal mechanisms can perform optimally under certain conditions. We then show empirically that the ensemble approximates the performance of the optimal mechanism under a broader range of conditions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "48444317",
                    "name": "Ben Abramowitz"
                },
                {
                    "authorId": "143999398",
                    "name": "Nicholas Mattei"
                }
            ]
        }
    ]
}