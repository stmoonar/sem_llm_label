{
    "authorId": "2116458151",
    "papers": [
        {
            "paperId": "12fca89dc57c1162c62f9c24b2a2c8a2d3d2abd3",
            "title": "Towards LifeSpan Cognitive Systems",
            "abstract": "Building a human-like system that continuously interacts with complex environments -- whether simulated digital worlds or human society -- presents several key challenges. Central to this is enabling continuous, high-frequency interactions, where the interactions are termed experiences. We refer to this envisioned system as the LifeSpan Cognitive System (LSCS). A critical feature of LSCS is its ability to engage in incremental and rapid updates while retaining and accurately recalling past experiences. We identify two major challenges in achieving this: (1) Abstraction and Experience Merging, and (2) Long-term Retention with Accurate Recall. These properties are essential for storing new experiences, organizing past experiences, and responding to the environment in ways that leverage relevant historical data. Unlike language models with continual learning, which typically rely on large corpora for fine-tuning and focus on improving performance within specific domains or tasks, LSCS must rapidly and incrementally update with new information from its environment at a high frequency. Existing technologies with the potential of solving the above two major challenges can be classified into four classes based on a conceptual metric called Storage Complexity, which measures the relative space required to store past experiences. Each of these four classes of technologies has its own strengths and limitations. Given that none of the existing technologies can achieve LSCS alone, we propose a novel paradigm for LSCS that integrates all four classes of technologies. The new paradigm operates through two core processes: Absorbing Experiences and Generating Responses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256185766",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2322810821",
                    "name": "Chi Han"
                },
                {
                    "authorId": "2322370156",
                    "name": "Tongtong Wu"
                },
                {
                    "authorId": "2322604263",
                    "name": "Xiaoxin He"
                },
                {
                    "authorId": "2322149547",
                    "name": "Wangchunshu Zhou"
                },
                {
                    "authorId": "68972893",
                    "name": "Nafis Sadeq"
                },
                {
                    "authorId": "2283264499",
                    "name": "Xiusi Chen"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "2322209422",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "2561045",
                    "name": "Gholamreza Haffari"
                },
                {
                    "authorId": "2324098598",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                }
            ]
        },
        {
            "paperId": "130850322b067af6961d49c84b04e8eee0002842",
            "title": "CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory",
            "abstract": "Large Language Models (LLMs) struggle to handle long input sequences due to high memory and runtime costs. Memory-augmented models have emerged as a promising solution to this problem, but current methods are hindered by limited memory capacity and require costly re-training to integrate with a new LLM. In this work, we introduce an associative memory module which can be coupled to any pre-trained (frozen) attention-based LLM without re-training, enabling it to handle arbitrarily long input sequences. Unlike previous methods, our associative memory module consolidates representations of individual tokens into a non-parametric distribution model, dynamically managed by properly balancing the novelty and recency of the incoming data. By retrieving information from this consolidated associative memory, the base LLM can achieve significant (up to 29.7% on Arxiv) perplexity reduction in long-context modeling compared to other baselines evaluated on standard benchmarks. This architecture, which we call CAMELoT (Consolidated Associative Memory Enhanced Long Transformer), demonstrates superior performance even with a tiny context window of 128 tokens, and also enables improved in-context learning with a much larger set of demonstrations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "2142741421",
                    "name": "Leonid Karlinsky"
                },
                {
                    "authorId": "2266361991",
                    "name": "Donghyun Kim"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                },
                {
                    "authorId": "2284865239",
                    "name": "Dmitry Krotov"
                },
                {
                    "authorId": "2239199018",
                    "name": "Rog\u00e9rio Feris"
                }
            ]
        },
        {
            "paperId": "3abd61d29c47949b2445b9eed08512500ebb6380",
            "title": "Cognitive Bias in Decision-Making with LLMs",
            "abstract": "Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. Given their training on human (created) data, LLMs have been shown to inherit societal biases against protected groups, as well as be subject to bias functionally resembling cognitive bias. Human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive science, we develop a dataset containing 13,465 prompts to evaluate LLM decisions on different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, while proposing a novel method utilizing LLMs to debias their own human-like cognitive bias within prompts. Our analysis provides a comprehensive picture of the presence and effects of cognitive bias across commercial and open-source models. We demonstrate that our selfhelp debiasing effectively mitigates model answers that display patterns akin to human cognitive bias without having to manually craft examples for each bias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "80743661",
                    "name": "J. Echterhoff"
                },
                {
                    "authorId": "2261358086",
                    "name": "Yao Liu"
                },
                {
                    "authorId": "2289842171",
                    "name": "Abeer Alessa"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                }
            ]
        },
        {
            "paperId": "8f6061730f9964ebda3bac4f99e5a170df2c38c9",
            "title": "LVCHAT: Facilitating Long Video Comprehension",
            "abstract": "Enabling large language models (LLMs) to read videos is vital for multimodal LLMs. Existing works show promise on short videos whereas long video (longer than e.g.~1 minute) comprehension remains challenging. The major problem lies in the over-compression of videos, i.e., the encoded video representations are not enough to represent the whole video. To address this issue, we propose Long Video Chat (LVChat), where Frame-Scalable Encoding (FSE) is introduced to dynamically adjust the number of embeddings in alignment with the duration of the video to ensure long videos are not overly compressed into a few embeddings. To deal with long videos whose length is beyond videos seen during training, we propose Interleaved Frame Encoding (IFE), repeating positional embedding and interleaving multiple groups of videos to enable long video input, avoiding performance degradation due to overly long videos. Experimental results show that LVChat significantly outperforms existing methods by up to 27\\% in accuracy on long-video QA datasets and long-video captioning benchmarks. Our code is published at https://github.com/wangyu-ustc/LVChat.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256185766",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2284843576",
                    "name": "Zeyuan Zhang"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                }
            ]
        },
        {
            "paperId": "9b614735fdf3730304c54fcac91bb15850945e24",
            "title": "InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization",
            "abstract": "Ranking items regarding individual user interests is a core technique of multiple downstream tasks such as recommender systems. Learning such a personalized ranker typically relies on the implicit feedback from users' past click-through behaviors. However, collected feedback is biased toward previously highly-ranked items and directly learning from it would result in \"rich-get-richer\" phenomena. In this paper, we propose a simple yet sufficient unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously address both position and popularity biases. We begin by consolidating the impacts of those biases into a single observation factor, thereby providing a unified approach to addressing bias-related issues. Subsequently, we minimize the mutual information between the observation estimation and the relevance estimation conditioned on the input features. By doing so, our relevance estimation can be proved to be free of bias. To implement InfoRank, we first incorporate an attention mechanism to capture latent correlations within user-item features, thereby generating estimations of observation and relevance. We then introduce a regularization term, grounded in conditional mutual information, to promote conditional independence between relevance estimation and observation estimation. Experimental evaluations conducted across three extensive recommendation and search datasets reveal that InfoRank learns more precise and unbiased ranking strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16278568",
                    "name": "Jiarui Jin"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "145788064",
                    "name": "Mengyue Yang"
                },
                {
                    "authorId": "2244690305",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2119021541",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2256981980",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                }
            ]
        },
        {
            "paperId": "b1c0a7a595c1c2cca63eaf9aab80ef3bc75dc786",
            "title": "Large Scale Knowledge Washing",
            "abstract": "Large language models show impressive abilities in memorizing world knowledge, which leads to concerns regarding memorization of private information, toxic or sensitive knowledge, and copyrighted content. We introduce the problem of Large Scale Knowledge Washing, focusing on unlearning an extensive amount of factual knowledge. Previous unlearning methods usually define the reverse loss and update the model via backpropagation, which may affect the model's fluency and reasoning ability or even destroy the model due to extensive training with the reverse loss. Existing works introduce additional data from downstream tasks to prevent the model from losing capabilities, which requires downstream task awareness. Controlling the tradeoff of unlearning and maintaining existing capabilities is also challenging. To this end, we propose LAW (Large Scale Washing) to update the MLP layers in decoder-only large language models to perform knowledge washing, as inspired by model editing methods and based on the hypothesis that knowledge and reasoning are disentanglable. We derive a new objective with the knowledge to be unlearned to update the weights of certain MLP layers. Experimental results demonstrate the effectiveness of LAW in forgetting target knowledge while maintaining reasoning ability. The code will be open-sourced at https://github.com/wangyu-ustc/LargeScaleWashing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256185766",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2303432425",
                    "name": "Ruihan Wu"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "2283264499",
                    "name": "Xiusi Chen"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                }
            ]
        },
        {
            "paperId": "0208b95cc3b677113c14335b899effe0fcad90a9",
            "title": "Deciphering Compatibility Relationships with Textual Descriptions via Extraction and Explanation",
            "abstract": "Understanding and accurately explaining compatibility relationships between fashion items is a challenging problem in the burgeoning domain of AI-driven outfit recommendations. Present models, while making strides in this area, still occasionally fall short, offering explanations that can be elementary and repetitive. This work aims to address these shortcomings by introducing the Pair Fashion Explanation (PFE) dataset, a unique resource that has been curated to illuminate these compatibility relationships. Furthermore, we propose an innovative two stage pipeline model that leverages this dataset. This fine-tuning allows the model to generate explanations that convey the compatibility relationships between items. Our experiments showcase the model's potential in crafting descriptions that are knowledgeable, aligned with ground-truth matching correlations, and that produce understandable and informative descriptions, as assessed by both automatic metrics and human evaluation. Our code and data are released at https://github.com/wangyu-ustc/PairFashionExplanation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256185766",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "51002202",
                    "name": "Zhankui He"
                },
                {
                    "authorId": "2275246595",
                    "name": "Hao Xu"
                },
                {
                    "authorId": "2258962117",
                    "name": "Julian McAuley"
                }
            ]
        },
        {
            "paperId": "39abce3268f309d5655247de0c442a28219df390",
            "title": "MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation",
            "abstract": "Curated datasets for healthcare are often limited due to the need of human annotations from experts. In this paper, we present MedEval, a multi-level, multi-task, and multi-domain medical benchmark to facilitate the development of language models for healthcare. MedEval is comprehensive and consists of data from several healthcare systems and spans 35 human body regions from 8 examination modalities. With 22,779 collected sentences and 21,228 reports, we provide expert annotations at multiple levels, offering a granular potential usage of the data and supporting a wide range of tasks. Moreover, we systematically evaluated 10 generic and domain-specific language models under zero-shot and finetuning settings, from domain-adapted baselines in healthcare to general-purposed state-of-the-art large language models (e.g., ChatGPT). Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction tuning for few-shot usage of large language models. Our investigation paves the way toward benchmarking language models for healthcare and provides valuable insights into the strengths and limitations of adopting large language models in medical domains, informing their practical applications and future advancements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "2256185766",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2254201486",
                    "name": "An Yan"
                },
                {
                    "authorId": "2261358086",
                    "name": "Yao Liu"
                },
                {
                    "authorId": "2261287163",
                    "name": "Eric Y. Chang"
                },
                {
                    "authorId": "2250624868",
                    "name": "Amilcare Gentili"
                },
                {
                    "authorId": "2254271546",
                    "name": "Julian J. McAuley"
                },
                {
                    "authorId": "2257436141",
                    "name": "Chun-Nan Hsu"
                }
            ]
        },
        {
            "paperId": "71b99a53892409720dc8867afffe64bf3632af6b",
            "title": "Learning Concise and Descriptive Attributes for Visual Recognition",
            "abstract": "Recent advances in foundation models present new opportunities for interpretable visual recognition \u2013 one can first query Large Language Models (LLMs) to obtain a set of attributes that describe each class, then apply vision-language models to classify images via these attributes. Pioneering work shows that querying thousands of attributes can achieve performance competitive with image features. However, our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words. This surprising finding suggests that significant noise may be present in these attributes. We hypothesize that there exist subsets of attributes that can maintain the classification performance with much smaller sizes, and propose a novel learning-to-search method to discover those concise sets of attributes. As a result, on the CUB dataset, our method achieves performance close to that of massive LLM-generated attributes (e.g., 10k attributes for CUB), yet using only 32 attributes in total to distinguish 200 bird species. Furthermore, our new paradigm demonstrates several additional benefits: higher interpretability and interactivity for humans, and the ability to summarize knowledge for a recognition task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064233490",
                    "name": "Andy Yan"
                },
                {
                    "authorId": "2153604285",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1828787912",
                    "name": "Yiwu Zhong"
                },
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "47006228",
                    "name": "Yujie Lu"
                },
                {
                    "authorId": "2187907974",
                    "name": "William Wang"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "35660011",
                    "name": "Julian McAuley"
                }
            ]
        },
        {
            "paperId": "88c57f3a7267dbf56c477e3a77d620746bd487fe",
            "title": "Farzi Data: Autoregressive Data Distillation",
            "abstract": "We study data distillation for auto-regressive machine learning tasks, where the input and output have a strict left-to-right causal structure. More specifically, we propose Farzi, which summarizes an event sequence dataset into a small number of synthetic sequences -- Farzi Data -- which are optimized to maintain (if not improve) model performance compared to training on the full dataset. Under the hood, Farzi conducts memory-efficient data distillation by (i) deriving efficient reverse-mode differentiation of the Adam optimizer by leveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional discrete event-space into a latent-space which provably promotes implicit regularization. Empirically, for sequential recommendation and language modeling tasks, we are able to achieve 98-120% of downstream full-data performance when training state-of-the-art models on Farzi Data of size as little as 0.1% of the original dataset. Notably, being able to train better models with significantly less data sheds light on the design of future large auto-regressive models, and opens up new opportunities to further scale up model and data sizes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40705044",
                    "name": "Noveen Sachdeva"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "2741053",
                    "name": "Wang-Cheng Kang"
                },
                {
                    "authorId": "2148023",
                    "name": "Jianmo Ni"
                },
                {
                    "authorId": "48573272",
                    "name": "D. Cheng"
                },
                {
                    "authorId": "2254271546",
                    "name": "Julian J. McAuley"
                }
            ]
        }
    ]
}