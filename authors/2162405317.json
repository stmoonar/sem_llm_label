{
    "authorId": "2162405317",
    "papers": [
        {
            "paperId": "8758e094bd55c6810728963f212e07722a50ab74",
            "title": "Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation",
            "abstract": "Session-based recommendation has gained increasing attention in recent years, with its aim to offer tailored suggestions based on users' historical behaviors within sessions. To advance this field, a variety of methods have been developed, with ID-based approaches typically demonstrating promising performance. However, these methods often face challenges with long-tail items and overlook other rich forms of information, notably valuable textual semantic information. To integrate text information, various methods have been introduced, mostly following a naive fusion framework. Surprisingly, we observe that fusing these two modalities does not consistently outperform the best single modality by following the naive fusion framework. Further investigation reveals an potential imbalance issue in naive fusion, where the ID dominates and text modality is undertrained. This suggests that the unexpected observation may stem from naive fusion's failure to effectively balance the two modalities, often over-relying on the stronger ID modality. This insight suggests that naive fusion might not be as effective in combining ID and text as previously expected. To address this, we propose a novel alternative training strategy AlterRec. It separates the training of ID and text, thereby avoiding the imbalance issue seen in naive fusion. Additionally, AlterRec designs a novel strategy to facilitate the interaction between the two modalities, enabling them to mutually learn from each other and integrate the text more effectively. Comprehensive experiments demonstrate the effectiveness of AlterRec in session-based recommendation. The implementation is available at https://github.com/Juanhui28/AlterRec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2257089588",
                    "name": "Zhikai Chen"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2284066656",
                    "name": "Amin Javari"
                },
                {
                    "authorId": "2256937217",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "be9f4354285fc4ef1a9af5868797a25a2fa13cb5",
            "title": "Mixture of Link Predictors",
            "abstract": "Link prediction, which aims to forecast unseen connections in graphs, is a fundamental task in graph machine learning. Heuristic methods, leveraging a range of different pairwise measures such as common neighbors and shortest paths, often rival the performance of vanilla Graph Neural Networks (GNNs). Therefore, recent advancements in GNNs for link prediction (GNN4LP) have primarily focused on integrating one or a few types of pairwise information. In this work, we reveal that different node pairs within the same dataset necessitate varied pairwise information for accurate prediction and models that only apply the same pairwise information uniformly could achieve suboptimal performance. As a result, we propose a simple mixture of experts model Link-MoE for link prediction. Link-MoE utilizes various GNNs as experts and strategically selects the appropriate expert for each node pair based on various types of pairwise information. Experimental results across diverse real-world datasets demonstrate substantial performance improvement from Link-MoE. Notably, Link-MoE achieves a relative improvement of 18.82\\% on the MRR metric for the Pubmed dataset and 10.8\\% on the Hits@100 metric for the ogbl-ppa dataset, compared to the best baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284027842",
                    "name": "Li Ma"
                },
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2220302956",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2261366610",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "11732258",
                    "name": "Xiaofeng Gao"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f5aa366ff70215f06ae6501c322eba2f0934a7c3",
            "title": "Node-wise Filtering in Graph Neural Networks: A Mixture of Experts Approach",
            "abstract": "Graph Neural Networks (GNNs) have proven to be highly effective for node classification tasks across diverse graph structural patterns. Traditionally, GNNs employ a uniform global filter, typically a low-pass filter for homophilic graphs and a high-pass filter for heterophilic graphs. However, real-world graphs often exhibit a complex mix of homophilic and heterophilic patterns, rendering a single global filter approach suboptimal. In this work, we theoretically demonstrate that a global filter optimized for one pattern can adversely affect performance on nodes with differing patterns. To address this, we introduce a novel GNN framework Node-MoE that utilizes a mixture of experts to adaptively select the appropriate filters for different nodes. Extensive experiments demonstrate the effectiveness of Node-MoE on both homophilic and heterophilic graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2049039664",
                    "name": "Haoyu Han"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2267308439",
                    "name": "Wei Huang"
                },
                {
                    "authorId": "2301317582",
                    "name": "Xianfeng Tang"
                },
                {
                    "authorId": "2257363913",
                    "name": "Hanqing Lu"
                },
                {
                    "authorId": "2305051640",
                    "name": "Chen Luo"
                },
                {
                    "authorId": "2253533415",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "3e80c134db377491c12e8cc9a65752444cc5c0d3",
            "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
            "abstract": "Knowledge graph completion (KGC) aims to predict unseen edges in knowledge graphs (KGs), resulting in the discovery of new facts. A new class of methods have been proposed to tackle this problem by aggregating path information. These methods have shown tremendous ability in the task of KGC. However they are plagued by efficiency issues. Though there are a few recent attempts to address this through learnable path pruning, they often sacrifice the performance to gain efficiency. In this work, we identify two intrinsic limitations of these methods that affect the efficiency and representation quality. To address the limitations, we introduce a new method, TAGNet, which is able to efficiently propagate information. This is achieved by only aggregating paths in a fixed window for each source-target pair. We demonstrate that the complexity of TAGNet is independent of the number of layers. Extensive experiments demonstrate that TAGNet can cut down on the number of propagated messages by as much as 90% while achieving competitive performance on multiple KG datasets. The code is available at https://github.com/HarryShomer/TAGNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2259889350",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2166048911",
                    "name": "Charu Aggarwal"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "9be934355f24c0c4f8757e839e352efab96649cb",
            "title": "Revisiting Link Prediction: A Data Perspective",
            "abstract": "Link prediction, a fundamental task on graphs, has proven indispensable in various applications, e.g., friend recommendation, protein analysis, and drug interaction prediction. However, since datasets span a multitude of domains, they could have distinct underlying mechanisms of link formation. Evidence in existing literature underscores the absence of a universally best algorithm suitable for all datasets. In this paper, we endeavor to explore principles of link prediction across diverse datasets from a data-centric perspective. We recognize three fundamental factors critical to link prediction: local structural proximity, global structural proximity, and feature proximity. We then unearth relationships among those factors where (i) global structural proximity only shows effectiveness when local structural proximity is deficient. (ii) The incompatibility can be found between feature and structural proximity. Such incompatibility leads to GNNs for Link Prediction (GNN4LP) consistently underperforming on edges where the feature proximity factor dominates. Inspired by these new insights from a data perspective, we offer practical instruction for GNN4LP model design and guidelines for selecting appropriate benchmark datasets for more comprehensive evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2220302956",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254637024",
                    "name": "Bingheng Li"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2256340293",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "2253409421",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f193329a4ae4167f28e43b6d358b37a3d47ee065",
            "title": "LPFormer: An Adaptive Graph Transformer for Link Prediction",
            "abstract": "Link prediction is a common task on graph-structured data that has seen applications in a variety of domains. Classically, hand-crafted heuristics were used for this task. Heuristic measures are chosen such that they correlate well with the underlying factors related to link formation. In recent years, a new class of methods has emerged that combines the advantages of message-passing neural networks (MPNN) and heuristics methods. These methods perform predictions by using the output of an MPNN in conjunction with a\"pairwise encoding\"that captures the relationship between nodes in the candidate link. They have been shown to achieve strong performance on numerous datasets. However, current pairwise encodings often contain a strong inductive bias, using the same underlying factors to classify all links. This limits the ability of existing methods to learn how to properly classify a variety of different links that may form from different factors. To address this limitation, we propose a new method, LPFormer, which attempts to adaptively learn the pairwise encodings for each link. LPFormer models the link factors via an attention module that learns the pairwise encoding that exists between nodes by modeling multiple factors integral to link prediction. Extensive experiments demonstrate that LPFormer can achieve SOTA performance on numerous datasets while maintaining efficiency. The code is available at The code is available at https://github.com/HarryShomer/LPFormer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220302956",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2259889350",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f442378ead6282024cf5b9046daa10422fe9fc5f",
            "title": "Evaluating Graph Neural Networks for Link Prediction: Current Pitfalls and New Benchmarking",
            "abstract": "Link prediction attempts to predict whether an unseen edge exists based on only a portion of edges of a graph. A flurry of methods have been introduced in recent years that attempt to make use of graph neural networks (GNNs) for this task. Furthermore, new and diverse datasets have also been created to better evaluate the effectiveness of these new models. However, multiple pitfalls currently exist that hinder our ability to properly evaluate these new methods. These pitfalls mainly include: (1) Lower than actual performance on multiple baselines, (2) A lack of a unified data split and evaluation metric on some datasets, and (3) An unrealistic evaluation setting that uses easy negative samples. To overcome these challenges, we first conduct a fair comparison across prominent methods and datasets, utilizing the same dataset and hyperparameter search settings. We then create a more practical evaluation setting based on a Heuristic Related Sampling Technique (HeaRT), which samples hard negative samples via multiple heuristics. The new evaluation setting helps promote new challenges and opportunities in link prediction by aligning the evaluation with real-world situations. Our implementation and data are available at https://github.com/Juanhui28/HeaRT",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2220302956",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2152235983",
                    "name": "Shenglai Zeng"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "145474474",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "f7cbe49ee96dfa3ee18b5dd5413355a75f98e8a7",
            "title": "Adaptive Pairwise Encodings for Link Prediction",
            "abstract": "Link prediction is a common task on graph-structured data that has seen applications in a variety of domains. Classically, hand-crafted heuristics were used for this task. Heuristic measures are chosen such that they correlate well with the underlying factors re-lated to link formation. In recent years, a new class of methods has emerged that combines the advantages of message-passing neural networks (MPNN) and heuristics methods. These methods perform predictions by using the output of an MPNN in conjunction with a \u201cpairwise encoding\" that captures the relationship between nodes in the candidate link. They have been shown to achieve strong performance on numerous datasets. However, current pairwise encodings often contain a strong inductive bias, using the same underlying factors to classify all links. This limits the ability of existing meth-ods to learn how to properly classify a variety of different links that may form from different factors. To address this limitation, we propose a new method, LPFormer , which attempts to adaptively learn the pairwise encodings for each link. LPFormer models the link factors via an attention module that learns the pairwise encoding that exists between nodes by modeling multiple factors integral to link prediction. Extensive experiments demonstrate that LPFormer can achieve SOTA performance on numerous datasets while maintaining efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2259889350",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2283301882",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "2339091449b03d574e9bc460b13a83284c7c474a",
            "title": "Graph Enhanced BERT for Query Understanding",
            "abstract": "Query understanding plays a key role in exploring users' search intents and facilitating users to locate their most desired information. However, it is inherently challenging since it needs to capture semantic information from short and ambiguous queries and often requires massive task-specific labeled data. In recent years, pre-trained language models (PLMs) have advanced various natural language processing tasks because they can extract general semantic information from large-scale corpora. However, directly applying them to query understanding is sub-optimal because existing strategies rarely consider to boost the search performance. On the other hand, search logs contain user clicks between queries and urls that provide rich users' search behavioral information on queries beyond their content. Therefore, in this paper, we aim to fill this gap by exploring search logs. In particular, we propose a novel graph-enhanced pre-training framework, GE-BERT, which leverages both query content and the query graph. The model is trained on a query graph where nodes are queries and two queries are connected if they lead to clicks on the same urls, to capture both semantic information and users' search behavioral information of queries. Extensive experiments on offline and online tasks have demonstrated the effectiveness of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "90026606",
                    "name": "Weizhen Zeng"
                },
                {
                    "authorId": "2111102795",
                    "name": "Suqi Cheng"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2386396",
                    "name": "Shuaiqiang Wang"
                },
                {
                    "authorId": "50559722",
                    "name": "Dawei Yin"
                }
            ]
        },
        {
            "paperId": "67784eedd6f76a5ee26feae28e1578d3a4d3c280",
            "title": "Are Graph Neural Networks Really Helpful for Knowledge Graph Completion?",
            "abstract": "Knowledge graphs (KGs) facilitate a wide variety of applications due to their ability to store relational knowledge applicable to many areas. Despite great efforts invested in creation and maintenance, even the largest KGs are far from complete. Hence, KG completion (KGC) has become one of the most crucial tasks for KG research. Recently, considerable literature in this space has centered around the use of Graph Neural Networks (GNNs) to learn powerful embeddings which leverage topological structures in the KGs. Specifically, dedicated efforts have been made to extend GNNs, which are com-monly designed for simple homogeneous and uni-relational graphs, to the KG context which has diverse and multi-relational connec-tions between entities, by designing more complex aggregation schemes over neighboring nodes (crucial to GNN performance) to appropriately leverage multi-relational information. The success of these methods is naturally attributed to the use of GNNs over simpler multi-layer perceptron (MLP) models, owing to their additional aggregation functionality. In this work, we find that surprisingly, simple MLP models are able to achieve comparable performance to GNNs, suggesting that aggregation may not be as crucial as previ-ously believed. With further exploration, we show careful scoring function and loss function design has a much stronger influence on KGC model performance, and aggregation is not practically required. This suggests a conflation of scoring function design, loss function design, and aggregation in prior",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "50813549",
                    "name": "Jiayu Ding"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "145474474",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2136400100",
                    "name": "Dawei Yin"
                }
            ]
        }
    ]
}