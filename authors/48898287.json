{
    "authorId": "48898287",
    "papers": [
        {
            "paperId": "20a60259fb3001ccb94ec1a1825a46f38ba8daf8",
            "title": "Moral Values Underpinning COVID-19 Online Communication Patterns",
            "abstract": "The COVID-19 pandemic has triggered profound societal changes, extending beyond its health impacts to the moralization of behaviors. Leveraging insights from moral psychology, this study delves into the moral fabric shaping online discussions surrounding COVID-19 over a span of nearly two years. Our investigation identifies four distinct user groups characterized by differences in morality, political ideology, and communication styles. We underscore the intricate relationship between moral differences and political ideologies, revealing a nuanced picture where moral orientations do not rigidly separate users politically. Furthermore, we uncover patterns of moral homophily within the social network, highlighting the existence of one potential moral echo chamber. Analyzing the moral themes embedded in messages, we observe that messages featuring moral foundations not typically favored by their authors, as well as those incorporating multiple moral foundations, resonate more effectively with out-group members. This research contributes valuable insights into the complex interplay between moral foundations, communication dynamics, and network structures on Twitter.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "102319456",
                    "name": "Julie Jiang"
                },
                {
                    "authorId": "3349623",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "2e80284e11e2c590e3612748ac76cba9aaa6b758",
            "title": "Tracking the 2024 US Presidential Election Chatter on Tiktok: A Public Multimodal Dataset",
            "abstract": "This paper documents our release of a large-scale data collection of TikTok posts related to the upcoming 2024 U.S. Presidential Election. Our current data comprises 1.8 million videos published between November 1, 2023, and May 26, 2024. Its exploratory analysis identifies the most common keywords, hashtags, and bigrams in both Spanish and English posts, focusing on the election and the two main Presidential candidates, President Joe Biden and Donald Trump. We utilized the TikTok Research API, incorporating various election-related keywords and hashtags, to capture the full scope of relevant content. To address the limitations of the TikTok Research API, we also employed third-party scrapers to expand our dataset. The dataset is publicly available at https://github.com/gabbypinto/US2024PresElectionTikToks",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283303108",
                    "name": "Gabriela Pinto"
                },
                {
                    "authorId": "2309178150",
                    "name": "Charles Bickham"
                },
                {
                    "authorId": "2309178440",
                    "name": "Tanishq Salkar"
                },
                {
                    "authorId": "3349623",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "6603d7ea809e90a4b4fa1d24f1004d46ba39d957",
            "title": "The Susceptibility Paradox in Online Social Influence",
            "abstract": "Understanding susceptibility to online influence is crucial for mitigating the spread of misinformation and protecting vulnerable audiences. This paper investigates susceptibility to influence within social networks, focusing on the differential effects of influence-driven versus spontaneous behaviors on user content adoption. Our analysis reveals that influence-driven adoption exhibits high homophily, indicating that individuals prone to influence often connect with similarly susceptible peers, thereby reinforcing peer influence dynamics, whereas spontaneous adoption shows significant but lower homophily. Additionally, we extend the Generalized Friendship Paradox to influence-driven behaviors, demonstrating that users' friends are generally more susceptible to influence than the users themselves, de facto establishing the notion of Susceptibility Paradox in online social influence. This pattern does not hold for spontaneous behaviors, where friends exhibit fewer spontaneous adoptions. We find that susceptibility to influence can be predicted using friends' susceptibility alone, while predicting spontaneous adoption requires additional features, such as user metadata. These findings highlight the complex interplay between user engagement and characteristics in spontaneous content adoption. Our results provide new insights into social influence mechanisms and offer implications for designing more effective moderation strategies to protect vulnerable audiences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3349623",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "2116476275",
                    "name": "Jin Ye"
                },
                {
                    "authorId": "102319456",
                    "name": "Julie Jiang"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "73f55e8877db271dd2881678e386b8b1b329912b",
            "title": "Large Language Models for Wearable Sensor-Based Human Activity Recognition, Health Monitoring, and Behavioral Modeling: A Survey of Early Trends, Datasets, and Challenges",
            "abstract": "The proliferation of wearable technology enables the generation of vast amounts of sensor data, offering significant opportunities for advancements in health monitoring, activity recognition, and personalized medicine. However, the complexity and volume of these data present substantial challenges in data modeling and analysis, which have been addressed with approaches spanning time series modeling to deep learning techniques. The latest frontier in this domain is the adoption of large language models (LLMs), such as GPT-4 and Llama, for data analysis, modeling, understanding, and human behavior monitoring through the lens of wearable sensor data. This survey explores the current trends and challenges in applying LLMs for sensor-based human activity recognition and behavior modeling. We discuss the nature of wearable sensor data, the capabilities and limitations of LLMs in modeling them, and their integration with traditional machine learning techniques. We also identify key challenges, including data quality, computational requirements, interpretability, and privacy concerns. By examining case studies and successful applications, we highlight the potential of LLMs in enhancing the analysis and interpretation of wearable sensor data. Finally, we propose future directions for research, emphasizing the need for improved preprocessing techniques, more efficient and scalable models, and interdisciplinary collaboration. This survey aims to provide a comprehensive overview of the intersection between wearable sensor data and LLMs, offering insights into the current state and future prospects of this emerging field.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "b4cb7c15bac6a5cb338db9b774dd7e059c21beb3",
            "title": "Coordinated Activity Modulates the Behavior and Emotions of Organic Users: A Case Study on Tweets about the Gaza Conflict",
            "abstract": "Social media has become a crucial conduit for the swift dissemination of information during global crises. However, this also paves the way for the manipulation of narratives by malicious actors. This research delves into the interaction dynamics between coordinated (malicious) entities and organic (regular) users on Twitter amidst the Gaza conflict. Through the analysis of approximately 3.5 million tweets from over 1.3 million users, our study uncovers that coordinated users significantly impact the information landscape, successfully disseminating their content across the network: a substantial fraction of their messages is adopted and shared by organic users. Furthermore, the study documents a progressive increase in organic users' engagement with coordinated content, which is paralleled by a discernible shift towards more emotionally polarized expressions in their subsequent communications. These results highlight the critical need for vigilance and a nuanced understanding of information manipulation on social media platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283307907",
                    "name": "Priyanka Dey"
                },
                {
                    "authorId": "3349623",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "ea24454853d1a88f3451d6e9094023c2a4deae1c",
            "title": "FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs",
            "abstract": "Our society is facing rampant misinformation harming public health and trust. To address the societal challenge, we introduce FACT-GPT, a framework leveraging Large Language Models (LLMs) to assist fact-checking. FACT-GPT, trained on a synthetic dataset, identifies social media content that aligns with, contradicts, or is irrelevant to previously debunked claims. Our evaluation shows that our specialized LLMs can match the accuracy of larger models in identifying related claims, closely mirroring human judgment. This research provides a solution for efficient claim matching, demonstrates the potential of LLMs in supporting fact-checkers, and offers valuable resources for further research in the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2306759664",
                    "name": "Eun Cheol Choi"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "16d83e930a4dab2d49f5d276838ddce79df3f787",
            "title": "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models",
            "abstract": "As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "230d1486a8030fcf2b4cdad133642bb2dd226c60",
            "title": "Identifying Informational Sources in News Articles",
            "abstract": "News articles are driven by the informational sources journalists use in reporting. Modeling when, how and why sources get used together in stories can help us better understand the information we consume and even help journalists with the task of producing it. In this work, we take steps toward this goal by constructing the largest and widest-ranging annotated dataset, to date, of informational sources used in news writing. We show that our dataset can be used to train high-performing models for information detection and source attribution. We further introduce a novel task, source prediction, to study the compositionality of sources in news articles. We show good performance on this task, which we argue is an important proof for narrative science exploring the internal structure of news articles and aiding in planning-based language generation, and an important step towards a source-recommendation system to aid journalists.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51444076",
                    "name": "Alexander Spangher"
                },
                {
                    "authorId": "3157053",
                    "name": "Nanyun Peng"
                },
                {
                    "authorId": "143823227",
                    "name": "Jonathan May"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "2b51c7d35eca4eceb911cdfb57fcc045d4650f42",
            "title": "Social bot detection in the age of ChatGPT: Challenges and opportunities",
            "abstract": "We present a comprehensive overview of the challenges and opportunities in social bot detection in the context of the rise of sophisticated AI-based chatbots. By examining the state of the art in social bot detection techniques and the more salient real-world application to date, we identify gaps and emerging trends in the field, with a focus on addressing the unique challenges posed by AI-generated conversations and behaviors. We suggest potentially promising opportunities and research directions in social bot detection, including (i) the use of generative agents for synthetic data generation, testing and evaluation; (ii) the need for multimodal and cross-platform detection based on network and behavioral signatures of coordination and influence; (iii) the opportunity to extend bot detection to non-English and low-resource language settings; and, (iv) the room for development of collaborative, federated learning detection models that can help facilitate cooperation between different organizations and platforms while preserving user privacy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        },
        {
            "paperId": "3fe9d1d5bce66d029afea87021c504ac9f609a8c",
            "title": "Controlled Text Generation with Hidden Representation Transformations",
            "abstract": "We propose CHRT (Control Hidden Representation Transformation) - a controlled language generation framework that steers large language models to generate text pertaining to certain attributes (such as toxicity). CHRT gains attribute control by modifying the hidden representation of the base model through learned transformations. We employ a contrastive-learning framework to learn these transformations that can be combined to gain multi-attribute control. The effectiveness of CHRT is experimentally shown by comparing it with seven baselines over three attributes. CHRT outperforms all the baselines in the task of detoxification, positive sentiment steering, and text simplification while minimizing the loss in linguistic qualities. Further, our approach has the lowest inference latency of only 0.01 seconds more than the base model, making it the most suitable for high-performance production environments. We open-source our code and release two novel datasets to further propel controlled language generation research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1830436286",
                    "name": "Vaibhav Kumar"
                },
                {
                    "authorId": "1936239",
                    "name": "H. Koorehdavoudi"
                },
                {
                    "authorId": "1771561",
                    "name": "Masud Moshtaghi"
                },
                {
                    "authorId": "2461655",
                    "name": "Amita Misra"
                },
                {
                    "authorId": "2187857302",
                    "name": "Ankit Chadha"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                }
            ]
        }
    ]
}