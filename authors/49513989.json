{
    "authorId": "49513989",
    "papers": [
        {
            "paperId": "14f593d7e866d68f78fd84a283e2c751bfa2f667",
            "title": "A Case Study on Filtering for End-to-End Speech Translation",
            "abstract": "It is relatively easy to mine a large parallel corpus for any machine learning task, such as speech-to-text or speech-to-speech translation. Although these mined corpora are large in volume, their quality is questionable. This work shows that the simplest filtering technique can trim down these big, noisy datasets to a more manageable, clean dataset. We also show that using this clean dataset can improve the model's performance, as in the case of the multilingual-to-English Speech Translation (ST) model, where, on average, we obtain a 4.65 BLEU score improvement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007788331",
                    "name": "Md Mahfuz Ibn Alam"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "23e3ff6b76d99f78afc7ad3c806bc49172f43ded",
            "title": "A Morphologically-Aware Dictionary-based Data Augmentation Technique for Machine Translation of Under-Represented Languages",
            "abstract": "The availability of parallel texts is crucial to the performance of machine translation models. However, most of the world's languages face the predominant challenge of data scarcity. In this paper, we propose strategies to synthesize parallel data relying on morpho-syntactic information and using bilingual lexicons along with a small amount of seed parallel data. Our methodology adheres to a realistic scenario backed by the small parallel seed data. It is linguistically informed, as it aims to create augmented data that is more likely to be grammatically correct. We analyze how our synthetic data can be combined with raw parallel data and demonstrate a consistent improvement in performance in our experiments on 14 languages (28 English<->X pairs) ranging from well- to very low-resource ones. Our method leads to improvements even when using only five seed sentences and a bilingual lexicon.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007788331",
                    "name": "Md Mahfuz Ibn Alam"
                },
                {
                    "authorId": "2282538486",
                    "name": "Sina Ahmadi"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "5b507bfc0251093b380363301e26106432e2e146",
            "title": "Language and Speech Technology for Central Kurdish Varieties",
            "abstract": "Kurdish, an Indo-European language spoken by over 30 million speakers, is considered a dialect continuum and known for its diversity in language varieties. Previous studies addressing language and speech technology for Kurdish handle it in a monolithic way as a macro-language, resulting in disparities for dialects and varieties for which there are few resources and tools available. In this paper, we take a step towards developing resources for language and speech technology for varieties of Central Kurdish, creating a corpus by transcribing movies and TV series as an alternative to fieldwork. Additionally, we report the performance of machine translation, automatic speech recognition, and language identification as downstream tasks evaluated on Central Kurdish subdialects. Data and models are publicly available under an open license at https://github.com/sinaahmadi/CORDI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282538486",
                    "name": "Sina Ahmadi"
                },
                {
                    "authorId": "1986189481",
                    "name": "Daban Q. Jaff"
                },
                {
                    "authorId": "2007788331",
                    "name": "Md Mahfuz Ibn Alam"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "cd77f734f0c54bccbea1b75c9458cbde121a38dc",
            "title": "CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models",
            "abstract": "Effectively using Natural Language Processing (NLP) tools in under-resourced languages requires a thorough understanding of the language itself, familiarity with the latest models and training methodologies, and technical expertise to deploy these models. This could present a significant obstacle for language community members and linguists to use NLP tools. This paper introduces the CMU Linguistic Annotation Backend, an open-source framework that simplifies model deployment and continuous human-in-the-loop fine-tuning of NLP models. CMULAB enables users to leverage the power of multilingual models to quickly adapt and extend existing tools for speech recognition, OCR, translation, and syntactic analysis to new languages, even with limited training data. We describe various tools and APIs that are currently available and how developers can easily add new models/functionality to the framework. Code is available at https://github.com/neulab/cmulab along with a live demo at https://cmulab.dev",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38599655",
                    "name": "Zaid A. W. Sheikh"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "7391530",
                    "name": "Shruti Rijhwani"
                },
                {
                    "authorId": "2219036626",
                    "name": "Lindia Tjuatja"
                },
                {
                    "authorId": "2294720293",
                    "name": "Robbie Jimerson"
                },
                {
                    "authorId": "2265547593",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "0ca3ea625fdbb3f039b2ab24566fa47a4c2ea304",
            "title": "GMU Systems for the IWSLT 2023 Dialect and Low-resource Speech Translation Tasks",
            "abstract": "This paper describes the GMU Systems for the IWSLT 2023 Dialect and Low-resource Speech Translation Tasks. We submitted systems for five low-resource tasks and the dialectal task. In this work, we explored self-supervised pre-trained speech models and finetuned them on speech translation downstream tasks. We use the Wav2vec 2.0, XLSR-53, and Hubert as self-supervised models. Unlike Hubert, Wav2vec 2.0 and XLSR-53 achieve the best results when we remove the top three layers. Our results show that Wav2vec 2.0 and Hubert perform similarly with their relative best configuration. In addition, we found that Wav2vec 2.0 pre-trained on audio data of the same language as the source language of a speech translation model achieves better results. For the low-resource setting, the best results are achieved using either the Wav2vec 2.0 or Hubert models, while XLSR-53 achieves the best results for the dialectal transfer task. We find that XLSR-53 does not perform well for low-resource tasks. Using Wav2vec 2.0, we report close to 2 BLEU point improvements on the test set for the Tamasheq-French compared to the baseline system at the IWSLT 2022.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "114843061",
                    "name": "J. Mbuya"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "17605c43ca3eb982c99642052ddc21a93d116594",
            "title": "GlobalBench: A Benchmark for Global Progress in Natural Language Processing",
            "abstract": "Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "148310739",
                    "name": "Yueqi Song"
                },
                {
                    "authorId": "2218206121",
                    "name": "Catherine Cui"
                },
                {
                    "authorId": "1452678825",
                    "name": "Simran Khanuja"
                },
                {
                    "authorId": "144118452",
                    "name": "Pengfei Liu"
                },
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "1475670743",
                    "name": "Alissa Ostapenko"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "66986482",
                    "name": "Samuel Cahyawijaya"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "2f5250badaafba833df96849ec8ae8d7a440a0a2",
            "title": "Towards a Universal Python: Translating the Natural Modality of Python into Other Human Languages",
            "abstract": "The Python programming language plays a large role in computer science today, both in industry and education. While the pseudo-code nature of its keywords and built-in functions/modules makes programming easy to learn for English speakers, non-English speakers do not have this advantage. Our goal is to further the democratization of computer science, allowing anyone to code in their native language, anywhere. This paper describes our vision for realizing this goal by automatically translating Python (keywords, error messages, identifiers) into other human languages, leveraging recent developments in machine translation and language technologies in general. As a first step, we introduce a preliminary multi-lingual Python tool that enables a user to code, translate, and execute Python in 5 additional languages, as well as a roadmap for the future development of our automated framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256426614",
                    "name": "Joshua Otten"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "2256426642",
                    "name": "Kevin Moran"
                }
            ]
        },
        {
            "paperId": "43c0f77f116f986b53eb04f5c9b33f10132ded55",
            "title": "User-Centric Evaluation of OCR Systems for Kwak\u2019wala",
            "abstract": "There has been recent interest in improving optical character recognition (OCR) for endangered languages, particularly because a large number of documents and books in these languages are not in machine-readable formats. The performance of OCR systems is typically evaluated using automatic metrics such as character and word error rates. While error rates are useful for the comparison of different models and systems, they do not measure whether and how the transcriptions produced from OCR tools are useful to downstream users. In this paper, we present a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study. With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7391530",
                    "name": "Shruti Rijhwani"
                },
                {
                    "authorId": "102758386",
                    "name": "Daisy Rosenblum"
                },
                {
                    "authorId": "2209989543",
                    "name": "Michayla King"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "4488203f1aa489c6e4ebd48d87b3feb2e211261b",
            "title": "Zambezi Voice: A Multilingual Speech Corpus for Zambian Languages",
            "abstract": "This work introduces Zambezi Voice, an open-source multilingual speech resource for Zambian languages. It contains two collections of datasets: unlabelled audio recordings of radio news and talk shows programs (160 hours) and labelled data (over 80 hours) consisting of read speech recorded from text sourced from publicly available literature books. The dataset is created for speech recognition but can be extended to multilingual speech processing research for both supervised and unsupervised learning approaches. To our knowledge, this is the first multilingual speech dataset created for Zambian languages. We exploit pretraining and cross-lingual transfer learning by finetuning the Wav2Vec2.0 large-scale multilingual pre-trained model to build end-to-end (E2E) speech recognition models for our baseline models. The dataset is released publicly under a Creative Commons BY-NC-ND 4.0 license and can be accessed via https://github.com/unza-speech-lab/zambezi-voice .",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1573690693",
                    "name": "Claytone Sikasote"
                },
                {
                    "authorId": "2219273864",
                    "name": "Kalinda Siaminwe"
                },
                {
                    "authorId": "2219270908",
                    "name": "Stanly Mwape"
                },
                {
                    "authorId": "2219271853",
                    "name": "Bangiwe Zulu"
                },
                {
                    "authorId": "2216787102",
                    "name": "Mofya Phiri"
                },
                {
                    "authorId": "2219273017",
                    "name": "Martin Phiri"
                },
                {
                    "authorId": "9129397",
                    "name": "David Zulu"
                },
                {
                    "authorId": "2029678",
                    "name": "Mayumbo Nyirenda"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "753f76976c3218d4268fa2c9ec4141a144105d2a",
            "title": "Approaches to Corpus Creation for Low-Resource Language Technology: the Case of Southern Kurdish and Laki",
            "abstract": "One of the major challenges that under-represented and endangered language communities face in language technology is the lack or paucity of language data. This is also the case of the Southern varieties of the Kurdish and Laki languages for which very limited resources are available with insubstantial progress in tools. To tackle this, we provide a few approaches that rely on the content of local news websites, a local radio station that broadcasts content in Southern Kurdish and fieldwork for Laki. In this paper, we describe some of the challenges of such under-represented languages, particularly in writing and standardization, and also, in retrieving sources of data and retro-digitizing handwritten content to create a corpus for Southern Kurdish and Laki. In addition, we study the task of language identification in light of the other variants of Kurdish and Zaza-Gorani languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35183492",
                    "name": "Sina Ahmadi"
                },
                {
                    "authorId": "114874509",
                    "name": "Zahra Azin"
                },
                {
                    "authorId": "2099186118",
                    "name": "Sara Belelli"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        }
    ]
}