{
    "authorId": "1709023",
    "papers": [
        {
            "paperId": "871b47aca63b0e7a0e9828f1f55ecf6b1537a6df",
            "title": "Subset Models for Multivariate Time Series Forecast",
            "abstract": "Multivariate time series find extensive applications in conjunction with machine learning methodologies for scenario forecasting across various domains. Nevertheless, certain domains exhibit inherent complexities and diversities, which detrimentally impact the predictive efficacy of global models. This ongoing study introduces a Subset Modeling Framework designed to acknowledge the inherent diversity within a domain\u2019s multivariate space. Comparative assessments between subset models and global models are conducted in terms of performance, revealing compelling findings and suggesting the potential for further exploration and refinement of this novel framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2255436137",
                    "name": "Raphael Saldanha"
                },
                {
                    "authorId": "2283565076",
                    "name": "Victor Ribeiro"
                },
                {
                    "authorId": "2255545324",
                    "name": "Eduardo H. M. Pena"
                },
                {
                    "authorId": "2283563757",
                    "name": "Marcel Pedroso"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "144255847",
                    "name": "P. Valduriez"
                },
                {
                    "authorId": "2255565502",
                    "name": "F\u00e1bio Porto"
                }
            ]
        },
        {
            "paperId": "0385d39a5f32175b9007bd8034d25f9207f87857",
            "title": "Subset Modelling: A Domain Partitioning Strategy for Data-efficient Machine-Learning",
            "abstract": "The success of machine learning (ML) systems depends on data availability, volume, quality, and efficient computing resources. A challenge in this context is to reduce computational costs while maintaining adequate accuracy of the models. This paper presents a framework to address this challenge. The idea is to identify \u201csubdomains\u201d within the input space, train local models that produce better predictions for samples from that specific subdomain, instead of training a single global model on the full dataset. We experimentally evaluate our approach on two real-world datasets. Our results indicate that subset modelling (i) improves the predictive performance compared to a single global model and (ii) allows data-efficient training.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2255558225",
                    "name": "Vitor Ribeiro"
                },
                {
                    "authorId": "2255545324",
                    "name": "Eduardo H. M. Pena"
                },
                {
                    "authorId": "2255436137",
                    "name": "Raphael Saldanha"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "144255847",
                    "name": "P. Valduriez"
                },
                {
                    "authorId": "1410017982",
                    "name": "Falaah Arif Khan"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2255565502",
                    "name": "F\u00e1bio Porto"
                }
            ]
        },
        {
            "paperId": "7486179e3500e6246b1e0e3ab32ecbc3e61f11d7",
            "title": "SoftED: Metrics for Soft Evaluation of Time Series Event Detection",
            "abstract": "Time series event detection methods are evaluated mainly by standard classification metrics that focus solely on detection accuracy. However, inaccuracy in detecting an event can often result from its preceding or delayed effects reflected in neighboring detections. These detections are valuable to trigger necessary actions or help mitigate unwelcome consequences. In this context, current metrics are insufficient and inadequate for the context of event detection. There is a demand for metrics that incorporate both the concept of time and temporal tolerance for neighboring detections. This paper introduces SoftED metrics, a new set of metrics designed for soft evaluating event detection methods. They enable the evaluation of both detection accuracy and the degree to which their detections represent events. They improved event detection evaluation by associating events and their representative detections, incorporating temporal tolerance in over 36\\% of experiments compared to the usual classification metrics. SoftED metrics were validated by domain specialists that indicated their contribution to detection evaluation and method selection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31683603",
                    "name": "Rebecca Salles"
                },
                {
                    "authorId": "2113233053",
                    "name": "J. Lima"
                },
                {
                    "authorId": "3049239",
                    "name": "R. Coutinho"
                },
                {
                    "authorId": "1685125",
                    "name": "Esther Pacitti"
                },
                {
                    "authorId": "2028901",
                    "name": "F. Masseglia"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": null,
                    "name": "Chao Chen"
                },
                {
                    "authorId": "2142288865",
                    "name": "Jonathan Garibaldi"
                },
                {
                    "authorId": "2145364345",
                    "name": "F\u00e1bio Porto"
                },
                {
                    "authorId": "2176421587",
                    "name": "Eduardo S. Ogasawara"
                }
            ]
        },
        {
            "paperId": "e65d90f63b9683b4fc8d6209d1910884bef91332",
            "title": "Variable size segmentation for efficient representation and querying of non-uniform time series datasets",
            "abstract": "Existing approaches for time series similarity computing are the core of many data analytics tasks. Given the considered data volumes, or simply the need for fast response times, they often rely on shorter representations, usually with information loss. This incurs approximate comparisons where precision is a major issue. We present and experimentally evaluate ASAX, a new approach for segmenting time series before their transformation into symbolic representations. ASAX reduces significantly the information loss incurred by possible splittings at different steps of the representation calculation, particularly for datasets with unbalanced (nonuniform) distributions. We provide theoretical guarantees on the lower bound of similarity measures, and our experiments illustrate that our method outperforms the state of the art, with significant gain in precision for datasets with unbalanced distributions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2164256554",
                    "name": "Lamia Djebour"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "2028901",
                    "name": "F. Masseglia"
                }
            ]
        },
        {
            "paperId": "7a9904e12f3e0f71579d143b8d013861a8a7cf23",
            "title": "Efficient Incremental Computation of Aggregations over Sliding Windows",
            "abstract": "Computing aggregation over sliding windows, i.e., finite subsets of an unbounded stream, is a core operation in streaming analytics. We propose PBA (Parallel Boundary Aggregator), a novel parallel algorithm that groups continuous slices of streaming values into chunks and exploits two buffers, cumulative slice aggregations and left cumulative slice aggregations, to compute sliding window aggregations efficiently. PBA runs in O(1) time, performing at most 3 merging operations per slide while consuming O(n) space for windows with n partial aggregations. Our empirical experiments demonstrate that PBA can improve throughput up to 4X while reducing latency, compared to state-of-the-art algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152737229",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "1699022",
                    "name": "Farouk Toumani"
                }
            ]
        },
        {
            "paperId": "1a37223175138bc1aa53b425ea2fdd0b382405a5",
            "title": "Massively Distributed Time Series Indexing and Querying",
            "abstract": "Indexing is crucial for many data mining tasks that rely on efficient and effective similarity query processing. Consequently, indexing large volumes of time series, along with high performance similarity query processing, have became topics of high interest. For many applications across diverse domains though, the amount of data to be processed might be intractable for a single machine, making existing centralized indexing solutions inefficient. We propose a parallel indexing solution that gracefully scales to billions of time series, and a parallel query processing strategy that, given a batch of queries, efficiently exploits the index. Our experiments, on both synthetic and real world data, illustrate that our index creation algorithm works on four billion time series in less than five hours, while the state of the art centralized algorithms do not scale and have their limit on 1 billion time series, where they need more than five days. Also, our distributed querying algorithm is able to efficiently process millions of queries over collections of billions of time series, thanks to an effective load balancing mechanism.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32212787",
                    "name": "D. Yagoubi"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "2028901",
                    "name": "F. Masseglia"
                },
                {
                    "authorId": "1725167",
                    "name": "Themis Palpanas"
                }
            ]
        },
        {
            "paperId": "17948d63a03b8dbf862f9c34f8c69e50b6f4fbde",
            "title": "Parallel Techniques for Big Data Analytics",
            "abstract": "Nowadays, we are witnessing the production of large volumes of data in many applications domains like social networks, medical monitoring, weather forecasting, biology, agronomy, earth monitoring, etc. Analyzing this data would help us to extract a lot of hidden knowledge about the events happened or to be happened in the future. However, traditional data analytics techniques are not ef\ufb01cient for analyzing such data volumes. A promising solution for improving the performance of data analytics is to take advantage of the computing power of distributed systems and parallel frameworks such as Spark. In this HDR manuscript, I describe my research activities for developing parallel and distributed techniques to deal with two main data analytics problems: 1) similarity search over time series; 2) maximally informative k -itemsets mining. The \ufb01rst problem, i.e. , similarity search over time series , is very important for many applications such as fraud detection in \ufb01nance, earthquake prediction, plant monitoring, etc. In order to improve the performance of similarity queries, index construction is one of the most popular techniques, which has been successfully used in a variety of settings and applications. In our research activities, we took advantage of parallel and distributed frameworks such as Spark, and developed ef\ufb01cient solutions for parallel construction of tree-based and grid-based indexes over large time series datasets. We also developed ef\ufb01cient algorithms for parallel similarity search over distributed time series datasets using indexes. The second problem, i.e. , maximally informative k -itemsets mining ( miki for short), is one of the fundamental building bricks for exploring informative patterns in databases. on our synthetic and real datasets. The results show that DPiSAX is 40-120 times faster than iSAX2+. We observe that the performance gain depends on the dataset size in relation to the number of Spark nodes used in the deployment. Note that the time Spark needs to deploy on 32 nodes is accounted for in our measurements. Thus, given the very short time needed to construct the DPiSAX index on the seismic dataset (420 seconds), the proportion of the time taken by the Spark deployment, when compared to index construction, is higher than for the much larger Random dataset. , an indexing time of less than 2 hours for more than one billion time series, while the state of the art centralized algorithm needs several days). The results also show that the distributed querying algorithm of DPiSAX is able to process millions of similarity queries over collections of billions of time series with very fast execution times ( e.g. , 140s for 10M queries), thanks to our load balancing mechanism. Overall, the experimental results show that by using our parallel technique, the indexing and mining of very large volumes of time series can now be done in very small execution times, which are impossible to achieve using traditional centralized approaches. techniques that renders the miki mining process very fast. These techniques concern the architecture at a global scale, but also the computation of entropy on distributed nodes, at a local scale. The result is a fast and ef\ufb01cient discovery of miki with high itemset size. Such ability to use high itemset size is mandatory when dealing with Big Data and particularly one Terabyte like what we have done in our experiments. Our results show that PHIKS algorithm outperforms other alternatives by several orders of magnitude, and makes the difference between an inoperative and a successful miki extraction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                }
            ]
        },
        {
            "paperId": "5460f57b817ee8e981a551ccd8f7791abfcaa345",
            "title": "Efficient Matrix Profile Computation Using Different Distance Functions",
            "abstract": "Matrix profile has been recently proposed as a promising technique to the problem of all-pairs-similarity search on time series. Efficient algorithms have been proposed for computing it, e.g., STAMP [13], STOMP [15] and SCRIMP++ [10]. All these algorithms use the z-normalized Euclidean distance to measure the distance between subsequences. However, as we observed, for some datasets other Euclidean measurements are more useful for knowledge discovery from time series. In this paper, we propose efficient algorithms for computing matrix profile for a general class of Euclidean distances. We first propose a simple but efficient algorithm called AAMP for computing matrix profile with the \"pure\" (non-normalized) Euclidean distance. Then, we extend our algorithm for the p- norm distance. We also propose an algorithm, called ACAMP, that uses the same principle as AAMP, but for the case of z-normalized Euclidean distance. We implemented our algorithms, and evaluated their performance through experimentation. The experiments show excellent performance results. For example, they show that AAMP is very efficient for com- putting matrix profile for non-normalized Euclidean distances. The results also show that the ACAMP algorithm is significantly faster than SCRIMP++ (the state of the art matrix profile algorithm) for the case of z-normalized Euclidean distance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "11630855",
                    "name": "B. Cloez"
                }
            ]
        },
        {
            "paperId": "839f91a2ff1741d335f2dfaf315ce4b1e34a4bb7",
            "title": "Pipelined Implementation of a Parallel Streaming Method for Time Series Correlation Discovery on Sliding Windows",
            "abstract": "This paper addresses the problem of continuously finding highly correlated pairs of time series over the most recent time window. The solution builds upon the ParCorr parallel method for online correlation discovery and is designed to run continuously on top of the UPM-CEP data streaming engine through efficient streaming operators. The implementation takes advantage of the flexible API of the streaming engine that provides low level primitives for developing custom operators. Thus, each operator is implemented to process incoming tuples on-the-fly and hence emit resulting tuples as early as possible. This guarantees a real pipelined flow of data that allows for outputting early results, as the experimental evaluation shows.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25017334",
                    "name": "B. Kolev"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "1398264223",
                    "name": "R. Jim\u00e9nez-Peris"
                },
                {
                    "authorId": "145282585",
                    "name": "O. Levchenko"
                },
                {
                    "authorId": "2028901",
                    "name": "F. Masseglia"
                },
                {
                    "authorId": "35016176",
                    "name": "M. Pati\u00f1o"
                },
                {
                    "authorId": "144255847",
                    "name": "P. Valduriez"
                }
            ]
        },
        {
            "paperId": "9776d0336353b5ba9e71add13d88e6e45756c645",
            "title": "Parallel Streaming Implementation of Online Time Series Correlation Discovery on Sliding Windows with Regression Capabilities",
            "abstract": "This paper addresses the problem of continuously finding highly correlated pairs of time series over the most recent time window and possibly use the discovered correlations to select features for training a regression model for prediction. The implementation builds upon the ParCorr parallel method for online correlation discovery and is designed to run continuously on top of the UPM-CEP data streaming engine through efficient streaming operators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25017334",
                    "name": "B. Kolev"
                },
                {
                    "authorId": "1709023",
                    "name": "Reza Akbarinia"
                },
                {
                    "authorId": "1398264223",
                    "name": "R. Jim\u00e9nez-Peris"
                },
                {
                    "authorId": "145282585",
                    "name": "O. Levchenko"
                },
                {
                    "authorId": "2028901",
                    "name": "F. Masseglia"
                },
                {
                    "authorId": "35016176",
                    "name": "M. Pati\u00f1o"
                },
                {
                    "authorId": "144255847",
                    "name": "P. Valduriez"
                }
            ]
        }
    ]
}