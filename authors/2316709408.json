{
    "authorId": "2316709408",
    "papers": [
        {
            "paperId": "ab944b8561dc0280180469bdb94f189be1cc2e80",
            "title": "ActionIE: Action Extraction from Scientific Literature with Programming Languages",
            "abstract": "Extraction of experimental procedures from human language in scientific literature and patents into actionable sequences in robotics language holds immense significance in scientific domains. Such an action extraction task is particularly challenging given the intricate details and context-dependent nature of the instructions, especially in fields like chemistry where reproducibility is paramount. In this paper, we introduce A CTION IE, a method that leverages Large Language Models (LLMs) to bridge this divide by converting actions written in natural language into executable Python code. This enables us to capture the entities of interest, and the relationship between each action, given the features of Programming Languages. Utilizing linguistic cues identified by frequent patterns, ActionIE provides an improved mechanism to discern entities of interest. While our method is broadly applicable, we exemplify its power in the domain of chemical literature, wherein we focus on extracting experimental procedures for chemical synthesis. The code generated by our method can be easily transformed into robotics language which is in high demand in scientific fields. Comprehensive experiments demonstrate the superiority of our method. In addition, we propose a graph-based metric to more accurately reflect the precision of extraction. We also develop a dataset to address the scarcity of scientific literature occurred in existing datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2269835943",
                    "name": "Xianrui Zhong"
                },
                {
                    "authorId": "2312034033",
                    "name": "Yufeng Du"
                },
                {
                    "authorId": "2260339714",
                    "name": "Siru Ouyang"
                },
                {
                    "authorId": "2316709408",
                    "name": "Ming Zhong"
                },
                {
                    "authorId": "2316653022",
                    "name": "Tingfeng Luo"
                },
                {
                    "authorId": "2316633143",
                    "name": "Qirong Ho"
                },
                {
                    "authorId": "2316788204",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "ede9e29755a9856b820137869f136a9b5842f43c",
            "title": "Investigating Instruction Tuning Large Language Models on Graphs",
            "abstract": "Inspired by the recent advancements of Large Language Models (LLMs) in NLP tasks, there's growing interest in applying LLMs to graph-related tasks. This study delves into the capabilities of instruction-following LLMs for engaging with real-world graphs, aiming to offer empirical insights into how LLMs can effectively interact with graphs and generalize across graph tasks. We begin by constructing a dataset designed for instruction tuning, which comprises a diverse collection of 79 graph-related tasks from academic and e-commerce domains, featuring 44,240 training instances and 18,960 test samples. Utilizing this benchmark, our initial investigation focuses on identifying the optimal graph representation that serves as a conduit for LLMs to understand complex graph structures. Our findings indicate that JSON format for graph representation consistently outperforms natural language and code formats across various LLMs and graph types. Furthermore, we examine the key factors that influence the generalization abilities of instruction-tuned LLMs by evaluating their performance on both in-domain and out-of-domain graph tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315925352",
                    "name": "Kerui Zhu"
                },
                {
                    "authorId": "2110607118",
                    "name": "Bo-Wei Huang"
                },
                {
                    "authorId": "2057050247",
                    "name": "Bowen Jin"
                },
                {
                    "authorId": "1381900594",
                    "name": "Yizhu Jiao"
                },
                {
                    "authorId": "2316709408",
                    "name": "Ming Zhong"
                },
                {
                    "authorId": "2316048447",
                    "name": "Kevin Chang"
                },
                {
                    "authorId": "2315946279",
                    "name": "Shou-De Lin"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                }
            ]
        }
    ]
}