{
    "authorId": "1941997",
    "papers": [
        {
            "paperId": "8171546395f725ec0fec6c7d16795e29e756da80",
            "title": "PersonalTM: Transformer Memory for Personalized Retrieval",
            "abstract": "The Transformer Memory as a Differentiable Search Index (DSI) has been proposed as a new information retrieval paradigm, which aims to address the limitations of dual-encoder retrieval framework based on the similarity score. The DSI framework outperforms strong baselines by directly generating relevant document identifiers from queries without relying on an explicit index. The memorization power of DSI framework makes it suitable for personalized retrieval tasks. Therefore, we propose a Personal Transformer Memory (PersonalTM) architecture for personalized text retrieval. PersonalTM incorporates user-specific profiles and contextual user click behaviors, and introduces hierarchical loss in the decoding process to align with the hierarchical assignment of document identifier. Additionally, PersonalTM also employs an adapter architecture to improve the scalability for index updates and reduce computation costs, compared to the vanilla DSI. Experiments show that PersonalTM outperforms the DSI baseline, BM25, fine-tuned dual-encoder, and other personalized models in terms of precision at top 1st and 10th positions and Mean Reciprocal Rank (MRR). Specifically, PersonalTM improves p@1 by 58%, 49%, and 12% compared to BM25, Dual-encoder, and DSI, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2133468043",
                    "name": "Ruixue Lian"
                },
                {
                    "authorId": "34892980",
                    "name": "Sixing Lu"
                },
                {
                    "authorId": "2223763892",
                    "name": "Clint Solomon"
                },
                {
                    "authorId": "46402847",
                    "name": "Gustavo Aguilar"
                },
                {
                    "authorId": "1403237771",
                    "name": "Pragaash Ponnusamy"
                },
                {
                    "authorId": "3024833",
                    "name": "Jialong Han"
                },
                {
                    "authorId": "39923907",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "9a557225056919018622312218b7afd006e0ede9",
            "title": "PersonaPKT: Building Personalized Dialogue Agents via Parameter-efficient Knowledge Transfer",
            "abstract": "Personalized dialogue agents (DAs) powered by large pre-trained language models (PLMs) often rely on explicit persona descriptions to maintain personality consistency. However, such descriptions may not always be available or may pose privacy concerns. To tackle this bottleneck, we introduce PersonaPKT, a lightweight transfer learning approach that can build persona-consistent dialogue models without explicit persona descriptions. By representing each persona as a continuous vector, PersonaPKT learns implicit persona-specific features directly from a small number of dialogue samples produced by the same persona, adding less than 0.1% trainable parameters for each persona on top of the PLM backbone. Empirical results demonstrate that PersonaPKT effectively builds personalized DAs with high storage efficiency, outperforming various baselines in terms of persona consistency while maintaining good response generation quality. In addition, it enhances privacy protection by avoiding explicit persona descriptions. Overall, PersonaPKT is an effective solution for creating personalized DAs that respect user privacy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110981743",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2081082195",
                    "name": "Bin Guo"
                },
                {
                    "authorId": "2220601322",
                    "name": "Yoon Jung"
                },
                {
                    "authorId": "2052408469",
                    "name": "Benjamin Yao"
                },
                {
                    "authorId": "49889909",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "8015600",
                    "name": "Xiaohu Liu"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "9c04358ea28c58e1aca1b1a57c578e55a1360d85",
            "title": "Improving Contextual Query Rewrite for Conversational AI Agents through User-preference Feedback Learning",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2271411281",
                    "name": "Zhongkai Sun"
                },
                {
                    "authorId": "2272424966",
                    "name": "Yingxue Zhou"
                },
                {
                    "authorId": "2271812484",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "2273867974",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2220668748",
                    "name": "Yanbin Lu"
                },
                {
                    "authorId": "2270466265",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "2273650193",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "a33d1b24ff14a4e4559eea16387072a81d40b6be",
            "title": "KG-ECO: Knowledge Graph Enhanced Entity Correction For Query Rewriting",
            "abstract": "Query Rewriting (QR) plays a critical role in large-scale dialogue systems for reducing frictions. When there is an entity error, it imposes extra challenges for a dialogue system to produce satisfactory responses. In this work, we propose KG-ECO: Knowledge Graph enhanced Entity COrrection for query rewriting, an entity correction system with corrupt entity span detection and entity retrieval/re-ranking functionalities.To boost the model performance, we incorporate Knowledge Graph (KG) to provide entity structural information (neighboring entities encoded by graph neural networks) and textual information (KG entity descriptions encoded by RoBERTa). Experimental results show that our approach yields a clear performance gain over two baselines: utterance level QR and entity correction without utilizing KG information. The proposed system is particularly effective for few-shot learning cases where target entities are rarely seen in training or there is a KG relation between the target entity and other contextual entities in the query.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115670967",
                    "name": "Jason (Jinglun) Cai"
                },
                {
                    "authorId": "47628976",
                    "name": "Mingda Li"
                },
                {
                    "authorId": "2112347577",
                    "name": "Ziyan Jiang"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "2141144864",
                    "name": "Zheng Chen"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "de52e7151e8c2c402cc35f5edd022e6c8ef967bd",
            "title": "Clicker: Attention-Based Cross-Lingual Commonsense Knowledge Transfer",
            "abstract": "Recent advances in cross-lingual commonsense reasoning (CSR) are facilitated by the development of multilingual pre-trained models (mPTMs). While mPTMs show the potential to encode commonsense knowledge for different languages, transferring commonsense knowledge learned in large-scale English corpus to other languages is challenging. To address this problem, we propose the attention-based Cross-LIngual Commonsense Knowledge transfER (CLICKER) framework, which minimizes the performance gaps between English and non-English languages in commonsense question-answering tasks. CLICKER effectively improves commonsense reasoning for non-English languages by differentiating non-commonsense knowledge from commonsense knowledge. Experimental results on public benchmarks demonstrate that CLICKER achieves remarkable improvements in the cross-lingual CSR task for languages other than English.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125677648",
                    "name": "Ruolin Su"
                },
                {
                    "authorId": "13223746",
                    "name": "Zhongkai Sun"
                },
                {
                    "authorId": "34892980",
                    "name": "Sixing Lu"
                },
                {
                    "authorId": "39923907",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "edd2a0ebb266f7880c23d745aec0e4c6ad366d35",
            "title": "CL-QR: Cross-Lingual Enhanced Query Reformulation for Multi-lingual Conversational AI Agents",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2271411281",
                    "name": "Zhongkai Sun"
                },
                {
                    "authorId": "2272231787",
                    "name": "Zhengyang Zhao"
                },
                {
                    "authorId": "34892980",
                    "name": "Sixing Lu"
                },
                {
                    "authorId": "2270466265",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "2271351956",
                    "name": "Xiaohu Liu"
                },
                {
                    "authorId": "2273867974",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2273650193",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "53871ac59c687d312dfdd89f0dde82f79c5faf76",
            "title": "PAIGE: Personalized Adaptive Interactions Graph Encoder for Query Rewriting in Dialogue Systems",
            "abstract": "Unexpected responses or repeated clarification questions from conversational agents detract from the users\u2019 experience with technology meant to streamline their daily tasks. To reduce these frictions, Query Rewriting ( QR ) techniques replace transcripts of faulty queries with alternatives that lead to responses that satisfy the users\u2019 needs. Despite their successes, existing QR approaches are limited in their ability to fix queries that require considering users\u2019 personal preferences. We improve QR by proposing P ersonalized A daptive I nteractions G raph E ncoder (PAIGE). PAIGE is the first QR architecture that jointly models user\u2019s affinities and query semantics end-to-end. The core idea is to represent previous user-agent interactions and world knowledge in a structured form \u2014 a heterogeneous graph \u2014 and apply message passing to propagate latent representations of users\u2019 affinities to refine utterance embeddings. Using these embeddings, PAIGE can potentially provide different rewrites given the same query for users with different preferences. Our model, trained without any human-annotated data, improves the rewrite retrieval precision of state-of-the-art baselines by 12.5\u201317.5% while having nearly ten times fewer parameters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65987423",
                    "name": "Daniel Bis"
                },
                {
                    "authorId": "2118973203",
                    "name": "Saurabh Gupta"
                },
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "61807003003aac096de4b539834680ebdc1af185",
            "title": "Incremental User Embedding Modeling for Personalized Text Classification",
            "abstract": "Individual user profiles and interaction histories play a significant role in providing customized experiences in real-world applications such as chatbots, social media, retail, and education. Adaptive user representation learning by utilizing user personalized information has be-come increasingly challenging due to ever-growing his-tory data. In this work, we propose an incremental user embedding modeling approach, in which embeddings of user\u2019s recent interaction histories are dynamically integrated into the accumulated history vectors via a trans-former encoder. This modeling paradigm allows us to create generalized user representations in a consecutive manner and also alleviate the challenges of data management. We demonstrate the effectiveness of this approach by applying it to a personalized multi-class classification task based on the Reddit dataset, and achieve 9% and 30% relative improvement on prediction accuracy over a baseline system for two experiment settings through appropriate comment history encoding and task modeling.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2133468043",
                    "name": "Ruixue Lian"
                },
                {
                    "authorId": "2150608874",
                    "name": "Chengyu Huang"
                },
                {
                    "authorId": "3036900",
                    "name": "Y. Tang"
                },
                {
                    "authorId": "2054919308",
                    "name": "Qi Gu"
                },
                {
                    "authorId": "39923907",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "aace27a6753fefa38c6b2294846bf919aebceb1a",
            "title": "Query Expansion and Entity Weighting for Query Reformulation Retrieval in Voice Assistant Systems",
            "abstract": "Voice assistants such as Alexa, Siri, and Google Assistant have become increasingly popular worldwide. However, linguistic variations, variability of speech patterns, ambient acoustic conditions, and other such factors are often correlated with the assistants misinterpreting the user's query. In order to provide better customer experience, retrieval based query reformulation (QR) systems are widely used to reformulate those misinterpreted user queries. Current QR systems typically focus on neural retrieval model training or direct entities retrieval for the reformulating. However, these methods rarely focus on query expansion and entity weighting simultaneously, which may limit the scope and accuracy of the query reformulation retrieval. In this work, we propose a novel Query Expansion and Entity Weighting method (QEEW), which leverages the relationships between entities in the entity catalog (consisting of users' queries, assistant's responses, and corresponding entities), to enhance the query reformulation performance. Experiments on Alexa annotated data demonstrate that QEEW improves all top precision metrics, particularly 6% improvement in top10 precision, compared with baselines not using query expansion and weighting; and more than 5% improvement in top10 precision compared with other baselines using query expansion and weighting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13223746",
                    "name": "Zhongkai Sun"
                },
                {
                    "authorId": "34892980",
                    "name": "Sixing Lu"
                },
                {
                    "authorId": "39923907",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "8015600",
                    "name": "Xiaohu Liu"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "ad6c25a46a083e02dbfcdd4b6341945d517b5e31",
            "title": "A Vocabulary-Free Multilingual Neural Tokenizer for End-to-End Task Learning",
            "abstract": "Subword tokenization is a commonly used input pre-processing step in most recent NLP models. However, it limits the models\u2019 ability to leverage end-to-end task learning. Its frequency-based vocabulary creation compromises tokenization in low-resource languages, leading models to produce suboptimal representations. Additionally, the dependency on a fixed vocabulary limits the subword models\u2019 adaptability across languages and domains. In this work, we propose a vocabulary-free neural tokenizer by distilling segmentation information from heuristic-based subword tokenization. We pre-train our character-based tokenizer by processing unique words from multilingual corpus, thereby extensively increasing word diversity across languages. Unlike the predefined and fixed vocabularies in subword methods, our tokenizer allows end-to-end task learning, resulting in optimal task-specific tokenization. The experimental results show that replacing the subword tokenizer with our neural tokenizer consistently improves performance on multilingual (NLI) and code-switching (sentiment analysis) tasks, with larger gains in low-resource languages. Additionally, our neural tokenizer exhibits a robust performance on downstream tasks when adversarial noise is present (typos and misspelling), further increasing the initial improvements over statistical subword tokenizers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2804902",
                    "name": "Md. Mofijul Islam"
                },
                {
                    "authorId": "46402847",
                    "name": "Gustavo Aguilar"
                },
                {
                    "authorId": "1403237771",
                    "name": "Pragaash Ponnusamy"
                },
                {
                    "authorId": "3085140",
                    "name": "Clint Solomon Mathialagan"
                },
                {
                    "authorId": "39923907",
                    "name": "Chengyuan Ma"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        }
    ]
}