{
    "authorId": "2301214691",
    "papers": [
        {
            "paperId": "98168d4f8681f254c6dc55f9e280e9cd1b03c6b7",
            "title": "Term Importance for Transformer-Based QA Retrieval: A Case Study of StackExchange",
            "abstract": "Question-answering (QA) retrieval is the task of retrieving the most relevant answer to a given question from a collection of answers. Various approaches to QA retrieval have been developed recently. One successful and popular model is Contextualized Late Interaction over BERT (ColBERT), a transformer-based approach that adopts a query-document scoring mechanism that retains the granularity of transformer matching, whilst improving on efficiency. However, one key limitation is that it requires further fine-tuning for new query or collection types. In this work, we explore and propose several non-parametric retrieval augmentation methods based on explicit signals of term importance that improve over ColBERT's baseline performance. In particular, we consider the QA retrieval task in the context of StackExchange question-answering forum, verifying the effectiveness of our methods in this setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301214691",
                    "name": "Bryan Zhi Yang Tan"
                },
                {
                    "authorId": "3309003",
                    "name": "Hady W. Lauw"
                }
            ]
        }
    ]
}