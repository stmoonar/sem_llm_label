{
    "authorId": "2076323150",
    "papers": [
        {
            "paperId": "7deb314109af9394222064863945b54e89a3fea0",
            "title": "On the Necessity of Collapsing for Post-Quantum and Quantum Commitments",
            "abstract": "Collapse binding and collapsing were proposed by Unruh (Eurocrypt \u201916) as post-quantum strength-enings of computational binding and collision resistance, respectively. These notions have been very successful in facilitating the \u201clifting\u201d of classical security proofs to the quantum setting. A basic and natural question remains unanswered, however: are they the weakest notions that suffice for such lifting? In this work we answer this question in the affirmative by giving a classical commit-and-open protocol which is post-quantum secure if and only if the commitment scheme (resp. hash function) used is collapse binding (resp. collapsing). We also generalise the definition of collapse binding to quantum commitment schemes , and prove that the equivalence carries over when the sender in this commit-and-open protocol communicates quantum information. As a consequence, we establish that a variety of \u201cweak\u201d binding notions (sum binding, CDMS binding and unequivocality) are in fact equivalent to collapse binding, both for post-quantum and quantum commitments. Finally, we prove a \u201cwin-win\u201d result, showing that a post-quantum computationally binding commitment scheme that is not collapse binding can be used to build an equivocal commitment scheme (which can, in turn, be used to build one-shot signatures and other useful quantum primitives). This strengthens a result due to Zhandry (Eurocrypt \u201919) showing that the same object yields quantum lightning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "2422756",
                    "name": "N. Spooner"
                }
            ]
        },
        {
            "paperId": "eac877c27e940bfde277b8123e89f6db32cad6e5",
            "title": "Streaming Zero-Knowledge Proofs",
            "abstract": "Streaming interactive proofs (SIPs) enable a space-bounded algorithm with one-pass access to a massive stream of data to verify a computation that requires large space, by communicating with a powerful but untrusted prover. This work initiates the study of zero-knowledge proofs for data streams. We define the notion of zero-knowledge in the streaming setting and construct zero-knowledge SIPs for the two main algorithmic building blocks in the streaming interactive proofs literature: the sumcheck and polynomial evaluation protocols. To the best of our knowledge all known streaming interactive proofs are based on either of these tools, and indeed, this allows us to obtain zero-knowledge SIPs for central streaming problems such as index, point and range queries, median, frequency moments, and inner product. Our protocols are efficient in terms of time and space, as well as communication: the verifier algorithm's space complexity is $\\mathrm{polylog}(n)$ and, after a non-interactive setup that uses a random string of near-linear length, the remaining parameters are $n^{o(1)}$. En route, we develop an algorithmic toolkit for designing zero-knowledge data stream protocols, consisting of an algebraic streaming commitment protocol and a temporal commitment protocol.Our analyses rely on delicate algebraic and information-theoretic arguments and reductions from average-case communication complexity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "1774258",
                    "name": "Tom Gur"
                },
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                }
            ]
        },
        {
            "paperId": "a275154cd9388dfd23c8b6a0c000ca0bfe1e2ff5",
            "title": "On the necessity of collapsing",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "2422756",
                    "name": "N. Spooner"
                }
            ]
        },
        {
            "paperId": "cf28a3b50cef92f21992ed3326617f53988d3343",
            "title": "Quantum Proofs of Proximity",
            "abstract": "We initiate the systematic study of QMA algorithms in the setting of property testing, to which we refer as QMA proofs of proximity (QMAPs). These are quantum query algorithms that receive explicit access to a sublinear-size untrusted proof and are required to accept inputs having a property \u03a0 and reject inputs that are \u03b5-far from \u03a0, while only probing a minuscule portion of their input.We investigate the complexity landscape of this model, showing that QMAPs can be exponentially stronger than both classical proofs of proximity and quantum testers. To this end, we extend the methodology of Blais, Brody, and Matulef (Computational Complexity, 2012) to prove quantum property testing lower bounds via reductions from communication complexity. This also resolves a question raised in 2013 by Montanaro and de Wolf (cf. Theory of Computing, 2016).Our algorithmic results include a purpose an algorithmic framework that enables quantum speedups for testing an expressive class of properties, namely, those that are succinctly decomposable. A consequence of this framework is a QMA algorithm to verify the Parity of an n-bit string with O(n2/3) queries and proof length. We also propose a QMA algorithm for testing graph bipartitneness, a property that lies outside of this family, for which there is a quantum speedup.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "1774258",
                    "name": "Tom Gur"
                },
                {
                    "authorId": "102476123",
                    "name": "Subhayan Roy Moulik"
                },
                {
                    "authorId": "32523323",
                    "name": "J. Thaler"
                }
            ]
        },
        {
            "paperId": "1741d5871a0be930b17a7c51531518ffca2d2f17",
            "title": "A Structural Theorem for Local Algorithms with Applications to Coding, Testing, and Verification",
            "abstract": "We prove a general structural theorem for a wide family of local algorithms, which includes property testers, local decoders, and PCPs of proximity. Namely, we show that the structure of every algorithm that makes $q$ adaptive queries and satisfies a natural robustness condition admits a sample-based algorithm with $n^{1- 1/O(q^2 \\log^2 q)}$ sample complexity, following the definition of Goldreich and Ron (TOCT 2016). We prove that this transformation is nearly optimal. Our theorem also admits a scheme for constructing privacy-preserving local algorithms. Using the unified view that our structural theorem provides, we obtain results regarding various types of local algorithms, including the following. - We strengthen the state-of-the-art lower bound for relaxed locally decodable codes, obtaining an exponential improvement on the dependency in query complexity; this resolves an open problem raised by Gur and Lachish (SICOMP 2021). - We show that any (constant-query) testable property admits a sample-based tester with sublinear sample complexity; this resolves a problem left open in a work of Fischer, Lachish, and Vasudev (FOCS 2015) by extending their main result to adaptive testers. - We prove that the known separation between proofs of proximity and testers is essentially maximal; this resolves a problem left open by Gur and Rothblum (ECCC 2013, Computational Complexity 2018) regarding sublinear-time delegation of computation. Our techniques strongly rely on relaxed sunflower lemmas and the Hajnal-Szemer\\'edi theorem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "2273178504",
                    "name": "Tom Gur"
                },
                {
                    "authorId": "1714254",
                    "name": "Oded Lachish"
                }
            ]
        },
        {
            "paperId": "e5e78738c015405a9ecc2a3aecd45b5c75a96eef",
            "title": "A Structural Theorem for Local Algorithms with Applications to Coding, Testing, and Privacy",
            "abstract": "We prove a general structural theorem for a wide family of local algorithms, which includes property testers, local decoders, and PCPs of proximity. Namely, we show that the structure of every algorithm that makes $q$ adaptive queries and satisfies a natural robustness condition admits a sample-based algorithm with $n^{1- 1/O(q^2 \\log^2 q)}$ sample complexity, following the definition of Goldreich and Ron (TOCT 2016). We prove that this transformation is nearly optimal. Our theorem also admits a scheme for constructing privacy-preserving local algorithms. Using the unified view that our structural theorem provides, we obtain results regarding various types of local algorithms, including the following. \n- We strengthen the state-of-the-art lower bound for relaxed locally decodable codes, obtaining an exponential improvement on the dependency in query complexity; this resolves an open problem raised by Gur and Lachish (SODA 2020). \n- We show that any (constant-query) testable property admits a sample-based tester with sublinear sample complexity; this resolves a problem left open in a work of Fischer, Lachish, and Vasudev (FOCS 2015) by extending their main result to adaptive testers. \n- We prove that the known separation between proofs of proximity and testers is essentially maximal; this resolves a problem left open by Gur and Rothblum (ECCC 2013, Computational Complexity 2018) regarding sublinear-time delegation of computation. \nOur techniques strongly rely on relaxed sunflower lemmas and the Hajnal-Szemeredi theorem.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "1774258",
                    "name": "Tom Gur"
                },
                {
                    "authorId": "1714254",
                    "name": "Oded Lachish"
                }
            ]
        }
    ]
}