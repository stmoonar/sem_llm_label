{
    "authorId": "2027169833",
    "papers": [
        {
            "paperId": "1d493b2d2407222ab20742889b4a0a79ba958a1d",
            "title": "Image Reconstruction Using Variable Exponential Function Regularization for Wide-Field Polarization Modulation Imaging",
            "abstract": "Polarization modulation imaging technology plays an important role in microscopic super-resolution imaging. However, the specimen medium contains retardancy, while charge-coupled devices may provide discrete under-sampling, and the coupled wavefronts consisting of the polarization state of the light and the anisotropic distribution of the specimen can lead to vectorial phase fitting degradation. Considering that the point spread function (PSF) of the main degradation parts can be regarded as an asymmetric generalized Gaussian distribution with uncertain parameters, an adaptive image reconstruction method is proposed based on variable exponential function regularization. The proposed method concentrates on the diversity of the PSF and uses a variable exponent regularization to improve flexibility of the kernel. Moreover, it can balance image edge preservation and provide staircase artifact suppression, which reduces the over- and under-reconstruction of the microscopic images effectively. By optimizing the Split\u2013Bregman algorithm, we create an efficient method that minimizes the iterative loss function under the premise of achieving high estimation accuracy. Compared with other methods, the experimental results reveal better effectiveness and robustness of the proposed method, with improvements of 18% in the peak signal-to-noise ratio, 21% in the structural similarity index measurement, and 337% in the mean structural similarity index measurement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112259345",
                    "name": "Qiong Wu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2112144548",
                    "name": "Mu Li"
                },
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "70159791",
                    "name": "Hanwen Zhao"
                },
                {
                    "authorId": "14988841",
                    "name": "Jichuan Xiong"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2027169833",
                    "name": "Peilin Yu"
                }
            ]
        },
        {
            "paperId": "a3bed1b880728d3685b79591c392ca852751c9b8",
            "title": "Remote sensing image scene classification using deep combinative feature learning",
            "abstract": "Scene classification shows pivotal role in remote sensing image researches. Since challenges of large similarity between classes, high diversity in each class and huge variations in background, spatial resolution, translation, etc., remote sensing image scene classification still urgently need development. In this paper, we propose a novel method named deep combinative feature learning (DCFL) to extract low-level texture and high-level semantic information from different network layers. First, feature encoder VGGNet-16 is fine-tuned for subsequent multi-scale feature extraction. And two shallow convolutional (Conv) layers are selected for convolutional feature summing maps (CFSM), from which we extract uniform LBP with rotation invariance to excavate detailed texture. Deep semantic features from fully-connected (FC) layer concatenated with shallow detailed features constitute deep combinative features, which are thrown into support vector machine (SVM) classifier for final classification. Extensive experiments are carried out and results prove the comparable advantages and effectiveness of the proposed DCFL contrasting with different state-of-art methods.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "48016237",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2027169833",
                    "name": "Peilin Yu"
                },
                {
                    "authorId": "2118549112",
                    "name": "Ting Li"
                },
                {
                    "authorId": "2111498596",
                    "name": "Zhuoyi Chen"
                }
            ]
        }
    ]
}