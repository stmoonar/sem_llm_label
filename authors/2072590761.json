{
    "authorId": "2072590761",
    "papers": [
        {
            "paperId": "0a56515adb8489d4693f489d4a903410525a9632",
            "title": "KGTrust: Evaluating Trustworthiness of SIoT via Knowledge Enhanced Graph Neural Networks",
            "abstract": "Social Internet of Things (SIoT), a promising and emerging paradigm that injects the notion of social networking into smart objects (i.e., things), paving the way for the next generation of Internet of Things. However, due to the risks and uncertainty, a crucial and urgent problem to be settled is establishing reliable relationships within SIoT, that is, trust evaluation. Graph neural networks for trust evaluation typically adopt a straightforward way such as one-hot or node2vec to comprehend node characteristics, which ignores the valuable semantic knowledge attached to nodes. Moreover, the underlying structure of SIoT is usually complex, including both the heterogeneous graph structure and pairwise trust relationships, which renders hard to preserve the properties of SIoT trust during information propagation. To address these aforementioned problems, we propose a novel knowledge-enhanced graph neural network (KGTrust) for better trust evaluation in SIoT. Specifically, we first extract useful knowledge from users\u2019 comment behaviors and external structured triples related to object descriptions, in order to gain a deeper insight into the semantics of users and objects. Furthermore, we introduce a discriminative convolutional layer that utilizes heterogeneous graph structure, node semantics, and augmented trust relationships to learn node embeddings from the perspective of a user as a trustor or a trustee, effectively capturing multi-aspect properties of SIoT trust during information propagation. Finally, a trust prediction layer is developed to estimate the trust relationships between pairwise nodes. Extensive experiments on three public datasets illustrate the superior performance of KGTrust over state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "12073135",
                    "name": "Zhizhi Yu"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2106771001",
                    "name": "Cuiying Huo"
                },
                {
                    "authorId": "2163669096",
                    "name": "Zhiqiang Wang"
                },
                {
                    "authorId": "1500522513",
                    "name": "Xiulong Liu"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "153171583",
                    "name": "Jia Wu"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                }
            ]
        },
        {
            "paperId": "1f92a63cd5d2e1b1dbf335784372d6da9c5e3f46",
            "title": "One-shot Network Pruning at Initialization with Discriminative Image Patches",
            "abstract": "One-shot Network Pruning at Initialization (OPaI) is an effective method to decrease network pruning costs. Recently, there is a growing belief that data is unnecessary in OPaI. However, we obtain an opposite conclusion by ablation experiments in two representative OPaI methods, SNIP and GraSP. Specifically, we find that informative data is crucial to enhancing pruning performance. In this paper, we propose two novel methods, Discriminative One-shot Network Pruning (DOP) and Super Stitching, to prune the network by high-level visual discriminative image patches. Our contributions are as follows. (1) Extensive experiments reveal that OPaI is data-dependent. (2) Super Stitching performs significantly better than the original OPaI method on benchmark ImageNet, especially in a highly compressed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152747397",
                    "name": "Yinan Yang"
                },
                {
                    "authorId": "144602988",
                    "name": "Yi Ji"
                },
                {
                    "authorId": "40349048",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "1718829",
                    "name": "Jien Kato"
                }
            ]
        },
        {
            "paperId": "dad4f99d0175fafec01e6a5d34bfe26aa6ccc38e",
            "title": "NodeTrans: A Graph Transfer Learning Approach for Traffic Prediction",
            "abstract": "\u2014Recently, deep learning methods have made great progress in traf\ufb01c prediction, but their performance depends on a large amount of historical data. In reality, we may face the data scarcity issue. In this case, deep learning models fail to obtain satisfactory performance. Transfer learning is a promising approach to solve the data scarcity issue. However, existing transfer learning approaches in traf\ufb01c prediction are mainly based on regular grid data, which is not suitable for the inherent graph data in the traf\ufb01c network. Moreover, existing graph- based models can only capture shared traf\ufb01c patterns in the road network, and how to learn node-speci\ufb01c patterns is also a challenge. In this paper, we propose a novel transfer learning approach to solve the traf\ufb01c prediction with few data, which can transfer the knowledge learned from a data-rich source domain to a data-scarce target domain. First, a spatial-temporal graph neural network is proposed, which can capture the node-speci\ufb01c spatial-temporal traf\ufb01c patterns of different road networks. Then, to improve the robustness of transfer, we design a pattern-based transfer strategy, where we leverage a clustering-based mechanism to distill common spatial-temporal patterns in the source domain, and use these knowledge to further improve the prediction performance of the target domain. Experiments on real-world datasets verify the effectiveness of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152544049",
                    "name": "Xueyan Yin"
                },
                {
                    "authorId": "46493888",
                    "name": "Fei Li"
                },
                {
                    "authorId": "2115437382",
                    "name": "Yanming Shen"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "1714354",
                    "name": "Baocai Yin"
                }
            ]
        },
        {
            "paperId": "5ca2f64e6446a2c86d8a88193f47a0fd1faaacd9",
            "title": "Federated Unlearning via Class-Discriminative Pruning",
            "abstract": "We explore the problem of selectively forgetting categories from trained CNN classification models in federated learning (FL). Given that the data used for training cannot be accessed globally in FL, our insights probe deep into the internal influence of each channel. Through the visualization of feature maps activated by different channels, we observe that different channels have a varying contribution to different categories in image classification. Inspired by this, we propose a method for scrubbing the model cleanly of information about particular categories. The method does not require retraining from scratch, nor global access to the data used for training. Instead, we introduce the concept of Term Frequency Inverse Document Frequency (TF-IDF) to quantize the class discrimination of channels. Channels with high TF-IDF scores have more discrimination on the target categories and thus need to be pruned to unlearn. The channel pruning is followed by a fine-tuning process to recover the performance of the pruned model. Evaluated on CIFAR10 dataset, our method accelerates the speed of unlearning by 8.9\u00d7 for the ResNet model, and 7.9\u00d7 for the VGG model under no degradation in accuracy, compared to retraining from scratch. For CIFAR100 dataset, the speedups are 9.9\u00d7 and 8.4\u00d7, respectively. We envision this work as a complementary block for FL towards compliance with legal and ethical criteria.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7898042",
                    "name": "Junxiao Wang"
                },
                {
                    "authorId": "2115741842",
                    "name": "Song Guo"
                },
                {
                    "authorId": "2110972563",
                    "name": "Xin Xie"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                }
            ]
        },
        {
            "paperId": "780e976ad308f786dbdc91e91353e6a9b719025c",
            "title": "Soft-mask: Adaptive Substructure Extractions for Graph Neural Networks",
            "abstract": "For learning graph representations, not all detailed structures within a graph are relevant to the given graph tasks. Task-relevant structures can be localized or sparse which are only involved in subgraphs or characterized by the interactions of subgraphs (a hierarchical perspective). A graph neural network should be able to efficiently extract task-relevant structures and be invariant to irrelevant parts, which is challenging for general message passing GNNs. In this work, we propose to learn graph representations from a sequence of subgraphs of the original graph to better capture task-relevant substructures or hierarchical structures and skip noisy parts. To this end, we design soft-mask GNN layer to extract desired subgraphs through the mask mechanism. The soft-mask is defined in a continuous space to maintain the differentiability and characterize the weights of different parts. Compared with existing subgraph or hierarchical representation learning methods and graph pooling operations, the soft-mask GNN layer is not limited by the fixed sample or drop ratio, and therefore is more flexible to extract subgraphs with arbitrary sizes. Extensive experiments on public graph benchmarks show that soft-mask mechanism brings performance improvements. And it also provides interpretability where visualizing the values of masks in each layer allows us to have an insight into the structures learned by the model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150426854",
                    "name": "Mingqi Yang"
                },
                {
                    "authorId": "3178957",
                    "name": "Yanming Shen"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "1714354",
                    "name": "Baocai Yin"
                }
            ]
        },
        {
            "paperId": "c4d6d68a462dcfabb8d450e0e1547096b746c226",
            "title": "Improving Spectral Graph Convolution for Learning Graph-level Representation",
            "abstract": "From the original theoretically well-de\ufb01ned spectral graph convolution to the subsequent spatial bassed message-passing model, spatial locality (in vertex domain) acts as a fundamental principle of most graph neural networks (GNNs). In the spectral graph convolution, the \ufb01lter is approximated by polynomials, where a k -order polynomial covers k -hop neighbors. In the message-passing, various de\ufb01-nitions of neighbors used in aggregations are actually an extensive exploration of the spatial locality information. For learning node representations, the topological distance seems necessary since it characterizes the basic relations between nodes. However, for learning representations of the entire graphs, is it still necessary to hold? In this work, we show that such a principle is not necessary, it hinders most existing GNNs from ef\ufb01ciently encoding graph structures. By removing it, as well as the limitation of polynomial \ufb01lters, the resulting new architecture signi\ufb01cantly boosts performance on learning graph representations. We also study the effects of graph spectrum on signals and interpret various existing improvements as different spectrum smoothing techniques. It serves as a spatial understanding that quantitatively measures the effects of the spectrum to input signals in comparison to the well-known spectral understanding as high/low-pass \ufb01lters. More importantly, it sheds the light on developing powerful graph representation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150426854",
                    "name": "Mingqi Yang"
                },
                {
                    "authorId": "2150924701",
                    "name": "Rui Li"
                },
                {
                    "authorId": "2115437382",
                    "name": "Yanming Shen"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "1714354",
                    "name": "Baocai Yin"
                }
            ]
        },
        {
            "paperId": "5ee63b90f7cc9bebca2ab161cd9e0958763e2c31",
            "title": "An efficient deep learning hashing neural network for mobile visual search",
            "abstract": "Mobile visual search applications are emerging that enable users to sense their surroundings with smart phones. However, because of the particular challenges of mobile visual search, achieving a high recognition bitrate has becomes a consistent target of previous related works. In this paper, we propose a few-parameter, low-latency, and high-accuracy deep hashing approach for constructing binary hash codes for mobile visual search. First, we exploit the architecture of the MobileNet model, which significantly decreases the latency of deep feature extraction by reducing the number of model parameters while maintaining accuracy. Second, we add a hash-like layer into MobileNet to train the model on labeled mobile visual data. Evaluations show that the proposed system can exceed state-of-the-art accuracy performance in terms of the MAP. More importantly, the memory consumption is much less than that of other deep learning models. The proposed method requires only 13 MB of memory for the neural network and achieves a MAP of 97.80% on the mobile location recognition dataset used for testing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "1820419411",
                    "name": "Wu Liu"
                },
                {
                    "authorId": "40353343",
                    "name": "Liang Liu"
                }
            ]
        },
        {
            "paperId": "e591e31b9b6326571951a5193dde1c0f87beba78",
            "title": "Revisiting the Effectiveness of Off-the-shelf Temporal Modeling Approaches for Large-scale Video Classification",
            "abstract": "This paper describes our solution for the video recognition task of ActivityNet Kinetics challenge that ranked the 1st place. Most of existing state-of-the-art video recognition approaches are in favor of an end-to-end pipeline. One exception is the framework of DevNet. The merit of DevNet is that they first use the video data to learn a network (i.e. fine-tuning or training from scratch). Instead of directly using the end-to-end classification scores (e.g. softmax scores), they extract the features from the learned network and then fed them into the off-the-shelf machine learning models to conduct video classification. However, the effectiveness of this line work has long-term been ignored and underestimated. In this submission, we extensively use this strategy. Particularly, we investigate four temporal modeling approaches using the learned features: Multi-group Shifting Attention Network, Temporal Xception Network, Multi-stream sequence Model and Fast-Forward Sequence Model. Experiment results on the challenging Kinetics dataset demonstrate that our proposed temporal modeling approaches can significantly improve existing approaches in the large-scale video recognition tasks. Most remarkably, our best single Multi-group Shifting Attention Network can achieve 77.7% in term of top-1 accuracy and 93.2% in term of top-5 accuracy on the validation set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069792180",
                    "name": "Yunlong Bian"
                },
                {
                    "authorId": "144158271",
                    "name": "Chuang Gan"
                },
                {
                    "authorId": "73260353",
                    "name": "Xiao Liu"
                },
                {
                    "authorId": "2115362955",
                    "name": "Fu Li"
                },
                {
                    "authorId": "46550737",
                    "name": "Xiang Long"
                },
                {
                    "authorId": "1527095795",
                    "name": "Yandong Li"
                },
                {
                    "authorId": "2072590761",
                    "name": "Heng Qi"
                },
                {
                    "authorId": "49178343",
                    "name": "Jie Zhou"
                },
                {
                    "authorId": "2671368",
                    "name": "Shilei Wen"
                },
                {
                    "authorId": "119916460",
                    "name": "Yuanqing Lin"
                }
            ]
        }
    ]
}