{
    "authorId": "2114009138",
    "papers": [
        {
            "paperId": "f28e227ac157fe9e84c09c3e46992ce263547596",
            "title": "An Empirical Study on Numerical Bugs in Deep Learning Programs",
            "abstract": "The task of a deep learning (DL) program is to train a model with high precision and apply it to different scenarios. A DL program often involves massive numerical calculations. Therefore, the robustness and stability of the numerical calculations are dominant in the quality of DL programs. Indeed, numerical bugs are common in DL programs, producing NaN (Not-a-Number) and INF (Infinite). A numerical bug may render the DL models inaccurate, causing the DL applications unusable. In this work, we conduct the first empirical study on numerical bugs in DL programs by analyzing the programs implemented on the top of two popular DL libraries (i.e., TensorFlow and PyTorch). Specifically, We collect a dataset of 400 numerical bugs in DL programs. Then, we classify these numerical bugs into nine categories based on their root causes and summarize two findings. Finally, we provide the implications of our study on detecting numerical bugs in DL programs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117910558",
                    "name": "Gang Wang"
                },
                {
                    "authorId": "2140079210",
                    "name": "Zan Wang"
                },
                {
                    "authorId": "123878903",
                    "name": "Junjie Chen"
                },
                {
                    "authorId": "49794481",
                    "name": "Xiang Chen"
                },
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                }
            ]
        },
        {
            "paperId": "140f168d8f4e5d110416eb23bf53be7ac4d090cd",
            "title": "Elastic Graph Neural Networks",
            "abstract": "While many existing graph neural networks (GNNs) have been proven to perform $\\ell_2$-based graph smoothing that enforces smoothness globally, in this work we aim to further enhance the local smoothness adaptivity of GNNs via $\\ell_1$-based graph smoothing. As a result, we introduce a family of GNNs (Elastic GNNs) based on $\\ell_1$ and $\\ell_2$-based graph smoothing. In particular, we propose a novel and general message passing scheme into GNNs. This message passing algorithm is not only friendly to back-propagation training but also achieves the desired smoothing properties with a theoretical convergence guarantee. Experiments on semi-supervised learning tasks demonstrate that the proposed Elastic GNNs obtain better adaptivity on benchmark datasets and are significantly robust to graph adversarial attacks. The implementation of Elastic GNNs is available at \\url{https://github.com/lxiaorui/ElasticGNN}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390612725",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "2112343701",
                    "name": "W. Jin"
                },
                {
                    "authorId": "47009435",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "1527096073",
                    "name": "Yaxin Li"
                },
                {
                    "authorId": "2145497065",
                    "name": "Hua Liu"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f74dc2153c34bce1254fe043400e06f7c9abc277",
            "title": "Exposing numerical bugs in deep learning via gradient back-propagation",
            "abstract": "Numerical computation is dominant in deep learning (DL) programs. Consequently, numerical bugs are one of the most prominent kinds of defects in DL programs. Numerical bugs can lead to exceptional values such as NaN (Not-a-Number) and INF (Infinite), which can be propagated and eventually cause crashes or invalid outputs. They occur when special inputs cause invalid parameter values at internal mathematical operations such as log(). In this paper, we propose the first dynamic technique, called GRIST, which automatically generates a small input that can expose numerical bugs in DL programs. GRIST piggy-backs on the built-in gradient computation functionalities of DL infrastructures. Our evaluation on 63 real-world DL programs shows that GRIST detects 78 bugs including 56 unknown bugs. By submitting them to the corresponding issue repositories, eight bugs have been confirmed and three bugs have been fixed. Moreover, GRIST can save 8.79X execution time to expose numerical bugs compared to running original programs with its provided inputs. Compared to the state-of-the-art technique DEBAR (which is a static technique), DEBAR produces 12 false positives and misses 31 true bugs (of which 30 bugs can be found by GRIST), while GRIST only misses one known bug in those programs and no false positive. The results demonstrate the effectiveness of GRIST.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "123878903",
                    "name": "Junjie Chen"
                },
                {
                    "authorId": "1771551",
                    "name": "X. Zhang"
                },
                {
                    "authorId": "2106349652",
                    "name": "Lin Tan"
                },
                {
                    "authorId": "2117910558",
                    "name": "Gang Wang"
                },
                {
                    "authorId": "2140079210",
                    "name": "Zan Wang"
                }
            ]
        },
        {
            "paperId": "21eac24a839100981a57d6a31e5c70b8907f01e8",
            "title": "Practical Accuracy Estimation for Efficient Deep Neural Network Testing",
            "abstract": "Deep neural network (DNN) has become increasingly popular and DNN testing is very critical to guarantee the correctness of DNN, i.e., the accuracy of DNN in this work. However, DNN testing suffers from a serious efficiency problem, i.e., it is costly to label each test input to know the DNN accuracy for the testing set, since labeling each test input involves multiple persons (even with domain-specific knowledge) in a manual way and the testing set is large-scale. To relieve this problem, we propose a novel and practical approach, called PACE (which is short for Practical ACcuracy Estimation), which selects a small set of test inputs that can precisely estimate the accuracy of the whole testing set. In this way, the labeling costs can be largely reduced by just labeling this small set of selected test inputs. Besides achieving a precise accuracy estimation, to make PACE more practical it is also required that it is interpretable, deterministic, and as efficient as possible. Therefore, PACE first incorporates clustering to interpretably divide test inputs with different testing capabilities (i.e., testing different functionalities of a DNN model) into different groups. Then, PACE utilizes the MMD-critic algorithm, a state-of-the-art example-based explanation algorithm, to select prototypes (i.e., the most representative test inputs) from each group, according to the group sizes, which can reduce the impact of noise due to clustering. Meanwhile, PACE also borrows the idea of adaptive random testing to select test inputs from the minority space (i.e., the test inputs that are not clustered into any group) to achieve great diversity under the required number of test inputs. The two parallel selection processes (i.e., selection from both groups and the minority space) compose the final small set of selected test inputs. We conducted an extensive study to evaluate the performance of PACE based on a comprehensive benchmark (i.e., 24 pairs of DNN models and testing sets) by considering different types of models (i.e., classification and regression models, high-accuracy and low-accuracy models, and CNN and RNN models) and different types of test inputs (i.e., original, mutated, and automatically generated test inputs). The results demonstrate that PACE is able to precisely estimate the accuracy of the whole testing set with only 1.181%\u223c2.302% deviations, on average, significantly outperforming the state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123878903",
                    "name": "Junjie Chen"
                },
                {
                    "authorId": "2109569806",
                    "name": "Zhuo Wu"
                },
                {
                    "authorId": "2140079210",
                    "name": "Zan Wang"
                },
                {
                    "authorId": "2065449409",
                    "name": "Hanmo You"
                },
                {
                    "authorId": "2145398332",
                    "name": "Lingming Zhang"
                },
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                }
            ]
        },
        {
            "paperId": "368f36c67c70d484901c3f303aa25312e864d875",
            "title": "Deep learning library testing via effective model generation",
            "abstract": "Deep learning (DL) techniques are rapidly developed and have been widely adopted in practice. However, similar to traditional software systems, DL systems also contain bugs, which could cause serious impacts especially in safety-critical domains. Recently, many research approaches have focused on testing DL models, while little attention has been paid for testing DL libraries, which is the basis of building DL models and directly affects the behavior of DL systems. In this work, we propose a novel approach, LEMON, to testing DL libraries. In particular, we (1) design a series of mutation rules for DL models, with the purpose of exploring different invoking sequences of library code and hard-to-trigger behaviors; and (2) propose a heuristic strategy to guide the model generation process towards the direction of amplifying the inconsistent degrees of the inconsistencies between different DL libraries caused by bugs, so as to mitigate the impact of potential noise introduced by uncertain factors in DL libraries. We conducted an empirical study to evaluate the effectiveness of LEMON with 20 release versions of 4 widely-used DL libraries, i.e., TensorFlow, Theano, CNTK, MXNet. The results demonstrate that LEMON detected 24 new bugs in the latest release versions of these libraries, where 7 bugs have been confirmed and one bug has been fixed by developers. Besides, the results confirm that the heuristic strategy for model generation indeed effectively guides LEMON in amplifying the inconsistent degrees for bugs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108270195",
                    "name": "Zan Wang"
                },
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "123878903",
                    "name": "Junjie Chen"
                },
                {
                    "authorId": "2108591343",
                    "name": "Shuang Liu"
                },
                {
                    "authorId": "2007710710",
                    "name": "Dongdi Zhang"
                }
            ]
        },
        {
            "paperId": "3c6fc21459e5fee38818d826d79d8fd0e93c8bb5",
            "title": "Efficient Hyperparameter Optimization in Deep Learning Using a Variable Length Genetic Algorithm",
            "abstract": "Convolutional Neural Networks (CNN) have gained great success in many artificial intelligence tasks. However, finding a good set of hyperparameters for a CNN remains a challenging task. It usually takes an expert with deep knowledge, and trials and errors. Genetic algorithms have been used in hyperparameter optimizations. However, traditional genetic algorithms with fixed-length chromosomes may not be a good fit for optimizing deep learning hyperparameters, because deep learning models have variable number of hyperparameters depending on the model depth. As the depth increases, the number of hyperparameters grows exponentially, and searching becomes exponentially harder. It is important to have an efficient algorithm that can find a good model in reasonable time. In this article, we propose to use a variable length genetic algorithm (GA) to systematically and automatically tune the hyperparameters of a CNN to improve its performance. Experimental results show that our algorithm can find good CNN hyperparameters efficiently. It is clear from our experiments that if more time is spent on optimizing the hyperparameters, better results could be achieved. Theoretically, if we had unlimited time and CPU power, we could find the optimized hyperparameters and achieve the best results in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25702956",
                    "name": "Xueli Xiao"
                },
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "30401604",
                    "name": "S. Basodi"
                },
                {
                    "authorId": "48146035",
                    "name": "Chunyan Ji"
                },
                {
                    "authorId": "47304193",
                    "name": "Yi Pan"
                }
            ]
        },
        {
            "paperId": "afb4462ea118b0f4062b4d8bd58d5b5d6bdca4bd",
            "title": "Deep Neural Network Test Coverage: How Far Are We?",
            "abstract": "DNN testing is one of the most effective methods to guarantee the quality of DNN. In DNN testing, many test coverage metrics have been proposed to measure test effectiveness, including structural coverage and non-structural coverage (which are classified according to whether considering which structural elements are covered during testing). Those test coverage metrics are proposed based on the assumption: they are correlated with test effectiveness (i.e., the generation of adversarial test inputs or the error-revealing capability of test inputs in DNN testing studies). However, it is still unknown whether the assumption is tenable. In this work, we conducted the first extensive study to systematically validate the assumption by controlling for the size of test sets. In the study, we studied seven typical test coverage metrics based on 9 pairs of datasets and models with great diversity (including four pairs that have never been used to evaluate these test coverage metrics before). The results demonstrate that the assumption fails for structural coverage in general but holds for non-structural coverage on more than half of subjects, indicating that measuring the difference of DNN behaviors between test inputs and training data is more promising than measuring which structural elements are covered by test inputs for measuring test effectiveness. Even so, the current non-structural coverage metrics still can be improved from several aspects such as unfriendly parameters and unstable performance. That indicates that although a lot of test coverage metrics have been proposed before, there is still a lot of room for improvement of measuring test effectiveness in DNN testing, and our study has pointed out some promising directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123878420",
                    "name": "Junjie Chen"
                },
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "2140079210",
                    "name": "Zan Wang"
                },
                {
                    "authorId": "2110042508",
                    "name": "Y. Kang"
                },
                {
                    "authorId": "2109569806",
                    "name": "Zhuo Wu"
                }
            ]
        },
        {
            "paperId": "da278f764ebd2075f363f3f596e8fa5b67c3a5f8",
            "title": "Deep Neural Networks with Short Circuits for Improved Gradient Learning",
            "abstract": "Deep neural networks have achieved great success both in computer vision and natural language processing tasks. However, mostly state-of-art methods highly rely on external training or computing to improve the performance. To alleviate the external reliance, we proposed a gradient enhancement approach, conducted by the short circuit neural connections, to improve the gradient learning of deep neural networks. The proposed short circuit is a unidirectional connection that single back propagates the sensitive from the deep layer to the shallows. Moreover, the short circuit formulates to be a gradient truncation of its crossing layers which can plug into the backbone deep neural networks without introducing external training parameters. Extensive experiments demonstrate deep neural networks with our short circuit gain a large margin over the baselines on both computer vision and natural language processing tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "25702956",
                    "name": "Xueli Xiao"
                },
                {
                    "authorId": "10638646",
                    "name": "Joey Tianyi Zhou"
                },
                {
                    "authorId": "47304193",
                    "name": "Yi Pan"
                }
            ]
        },
        {
            "paperId": "e4734760f633a102a5921ba0fbef4aa2bb314b31",
            "title": "Revisiting deep neural network test coverage from the test effectiveness perspective",
            "abstract": "Many test coverage metrics have been proposed to measure the deep neural network (DNN) testing effectiveness, including structural coverage and nonstructural coverage. These test coverage metrics are proposed based on the fundamental assumption: They are correlated with test effectiveness. However, the fundamental assumption is still not validated sufficiently and reasonably, which brings question on the usefulness of DNN test coverage. This paper conducted a revisiting study on the existing DNN test coverage from the test effectiveness perspective, to effectively validate the fundamental assumption. Here, we carefully considered the diversity of subjects, three test effectiveness criteria, and both typical and state\u2010of\u2010the\u2010art test coverage metrics. Different from all the existing studies that deliver negative conclusions on the usefulness of existing DNN test coverage, we identified some positive conclusions on their usefulness from the test effectiveness perspective. In particular, we found the complementary relationship between structural and nonstructural coverage and identified the practical usage scenarios and promising research directions for these existing test coverage metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "123878903",
                    "name": "Junjie Chen"
                },
                {
                    "authorId": "1996206078",
                    "name": "Xuejie Cao"
                },
                {
                    "authorId": "2109569806",
                    "name": "Zhuo Wu"
                },
                {
                    "authorId": "2110042508",
                    "name": "Y. Kang"
                },
                {
                    "authorId": "2140079210",
                    "name": "Zan Wang"
                }
            ]
        },
        {
            "paperId": "8144abbc09812676666b6032d4c17af4f104be91",
            "title": "Multi-view learning for benign epilepsy with centrotemporal spikes",
            "abstract": "Benign epilepsy with centrotemporal spikes (BECT) may be the most popular epilepsy to attack children. In recent years, more and more studies have shown that magnetic resonance imaging (MRI) and functional magnetic resonance imaging (fMRI) are promising techniques in distinguishing BECT patients from healthy controls. However, these existing works have suffered from two limitations. On the one hand, they have paid more attention to the brain changes between BETC and healthy controls than developing machine learning methods that can recognize BECT patients. On the other hand, most of the existing approaches extract hand-crafted features from MRI or fMRI, which cannot obtain the desired performance due to the limited representative capacity of the used features. To address these issues, we propose a novel classification method by fusing the predictions of three different views: hand-crafted features view, MRI view, and fMRI view. The final result is obtained by passing through those predictions after a fusing neural network. The basic idea of our method is that multiple views could provide complementary information and thus can boost the classification performance. Extensive experiments show that the proposed multi-view method is remarkably superior to single-view methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114009138",
                    "name": "Ming Yan"
                },
                {
                    "authorId": "49480113",
                    "name": "Ling Liu"
                },
                {
                    "authorId": "30401604",
                    "name": "S. Basodi"
                },
                {
                    "authorId": "2115429927",
                    "name": "Yi Pan"
                }
            ]
        }
    ]
}