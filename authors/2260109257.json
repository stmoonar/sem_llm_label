{
    "authorId": "2260109257",
    "papers": [
        {
            "paperId": "0a29c3608817af68588df75a8f04cf4aead89951",
            "title": "KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection",
            "abstract": "SemEval-2024 Task 8 is focused on multigenerator, multidomain, and multilingual black-box machine-generated text detection. Such a detection is important for preventing a potential misuse of large language models (LLMs), the newest of which are very capable in generating multilingual human-like texts. We have coped with this task in multiple ways, utilizing language identification and parameter-efficient fine-tuning of smaller LLMs for text classification. We have further used the per-language classification-threshold calibration to uniquely combine fine-tuned models predictions with statistical detection metrics to improve generalization of the system detection performance. Our submitted method achieved competitive results, ranking at the fourth place, just under 1 percentage point behind the winner.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2267491220",
                    "name": "Michal Spiegel"
                },
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                }
            ]
        },
        {
            "paperId": "62ac45c894b38a9ec6ca089d1bea292281089d04",
            "title": "Authorship Obfuscation in Multilingual Machine-Generated Text Detection",
            "abstract": "High-quality text generation capability of recent Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation). Machine-generated text (MGT) detection is important to cope with such threats. However, it is susceptible to authorship obfuscation (AO) methods, such as paraphrasing, which can cause MGTs to evade detection. So far, this was evaluated only in monolingual settings. Thus, the susceptibility of recently proposed multilingual detectors is still unknown. We fill this gap by comprehensively benchmarking the performance of 10 well-known AO methods, attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10 $\\times$ 37 $\\times$ 11 = 4,070 combinations). We also evaluate the effect of data augmentation on adversarial robustness using obfuscated texts. The results indicate that all tested AO methods can cause evasion of automated detection in all tested languages, where homoglyph attacks are especially successful. However, some of the AO methods severely damaged the text, making it no longer readable or easily recognizable by humans (e.g., changed language, weird characters).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                },
                {
                    "authorId": "144535025",
                    "name": "R\u00f3bert M\u00f3ro"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2129782",
                    "name": "Ivan Srba"
                },
                {
                    "authorId": "2260072705",
                    "name": "Jason Samuel Lucas"
                },
                {
                    "authorId": "66848311",
                    "name": "Michiharu Yamashita"
                },
                {
                    "authorId": "66674465",
                    "name": "Nafis Irtiza Tripto"
                },
                {
                    "authorId": "2279666194",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "3165716",
                    "name": "Jakub Simko"
                },
                {
                    "authorId": "1726847",
                    "name": "M. Bielikov\u00e1"
                }
            ]
        },
        {
            "paperId": "657efb4b79c2c1761d6ca99b961f7bedd66cd955",
            "title": "MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts",
            "abstract": "Recent LLMs are able to generate high-quality multilingual texts, indistinguishable for humans from authentic human-written ones. Research in machine-generated text detection is however mostly focused on the English language and longer texts, such as news articles, scientific papers or student essays. Social-media texts are usually much shorter and often feature informal language, grammatical errors, or distinct linguistic items (e.g., emoticons, hashtags). There is a gap in studying the ability of existing methods in detection of such texts, reflected also in the lack of existing multilingual benchmark datasets. To fill this gap we propose the first multilingual (22 languages) and multi-platform (5 social media platforms) dataset for benchmarking machine-generated text detection in the social-media domain, called MultiSocial. It contains 472,097 texts, of which about 58k are human-written and approximately the same amount is generated by each of 7 multilingual LLMs. We use this benchmark to compare existing detection methods in zero-shot as well as fine-tuned form. Our results indicate that the fine-tuned detectors have no problem to be trained on social-media texts and that the platform selection for training matters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                },
                {
                    "authorId": "2307079780",
                    "name": "Jakub Kopal"
                },
                {
                    "authorId": "144535025",
                    "name": "R\u00f3bert M\u00f3ro"
                },
                {
                    "authorId": "2129782",
                    "name": "Ivan Srba"
                }
            ]
        },
        {
            "paperId": "055f297674edaca790b485b0d94495bcf44503df",
            "title": "IMGTB: A Framework for Machine-Generated Text Detection Benchmarking",
            "abstract": "In the era of large language models generating high quality texts, it is a necessity to develop methods for detection of machine-generated text to avoid harmful use or simply due to annotation purposes. It is, however, also important to properly evaluate and compare such developed methods. Recently, a few benchmarks have been proposed for this purpose; however, integration of newest detection methods is rather challenging, since new methods appear each month and provide slightly different evaluation pipelines. In this paper, we present the IMGTB framework, which simplifies the benchmarking of machine-generated text detection methods by easy integration of custom (new) methods and evaluation datasets. Its configurability and flexibility makes research and development of new detection methods easier, especially their comparison to the existing state-of-the-art detectors. The default set of analyses, metrics and visualizations offered by the tool follows the established practices of machine-generated text detection benchmarking found in state-of-the-art literature.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2267491220",
                    "name": "Michal Spiegel"
                },
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                }
            ]
        },
        {
            "paperId": "12868220782ded0a5eeb31b78ce527dce2d37332",
            "title": "Disinformation Capabilities of Large Language Models",
            "abstract": "Automated disinformation generation is often listed as an important risk associated with large language models (LLMs). The theoretical ability to flood the information space with disinformation content might have dramatic consequences for societies around the world. This paper presents a comprehensive study of the disinformation capabilities of the current generation of LLMs to generate false news articles in the English language. In our study, we evaluated the capabilities of 10 LLMs using 20 disinformation narratives. We evaluated several aspects of the LLMs: how good they are at generating news articles, how strongly they tend to agree or disagree with the disinformation narratives, how often they generate safety warnings, etc. We also evaluated the abilities of detection models to detect these articles as LLM-generated. We conclude that LLMs are able to generate convincing news articles that agree with dangerous disinformation narratives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2217274494",
                    "name": "Ivan Vykopal"
                },
                {
                    "authorId": "2217264741",
                    "name": "Mat'uvs Pikuliak"
                },
                {
                    "authorId": "2129782",
                    "name": "Ivan Srba"
                },
                {
                    "authorId": "144535025",
                    "name": "R\u00f3bert M\u00f3ro"
                },
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                },
                {
                    "authorId": "1726847",
                    "name": "M. Bielikov\u00e1"
                }
            ]
        },
        {
            "paperId": "311841075acf5a5b38d807c68fa9f55e4aa274bf",
            "title": "A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts",
            "abstract": "In the realm of text manipulation and linguistic transformation, the question of authorship has been a subject of fascination and philosophical inquiry. Much like the Ship of Theseus paradox, which ponders whether a ship remains the same when each of its original planks is replaced, our research delves into an intriguing question: Does a text retain its original authorship when it undergoes numerous paraphrasing iterations? Specifically, since Large Language Models (LLMs) have demonstrated remarkable proficiency in both the generation of original content and the modification of human-authored texts, a pivotal question emerges concerning the determination of authorship in instances where LLMs or similar paraphrasing tools are employed to rephrase the text--i.e., whether authorship should be attributed to the original human author or the AI-powered tool. Therefore, we embark on a philosophical voyage through the seas of language and authorship to unravel this intricate puzzle. Using a computational approach, we discover that the diminishing performance in text classification models, with each successive paraphrasing iteration, is closely associated with the extent of deviation from the original author's style, thus provoking a reconsideration of the current notion of authorship.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66674465",
                    "name": "Nafis Irtiza Tripto"
                },
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                },
                {
                    "authorId": "144535025",
                    "name": "R\u00f3bert M\u00f3ro"
                },
                {
                    "authorId": "2129782",
                    "name": "Ivan Srba"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2260345102",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "ba8a23aceb73e40c1aef784c797f39035e0d9062",
            "title": "Assessing the Impact of a Supervised Classification Filter on Flow-based Hybrid Network Anomaly Detection",
            "abstract": "Constant evolution and the emergence of new cyberattacks require the development of advanced techniques for defense. This paper aims to measure the impact of a supervised filter (classifier) in network anomaly detection. We perform our experiments by employing a hybrid anomaly detection approach in network flow data. For this purpose, we extended a state-of-the-art autoencoder-based anomaly detection method by prepending a binary classifier acting as a prefilter for the anomaly detector. The method was evaluated on the publicly available real-world dataset UGR'16. Our empirical results indicate that the hybrid approach does offer a higher detection rate of known attacks than a standalone anomaly detector while still retaining the ability to detect zero-day attacks. Employing a supervised binary prefilter has increased the AUC metric by over 11%, detecting 30% more attacks while keeping the number of false positives approximately the same.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                },
                {
                    "authorId": "2256996538",
                    "name": "Patrik Goldschmidt"
                },
                {
                    "authorId": "2261404904",
                    "name": "Peter Pistek"
                },
                {
                    "authorId": "2256995026",
                    "name": "Daniela Chud'a"
                }
            ]
        }
    ]
}