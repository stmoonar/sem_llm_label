{
    "authorId": "2118006435",
    "papers": [
        {
            "paperId": "253cd777340e09c9bb6390b0b1e4d4b635d352ec",
            "title": "MEC Network Slicing: Stackelberg-Game-Based Slice Pricing and Resource Allocation With QoS Guarantee",
            "abstract": "In multi-access edge computing (MEC) networks, network slicing enables the MEC network service provider (MEC-NSP) to provide customizable MEC services for user devices (UDs) with diverse QoS (Quality of Service) demands. In MEC network slicing, slice pricing and network resource allocation for slices are two core problems, which have not been jointly considered by existing works. To this end, we propose a two-stage slice pricing scheme to achieve balanced slice pricing and optimal network resource allocation. The goal of our scheme is to reduce the resource costs of the MEC-NSP and ensure its profit while meeting different user QoS requirements. At the first stage, we jointly optimize the computing, cache and communication resource allocation for all the slices by using problem decomposition. Then, we formulate a slice pricing problem based the Stackelberg game, prove the Nash equilibrium existence of the problem, and design an iterative algorithm based on the optimal response function. Extensive simulations are conducted in 4 scenarios, where our scheme is compared with 4 reference schemes. The simulation results demonstrate the superiority of our scheme in all the scenarios. The profit of the MEC-NSP optimized by our scheme is 17.64%-24.39% higher than those by the comparative works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2307485286",
                    "name": "Xuewei Li"
                },
                {
                    "authorId": "2274342023",
                    "name": "Bihua Tang"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "337546b96b1f9f259c4104d83b793374823e03d5",
            "title": "Collaborative Service Placement, Task Scheduling, and Resource Allocation for Task Offloading With Edge-Cloud Cooperation",
            "abstract": "In an edge-cloud cooperative computing network, the task offloading performance can be further improved by the edge-cloud and edge-edge cooperation, in which the tasks can be offloaded from an edge server to the cloud server or another edge server. Such edge-cloud cooperative task offloading can jointly utilize the resources of all the edge servers and the cloud server. This paper proposes a collaborative service placement, task scheduling, computing resource allocation, and transmission rate allocation scheme for a multi-task and multi-service scenario with edge-cloud cooperation. The objective of our optimization problem is to minimize the total task processing delay while guaranteeing long-term task queuing stability. Considering the high complexity of the original optimization problem, we transform the problem into a deterministic problem for each time slot based on the Lyapunov optimization. Then, we design an iterative algorithm to obtain the whole solution to the problem efficiently based on a hybrid method using multiple numerical techniques. Further, considering the inherent difference in the optimization periods of the service placement, resource allocation, and task scheduling sub-problems, we design a multi-timescale algorithm to solve the sub-problems with different optimization periods. The complexity of the proposed algorithms is analyzed, and extensive simulations are conducted by varying multiple crucial parameters. The superiority of our scheme is demonstrated in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2186397028",
                    "name": "Xun Liu"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "103483738",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "02e8d415d73b2de34f9ab8d6768837c194e3e44e",
            "title": "Joint Task Offloading and Resource Allocation for Vehicular Edge Computing Based on V2I and V2V Modes",
            "abstract": "In an internet of vehicle (IoV) scenario, vehicular edge computing (VEC) exploits the computing capabilities of the vehicles and roadside unit (RSU) to enhance the task processing capabilities of the vehicles. Resource management is essential to the performance improvement of the VEC system. In this paper, we propose a joint task offloading and resource allocation scheme to minimize the total task processing delay of all the vehicles through task scheduling, channel allocation, and computing resource allocation for the vehicles and RSU. Different from the existing works, our scheme: 1) considers task diversity by profiling the tasks of the vehicles by multiple attributes including data size, computation amount, delay tolerance, and task type; 2) considers vehicle classification by dividing the vehicles into 4 sets according to whether they have task offloading requirements or provide task processing services; 3) considers task processing flexibility by deciding for each vehicle to process its tasks locally, to offload the tasks to the RSU via V2I (Vehicle to Infrastructure) connections, or to the other vehicles via V2V (Vehicle to Vehicle) connections. An algorithm based on the Generalized Benders Decomposition (GBD) and Reformulation Linearization (RL) methods is designed to optimally solve the optimization problem. A heuristic algorithm is also designed to provide the sub-optimal solution with low computational complexity. We analyze the convergence and complexity of the proposed algorithms and conduct extensive simulations in 6 scenarios. The simulation results demonstrate the superiority of our scheme in comparison with 4 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2146651089",
                    "name": "Jie Liu"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "40646266",
                    "name": "Wei Huang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "0531ee80c08916b3fbd63513744bcdaef6dd2fe9",
            "title": "Joint DNN Partition and Resource Allocation Optimization for Energy-Constrained Hierarchical Edge-Cloud Systems",
            "abstract": "Hierarchical edge-cloud systems collaboratively utilize the resources of both the edge server and central cloud, enabling deep neural network (DNN) partition between the edge and cloud to accelerate the inference. However, the limited energy budgets of both the edge server and central cloud restrict them from providing optimal DNN inference services. Moreover, considering the high dynamics in stochastic environments, the long-term system performance should be optimized under long-term energy constraints. How to improve the long-term DNN inference performance in such energy-constrained hierarchical edge-cloud systems is less studied by existing related works. In this paper, we aim to jointly optimize DNN partition and computing resource allocation to minimize the long-term average end-to-end delay of multiple types of deep learning (DL) tasks while guaranteeing the energy consumption of the edge server and central cloud within their energy budgets. Based on the Lyapunov optimization technique and reinforcement learning, we design a novel deep deterministic policy gradient based DNN partition and resource allocation (DDPRA) algorithm to train policy to decide DNN partition dynamically by observing the environment. Moreover, the DDPRA algorithm is embedded with a heuristic computing resource allocation (HCRA) algorithm, which effectively reduces the complexity of policy training by decoupling and optimizing the computing resource allocation separately. We analyze the complexity of our algorithms and conduct extensive simulations. The numerical results demonstrate the superiority of our algorithm in comparison with 5 other schemes in multiple scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "13383067",
                    "name": "Li Gao"
                },
                {
                    "authorId": "2065508415",
                    "name": "Lei Qiao"
                },
                {
                    "authorId": "103483738",
                    "name": "Yuan\u2019an Liu"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                }
            ]
        },
        {
            "paperId": "1aa98fa3837a8a4c498594f59b0be16c014070ce",
            "title": "Game-Based Task Offloading and Resource Allocation for Vehicular Edge Computing With Edge-Edge Cooperation",
            "abstract": "Vehicular Edge Computing (VEC) enables task offloading from vehicles to the edge servers deployed on Road Side Units (RSUs), thus enhancing the task processing performance of the vehicles. However, in a multi-RSU VEC scenario, the uneven geographical distribution of the vehicles naturally causes the load imbalance among the edge servers and leads to the overload and performance degradation problems of the edge servers in hot areas. To this end, in this paper, we propose a joint task offloading and resource allocation for VEC with edge-edge cooperation, in which the tasks offloaded to a high-load edge server can be further offloaded to the other low-load edge servers. Our objective is to minimize the total task processing delay of all the vehicles while guaranteeing the task processing delay tolerance and the holding time of each vehicle. An M/M/1 queue is used to model the task queuing and task computing processes on each RSU. An exact potential game is adopted to model the competition process for the task offloading among the RSUs. A two-stage iterative algorithm is designed to decompose the optimization problem into two stages and solve them iteratively. We analyze the computational complexity of the algorithm and conduct extensive simulations by varying different crucial parameters. The superiority of our scheme is demonstrated in comparison with 3 other reference schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2153995001",
                    "name": "Mingyu Hua"
                },
                {
                    "authorId": "2200089182",
                    "name": "Yaoyin Zhang"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2307485286",
                    "name": "Xuewei Li"
                },
                {
                    "authorId": "33949252",
                    "name": "B. Tang"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "ac85903fd13625981867096299c64f935fdfffdd",
            "title": "A Truthful Combinatorial Auction Mechanism Towards Mobile Edge Computing in Industrial Internet of Things",
            "abstract": "Mobile edge computing (MEC) shows prominent application prospects in the Industrial Internet of Things (IIoT) by allowing resource-restricted IIoT mobile devices (MDs) to offload their tasks to geographical proximity edge clouds. An efficient incentive mechanism should be designed jointly addressing resource allocation and pricing to incentivize MDs (i.e., buyers) and edge clouds (i.e., sellers) to participate in offloading service trading. This article aims to solve the social welfare maximization problem of a personalized MEC computation offloading service market where each edge cloud can allocate different computing and wireless resources to each MD according to the MDs\u2019 delay and energy consumption constraints, and each MD submits bids to edge clouds differently based on the resource allocation of the edge clouds. We propose a truthful combinatorial auction (TCA) mechanism which involves three phases of resource allocation, buyer-seller matching, and payment determination. It should be highlighted that our proposed buyer-seller matching algorithm combines optimal matching and heuristic matching, so it greatly improves the auction effect while ensuring computational efficiency. Considerable theoretical analysis and experimental results prove that the performance of the proposed TCA mechanism is significantly superior to that of other auction mechanisms while holding the desirable properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2143862037",
                    "name": "Y. Liu"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                }
            ]
        },
        {
            "paperId": "b2cd91f92bf376b3af4bdf3ffa985ff9bf9a7e6c",
            "title": "DNN Deployment, Task Offloading, and Resource Allocation for Joint Task Inference in IIoT",
            "abstract": "Joint task inference, which fully utilizes end edge cloud cooperation, can effectively enhance the performance of deep neural network (DNN) inference services in the industrial internet of things (IIoT) applications. In this paper, we propose a novel joint resource management scheme for a multi task and multi service scenario consisting of multiple sensors, a cloud server, and a base station equipped with an edge server . A time slotted system model is proposed, incorporating DNN deployment, data size control, task offloading, computing resource allocation, and wireless channel allocation. Among them, the DNN deployment is to deploy proper DNNs on the edge server under its total resource constraint, and the data size control is to make trade off between task inference accuracy and task transmission delay through changing task da ta size. Our goal is to minimize the total cost including total task processing delay and total error inference penalty while guaranteeing long term task queue stability and all task inference accuracy requirements. Leveraging the Lyapunov optimization, we first transform the optimization problem into a deterministic problem for each time slot. Then, a deep deterministic policy gradient (DDPG) based deep reinforcement learning (DRL) algorithm is designed to provide the near optimal solution. We further desi gn a fast numerical method for the data size control sub problem to reduce the training complexity of the DRL model, and design a penalty mechanism to prevent frequent optimizations of DNN deployment. Extensive experiments are conducted by varying differen t crucial parameters. The superiority of our scheme is demonstrated in comparison with 3 other schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2111434705",
                    "name": "Zeyu Chen"
                },
                {
                    "authorId": "2178604984",
                    "name": "Zhibo Hao"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "33949252",
                    "name": "B. Tang"
                },
                {
                    "authorId": "2143860976",
                    "name": "Yuan'an Liu"
                }
            ]
        },
        {
            "paperId": "b3da24c1c25a9afae321aed05905f114e43e85a8",
            "title": "Joint DNN Partition and Resource Allocation for Task Offloading in Edge\u2013Cloud-Assisted IoT Environments",
            "abstract": "Multiaccess edge computing (MEC) is a promising approach to enhancing IoT devices running AI-based services. Especially, the edge\u2013cloud architecture acts as a strong supporter of the resource-limited IoT devices. How to optimize the system resources efficiently to improve the service performance is the key issue in this scenario. Motivated by this, in this article, we focus on a multi-base station (BS) and multiservice edge\u2013cloud-assisted IoT environment, where both the BSs (with edge servers deployed) and the cloud can assist the IoT devices to process multitype deep learning (DL) tasks via task offloading. DNN partition mechanism and both the communication and computing resources allocation are utilized to enable a collaborative optimization to minimize the processing delay of all the DL tasks in the system. Due to the mixed-integer nonlinear programming (MINLP) characteristic of our optimization problem, we propose an algorithm that decomposes the original problem into two subproblems, solves them separately, and then obtains the near-optimal solution efficiently. Extensive simulations are conducted by varying five different crucial parameters. The superiority of our scheme is demonstrated in comparisons with several other schemes proposed by existing works. Our scheme can achieve a notable 28.3% delay reduction on average.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "13383067",
                    "name": "Li Gao"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "b623906904a44ad1d11d425dc0d056e6982b5b8c",
            "title": "Joint Task Offloading and Resource Allocation for Accuracy-Aware Machine-Learning-Based IIoT Applications",
            "abstract": "Machine learning (ML) plays a key role in Intelligent Industrial Internet of Things (IIoT) applications. Processing of the computation-intensive ML tasks can be largely enhanced by applying edge computing (EC) to traditional cloud-based schemes. System optimizations in the existing works always ignore the inference accuracy of ML models with different complexities, and their impacts on error task inference. In this article, we propose a joint task offloading and resource allocation scheme for accuracy-aware machine-learning-based IIoT applications in an edge\u2013cloud-based network architecture. We aim at minimizing the long-term average system cost affected by the task offloading, computing resource allocation, and inference accuracy of the ML models deployed on the sensors, edge server, and cloud server. The Lyapunov optimization technique is applied to convert the long-term stochastic optimization problem into a short-term deterministic problem. An optimal algorithm based on the general Benders decomposition (GBD) technology and a heuristic algorithm based on proportional computing resource allocation and task offloading strategy comparison are proposed to efficiently solve the problem, respectively. The performance of our scheme is proved by theoretical analysis and evaluated by extensive simulations conducted in multiple scenarios. Simulation results demonstrate the effectiveness and superiority of our two algorithms in comparison with several other schemes proposed by the existing works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2170116726",
                    "name": "Shenmeng Li"
                },
                {
                    "authorId": "2146651089",
                    "name": "Jie Liu"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "2170048599",
                    "name": "Yuan\u2019an Liu"
                }
            ]
        },
        {
            "paperId": "4083c975678b38b55d4c88573db273a2cc87b139",
            "title": "Joint Task Offloading and Service Caching for Multi-Access Edge Computing in WiFi-Cellular Heterogeneous Networks",
            "abstract": "Enabled by Multi-access Edge Computing (MEC) in a WiFi-cellular heterogeneous network, the tasks of mobile terminals (MTs) can be offloaded via the cellular network to the MEC servers or cloud server, or via the WiFi network to alleviate transmission congestion of the cellular network. The MEC also enables service caching to cache the programs/libraries/databases of the tasks to avoid repeated input data uploading. Existing research works lack joint optimization on the task offloading and service caching for MEC in the WiFi-cellular heterogeneous network. In this paper, a novel resource management scheme for joint task offloading and service caching is proposed to maximize the energy consumption benefits of all the MTs covered by a WiFi-cellular heterogeneous network while guaranteeing the task processing delay tolerance of each MT. We consider the constraints on limited computing and storage resources of the MEC servers equipped on the cellular base station and the WiFi access point, and we also consider cellular channel allocation for the task offloading. We design an iterative algorithm based on the alternating optimization technique to solve the proposed mixed integer nonlinear programming problem efficiently. Extensive simulations are conducted in multiple scenarios by varying different crucial parameters. The numerical results demonstrate that our scheme can largely improve the system performance in all the scenarios, and energy consumption reduction optimized by our scheme is 16.24%-43.09% higher than those by the comparative works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8126987",
                    "name": "Wenhao Fan"
                },
                {
                    "authorId": "2000125543",
                    "name": "Junting Han"
                },
                {
                    "authorId": "2118006435",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2186397028",
                    "name": "Xun Liu"
                },
                {
                    "authorId": "1405885024",
                    "name": "Fan Wu"
                },
                {
                    "authorId": "33949252",
                    "name": "B. Tang"
                },
                {
                    "authorId": "2143860976",
                    "name": "Yuan'an Liu"
                }
            ]
        }
    ]
}