{
    "authorId": "2187512110",
    "papers": [
        {
            "paperId": "03776b12ecdea4a64c60b0194bcc7e6551d463a3",
            "title": "Benchmarking News Recommendation in the Era of Green AI",
            "abstract": "Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992% improvement in sustainability metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2290237904",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "3f46e66675a89f35d3991a85ff0556c1533de4d2",
            "title": "Multimodal Pretraining, Adaptation, and Generation for Recommendation: A Survey",
            "abstract": "Personalized recommendation serves as a ubiquitous channel for users to discover information tailored to their interests. However, traditional recommendation models primarily rely on unique IDs and categorical features for user-item matching, potentially overlooking the nuanced essence of raw item contents across multiple modalities such as text, image, audio, and video. This underutilization of multimodal data poses a limitation to recommender systems, especially in multimedia services like news, music, and short-video platforms. The recent advancements in large multimodal models offer new opportunities and challenges in developing content-aware recommender systems. This survey seeks to provide a comprehensive exploration of the latest advancements and future trajectories in multimodal pretraining, adaptation, and generation techniques, as well as their applications in enhancing recommender systems. Furthermore, we discuss current open challenges and opportunities for future research in this dynamic domain. We believe that this survey, alongside the curated resources, will provide valuable insights to inspire further advancements in this evolving landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2240695630",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2223871084",
                    "name": "Yanting Yang"
                },
                {
                    "authorId": "29969336",
                    "name": "Quanyu Dai"
                },
                {
                    "authorId": "2294672261",
                    "name": "Zhaocheng Du"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                },
                {
                    "authorId": "2265936086",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2163112250",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                }
            ]
        },
        {
            "paperId": "518a8957560a3c3be67738a190825a667a038e25",
            "title": "STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM",
            "abstract": "Traditional recommendation models often rely on unique item identifiers (IDs) to distinguish between items, which can hinder their ability to effectively leverage item content information and generalize to long-tail or cold-start items. Recently, semantic tokenization has been proposed as a promising solution that aims to tokenize each item's semantic representation into a sequence of discrete tokens. In this way, it preserves the item's semantics within these tokens and ensures that semantically similar items are represented by similar tokens. These semantic tokens have become fundamental in training generative recommendation models. However, existing generative recommendation methods typically involve multiple sub-models for embedding, quantization, and recommendation, leading to an overly complex system. In this paper, we propose to streamline the semantic tokenization and generative recommendation process with a unified framework, dubbed STORE, which leverages a single large language model (LLM) for both tasks. Specifically, we formulate semantic tokenization as a text-to-token task and generative recommendation as a token-to-token task, supplemented by a token-to-text reconstruction task and a text-to-token auxiliary task. All these tasks are framed in a generative manner and trained using a single LLM backbone. Extensive experiments have been conducted to validate the effectiveness of our STORE framework across various recommendation tasks and datasets. We will release the source code and configurations for reproducible research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2290237904",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2147259441",
                    "name": "Lu Fan"
                },
                {
                    "authorId": "2265936086",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "53fa01ab6d73878e32940ccf9ec861b24f2ab7c8",
            "title": "Discrete Semantic Tokenization for Deep CTR Prediction",
            "abstract": "Incorporating item content information into click-through rate (CTR) prediction models remains a challenge, especially with the time and space constraints of industrial scenarios. The content-encoding paradigm, which integrates user and item encoders directly into CTR models, prioritizes space over time. In contrast, the embedding-based paradigm transforms item and user semantics into latent embeddings, subsequently caching them to optimize processing time at the expense of space. In this paper, we introduce a new semantic-token paradigm and propose a discrete semantic tokenization approach, namely UIST, for user and item representation. UIST facilitates swift training and inference while maintaining a conservative memory footprint. Specifically, UIST quantizes dense embedding vectors into discrete tokens with shorter lengths and employs a hierarchical mixture inference module to weigh the contribution of each user-item token pair. Our experimental results on news recommendation showcase the effectiveness and efficiency (about 200-fold space compression) of UIST for CTR prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2244776472",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2258801777",
                    "name": "Hengchang Hu"
                },
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "2290237904",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2270948852",
                    "name": "Min-Yen Kan"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "86df20a63ad7893d3feeeaf9ea5204033fb0d588",
            "title": "LANID: LLM-assisted New Intent Discovery",
            "abstract": "Data annotation is expensive in Task-Oriented Dialogue (TOD) systems. New Intent Discovery (NID) is a task aims to identify novel intents while retaining the ability to recognize known intents. It is essential for expanding the intent base of task-based dialogue systems. Previous works relying on external datasets are hardly extendable. Meanwhile, the effective ones are generally depends on the power of the Large Language Models (LLMs). To address the limitation of model extensibility and take advantages of LLMs for the NID task, we propose LANID, a framework that leverages LLM\u2019s zero-shot capability to enhance the performance of a smaller text encoder on the NID task. LANID employs KNN and DBSCAN algorithms to select appropriate pairs of utterances from the training set. The LLM is then asked to determine the relationships between them. The collected data are then used to construct finetuning task and the small text encoder is optimized with a triplet loss. Our experimental results demonstrate the efficacy of the proposed method on three distinct NID datasets, surpassing all strong baselines in both unsupervised and semi-supervised settings. Our code can be found in https://github.com/floatSDSDS/LANID.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273534266",
                    "name": "Lu Fan"
                },
                {
                    "authorId": "34260749",
                    "name": "Jiashu Pu"
                },
                {
                    "authorId": "2269831996",
                    "name": "Rongsheng Zhang"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "b5fd2ec327151135e137a636f7c1fa663be670ca",
            "title": "Structure-aware Semantic Node Identifiers for Learning on Graphs",
            "abstract": "We present a novel graph tokenization framework that generates structure-aware, semantic node identifiers (IDs) in the form of a short sequence of discrete codes, serving as symbolic representations of nodes. We employs vector quantization to compress continuous node embeddings from multiple layers of a graph neural network (GNN), into compact, meaningful codes, under both self-supervised and supervised learning paradigms. The resulting node IDs capture a high-level abstraction of graph data, enhancing the efficiency and interpretability of GNNs. Through extensive experiments on 34 datasets, including node classification, graph classification, link prediction, and attributed graph clustering tasks, we demonstrate that our generated node IDs not only improve computational efficiency but also achieve competitive performance compared to current state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293898339",
                    "name": "Yuankai Luo"
                },
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2268718335",
                    "name": "Lei Shi"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "06545fc3aa68622ecdadcf93524f5343c652400a",
            "title": "EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs",
            "abstract": "We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs), Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample amounts of training data to bridge modalities,EasyGen leverages BiDiffuser,a bidirectional conditional diffusion model, to foster more efficient modality interactions. Easygen achieves text generation by training a projection layer linking BiDiffuser and an LLM, and facilities image generation by training an adapter to align the LLM's text space with the BiDiffuser's image space, Comprehensive quantitative and qualitative experiments show that EasyGen excels in data-efficient training, high-quality image generation, and extendibility, effectively addressing the challenges in multimodal generation. The source code is available at https://github.com/zxy556677/EasyGen.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116711673",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "73548014",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "144218801",
                    "name": "Guangyuan Shi"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "0790ffc8118c9ebba6a1d2b0e7f805f39faeae82",
            "title": "Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation",
            "abstract": "Modern techniques in Content-based Recommendation (CBR) leverage item content information to provide personalized services to users, but suffer from resource-intensive training on large datasets. To address this issue, we explore the dataset condensation for textual CBR in this paper. The goal of dataset condensation is to synthesize a small yet informative dataset, upon which models can achieve performance comparable to those trained on large datasets. While existing condensation approaches are tailored to classification tasks for continuous data like images or embeddings, direct application of them to CBR has limitations. To bridge this gap, we investigate efficient dataset condensation for content-based recommendation. Inspired by the remarkable abilities of large language models (LLMs) in text comprehension and generation, we leverage LLMs to empower the generation of textual content during condensation. To handle the interaction data involving both users and items, we devise a dual-level condensation method: content-level and user-level. At content-level, we utilize LLMs to condense all contents of an item into a new informative title. At user-level, we design a clustering-based synthesis module, where we first utilize LLMs to extract user interests. Then, the user interests and user embeddings are incorporated to condense users and generate interactions for condensed users. Notably, the condensation paradigm of this method is forward and free from iterative optimization on the synthesized dataset. Extensive empirical findings from our study, conducted on three authentic datasets, substantiate the efficacy of the proposed method. Particularly, we are able to approximate up to 97% of the original performance while reducing the dataset size by 95% (i.e., on dataset MIND).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "2244776472",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2258801777",
                    "name": "Hengchang Hu"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2254366521",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                },
                {
                    "authorId": "2253405825",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "0f4d00d01d43d3967ee92b58481b5ad530a944d1",
            "title": "A First Look at LLM-Powered Generative News Recommendation",
            "abstract": "Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. We will publish our code and data 1 for other researchers to reproduce our work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2257286538",
                    "name": "Nuo Chen"
                },
                {
                    "authorId": "2257233277",
                    "name": "Tetsuya Sakai"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        },
        {
            "paperId": "38ecf2897db59134250923805cbdf9fb5948965b",
            "title": "FANS: Fast Non-Autoregressive Sequence Generation for Item List Continuation",
            "abstract": "User-curated item lists, such as video-based playlists on Youtube and book-based lists on Goodreads, have become prevalent for content sharing on online platforms. Item list continuation is proposed to model the overall trend of a list and predict subsequent items. Recently, Transformer-based models have shown promise in comprehending contextual information and capturing item relationships in a list. However, deploying them in real-time industrial applications is challenging, mainly because the autoregressive generation mechanism used in them is time-consuming. In this paper, we propose a novel fast non-autoregressive sequence generation model, namely FANS, to enhance inference efficiency and quality for item list continuation. First, we use a non-autoregressive generation mechanism to decode next K items simultaneously instead of one by one in existing models. Then, we design a two-stage classifier to replace the vanilla classifier used in current transformer-based models to further reduce the decoding time. Moreover, to improve the quality of non-autoregressive generation, we employ a curriculum learning strategy to optimize training. Experimental results on four real-world item list continuation datasets including Zhihu, Spotify, AotM, and Goodreads show that our FANS model can significantly improve inference efficiency (up to 8.7x) while achieving competitive or better generation quality for item list continuation compared with the state-of-the-art autoregressive models. We also validate the efficiency of FANS in an industrial setting. Our source code and data will be available at MindSpore/models1 and Github2.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150270469",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "1917775411",
                    "name": "Tiandeng Wu"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                }
            ]
        }
    ]
}