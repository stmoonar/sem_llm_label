{
    "authorId": "2055181125",
    "papers": [
        {
            "paperId": "f81ea4626d83adcdaa9c1a9955d0be962457e0f4",
            "title": "Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis",
            "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "065f9775101218665b4baaa2833c91480ec25ccd",
            "title": "TimeAutoAD: Autonomous Anomaly Detection With Self-Supervised Contrastive Loss for Multivariate Time Series",
            "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in networked systems, e.g., IoT systems and 5G networks. Anomaly detection in MTS refers to identifying time series which exhibit different behaviors from normal status. Building such a system, however, is challenging due to a few reasons: i) labels for anomaly cases are usually unavailable or very rare; ii) most existing approaches rely on manual model-design and hyperparameter tuning, which may cost a huge amount of labor effort. To this end, we propose an autonomous anomaly detection technique for multivariate time series data (TimeAutoAD) based on a novel self-supervised contrastive loss. Specifically, we first present an automatic anomaly detection pipeline to optimize the model configuration and hyperparameters automatically. Next, we introduce three different strategies to augment the training data for generating pseudo negative time series and employ a self-supervised contrastive loss to distinguish the original time series and the generated time series. In this way, the representation learning capability of TimeAutoAD can be greatly enhanced and the anomaly detection performance can thus be improved. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoAD not only outperforms state-of-the-art anomaly detection approaches but also exhibits robustness when training data are contaminated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2118049422",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2082545536",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "2c5f6080a69efe76cf56d225808324fb5b692c1b",
            "title": "Asynchronous Distributed Bilevel Optimization",
            "abstract": "Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches require collecting massive amount of data to a single server, which inevitably incur significant communication expenses and may give rise to data privacy risks. Synchronous distributed bilevel optimization algorithms, on the other hand, often face the straggler problem and will immediately stop working if a few workers fail to respond. As a remedy, we propose Asynchronous Distributed Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel optimization problems with both nonconvex upper-level and lower-level objective functions, and its convergence is theoretically guaranteed. Furthermore, it is revealed through theoretic analysis that the iteration complexity of ADBO to obtain the $\\epsilon$-stationary point is upper bounded by $\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public datasets have been conducted to elucidate the effectiveness and efficiency of the proposed ADBO.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2142035704",
                    "name": "Chen Jian"
                }
            ]
        },
        {
            "paperId": "386c030c671bdc7429f0d237b3c0e6eb935dc766",
            "title": "CPMLHO: Hyperparameter Tuning via Cutting Plane and Mixed-Level Optimization",
            "abstract": "The hyperparameter optimization of neural network can be expressed as a bilevel optimization problem. The bilevel optimization is used to automatically update the hyperparameter, and the gradient of the hyperparameter is the approximate gradient based on the best response function. Finding the best response function is very time consuming. In this paper we propose CPMLHO, a new hyperparameter optimization method using cutting plane method and mixed-level objective function. The cutting plane is added to the inner layer to constrain the space of the response function. To obtain more accurate hypergradient, the mixed-level can flexibly adjust the loss function by using the loss of the training set and the verification set. Compared to existing methods, the experimental results show that our method can automatically update the hyperparameters in the training process, and can find more superior hyperparameters with higher accuracy and faster convergence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185661567",
                    "name": "Shu-Bo Yang"
                },
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "10675825",
                    "name": "Shaoyu Dou"
                },
                {
                    "authorId": "32421377",
                    "name": "Mana Zheng"
                },
                {
                    "authorId": "2162203362",
                    "name": "Chen Zhu"
                }
            ]
        },
        {
            "paperId": "404e862cc02b9024b40bfe059439299d0a239f98",
            "title": "Task-aware Similarity Learning for Event-triggered Time Series",
            "abstract": "\u2014Time series analysis has achieved great success in diverse applications such as network security, environmental monitoring, and medical informatics. Learning similarities among different time series is a crucial problem since it serves as the foundation for downstream analysis such as clustering and anomaly detection. It often remains unclear what kind of distance metric is suitable for similarity learning due to the complex temporal dynamics of the time series generated from event-triggered sensing, which is common in diverse applications, including automated driving, interactive healthcare, and smart home automation. The overarching goal of this paper is to develop an unsupervised learning framework that is capable of learning task-aware similarities among unlabeled event-triggered time series. From the machine learning vantage point, the proposed framework harnesses the power of both hierarchical multi-scale sequence autoencoders and Gaussian Mixture Model (GMM) to effectively learn the low-dimensional representations from the time series. Finally, the obtained similarity measure can be easily visualized for explaining. The proposed framework aspires to offer a stepping stone that gives rise to a systematic approach to model and learn similarities among a multitude of event-triggered time series. Through extensive qualitative and quantitative experiments, it is revealed that the proposed method outperforms state-of-the-art methods considerably.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10675825",
                    "name": "Shaoyu Dou"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": null,
                    "name": "Chengbo Qiu"
                },
                {
                    "authorId": "2145257973",
                    "name": "Kui Ren"
                }
            ]
        },
        {
            "paperId": "78dfc9800a537f0a1bc9c717f73b917e97603484",
            "title": "Distributed Distributionally Robust Optimization with Non-Convex Objectives",
            "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the distributed distributionally robust optimization (DDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "60773c01dd3c76be0e1d3bc429cf474e5f9d8519",
            "title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly Sampled Time Series",
            "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization are fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance its representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection performance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "1637401447",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "10675825",
                    "name": "Shaoyu Dou"
                },
                {
                    "authorId": "2052216790",
                    "name": "Pan Luo"
                },
                {
                    "authorId": "8602668",
                    "name": "Sijia Liu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                }
            ]
        }
    ]
}