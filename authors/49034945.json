{
    "authorId": "49034945",
    "papers": [
        {
            "paperId": "0071af30e74e3c08ffcd1874913375da020d65bd",
            "title": "Network Alignment With Holistic Embeddings",
            "abstract": "Network alignment is the task of identifying topologically and semantically similar nodes across (two) different networks. It plays an important role in various applications ranging from social network analysis to bioinformatic network interactions. However, existing alignment models either cannot handle large-scale graphs or fail to leverage different types of network information or modalities. In this paper, we propose a novel end-to-end alignment framework that can leverage different modalities to compare and align network nodes in an efficient way. In order to exploit the richness of the network context, our model constructs multiple embeddings for each node, each of which captures one modality or type of network information. We then design a late-fusion mechanism to combine the learned embeddings based on the importance of the underlying information. Our fusion mechanism allows our model to be adapted to various types of structure of the input network. Experimental results show that our technique outperforms state-of-the-art approaches in terms of accuracy on real and synthetic datasets, while being robust against various noise factors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "39822639",
                    "name": "Chi Thang Duong"
                },
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "2037792812",
                    "name": "V. Tong"
                },
                {
                    "authorId": "143756261",
                    "name": "A. Sattar"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "69e4ac52275312b1b26d53a6d78b29f83b9489ec",
            "title": "Efficient and Effective Multi-Modal Queries Through Heterogeneous Network Embedding",
            "abstract": "The heterogeneity of today\u2019s Web sources requires information retrieval (IR) systems to handle multi-modal queries. Such queries define a user\u2019s information needs by different data modalities, such as keywords, hashtags, user profiles, and other media. Recent IR systems answer such a multi-modal query by considering it as a set of separate uni-modal queries. However, depending on the chosen operationalisation, such an approach is inefficient or ineffective. It either requires multiple passes over the data or leads to inaccuracies since the relations between data modalities are neglected in the relevance assessment. To mitigate these challenges, we present an IR system that has been designed to answer genuine multi-modal queries. It relies on a heterogeneous network embedding, so that features from diverse modalities can be incorporated when representing both, a query and the data over which it shall be evaluated. By embedding a query and the data in the same vector space, the relations across modalities are made explicit and exploited for more accurate query evaluation. At the same time, multi-modal queries are answered with a single pass over the data. An experimental evaluation using diverse real-world and synthetic datasets illustrates that our approach returns twice the amount of relevant information compared to baseline techniques, while scaling to large multi-modal databases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39822639",
                    "name": "Chi Thang Duong"
                },
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2315762",
                    "name": "M. Weidlich"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "cd377155eb4d2ea04ed857b74fdcfec4e8b384e0",
            "title": "Entity Alignment for Knowledge Graphs With Multi-Order Convolutional Networks",
            "abstract": "Knowledge graphs (KGs) have become popular structures for unifying real-world entities by modelling the relationships between them and their attributes. To support multilingual applications, a significant number of language-specific KGs have been built by different parties using various data sources. As a result, these monolingual KGs are often disconnected, causing semantic heterogeneity and detracting from the original purpose of KGs. Entity alignment \u2013 the task of identifying corresponding entities across different KGs \u2013 has attracted a great deal of attention in both academia and industry. However, existing alignment techniques often require large amounts of labelled data, are unable to encode multi-modal data simultaneously, and enforce only a few consistency constraints. In this paper, we propose an end-to-end, unsupervised entity alignment framework for cross-lingual KGs that fuses different types of information in order to fully exploit the richness of KG data. The model captures the relation-based correlation between entities by using a multi-order graph convolutional neural (GCN) model that is designed to satisfy the consistency constraints, while incorporating the attribute-based correlation via a translation machine. We adopt a late-fusion mechanism to combine all the information together, which allows these approaches to complement each other and thus enhances the final alignment result, and makes the model more robust to consistency violations. Empirical results for various scenarios on real-world and synthetic KGs show that our model is up to 22.71 percent more accurate and orders of magnitude faster than existing baselines. We also demonstrate its sensitivity to hyper-parameters, effort saving in terms of labelling, and the robustness against adversarial conditions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2037792812",
                    "name": "V. Tong"
                },
                {
                    "authorId": "2037793264",
                    "name": "Darnbi Sakong"
                },
                {
                    "authorId": "133730578",
                    "name": "Bolong Zheng"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "6ca04af26fa97ca0814719ad18ef2dc1c7e62a27",
            "title": "Implicit entity linking in tweets: An ad-hoc retrieval approach",
            "abstract": "Within the context of Twitter analytics, the notion of implicit entity linking has recently been introduced to refer to the identification of a named entity, which is central to the topic of the tweet, but whose surface form is not present in the tweet itself. Compared to traditional forms of entity linking where the linking process revolves around an identified surface form of a potential entity, implicit entity linking relies on contextual clues to determine whether an implicit entity is present within a given tweet and if so, which entity is being referenced. The objective of this paper, while introducing and publicly sharing a comprehensive gold standard dataset for implicit entity linking, is to perform the task of implicit entity linking. The dataset consists of 7,870 tweets, which are classified as either containing implicit entities, explicit entities, both, or neither. The implicit entities are then linked to three levels of entities on Wikipedia, namely coarse-grained level, e.g., Person, Fine-grained level, e.g., Comedian, and the actual entity, e.g., Seinfeld. The proposed model in this work formulates the problem of implicit entity linking as an ad-hoc document retrieval process where the input query is the tweet, which needs to be implicitly linked and the document space is the set of textual descriptions of entities in the knowledge base. The novel contributions of our work include: 1) designing and collecting a gold standard dataset for the task of implicit entity linking; 2) defining the implicit entity linking process as an ad-hoc document retrieval task; and 3) proposing a neural embedding-based feature function that is interpolated with prior term dependency and entity-based feature functions to enhance implicit entity linking. We systematically compare our work with existing work in this area and show that our method is able to provide improvements on a number of retrieval measures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51258466",
                    "name": "Hawre Hosseini"
                },
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "2138787480",
                    "name": "Jimmy Wu"
                },
                {
                    "authorId": "145632843",
                    "name": "E. Bagheri"
                }
            ]
        },
        {
            "paperId": "9ddd9463eaeb462c6b3595f58e159070f67deb42",
            "title": "Implicit Entity Linking Through Ad-Hoc Retrieval",
            "abstract": "The systematic linking of explicitly-observed phrases within a document to entities of a knowledge base has already been explored in a process known as entity linking. The objective of this paper, however, is to identify and entity link those entities that are not mentioned but are implied within a document, more specifically within a tweet. This process is referred to as implicit entity linking. Unlike prior work that build a representation for each entity based on its related content in the knowledge base, we propose to perform implicit entity linking by determining how a tweet is related to user-generated content posted online and as such indirectly perform entity linking. We formulate this problem as an ad-hoc document retrieval process where the input query is the tweet, which needs to be implicitly linked and the document space is the set of user-generated content related to the entities of the knowledge base. We systematically compare our work with the state-of-the-art baseline and show that our method is able to provide statistically significant improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51258466",
                    "name": "Hawre Hosseini"
                },
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "145632843",
                    "name": "E. Bagheri"
                }
            ]
        },
        {
            "paperId": "39f8b5202dbe01d8c046074e1ed6195c8d044801",
            "title": "Learning event count models with application to affiliation ranking",
            "abstract": "Event count prediction is a class of problems in time series analysis, which has been extensively studied over the years. Its applications range from the prediction of the number of publications in the scientific community to ATM cash withdrawal transaction prediction in the banking industry. However, in applied data science problems, using event count prediction models for real-world data often faces difficulties because the data violates not only the Poisson distribution assumption, i.e., the rate at which events occur should be constant, but the data is also relatively sparse, i.e., only a few event count values are greater than zero. Traditional techniques do not work well under these two conditions. To overcome these limitations, some researchers have proposed the generic autoregressive (AR) models for event count prediction, which work with non-constant event occurrence rates. As AR models solely use historical event count for forecasting, they might not be as flexible for incorporating domain knowledge. Moreover, and similarly, AR models may not work very well with the relatively short length-time series. In order to overcome these challenges, we propose a machine learning approach to address the event count prediction problem. We benchmark our proposed solution on the KDD Cup 2016 dataset by formalizing affiliation ranking as an event count time series prediction problem. We map the time series onto a highly dimensional state space and systematically apply the state-of-the-art machine learning algorithms to predict event counts. We then compare our proposed approach against solutions in the KDD Cup 2016 competition and show that our work outperforms the best models in this with an [email\u00a0protected] score of 0.7573.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "145632843",
                    "name": "E. Bagheri"
                },
                {
                    "authorId": "2742677",
                    "name": "Jeong-Yoon Lee"
                },
                {
                    "authorId": "2145573169",
                    "name": "Hang Li"
                },
                {
                    "authorId": "37549110",
                    "name": "Mert Bay"
                },
                {
                    "authorId": "2154733509",
                    "name": "Song Chen"
                }
            ]
        },
        {
            "paperId": "0aef31b1adcbb7e47304a190cbb85e2377ec2174",
            "title": "A math-aware search engine for math question answering system",
            "abstract": "We propose a math-aware search engine that is capable of handling both textual keywords as well as mathematical expressions. Our math feature extraction and representation framework captures the semantics of math expressions via a Finite State Machine model. We adapt the passive aggressive online learning binary classifier as the ranking model. We benchmarked our approach against three classical information retrieval (IR) strategies on math documents crawled from Math Overflow, a well-known online math question answering system. Experimental results show that our proposed approach can perform better than other methods by more than 9%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "1731379",
                    "name": "Kuiyu Chang"
                },
                {
                    "authorId": "144194328",
                    "name": "S. Hui"
                }
            ]
        },
        {
            "paperId": "7e41e0273e8d880266ba9b326e15e4f70a829993",
            "title": "Supervised term weighting for sentiment analysis",
            "abstract": "Vector space text classification is commonly used in intelligence applications such as email and conversation analysis. In this paper we propose a supervised term weighting scheme called t\u0192 \u00d7 KL (term frequency Kullback-Leibler), which weights each word proportionally to the ratio of its document frequency across the positive and negative class. We then generalize t\u0192 \u00d7 KL to effectively deal with class imbalance, which is very common in real world intelligence analysis. The generalized t\u0192 \u00d7 KL weights each word according to the ratio of the positive and negative class conditioned word probabilities instead of the raw document frequencies. Results on four classification datasets show t\u0192 \u00d7 KL to perform consistently better than the baseline t\u0192 \u00d7id\u0192 and 4 other supervised term weighting schemes, including the recently proposed t\u0192 \u00d7 r\u0192 (term frequency relevance frequency). The generalized t\u0192 \u00d7 KL was found to be extremely robust in dealing with highly skewed class distributions, beating the second runner-up by more than 20% on a dataset that has only 10% positive training examples. The generalized t\u0192 \u00d7 KL is thus an effective and robust term weighting scheme that can significantly improve binary classification performance in sentiment analysis and intelligence applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "1731379",
                    "name": "Kuiyu Chang"
                },
                {
                    "authorId": "144194328",
                    "name": "S. Hui"
                }
            ]
        },
        {
            "paperId": "f3f51d7ec8082542e347dd3a68ac3a8c9ca8eb87",
            "title": "Word Cloud Model for Text Categorization",
            "abstract": "In centroid-based classification, each class is represented by a prototype or centroid document vector that is formed by averaging all member vectors during the training phase. In the prediction phase, the label of a test document vector is assigned to that of its nearest class prototype. Recently there has been revived interest in reformulating the prototype/centroid to improve classification performance. In this paper, we study the theoretical properties of the recently proposed Class Feature Centroid (CFC) classifier by considering the rate of change of each prototype vector with respect to individual dimensions (terms). The implication of our theoretical finding is that CFC is inherently biased towards large (dominant majority) classes, which means it is destined to perform poorly for highly class-imbalanced data. Another practical concern about CFC lies in its overly-aggressive design in weeding out terms that appear in all classes. To overcome these CFC limitations while retaining its intrinsic and worthy design goals, we propose an improved and robust centroid-based classifier that uses precise term-class distribution properties instead of simple presence or absence of terms in classes. Specifically, terms are weighted based on the Kullback-Leibler divergence measure between pairs of class-conditional term probabilities, we call this the CFC-KL centroid classifier. We then generalized CFC-KL to handle multi-class data by summing pair wise class-conditioned word probability ratios. Our proposed approach has been evaluated on 5 datasets, on which it consistently outperforms CFC and the baseline Support Vector Machine classifier. We also devise a word cloud visualization approach to highlight the important class-specific words picked out by our CFC-KL, and visually compare it with other popular term weigthing approaches. Our encouraging results show that the centroid based generalized CFC-KL classifier is both robust and efficient to deal with real-world text classification.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49034945",
                    "name": "Tam T. Nguyen"
                },
                {
                    "authorId": "1731379",
                    "name": "Kuiyu Chang"
                },
                {
                    "authorId": "144194328",
                    "name": "S. Hui"
                }
            ]
        }
    ]
}