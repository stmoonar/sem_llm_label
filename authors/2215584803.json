{
    "authorId": "2215584803",
    "papers": [
        {
            "paperId": "3eb3cb33d2c807b88c78c12d48041ffeba2ef096",
            "title": "Graph Neural Networks without Propagation",
            "abstract": "Due to the simplicity, intuition and explanation, most Graph Neural Networks (GNNs) are proposed by following the pipeline of message passing. Although they achieve superior performances in many tasks, propagation-based GNNs possess three essential drawbacks. Firstly, the propagation tends to produce smooth effect, which meets the inductive bias of homophily, and causes two serious issues: over-smoothing issue and performance drop on networks with heterophily. Secondly, the propagations to each node are irrelevant, which prevents GNNs from modeling high-order relation, and cause the GNNs fragile to the attributes noises. Thirdly, propagation-based GNNs may be fragile to topology noise, since they heavily relay on propagation over the topology. Therefore, the propagation, as the key component of most GNNs, may be the essence of some serious issues in GNNs. To get to the root of these issue, this paper attempts to replace the propagation with a novel local operation. Quantitative experimental analysis reveals: 1) the existence of low-rank characteristic in the node attributes from ego-networks and 2) the performance improvement by reducing its rank. Motivated by this finding, this paper propose the Low-Rank GNNs, whose key component is the low-rank attribute matrix approximation in ego-network. The graph topology is employed to construct the ego-networks instead of message propagation, which is sensitive to topology noises. The proposed Low-Rank GNNs posses some attractive characteristics, including robust to topology and attribute noises, parameter-free and parallelizable. Experimental evaluations demonstrate the superior performance, robustness to noises and universality of the proposed Low-Rank GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143921529",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "2215584803",
                    "name": "Qiuliang Zhang"
                },
                {
                    "authorId": "2215543502",
                    "name": "Runjie Shi"
                },
                {
                    "authorId": "2160390715",
                    "name": "Wenmiao Zhou"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "2109150586",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2149214322",
                    "name": "Xiaochun Cao"
                },
                {
                    "authorId": "40137924",
                    "name": "Dongxiao He"
                },
                {
                    "authorId": "2188012894",
                    "name": "Zhen Wang"
                },
                {
                    "authorId": "2613860",
                    "name": "Yuanfang Guo"
                }
            ]
        },
        {
            "paperId": "6d35b28af908c1f6e2c9de2f30e12a9573480ddc",
            "title": "Self-supervised Graph Neural Networks via Low-Rank Decomposition",
            "abstract": "Self-supervised learning is introduced to train graph neural networks (GNNs) by employing propagation-based GNNs designed for semi-supervised learning tasks. Unfortunately, this common choice tends to cause two serious issues. Firstly, global parameters cause the model lack the ability to capture the local property. Secondly, it is dif\ufb01cult to handle networks beyond homophily without label information. This paper tends to break through the common choice of employing propagation-based GNNs, which aggregate representations of nodes belonging to different classes and tend to lose discriminative information. If the propagation in each ego-network is just between the nodes from the same class, the obtained representation matrix should follow the low-rank characteristic. To meet this requirement, this paper proposes the Low-Rank Decomposition-based GNNs (LRD-GNN-Matrix) by employing Low-Rank Decomposition to the attribute matrix. Furthermore, to incorporate long-distance information, Low-Rank Tensor Decomposition-based GNN (LRD-GNN-Tensor) is proposed by constructing the node attribute tensor from selected similar ego-networks and performing Low-Rank Tensor Decomposition. The employed tensor nuclear norm facilitates the capture of the long-distance relationship between original and selected similar ego-networks. Extensive experiments demonstrate the superior performance and the robustness of LRD-GNNs",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258970173",
                    "name": "Liang Yang"
                },
                {
                    "authorId": "2215543502",
                    "name": "Runjie Shi"
                },
                {
                    "authorId": "2215584803",
                    "name": "Qiuliang Zhang"
                },
                {
                    "authorId": "2661834",
                    "name": "Bingxin Niu"
                },
                {
                    "authorId": "2259628664",
                    "name": "Zhen Wang"
                },
                {
                    "authorId": "2259851578",
                    "name": "Chuan Wang"
                },
                {
                    "authorId": "2259620725",
                    "name": "Xiaochun Cao"
                }
            ]
        }
    ]
}