{
    "authorId": "3195704",
    "papers": [
        {
            "paperId": "e682e4a39c3597d3be8a921919989077047db2dd",
            "title": "Transformer-based Models for Long-Form Document Matching: Challenges and Empirical Analysis",
            "abstract": "Recent advances in the area of long document matching have primarily focused on using transformer-based models for long document encoding and matching. There are two primary challenges associated with these models. Firstly, the performance gain provided by transformer-based models comes at a steep cost \u2013 both in terms of the required training time and the resource (memory and energy) consumption. The second major limitation is their inability to handle more than a pre-defined input token length at a time. In this work, we empirically demonstrate the effectiveness of simple neural models (such as feed-forward networks, and CNNs) and simple embeddings (like GloVe, and Paragraph Vector) over transformer-based models on the task of document matching. We show that simple models outperform the more complex BERT-based models while taking significantly less training time, energy, and memory. The simple models are also more robust to variations in document length and text perturbations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "2124016792",
                    "name": "Adithya Samavedhi"
                },
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "86e0c6e038ba928b091329950400b8debe79363f",
            "title": "Supervised Contrastive Learning for Interpretable Long Document Comparison",
            "abstract": "Recent advancements in deep learning techniques have transformed the area of semantic text matching. However, most of the state-of-the-art models are designed to operate with short documents such as tweets, user reviews, comments, etc., and have fundamental limitations when applied to long-form documents such as scientific papers, legal documents, and patents. When handling such long documents, there are three primary challenges: (i) The presence of different contexts for the same word throughout the document, (ii) Small sections of contextually similar text between two documents, but dissimilar text in the remaining parts \u2013 this defies the basic understanding of \"similarity\", and (iii) The coarse nature of a single global similarity measure which fails to capture the heterogeneity of the document content. In this paper, we describe CoLDE : Co ntrastive L ong D ocument E ncoder \u2013 a transformer-based framework that addresses these challenges and allows for interpretable comparisons of long documents. CoLDE uses unique positional embeddings and a multi-headed chunkwise attention layer in conjunction with a contrastive learning framework to capture similarity at three different levels: (i) high-level similarity scores between a pair of documents, (ii) similarity scores between different sections within and across documents, and (iii) similarity scores between different chunks in the same document and also other documents. These fine-grained similarity scores aid in better interpretability. We evaluate CoLDE on three long document datasets namely, ACL Anthology publications, Wikipedia articles, and USPTO patents. Besides outperforming the state-of-the-art methods on the document comparison task, CoLDE also proves interpretable and robust to changes in document length and text perturbations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "2124016792",
                    "name": "Adithya Samavedhi"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "e9fe90baf1b811411943d73f40daf4d947f9102e",
            "title": "Supervised Contrastive Learning for Interpretable Long-Form Document Matching",
            "abstract": "Recent advancements in deep learning techniques have transformed the area of semantic text matching (STM). However, most state-of-the-art models are designed to operate with short documents such as tweets, user reviews, comments, and so on. These models have fundamental limitations when applied to long-form documents such as scientific papers, legal documents, and patents. When handling such long documents, there are three primary challenges: (i) the presence of different contexts for the same word throughout the document, (ii) small sections of contextually similar text between two documents, but dissimilar text in the remaining parts (this defies the basic understanding of \u201csimilarity\u201d), and (iii) the coarse nature of a single global similarity measure which fails to capture the heterogeneity of the document content. In this article, we describe CoLDE: Contrastive Long Document Encoder\u2014a transformer-based framework that addresses these challenges and allows for interpretable comparisons of long documents. CoLDE uses unique positional embeddings and a multi-headed chunkwise attention layer in conjunction with a supervised contrastive learning framework to capture similarity at three different levels: (i) high-level similarity scores between a pair of documents, (ii) similarity scores between different sections within and across documents, and (iii) similarity scores between different chunks in the same document and across other documents. These fine-grained similarity scores aid in better interpretability. We evaluate CoLDE on three long document datasets namely, ACL Anthology publications, Wikipedia articles, and USPTO patents. Besides outperforming the state-of-the-art methods on the document matching task, CoLDE is also robust to changes in document length and text perturbations and provides interpretable results. The code for the proposed model is publicly available at https://github.com/InterDigitalInc/CoLDE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36701727",
                    "name": "Akshita Jha"
                },
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "2124016792",
                    "name": "Adithya Samavedhi"
                },
                {
                    "authorId": "144417522",
                    "name": "Chandan K. Reddy"
                }
            ]
        },
        {
            "paperId": "e1aab4a0ea725b793050bd992ee5c31429814a0e",
            "title": "User Modeling and Churn Prediction in Over-the-top Media Services",
            "abstract": "We address the problem of customer retention ( churn ) in applications installed on over the top (OTT) streaming devices. In the first part of our work, we analyze various behavioral characteristics of users that drive application usage. By examining a variety of statistical measures, we answer the following questions: (1) how do users allocate time across various applications? , (2) how consistently do users engage with their devices? and (3) how likely are dormant users liable to becoming active again? In the second part, we leverage these insights to design interpretable churn prediction models that learn the latent characteristics of users by prioritizing the specifications of the users. Specifically, we propose the following models: (1) Attention LSTM (ALSTM), where churn prediction is done using a single level of attention by weighting on individual time frames (temporal-level attention) and (2) Neural Churn Prediction Model (NCPM), a more comprehensive model that uses two levels of attentions, one for measuring the temporality of each feature and another to measure the influence across features (feature-level attention). Using a series of experiments, we show that our models provide good churn prediction accuracy with interpretable reasoning. We believe that the data analysis, feature engineering and modeling techniques presented in this work can help organizations better understand the reason behind user churn on OTT devices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144060189",
                    "name": "Vineeth Rakesh"
                },
                {
                    "authorId": "2007951311",
                    "name": "Ajith Pudiyavitil"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                }
            ]
        },
        {
            "paperId": "9ac872f571055841f55b7df1cce3814e0dd8c323",
            "title": "Inferring Networked Device Categories from Low-Level Activity Indicators",
            "abstract": "We study the problem of inferring the type of a networked device in a home network by leveraging low level traffic activity indicators seen at commodity home gateways. We analyze a dataset of detailed device network activity obtained from 240 subscriber homes of a large European ISP and extract a number of traffic and spatial fingerprints for individual devices. We develop a two level taxonomy to describe devices onto which we map individual devices using a number of heuristics. We leverage the heuristically derived labels to train classifiers that distinguish device classes based on the traffic and spatial fingerprints of a device. Our results show an accuracy level up to 91% for the coarse level category and up to 84% for the fine grained category. By incorporating information from other sources (e.g., MAC OUI), we are able to further improve accuracy to above 97% and 92%, respectively. Finally, we also extract a set of simple and human-readable rules that concisely capture the behaviour of these distinct device categories.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1963856",
                    "name": "K. S. Esmaili"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "3283901",
                    "name": "P. L. Guyadec"
                }
            ]
        },
        {
            "paperId": "111025586722ca51334d30b906547cb84d56dc72",
            "title": "Taming the Android AppStore: Lightweight Characterization of Android Applications",
            "abstract": "There are over 1.2 million applications on the Google Play store today with a large number of competing applications for any given use or function. This creates challenges for users in selecting the right application. Moreover, some of the applications being of dubious origin, there are no mechanisms for users to understand who the applications are talking to, and to what extent. In our work, we first develop a lightweight characterization methodology that can automatically extract descriptions of application network behavior, and apply this to a large selection of applications from the Google App Store. We find several instances of overly aggressive communication with tracking websites, of excessive communication with ad related sites, and of communication with sites previously associated with malware activity. Our results underscore the need for a tool to provide users more visibility into the communication of apps installed on their mobile devices. To this end, we develop an Android application to do just this; our application monitors outgoing traffic, associates it with particular applications, and then identifies destinations in particular categories that we believe suspicious or else important to reveal to the end-user.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2253228",
                    "name": "Luigi Vigneri"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "2285687",
                    "name": "Ioannis Pefkianakis"
                },
                {
                    "authorId": "3039675",
                    "name": "Olivier Heen"
                }
            ]
        },
        {
            "paperId": "53ca21c1b83a27280ab63e532a43078e326de359",
            "title": "Characterizing home wireless performance: The gateway view",
            "abstract": "In this paper, we analyze a large dataset of passive wireless measurements and obtain insights about wireless performance. We monitor 167 homes continuously for 4 months from the vantage point of the gateway, which allows us to capture all the activity on the home wireless network. We report on the makeup of the home wireless network, traffic activity, and performance characteristics. We find that in most homes, a small number of devices account for most of the observed traffic volume and the bulk of this traffic activity occurs in the evenings. Studying link performance, we find that overall, the vast majority of transmissions are carried out at high data rates and the wireless networks have good coverage. We find a small number of episodes where performance is poor; a few homes have a disproportionate number of poor performance reports. Investigating further, we observe that most of these are not caused by poor coverage (pointing to network interference). Our results significantly add to the understanding of home wireless networks and will help ISPs to understand their subscriber networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2285687",
                    "name": "Ioannis Pefkianakis"
                },
                {
                    "authorId": "143735248",
                    "name": "Henrik Lundgren"
                },
                {
                    "authorId": "36912430",
                    "name": "Augustin Soule"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "3283901",
                    "name": "P. L. Guyadec"
                },
                {
                    "authorId": "1737360",
                    "name": "C. Diot"
                },
                {
                    "authorId": "46518232",
                    "name": "M. May"
                },
                {
                    "authorId": "2546848",
                    "name": "K. V. Doorselaer"
                },
                {
                    "authorId": "3205897",
                    "name": "K. V. Oost"
                }
            ]
        },
        {
            "paperId": "639700f9f05b3ca221e5abed10e1ea7647f3ca99",
            "title": "Characterizing mobile user habits: The case for energy budgeting",
            "abstract": "In this paper, we collect and analyze data from 85 smartphone users over a 9 month period. Different from existing work, we study device usage patterns in concert with network performance in space and time. Our results uncover predictable mobility patterns, where users are moving between hubs (i.e., home or workplace) and transit locations. In hubs, users are typically connected using Wi-Fi, while in transit locations cellular connectivity dominates with highly varying performance (from EDGE to HSPA+). Interestingly, there are set of apps over time running on user devices, independent of the location, network conditions, and device resources (e.g., battery level). These apps can aggressively use the network, which leads to significant device resource consumption (e.g., energy), as shown by our controlled experiments. We discuss how our findings can be used to budget mobile device available resources and improve user experience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3214936",
                    "name": "R. Sheshadri"
                },
                {
                    "authorId": "2285687",
                    "name": "Ioannis Pefkianakis"
                },
                {
                    "authorId": "143735248",
                    "name": "Henrik Lundgren"
                },
                {
                    "authorId": "2706303",
                    "name": "Dimitrios Koutsonikolas"
                },
                {
                    "authorId": "11585779",
                    "name": "Anna-Kaisa Pietilainen"
                },
                {
                    "authorId": "36912430",
                    "name": "Augustin Soule"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                }
            ]
        },
        {
            "paperId": "96cf3a7e9076e7e64cec7cbe653eed5d03fe6206",
            "title": "Quid Pro Quo: Reducing Peak Traffic Costs with (Subscriber) Price Incentives",
            "abstract": "<b>Motivation:</b> ISPs today are seeing unprecedented growth in residential broadband traffic volumes driven by the wide- spread popularity of video streaming services such as Net- flix, Hulu, Youtube and so on. This traffic explosion creates a need for (expensive) periodic network capacity upgrades and also increases transit costs paid to upstream providers. As a response, several ISPs started to impose time-of-day data caps, i.e., where per subscriber data usage limits are defined for particular periods of the day, e.g. BRC [USA] from 5pm-1am daily.While these have the effect of reducing traffic in busy periods (and hence costs), they also run the risk of alienating subscribers due their punitive nature. In this abstract, we propose an alternative mechanism where the ISP has a simple fixed monthly subscription price but also applies <i>price discounts</i> to influence subscribers to shift their traffic demands outside of the peak windows.\n <b>Cost Model:</b> Most ISPs size the network for peak demand and over-provision network <i>capacity</i> so that average utilization stays below a threshold <i>p</i>. Capacity upgrades are triggered by sustained, upward shifts in the peak traffic (denoted <i>P</i><sub>100</sub>). Hence, capacity cost can be assumed to scale proportionally to a rate factor <i>c</i> (\u03b5/Mbps) and <i>P</i><sub>100</sub>. The second cost component, transit, is charged based on the 95th percentile (denoted P<sub>95</sub>) of the transit traffic (computed over 5 minute windows in a month) and a committed price <i>r</i> (\u03b5 per Mbps). The actual fraction of transit traffic (<i>f</i>) depends greatly on several factors -- ISP size, geographic market, etc. For example, <i>f</i> ~ 0.3 in Japan, and <i>f</i> ~ 0.8 in Africa [1].\n <b>Utility Model:</b> Previous work has considered user utility to be a quadratic function of the monthly data usage [2]. In this abstract, we assume a general model where each subscriber may have different utility functions at different peak-time intervals. Hence, for a subscriber <i>k</i> that generates <i>w<sub>t</sub></i> amount of data (in bytes) in <i>t</i>, the total utility will be: <i>U<sub>k</sub></i>(w) = \u2211/<i>t</i> \u03b1<i><sub>kt</sub></i> \u2022 (<i>b<sub>kt</sub></i> \u2022 <i>w'<sub>t</sub></i> -- <i>w'</i><sup>2</sup><sub>t</sub>/2) (1) where <i>w'<sub>t</sub></i> = min v{<i>w<sub>t</sub></i>, <i>b<sub>kt</sub></i>} and \u03b1<i><sub>kt</sub></i>, <i>b<sub>kt</sub></i> are constants.\n <b>IncentiveMechanism:</b> The exact price discount is based on two values computed by the ISP in each interval t: (i) The implementation of the scientific publication is co-financed through the Project \"State Scholarships Foundation\" from the resources of the Operational Program \"Education & Lifelong Learning\", European Social Fund (ESF) and the NSRF, 2007-2013. The first author would like to acknowledge the \"Alexander S. Onassis\" Public Benefit Foundation, Greece for providing a scholarship. a data threshold D<sub>t</sub> \u2265 0 (in bytes) and (ii) a discount rate <i>pt</i> \u2265 0 (in \u03b5/byte). If the monthly data usage of <i>k</i> inside <i>t</i>, <i>d<sup>kt</sup></i>, is lower than <i>D<sup>t</sup></i>, <i>k</i> gets a discount <i>pt</i> \u2022 (<i>D<sup>t</sup></i>--<i>d<sup>kt</sup></i>). Then, <i>k</i> will adopt her behavior so that: Max/<i>d<sup>k</sup></i>\u22650 <i>U<sup>k</sup></i>(<i>d<sup>k</sup></i>) + \u2211<i>P<sup>t</sup></i> \u2022 (<i>D<sup>t</sup></i> ? <i>d<sup>kt</sup></i> (D, p))+ (2) where (.)+ = max(., 0). D, p and d<sup>k</sup> are the vectors 8t. We assume that the ISP can estimate the per subscriber daily traffic pattern and predict how it will change as a response to the incentives by solving the problem in (2). Then, the ISP will try to minimize the incentive and traffic costs: Min/D,p \u2211/<i>t</i>(<i>pt</i> \u2211(<i>D<sup>t</sup></i> -- <i>d<sub>kt</sub></i>(D, p))+) + <i>r</i> \u2022 <i>f</i> \u2022 P95 + c/? \u2022 P<sub>100</sub> (3) where P<sub>95</sub>, P<sub>100</sub> are the traffic percentiles after incentives.\n <b>Approximation:</b> The above problem is NP-Hard in general. The difficulty lies on the ordering in the objective function, which renders it non-continuous. Interestingly, the slightly different problem for which we are to minimize the weighted sum of all the percentile values from the 95th up to the 100th, is of lower complexity. Specifically, this problem can be solved by replacing the percentile terms with new optimization variables and adding a set of linear constraints [3]. The ISP can alternatively solve the above problem to get a solution close to the optimal one for the problem in (3).\n <b>Evaluation:</b> We applied the price incentives on a dataset of 223 subscribers of a European ISP measured in Dec. 2013. The ISP offers discounts only during the peak period of 6- 11pm, at 1 hour granularity. We set bkt to the total data usage of k in t in our dataset, and considered utility to be equal to the tariff price to find akt. We find evidence of tangible benefits to the ISP (up to 24% cost reduction), while the discounts varied from 0.08e - 1.45e per subscriber.\n <b>Conclusion:</b> The proposed mechanism does not mandate changes in behavior, but instead offers a quid-pro-quo to subscribers. In contrast to previous incentive mechanisms [4], [5], our scheme is designed requiring no dynamic traffic management and additional communication between the ISP and the subscribers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1781353",
                    "name": "Konstantinos Poularakis"
                },
                {
                    "authorId": "2285687",
                    "name": "Ioannis Pefkianakis"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "1705536",
                    "name": "L. Tassiulas"
                }
            ]
        },
        {
            "paperId": "c6bad18587cfbf62be967c11e6d9887fec3fe479",
            "title": "User-Driven Idle Energy Save for 802.11x Mobile Devices",
            "abstract": "Modern mobile devices are equipped with multiple network interfaces, with WiFi to be the preferred choice when it can be associated with an Access Point. Our study using real traces and experiments with 802.11 devices uncovers long idle times, while WiFi is scanning for networks and is listening for incoming traffic. During idle, WiFi consumes a significant amount of energy, which is exacerbated with the 802.11n/ac high speed features (MIMO, channel-bonding). State of the art power saving solutions, including the IEEE 802.11 PSM and SMPS features are user-agnostic, infrastructure-driven and oblivious to the power hungry 802.11n/ac features. As a result they may not save energy in practical settings. To this end, this work presents WiFi idle energy save (WiFi-ies). WiFi-ies leverages user context and behavior information to identify idle times where energy can be saved. We verify WiFi-ies energy savings using trace-driven simulations and prototype implementations on Android smartphones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2285687",
                    "name": "Ioannis Pefkianakis"
                },
                {
                    "authorId": "3195704",
                    "name": "J. Chandrashekar"
                },
                {
                    "authorId": "143735248",
                    "name": "Henrik Lundgren"
                }
            ]
        }
    ]
}