{
    "authorId": "2218469963",
    "papers": [
        {
            "paperId": "4dde239ece5fb0e01c60b8a40b25f21fd7f006b6",
            "title": "Algorithmic Drift: A Simulation Framework to Study the Effects of Recommender Systems on User Preferences",
            "abstract": "Digital platforms such as social media and e-commerce websites adopt Recommender Systems to provide value to the user. However, the social consequences deriving from their adoption are still unclear. Many scholars argue that recommenders may lead to detrimental effects, such as bias-amplification deriving from the feedback loop between algorithmic suggestions and users' choices. Nonetheless, the extent to which recommenders influence changes in users leaning remains uncertain. In this context, it is important to provide a controlled environment for evaluating the recommendation algorithm before deployment. To address this, we propose a stochastic simulation framework that mimics user-recommender system interactions in a long-term scenario. In particular, we simulate the user choices by formalizing a user model, which comprises behavioral aspects, such as the user resistance towards the recommendation algorithm and their inertia in relying on the received suggestions. Additionally, we introduce two novel metrics for quantifying the algorithm's impact on user preferences, specifically in terms of drift over time. We conduct an extensive evaluation on multiple synthetic datasets, aiming at testing the robustness of our framework when considering different scenarios and hyper-parameters setting. The experimental results prove that the proposed methodology is effective in detecting and quantifying the drift over the users preferences by means of the simulation. All the code and data used to perform the experiments are publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "2239521830",
                    "name": "Simone Mungari"
                },
                {
                    "authorId": "3128414",
                    "name": "E. Ritacco"
                },
                {
                    "authorId": "2304250921",
                    "name": "Francesco Fabbri"
                },
                {
                    "authorId": "2067355150",
                    "name": "Marco Minici"
                },
                {
                    "authorId": "2312324602",
                    "name": "Francesco Bonchi"
                },
                {
                    "authorId": "2062659381",
                    "name": "G. Manco"
                }
            ]
        },
        {
            "paperId": "c1943da4bb66534892d6dbc506dc6dfa1f9d723d",
            "title": "Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations",
            "abstract": "Providing recommendations that are both relevant and diverse is a key consideration of modern recommender systems. Optimizing both of these measures presents a fundamental trade-off, as higher diversity typically comes at the cost of relevance, resulting in lower user engagement. Existing recommendation algorithms try to resolve this trade-off by combining the two measures, relevance and diversity, into one aim and then seeking recommendations that optimize the combined objective, for a given number of items to recommend. Traditional approaches, however, do not consider the user interaction with the recommended items. In this paper, we put the user at the central stage, and build on the interplay between relevance, diversity, and user behavior. In contrast to applications where the goal is solely to maximize engagement, we focus on scenarios aiming at maximizing the total amount of knowledge encountered by the user. We use diversity as a surrogate of the amount of knowledge obtained by the user while interacting with the system, and we seek to maximize diversity. We propose a probabilistic user-behavior model in which users keep interacting with the recommender system as long as they receive relevant recommendations, but they may stop if the relevance of the recommended items drops. Thus, for a recommender system to achieve a high-diversity measure, it will need to produce recommendations that are both relevant and diverse. Finally, we propose a novel recommendation strategy that combines relevance and diversity by a copula function. We conduct an extensive evaluation of the proposed methodology over multiple datasets, and we show that our strategy outperforms several state-of-the-art competitors. Our implementation is publicly available at https://github.com/EricaCoppolillo/EXPLORE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "2313479443",
                    "name": "Giuseppe Manco"
                },
                {
                    "authorId": "1682878",
                    "name": "A. Gionis"
                }
            ]
        },
        {
            "paperId": "ce8b7b0118f972892b43648e85613009af14906f",
            "title": "GenRec: A Flexible Data Generator for Recommendations",
            "abstract": "The scarcity of realistic datasets poses a significant challenge in benchmarking recommender systems and social network analysis methods and techniques. A common and effective solution is to generate synthetic data that simulates realistic interactions. However, although various methods have been proposed, the existing literature still lacks generators that are fully adaptable and allow easy manipulation of the underlying data distributions and structural properties. To address this issue, the present work introduces GenRec, a novel framework for generating synthetic user-item interactions that exhibit realistic and well-known properties observed in recommendation scenarios. The framework is based on a stochastic generative process based on latent factor modeling. Here, the latent factors can be exploited to yield long-tailed preference distributions, and at the same time they characterize subpopulations of users and topic-based item clusters. Notably, the proposed framework is highly flexible and offers a wide range of hyper-parameters for customizing the generation of user-item interactions. The code used to perform the experiments is publicly available at https://anonymous.4open.science/r/GenRec-DED3.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "2239521830",
                    "name": "Simone Mungari"
                },
                {
                    "authorId": "3128414",
                    "name": "E. Ritacco"
                },
                {
                    "authorId": "2062659381",
                    "name": "G. Manco"
                }
            ]
        },
        {
            "paperId": "dec985ebbf14c19ad686b3487499a176e3cef1ed",
            "title": "Balanced Quality Score (BQS): Measuring Popularity Debiasing in Recommendation",
            "abstract": "Popularity bias is the tendency of recommender systems to further suggest popular items while disregarding niche ones, hence giving no chance for items with low popularity to emerge. Although the literature is rich in debiasing techniques, it still lacks quality measures that effectively enable their analyses and comparisons. In this paper, we first introduce a formal, data-driven, and parameter-free strategy for classifying items into low, medium, and high popularity categories. Then we introduce BQS, a quality measure that rewards the debiasing techniques that successfully push a recommender system to suggest niche items, without losing points in its predictive capability in terms of global accuracy. We conduct tests of BQS on three distinct baseline collaborative filtering (CF) frameworks: one based on history-embedding and two on user/item-embedding modeling. These evaluations are performed on multiple benchmark datasets and against various state-of-the-art competitors, demonstrating the effectiveness of BQS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "2067355150",
                    "name": "Marco Minici"
                },
                {
                    "authorId": "3128414",
                    "name": "E. Ritacco"
                },
                {
                    "authorId": "2289407682",
                    "name": "Luciano Caroprese"
                },
                {
                    "authorId": "1708290",
                    "name": "F. S. Pisani"
                },
                {
                    "authorId": "2062659381",
                    "name": "G. Manco"
                }
            ]
        },
        {
            "paperId": "f6f7b3687c60ddc4097b42bd7adf8cc143a38e2a",
            "title": "LLASP: Fine-tuning Large Language Models for Answer Set Programming",
            "abstract": "Recently, Large Language Models (LLMs) have showcased their potential in various natural language processing tasks, including code generation. However, while significant progress has been made in adapting LLMs to generate code for several imperative programming languages and tasks, there remains a notable gap in their application to declarative formalisms, such as Answer Set Programming (ASP). In this paper, we move a step towards exploring the capabilities of LLMs for ASP code generation. First, we perform a systematic evaluation of several state-of-the-art LLMs. Despite their power in terms of number of parameters, training data and computational resources, empirical results demonstrate inadequate performances in generating correct ASP programs. Therefore, we propose LLASP, a fine-tuned lightweight model specifically trained to encode fundamental ASP program patterns. To this aim, we create an ad-hoc dataset covering a wide variety of fundamental problem specifications that can be encoded in ASP. Our experiments demonstrate that the quality of ASP programs generated by LLASP is remarkable. This holds true not only when compared to the non-fine-tuned counterpart but also when compared to the majority of eager LLM candidates, particularly from a semantic perspective. All the code and data used to perform the experiments are publicly available at https://anonymous.4open.science/r/LLASP-D86C/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "1748306",
                    "name": "Francesco Calimeri"
                },
                {
                    "authorId": "2313479443",
                    "name": "Giuseppe Manco"
                },
                {
                    "authorId": "9950515",
                    "name": "S. Perri"
                },
                {
                    "authorId": "2272369466",
                    "name": "Francesco Ricca"
                }
            ]
        },
        {
            "paperId": "04e5ac28a1a51921874f19972633192bb4370830",
            "title": "Fighting Misinformation, Radicalization and Bias in Social Media",
            "abstract": "Social media have become the ideal place for black hats and malicious individuals to target susceptible users through different attack vectors and then manipulate their opinions and interests. Fake news, radicalization, and pushing bias into the data represent some popular ways noxious users adopt to perpetrate their criminal intents. In this evolving scenario, Artificial Intelligence techniques represent a valuable tool to early detect and mitigate the risk due to the spreading of these emerging attacks. In this work, we describe the Machine Learning based solutions developed to address the problems mentioned above and our current research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "1685160",
                    "name": "C. Comito"
                },
                {
                    "authorId": "2067355150",
                    "name": "Marco Minici"
                },
                {
                    "authorId": "3128414",
                    "name": "E. Ritacco"
                },
                {
                    "authorId": "1722716",
                    "name": "G. Folino"
                },
                {
                    "authorId": "1708290",
                    "name": "F. S. Pisani"
                },
                {
                    "authorId": "2239220647",
                    "name": "Massimo Guarascio"
                },
                {
                    "authorId": "2062659381",
                    "name": "G. Manco"
                }
            ]
        },
        {
            "paperId": "4dfeebe0539c5344bf9b2d1c0d038ae7b2431c2d",
            "title": "Exploiting Deep Learning and Explanation Methods for Movie Tag Prediction",
            "abstract": "Indexing multimedia content with rich and accurate metadata allows for improving the quality of the search engines\u2019 results and boosting the recommender systems performances, which can benefit from this information to yield more effective recommendation lists. Therefore, the adoption of tools able to automatically label multimedia content with informative tags represents an important task for all the companies offering streaming entertainment services. However, domain experts generally perform the tagging process manually, making it time-consuming and error-prone. In the last few years, Machine Learning techniques have been proposed as a promising solution to automate this type of task, but the lack of clean and labeled training data hinders the learning of robust classification models. To cope with the issues described above, in this work, we devised a Deep Learning based solution for semi-automatic multi-label classification integrating post-hoc explanation techniques. Specifically, model explanation methods are exploited to assist the operator in the labeling process by facilitating an understanding of the model predictions. The proposed approach has been validated on a real dataset, and the experimental results demonstrate its effectiveness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "1794971",
                    "name": "M. Guarascio"
                },
                {
                    "authorId": "2067355150",
                    "name": "Marco Minici"
                },
                {
                    "authorId": "1708290",
                    "name": "F. S. Pisani"
                }
            ]
        },
        {
            "paperId": "a5b28000a0e5a410164148a3d4d86df9d5749462",
            "title": "Towards Self-Supervised Cross-Domain Fake News Detection",
            "abstract": "Twitter, Facebook, and Instagram are just some examples of social media currently used by people to share news with other users worldwide. However, the information widespread through these channels is typically unverified and/or interpreted according to the user\u2019s point of view. Accordingly, those means represent the perfect tool to hack user opinions with misleading or false news and make fake news viral. Identifying this malicious information is a crucial but challenging task since fake news can concern different topics. Indeed, the detection models learned against a specific domain will exhibit poor performances when tested on a different one. In this work, we propose a novel deep learning-based architecture able to mitigate this problem by yielding cross-domain high-level features for addressing this task. Preliminary experimentation conducted on two benchmarks demonstrated the validity of the proposed solution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1685160",
                    "name": "C. Comito"
                },
                {
                    "authorId": "1708290",
                    "name": "F. S. Pisani"
                },
                {
                    "authorId": "2218469963",
                    "name": "Erica Coppolillo"
                },
                {
                    "authorId": "1659064160",
                    "name": "Angelica Liguori"
                },
                {
                    "authorId": "2239220647",
                    "name": "Massimo Guarascio"
                },
                {
                    "authorId": "1718485",
                    "name": "G. Manco"
                }
            ]
        }
    ]
}