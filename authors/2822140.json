{
    "authorId": "2822140",
    "papers": [
        {
            "paperId": "67df4fd2dd28b7c6356b2dddd9dc934d45aad119",
            "title": "Attention-Based Cloth Manipulation from Model-free Topological Representation",
            "abstract": "The robotic manipulation of deformable objects, such as clothes and fabric, is known as a complex task from both the perception and planning perspectives. Indeed, the stochastic nature of the underlying environment dynamics makes it an interesting research field for statistical learning approaches and neural policies. In this work, we introduce a novel attention-based neural architecture capable of solving a smoothing task for such objects by means of a single robotic arm. To train our network, we leverage an oracle policy, executed in simulation, which uses the topological description of a mesh of points for representing the object to smooth. In a second step, we transfer the resulting behavior in the real world with imitation learning using the cloth point cloud as decision support, which is captured from a single RGBD camera placed egocentrically on the wrist of the arm. This approach allows fast training of the real-world manipulation neural policy while not requiring scene reconstruction at test time, but solely a point cloud acquired from a single RGBD camera. Our resulting policy first predicts the desired point to choose from the given point cloud and then the correct displacement to achieve a smoothed cloth. Experimentally, we first assess our results in a simulation environment by comparing them with an existing heuristic policy, as well as several baseline attention architectures. Then, we validate the performance of our approach in a real-world scenario. Project website: link",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120201236",
                    "name": "Kevin Galassi"
                },
                {
                    "authorId": "2282346456",
                    "name": "Bingbing Wu"
                },
                {
                    "authorId": "2282413160",
                    "name": "Julien Perez"
                },
                {
                    "authorId": "2315505803",
                    "name": "Gianluca Palli"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                }
            ]
        },
        {
            "paperId": "e0817781261f075fca19aa5eac370b689eb90c43",
            "title": "SLIM: Skill Learning with Multiple Critics",
            "abstract": "Self-supervised skill learning aims to acquire useful behaviors that leverage the underlying dynamics of the environment. Latent variable models, based on mutual information maximization, have been successful in this task but still struggle in the context of robotic manipulation. As it requires impacting a possibly large set of degrees of freedom composing the environment, mutual information maximization fails alone in producing useful and safe manipulation behaviors. Furthermore, tackling this by augmenting skill discovery rewards with additional rewards through a naive combination might fail to produce desired behaviors. To address this limitation, we introduce SLIM, a multi-critic learning approach for skill discovery with a particular focus on robotic manipulation. Our main insight is that utilizing multiple critics in an actor-critic framework to gracefully combine multiple reward functions leads to a significant improvement in latent-variable skill discovery for robotic manipulation while overcoming possible interference occurring among rewards which hinders convergence to useful skills. Furthermore, in the context of tabletop manipulation, we demonstrate the applicability of our novel skill discovery approach to acquire safe and efficient motor primitives in a hierarchical reinforcement learning fashion and leverage them through planning, significantly surpassing baseline approaches for skill discovery.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139659552",
                    "name": "David Emukpere"
                },
                {
                    "authorId": "2282346456",
                    "name": "Bingbing Wu"
                },
                {
                    "authorId": "2282413160",
                    "name": "Julien Perez"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                }
            ]
        },
        {
            "paperId": "e39f1145104943cf26a27dc049db56c0f79f19ba",
            "title": "Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset",
            "abstract": "Unbiased learning-to-rank (ULTR) is a well-established framework for learning from user clicks, which are often biased by the ranker collecting the data. While theoretically justified and extensively tested in simulation, ULTR techniques lack empirical validation, especially on modern search engines. The Baidu-ULTR dataset released for the WSDM Cup 2023, collected from Baidu's search engine, offers a rare opportunity to assess the real-world performance of prominent ULTR techniques. Despite multiple submissions during the WSDM Cup 2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether the observed improvements stem from applying ULTR or other learning techniques. In this work, we revisit and extend the available experiments on the Baidu-ULTR dataset. We find that standard unbiased learning-to-rank techniques robustly improve click predictions but struggle to consistently improve ranking performance, especially considering the stark differences obtained by choice of ranking loss and query-document features. Our experiments reveal that gains in click prediction do not necessarily translate to enhanced ranking performance on expert relevance annotations, implying that conclusions strongly depend on how success is measured in this benchmark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280674756",
                    "name": "Philipp Hager"
                },
                {
                    "authorId": "2189225090",
                    "name": "Romain Deffayet"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "1769092",
                    "name": "O. Zoeter"
                },
                {
                    "authorId": "2265490493",
                    "name": "M. D. Rijke"
                }
            ]
        },
        {
            "paperId": "78486d4d1eecfac46e4a24efd02d5aefae84a9b9",
            "title": "SARDINE: A Simulator for Automated Recommendation in Dynamic and Interactive Environments",
            "abstract": "Simulators can provide valuable insights for researchers and practitioners who wish to improve recommender systems, because they allow one to easily tweak the experimental setup in which recommender systems operate, and as a result lower the cost of identifying general trends and uncovering novel findings about the candidate methods. A key requirement to enable this accelerated improvement cycle is that the simulator is able to span the various sources of complexity that can be found in the real recommendation environment that it simulates. With the emergence of interactive and data-driven methods \u2013 e.g., reinforcement learning or online and counterfactual learning-to-rank \u2013 that aim to achieve user-related goals beyond the traditional accuracy-centric objectives, adequate simulators are needed. In particular, such simulators must model the various mechanisms that render the recommendation environment dynamic and interactive, e.g., the effect of recommendations on the user or the effect of biased data on subsequent iterations of the recommender system. We therefore propose simulator for automated recommendation in dynamic and interactive environments, a flexible and interpretable recommendation simulator that can help accelerate research in interactive and data-driven recommender systems. We demonstrate its usefulness by studying existing methods within nine diverse environments derived from SARDINE, and even uncover novel insights about them.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189225090",
                    "name": "Romain Deffayet"
                },
                {
                    "authorId": "2955690",
                    "name": "Thibaut Thonet"
                },
                {
                    "authorId": "2268493230",
                    "name": "Dongyoon Hwang"
                },
                {
                    "authorId": "46240914",
                    "name": "Vassilissa Lehoux"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "2265490493",
                    "name": "M. D. Rijke"
                }
            ]
        },
        {
            "paperId": "b9b453fba8a7252ad34c74d93eaec6670475e9e6",
            "title": "An Offline Metric for the Debiasedness of Click Models",
            "abstract": "A well-known problem when learning from user clicks are inherent biases prevalent in the data, such as position or trust bias. Click models are a common method for extracting information from user clicks, such as document relevance in web search, or to estimate click biases for downstream applications such as counterfactual learning-to-rank, ad placement, or fair ranking. Recent work shows that the current evaluation practices in the community fail to guarantee that a well-performing click model generalizes well to downstream tasks in which the ranking distribution differs from the training distribution, i.e., under covariate shift. In this work, we propose an evaluation metric based on conditional independence testing to detect a lack of robustness to covariate shift in click models. We introduce the concept of debiasedness and a metric for measuring it. We prove that debiasedness is a necessary condition for recovering unbiased and consistent relevance scores and for the invariance of click prediction under covariate shift. In extensive semi-synthetic experiments, we show that our proposed metric helps to predict the downstream performance of click models under covariate shift and is useful in an off-policy model selection setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189225090",
                    "name": "Romain Deffayet"
                },
                {
                    "authorId": "2066021785",
                    "name": "Philipp Hager"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "1696030",
                    "name": "M. de Rijke"
                }
            ]
        },
        {
            "paperId": "c71c72e29c8e5b1e0a32fc90d24bdc66726c3d24",
            "title": "Distributional Reinforcement Learning with Dual Expectile-Quantile Regression",
            "abstract": "Distributional reinforcement learning (RL) has proven useful in multiple benchmarks as it enables approximating the full distribution of returns and makes a better use of environment samples. The commonly used quantile regression approach to distributional RL -- based on asymmetric $L_1$ losses -- provides a flexible and effective way of learning arbitrary return distributions. In practice, it is often improved by using a more efficient, hybrid asymmetric $L_1$-$L_2$ Huber loss for quantile regression. However, by doing so, distributional estimation guarantees vanish, and we empirically observe that the estimated distribution rapidly collapses to its mean. Indeed, asymmetric $L_2$ losses, corresponding to expectile regression, cannot be readily used for distributional temporal difference learning. Motivated by the efficiency of $L_2$-based learning, we propose to jointly learn expectiles and quantiles of the return distribution in a way that allows efficient learning while keeping an estimate of the full distribution of returns. We prove that our approach approximately learns the correct return distribution, and we benchmark a practical implementation on a toy example and at scale. On the Atari benchmark, our approach matches the performance of the Huber-based IQN-1 baseline after $200$M training frames but avoids distributional collapse and keeps estimates of the full distribution of returns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130153188",
                    "name": "Sami Jullien"
                },
                {
                    "authorId": "2189225090",
                    "name": "Romain Deffayet"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "2297217789",
                    "name": "Paul Groth"
                },
                {
                    "authorId": "2265490493",
                    "name": "M. D. Rijke"
                }
            ]
        },
        {
            "paperId": "6b4da09ff5280e274b295f01f6ccf6994d34b06b",
            "title": "Introducing the Expohedron for Efficient Pareto-optimal Fairness-Utility Amortizations in Repeated Rankings",
            "abstract": "We consider the problem of computing a sequence of rankings that maximizes consumer-side utility while minimizing producer-side individual unfairness of exposure. While prior work has addressed this problem using linear or quadratic programs on bistochastic matrices, such approaches, relying on Birkhoff-von Neumann (BvN) decompositions, are too slow to be implemented at large scale. In this paper we introduce a geometrical object, a polytope that we call expohedron, whose points represent all achievable exposures of items for a Position Based Model (PBM). We exhibit some of its properties and lay out a Carath\u00e9odory decomposition algorithm with complexity $O(n^2\u0142og(n))$ able to express any point inside the expohedron as a convex sum of at most n vertices, where n is the number of items to rank. Such a decomposition makes it possible to express any feasible target exposure as a distribution over at most n rankings. Furthermore we show that we can use this polytope to recover the whole Pareto frontier of the multi-objective fairness-utility optimization problem, using a simple geometrical procedure with complexity $O(n^2\u0142og(n))$. Our approach compares favorably to linear or quadratic programming baselines in terms of algorithmic complexity and empirical runtime and is applicable to any merit that is a non-decreasing function of item relevance. Furthermore our solution can be expressed as a distribution over only $\\ndoc$ permutations, instead of the $(n-1)^2 + 1$ achieved with BvN decompositions. We perform experiments on synthetic and real-world datasets, confirming our theoretical results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2088932557",
                    "name": "Till Kletti"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "143710789",
                    "name": "P. Loiseau"
                }
            ]
        },
        {
            "paperId": "9490e5dd729a0f7b3e4dd7dd0e206433d327b344",
            "title": "Offline Evaluation for Reinforcement Learning-Based Recommendation",
            "abstract": "In this paper, we argue that the paradigm commonly adopted for offline evaluation of sequential recommender systems is unsuitable for evaluating reinforcement learning-based recommenders. We find that most of the existing offline evaluation practices for reinforcement learning-based recommendation are based on a next-item prediction protocol, and detail three shortcomings of such an evaluation protocol. Notably, it cannot reflect the potential benefits that reinforcement learning (RL) is expected to bring while it hides critical deficiencies of certain offline RL agents. Our suggestions for alternative ways to evaluate RL-based recommender systems aim to shed light on the existing possibilities and inspire future research on reliable evaluation protocols.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189225090",
                    "name": "Romain Deffayet"
                },
                {
                    "authorId": "2955690",
                    "name": "Thibaut Thonet"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "1696030",
                    "name": "M. de Rijke"
                }
            ]
        },
        {
            "paperId": "a890ecfa2eb8b5db0e47fd5e5562b35f92f5220e",
            "title": "Listwise Learning to Rank Based on Approximate Rank Indicators",
            "abstract": "We study here a way to approximate information retrieval metrics through a softmax-based approximation of the rank indicator function. Indeed, this latter function is a key component in the design of information retrieval metrics, as well as in the design of the ranking and sorting functions. Obtaining a good approximation for it thus opens the door to differentiable approximations of many evaluation measures that can in turn be used in neural end-to-end approaches. We first prove theoretically that the approximations proposed are of good quality, prior to validate them experimentally on both learning to rank and text-based information retrieval tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2955690",
                    "name": "Thibaut Thonet"
                },
                {
                    "authorId": "2562951",
                    "name": "Yagmur Gizem Cinar"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": null,
                    "name": "Minghan Li"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                }
            ]
        },
        {
            "paperId": "ce4549ace17f32be403262cc8915c51fd9e37dac",
            "title": "Pareto-Optimal Fairness-Utility Amortizations in Rankings with a DBN Exposure Model",
            "abstract": "In recent years, it has become clear that rankings delivered in many areas need not only be useful to the users but also respect fairness of exposure for the item producers. We consider the problem of finding ranking policies that achieve a Pareto-optimal tradeoff between these two aspects. Several methods were proposed to solve it; for instance a popular one is to use linear programming with a Birkhoff-von Neumann decomposition. These methods, however, are based on a classical Position Based exposure Model (PBM), which assumes independence between the items (hence the exposure only depends on the rank). In many applications, this assumption is unrealistic and the community increasingly moves towards considering other models that include dependences, such as the Dynamic Bayesian Network (DBN) exposure model. For such models, computing (exact) optimal fair ranking policies remains an open question. In this paper, we answer this question by leveraging a new geometrical method based on the so-called expohedron proposed recently for the PBM (Kletti et al., WSDM'22). We lay out the structure of a new geometrical object (the DBN-expohedron), and propose for it a Carath\u00e9odory decomposition algorithm of complexity $O(n^3)$, where n is the number of documents to rank. Such an algorithm enables expressing any feasible expected exposure vector as a distribution over at most n rankings; furthermore we show that we can compute the whole set of Pareto-optimal expected exposure vectors with the same complexity $O(n^3)$. Our work constitutes the first exact algorithm able to efficiently find a Pareto-optimal distribution of rankings. It is applicable to a broad range of fairness notions, including classical notions of meritocratic and demographic fairness. We empirically evaluate our method on the TREC2020 and MSLR datasets and compare it to several baselines in terms of Pareto-optimality and speed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2088932557",
                    "name": "Till Kletti"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                },
                {
                    "authorId": "143710789",
                    "name": "P. Loiseau"
                }
            ]
        }
    ]
}