{
    "authorId": "31938009",
    "papers": [
        {
            "paperId": "130528e119f0d17dedfecb82fb85af9c05b5e231",
            "title": "Characterizing and Verifying Queries Via CINSGEN",
            "abstract": "Example database instances can be very helpful in understanding complex queries. Different examples may illustrate alternative situations in which answers emerge in the query results and can be useful for testing. Examples can also help reveal semantic differences between queries that are supposed to be equivalent, e.g., when students try to understand how their queries behave differently from a reference solution, or when programmers try to pinpoint mistakes inadvertently introduced by rewrites meant to improve readability or performance. In this paper, we propose to demonstrate CinsGen, a system that can characterize queries and help distinguish between two queries. Given a query, CinsGen generates minimal conditional instances (c-instances) that satisfy it. In turn, each c-instance is a generalization of multiple database instances, yielding a compact representation. Thus, using CinsGen enables users to obtain a comprehensive and compact view of all scenarios that satisfy a specified query, allowing for query characterization or distinction between two queries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2168549534",
                    "name": "Hanze Meng"
                },
                {
                    "authorId": "2594274",
                    "name": "Zhengjie Miao"
                },
                {
                    "authorId": "32466098",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "2845918",
                    "name": "Jun Yang"
                }
            ]
        },
        {
            "paperId": "6464b5c1896852d66c419d9c09e2fbaff007829e",
            "title": "A Double Machine Learning Approach to Combining Experimental and Observational Data",
            "abstract": "Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one of these assumptions is violated, we provide semiparametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. Through comparative analyses, we show our framework's superiority over existing data fusion methods. The practical utility of our approach is further exemplified by three real-world case studies, underscoring its potential for widespread application in empirical research.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "72588620",
                    "name": "Marco Morucci"
                },
                {
                    "authorId": "1515535466",
                    "name": "Vittorio Orlandi"
                },
                {
                    "authorId": "144881140",
                    "name": "Harsh Parikh"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "2060638599",
                    "name": "C. Rudin"
                },
                {
                    "authorId": "6974508",
                    "name": "A. Volfovsky"
                }
            ]
        },
        {
            "paperId": "66063ac227bc5be831b6d1f102153ef87d68691c",
            "title": "Seventh Workshop on Human-In-the-Loop Data Analytics (HILDA)",
            "abstract": "HILDA brings together researchers and practitioners to exchange ideas and results on human-data interaction. It explores how data management and analysis can be made more effective when taking into account the people who design and build these processes as well as those who are impacted by their results. Following last year, we plan to continue to focus on this year's workshop on early-stage research that is promising and exciting. A core part of this plan is that every paper gets a mentor. The theme for this edition of the workshop is commodifying human-in-the-loop data analytics, i.e., making systems ready for end-user consumption. However, the workshop is not limited to this theme and other topics are also of interest. In this summary, we describe the workshop, its main focus areas and our review and mentorship plan.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1714104",
                    "name": "Dominik Moritz"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                }
            ]
        },
        {
            "paperId": "b3456b149cd24723d4c4616984d8a32e5b0082ea",
            "title": "Causal What-If and How-To Analysis Using HypeR",
            "abstract": "What-if and How-to queries are fundamental data analysis questions that provide insights about the effects of a hypothetical update without actually making changes to the database. Traditional systems assume independence across differ\u00acent tuples and non-updated attributes of the database. However, different attributes and tuples are generally dependent in real-world scenarios. We propose to demonstrate HypeR, a novel system to efficiently answer what-if and how-to queries while capturing causal dependencies among different attributes and tuples in the database. To compute the results, HypeR leverages a suite of optimizations along with techniques from causal inference to effectively estimate the answers. HypeR allows users to formulate complex hypothetical queries by using a novel SQL-like syntax and presents the output as interactive visualizations that can be explored and analyzed with ease.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2224943200",
                    "name": "Fangzhu Shen"
                },
                {
                    "authorId": "2224955839",
                    "name": "Kayvon Heravi"
                },
                {
                    "authorId": "2224953752",
                    "name": "Oscar Gomez"
                },
                {
                    "authorId": "2663974",
                    "name": "Sainyam Galhotra"
                },
                {
                    "authorId": "32466098",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "2124624117",
                    "name": "Babak Salimi"
                }
            ]
        },
        {
            "paperId": "009f9a2fdc25cc6146ff164ecf82431606380873",
            "title": "CaJaDE: Explaining Query Results by Augmenting Provenance with Context",
            "abstract": "\n In this work, we demonstrate CaJaDE (Context-Aware Join-Augmented Deep Explanations), a system that explains query results by augmenting provenance with contextual information from other related tables in the database. Given two query results whose difference the user wants to understand, we enumerate possible ways of joining the\n provenance\n (i.e., contributing input tuples) of these two query results with tuples from other relevant tables in the database that were\n not\n used in the query. We use patterns to concisely explain the difference between the\n augmented provenance\n of the two query results. CaJaDE, through a comprehensive UI, enables the user to formulate questions and explore explanations interactively.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109338011",
                    "name": "Chenjie Li"
                },
                {
                    "authorId": "2108303061",
                    "name": "Juseung Lee"
                },
                {
                    "authorId": "2594274",
                    "name": "Zhengjie Miao"
                },
                {
                    "authorId": "1798930",
                    "name": "Boris Glavic"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                }
            ]
        },
        {
            "paperId": "04309abfc8b361147adb64794c7737611bf29356",
            "title": "Understanding Queries by Conditional Instances",
            "abstract": "A powerful way to understand a complex query is by observing how it operates on data instances. However, specific database instances are not ideal for such observations: they often include large amounts of superfluous details that are not only irrelevant to understanding the query but also cause cognitive overload; and one specific database may not be enough. Given a relational query, is it possible to provide a simple and generic \"representative'' instance that (1) illustrates how the query can be satisfied, (2) summarizes all specific instances that would satisfy the query in the same way by abstracting away unnecessary details? Furthermore, is it possible to find a collection of such representative instances that together completely characterize all possible ways in which the query can be satisfied? This paper takes initial steps towards answering these questions. We design what these representative instances look like, define what they stand for, and formalize what it means for them to satisfy a query in \"all possible ways.\" We argue that this problem is undecidable for general domain relational calculus queries, and develop practical algorithms for computing a minimum collection of such instances subject to other constraints. We evaluate the efficiency of our approach experimentally, and show its effectiveness in helping users debug relational queries through a user study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32466098",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "2594274",
                    "name": "Zhengjie Miao"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "9125547",
                    "name": "Jun Yang"
                }
            ]
        },
        {
            "paperId": "0f36ecdd1ad4118af8c48bcf4dd09e9808c493a2",
            "title": "DPXPlain: Privately Explaining Aggregate Query Answers",
            "abstract": "Differential privacy (DP) is the state-of-the-art and rigorous notion of privacy for answering aggregate database queries while preserving the privacy of sensitive information in the data. In today's era of data analysis, however, it poses new challenges for users to understand the trends and anomalies observed in the query results: Is the unexpected answer due to the data itself, or is it due to the extra noise that must be added to preserve DP? In the second case, even the observation made by the users on query results may be wrong. In the first case, can we still mine interesting explanations from the sensitive data while protecting its privacy? To address these challenges, we present a three-phase framework DPXPlain, which is the first system to the best of our knowledge for explaining group-by aggregate query answers with DP. In its three phases, DPXPlain (a) answers a group-by aggregate query with DP, (b) allows users to compare aggregate values of two groups and with high probability assesses whether this comparison holds or is flipped by the DP noise, and (c) eventually provides an explanation table containing the approximately 'top-k' explanation predicates along with their relative influences and ranks in the form of confidence intervals, while guaranteeing DP in all steps. We perform an extensive experimental analysis of DPXPlain with multiple use-cases on real and synthetic data showing that DPXPlain efficiently provides insightful explanations with good accuracy and utility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66262276",
                    "name": "Yuchao Tao"
                },
                {
                    "authorId": "32466098",
                    "name": "Amir Gilad"
                },
                {
                    "authorId": "2357165",
                    "name": "Ashwin Machanavajjhala"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                }
            ]
        },
        {
            "paperId": "30d74ceaab5d5e0451c7ff9057792cb6464b8b57",
            "title": "Toward Interpretable and Actionable Data Analysis with Explanations and Causality",
            "abstract": "\n We live in a world dominated by data, where users from different fields routinely collect, study, and make decisions supported by data. To aid these users, the current trend in data analysis is to design tools that allow large-scale analytics, sophisticated predictive models, and beautiful visualizations. At this exciting time when both data and analytics tools are widely accessible to users, treating analyses as magical black boxes can painfully mislead users and make troubleshooting frustratingly time-consuming. For instance, although the perils of interpreting correlations inferred by predictive models as causation are well-documented, making such a distinction can be tricky for many users who do not have formal training in computer science or statistics. In this paper, we give an overview of our research toward bridging this gap along two main thrusts of\n explanations\n and\n causality.\n Explanations support a primary goal of data analysis - empowering users to be able to interpret the results in data analysis and troubleshoot the process. Causality complements explanations by supporting prescriptive or actionable analytics with counterfactuals and interventions, thereby helping sound decision making. In these thrusts, we explore the symbiotic relationship between core database techniques and complementary techniques from machine learning and statistics via interdisciplinary collaborations, and employ them to applications in domains like computer science education, law, and health.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                }
            ]
        },
        {
            "paperId": "3a9ea02441c6030c6fa3788c0ba8bfee22eb1bb0",
            "title": "Selectivity Functions of Range Queries are Learnable",
            "abstract": "This paper explores the use of machine learning for estimating the selectivity of range queries in database systems. Using classic learning theory for real-valued functions based on shattering dimension, we show that the selectivity function of a range space with bounded VC-dimension is learnable. As many popular classes of queries (e.g., orthogonal range search, inequalities involving linear combination of attributes, distance-based search, etc.) represent range spaces with finite VC-dimension, our result immediately implies that their selectivity functions are also learnable. To the best of our knowledge, this is the first attempt at formally explaining the role of machine learning techniques in selectivity estimation, and complements the growing literature in empirical studies in this direction. Supplementing these theoretical results, our experimental results demonstrate that, empirically, even a basic learning algorithm with generic models is able to produce accurate predictions across settings, matching state-of-art methods designed for specific queries, and using training sample sizes commensurate with our theory.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218084191",
                    "name": "Xiao Hu"
                },
                {
                    "authorId": "2108135900",
                    "name": "Yuxi Liu"
                },
                {
                    "authorId": "2165740958",
                    "name": "Haibo Xiu"
                },
                {
                    "authorId": "1705077",
                    "name": "P. Agarwal"
                },
                {
                    "authorId": "1715972",
                    "name": "Debmalya Panigrahi"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "2845918",
                    "name": "Jun Yang"
                }
            ]
        },
        {
            "paperId": "99f7ca909934a74825b7a13a35af3f4f77da69bb",
            "title": "I-Rex: An Interactive Relational Query Debugger for SQL",
            "abstract": "Despite the enduring popularity of SQL (Structured Query Language), it is challenging to learn and debug, even for people with considerable programming experience. There is also a lack of SQL tools with advanced debugger features like breakpoints, stepped execution, and variable watching. We present I-Rex, an interactive SQL debugger that enables users to trace the evaluation of a query by its constituent blocks, visualizing how each block computes results from its inputs, and exploring the dependencies among these blocks. I-Rex can be integrated into an autograder, which typically works by comparing the results of submitted queries against reference queries over test database instances. Instead of showing full test instances, which often overwhelm students, I-Rex automatically generates small, illustrative instances for debugging. In this demo, we show how I-Rex helps a student trace complex SQL query execution, learn the semantics of various query constructs, and understand why a query produces (or does not produce) certain results. We also show how a teacher can customize I-Rex for a set of SQL exercises over a database. Overall, we demonstrate how I-Rex supports SQL learning and debugging, thereby increasing students' self-reliance and reducing the burden on the teaching staff.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3423867",
                    "name": "Yihao Hu"
                },
                {
                    "authorId": "2594274",
                    "name": "Zhengjie Miao"
                },
                {
                    "authorId": "2155663949",
                    "name": "Zhiming Leong"
                },
                {
                    "authorId": "2155815051",
                    "name": "Haechan Lim"
                },
                {
                    "authorId": "2156351581",
                    "name": "Zachary Zheng"
                },
                {
                    "authorId": "31938009",
                    "name": "Sudeepa Roy"
                },
                {
                    "authorId": "1405619995",
                    "name": "Kristin Stephens-Martinez"
                },
                {
                    "authorId": "2845918",
                    "name": "Jun Yang"
                }
            ]
        }
    ]
}