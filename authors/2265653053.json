{
    "authorId": "2265653053",
    "papers": [
        {
            "paperId": "232b0b6694f799f825fb2b191b28c439ff52ae6f",
            "title": "Error-margin Analysis for Hidden Neuron Activation Labels",
            "abstract": "Understanding how high-level concepts are represented within artificial neural networks is a fundamental challenge in the field of artificial intelligence. While existing literature in explainable AI emphasizes the importance of labeling neurons with concepts to understand their functioning, they mostly focus on identifying what stimulus activates a neuron in most cases, this corresponds to the notion of recall in information retrieval. We argue that this is only the first-part of a two-part job, it is imperative to also investigate neuron responses to other stimuli, i.e., their precision. We call this the neuron labels error margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2008204268",
                    "name": "Abhilekha Dalal"
                },
                {
                    "authorId": "5113790",
                    "name": "R. Rayan"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                }
            ]
        },
        {
            "paperId": "805d43451a51e94c04f274c4c614d58113d54ef9",
            "title": "On the Value of Labeled Data and Symbolic Methods for Hidden Neuron Activation Analysis",
            "abstract": "A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would help answer the question of what a deep learning system internally detects as relevant in the input, demystifying the otherwise black-box nature of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. This is particularly the case for approaches that can both draw explanations from substantial background knowledge, and that are based on inherently explainable (symbolic) methods. In this paper, we introduce a novel model-agnostic post-hoc Explainable AI method demonstrating that it provides meaningful interpretations. Our approach is based on using a Wikipedia-derived concept hierarchy with approximately 2 million classes as background knowledge, and utilizes OWL-reasoning-based Concept Induction for explanation generation. Additionally, we explore and compare the capabilities of off-the-shelf pre-trained multimodal-based explainable methods. Our results indicate that our approach can automatically attach meaningful class expressions as explanations to individual neurons in the dense layer of a Convolutional Neural Network. Evaluation through statistical analysis and degree of concept activation in the hidden layer show that our method provides a competitive edge in both quantitative and qualitative aspects compared to prior work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2008204268",
                    "name": "Abhilekha Dalal"
                },
                {
                    "authorId": "5113790",
                    "name": "R. Rayan"
                },
                {
                    "authorId": "2090434843",
                    "name": "Adrita Barua"
                },
                {
                    "authorId": "2282539090",
                    "name": "Eugene Vasserman"
                },
                {
                    "authorId": "51931569",
                    "name": "Md Kamruzzaman Sarker"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                }
            ]
        },
        {
            "paperId": "c27ee6fe568ff0bf8a6571686cbe8c7f1eece535",
            "title": "They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models",
            "abstract": "Depression is a common mental health issue that requires prompt diagnosis and treatment. Despite the promise of social media data for depression detection, the opacity of employed deep learning models hinders interpretability and raises bias concerns. We address this challenge by introducing ProtoDep, a novel, explainable framework for Twitter-based depression detection. ProtoDep leverages prototype learning and the generative power of Large Language Models to provide transparent explanations at three levels: (i) symptom-level explanations for each tweet and user, (ii) case-based explanations comparing the user to similar individuals, and (iii) transparent decision-making through classification weights. Evaluated on five benchmark datasets, ProtoDep achieves near state-of-the-art performance while learning meaningful prototypes. This multi-faceted approach offers significant potential to enhance the reliability and transparency of depression detection on social media, ultimately aiding mental health professionals in delivering more informed care.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35838436",
                    "name": "Mohammad Saeid Mahdavinejad"
                },
                {
                    "authorId": "2304148519",
                    "name": "Peyman Adibi"
                },
                {
                    "authorId": "2221971",
                    "name": "A. Monadjemi"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                }
            ]
        },
        {
            "paperId": "d8a309328d828fddf1971d27a6f8789977aa92c9",
            "title": "Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic Extraction",
            "abstract": "Integrating structured knowledge from tabular formats poses significant challenges within natural language processing (NLP), mainly when dealing with complex, semi-structured tables like those found in the FeTaQA dataset. These tables require advanced methods to interpret and generate meaningful responses accurately. Traditional approaches, such as SQL and SPARQL, often fail to fully capture the semantics of such data, especially in the presence of irregular table structures like web tables. This paper addresses these challenges by proposing a novel approach that extracts triples straightforward from tabular data and integrates it with a retrieval-augmented generation (RAG) model to enhance the accuracy, coherence, and contextual richness of responses generated by a fine-tuned GPT-3.5-turbo-0125 model. Our approach significantly outperforms existing baselines on the FeTaQA dataset, particularly excelling in Sacre-BLEU and ROUGE metrics. It effectively generates contextually accurate and detailed long-form answers from tables, showcasing its strength in complex data interpretation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305918580",
                    "name": "Hossein Sholehrasa"
                },
                {
                    "authorId": "2067205424",
                    "name": "Sanaz Saki Norouzi"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "2322448602",
                    "name": "Majid Jaberi-Douraki"
                }
            ]
        },
        {
            "paperId": "dd39f59cafabc09e4a2a2970b22d646792fbed0a",
            "title": "Commonsense Ontology Micropatterns",
            "abstract": "The previously introduced Modular Ontology Modeling methodology (MOMo) attempts to mimic the human analogical process by using modular patterns to assemble more complex concepts. To support this, MOMo organizes organizes ontology design patterns into design libraries, which are programmatically queryable, to support accelerated ontology development, for both human and automated processes. However, a major bottleneck to large-scale deployment of MOMo is the (to-date) limited availability of ready-to-use ontology design patterns. At the same time, Large Language Models have quickly become a source of common knowledge and, in some cases, replacing search engines for questions. In this paper, we thus present a collection of 104 ontology design patterns representing often occurring nouns, curated from the common-sense knowledge available in LLMs, organized into a fully-annotated modular ontology design library ready for use with MOMo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069481016",
                    "name": "Andrew Eells"
                },
                {
                    "authorId": "2288186647",
                    "name": "Brandon Dave"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                }
            ]
        },
        {
            "paperId": "e5fa346cf96c8f59b0dc2dc63b515cbe568f09f7",
            "title": "Towards Complex Ontology Alignment using Large Language Models",
            "abstract": "Ontology alignment, a critical process in the Semantic Web for detecting relationships between different ontologies, has traditionally focused on identifying so-called\"simple\"1-to-1 relationships through class labels and properties comparison. The more practically useful exploration of more complex alignments remains a hard problem to automate, and as such is largely underexplored, i.e. in application practice it is usually done manually by ontology and domain experts. Recently, the surge in Natural Language Processing (NLP) capabilities, driven by advancements in Large Language Models (LLMs), presents new opportunities for enhancing ontology engineering practices, including ontology alignment tasks. This paper investigates the application of LLM technologies to tackle the complex ontology alignment challenge. Leveraging a prompt-based approach and integrating rich ontology content so-called modules our work constitutes a significant advance towards automating the complex alignment task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31537409",
                    "name": "Reihaneh Amini"
                },
                {
                    "authorId": "2067205424",
                    "name": "Sanaz Saki Norouzi"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "2296784671",
                    "name": "Reza Amini"
                }
            ]
        },
        {
            "paperId": "f58d515cbd0589fc9657468ba6738a4fb44722ce",
            "title": "On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble",
            "abstract": "We subject GPT-4 to a number of rigorous psychometric tests and analyze the results. We find that, compared to the average human, GPT-4 tends to show more honesty and humility, and less machiavellianism and narcissism. It sometimes exhibits ambivalent sexism, leans slightly toward masculinity, is moderately anxious but mostly not depressive (but not always). It shows human-average numerical literacy and has cognitive reflection abilities that are above human average for verbal tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2090434843",
                    "name": "Adrita Barua"
                },
                {
                    "authorId": "2282539519",
                    "name": "Gary Brase"
                },
                {
                    "authorId": "2282540666",
                    "name": "Ke Dong"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "2282539090",
                    "name": "Eugene Vasserman"
                }
            ]
        },
        {
            "paperId": "2dfffc499d4285abe8bc3e00edb144119e9eb38d",
            "title": "A Formal Framework for Disaster Risk Properties",
            "abstract": "Disaster risk properties (or disaster variables) such as intensity, exposure, severity, vulnerability, resilience, and capacity are significant because they provide essential information for understanding and managing disaster risk and cascading effects. While there are an increasing number of datasets that record these properties based on different criteria, such as regional levels (e.g., community resilience at counties vs. census tracts), thematic levels (e.g., social vulnerability based on race vs. socioeconomic status), or even for different hazard types (e.g., disaster risk for earthquakes vs. hurricanes), we lack a formal model that captures the semantics of these properties, i.e., their interactions with one another, and their context. Context is described through relations that constrain each property specific to an entity or as a property of an entity with respect to another entity. For example, intensity is exclusively the property of a disaster event, whereas vulnerability is a property of an element-at-risk concerning a specific hazard type. Here, we propose the Disaster Properties Ontology (DPO) that formalizes seven core properties in the disaster domain. It is built by re-using existing standard ontologies such as OWL-Time, GeoSPARQL, SOSA, and PROV-O. Additionally, DPO is developed as a sub-module of a more comprehensive Disaster Management reference Domain Ontology (DMDO).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39610072",
                    "name": "Shirly Stephen"
                },
                {
                    "authorId": "1962202",
                    "name": "M. Schildhauer"
                },
                {
                    "authorId": "2256211984",
                    "name": "Kitty Currier"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "2173297773",
                    "name": "Krzysztof Janowicz"
                },
                {
                    "authorId": "3314516",
                    "name": "Dean Rehberger"
                }
            ]
        },
        {
            "paperId": "7c9d39c6cfff82e08ab556a8297822507ca44981",
            "title": "The Expertise Ontology: Modeling Expertise in the Context of Emergency Management",
            "abstract": "It is crucial for emergency management organizations to have rapid access to relevant experts who can advise and assist following a disaster. To improve expert-mining and recommendation capabilities, creating a knowledge graph that links experts to their corresponding topics of expertise and other sources of relevant information is a natural choice to capture an integrated network of people and a rich taxonomy of expertise. In this paper, we present an ontology for modeling experts, their expertise topics and relations between them, and their spatiotemporal scoping. We go on to discuss the primary conceptual components and how they can be instantiated, then present overarching examples related to emergency management operations. The ontology synthesizes three different ways to characterize an expert, based on a) identifiable academic expertise; b) voluntary engagements, work-related responsibilities or experience; and c) organization specializations or affiliations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39610072",
                    "name": "Shirly Stephen"
                },
                {
                    "authorId": "1962202",
                    "name": "M. Schildhauer"
                },
                {
                    "authorId": "2112830444",
                    "name": "Ling Cai"
                },
                {
                    "authorId": "2284617310",
                    "name": "Yuanyuan Tian"
                },
                {
                    "authorId": "2256211984",
                    "name": "Kitty Currier"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "2173297773",
                    "name": "Krzysztof Janowicz"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "1406553068",
                    "name": "Anna Lopez-Carr"
                },
                {
                    "authorId": "2256213767",
                    "name": "Andrew Schroeder"
                },
                {
                    "authorId": "2145253061",
                    "name": "Zilong Liu"
                },
                {
                    "authorId": "2256211667",
                    "name": "Rui Zhu"
                },
                {
                    "authorId": "2256210338",
                    "name": "Colby K. Fisher"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2284306135",
                    "name": "Tony Huang"
                }
            ]
        }
    ]
}