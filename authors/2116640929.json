{
    "authorId": "2116640929",
    "papers": [
        {
            "paperId": "ea82543dc2db4ef07cd2fa197e6967d0c676e228",
            "title": "Multi-Subject 3D Human Mesh Construction Using Commodity WiFi",
            "abstract": "This paper introduces MultiMesh, a multi-subject 3D human mesh construction system based on commodity WiFi. Our system can reuse commodity WiFi devices in the environment and is capable of working in non-line-of-sight (NLoS) conditions compared with the traditional computer vision-based approach. Specifically, we leverage an L-shaped antenna array to generate the two-dimensional angle of arrival (2D AoA) of reflected signals for subject separation in the physical space. We further leverage the angle of departure and time of flight of the signal to enhance the resolvability for precise separation of close subjects. Then we exploit information from various signal dimensions to mitigate the interference of indirect reflections according to different signal propagation paths. Moreover, we employ the continuity of human movement in the spatial-temporal domain to track weak reflected signals of faraway subjects. Finally, we utilize a deep learning model to digitize 2D AoA images of each subject into the 3D human mesh. We conducted extensive experiments in real-world multi-subject scenarios under various environments to evaluate the performance of our system. For example, we conduct experiments with occlusion and perform human mesh construction for different distances between two subjects and different distances between subjects and WiFi devices. The results show that MultiMesh can accurately construct 3D human meshes for multiple users with an average vertex error of 4cm. The evaluations also demonstrate that our system could achieve comparable performance for unseen environments and people. Moreover, we also evaluate the accuracy of spatial information extraction and the performance of subject detection. These evaluations demonstrate the robustness and effectiveness of our system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2115243061",
                    "name": "Yili Ren"
                },
                {
                    "authorId": "2290686326",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "884f8a29a7979a1f05223f432d9a149ac4dcc6b4",
            "title": "PLATE: A Prompt-Enhanced Paradigm for Multi-Scenario Recommendations",
            "abstract": "With the explosive growth of commercial applications of recommender systems, multi-scenario recommendation (MSR) has attracted considerable attention, which utilizes data from multiple domains to improve their recommendation performance simultaneously. However, training a unified deep recommender system (DRS) may not explicitly comprehend the commonality and difference among domains, whereas training an individual model for each domain neglects the global information and incurs high computation costs. Likewise, fine-tuning on each domain is inefficient, and recent advances that apply the prompt tuning technique to improve fine-tuning efficiency rely solely on large-sized transformers. In this work, we propose a novel prompt-enhanced paradigm for multi-scenario recommendation. Specifically, a unified DRS backbone model is first pre-trained using data from all the domains in order to capture the commonality across domains. Then, we conduct prompt tuning with two novel prompt modules, capturing the distinctions among various domains and users. Our experiments on Douban, Amazon, and Ali-CCP datasets demonstrate the effectiveness of the proposed paradigm with two noticeable strengths: (i) its great compatibility with various DRS backbone models, and (ii) its high computation and storage efficiency with only 6% trainable parameters in prompt tuning phase. The implementation code is available for easy reproduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2112246463",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2167046956",
                    "name": "Huanshuo Liu"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "144142354",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "941dd711ef05ca159213bb32ea57c268961252e9",
            "title": "Multi-Task Deep Recommender Systems: A Survey",
            "abstract": "Multi-task learning (MTL) aims at learning related tasks in a unified model to achieve mutual improvement among tasks considering their shared knowledge. It is an important topic in recommendation due to the demand for multi-task prediction considering performance and efficiency. Although MTL has been well studied and developed, there is still a lack of systematic review in the recommendation community. To fill the gap, we provide a comprehensive review of existing multi-task deep recommender systems (MTDRS) in this survey. To be specific, the problem definition of MTDRS is first given, and it is compared with other related areas. Next, the development of MTDRS is depicted and the taxonomy is introduced from the task relation and methodology aspects. Specifically, the task relation is categorized into parallel, cascaded, and auxiliary with main, while the methodology is grouped into parameter sharing, optimization, and training mechanism. The survey concludes by summarizing the application and public datasets of MTDRS and highlighting the challenges and future directions of the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185248657",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "3222510",
                    "name": "Ha T. Lam"
                },
                {
                    "authorId": "2150070704",
                    "name": "Y. Wong"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "c2526dd73bf5662e242004c935988d81597d6ee9",
            "title": "Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendation",
            "abstract": "Click-Through Rate (CTR) prediction is a fundamental technique in recommendation and advertising systems. Recent studies have shown that implementing multi-scenario recommendations contributes to strengthening information sharing and improving overall performance. However, existing multi-scenario models only consider coarse-grained explicit scenario modeling that depends on pre-defined scenario identification from manual prior rules, which is biased and sub-optimal. To address these limitations, we propose a Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendations (HierRec), which perceives implicit patterns adaptively and conducts explicit and implicit scenario modeling jointly. In particular, HierRec designs a basic scenario-oriented module based on the dynamic weight to capture scenario-specific information. Then the hierarchical explicit and implicit scenario-aware modules are proposed to model hybrid-grained scenario information. The multi-head implicit modeling design contributes to perceiving distinctive patterns from different perspectives. Our experiments on two public datasets and real-world industrial applications on a mainstream online advertising platform demonstrate that our HierRec outperforms existing models significantly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2238203237",
                    "name": "Menghui Zhu"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2238125533",
                    "name": "Xiaopeng Li"
                },
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "e0d1066f8a3dfdd1ab22749c4f9b0eca0f440101",
            "title": "HAMUR: Hyper Adapter for Multi-Domain Recommendation",
            "abstract": "Multi-Domain Recommendation (MDR) has gained significant attention in recent years, which leverages data from multiple domains to enhance their performance concurrently. However, current MDR models are confronted with two limitations. Firstly, the majority of these models adopt an approach that explicitly shares parameters between domains, leading to mutual interference among them. Secondly, due to the distribution differences among domains, the utilization of static parameters in existing methods limits their flexibility to adapt to diverse domains. To address these challenges, we propose a novel model HAMUR. Specifically, HAMUR consists of two components: (1). Domain-specific adapter, designed as a pluggable module that can be seamlessly integrated into various existing multi-domain backbone models, and (2). Domain-shared hyper-network, which implicitly captures shared information among domains and dynamically generates the parameters for the adapter. We conduct extensive experiments on two public datasets using various backbone networks. The experimental results validate the effectiveness and scalability of the proposed model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238125533",
                    "name": "Xiaopeng Li"
                },
                {
                    "authorId": "2223746444",
                    "name": "Fan Yan"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "02df8e65d9b44a84d9a202b78f4a65fedf7ed74d",
            "title": "CausalInt: Causal Inspired Intervention for Multi-Scenario Recommendation",
            "abstract": "Building appropriate scenarios to meet the personalized demands of different user groups is a common practice. Despite various scenario brings personalized service, it also leads to challenges for the recommendation on multiple scenarios, especially the scenarios with limited traffic. To give desirable recommendation service for all scenarios and reduce the cost of resource consumption, how to leverage the information from multiple scenarios to construct a unified model becomes critical. Unfortunately, the performance of existing multi-scenario recommendation approaches is poor since they introduce unnecessary information from other scenarios to target scenario. In this paper, we show it is possible to selectively utilize the information from different scenarios to construct the scenario-aware estimators in a unified model. Specifically, we first do analysis on multi-scenario modeling with causal graph from the perspective of users and modeling processes, and then propose the Causal Inspired Intervention (CausalInt) framework for multi-scenario recommendation. CausalInt consists of three modules: (1) Invariant Representation Modeling module to squeeze out the scenario-aware information through disentangled representation learning and obtain a scenario-invariant representation; (2) Negative Effects Mitigating module to resolve conflicts between different scenarios and conflicts between scenario-specific and scenario-invariant representations via gradient based orthogonal regularization and model-agnostic meta learning, respectively; (3) Inter-Scenario Transferring module designs a novel TransNet to simulate a counterfactual intervention and effectively fuse the information from other scenarios. Offline experiments over two real-world dataset and online A/B test are conducted to demonstrate the superiority of CausalInt.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "47781389",
                    "name": "Zhirong Liu"
                },
                {
                    "authorId": "2145908338",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2175453540",
                    "name": "Zhicheng He"
                },
                {
                    "authorId": "2181501520",
                    "name": "Hongkun Zheng"
                },
                {
                    "authorId": "2149550654",
                    "name": "Weiwei Yao"
                },
                {
                    "authorId": "2129409829",
                    "name": "Muyu Zhang"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "18579882be0d6059f9a5608357e09fcb944a2143",
            "title": "A Vision-Based Approach for Commodity WiFi Sensing",
            "abstract": "The ubiquitous WiFi signals provide us the opportunity to sense human activities and the physical environment. In this work, we take a layered approach to design a vision-based method for commodity WiFi sensing. Specifically, the next-generation WiFi supports a larger number of antennas that can provide spatial information of the signal reflections, which enables a vision-based approach for WiFi sensing. To better leverage the spatial formation of the signal reflections and fulfill emerging applications, we provide a holistic layered framework including hardware, physical, deep learning, and application layers as well as a case study. The proposed layered approach could enlighten the research on future WiFi sensing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115243061",
                    "name": "Yili Ren"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2156597262",
                    "name": "Yingying Chen"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "3092d2257c1b95e6b07b59ccd4e7f427602b88fc",
            "title": "A wifi vision-based 3D human mesh reconstruction",
            "abstract": "In this work, we present, Wi-Mesh, a WiFi vision-based 3D human mesh construction system. Our system leverages the advances of WiFi to visualize the shape and deformations of the human body for 3D mesh construction. In particular, it estimates the two-dimensional angle of arrival (2D AoA) of the WiFi signal reflections to enable WiFi devices to \"see\" the physical environment as we humans do. It then extracts only the images of the human body from the physical environment, and leverages deep learning models to digitize the extracted human body into 3D mesh representation. Experimental evaluation under various indoor environments shows that Wi-Mesh achieves an average vertices location error of 2.58cm and joint position error of 2.24cm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2115243061",
                    "name": "Yili Ren"
                },
                {
                    "authorId": "2156597262",
                    "name": "Yingying Chen"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "35328cf9d6100230ebc79afea3d6300747f167b3",
            "title": "Person re-identification using wifi signals",
            "abstract": "Person re-identification (Re-ID) has become increasingly important as it supports a wide range of security applications. In this work, we propose a WiFi-based person Re-ID system in 3D space, which leverages the advances of WiFi and deep learning to extract the static body shape and dynamic walking patterns to recognize people. In particular, we leverage multiple antennas on WiFi devices to capture signal reflections of the human body and produce a WiFi image of a person. We then leverage deep learning to extract both the static body shape and dynamic walking patterns for person Re-ID. Our evaluation results show that our system achieves an overall rank-1 accuracy of 87.1%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115243061",
                    "name": "Yili Ren"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "145092664",
                    "name": "Sheng Tan"
                },
                {
                    "authorId": "2156597262",
                    "name": "Yingying Chen"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        },
        {
            "paperId": "5e3bac7b63d36ff2c7784db55075179c4c0184cf",
            "title": "Poster: A WiFi Vision-based Approach to Person Re-identification",
            "abstract": "In this work, we propose a WiFi vision-based approach to person re-identification (Re-ID) indoors. Our approach leverages the advances of WiFi to visualize a person and utilizes deep learning to help WiFi devices identify and recognize people. Specifically, we leverage multiple antennas on WiFi devices to estimate the two-dimensional angle of arrival (2D AoA) of the WiFi signal reflections to enable WiFi devices to \"see'' a person. We then utilize deep learning techniques to extract a 3D mesh representation of a person and extract the body shape and walking patterns for person Re-ID. Our preliminary study shows that our system achieves high overall ranking accuracies. It also works under non-line-of-sight and different person appearance conditions, where the traditional camera vision-based systems do not work well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115243061",
                    "name": "Yili Ren"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "145092664",
                    "name": "Sheng Tan"
                },
                {
                    "authorId": "2156597262",
                    "name": "Yingying Chen"
                },
                {
                    "authorId": "1688428",
                    "name": "Jie Yang"
                }
            ]
        }
    ]
}