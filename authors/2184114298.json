{
    "authorId": "2184114298",
    "papers": [
        {
            "paperId": "2044d10c08584acee2081db2363ffb679d687df7",
            "title": "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization",
            "abstract": "Language models frequently inherit societal biases from their training data. Numerous techniques have been proposed to mitigate these biases during both the pre-training and fine-tuning stages. However, fine-tuning a pre-trained debiased language model on a downstream task can reintroduce biases into the model. Additionally, existing debiasing methods for downstream tasks either (i) require labels of protected attributes (e.g., age, race, or political views) that are often not available or (ii) rely on indicators of bias, which restricts their applicability to gender debiasing since they rely on gender-specific words. To address this, we introduce a novel debiasing regularization technique based on the class-wise variance of embeddings. Crucially, our method does not require attribute labels and targets any attribute, thus addressing the shortcomings of existing debiasing methods. Our experiments on encoder language models and three datasets demonstrate that our method outperforms existing strong debiasing baselines that rely on target attribute labels while maintaining performance on the target task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "2323514000",
                    "name": "Markus Frohman"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                },
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "9b4ad8a194baf6ba68cca532394b82040ddb88ec",
            "title": "The Importance of Cognitive Biases in the Recommendation Ecosystem",
            "abstract": "Cognitive biases have been studied in psychology, sociology, and behavioral economics for decades. Traditionally, they have been considered a negative human trait that leads to inferior decision-making, reinforcement of stereotypes, or can be exploited to manipulate consumers, respectively. We argue that cognitive biases also manifest in different parts of the recommendation ecosystem and at different stages of the recommendation process. More importantly, we contest this traditional detrimental perspective on cognitive biases and claim that certain cognitive biases can be beneficial when accounted for by recommender systems. Concretely, we provide empirical evidence that biases such as feature-positive effect, Ikea effect, and cultural homophily can be observed in various components of the recommendation pipeline, including input data (such as ratings or side information), recommendation algorithm or model (and consequently recommended items), and user interactions with the system. In three small experiments covering recruitment and entertainment domains, we study the pervasiveness of the aforementioned biases. We ultimately advocate for a prejudice-free consideration of cognitive biases to improve user and item models as well as recommendation algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2248299153",
                    "name": "Markus Schedl"
                },
                {
                    "authorId": "2053814964",
                    "name": "Oleg Lesota"
                },
                {
                    "authorId": "2096412201",
                    "name": "Stefan Brandl"
                },
                {
                    "authorId": "2316641165",
                    "name": "Mohammad Lotfi"
                },
                {
                    "authorId": "2129633087",
                    "name": "Gustavo Junior Escobedo Ticona"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                }
            ]
        },
        {
            "paperId": "a8d24ff3c82eb9c3e31c07335b2ed27ed3c6036a",
            "title": "Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters",
            "abstract": "Bias mitigation of Language Models has been the topic of many studies with a recent focus on learning separate modules like adapters for on-demand debiasing. Besides optimizing for a modularized debiased model, it is often critical in practice to control the degree of bias reduction at inference time, e.g., in order to tune for a desired performance-fairness trade-off in search results or to control the strength of debiasing in classification tasks. In this paper, we introduce Controllable Gate Adapter (ConGater), a novel modular gating mechanism with adjustable sensitivity parameters, %In addition to better perseverance of task performance and enhanced information removal, which allows for a gradual transition from the biased state of the model to the fully debiased version at inference time. We demonstrate ConGater performance by (1) conducting adversarial debiasing experiments with three different models on three classification tasks with four protected attributes, and (2) reducing the bias of search results through fairness list-wise regularization to enable adjusting a trade-off between performance and fairness metrics. Our experiments on the classification tasks show that compared to baselines of the same caliber, ConGater can maintain higher task performance while containing less information regarding the attributes. Our results on the retrieval task show that the fully debiased ConGater can achieve the same fairness performance while maintaining more than twice as high task performance than recent strong baselines. Overall, besides strong performance ConGater enables the continuous transitioning between biased and debiased states of models, enhancing personalization of use and interpretability through controllability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "2281826520",
                    "name": "Cornelia Volaucnik"
                },
                {
                    "authorId": "2261402406",
                    "name": "Markus Schedl"
                }
            ]
        },
        {
            "paperId": "03627e32a048ba71ad6ed632df2f3669464a7dae",
            "title": "Domain Information Control at Inference Time for Acoustic Scene Classification",
            "abstract": "Domain shift is considered a challenge in machine learning as it causes significant degradation of model performance. In the Acoustic Scene Classification task (ASC), domain shift is mainly caused by different recording devices. Several studies have already targeted domain generalization to improve the performance of ASC models on unseen domains, such as new devices. Recently, the Controllable Gate Adapter (CONGATER) has been proposed in Natural Language Processing to address the biased training data problem. CONGATER allows controlling the debiasing process at inference time. CONGATER's main advantage is the continuous and selective debiasing of a trained model, during inference. In this work, we adapt CONGATER to the audio spectrogram transformer for an acoustic scene classification task. We show that CONGATER can be used to selectively adapt the learned representations to be invariant to device domain shifts such as recording devices. Our analysis shows that CONGATER can progressively remove device information from the learned representations and improve the model generalization, especially under domain shift conditions (e.g. unseen devices). We show that information removal can be extended to both device and location domain. Finally, we demonstrate CONGATER's ability to enhance specific device performance without further training11Source Code: https://github.com/ShawMaskldcase22_CONGATER.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "28921847",
                    "name": "Khaled Koutini"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "145964711",
                    "name": "G. Widmer"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "c4ca8096f11af3c8657dd8497a4e8dcb2428d7ee",
            "title": "ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
            "abstract": "Multi-task learning (MTL) has shown considerable practical benefits, particularly when using language models (LMs). While this is commonly achieved by learning $n$ tasks under a joint optimization procedure, some methods, such as AdapterFusion, divide the problem into two stages: (i) task learning, where knowledge specific to a task is encapsulated within sets of parameters (e.g., adapters), and (ii) transfer, where this already learned knowledge is leveraged for a target task. This separation of concerns provides numerous benefits (e.g., promoting reusability). However, current two-stage MTL introduces a substantial number of additional parameters. We address this issue by leveraging the usefulness of linearly scaling the output representations of source adapters for transfer learning. We introduce ScaLearn, a simple and highly parameter-efficient two-stage MTL method that capitalizes on the knowledge of the source tasks by learning a minimal set of scaling parameters that enable effective transfer to a target task. Our experiments on three benchmarks (GLUE, SuperGLUE, and HumSet) and two encoder LMs show that ScaLearn consistently outperforms strong baselines with a small number of transfer parameters (~ $0.35$% of those of AdapterFusion). Remarkably, we observe that ScaLearn maintains its strong abilities even when further reducing parameters, achieving competitive results with only $8$ transfer parameters per target task. Our proposed approach thus demonstrates the power of simple scaling as a promise for more efficient task transfer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2226600284",
                    "name": "Markus Frohmann"
                },
                {
                    "authorId": "2161965407",
                    "name": "Carolin Holtermann"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "29891652",
                    "name": "Anne Lauscher"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        },
        {
            "paperId": "206d8afa93a3afcd1d6f327bc898eb41aa8b3e59",
            "title": "Knowledge Distillation from Transformers for Low-Complexity Acoustic Scene Classification",
            "abstract": "Knowledge Distillation (KD) is known for its ability to compress large models into low-complexity solutions while preserving high predictive performance. In Acoustic Scene Classification (ASC), this ability has recently been exploited successfully, as underlined by three of the top four systems in the low-complexity ASC task of the DCASE\u201821 challenge [1] relying on KD. Current KD solutions for ASC mainly use large-scale CNNs or specialist ensembles to derive superior teacher predictions. In this work, we use the Audio Spectrogram Transformer model PaSST , pre-trained on Audioset, as a teacher model. We show how the pre-trained PaSST model can be properly trained downstream on the TAU Urban Acoustic Scenes 2022 Mobile development dataset [2] and how to distill the knowledge into a low-complexity CNN student. We study the effect of using teacher ensembles, using teacher predictions on extended audio sequences, and using Audioset as an additional dataset for knowledge transfer. Additionally, we compare the effectiveness of Mixup and Freq-MixStyle to improve performance and enhance device generalization. The described system achieved rank 1 in the Low-complexity ASC Task of the DCASE\u201822 challenge [3] 1 .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49739808",
                    "name": "Florian Schmid"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "28921847",
                    "name": "Khaled Koutini"
                },
                {
                    "authorId": "145964711",
                    "name": "G. Widmer"
                }
            ]
        },
        {
            "paperId": "65f1595bad9c04a01c2ec3da87467970ab363ded",
            "title": "Learning General Audio Representations with Large-Scale Training of Patchout Audio Transformers",
            "abstract": "The success of supervised deep learning methods is largely due to their ability to learn relevant features from raw data. Deep Neural Networks (DNNs) trained on large-scale datasets are capable of capturing a diverse set of features, and learning a representation that can generalize onto unseen tasks and datasets that are from the same domain. Hence, these models can be used as powerful feature extractors, in combination with shallower models as classifiers, for smaller tasks and datasets where the amount of training data is insufficient for learning an end-to-end model from scratch. During the past years, Convolutional Neural Networks (CNNs) have largely been the method of choice for audio processing. However, recently attention-based transformer models have demonstrated great potential in supervised settings, outperforming CNNs. In this work, we investigate the use of audio transformers trained on large-scale datasets to learn general-purpose representations. We study how the different setups in these audio transformers affect the quality of their embeddings. We experiment with the models' time resolution, extracted embedding level, and receptive fields in order to see how they affect performance on a variety of tasks and datasets, following the HEAR 2021 NeurIPS challenge evaluation setup. Our results show that representations extracted by audio transformers outperform CNN representations. Furthermore, we will show that transformers trained on Audioset can be extremely effective representation extractors for a wide range of downstream tasks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "28921847",
                    "name": "Khaled Koutini"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "49739808",
                    "name": "Florian Schmid"
                },
                {
                    "authorId": "1406798986",
                    "name": "Hamid Eghbalzadeh"
                },
                {
                    "authorId": "1389602735",
                    "name": "Jan Schluter"
                },
                {
                    "authorId": "145964711",
                    "name": "G. Widmer"
                }
            ]
        },
        {
            "paperId": "f486eca96af518bf8b8e58b60e577522ccdf192b",
            "title": "Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks",
            "abstract": "Societal biases are reflected in large pre-trained language models and their fine-tuned versions on downstream tasks. Common in-processing bias mitigation approaches, such as adversarial training and mutual information removal, introduce additional optimization criteria, and update the model to reach a new debiased state. However, in practice, end-users and practitioners might prefer to switch back to the original model, or apply debiasing only on a specific subset of protected attributes. To enable this, we propose a novel modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks, where each debiasing module can be integrated into the core model on-demand at inference time. Our approach draws from the concept of \\emph{diff} pruning, and proposes a novel training regime adaptable to various representation disentanglement optimizations. We conduct experiments on three classification tasks with gender, race, and age as protected attributes. The results show that our modular approach, while maintaining task performance, improves (or at least remains on-par with) the effectiveness of bias mitigation in comparison with baseline finetuning. Particularly on a two-attribute dataset, our approach with separately learned debiasing subnetworks shows effective utilization of either or both the subnetworks for selective bias mitigation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2167029006",
                    "name": "Lukas Hauzenberger"
                },
                {
                    "authorId": "2184114298",
                    "name": "Shahed Masoudian"
                },
                {
                    "authorId": "2116415191",
                    "name": "Deepak Kumar"
                },
                {
                    "authorId": "144125621",
                    "name": "M. Schedl"
                },
                {
                    "authorId": "2844293",
                    "name": "Navid Rekabsaz"
                }
            ]
        }
    ]
}