{
    "authorId": "1699590260",
    "papers": [
        {
            "paperId": "3c253a615beedb737c3a679432d777aa70099f69",
            "title": "Accurate Node Feature Estimation with Structured Variational Graph Autoencoder",
            "abstract": "Given a graph with partial observations of node features, how can we estimate the missing features accurately? Feature estimation is a crucial problem for analyzing real-world graphs whose features are commonly missing during the data collection process. Accurate estimation not only provides diverse information of nodes but also supports the inference of graph neural networks that require the full observation of node features. However, designing an effective approach for estimating high-dimensional features is challenging, since it requires an estimator to have large representation power, increasing the risk of overfitting. In this work, we propose SVGA (Structured Variational Graph Autoencoder), an accurate method for feature estimation. SVGA applies strong regularization to the distribution of latent variables by structured variational inference, which models the prior of variables as Gaussian Markov random field based on the graph structure. As a result, SVGA combines the advantages of probabilistic inference and graph neural networks, achieving state-of-the-art performance in real datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "27539372",
                    "name": "Hyunsik Jeon"
                },
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "90089661eb00c755b3ad42b400c0e75636a95f59",
            "title": "DPar2: Fast and Scalable PARAFAC2 Decomposition for Irregular Dense Tensors",
            "abstract": "Given an irregular dense tensor, how can we ef-ficiently analyze it? An irregular tensor is a collection of matrices whose columns have the same size and rows have different sizes from each other. PARAFAC2 decomposition is a fundamental tool to deal with an irregular tensor in applications including phenotype discovery and trend analysis. Although several PARAFAC2 decomposition methods exist, their efficiency is limited for irregular dense tensors due to the expensive computations involved with the tensor. In this paper, we propose DP AR2, a fast and scalable PARAFAC2 decomposition method for irregular dense tensors. DP AR2 achieves high efficiency by effectively compressing each slice matrix of a given irregular tensor, careful reordering of computations with the compression results, and exploiting the ir-regularity of the tensor. Extensive experiments show that DP AR2 is up to 6.0 x faster than competitors on real-world irregular tensors while achieving comparable accuracy. In addition, DP AR2 is scalable with respect to the tensor size and target rank.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145382482",
                    "name": "Jun-Gi Jang"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "a89e98dec113aebb4529fa4c4821a2acf93f78ec",
            "title": "Accurate Stock Movement Prediction with Self-supervised Learning from Sparse Noisy Tweets",
            "abstract": "Given historical stock prices and sparse tweets, how can we accurately predict stock price movement? Many market analysts strive to use a large amount of information for stock price prediction, and Twitter is one of the richest sources of information presenting real-time opinions of people. However, previous works that use tweet data in stock movement prediction have suffered from two limitations. First, the number of tweets is heavily biased towards only a few popular stocks, and most stocks have insufficient evidence for accurate price prediction. Second, many tweets provide noisy information irrelevant of actual price movement, and extracting reliable information from tweets is as challenging as predicting stock prices.In this paper, we propose SLOT (Self-supervised Learning of Tweets for Capturing Multi-level Price Trends), an accurate method for stock movement prediction. SLOT has two main ideas to address the limitations of previous tweet-based models. First, SLOT learns embedding vectors of stocks and tweets in the same semantic space through self-supervised learning. The embeddings allow us to use all available tweets to improve the prediction for even unpopular stocks, addressing the sparsity problem. Second, SLOT learns multi-level relationships between stocks from tweets, rather than using them as direct evidence for prediction, making it robust to the unreliability of tweets. Extensive experiments on real world datasets show that SLOT provides the state-of-the-art accuracy of stock movement prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123019191",
                    "name": "Yejun Soun"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2098811958",
                    "name": "Minyong Cho"
                },
                {
                    "authorId": "2203063790",
                    "name": "Jihyeong Jeon"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "29415d78bba90a18693c2ca89782df6467b4cb57",
            "title": "Accurate Online Tensor Factorization for Temporal Tensor Streams with Missing Values",
            "abstract": "Given a time-evolving tensor stream with missing values, how can we accurately discover latent factors in an online manner to predict missing values? Online tensor factorization is a crucial task with many important applications including the analysis of climate, network traffic, and epidemic disease. However, existing online methods have disregarded temporal locality and thus have limited accuracy. In this paper, we propose STF (Streaming Tensor Factorization), an accurate online tensor factorization method for real-world temporal tensor streams with missing values. We exploit an attention-based temporal regularization to learn inherent temporal patterns of the streams. We also propose an efficient online learning algorithm which allows each row of the temporal factor matrix to be updated from past and future information. Extensive experiments show that the proposed method gives the state-of-the-art accuracy, and quickly processes each tensor slice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1999676752",
                    "name": "Dawon Ahn"
                },
                {
                    "authorId": "2109583784",
                    "name": "Seyun Kim"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "8892b289e2f5b7666e383609364fe49226f3799d",
            "title": "Attention-Based Autoregression for Accurate and Efficient Multivariate Time Series Forecasting",
            "abstract": "Given a multivariate time series, how can we forecast all of its variables e\ufb03ciently and accurately? The multivariate forecasting, which is to predict the future observations of a multivariate time series, is a fundamental problem closely related to many real-world applications. However, previous multivariate models su\ufb00er from large model sizes due to the ine\ufb03ciency of capturing complex intra-variable patterns and inter-variable correlations, resulting in poor accuracy. In this work, we propose AttnAR (attention-based autoregression), a novel approach for general multivariate forecasting which maximizes its model e\ufb03ciency via separable structure. At-tnAR \ufb01rst extracts variable-wise patterns by a mixed convolution extractor that e\ufb03ciently combines deep convolution layers and shallow dense layers. Then, AttnAR aggregates the patterns by learning time-invariant attention maps be-tween the target variables. AttnAR accomplishes the state-of-the-art forecasting accuracy in four datasets with up to 117.3 times fewer parameters than the best competitors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "b03bc5c123b5422d6646b7375ddcfc86a204dc7d",
            "title": "Accurate Multivariate Stock Movement Prediction via Data-Axis Transformer with Multi-Level Contexts",
            "abstract": "How can we efficiently correlate multiple stocks for accurate stock movement prediction? Stock movement prediction has received growing interest in data mining and machine learning communities due to its substantial impact on financial markets. One way to improve the prediction accuracy is to utilize the correlations between multiple stocks, getting a reliable evidence regardless of the random noises of individual prices. However, it has been challenging to acquire accurate correlations between stocks because of their asymmetric and dynamic nature which is also influenced by the global movement of a market. In this work, we propose DTML (Data-axis Transformer with Multi-Level contexts), a novel approach for stock movement prediction that learns the correlations between stocks in an end-to-end way. DTML makes asymmetric and dynamic correlations by a) learning temporal correlations within each stock, b) generating multi-level contexts based on a global market context, and c) utilizing a transformer encoder for learning inter-stock correlations. DTML achieves the state-of-the-art accuracy on six datasets collected from various stock markets from US, China, Japan, and UK, making up to 13.8%p higher profits than the best competitors and the annualized return of 44.4% on investment simulation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2123019191",
                    "name": "Yejun Soun"
                },
                {
                    "authorId": "2145791552",
                    "name": "Yong-chan Park"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "da51f2b8b3d1a2c02f3984e1de7097b0852b3bfe",
            "title": "Fast and Memory-Efficient Tucker Decomposition for Answering Diverse Time Range Queries",
            "abstract": "Given a temporal dense tensor and an arbitrary time range, how can we efficiently obtain latent factors in the range? Tucker decomposition is a fundamental tool for analyzing dense tensors to discover hidden factors, and has been exploited in many data mining applications. However, existing decomposition methods do not provide the functionality to analyze a specific range of a temporal tensor. The existing methods are one-off, with the main focus on performing Tucker decomposition once for a whole input tensor. Although a few existing methods with a preprocessing phase can deal with a time range query, they are still time-consuming and suffer from low accuracy. In this paper, we propose Zoom-Tucker, a fast and memory-efficient Tucker decomposition method for finding hidden factors of temporal tensor data in an arbitrary time range. Zoom-Tucker fully exploits block structure to compress a given tensor, supporting an efficient query and capturing local information. Zoom-Tucker answers diverse time range queries quickly and memory-efficiently, by elaborately decoupling the preprocessed results included in the range and carefully determining the order of computations. We demonstrate that Zoom-Tucker is up to 171.9x faster and requires up to 230x less space than existing methods while providing comparable accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145382482",
                    "name": "Jun-Gi Jang"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "dedc722ae95660b0b6463798cdb2bdd482285763",
            "title": "Accurate Graph-Based PU Learning without Class Prior",
            "abstract": "How can we classify graph-structured data only with positive labels? Graph-based positive-unlabeled (PU) learning is to train a binary classifier given only the positive labels when the relationship between examples is given as a graph. The problem is of great importance for various tasks such as detecting malicious accounts in a social network, which are difficult to be modeled by supervised learning when the true negative labels are absent. Previous works for graph-based PU learning assume that the prior distribution of positive nodes is known in advance, which is not true in many real-world cases. In this work, we propose GRAB (Graph-based Risk minimization with iterAtive Belief propagation), a novel end-to-end approach for graph-based PU learning that requires no class prior. GRAB models a given graph as a Markov network and runs the marginalization and update steps iteratively. The marginalization step estimates the marginals of latent variables, while the update step trains a classifier network utilizing the computed priors in the objective function. Extensive experiments on five datasets show that GRAB achieves state-of-the-art accuracy, even compared with previous methods that are given the true prior.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2117094996",
                    "name": "Junghun Kim"
                },
                {
                    "authorId": "20812465",
                    "name": "Hoyoung Yoon"
                },
                {
                    "authorId": "2115989198",
                    "name": "Geonsoon Kim"
                },
                {
                    "authorId": "2056257870",
                    "name": "Changwon Jang"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "fceb7444d6eb2d77609d342e7517ff521f4c8cd1",
            "title": "Fast and Accurate Partial Fourier Transform for Time Series Data",
            "abstract": "Given a time-series vector, how can we efficiently detect anomalies? A widely used method is to use Fast Fourier transform (FFT) to compute Fourier coefficients, take first few coefficients while discarding the remaining small coefficients, and reconstruct the original time series to find points with large errors. Despite the pervasive use, the method requires to compute all of the Fourier coefficients which can be cumbersome if the input length is large or when we need to perform many FFT operations. In this paper, we propose Partial Fourier Transform (PFT), an efficient and accurate algorithm for computing only a part of Fourier coefficients. PFT approximates a part of twiddle factors (trigonometric constants) using polynomials, thereby reducing the computational complexity due to the mixture of many twiddle factors. We derive the asymptotic time complexity of PFT with respect to input and output sizes, and tolerance. We also show that PFT provides an option to set an arbitrary approximation error bound, which is useful especially when the fast evaluation is of utmost importance. Experimental results show that PFT outperforms the current state-of-the-art algorithms, with an order of magnitude of speedup for sufficiently small output sizes without sacrificing accuracy. In addition, we demonstrate the accuracy and efficacy of PFT on real-world anomaly detection, with interpretations of anomalies in stock price data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145791552",
                    "name": "Yong-chan Park"
                },
                {
                    "authorId": "145382482",
                    "name": "Jun-Gi Jang"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        },
        {
            "paperId": "0cc13ac0d3dfde407829537e2da0ea33e6a88e4a",
            "title": "Signed Graph Diffusion Network",
            "abstract": "Given a signed social graph, how can we learn appropriate node representations to infer the signs of missing edges? Signed social graphs have received considerable attention to model trust relationships. Learning node representations is crucial to effectively analyze graph data, and various techniques such as network embedding and graph convolutional network (GCN) have been proposed for learning signed graphs. However, traditional network embedding methods are not end-to-end for a specific task such as link sign prediction, and GCN-based methods suffer from a performance degradation problem when their depth increases. In this paper, we propose Signed Graph Diffusion Network (SGDNet), a novel graph neural network that achieves end-to-end node representation learning for link sign prediction in signed social graphs. We propose a random walk technique specially designed for signed graphs so that SGDNet effectively diffuses hidden node features. Through extensive experiments, we demonstrate that SGDNet outperforms state-of-the-art models in terms of link sign prediction accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130912362",
                    "name": "Jinhong Jung"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "1699590260",
                    "name": "U. Kang"
                }
            ]
        }
    ]
}