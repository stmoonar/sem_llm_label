{
    "authorId": "8856206",
    "papers": [
        {
            "paperId": "f21d1450b08f83c06ed548f143c24076788e1bc1",
            "title": "Overview of Factify5WQA: Fact Verification through 5W Question-Answering",
            "abstract": "Researchers have found that fake news spreads much times faster than real news. This is a major problem, especially in today's world where social media is the key source of news for many among the younger population. Fact verification, thus, becomes an important task and many media sites contribute to the cause. Manual fact verification is a tedious task, given the volume of fake news online. The Factify5WQA shared task aims to increase research towards automated fake news detection by providing a dataset with an aspect-based question answering based fact verification method. Each claim and its supporting document is associated with 5W questions that help compare the two information sources. The objective performance measure in the task is done by comparing answers using BLEU score to measure the accuracy of the answers, followed by an accuracy measure of the classification. The task had submissions using custom training setup and pre-trained language-models among others. The best performing team posted an accuracy of 69.56%, which is a near 35% improvement over the baseline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2324785038",
                    "name": "Suryavardan Suresh"
                },
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "1579818535",
                    "name": "Parth Patwa"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "2212131028",
                    "name": "Vinija Jain"
                },
                {
                    "authorId": "2275226689",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2240213656",
                    "name": "Asif Ekbal"
                }
            ]
        },
        {
            "paperId": "1a23ed979aee638ae05c030dae6d7d1f13ee3f78",
            "title": "Factify 2: A multimodal fake news and satire news dataset",
            "abstract": "The internet gives the world an open platform to express their views and share their stories. While this is very valuable, it makes fake news one of our society's most pressing problems. Manual fact checking process is time consuming, which makes it challenging to disprove misleading assertions before they cause significant harm. This is he driving interest in automatic fact or claim verification. Some of the existing datasets aim to support development of automating fact-checking techniques, however, most of them are text based. Multi-modal fact verification has received relatively scant attention. In this paper, we provide a multi-modal fact-checking dataset called FACTIFY 2, improving Factify 1 by using new data sources and adding satire articles. Factify 2 has 50,000 new data instances. Similar to FACTIFY 1.0, we have three broad categories - support, no-evidence, and refute, with sub-categories based on the entailment of visual and textual data. We also provide a BERT and Vison Transformer based baseline, which achieves 65% F1 score in the test set. The baseline codes and the dataset will be made available at https://github.com/surya1701/Factify-2.0.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183788283",
                    "name": "S. Suryavardan"
                },
                {
                    "authorId": "2183731959",
                    "name": "Shreyash Mishra"
                },
                {
                    "authorId": "1579818535",
                    "name": "Parth Patwa"
                },
                {
                    "authorId": "2212098521",
                    "name": "Megha Chakraborty"
                },
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2031480",
                    "name": "Manoj Kumar Chinnakotla"
                },
                {
                    "authorId": "1734904",
                    "name": "Asif Ekbal"
                },
                {
                    "authorId": "2109543348",
                    "name": "Srijan Kumar"
                }
            ]
        },
        {
            "paperId": "4a2008b8793d6ee8a14a95b2c21f30fe55720834",
            "title": "Simplifying Distributed Neural Network Training on Massive Graphs: Randomized Partitions Improve Model Aggregation",
            "abstract": "Distributed training of GNNs enables learning on massive graphs (e.g., social and e-commerce networks) that exceed the storage and computational capacity of a single machine. To reach performance comparable to centralized training, distributed frameworks focus on maximally recovering cross-instance node dependencies with either communication across instances or periodic fallback to centralized training, which create overhead and limit the framework scalability. In this work, we present a simplified framework for distributed GNN training that does not rely on the aforementioned costly operations, and has improved scalability, convergence speed and performance over the state-of-the-art approaches. Specifically, our framework (1) assembles independent trainers, each of which asynchronously learns a local model on locally-available parts of the training graph, and (2) only conducts periodic (time-based) model aggregation to synchronize the local models. Backed by our theoretical analysis, instead of maximizing the recovery of cross-instance node dependencies -- which has been considered the key behind closing the performance gap between model aggregation and centralized training -- , our framework leverages randomized assignment of nodes or super-nodes (i.e., collections of original nodes) to partition the training graph such that it improves data uniformity and minimizes the discrepancy of gradient and loss function across instances. In our experiments on social and e-commerce networks with up to 1.3 billion edges, our proposed RandomTMA and SuperTMA approaches -- despite using less training data -- achieve state-of-the-art performance and 2.31x speedup compared to the fastest baseline, and show better robustness to trainer failures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "2057479333",
                    "name": "E-Wen Huang"
                },
                {
                    "authorId": "51118486",
                    "name": "Charles Dickens"
                },
                {
                    "authorId": "145850291",
                    "name": "Nikhil S. Rao"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "7c46ed81618acc4464c8051e4b6deb2e671c8c36",
            "title": "Memotion 3: Dataset on sentiment and emotion analysis of codemixed Hindi-English Memes",
            "abstract": "Memes are the new-age conveyance mechanism for humor on social media sites. Memes often include an image and some text. Memes can be used to promote disinformation or hatred, thus it is crucial to investigate in details. We introduce Memotion 3, a new dataset with 10,000 annotated memes. Unlike other prevalent datasets in the domain, including prior iterations of Memotion, Memotion 3 introduces Hindi-English Codemixed memes while prior works in the area were limited to only the English memes. We describe the Memotion task, the data collection and the dataset creation methodologies. We also provide a baseline for the task. The baseline code and dataset will be made available at https://github.com/Shreyashm16/Memotion-3.0",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183731959",
                    "name": "Shreyash Mishra"
                },
                {
                    "authorId": "2183788283",
                    "name": "S. Suryavardan"
                },
                {
                    "authorId": "1579818535",
                    "name": "Parth Patwa"
                },
                {
                    "authorId": "2212098521",
                    "name": "Megha Chakraborty"
                },
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2031480",
                    "name": "Manoj Kumar Chinnakotla"
                },
                {
                    "authorId": "1734904",
                    "name": "Asif Ekbal"
                },
                {
                    "authorId": "2109543348",
                    "name": "Srijan Kumar"
                }
            ]
        },
        {
            "paperId": "80820eb833953e0985ecc5f95998655009d93f63",
            "title": "Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes",
            "abstract": "Analyzing memes on the internet has emerged as a crucial endeavor due to the impact this multi-modal form of content wields in shaping online discourse. Memes have become a powerful tool for expressing emotions and sentiments, possibly even spreading hate and misinformation, through humor and sarcasm. In this paper, we present the overview of the Memotion 3 shared task, as part of the DeFactify 2 workshop at AAAI-23. The task released an annotated dataset of Hindi-English code-mixed memes based on their Sentiment (Task A), Emotion (Task B), and Emotion intensity (Task C). Each of these is defined as an individual task and the participants are ranked separately for each task. Over 50 teams registered for the shared task and 5 made final submissions to the test set of the Memotion 3 dataset. CLIP, BERT modifications, ViT etc. were the most popular models among the participants along with approaches such as Student-Teacher model, Fusion, and Ensembling. The best final F1 score for Task A is 34.41, Task B is 79.77 and Task C is 59.82.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183731959",
                    "name": "Shreyash Mishra"
                },
                {
                    "authorId": "2183788283",
                    "name": "S. Suryavardan"
                },
                {
                    "authorId": "2212098521",
                    "name": "Megha Chakraborty"
                },
                {
                    "authorId": "1579818535",
                    "name": "Parth Patwa"
                },
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "144463965",
                    "name": "A. Sheth"
                },
                {
                    "authorId": "2031480",
                    "name": "Manoj Kumar Chinnakotla"
                },
                {
                    "authorId": "1734904",
                    "name": "Asif Ekbal"
                },
                {
                    "authorId": "2239406997",
                    "name": "Srijan Kumar"
                }
            ]
        },
        {
            "paperId": "90b20012b3bc4434f19fc68fdf86f39589061eaf",
            "title": "Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models",
            "abstract": "Identifying analogies plays a pivotal role in human cognition and language proficiency. In the last decade, there has been extensive research on word analogies in the form of \u201cA is to B as C is to D.\u201d However, there is a growing interest in analogies that involve longer text, such as sentences and collections of sentences, which convey analogous meanings. While the current NLP research community evaluates the ability of Large Language Models (LLMs) to identify such analogies, the underlying reasons behind these abilities warrant deeper investigation. Furthermore, the capability of LLMs to encode both syntactic and semantic structures of language within their embeddings has garnered significant attention with the surge in their utilization. In this work, we examine the relationship between the abilities of multiple LLMs to identify sentence analogies, and their capacity to encode syntactic and semantic structures. Through our analysis, we find that analogy identification ability of LLMs is positively correlated with their ability to encode syntactic and semantic structures of sentences. Specifically, we find that the LLMs which capture syntactic structures better, also have higher abilities in identifying sentence analogies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "70510564",
                    "name": "Ruwan Wickramarachchi"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "2212131028",
                    "name": "Vinija Jain"
                },
                {
                    "authorId": "2275226689",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "d88afa9aaa1aa1a0b777adc9bc7190885aafeb76",
            "title": "Graph Coarsening via Convolution Matching for Scalable Graph Neural Network Training",
            "abstract": "Graph summarization as a preprocessing step is an effective and complementary technique for scalable graph neural network (GNN) training. In this work, we propose the Coarsening Via Convolution Matching (ConvMatch) algorithm and a highly scalable variant, A-ConvMatch, for creating summarized graphs that preserve the output of graph convolution. We evaluate ConvMatch on six real-world link prediction and node classification graph datasets, and show it is efficient and preserves prediction performance while significantly reducing the graph size. Notably, ConvMatch achieves up to 95% of the prediction performance of GNNs on node classification while trained on graphs summarized down to 1% the size of the original graph. Furthermore, on link prediction tasks, ConvMatch consistently outperforms all baselines, achieving up to a 2X improvement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276430640",
                    "name": "Charles Dickens"
                },
                {
                    "authorId": "2057479333",
                    "name": "E-Wen Huang"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "50077183",
                    "name": "Jiong Zhu"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        },
        {
            "paperId": "eafc4e5667826a3b9d7eaec9516d7f2141eaca23",
            "title": "On the Relationship between Sentence Analogy Identification and Sentence Structure Encoding in Large Language Models",
            "abstract": "The ability of Large Language Models (LLMs) to encode syntactic and semantic structures of language is well examined in NLP. Additionally, analogy identification, in the form of word analogies are extensively studied in the last decade of language modeling literature. In this work we specifically look at how LLMs\u2019 abilities to capture sentence analogies (sentences that convey analogous meaning to each other) vary with LLMs\u2019 abilities to encode syntactic and semantic structures of sentences. Through our analysis, we find that LLMs\u2019 ability to identify sentence analogies is positively correlated with their ability to encode syntactic and semantic structures of sentences. Specifically, we find that the LLMs which capture syntactic structures better, also have higher abilities in identifying sentence analogies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "70510564",
                    "name": "Ruwan Wickramarachchi"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "2212131028",
                    "name": "Vinija Jain"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "ed226d52694ec73fe3f8503ff6c872d0dc4a7573",
            "title": "Findings of factify 2: multimodal fake news detection",
            "abstract": "With social media usage growing exponentially in the past few years, fake news has also become extremely prevalent. The detrimental impact of fake news emphasizes the need for research focused on automating the detection of false information and verifying its accuracy. In this work, we present the outcome of the Factify 2 shared task, which provides a multi-modal fact verification and satire news dataset, as part of the DeFactify 2 workshop at AAAI'23. The data calls for a comparison based approach to the task by pairing social media claims with supporting documents, with both text and image, divided into 5 classes based on multi-modal relations. In the second iteration of this task we had over 60 participants and 9 final test-set submissions. The best performances came from the use of DeBERTa for text and Swinv2 and CLIP for image. The highest F1 score averaged for all five classes was 81.82%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183788283",
                    "name": "S. Suryavardan"
                },
                {
                    "authorId": "2183731959",
                    "name": "Shreyash Mishra"
                },
                {
                    "authorId": "2212098521",
                    "name": "Megha Chakraborty"
                },
                {
                    "authorId": "1579818535",
                    "name": "Parth Patwa"
                },
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "118679299",
                    "name": "Amanat Chadha"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2031480",
                    "name": "Manoj Kumar Chinnakotla"
                },
                {
                    "authorId": "1734904",
                    "name": "Asif Ekbal"
                },
                {
                    "authorId": "2109543348",
                    "name": "Srijan Kumar"
                }
            ]
        },
        {
            "paperId": "fc09ee18ab94884cb8026a7db645dd0f0fc04d38",
            "title": "ANALOGICAL - A Novel Benchmark for Long Text Analogy Evaluation in Large Language Models",
            "abstract": "Over the past decade, analogies, in the form of word-level analogies, have played a significant role as an intrinsic measure of evaluating the quality of word embedding methods such as word2vec. Modern large language models (LLMs), however, are primarily evaluated on extrinsic measures based on benchmarks such as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs can draw analogies between long texts. In this paper, we present ANALOGICAL, a new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of long text with six levels of complexity -- (i) word, (ii) word vs. sentence, (iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using thirteen datasets and three different distance measures, we evaluate the abilities of eight LLMs in identifying analogical pairs in the semantic vector space. Our evaluation finds that it is increasingly challenging for LLMs to identify analogies when going up the analogy taxonomy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "70510564",
                    "name": "Ruwan Wickramarachchi"
                },
                {
                    "authorId": "2216606354",
                    "name": "Bimal Gajera"
                },
                {
                    "authorId": "2216605596",
                    "name": "Shreeyash Mukul Gowaikar"
                },
                {
                    "authorId": "153232070",
                    "name": "Chandan Gupta"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "8856206",
                    "name": "Aishwarya N. Reganti"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                }
            ]
        }
    ]
}