{
    "authorId": "3142706",
    "papers": [
        {
            "paperId": "83cac1fe76a146a3b0d68ef2c30a8d4c9f11e985",
            "title": "Where there's a will there's a way: ChatGPT is used more for science in countries where it is prohibited",
            "abstract": "Regulating AI is a key societal challenge, but which regulation methods are effective is unclear. This study measures the effectiveness of restricting AI services geographically, focusing on ChatGPT. OpenAI restricts ChatGPT access in several countries, including China and Russia. If restrictions are effective, ChatGPT use should be minimal in these countries. We measured use with a classifier based on distinctive word usage found in early versions of ChatGPT, e.g.\"delve.\"We trained the classifier on pre- and post-ChatGPT\"polished\"abstracts and found it outperformed GPTZero and ZeroGPT on validation sets, including papers with self-reported AI use. Applying the classifier to preprints from Arxiv, BioRxiv, and MedRxiv showed ChatGPT was used in about 12.6% of preprints by August 2023, with 7.7% higher usage in restricted countries. The gap appeared before China's first major legal LLM became widely available. To test the possibility that, due to high demand, use in restricted countries would have been even higher without restrictions, we compared Asian countries with high expected demand (where English is not an official language) and found that use was higher in those with restrictions. ChatGPT use was correlated with higher views and downloads, but not citations or journal placement. Overall, restricting ChatGPT geographically has proven ineffective in science and possibly other domains, likely due to widespread workarounds.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278849766",
                    "name": "Honglin Bao"
                },
                {
                    "authorId": "2308815535",
                    "name": "Mengyi Sun"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                }
            ]
        },
        {
            "paperId": "463dc7fb9d9ea3e4c14a7595baaa8f184a88f332",
            "title": "3rd International Workshop on Scientific Knowledge Representation, Discovery, and Assessment (Sci-K 2023)",
            "abstract": "The International Workshop on Scientific Knowledge: Representation, Discovery, and Assessment (Sci-K 2023) is now running its third edition. The Sci-K workshop is a venue that brings together researchers and practitioners from different disciplines (including, but not limited to, Digital Libraries, Information Extraction, Machine Learning, Semantic Web, Knowledge Engineering, Natural Language Processing, Scholarly Communication, Science of Science, Scientometrics and Bibliometrics), as well as professionals from the industry, to explore innovative solutions and ideas for the production and consumption of Scientific Knowledge Graphs and assessing the research impact. The workshop has called for high-quality submissions around the three main themes of research, related to scientific knowledge: representation, discovery, and assessment. In response to the call for papers, the workshop has received outstanding submissions from researchers in 15 different countries: United States of America, Germany, United Kingdom, Ireland, Sweden, Canada, India, Brazil, Australia, Italy, Slovenia, Bulgaria, Denmark, Ethiopia, and Norway. Each paper was reviewed at least by three members of the programme committee. Given the quality and the interesting topics covered by the submissions, we accepted 10 papers. Sci-K 2023 builds on two previous successful editions and keeps attracting a combined pool of attendees. The first edition (Sci-K 2021), was held on 13 April 2021 in conjunction with The Web Conference 2021. Its program consisted of two keynote talks, and the presentation of 11 research papers. The second edition (Sci-K 2022) took place on the 26 April 2022 at The Web Conference 2022. The program included the presentation of 5 long papers, 4 short papers, 2 vision papers, 2 keynote speeches and a panel on \u201cWhat\u2019s next after Microsoft Academic Graph?\u201d. The full program as well as the list of accepted papers can be found on the Sci-K website: https://sci-k.github.io/2023/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40520756",
                    "name": "Angelo Salatino"
                },
                {
                    "authorId": "80354842",
                    "name": "Yushuai Bu"
                },
                {
                    "authorId": "2111237412",
                    "name": "Ying Ding"
                },
                {
                    "authorId": "2063949950",
                    "name": "\u00c1gnes Horv\u00e1t"
                },
                {
                    "authorId": "2145587478",
                    "name": "Yong Huang"
                },
                {
                    "authorId": "47842495",
                    "name": "Meijun Liu"
                },
                {
                    "authorId": "1799502",
                    "name": "P. Manghi"
                },
                {
                    "authorId": "2043406",
                    "name": "Andrea Mannocci"
                },
                {
                    "authorId": "2052329",
                    "name": "Francesco Osborne"
                },
                {
                    "authorId": "2183689460",
                    "name": "Daniel M. Romero"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "2143633281",
                    "name": "Feng Xia"
                },
                {
                    "authorId": "49337746",
                    "name": "Yujia Zhai"
                }
            ]
        },
        {
            "paperId": "5025f315c98afa708488abd4d8337fe084261bdc",
            "title": "Do \"bad\" citations have \"good\" effects?",
            "abstract": "The scientific community discourages authors of research papers from citing papers that did not influence them. Such\"rhetorical\"citations are assumed to degrade the literature and incentives for good work. While a world where authors cite only substantively appears attractive, we argue that mandating substantive citing may have underappreciated consequences on the allocation of attention and dynamism in scientific literatures. We develop a novel agent-based model in which agents cite substantively and rhetorically. Agents first select papers to read based on their expected quality, read them and observe their actual quality, become influenced by those that are sufficiently good, and substantively cite them. Next, agents fill any remaining slots in the reference lists by (rhetorically) citing papers that support their narrative, regardless of whether they were actually influential. By turning rhetorical citing on-and-off, we find that rhetorical citing increases the correlation between quality and citations, increases citation churn, and reduces citation inequality. This occurs because rhetorical citing redistributes some citations from a stable set of elite-quality papers to a more dynamic set with high-to-moderate quality and high rhetorical value. Increasing the size of reference lists, often seen as an undesirable trend, amplifies the effects. In sum, rhetorical citing helps deconcentrate attention and makes it easier to displace incumbent ideas, so whether it is indeed undesirable depends on the metrics used to judge desirability.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "3113891",
                    "name": "Honglin Bao"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                }
            ]
        },
        {
            "paperId": "c7e7608dafd0f765638fba0c327572d3b639e003",
            "title": "The effect of in-person conferences on the diffusion of ideas",
            "abstract": "As the academic community debates the future of in-person conferences, it is important to understand how effective they are at diffusing ideas. Most previous attempts to analyze this question have struggled to separate causation from correlation and used potentially biased measures like self-reported learning. Here, we propose a novel approach using scheduling conflicts. When multiple presentations of interest to an attendee are scheduled at the same time, the attendee is less able to see them, on average. If seeing presentations influences future research, then conflicting presentations should influence research less than unconflicting ones. Analyzing conflicts in the personalized schedules of 1960 attendees of 20 computer science conferences reveals that when an attendee is able to see a paper presentation, she is almost twice as likely to cite the paper in her future work. The effect is robust to underlying differences between attendees, papers, and paper authors, and is even larger for a stronger measure of influence \u2013 citing the presented paper multiple times. Given the substantial learning effects of in-person presentations, it will be important to ensure that attempts to turn conferences hybrid or virtual do not imperil knowledge diffusion. * To whom correspondence should be addressed: Misha Teplitskiy, tepl@umich.edu",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "2504744",
                    "name": "Soya Park"
                },
                {
                    "authorId": "145584543",
                    "name": "Neil C. Thompson"
                },
                {
                    "authorId": "1743286",
                    "name": "David R Karger"
                }
            ]
        },
        {
            "paperId": "f9ffe395712353e90fde67c6304ba72ca9d7f468",
            "title": "Intentional and serendipitous diffusion of ideas: Evidence from academic conferences",
            "abstract": "This paper investigates the effects of seeing ideas presented in-person when they are easily accessible online. Presentations may increase the diffusion of ideas intentionally (when one attends the presentation of an idea of interest) and serendipitously (when one sees other ideas presented in the same session). We measure these effects in the context of 25 computer science conferences using data from the scheduling application Confer, which lets users browse papers, Like those of interest, and receive schedules of their presentations. We address endogeneity concerns in presentation attendance by exploiting scheduling conflicts: when a user Likes multiple papers that are presented at the same time, she cannot see them both, potentially affecting their diffusion. Estimates show that being able to see presentations increases citing of Liked papers within two years by 1.5 percentage points (62.5% boost over the baseline citation rate). Attention to Liked papers also spills over to non-Liked papers in the same session, increasing their citing by 0.5 percentage points (125% boost), and this serendipitous diffusion represents 30.5% of the total effect. Both diffusion types were concentrated among papers semantically close to an attendee's prior work, suggesting that there are inefficiencies in finding related research that conferences help overcome. Overall, even when ideas are easily accessible online, in-person presentations substantially increase diffusion, much of it serendipitous.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "2504744",
                    "name": "Soya Park"
                },
                {
                    "authorId": "145584543",
                    "name": "Neil C. Thompson"
                },
                {
                    "authorId": "1743286",
                    "name": "David R Karger"
                }
            ]
        },
        {
            "paperId": "fe5c38e1f961290bf8fc1de6c22122ffa6f9415f",
            "title": "The Gender Gap in Scholarly Self-Promotion on Social Media",
            "abstract": "Self-promotion in science is ubiquitous but may not be exercised equally by men and women. Research on self-promotion in other domains suggests that, due to bias in self-assessment and adverse reactions to non-gender-conforming behaviors (``pushback''), women tend to self-promote less often than men. We test whether this pattern extends to scholars by examining self-promotion over six years using 23M Tweets about 2.8M research papers by 3.5M authors. Overall, women are about 28% less likely than men to self-promote their papers even after accounting for important confounds, and this gap has grown over time. Moreover, differential adoption of Twitter does not explain the gender gap, which is large even in relatively gender-balanced broad research areas, where bias in self-assessment and pushback are expected to be smaller. Further, the gap increases with higher performance and status, being most pronounced for productive women from top-ranked institutions who publish in high-impact journals. Critically, we find differential returns with respect to gender: while self-promotion is associated with increased tweets of papers, the increase is smaller for women than for men. Our findings suggest that self-promotion varies meaningfully by gender and help explain gender differences in the visibility of scientific ideas.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2138443791",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "144463004",
                    "name": "Daniel M. Romero"
                },
                {
                    "authorId": "2046830974",
                    "name": "EmHoke-'Agnes Horv'at"
                }
            ]
        },
        {
            "paperId": "34050692be542898b9062e735e06730d16feebff",
            "title": "Does double\u2010blind peer review reduce bias? Evidence from a top computer science conference",
            "abstract": "Peer review is essential for advancing scientific research, but there are long\u2010standing concerns that authors' prestige or other characteristics can bias reviewers. Double\u2010blind peer review has been proposed as a way to reduce reviewer bias, but the evidence for its effectiveness is limited and mixed. Here, we examine the effects of double\u2010blind peer review by analyzing the review files of 5,027 papers submitted to a top computer science conference that changed its reviewing format from single\u2010 to double\u2010blind in 2018. First, we find that the scores given to the most prestigious authors significantly decreased after switching to double\u2010blind review. However, because many of these papers were above the threshold for acceptance, the change did not affect paper acceptance significantly. Second, the inter\u2010reviewer disagreement increased significantly in the double\u2010blind format. Third, papers rejected in the single\u2010blind format are cited more than those rejected under double\u2010blind, suggesting that double\u2010blind review better excludes poorer quality papers. Lastly, an apparently unrelated change in the rating scale from 10 to 4 points likely reduced prestige bias significantly such that papers' acceptance was affected. These results support the effectiveness of double\u2010blind review in reducing biases, while opening new research directions on the impact of peer\u2010review formats.",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "6670394",
                    "name": "Mengyi Sun"
                },
                {
                    "authorId": "2045298738",
                    "name": "Jainabou Barry Danfa"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                }
            ]
        },
        {
            "paperId": "02ca88b9e6796394230e6119d82ab52e901ddc56",
            "title": "Author mentions in science news reveal widespread disparities across name-inferred ethnicities",
            "abstract": "Abstract Media outlets play a key role in spreading scientific knowledge to the public and raising the profile of researchers among their peers. Yet, how journalists choose to present researchers in their stories is poorly understood. Using a comprehensive data set of 223,587 news stories from 288 US outlets reporting on 100,486 research papers across all areas of science, we investigate whether authors\u2019 ethnicities, as inferred from names, are associated with whether journalists explicitly mention them by name. We find substantial disparities in mention rates across ethnic names. Researchers with non-Anglo names, especially those with East Asian and African names, are significantly less likely to be mentioned in their news stories, even with extensive controls for author prestige, semantic content, news outlets, publication venues, and research topics. The disparities are not fully explained by affiliation locations, suggesting that pragmatic factors play only a partial role. Furthermore, among US-based authors, journalists more often use authors\u2019 institutions instead of names when referring to non-Anglo-named authors, suggesting that journalists\u2019 rhetorical choices are also key. Overall, this study finds evidence of ethnic disparities in how often researchers are described in the media coverage of their research, likely affecting thousands of non-Anglo-named scholars in our data alone.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2138443791",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "3046220",
                    "name": "David Jurgens"
                }
            ]
        },
        {
            "paperId": "0fa657b99b7cf5bd1890e10e728cc8c739931ff8",
            "title": "Conservatism Gets Funded? A Field Experiment on the Role of Negative Information in Novel Project Evaluation",
            "abstract": "The evaluation and selection of novel projects lies at the heart of scientific and technological innovation, and yet there are persistent concerns about bias, such as conservatism. This paper investigates the role that the format of evaluation, specifically information sharing among expert evaluators, plays in generating conservative decisions. We executed two field experiments in two separate grant-funding opportunities at a leading research university, mobilizing 369 evaluators from seven universities to evaluate 97 projects, resulting in 761 proposal-evaluation pairs and more than $250,000 in awards. We exogenously varied the relative valence (positive and negative) of others\u2019 scores and measured how exposures to higher and lower scores affect the focal evaluator\u2019s propensity to change their initial score. We found causal evidence of a negativity bias, where evaluators lower their scores by more points after seeing scores more critical than their own rather than raise them after seeing more favorable scores. Qualitative coding of the evaluators\u2019 justifications for score changes reveals that exposures to lower scores were associated with greater attention to uncovering weaknesses, whereas exposures to neutral or higher scores were associated with increased emphasis on nonevaluation criteria, such as confidence in one\u2019s judgment. The greater power of negative information suggests that information sharing among expert evaluators can lead to more conservative allocation decisions that favor protecting against failure rather than maximizing success.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38875309",
                    "name": "Jacqueline N. Lane"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "123290328",
                    "name": "Gary Gray"
                },
                {
                    "authorId": "40153616",
                    "name": "H. Ranu"
                },
                {
                    "authorId": "1843509",
                    "name": "Michael Menietti"
                },
                {
                    "authorId": "6516277",
                    "name": "E. Guinan"
                },
                {
                    "authorId": "2505610",
                    "name": "K. Lakhani"
                }
            ]
        },
        {
            "paperId": "3db85b57d129d07bf30ec7b41b30115b3f1ed6bc",
            "title": "Author Mentions in Science News Reveal Wide-Spread Ethnic Bias",
            "abstract": "Media outlets play a key role in spreading scientific knowledge to the general public and raising the profile of researchers among their peers. Yet, given time and space constraints, not all scholars can receive equal media attention, and journalists' choices of whom to mention are poorly understood. In this study, we use a comprehensive dataset of 232,524 news stories from 288 U.S.-based outlets covering 100,208 research papers across all sciences to investigate the rates at which scientists of different ethnicities are mentioned by name. We find strong evidence of ethnic biases in author mentions, even after controlling for a wide range of possible confounds. Specifically, authors with non-British-origin names are significantly less likely to be mentioned or quoted than comparable British-origin named authors, even within the stories of a particular news outlet covering a particular scientific venue on a particular research topic. Instead, minority scholars are more likely to have their names substituted with their role at their institution. This ethnic bias is consistent across all types of media outlets, with even larger disparities in General-Interest outlets that tend to publish longer stories and have dedicated editorial teams for accurately reporting science. Our findings reveal that the perceived ethnicity can substantially shape scientists' media attention, and, by our estimation, this bias has affected thousands of scholars unfairly.",
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "authors": [
                {
                    "authorId": "2138443791",
                    "name": "Hao Peng"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "3046220",
                    "name": "David Jurgens"
                }
            ]
        }
    ]
}