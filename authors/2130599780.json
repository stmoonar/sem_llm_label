{
    "authorId": "2130599780",
    "papers": [
        {
            "paperId": "7c88a1ae3652d8db5b93fffd9a84559cadf42f99",
            "title": "Clo(o)k: A Clock That Looks",
            "abstract": "What if a clock could do more than just tell time - what if it could actually see? This paper delves into the conceptualization, design, and construction of a timepiece with visual perception capabilities, featuring three applications that expand the possibilities of human-time interaction. Insights from an Open House showcase are also shared, highlighting the unique user experiences of this device.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                }
            ]
        },
        {
            "paperId": "cf2e413be7d669f7789ac13e9e2e4266eb3f6894",
            "title": "EAAI-23 Blue Sky Ideas in Artificial Intelligence Education from the AAAI/ACM SIGAI New and Future AI Educator Program",
            "abstract": "The 13th Symposium on Educational Advances in Artificial Intelligence (EAAI-23), co-chaired by Michael Guerzhoy, Marion Neumann, and Pat Virtue, continued the tradition of the AAAI/ACM SIGAI New and Future AI Educator (NFAIED) Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia). This paper is a collection of the \"blue sky\" essays of the 2023 NFAIED awardees, intended to help motivate discussion around various current and important issues in AI education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1959343",
                    "name": "Michael Guerzhoy"
                },
                {
                    "authorId": "40945167",
                    "name": "Marion Neumann"
                },
                {
                    "authorId": "144173470",
                    "name": "Emmanuel Johnson"
                },
                {
                    "authorId": "2150446362",
                    "name": "David Johnson"
                },
                {
                    "authorId": "2190128879",
                    "name": "Henry Chai"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                },
                {
                    "authorId": "3177971",
                    "name": "Christopher James Maclellan"
                }
            ]
        },
        {
            "paperId": "1176fa6fc0004aef23490ae2bc0db383d36c8a85",
            "title": "Touching The Droid: Understanding and Improving Touch Precision With Mobile Devices in Virtual Reality",
            "abstract": "Touch interaction with physical smartphones and tablets in Virtual Reality offers interesting opportunities for cross-device input. Unfortunately, any imprecision in the alignment of the visual representation of either the hand or device can impact the precision of touch and the realism of the experience. We first study a user\u2019s ability to rely solely on preoperative feedback to perform touch interaction in VR, where no rendering of the hand is provided. Results indicate that touch in VR is possible without a visual representation of the hand, but accuracy is influenced by how the device is held and the distance traveled to the target. We then introduce a dynamic calibration algorithm to minimize the offset between the physical hand and its virtual representation. In a second study, we show that this algorithm can increase touch accuracy by 43%, and minimize depth-based \u201cscreen penetration\u201d or \u201cfloating touch\u201d errors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2075370285",
                    "name": "Fengyuan Zhu"
                },
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                },
                {
                    "authorId": "145480058",
                    "name": "Maur\u00edcio Sousa"
                },
                {
                    "authorId": "2666589",
                    "name": "Tovi Grossman"
                }
            ]
        },
        {
            "paperId": "43cf76ac5f7712dbfd9cbff3d32a2a6379f44c32",
            "title": "EAAI-22 Blue Sky Ideas in Artificial Intelligence Education from the AAAI/ACM SIGAI New and Future AI Educator Program",
            "abstract": "The 12th Symposium on Educational Advances in Artificial Intelligence (EAAI-22, cochaired by Michael Guerzhoy and Marion Neumann) continued the AAAI/ACM SIGAI New and Future AI Educator Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia). As part of the program, awardees were asked to address one of the following \"blue sky\" questions: \u2022How could/should AI courses incorporate AI Ethics into the curriculum? \u2022How could we teach AI topics at an early undergraduate or a secondary school level? \u2022AI has the potential for broad impact to numerous disciplines. How could we make AI education more interdisciplinary, specifically to benefit non-engineering fields? \u2022How should standard AI courses evolve? \u2022How could we leverage AI education to promote diversity in the field? This paper is a collection of their responses, intended to help motivate discussion around these issues in AI education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1959343",
                    "name": "Michael Guerzhoy"
                },
                {
                    "authorId": "40945167",
                    "name": "Marion Neumann"
                },
                {
                    "authorId": "2257692676",
                    "name": "Emmanuel Johnson"
                },
                {
                    "authorId": "2257268152",
                    "name": "David Johnson"
                },
                {
                    "authorId": "2190128879",
                    "name": "Henry Chai"
                },
                {
                    "authorId": "2257238200",
                    "name": "Daniel Garijo"
                },
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                },
                {
                    "authorId": "2257237899",
                    "name": "Christopher J. MacLellan"
                }
            ]
        },
        {
            "paperId": "ba613154a6e8bc55f9eb7f137df04615fc1f14fd",
            "title": "HomeView: Automatically Building Smart Home Digital Twins With Augmented Reality Headsets",
            "abstract": "Digital twins have demonstrated great capabilities in the industrial setting, but the cost of building them prohibits their usage in home environments. We present HomeView, a system that automatically builds and maintains a digital twin using data from Augmented Reality (AR) headsets and Internet of Things (IoT) devices. We evaluated the system in a simulator and found it performs better than the baseline algorithm. The user feedback on programming IoT devices also suggests that contextual information rendered by HomeView is preferable to text descriptions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                },
                {
                    "authorId": "3886207",
                    "name": "Jackie Yang"
                },
                {
                    "authorId": "39682108",
                    "name": "M. Lam"
                },
                {
                    "authorId": "9522307",
                    "name": "J. Landay"
                }
            ]
        },
        {
            "paperId": "bc56a57dd246d4761b3e1d45275050e893a0fe67",
            "title": "AIive: Interactive Visualization and Sonification of Neural Networks in Virtual Reality",
            "abstract": "Artificial Intelligence (AI), especially Neural Networks (NNs), has become increasingly popular. However, people usually treat AI as a tool, focusing on improving outcome, accuracy, and performance while paying less attention to the representation of AI itself. We present AIive, an interactive visualization of AI in Virtual Reality (VR) that brings AI \u201calive\u201d. AIive enables users to manipulate the parameters of NNs with virtual hands and provides auditory feedback for the real-time values of loss, accuracy, and hyperparameters. Thus, AIive contributes an artistic and intuitive way to represent AI by integrating visualization, sonification, and direct manipulation in VR, potentially targeting a wide range of audiences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                },
                {
                    "authorId": "2109639114",
                    "name": "Jiannan Li"
                },
                {
                    "authorId": "2112547231",
                    "name": "Bryan Wang"
                }
            ]
        },
        {
            "paperId": "c87a9e2fc2d1c4a8d48c10718601f88c48dfa2f0",
            "title": "Introducing Variational Autoencoders to High School Students",
            "abstract": "Generative Artificial Intelligence (AI) models are a compelling way to introduce K-12 students to AI education using an artistic medium, and hence have drawn attention from K-12 AI educators. Previous Creative AI curricula mainly focus on Generative Adversarial Networks (GANs) while paying less attention to Autoregressive Models, Variational Autoencoders (VAEs), or other generative models, which have since become common in the field of generative AI. VAEs' latent-space structure and interpolation ability could effectively ground the interdisciplinary learning of AI, creative arts, and philosophy. Thus, we designed a lesson to teach high school students about VAEs. We developed a web-based game and used Plato's cave, a philosophical metaphor, to introduce how VAEs work. We used a Google Colab notebook for students to re-train VAEs with their hand-written digits to consolidate their understandings. Finally, we guided the exploration of creative VAE tools such as SketchRNN and MusicVAE to draw the connection between what they learned and real-world applications. This paper describes the lesson design and shares insights from the pilot studies with 22 students. We found that our approach was effective in teaching students about a novel AI concept.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130599780",
                    "name": "Zhuoyue Lyu"
                },
                {
                    "authorId": "51134075",
                    "name": "Safinah Ali"
                },
                {
                    "authorId": "2065304843",
                    "name": "C. Breazeal"
                }
            ]
        }
    ]
}