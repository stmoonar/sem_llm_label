{
    "authorId": "40422511",
    "papers": [
        {
            "paperId": "084911311b2190180c1772a79f14f09579d94097",
            "title": "High-Precision 3D Reconstruction Study with Emphasis on Refractive Calibration of GelStereo-Type Sensors",
            "abstract": "GelStereo sensing technology is capable of performing three-dimensional (3D) contact shape measurement under various contact structures such as bionic curved surfaces, which has promising advantages in the field of visuotactile sensing. However, due to multi-medium ray refraction in the imaging system, robust and high-precision tactile 3D reconstruction remains a challenging problem for GelStereo-type sensors with different structures. In this paper, we first propose a universal Refractive Stereo Ray Tracing (RSRT) model for GelStereo-type sensing systems to realize 3D reconstruction of the contact surface. Moreover, a relative geometry-based optimization method is presented to calibrate multiple parameters of the proposed RSRT model, such as the refractive indices and structural dimensions. Furthermore, extensive quantitative calibration experiments are performed on four different GelStereo sensing platforms; the experimental results show that the proposed calibration pipeline can achieve less than 0.35 mm in Euclidean distance error, based on which we believe that the proposed refractive calibration method can be further applied in more complex GelStereo-type and other similar visuotactile sensing systems. Such high-precision visuotactile sensors can facilitate the study of robotic dexterous manipulation.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "1853836031",
                    "name": "Shaowei Cui"
                },
                {
                    "authorId": "2146294762",
                    "name": "Shuo Wang"
                },
                {
                    "authorId": "2118518742",
                    "name": "Jingyi Hu"
                },
                {
                    "authorId": "2210402895",
                    "name": "Yipeng Huangfu"
                },
                {
                    "authorId": "2202061746",
                    "name": "Boyue Zhang"
                }
            ]
        },
        {
            "paperId": "096a209e36ce0321571c66061b366d4aedaeac89",
            "title": "CRSNet: Cloud and Cloud Shadow Refinement Segmentation Networks for Remote Sensing Imagery",
            "abstract": "Cloud detection is a critical task in remote sensing image tasks. Due to the influence of ground objects and other noises, the traditional detection methods are prone to miss or false detection and rough edge segmentation in the detection process. To avoid the defects of traditional methods, Cloud and Cloud Shadow Refinement Segmentation Networks are proposed in this paper. The network can correctly and efficiently detect smaller clouds and obtain finer edges. The model takes ResNet-18 as the backbone to extract features at different levels, and the Multi-scale Global Attention Module is used to strengthen the channel and spatial information to improve the accuracy of detection. The Strip Pyramid Channel Attention Module is used to learn spatial information at multiple scales to detect small clouds better. Finally, the high-dimensional feature and low-dimensional feature are fused by the Hierarchical Feature Aggregation Module, and the final segmentation effect is obtained by up-sampling layer by layer. The proposed model attains excellent results compared to methods with classic or special cloud segmentation tasks on Cloud and Cloud Shadow Dataset and the public dataset CSWV.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "1779987",
                    "name": "L. Weng"
                },
                {
                    "authorId": "2212047503",
                    "name": "Li Ding"
                },
                {
                    "authorId": "2144080515",
                    "name": "Min Xia"
                },
                {
                    "authorId": "1986727294",
                    "name": "Haifeng Lin"
                }
            ]
        },
        {
            "paperId": "1b676e2936cfe38cd852d43cdaddec32b86fdd56",
            "title": "ImDiffusion: Imputed Diffusion Models for Multivariate Time Series Anomaly Detection",
            "abstract": "Anomaly detection in multivariate time series data is of paramount importance for large-scale systems. However, accurately detecting anomalies in such data poses significant challenges due to the need for precise data modeling capability. Existing forecasting and reconstruction-based methods struggle to address these challenges effectively. To overcome these limitations, we propose a novel anomaly detection framework named ImDiffusion, which combines time series imputation and diffusion models to achieve accurate and robust anomaly detection. The imputation-based approach employed by ImDiffusion leverages the information from neighboring values in the time series, enabling precise modeling of temporal and inter-correlated dependencies, reducing uncertainty in the data, thereby enhancing the robustness of the anomaly detection process. ImDiffusion further leverages diffusion models as time series imputers to accurately capture complex dependencies. We leverage the step-by-step denoised outputs generated during the inference process to serve as valuable signals for anomaly prediction, resulting in improved accuracy and robustness of the detection process.\n We evaluate the performance of ImDiffusion via extensive experiments on benchmark datasets. The results demonstrate that our proposed framework significantly outperforms state-of-the-art approaches in terms of detection accuracy and timeliness. ImDiffusion is further integrated into the real production system in Microsoft and observes a remarkable 11.4% increase in detection F1 score compared to the legacy approach. To the best of our knowledge, ImDiffusion represents a pioneering approach that combines imputation-based techniques with time series anomaly detection, while introducing the novel use of diffusion models to the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2230032000",
                    "name": "Yuhang Chen"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "3152770",
                    "name": "Minghua Ma"
                },
                {
                    "authorId": "2181323068",
                    "name": "Yudong Liu"
                },
                {
                    "authorId": "2118722803",
                    "name": "Ruomeng Ding"
                },
                {
                    "authorId": "71788673",
                    "name": "Bo Li"
                },
                {
                    "authorId": "3470504",
                    "name": "Shilin He"
                },
                {
                    "authorId": "148121358",
                    "name": "S. Rajmohan"
                },
                {
                    "authorId": "2793487",
                    "name": "Qingwei Lin"
                },
                {
                    "authorId": "2109581369",
                    "name": "Dongmei Zhang"
                }
            ]
        },
        {
            "paperId": "4ac14a3d12e027056e57c5a05b0414b6b0ff7002",
            "title": "Deep Dag Learning of Effective Brain Connectivity for FMRI Analysis",
            "abstract": "Functional magnetic resonance imaging (fMRI) has become one of the most common imaging modalities for brain function analysis. Recently, graph neural networks (GNN) have been adopted for fMRI analysis with superior performance. Unfortunately, traditional functional brain networks are mainly constructed based on similarities among region of interests (ROIs), which are noisy and can lead to inferior results for GNN models. To better adapt GNNs for fMRI analysis, we propose DABNet, a Deep DAG learning framework based on Brain Networks for fMRI analysis. DABNet adopts a brain network generator module, which harnesses the DAG learning approach to transform the raw time-series into effective brain connectivities. Experiments on two fMRI datasets demonstrate the efficacy of DABNet. The generated brain networks also highlight the prediction-related brain regions and thus provide interpretations for predictions.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1633124736",
                    "name": "Yue Yu"
                },
                {
                    "authorId": "2052319438",
                    "name": "Xuan Kan"
                },
                {
                    "authorId": "2112821580",
                    "name": "Hejie Cui"
                },
                {
                    "authorId": "47462790",
                    "name": "Ran Xu"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "2653121",
                    "name": "Yanqiao Zhu"
                },
                {
                    "authorId": "2175349484",
                    "name": "Kun Zhang"
                },
                {
                    "authorId": "41034714",
                    "name": "Razieh Nabi"
                },
                {
                    "authorId": "2153202261",
                    "name": "Ying Guo"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "1390553618",
                    "name": "Carl Yang"
                }
            ]
        },
        {
            "paperId": "58571edf492480b0fb923db798ff13f3ac48f58b",
            "title": "SARNas: A Hardware-Aware SAR Target Detection Algorithm via Multiobjective Neural Architecture Search",
            "abstract": "Most of the existing deep learning-based synthetic aperture radar (SAR) target detection algorithms rely on manual experience to repeatedly adjust structures and parameters to design models suitable for specific scenarios or tasks. The implementation of the above methods is complicated, the design efficiency is low, and it is difficult to ensure the balance between accuracy and complexity. We innovatively propose a hardware-aware SAR target detection algorithm via multiobjective neural architecture search (NAS), referred to as SARNas. First, we design a flexible and efficient search space, a supernet search strategy, and a subnet contribution evaluation strategy. Furthermore, we construct a new NAS loss function, called SARMI-Loss, to guide the learning of an SAR object detector that balances accuracy and computational complexity. Our SARNas method can address the resource limitations of edge devices and automatically search for the optimal SAR target detector in an end-to-end manner for any deep learning-based SAR baseline model. A series of comparative experiments on three SAR image object detection datasets (SSDD, HRSID, and MSAR) demonstrate the superiority of our method. The experimental results with YOLOV5 as the benchmark model show that the detection accuracy of the target detection networks automatically found by using the SARNas method on the SSDD, HRSID, and MSAR datasets can reach 98.5%, 92.8%, and 91.8% in mean average precision (mAP) with only 2.31M, 1.99M, and 2.21M parameters, respectively. The number of model parameters is reduced by 88.9%, 90.46%, and 68.5%, respectively, and the inference speed is increased by 51.6%, 46.1%, and 13.9% without losing accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2221846776",
                    "name": "WenTian Du"
                },
                {
                    "authorId": "2155099282",
                    "name": "Jie Chen"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "2222008828",
                    "name": "Po Zhao"
                },
                {
                    "authorId": "2119229021",
                    "name": "Huiyao Wan"
                },
                {
                    "authorId": "2157944548",
                    "name": "Zheng Zhou"
                },
                {
                    "authorId": "2112866142",
                    "name": "Yi Cao"
                },
                {
                    "authorId": "2156500438",
                    "name": "Zhixiang Huang"
                },
                {
                    "authorId": "2155508006",
                    "name": "Yingsong Li"
                },
                {
                    "authorId": "31215261",
                    "name": "Bocai Wu"
                }
            ]
        },
        {
            "paperId": "6f51080d212cf54662ed93b2bc9709c5d94953c5",
            "title": "Integrated Super-Resolution Sensing and Communication with 5G NR Waveform: Signal Processing with Uneven CPs and Experiments: (Invited Paper)",
            "abstract": "Integrated sensing and communication (ISAC) is a promising technology to simultaneously provide high performance wireless communication and radar sensing services in future networks. In this paper, we propose the concept of integrated super-resolution sensing and communication (ISSAC), which uses super-resolution algorithms in ISAC systems to achieve extreme sensing performance for those critical parameters, such as delay, Doppler, and angle of the sensing targets. Based on practical fifth generation (5G) New Radio (NR) wave forms, the signal processing techniques of ISSAC are investigated and prototyping experiments are performed to verify the achievable performance. To this end, we first study the effect of uneven cyclic prefix (CP) lengths of 5G NR orthogonal frequency division multiplexing (OFDM) waveforms on various sensing algorithms. Specifically, the performance of the standard Periodogram based radar processing method, together with the two classical super resolution algorithms, namely, MUltiple SIgnal Classification (MUSIC) and Estimation of Signal Parameter via Rotational Invariance Techniques (ESPRIT) are analyzed in terms of the delay and Doppler estimation. To resolve the uneven CP issue, a new structure of steering vector for MUSIC and a new selection of submatrices for ESPRIT are proposed. Furthermore, an ISSAC experimental platform is setup to validate the theoretical analysis, and the experimental results show that the performance degradation caused by unequal CP length is insignificant and high-resolution delay and Doppler estimation of the target can be achieved with 5G NR waveforms.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "2149135294",
                    "name": "Zhiwen Zhou"
                },
                {
                    "authorId": "1471560198",
                    "name": "Huizhi Wang"
                },
                {
                    "authorId": "9317732",
                    "name": "Yongbo Zeng"
                }
            ]
        },
        {
            "paperId": "767bafdd5fe4ed7ee9b788c26312c4211dd0699e",
            "title": "GelStereo Palm: A Novel Curved Visuotactile Sensor for 3-D Geometry Sensing",
            "abstract": "Recently, visuotactile sensors have shown promising potential in robotics due to their high-resolution sensing ability. Unfortunately, the majority of available visuotactile sensors are limited to flat shapes, which severely limits their application possibilities. In this article, we propose a novel curved visuotactile sensor, the GelStereo Palm, which senses the 3-D contact geometry on a curved surface using a binocular vision system. Meanwhile, to solve the light refraction problem in the binocular stereo vision system under a curved medium, a refractive stereo ray tracing model for GelStereo Palm is presented. Moreover, a 3-D tactile point cloud sensing pipeline is introduced to reconstruct the 3-D contact geometry in real-time. Finally, extensive experiments are conducted to verify the accuracy and robustness of the 3-D contact geometry sensing of our GelStereo Palm sensor.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118518742",
                    "name": "Jingyi Hu"
                },
                {
                    "authorId": "1853836031",
                    "name": "Shaowei Cui"
                },
                {
                    "authorId": "2146294762",
                    "name": "Shuo Wang"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "2151036128",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "150185273",
                    "name": "Lipeng Chen"
                },
                {
                    "authorId": "2110539199",
                    "name": "Yuhao Li"
                }
            ]
        },
        {
            "paperId": "863a5b2db8c75f4b5d626139e310a37f0c3f7187",
            "title": "Estimating the Forest Carbon Storage of Chongming Eco-Island, China, Using Multisource Remotely Sensed Data",
            "abstract": "Urban forests are highly heterogeneous; information about the combined effect of forest classification scale and algorithm selection on the estimation accuracy for urban forests remains unclear. In this study, we chose Chongming eco-island in the mega-city of Shanghai, a national experimental carbon neutral construction plot in China, as the study object. Remote sensing estimation models (simple regression models vs. machine learning models) of forest carbon density were constructed across different classification scales (all forests, different forest types, and dominant tree species) based on high-resolution aerial photographs and Sentinel-2A remote sensing images, and a large number of field surveys and optimal models were screened by ten-fold cross-validation. The results showed that (1) in early 2020, the total forest area and carbon storage of Chongming eco-island were 307.8 km2 and 573,123.6 t, respectively, among which the areal ratios and total carbon storage ratios of evergreen broad-leaved forest, deciduous broad-leaved forest, and warm coniferous forest were 51.4% and 53.3%, 33.5% and 32.8%, and 15.1% and 13.9%, respectively. (2) The average forest carbon density of Chongming eco-island was 18.6 t/ha, among which no differences were detected among the three forest types (i.e., 17.2\u201319.2 t/ha), opposite to what was observed among the dominant tree species (i.e., 14.6\u201323.7 t/ha). (3) Compared to simple regression models, machine learning models showed an improvement in accuracy performance across all three classification scales, with average rRMSE and rBias values decreasing by 29.4% and 53.1%, respectively; compared to the all-forests classification scale, the average rRMSE and rBias across the algorithms decreased by 25.0% and 45.2% at the forest-type classification scale and by 28.6% and 44.3% at the tree species classification scale, respectively. We concluded that refining the forest classification, combined with advanced prediction procedures, could improve the accuracy of carbon storage estimates for urban forests.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "32163837",
                    "name": "Tongtong Song"
                },
                {
                    "authorId": "2608978",
                    "name": "Runhe Shi"
                },
                {
                    "authorId": "19292633",
                    "name": "Z. Hou"
                },
                {
                    "authorId": "2024182582",
                    "name": "Nan Wu"
                },
                {
                    "authorId": "2119079336",
                    "name": "Han Zhang"
                },
                {
                    "authorId": "2004222179",
                    "name": "Wei Zhuo"
                }
            ]
        },
        {
            "paperId": "975971562d19b1c8d324e1ca1d7c1990a258149d",
            "title": "Lunar Orbit VLBI Experiment Ground Validation System",
            "abstract": "China is planning to launch a relay satellite in the coming years with a payload for the Earth\u2013Moon very-long-baseline interferometer observation research and scientific applications, known as the lunar orbit very-long-baseline interferometry (VLBI) experiment (LOVEX) system. This system will perform the LOVEXs for in the world, and will improve the accuracy of planetary spacecraft orbit determination and the scientific observation capabilities of astrophysics and astrometry. Prior to launch, key technologies of the system must be verified, so we have established a LOVEX ground validation system with similar performance to the LOVEX system. The LOVEX ground validation system consists of a 4.5-m ring-focus antenna, $X$ -band receiver, frequency converter and digital backend, hydrogen maser, and monitoring and control software. Using this system, we have successfully conducted VLBI differential observation experiments with the Shanghai 65 m radio telescope and Beijing 50 m radio telescope. The experimental results show that, after calibration with NRAO150, the standard deviations (STDs) of delay error of Tianwen-1 are within 0.5 ns, consistent with the theoretical timing accuracy, verifying the feasibility of the LOVEX time-delay calibration.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070478531",
                    "name": "Wei Shang-Guan"
                },
                {
                    "authorId": "121140118",
                    "name": "R. Zhao"
                },
                {
                    "authorId": "2109492764",
                    "name": "Jinqing Wang"
                },
                {
                    "authorId": "2192332002",
                    "name": "Zhichao Wang"
                },
                {
                    "authorId": "2295728843",
                    "name": "Qing-Hui Liu"
                },
                {
                    "authorId": "93388476",
                    "name": "X. Hong"
                },
                {
                    "authorId": "48737906",
                    "name": "Guangli Wang"
                },
                {
                    "authorId": "153811985",
                    "name": "Weimin Zheng"
                },
                {
                    "authorId": "2127110578",
                    "name": "Xiumu Zhang"
                },
                {
                    "authorId": "2069230611",
                    "name": "T. Shuai"
                },
                {
                    "authorId": "2152532784",
                    "name": "Zhen Yan"
                },
                {
                    "authorId": "2108794383",
                    "name": "Yi-Dan Huang"
                },
                {
                    "authorId": "2048321616",
                    "name": "Xue-Jiang Lu"
                },
                {
                    "authorId": "6989691",
                    "name": "Linfeng Yu"
                },
                {
                    "authorId": "48752045",
                    "name": "Yong-Bin Jiang"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "2153935034",
                    "name": "Maoli Ma"
                },
                {
                    "authorId": "2022294339",
                    "name": "Wei-Ye Zhong"
                },
                {
                    "authorId": "50883488",
                    "name": "Ren-Jie Zhu"
                },
                {
                    "authorId": "47825073",
                    "name": "Wen Wang"
                },
                {
                    "authorId": "2108136958",
                    "name": "Juan Zhang"
                },
                {
                    "authorId": "144118858",
                    "name": "B. Xia"
                },
                {
                    "authorId": "2218946043",
                    "name": "Chu-Yuan Zhang"
                }
            ]
        },
        {
            "paperId": "984c3a2e6e321319d34a65ace0ff7d94e655ad2a",
            "title": "AnchorPoint: Query Design for Transformer-Based 3D Object Detection and Tracking",
            "abstract": "With the success of Transformers in natural language processing, object detection with Transformers (DETR) has attracted widespread attentions. In previous Transformer-based 2D detectors, the object queries are a set of learning embeddings. However, it is very hard to apply these detectors to the 3D domain due to the lack of explicit physical meanings and position priors of learned object queries. In this paper, we introduce the concept of anchors and propose a novel query design based on anchor points. In our query design, we use the foreground points as the anchor points and encode these anchor points as the object queries. Consequently, each object query has an explicit physical meaning and only focus on its nearby object. Additionally, we also propose an instance-aware sampling strategy to select a small set of representation foreground points from the scene point cloud. Extensive experiments on several large-scale 3D object detection datasets demonstrate that the proposed AnchorPoint detector achieves promising accuracy and efficiency. In particularly, AnchorPoint achieves an average precision (AP) of 83.21 at 61 frame-per-second (FPS) on the moderate level of the KITTI-DET Car subset. Moreover, we model each object as its corresponding anchor point, and extend the AnchorPoint model to 3D multi-object tracking by adding an extra tracking head. We show that our method achieves comparable performance to existing state-of-the-art methods on the KITTI-MOT dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143856589",
                    "name": "Hao Liu"
                },
                {
                    "authorId": "1698967708",
                    "name": "Yanni Ma"
                },
                {
                    "authorId": "2027137715",
                    "name": "Hanyun Wang"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "2046783779",
                    "name": "Yulan Guo"
                }
            ]
        }
    ]
}