{
    "authorId": "2161017247",
    "papers": [
        {
            "paperId": "27387572208cf777fb2c55db8880dd5407d0e779",
            "title": "Personalized and privacy-preserving federated heterogeneous medical image analysis with PPPML-HMI",
            "abstract": "Heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging. However, there are few open-source frameworks for federated heterogeneous medical image analysis with personalization and privacy protection without the demand to modify the existing model structures or to share any private data. In this paper, we proposed PPPML-HMI, a novel open-source learning paradigm for personalized and privacy-preserving federated heterogeneous medical image analysis. To our best knowledge, personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the PerFedAvg algorithm and designing the novel cyclic secure aggregation with the homomorphic encryption algorithm. To show the utility of PPPML-HMI, we applied it to a simulated classification task namely the classification of healthy people and patients from the RAD-ChestCT Dataset, and one real-world segmentation task namely the segmentation of lung infections from COVID-19 CT scans. For the real-world task, PPPML-HMI achieved $sim$5% higher Dice score on average compared to conventional FL under the heterogeneous scenario. Meanwhile, we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the strong privacy-preserving capability of PPPML-HMI. By applying PPPML-HMI to both tasks with different neural networks, a varied number of users, and sample sizes, we further demonstrated the strong generalizability of PPPML-HMI.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1502765940",
                    "name": "Juexiao Zhou"
                },
                {
                    "authorId": "46696611",
                    "name": "Longxi Zhou"
                },
                {
                    "authorId": "2161017247",
                    "name": "Di Wang"
                },
                {
                    "authorId": "2142540079",
                    "name": "Xiaopeng Xu"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2166165505",
                    "name": "Yuetan Chu"
                },
                {
                    "authorId": "2028962393",
                    "name": "Wenkai Han"
                },
                {
                    "authorId": "2198273175",
                    "name": "Xin Gao"
                }
            ]
        },
        {
            "paperId": "33277ae157017cc797e2351bc2cd45d915e9fca7",
            "title": "Practical Differentially Private and Byzantine-resilient Federated Learning",
            "abstract": "Privacy and Byzantine resilience are two indispensable requirements for a federated learning (FL) system. Although there have been extensive studies on privacy and Byzantine security in their own track, solutions that consider both remain sparse. This is due to difficulties in reconciling privacy-preserving and Byzantine-resilient algorithms. In this work, we propose a solution to such a two-fold issue. We use our version of differentially private stochastic gradient descent (DP-SGD) algorithm to preserve privacy and then apply our Byzantine-resilient algorithms. We note that while existing works follow this general approach, an in-depth analysis on the interplay between DP and Byzantine resilience has been ignored, leading to unsatisfactory performance. Specifically, for the random noise introduced by DP, previous works strive to reduce its seemingly detrimental impact on the Byzantine aggregation. In contrast, we leverage the random noise to construct a first-stage aggregation that effectively rejects many existing Byzantine attacks. Moreover, based on another property of our DP variant, we form a second-stage aggregation which provides a final sound filtering. Our protocol follows the principle of co-designing both DP and Byzantine resilience. We provide both theoretical proof and empirical experiments to show our protocol is effective: retaining high accuracy while preserving the DP guarantee and Byzantine resilience. Compared with the previous work, our protocol 1) achieves significantly higher accuracy even in a high privacy regime; 2) works well even when up to 90% distributive workers are Byzantine.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2048004796",
                    "name": "Zihang Xiang"
                },
                {
                    "authorId": "49980880",
                    "name": "Tianhao Wang"
                },
                {
                    "authorId": "2526241",
                    "name": "Wanyu Lin"
                },
                {
                    "authorId": "2161017247",
                    "name": "Di Wang"
                }
            ]
        }
    ]
}