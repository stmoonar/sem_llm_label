{
    "authorId": "2152797245",
    "papers": [
        {
            "paperId": "1d6ba7435383ab645a8b6d02c48a95a863eeda2c",
            "title": "Unified Contextual Query Rewriting",
            "abstract": "Query rewriting (QR) is an important technique for user friction (i.e. recovering ASR error or system error) reduction and contextual carryover (i.e. ellipsis and co-reference) in conversational AI systems. Recently, generation-based QR models have achieved promising results on these two tasks separately. Although these two tasks have many similarities such as they both use the previous dialogue along with the current request as model input, there is no unified model to solve them jointly. To this end, we propose a unified contextual query rewriting model that unifies QR for both reducing friction and contextual carryover purpose. Moreover, we involve multiple auxiliary tasks such as trigger prediction and NLU interpretation tasks to boost the performance of the rewrite. We leverage the text-to-text unified framework which uses independent tasks with weighted loss to account for task importance. Then we propose new unified multitask learning strategies including a sequential model which outputs one sentence for multi-tasks, and a hybrid model where some tasks are independent and some tasks are sequentially generated. Our experimental results demonstrate the effectiveness of the proposed unified learning methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118861187",
                    "name": "Yingxue Zhou"
                },
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "35315626",
                    "name": "Mukund Rungta"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2220668748",
                    "name": "Yanbin Lu"
                },
                {
                    "authorId": "7159482",
                    "name": "V. Vasudevan"
                },
                {
                    "authorId": "39312387",
                    "name": "Kellen Gillespie"
                },
                {
                    "authorId": "3274284",
                    "name": "Zeynab Raeesy"
                }
            ]
        },
        {
            "paperId": "a33d1b24ff14a4e4559eea16387072a81d40b6be",
            "title": "KG-ECO: Knowledge Graph Enhanced Entity Correction For Query Rewriting",
            "abstract": "Query Rewriting (QR) plays a critical role in large-scale dialogue systems for reducing frictions. When there is an entity error, it imposes extra challenges for a dialogue system to produce satisfactory responses. In this work, we propose KG-ECO: Knowledge Graph enhanced Entity COrrection for query rewriting, an entity correction system with corrupt entity span detection and entity retrieval/re-ranking functionalities.To boost the model performance, we incorporate Knowledge Graph (KG) to provide entity structural information (neighboring entities encoded by graph neural networks) and textual information (KG entity descriptions encoded by RoBERTa). Experimental results show that our approach yields a clear performance gain over two baselines: utterance level QR and entity correction without utilizing KG information. The proposed system is particularly effective for few-shot learning cases where target entities are rarely seen in training or there is a KG relation between the target entity and other contextual entities in the query.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115670967",
                    "name": "Jason (Jinglun) Cai"
                },
                {
                    "authorId": "47628976",
                    "name": "Mingda Li"
                },
                {
                    "authorId": "2112347577",
                    "name": "Ziyan Jiang"
                },
                {
                    "authorId": "4006425",
                    "name": "Eunah Cho"
                },
                {
                    "authorId": "2141144864",
                    "name": "Zheng Chen"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "c8525b6119a6ec89bd64a97a6ee5d7d377f8841c",
            "title": "CGF: Constrained Generation Framework for Query Rewriting in Conversational AI",
            "abstract": "In conversational AI agents, Query Rewriting 001 (QR) plays a crucial role in reducing users fric- 002 tions and satisfying their daily demands. Users 003 frictions are caused by various reasons, such 004 as errors in the spoken dialogue system, users\u2019 005 accent or their abridged language. In this work, 006 we present a novel Constrained Generation 007 Framework (CGF) for query rewriting at both 008 global and personalized level. The proposed 009 framework is based on the encoder-decoder 010 framework and consists of a context-enhanced 011 encoding and constrained generation decoding 012 phrases. The model takes the query and its 013 previous dialogue context information as the 014 encoder input, then the decoder relies on the 015 pre-defined global or personalized constrained 016 decoding space to generate the rewrites. Ex- 017 tensive offline and online A/B experimental re- 018 sults show that the proposed CGF significantly 019 boosts the query rewriting performance. 020",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145485960",
                    "name": "Jie Hao"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2118973203",
                    "name": "Saurabh Gupta"
                },
                {
                    "authorId": "2805456",
                    "name": "Saleh Soltan"
                },
                {
                    "authorId": "147887099",
                    "name": "Rakesh Chada"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                },
                {
                    "authorId": "1748051",
                    "name": "G\u00f6khan T\u00fcr"
                }
            ]
        },
        {
            "paperId": "2d27fc841823364561a6c8afae27b246bec9c6d9",
            "title": "Graph Enhanced Query Rewriting for Spoken Language Understanding System",
            "abstract": "Query rewriting (QR) is an increasingly important component in voice assistant systems to reduce customer friction caused by errors in a spoken language understanding pipeline. These errors originate from various sources such as Automatic Speech Recognition (ASR) and Natural Language Understanding (NLU) modules. In this work, we construct a user interaction graph from their queries using data mined from a Markov Chain Model [1], and introduce a self-supervised pre-training process for learning query embeddings by leveraging the recent developments in Graph Representation Learning (GRL). We then fine-tune these embeddings with weak supervised data for the query rewriting task, and observe improvement over the neural retrieval baseline system, demonstrating the effectiveness of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087092426",
                    "name": "Siyang Yuan"
                },
                {
                    "authorId": "2118973203",
                    "name": "Saurabh Gupta"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "2146063081",
                    "name": "Derek Liu"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                }
            ]
        },
        {
            "paperId": "ebfb824c87663bb091d91f3f72f3fc232fe831a6",
            "title": "Learning to Selectively Learn for Weakly-supervised Paraphrase Generation",
            "abstract": "Paraphrase generation is a longstanding NLP task that has diverse applications on downstream NLP tasks. However, the effectiveness of existing efforts predominantly relies on large amounts of golden labeled data. Though unsupervised endeavors have been proposed to alleviate this issue, they may fail to generate meaningful paraphrases due to the lack of supervision signals. In this work, we go beyond the existing paradigms and propose a novel approach to generate high-quality paraphrases with data of weak supervision. Specifically, we tackle the weakly-supervised paraphrase generation problem by: (1) obtaining abundant weakly-labeled parallel sentences via retrieval-based pseudo paraphrase expansion; and (2) developing a meta-learning framework to progressively select valuable samples for fine-tuning a pre-trained language model BART on the sentential paraphrasing task. We demonstrate that our approach achieves significant improvements over existing unsupervised approaches, and is even comparable in performance with supervised state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66807781",
                    "name": "Kaize Ding"
                },
                {
                    "authorId": "34377382",
                    "name": "Dingcheng Li"
                },
                {
                    "authorId": "2123247219",
                    "name": "A. Li"
                },
                {
                    "authorId": "2117800368",
                    "name": "Xing Fan"
                },
                {
                    "authorId": "1941997",
                    "name": "Chenlei Guo"
                },
                {
                    "authorId": "2152797245",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "145896397",
                    "name": "Huan Liu"
                }
            ]
        }
    ]
}