{
    "authorId": "22593971",
    "papers": [
        {
            "paperId": "656216cf5b5c206486a36dd875bf2a5abee7019c",
            "title": "Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning",
            "abstract": "Recently, self-supervised learning (SSL) was shown to be vulnerable to patch-based data poisoning backdoor attacks. It was shown that an adversary can poison a small part of the unlabeled data so that when a victim trains an SSL model on it, the final model will have a back-door that the adversary can exploit. This work aims to defend self-supervised learning against such attacks. We use a three-step defense pipeline, where we first train a model on the poisoned data. In the second step, our proposed defense algorithm (PatchSearch) uses the trained model to search the training data for poisoned samples and removes them from the training set. In the third step, a final model is trained on the cleaned-up training set. Our results show that PatchSearch is an effective defense. As an example, it improves a model's accuracy on images containing the trigger from 38.2% to 63.7% which is very close to the clean model's accuracy, 64.6%. More-over, we show that PatchSearch outperforms baselines and state-of-the-art defense approaches including those using additional clean, trusted data. Our code is available at https://github.com/UCDvision/PatchSearch",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1471776526",
                    "name": "Ajinkya Tejankar"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "145196279",
                    "name": "Qifan Wang"
                },
                {
                    "authorId": "2116420716",
                    "name": "Sinong Wang"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "2367683",
                    "name": "H. Pirsiavash"
                },
                {
                    "authorId": "48327785",
                    "name": "L Tan"
                }
            ]
        },
        {
            "paperId": "97f4601d9ae203e8d14c354da722ed562e637473",
            "title": "Identifying Interpretable Subspaces in Image Representations",
            "abstract": "We propose Automatic Feature Explanation using Contrasting Concepts (FALCON), an interpretability framework to explain features of image representations. For a target feature, FALCON captions its highly activating cropped images using a large captioning dataset (like LAION-400m) and a pre-trained vision-language model like CLIP. Each word among the captions is scored and ranked leading to a small number of shared, human-understandable concepts that closely describe the target feature. FALCON also applies contrastive interpretation using lowly activating (counterfactual) images, to eliminate spurious concepts. Although many existing approaches interpret features independently, we observe in state-of-the-art self-supervised and supervised models, that less than 20% of the representation space can be explained by individual features. We show that features in larger spaces become more interpretable when studied in groups and can be explained with high-order scoring concepts through FALCON. We discuss how extracted concepts can be used to explain and debug failures in downstream tasks. Finally, we present a technique to transfer concepts from one (explainable) representation space to another unseen representation space by learning a simple linear transformation. Code available at https://github.com/NehaKalibhat/falcon-explain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35359875",
                    "name": "N. Kalibhat"
                },
                {
                    "authorId": "34971636",
                    "name": "S. Bhardwaj"
                },
                {
                    "authorId": "79701033",
                    "name": "Bayan Bruss"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "34389431",
                    "name": "S. Feizi"
                }
            ]
        },
        {
            "paperId": "be9447ccc05a0e8a07321272778c7574173cf00e",
            "title": "RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models",
            "abstract": "Chain-of-thought (CoT) has impressively unlocked the reasoning potential of large language models (LLMs). Yet, it falls short when tackling problems that require multiple reasoning steps. This limitation arises from the complex nature of multi-step reasoning processes: later stages often depend not only on the immediately preceding step, but also on the results from several steps earlier. Such complexities indicate the reasoning process is naturally a graph. The almost linear structure of CoT, however, struggles to capture this complex reasoning graph. To address this challenge, we propose Residual Connection Prompting (ResPrompt), a new prompting strategy that advances multi-step reasoning in LLMs. The core of our idea is to reconstruct the reasoning graph within prompts. We achieve this by integrating necessary connections\u2013links present in reasoning graph but missing in the linear CoT flow\u2013into the prompts. Termed \u201cresidual connections\u201d, these links can transform linear CoT into the complex reasoning graphs that multi-step problems entail. On benchmarks across math, sequential, and commonsense domains, ResPrompt demonstrates clear improvements in multi-step reasoning compared with CoT. Through extensive ablation studies and analyses, we pinpoint how to effectively build residual connections and also identify situations where it might be unnecessary.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2249954878",
                    "name": "Song Jiang"
                },
                {
                    "authorId": "2249758145",
                    "name": "Zahra Shakeri"
                },
                {
                    "authorId": "2258300145",
                    "name": "Aaron Chan"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "2258547654",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "36535404",
                    "name": "Bugra Akyildiz"
                },
                {
                    "authorId": "2257321412",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "2257099455",
                    "name": "Jinchao Li"
                },
                {
                    "authorId": "2250669429",
                    "name": "Qifan Wang"
                },
                {
                    "authorId": "1709797",
                    "name": "Asli Celikyilmaz"
                }
            ]
        },
        {
            "paperId": "edf0d80400c319679c5f44e7f01f9ffa23da11c3",
            "title": "MUSTIE: Multimodal Structural Transformer for Web Information Extraction",
            "abstract": "The task of web information extraction is to extract target fields of an object from web pages, such as extracting the name, genre and actor from a movie page. Recent sequential modeling approaches have achieved state-of-the-art results on web information extraction. However, most of these methods only focus on extracting information from textual sources while ignoring the rich information from other modalities such as image and web layout. In this work, we propose a novel MUltimodal Structural Transformer (MUST) that incorporates multiple modalities for web information extraction. Concretely, we develop a structural encoder that jointly encodes the multimodal information based on the HTML structure of the web layout, where high-level DOM nodes, and low-level text and image tokens are introduced to represent the entire page. Structural attention patterns are designed to learn effective cross-modal embeddings for all DOM nodes and low-level tokens. An extensive set of experiments are conducted on WebSRC and Common Crawl benchmarks. Experimental results demonstrate the superior performance of MUST over several state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145778781",
                    "name": "Qifan Wang"
                },
                {
                    "authorId": "2109593338",
                    "name": "Jingang Wang"
                },
                {
                    "authorId": "38472218",
                    "name": "Xiaojun Quan"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2155432076",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "35557488",
                    "name": "Shaoliang Nie"
                },
                {
                    "authorId": "2116420716",
                    "name": "Sinong Wang"
                },
                {
                    "authorId": "2072010",
                    "name": "Madian Khabsa"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "1995922397",
                    "name": "Dongfang Liu"
                }
            ]
        },
        {
            "paperId": "f25f0489c31b680aabc295d826c1ca4f9a7ffd59",
            "title": "Meta-training with Demonstration Retrieval for Efficient Few-shot Learning",
            "abstract": "Large language models show impressive results on few-shot NLP tasks. However, these models are memory and computation-intensive. Meta-training allows one to leverage smaller models for few-shot generalization in a domain-general and task-agnostic manner; however, these methods alone results in models that may not have sufficient parameterization or knowledge to adapt quickly to a large variety of tasks. To overcome this issue, we propose meta-training with demonstration retrieval, where we use a dense passage retriever to retrieve semantically similar labeled demonstrations to each example for more varied supervision. By separating external knowledge from model parameters, we can use meta-training to train parameter-efficient models that generalize well on a larger variety of tasks. We construct a meta-training set from UnifiedQA and CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our knowledge, our work is the first to combine retrieval with meta-training, to use DPR models to retrieve demonstrations, and to leverage demonstrations from many tasks simultaneously, rather than randomly sampling demonstrations from the training set of the target task. Our approach outperforms a variety of targeted parameter-efficient and retrieval-augmented few-shot methods on QA, NLI, and text classification tasks (including SQuAD, QNLI, and TREC). Our approach can be meta-trained and fine-tuned quickly on a single GPU.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49355602",
                    "name": "Aaron Mueller"
                },
                {
                    "authorId": "3089055",
                    "name": "Kanika Narang"
                },
                {
                    "authorId": "36299222",
                    "name": "Lambert Mathias"
                },
                {
                    "authorId": "2145778781",
                    "name": "Qifan Wang"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                }
            ]
        },
        {
            "paperId": "1dd25d1bc1266f9f1e088c99f8b7f22d038f4d19",
            "title": "Detecting and Understanding Harmful Memes: A Survey",
            "abstract": "The automatic identification of harmful content online is of major concern for social media platforms, policymakers, and society. Researchers have studied textual, visual, and audio content, but typically in isolation. Yet, harmful content often combines multiple modalities, as in the case of memes. With this in mind, here we offer a comprehensive survey with a focus on harmful memes. Based on a systematic analysis of recent literature, we first propose a new typology of harmful memes, and then we highlight and summarize the relevant state of the art. One interesting finding is that many types of harmful memes are not really studied, e.g., such featuring self-harm and extremism, partly due to the lack of suitable datasets. We further find that existing datasets mostly capture multi-class scenarios, which are not inclusive of the affective spectrum that memes can represent. Another observation is that memes can propagate globally through repackaging in different languages and that they can also be multilingual, blending different cultures. We conclude by highlighting several challenges related to multimodal semiotics, technological constraints, and non-trivial social engagement, and we present several open-ended aspects such as delineating online harm and empirically examining related frameworks and assistive interventions, which we believe will motivate and drive future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1491627343",
                    "name": "Shivam Sharma"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "46815454",
                    "name": "Md. Shad Akhtar"
                },
                {
                    "authorId": "2105813793",
                    "name": "Dimitar I. Dimitrov"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "2eb0b5b9c1f03f0f945fd69949fbd623ce206cad",
            "title": "Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem",
            "abstract": "We propose an autoregressive entity linking model, that is trained with two auxiliary tasks, and learns to re-rank generated samples at inference time. Our proposed novelties address two weaknesses in the literature. First, a recent method proposes to learn mention detection and then entity candidate selection, but relies on predefined sets of candidates. We use encoder-decoder autoregressive entity linking in order to bypass this need, and propose to train mention detection as an auxiliary task instead. Second, previous work suggests that re-ranking could help correct prediction errors. We add a new, auxiliary task, match prediction, to learn re-ranking. Without the use of a knowledge base or candidate sets, our model sets a new state of the art in two benchmark datasets of entity linking: COMETA in the biomedical domain, and AIDA-CoNLL in the news domain. We show through ablation studies that each of the two auxiliary tasks increases performance, and that re-ranking is an important factor to the increase. Finally, our low-resource experimental results suggest that performance on the main task benefits from the knowledge learned by the auxiliary tasks, and not just from the additional training data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46180513",
                    "name": "Khalil Mrini"
                },
                {
                    "authorId": "35557488",
                    "name": "Shaoliang Nie"
                },
                {
                    "authorId": "3016273",
                    "name": "Jiatao Gu"
                },
                {
                    "authorId": "2116420716",
                    "name": "Sinong Wang"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                }
            ]
        },
        {
            "paperId": "506f4614f2be3b02984a1b293553ce07d18b38bb",
            "title": "ER-TEST Evaluating Explanation Regularization Methods for NLP Models",
            "abstract": "Neural language models\u2019 (NLMs\u2019) reasoning processes are notoriously hard to explain. Recently, there has been much progress in automatically generating machine rationales of NLM behavior, but less in utilizing the rationales to improve NLM behavior. For the latter, explanation regularization (ER) aims to improve NLM generalization by pushing the machine rationales to align with human rationales. Whereas prior works primarily evaluate such ER models via in-distribution (ID) generalization, ER\u2019s impact on out-of-distribution (OOD) is largely underexplored. Plus, little is understood about how ER model performance is affected by the choice of ER criteria or by the number/choice of training instances with human rationales. In light of this, we propose ER-TEST, a protocol for evaluating ER models\u2019 OOD generalization along three dimensions: (1) unseen datasets, (2) contrast set tests, and (3) functional tests. Using ER-TEST, we study two key questions: (A) Which ER criteria are most effective for the given OOD setting? (B) How is ER affected by the number/choice of training instances with human rationales? ER-TEST enables comprehensive analysis of these questions by considering a diverse range of tasks and datasets. Through ER-TEST, we show that ER has little impact on ID performance, but can yield large gains on OOD performance w.r.t. (1)-(3). Also, we find that the best ER criterion is task-dependent, while ER can improve OOD performance even with limited human rationales.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41017365",
                    "name": "Brihi Joshi"
                },
                {
                    "authorId": "2114015857",
                    "name": "Aaron Chan"
                },
                {
                    "authorId": "1671844964",
                    "name": "Ziyi Liu"
                },
                {
                    "authorId": "35557488",
                    "name": "Shaoliang Nie"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "60c7c46a6adccc1e8965c0c8dff40d00f573ddc2",
            "title": "ER-Test: Evaluating Explanation Regularization Methods for Language Models",
            "abstract": "By explaining how humans would solve a given task, human rationales can provide strong learning signal for neural language models (LMs). Explanation regularization (ER) aims to improve LM generalization by pushing the LM's machine rationales (Which input tokens did the LM focus on?) to align with human rationales (Which input tokens would humans focus on?). Though prior works primarily study ER via in-distribution (ID) evaluation, out-of-distribution (OOD) generalization is often more critical in real-world scenarios, yet ER's effect on OOD generalization has been underexplored. In this paper, we introduce ER-Test, a framework for evaluating ER models' OOD generalization along three dimensions: unseen dataset tests, contrast set tests, and functional tests. Using ER-Test, we extensively analyze how ER models' OOD generalization varies with different ER design choices. Across two tasks and six datasets, ER-Test shows that ER has little impact on ID performance but can yield large OOD performance gains. Also, we find that ER can improve OOD performance even with limited rationale supervision. ER-Test's results help demonstrate ER's utility and establish best practices for using ER effectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41017365",
                    "name": "Brihi Joshi"
                },
                {
                    "authorId": "2114015857",
                    "name": "Aaron Chan"
                },
                {
                    "authorId": "2117941373",
                    "name": "Ziyi Liu"
                },
                {
                    "authorId": "35557488",
                    "name": "Shaoliang Nie"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "64f0d82e7ddaa688305d6e8c78abf18179d98d88",
            "title": "FRAME: Evaluating Simulatability Metrics for Free-Text Rationales",
            "abstract": "Free-text rationales aim to explain neural language model (LM) behavior more \ufb02exibly and intuitively via natural language. To ensure rationale quality, it is important to have metrics for measuring rationales\u2019 faithfulness (re-\ufb02ects LM\u2019s actual behavior) and plausibility (convincing to humans). All existing free-text rationale metrics are based on simulatability (association between rationale and LM\u2019s predicted label), but there is no protocol for assessing such metrics\u2019 reliability. To investigate this, we propose FRAME, a framework for evaluating free-text rationale simulatability metrics. FRAME is based on three axioms: (1) good metrics should yield highest scores for reference rationales, which maximize rationale-label association by construction; (2) good metrics should be appropriately sensitive to semantic perturbation of rationales; and (3) good metrics should be robust to variation in the LM\u2019s task performance. Across three text classi\ufb01cation datasets, we show that existing simulatability metrics cannot satisfy all three FRAME axioms, since they are implemented via model pretraining which muddles the metric\u2019s signal. We introduce a non-pretraining simulatability variant that improves performance on (1) and (3) by an average of 41.7% and 42.9%, respectively, while performing competitively on (2).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114015857",
                    "name": "Aaron Chan"
                },
                {
                    "authorId": "35557488",
                    "name": "Shaoliang Nie"
                },
                {
                    "authorId": "2106350603",
                    "name": "Liang Tan"
                },
                {
                    "authorId": "2602530",
                    "name": "Xiaochang Peng"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "2095979",
                    "name": "Maziar Sanjabi"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        }
    ]
}