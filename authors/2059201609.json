{
    "authorId": "2059201609",
    "papers": [
        {
            "paperId": "c897d0664cec04252d4c106a656a8383b9dd79c5",
            "title": "Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI",
            "abstract": "Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2281946312",
                    "name": "Wei Shuai"
                },
                {
                    "authorId": "2282081700",
                    "name": "Jiyao Zhang"
                },
                {
                    "authorId": "2301045597",
                    "name": "Zhida Sun"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                }
            ]
        },
        {
            "paperId": "0c65dfacc858102af978debc10b56536fa186f20",
            "title": "Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration",
            "abstract": "Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel data-aware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2155699322",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "4e10e2e77d2dee62bc8496adc4753b973ce497ce",
            "title": "Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition",
            "abstract": "Datamation is designed to animate an analysis pipeline step by step, which is an intuitive and effective way to interpret the results from data analysis. However, creating a datamation is not easy. A qualified datamation needs to not only provide a correct analysis result but also ensure that the data flow and animation are coherent. Existing animation authoring tools focus on either leveraging algorithms to automatically generate an animation based on user-provided charts or building graphical user interfaces to provide a programming-free authoring environment for users. None of them are able to help users translate an analysis task into a series of data operations to form an analysis pipeline and visualize them as a datamation. To fill this gap, we introduce Datamator, an intelligent authoring tool developed to support datamation design and generation. It leverages a novel data query decomposition model to allow users to generate an initial datamation by simply inputting a data query in natural language. The initial datamation can be refined via rich interactions and a feedback mechanism is utilized to update the decomposition model based on user knowledge and preferences. Our system produces an animated sequence of visualizations driven by a set of low-level data actions. It supports unit visualizations, which provide a mapping from each data item to a unique visual mark. We demonstrate the effectiveness of Datamator via a series of evaluations including case studies, performance validation, and a controlled user study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "1410503485",
                    "name": "Ligan Cai"
                },
                {
                    "authorId": "2134152070",
                    "name": "Yanqiu Wu"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                }
            ]
        },
        {
            "paperId": "6d1d4c3d591a9a6cc020082ff588107c4a6ae450",
            "title": "Calliope-Net: Automatic Generation of Graph Data Facts via Annotated Node-Link Diagrams",
            "abstract": "Graph or network data are widely studied in both data mining and visualization communities to review the relationship among different entities and groups. The data facts derived from graph visual analysis are important to help understand the social structures of complex data, especially for data journalism. However, it is challenging for data journalists to discover graph data facts and manually organize correlated facts around a meaningful topic due to the complexity of graph data and the difficulty to interpret graph narratives. Therefore, we present an automatic graph facts generation system, Calliope-Net, which consists of a fact discovery module, a fact organization module, and a visualization module. It creates annotated node-link diagrams with facts automatically discovered and organized from network data. A novel layout algorithm is designed to present meaningful and visually appealing annotated graphs. We evaluate the proposed system with two case studies and an in-lab user study. The results show that Calliope-Net can benefit users in discovering and understanding graph data facts with visually pleasing annotated visualizations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2118768185",
                    "name": "Nan Chen"
                },
                {
                    "authorId": "2005512798",
                    "name": "W. Shuai"
                },
                {
                    "authorId": "2153300135",
                    "name": "Guande Wu"
                },
                {
                    "authorId": "2149237236",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "2058143613",
                    "name": "H. Tong"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                }
            ]
        },
        {
            "paperId": "c831f34da8cfa38c08861e6914fe3b83196bd96b",
            "title": "Chart2Vec: A Universal Embedding of Context-Aware Visualizations",
            "abstract": "The advances in AI-enabled techniques have accelerated the creation and automation of visualizations in the past decade. However, presenting visualizations in a descriptive and generative format remains a challenge. Moreover, current visualization embedding methods focus on standalone visualizations, neglecting the importance of contextual information for multi-view visualizations. To address this issue, we propose a new representation model, Chart2Vec, to learn a universal embedding of visualizations with context-aware information. Chart2Vec aims to support a wide range of downstream visualization tasks such as recommendation and storytelling. Our model considers both structural and semantic information of visualizations in declarative specifications. To enhance the context-aware capability, Chart2Vec employs multi-task learning on both supervised and unsupervised tasks concerning the cooccurrence of visualizations. We evaluate our method through an ablation study, a user study, and a quantitative comparison. The results verified the consistency of our embedding method with human cognition and showed its advantages over existing methods.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "2261944198",
                    "name": "Ying Chen"
                },
                {
                    "authorId": "152570557",
                    "name": "Wei Shuai"
                },
                {
                    "authorId": "2220099450",
                    "name": "Ruishi Zou"
                },
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2124913650",
                    "name": "Jiazhe Wang"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                }
            ]
        },
        {
            "paperId": "82451ff3ac88da3c206f75abcbfe7389a4d89268",
            "title": "Talk2Data: A Natural Language Interface for Exploratory Visual Analysis via Question Decomposition",
            "abstract": "Through a natural language interface (NLI) for exploratory visual analysis, users can directly \u201cask\u201d analytical questions about the given tabular data. This process greatly improves user experience and lowers the technical barriers of data analysis. Existing techniques focus on generating a visualization from a concrete question. However, complex questions, requiring multiple data queries and visualizations to answer, are frequently asked in data exploration and analysis, which cannot be easily solved with the existing techniques. To address this issue, in this article, we introduce Talk2Data, a natural language interface for exploratory visual analysis that supports answering complex questions. It leverages an advanced deep-learning model to resolve complex questions into a series of simple questions that could gradually elaborate on the users\u2019 requirements. To present answers, we design a set of annotated and captioned visualizations to represent the answers in a form that supports interpretation and narration. We conducted an ablation study and a controlled user study to evaluate the Talk2Data\u2019s effectiveness and usefulness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2151671022",
                    "name": "Mingjuan Guo"
                },
                {
                    "authorId": "2134152070",
                    "name": "Yanqiu Wu"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                }
            ]
        }
    ]
}