{
    "authorId": "151484341",
    "papers": [
        {
            "paperId": "43c05d2046d74a9536971a6f86b55420d214576e",
            "title": "L3 Ensembles: Lifelong Learning Approach for Ensemble of Foundational Language Models\u2731",
            "abstract": "Fine-tuning pre-trained foundational language models (FLM) for specific tasks is often impractical, especially for resource-constrained devices. This necessitates the development of a Lifelong Learning (L3) framework that continuously adapts to a stream of Natural Language Processing (NLP) tasks efficiently. We propose an approach that focuses on extracting meaningful representations from unseen data, constructing a structured knowledge base, and improving task performance incrementally. We conducted experiments on various NLP tasks to validate its effectiveness, including benchmarks like GLUE and SuperGLUE. We measured good performance across the accuracy, training efficiency, and knowledge transfer metrics. Initial experimental results show that the proposed L3 ensemble method increases the model accuracy 4% \u223c 36% compared to the fine-tuned FLM. Furthermore, L3 model outperforms naive fine-tuning approaches while maintaining competitive or superior performance (up to 15.4% increase in accuracy) compared to the state-of-the-art language model (T5) for the given task, STS benchmark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "2091913080",
                    "name": "Kaushik Roy"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "1491238594",
                    "name": "Manas Gaur"
                }
            ]
        },
        {
            "paperId": "81d0303db4cbd755945669ab9c42938d63b3c987",
            "title": "Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models",
            "abstract": "Foundational Language Models (FLMs) have advanced natural language processing (NLP) research. Current researchers are developing larger FLMs (e.g., XLNet, T5) to enable contextualized language representation, classification, and generation. While developing larger FLMs has been of significant advantage, it is also a liability concerning hallucination and predictive uncertainty. Fundamentally, larger FLMs are built on the same foundations as smaller FLMs (e.g., BERT); hence, one must recognize the potential of smaller FLMs which can be realized through an ensemble. In the current research, we perform a reality check on FLMs and their ensemble on benchmark and real-world datasets. We hypothesize that the ensembling of FLMs can influence the individualistic attention of FLMs and unravel the strength of coordination and cooperation of different FLMs. We utilize BERT and define three other ensemble techniques: {Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a knowledge-guided reinforcement learning approach. We discovered that the suggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by a factor of many times using datasets that show the usefulness of NLP in sensitive fields, such as mental health.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150504227",
                    "name": "Nancy Tyagi"
                },
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "2215467580",
                    "name": "Surjodeep Sarkar"
                },
                {
                    "authorId": "1833378844",
                    "name": "A. Umrawal"
                },
                {
                    "authorId": "1491238594",
                    "name": "Manas Gaur"
                }
            ]
        },
        {
            "paperId": "1e1d13b81f8138276e97a5932c61e3e834d8665f",
            "title": "Efficient Language-Guided Reinforcement Learning for Resource-Constrained Autonomous Systems",
            "abstract": "In this article, we propose an energy-efficient architecture, which is designed to receive both images and text inputs as a step toward designing reinforcement learning agents that can understand human language and act in real-world environments. We evaluate our proposed method on three different software environments and a low power drone named Crazyflie to navigate toward specified goals and avoid obstacles successfully. To find the most efficient language-guided reinforcement learning model, we implemented the model with various configurations of image input sizes and text instruction sizes on the Crazyflie drone GAP8, which consists of eight reduced instruction set computer-V cores. The task completion success rate and onboard power consumption, latency, and memory usage of GAP8 are measured and compared with Jetson TX2 ARM central processing unit and Raspberry Pi 4. The results show that by decreasing 20% of input image size we achieve up to 78% energy improvement while achieving an 82% task completion success rate.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "2180067662",
                    "name": "Mozhgan Navardi"
                },
                {
                    "authorId": "2180067690",
                    "name": "Tejaswini Manjunath"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        },
        {
            "paperId": "76b3ba80ad7a78c887621377dba47d65cfe065a2",
            "title": "E2HRL: An Energy-efficient Hardware Accelerator for Hierarchical Deep Reinforcement Learning",
            "abstract": "Recently, Reinforcement Learning (RL) has shown great performance in solving sequential decision-making and control in dynamic environment problems. Despite its achievements, deploying Deep Neural Network (DNN)-based RL is expensive in terms of time and power due to the large number of episodes required to train agents with high dimensional image representations. Additionally, at the interference the large energy footprint of deep neural networks can be a major drawback. Embedded edge devices as the main platform for deploying RL applications are intrinsically resource-constrained and deploying deep neural network-based RL on them is a challenging task. As a result, reducing the number of actions taken by the RL agent to learn desired policy, along with the energy-efficient deployment of RL, is crucial. In this article, we propose Energy Efficient Hierarchical Reinforcement Learning (E2HRL), which is a scalable hardware architecture for RL applications. E2HRL utilizes a cross-layer design methodology for achieving better energy efficiency, smaller model size, higher accuracy, and system integration at the software and hardware layers. Our proposed model for RL agent is designed based on the learning hierarchical policies, which makes the network architecture more efficient for implementation on mobile devices. We evaluated our model in three different RL environments with different level of complexity. Simulation results with our analysis illustrate that hierarchical policy learning with several levels of control improves RL agents training efficiency and the agent learns the desired policy faster compared to a non-hierarchical model. This improvement is specifically more observable as the environment or the task becomes more complex with multiple objective subgoals. We tested our model with different hyperparameters to achieve the maximum reward by the RL agent while minimizing the model size, parameters, and required number of operations. E2HRL model enables efficient deployment of RL agent on resource-constraint-embedded devices with the proposed custom hardware architecture that is scalable and fully parameterized with respect to the number of input channels, filter size, and depth. The number of processing engines (PE) in the proposed hardware can vary between 1 to 8, which provides the flexibility of tradeoff of different factors such as latency, throughput, power, and energy efficiency. By performing a systematic hardware parameter analysis and design space exploration, we implemented the most energy-efficient hardware architectures of E2HRL on Xilinx Artix-7 FPGA and NVIDIA Jetson TX2. Comparing the implementation results shows Jetson TX2 boards achieve 0.1 \u223c 1.3 GOP/S/W energy efficiency while Artix-7 FPGA achieves 1.1 \u223c 11.4 GOP/S/W, which denotes 8.8\u00d7 \u223c 11\u00d7 better energy efficiency of E2HRL when model is implemented on FPGA. Additionally, compared to similar works our design shows better performance and energy efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "88739550",
                    "name": "Utteja Kallakuri"
                },
                {
                    "authorId": "2058855794",
                    "name": "Hasib-Al Rashid"
                },
                {
                    "authorId": "1925495273",
                    "name": "Bharat Prakash"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "143979239",
                    "name": "T. Oates"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        },
        {
            "paperId": "baa5b4c285f420e7df9220ee01926bc7ab0eb224",
            "title": "An Optimization Framework for Efficient Vision-Based Autonomous Drone Navigation",
            "abstract": "Fully autonomous drones are a new emerging field that has enabled many applications such as gas source leakage localization, wild-fire detection, smart agriculture, and search and rescue missions in unknown limited communication and GPS denied environments. Artificial intelligence and deep Neural Networks (NN) have enabled applications such as visual perception and navigation which can be deployed to make drones smarter and more efficient. However, deploying such techniques on tiny drones is extremely challenging due to the limited computational resources and power envelope of edge devices. To achieve this goal, this paper proposes an efficient end-to-end optimization method for deploying deep NN models for vision-based autonomous drone navigation applications, such as obstacle avoidance and steering task. This paper formulates two different methods for implementing the NN inference phase onto tiny drones and analyzing the implementation results for each case: 1) a Cloud-IoT implementation and 2) Onboard Processing. Several models are trained with state-of-the-art scalable NN architectures and the most efficient cases in terms of computation complexity and accuracy are selected for implementation on a cloud server and several edge devices. By designing hardware-friendly NN models and optimal configuration of the implementation platforms, we were able to reach up to 97% accuracy, speed up the computation 2.3\u00d7, have 22\u00d7 less complexity, and 53% energy reduction. Also, we achieve up to 25 fps on the GAP8 processor, which is enough for real-time drone navigation requirements, even when the model is running on a small IoT device.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2180067662",
                    "name": "Mozhgan Navardi"
                },
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "8545443",
                    "name": "E. Humes"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        },
        {
            "paperId": "2e34ef4fa91afae293df0552c71d89bf9e1e0765",
            "title": "An Energy Efficient EdgeAI Autoencoder Accelerator for Reinforcement Learning",
            "abstract": "In EdgeAI embedded devices that exploit reinforcement learning (RL), it is essential to reduce the number of actions taken by the agent in the real world and minimize the compute-intensive policies learning process. Convolutional autoencoders (AEs) has demonstrated great improvement for speeding up the policy learning time when attached to the RL agent, by compressing the high dimensional input data into a small latent representation for feeding the RL agent. Despite reducing the policy learning time, AE adds a significant computational and memory complexity to the model which contributes to the increase in the total computation and the model size. In this article, we propose a model for speeding up the policy learning process of RL agent with the use of AE neural networks, which engages binary and ternary precision to address the high complexity overhead without deteriorating the policy that an RL agent learns. Binary Neural Networks (BNNs) and Ternary Neural Networks (TNNs) compress weights into 1 and 2 bits representations, which result in significant compression of the model size and memory as well as simplifying multiply-accumulate (MAC) operations. We evaluate the performance of our model in three RL environments including DonkeyCar, Miniworld sidewalk, and Miniworld Object Pickup, which emulate various real-world applications with different levels of complexity. With proper hyperparameter optimization and architecture exploration, TNN models achieve near the same average reward, Peak Signal to Noise Ratio (PSNR) and Mean Squared Error (MSE) performance as the full-precision model while reducing the model size by <inline-formula> <tex-math notation=\"LaTeX\">$10\\times $ </tex-math></inline-formula> compared to full-precision and <inline-formula> <tex-math notation=\"LaTeX\">$3\\times $ </tex-math></inline-formula> compared to BNNs. However, in BNN models the average reward drops up to 12% \u2013 25% compared to the full-precision even after increasing its model size by <inline-formula> <tex-math notation=\"LaTeX\">$4\\times $ </tex-math></inline-formula>. We designed and implemented a scalable hardware accelerator which is configurable in terms of the number of processing elements (PEs) and memory data width to achieve the best power, performance, and energy efficiency trade-off for EdgeAI embedded devices. The proposed hardware implemented on Artix-7 FPGA dissipates <inline-formula> <tex-math notation=\"LaTeX\">$250~\\mu \\text{J}$ </tex-math></inline-formula> energy while meeting 30 frames per second (FPS) throughput requirements. The hardware is configurable to reach an efficiency of over 1 TOP/J on FPGA implementation. The proposed hardware accelerator is synthesized and placed-and-routed in 14 nm FinFET ASIC technology which brings down the power dissipation to <inline-formula> <tex-math notation=\"LaTeX\">$3.9~\\mu \\text{J}$ </tex-math></inline-formula> and maximum throughput of 1,250 FPS. Compared to the state of the art TNN implementations on the same target platform, our hardware is <inline-formula> <tex-math notation=\"LaTeX\">$5\\times $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$4.4\\times $ </tex-math></inline-formula> (<inline-formula> <tex-math notation=\"LaTeX\">$2.2\\times $ </tex-math></inline-formula> if technology scaled) more energy efficient on FPGA and ASIC, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1820794562",
                    "name": "N. Manjunath"
                },
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "153355079",
                    "name": "M. Hosseini"
                },
                {
                    "authorId": "1925495273",
                    "name": "Bharat Prakash"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        },
        {
            "paperId": "4505fa286e850e11406d0d547e1efae98cce04d3",
            "title": "A Novel Implementation of CORDIC Algorithm Based on Dynamic Microrotation Generation",
            "abstract": "Mathematical functions are generally classified into two groups. Functions such as logarithmic or trigonometric functions are called elementary functions, and functions such as sin(1/x), which are a combination of two or more elementary functions, are called combinatorial functions. Mathematical functions have many applications in digital devices, such as digital signal processing, image processing, and telecommunication systems. Although software computation of mathematical functions in digital systems has flexibility and convenience advantage, sometimes it does not keep up with the real-time requirements of modern digital systems. To solve this problem, various algorithms have been proposed to implement mathematical functions on hardware. Hardware implementations tend to have higher throughput compared to software implementations, but usually, they suffer in terms of accuracy. In this paper, we propose a novel method for calculating the elementary trigonometric functions using the CORDIC algorithm based on the dynamic microrotation generation technique. We implement our design on Spartan-6 FPGA. Results show our method outperforms similar works in terms of throughput and power consumption while exploiting less hardware.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                }
            ]
        },
        {
            "paperId": "8b50b339cc9a363b179ffb8888277011b65f93b5",
            "title": "A Hardware Accelerator for Language-Guided Reinforcement Learning",
            "abstract": "Reinforcement learning guided with language instructions can potentially improve efficiency and better align with overall system design goals. This article introduces a hardware-friendly architecture for training reinforcement learning equipped with natural language instructions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "1564619335",
                    "name": "A. Mazumder"
                },
                {
                    "authorId": "1925495273",
                    "name": "Bharat Prakash"
                },
                {
                    "authorId": "1747542",
                    "name": "H. Homayoun"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        },
        {
            "paperId": "ea6af4f1aa3c81207db292dfbff176fb76d04752",
            "title": "An Energy-Efficient Hardware Accelerator for Hierarchical Deep Reinforcement Learning",
            "abstract": "Reinforcement Learning (RL) has shown great performance in solving sequential decision-making and control in dynamic environments problems. Despite its achievements, training Deep Neural Network (DNN) based RL is expensive in terms of time and power because of the large number of episodes required to train agents with high dimensional image representations. At the deployment also, the massive energy footprint of deep neural networks can be a major drawback. Embedded devices as the main deployment platform, are intrinsically resource-constrained and deploying DNN on them is challenging. Consequently, reducing the number of actions taken by the RL agent to learn desired policy, along with the development of efficient hardware architectures for RL is crucial. In this paper, we propose a novel hardware architecture for RL agents based on the learning hierarchical policies method. We show that hierarchical learning with several levels of control improves RL agents training efficiency and the agent converges faster compared to a none hierarchical model and therefore using less power. This is especially true as the environment becomes more complex with multiple objective sub-goals. Our method is important for efficient learning of policies for RL agent, especially when the target platform is a resource constraint embedded device. By performing a systematic neural network architecture search and hardware design space exploration, we implemented an energy-efficient scalable hardware accelerator for the hierarchical RL. Hardware factors of merit such as the latency, throughput, and energy consumption of the accelerator are evaluated with the various processing elements, and model parameters. The most energy-efficient configuration achieves 139 fps throughput with 5.8 mJ energy consumption per classification on Xilinx Artix-7 FPGA. Compared to similar works our design shows up to 3x better energy efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "1925495273",
                    "name": "Bharat Prakash"
                },
                {
                    "authorId": "1564619335",
                    "name": "A. Mazumder"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "143979239",
                    "name": "T. Oates"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        },
        {
            "paperId": "effa6165f0a69d8b2adf37d2b6f6c46855fe9e03",
            "title": "Energy-Efficient Hardware for Language Guided Reinforcement Learning",
            "abstract": "Reinforcement learning (RL) has shown great performance in solving sequential decision-making problems. While a lot of works have done on processing state information such as images, there has been some effort towards integrating natural language instructions into RL. In this paper, we propose an energy-efficient architecture which is designed to receive both images and text inputs as a step towards designing RL agents that can understand human language and act in real-world environments. Different configurations are proposed to illustrate the trade off between the number of parameters and the model accuracy, and a custom low power hardware is designed and implemented on FPGA based on the best configuration. The hardware designed to be configurable with different parameters such as number of processing elements, so that it can easily balance power and performance. The high throughput configuration achieves 217 frames per second throughput with 1.2 mJ energy consumption per classification on Xilinx Artix-7 FPGA, while the low power configuration consumes less than 139 mW for 30 frames per second classification. Compared to the similar works using FPGA for hardware implementation, our design is more energy efficient and need less energy for generating each output.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151484341",
                    "name": "Aidin Shiri"
                },
                {
                    "authorId": "1564619335",
                    "name": "A. Mazumder"
                },
                {
                    "authorId": "1925495273",
                    "name": "Bharat Prakash"
                },
                {
                    "authorId": "1820794562",
                    "name": "N. Manjunath"
                },
                {
                    "authorId": "1747542",
                    "name": "H. Homayoun"
                },
                {
                    "authorId": "1798722",
                    "name": "Avesta Sasan"
                },
                {
                    "authorId": "3436871",
                    "name": "Nicholas R. Waytowich"
                },
                {
                    "authorId": "2393902",
                    "name": "T. Mohsenin"
                }
            ]
        }
    ]
}