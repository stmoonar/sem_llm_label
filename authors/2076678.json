{
    "authorId": "2076678",
    "papers": [
        {
            "paperId": "cbba07e754aaf2e364a4af42e18250e5debd8462",
            "title": "To Test Machine Comprehension, Start by Defining Comprehension",
            "abstract": "Many tasks aim to measure machine reading comprehension (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehension\u2014a \u201cTemplate of Understanding\u201d\u2014for a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing systems are not up to the task of narrative understanding as we define it.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "102524625",
                    "name": "Greg Burnham"
                },
                {
                    "authorId": "2528900",
                    "name": "Akash Bharadwaj"
                },
                {
                    "authorId": "1403252641",
                    "name": "Jennifer Chu-Carroll"
                },
                {
                    "authorId": "1702447",
                    "name": "Owen Rambow"
                },
                {
                    "authorId": "2295799",
                    "name": "D. Ferrucci"
                }
            ]
        },
        {
            "paperId": "6a075cbeb020df53f57ea886b5001c111b08bfe4",
            "title": "DeepCx: A transition-based approach for shallow semantic parsing with complex constructional triggers",
            "abstract": "This paper introduces the surface construction labeling (SCL) task, which expands the coverage of Shallow Semantic Parsing (SSP) to include frames triggered by complex constructions. We present DeepCx, a neural, transition-based system for SCL. As a test case for the approach, we apply DeepCx to the task of tagging causal language in English, which relies on a wider variety of constructions than are typically addressed in SSP. We report substantial improvements over previous tagging efforts on a causal language dataset. We also propose ways DeepCx could be extended to still more difficult constructions and to other semantic domains once appropriate datasets become available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                }
            ]
        },
        {
            "paperId": "31f9e4a26870b48c5c254fd42c812cd2742d21f5",
            "title": "The BECauSE Corpus 2.0: Annotating Causality and Overlapping Relations",
            "abstract": "Language of cause and effect captures an essential component of the semantics of a text. However, causal language is also intertwined with other semantic relations, such as temporal precedence and correlation. This makes it difficult to determine when causation is the primary intended meaning. This paper presents BECauSE 2.0, a new version of the BECauSE corpus with exhaustively annotated expressions of causal language, but also seven semantic relations that are frequently co-present with causation. The new corpus shows high inter-annotator agreement, and yields insights both about the linguistic expressions of causation and about the process of annotating co-present semantic relations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                }
            ]
        },
        {
            "paperId": "a5583896b2ebf1e353901596cdefd5ed24441e38",
            "title": "Automatically Tagging Constructions of Causation and Their Slot-Fillers",
            "abstract": "This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case. Semantic parsing becomes difficult in the face of the wide variety of linguistic realizations that causation can take on. We therefore base our approach on the concept of constructions from the linguistic paradigm known as Construction Grammar (CxG). In CxG, a construction is a form/function pairing that can rely on arbitrary linguistic and semantic features. Rather than codifying all aspects of each construction\u2019s form, as some attempts to employ CxG in NLP have done, we propose methods that offload that problem to machine learning. We describe two supervised approaches for tagging causal constructions and their arguments. Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions. Our results show that these approaches are promising: they significantly outperform na\u00efve baselines for both construction recognition and cause and effect head matches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                }
            ]
        },
        {
            "paperId": "cde853290bb6e8be14c3ae9e414424c392168a6d",
            "title": "Construction Detection in a Conventional NLP Pipeline",
            "abstract": "This paper presents an approach to detecting constructions based on a conventional NLP pipeline: the \u201cconstructions on top\u201d approach to integrating constructions into NLP, as opposed to \u201cconstructions all the way down.\u201d The approach is illustrated with the BECauSE corpus of causal language, the BECauSE constructicon, and the Causeway causal language detector, described elsewhere. We argue here that although BECauSE is not a full construction grammar, its lightweight design and compatibility with conventional NLP tools have facilitated progress on and insights into issues related to construction detection in news corpora. The issues we discuss are (1) individuating families of constructions, and (2) dealing with co-present, non-prototypical meanings that may be present alongside the prototypical meaning of a construction. Particularly signi\ufb01cant is the observation that the BECauSE constructicon highlights the importance of integrating frame-evoking constructions into frame semantic resources such as FrameNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                },
                {
                    "authorId": "1903312",
                    "name": "Miriam R. L. Petruck"
                }
            ]
        },
        {
            "paperId": "1f3acc26346ec3a1e2ed66771c3feb598a843318",
            "title": "Annotating Causal Language Using Corpus Lexicography of Constructions",
            "abstract": "Detecting and analyzing causal language is essential to extracting semantic relationships. To that end, we present an annotation scheme for English causal language (not metaphysical causality), and discuss two methodologies for annotation. The first uses only a coding manual to train annotators in distinguishing causal from non-causal language. To address low inter-coder agreement, we adopted a second methodology, in which we first created a causal language constructicon based on corpus analysis, then required annotators only to annotate instances based on the constructicon. (This resembles the methodology used for annotating the FrameNet and PropBank corpora.) Our contributions, in addition to the annotation scheme itself, are methodological: we discuss when constructicon-based methodology is appropriate, and address the validity of annotation schemes that require expertlevel metalinguistic awareness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                }
            ]
        },
        {
            "paperId": "36a181c75ecf77be863cea34adb21398fadd7b5f",
            "title": "A New Entity Salience Task with Millions of Training Examples",
            "abstract": "Although many NLP systems are moving toward entity-based processing, most still identify important phrases using classical keyword-based approaches. To bridge this gap, we introduce the task of entity salience: assigning a relevance score to each entity in a document. We demonstrate how a labeled corpus for the task can be automatically generated from a corpus of documents and accompanying abstracts. We then show how a classifier with features derived from a standard NLP pipeline outperforms a strong baseline by 34%. Finally, we outline initial experiments on further improving accuracy by leveraging background knowledge about the relationships between entities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "2396669",
                    "name": "D. Gillick"
                }
            ]
        },
        {
            "paperId": "21719835cda1b9b2703da4e1874dd3a2bf8e9bf5",
            "title": "The Effects of Lexical Resource Quality on Preference Violation Detection",
            "abstract": "Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. Often, the resources are used as-is, without question or examination. This practice risks missing significant performance gains and even entire techniques. This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. We present DAVID, a simple, lexical resource-based preference violation detector. With asis lexical resources, DAVID achieves an F1-measure of just 28.27%. When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources. More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                },
                {
                    "authorId": "1686960",
                    "name": "Lori S. Levin"
                },
                {
                    "authorId": "143712374",
                    "name": "J. Carbonell"
                }
            ]
        },
        {
            "paperId": "6a5573248fea7448617f1412308b4f937a641e38",
            "title": "PyDecay/GraphPhys: A Unified Language and Storage System for Particle Decay Process Descriptions",
            "abstract": "To ease the tasks of Monte Carlo (MC) simulation and event reconstruction (i.e. inferring particle-decay events from experimental data) for long-term BaBar data preservation and analysis, the following software components have been designed: a language ('GraphPhys') for specifying decay processes, common to both simulation and data analysis, allowing arbitrary parameters on particles, decays, and entire processes; an automated visualization tool to show graphically what decays have been specified; and a searchable database storage mechanism for decay specifications. Unlike HepML, a proposed XML standard for HEP metadata, the specification language is designed not for data interchange between computer systems, but rather for direct manipulation by human beings as well as computers. The components are interoperable: the information parsed from files in the specification language can easily be rendered as an image by the visualization package, and conversion between decay representations was implemented. Several proof-of-concept command-line tools were built based on this framework. Applications include building easier and more efficient interfaces to existing analysis tools for current projects (e.g. BaBar/BESII), providing a framework for analyses in future experimental settings (e.g. LHC/SuperB), and outreach programs that involve giving students access to BaBar data and analysis tools to give them a hands-on feel formore\u00a0\u00bb scientific analysis.\u00ab\u00a0less",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2076678",
                    "name": "Jesse Dunietz"
                }
            ]
        }
    ]
}