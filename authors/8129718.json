{
    "authorId": "8129718",
    "papers": [
        {
            "paperId": "098be01c95b4c18e2c7e8b4164d29dbb0903e71f",
            "title": "Can a Multichoice Dataset be Repurposed for Extractive Question Answering?",
            "abstract": "The rapid evolution of Natural Language Processing (NLP) has favored major languages such as English, leaving a significant gap for many others due to limited resources. This is especially evident in the context of data annotation, a task whose importance cannot be underestimated, but which is time-consuming and costly. Thus, any dataset for resource-poor languages is precious, in particular when it is task-specific. Here, we explore the feasibility of repurposing existing datasets for a new NLP task: we repurposed the Belebele dataset (Bandarkar et al., 2023), which was designed for multiple-choice question answering (MCQA), to enable extractive QA (EQA) in the style of machine reading comprehension. We present annotation guidelines and a parallel EQA dataset for English and Modern Standard Arabic (MSA). We also present QA evaluation results for several monolingual and cross-lingual QA pairs including English, MSA, and five Arabic dialects. Our aim is to enable others to adapt our approach for the 120+ other language variants in Belebele, many of which are deemed under-resourced. We also conduct a thorough analysis and share our insights from the process, which we hope will contribute to a deeper understanding of the challenges and the opportunities associated with task reformulation in NLP research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298756162",
                    "name": "Teresa Lynn"
                },
                {
                    "authorId": "51935928",
                    "name": "Malik H. Altakrori"
                },
                {
                    "authorId": "148087360",
                    "name": "S. Magdy"
                },
                {
                    "authorId": "2211732585",
                    "name": "Rocktim Jyoti Das"
                },
                {
                    "authorId": "2266387313",
                    "name": "Chenyang Lyu"
                },
                {
                    "authorId": "2056258384",
                    "name": "Mohamed Nasr"
                },
                {
                    "authorId": "2282523149",
                    "name": "Younes Samih"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "1781292",
                    "name": "S. Roukos"
                },
                {
                    "authorId": "2261287685",
                    "name": "Radu Florian"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                }
            ]
        },
        {
            "paperId": "3aabd69e13f64f10fd210e4e9e6b2e75c0e734d1",
            "title": "CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark",
            "abstract": "Visual Question Answering (VQA) is an important task in multimodal AI, and it is often used to test the ability of vision-language models to understand and reason on knowledge present in both visual and textual data. However, most of the current VQA models use datasets that are primarily focused on English and a few major world languages, with images that are typically Western-centric. While recent efforts have tried to increase the number of languages covered on VQA datasets, they still lack diversity in low-resource languages. More importantly, although these datasets often extend their linguistic range via translation or some other approaches, they usually keep images the same, resulting in narrow cultural representation. To address these limitations, we construct CVQA, a new Culturally-diverse multilingual Visual Question Answering benchmark, designed to cover a rich set of languages and cultures, where we engage native speakers and cultural experts in the data collection process. As a result, CVQA includes culturally-driven images and questions from across 28 countries on four continents, covering 26 languages with 11 scripts, providing a total of 9k questions. We then benchmark several Multimodal Large Language Models (MLLMs) on CVQA, and show that the dataset is challenging for the current state-of-the-art models. This benchmark can serve as a probing evaluation suite for assessing the cultural capability and bias of multimodal models and hopefully encourage more research efforts toward increasing cultural awareness and linguistic diversity in this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305602940",
                    "name": "David Romero"
                },
                {
                    "authorId": "2266387313",
                    "name": "Chenyang Lyu"
                },
                {
                    "authorId": "49918371",
                    "name": "Haryo Akbarianto Wibowo"
                },
                {
                    "authorId": "2298756162",
                    "name": "Teresa Lynn"
                },
                {
                    "authorId": "3248560",
                    "name": "Injy Hamed"
                },
                {
                    "authorId": "2305619033",
                    "name": "Aditya Nanda Kishore"
                },
                {
                    "authorId": "2305622255",
                    "name": "Aishik Mandal"
                },
                {
                    "authorId": "2305619182",
                    "name": "Alina Dragonetti"
                },
                {
                    "authorId": "1396213362",
                    "name": "Artem Abzaliev"
                },
                {
                    "authorId": "2148631756",
                    "name": "A. Tonja"
                },
                {
                    "authorId": "2305622331",
                    "name": "Bontu Fufa Balcha"
                },
                {
                    "authorId": "2161240241",
                    "name": "Chenxi Whitehouse"
                },
                {
                    "authorId": "51124788",
                    "name": "Christian Salamea"
                },
                {
                    "authorId": "1994718316",
                    "name": "Dan John Velasco"
                },
                {
                    "authorId": "2273673245",
                    "name": "D. Adelani"
                },
                {
                    "authorId": "70145452",
                    "name": "D. Meur"
                },
                {
                    "authorId": "2183780558",
                    "name": "Emilio Villa-Cueva"
                },
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2266756359",
                    "name": "Fauzan Farooqui"
                },
                {
                    "authorId": "1738707459",
                    "name": "Frederico Belcavello"
                },
                {
                    "authorId": "2151970366",
                    "name": "Ganzorig Batnasan"
                },
                {
                    "authorId": "2305623074",
                    "name": "Gisela Vallejo"
                },
                {
                    "authorId": "2305619231",
                    "name": "Grainne Caulfield"
                },
                {
                    "authorId": "2213060824",
                    "name": "Guido Ivetta"
                },
                {
                    "authorId": "2980506",
                    "name": "Haiyue Song"
                },
                {
                    "authorId": "2305619369",
                    "name": "Henok Biadglign Ademtew"
                },
                {
                    "authorId": "2139773809",
                    "name": "Hern\u00e1n Maina"
                },
                {
                    "authorId": "116344405",
                    "name": "Holy Lovenia"
                },
                {
                    "authorId": "2304752238",
                    "name": "Israel Abebe Azime"
                },
                {
                    "authorId": "2282499634",
                    "name": "Jan Christian Blaise Cruz"
                },
                {
                    "authorId": "1992915388",
                    "name": "Jay Gala"
                },
                {
                    "authorId": "2266466915",
                    "name": "Jiahui Geng"
                },
                {
                    "authorId": "1724941617",
                    "name": "Jes\u00fas-Germ\u00e1n Ortiz-Barajas"
                },
                {
                    "authorId": "90765684",
                    "name": "Jinheon Baek"
                },
                {
                    "authorId": "2305082736",
                    "name": "Jocelyn Dunstan"
                },
                {
                    "authorId": "2276687",
                    "name": "L. A. Alemany"
                },
                {
                    "authorId": "2290013575",
                    "name": "Kumaranage Ravindu Yasas Nagasinghe"
                },
                {
                    "authorId": "2066254822",
                    "name": "Luciana Benotti"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1738707461",
                    "name": "Marcelo Viridiano"
                },
                {
                    "authorId": "2168569460",
                    "name": "Marcos Estecha-Garitagoitia"
                },
                {
                    "authorId": "2305622553",
                    "name": "Maria Camila Buitrago Cabrera"
                },
                {
                    "authorId": "2220406508",
                    "name": "Mario Rodr'iguez-Cantelar"
                },
                {
                    "authorId": "71090258",
                    "name": "M\u00e9lanie Jouitteau"
                },
                {
                    "authorId": "121947924",
                    "name": "M. Mihaylov"
                },
                {
                    "authorId": "2305619376",
                    "name": "Mohamed Fazli Mohamed Imam"
                },
                {
                    "authorId": "2191731497",
                    "name": "Muhammad Farid Adilazuarda"
                },
                {
                    "authorId": "66556569",
                    "name": "Munkhjargal Gochoo"
                },
                {
                    "authorId": "2159634278",
                    "name": "Munkh-Erdene Otgonbold"
                },
                {
                    "authorId": "1742219452",
                    "name": "Naome A. Etori"
                },
                {
                    "authorId": "2305623065",
                    "name": "Olivier Niyomugisha"
                },
                {
                    "authorId": "2307313242",
                    "name": "Paula M'onica Silva"
                },
                {
                    "authorId": "2040713514",
                    "name": "Pranjal A. Chitale"
                },
                {
                    "authorId": "3209719",
                    "name": "Raj Dabre"
                },
                {
                    "authorId": "2148764367",
                    "name": "Rendi Chevi"
                },
                {
                    "authorId": "49775305",
                    "name": "Ruochen Zhang"
                },
                {
                    "authorId": "2197070752",
                    "name": "Ryandito Diandaru"
                },
                {
                    "authorId": "66986482",
                    "name": "Samuel Cahyawijaya"
                },
                {
                    "authorId": "2305622481",
                    "name": "Santiago G'ongora"
                },
                {
                    "authorId": "8599185",
                    "name": "Soyeong Jeong"
                },
                {
                    "authorId": "152881983",
                    "name": "Sukannya Purkayastha"
                },
                {
                    "authorId": "83446147",
                    "name": "Tatsuki Kuribayashi"
                },
                {
                    "authorId": "2219413815",
                    "name": "Thanmay Jayakumar"
                },
                {
                    "authorId": "2244512282",
                    "name": "T. Torrent"
                },
                {
                    "authorId": "2305621229",
                    "name": "Toqeer Ehsan"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "51208524",
                    "name": "Yova Kementchedjhieva"
                },
                {
                    "authorId": "2305621242",
                    "name": "Zara Burzo"
                },
                {
                    "authorId": "2305621264",
                    "name": "Zheng Wei Lim"
                },
                {
                    "authorId": "2282475073",
                    "name": "Zheng-Xin Yong"
                },
                {
                    "authorId": "2293317558",
                    "name": "Oana Ignat"
                },
                {
                    "authorId": "2218338376",
                    "name": "Joan Nwatu"
                },
                {
                    "authorId": "2105984203",
                    "name": "Rada Mihalcea"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                }
            ]
        },
        {
            "paperId": "3d4b5e6f59deba7a4fb76fa095ea6a562a8f5ee0",
            "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
            "abstract": "Hate speech poses a significant threat to social harmony. Over the past two years, Indonesia has seen a ten-fold increase in the online hate speech ratio, underscoring the urgent need for effective detection mechanisms. However, progress is hindered by the limited availability of labeled data for Indonesian texts. The condition is even worse for marginalized minorities, such as Shia, LGBTQ, and other ethnic minorities because hate speech is underreported and less understood by detection tools. Furthermore, the lack of accommodation for subjectivity in current datasets compounds this issue. To address this, we introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity classification dataset. Comprising 43,692 entries annotated by 19 diverse individuals, the dataset focuses on texts targeting vulnerable groups in Indonesia, specifically during the hottest political event in the country: the presidential election. We establish baselines for seven binary classification tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet) fine-tuned for hate speech classification. Furthermore, we demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo. However, we also caution that an overemphasis on demographic information can negatively impact the fine-tuned model performance due to data fragmentation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264978269",
                    "name": "Lucky Susanto"
                },
                {
                    "authorId": "2284094503",
                    "name": "M. Wijanarko"
                },
                {
                    "authorId": "2189333534",
                    "name": "Prasetia Anugrah Pratama"
                },
                {
                    "authorId": "2308465842",
                    "name": "Traci Hong"
                },
                {
                    "authorId": "2284088774",
                    "name": "Ika Idris"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2308468276",
                    "name": "Derry Wijaya"
                }
            ]
        },
        {
            "paperId": "5428341c98bfaf4dfeac1a25ef22b56ab3480e64",
            "title": "Daisy-TTS: Simulating Wider Spectrum of Emotions via Prosody Embedding Decomposition",
            "abstract": "We often verbally express emotions in a multifaceted manner, they may vary in their intensities and may be expressed not just as a single but as a mixture of emotions. This wide spectrum of emotions is well-studied in the structural model of emotions, which represents variety of emotions as derivative products of primary emotions with varying degrees of intensity. In this paper, we propose an emotional text-to-speech design to simulate a wider spectrum of emotions grounded on the structural model. Our proposed design, Daisy-TTS, incorporates a prosody encoder to learn emotionally-separable prosody embedding as a proxy for emotion. This emotion representation allows the model to simulate: (1) Primary emotions, as learned from the training samples, (2) Secondary emotions, as a mixture of primary emotions, (3) Intensity-level, by scaling the emotion embedding, and (4) Emotions polarity, by negating the emotion embedding. Through a series of perceptual evaluations, Daisy-TTS demonstrated overall higher emotional speech naturalness and emotion perceiveability compared to the baseline.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2148764367",
                    "name": "Rendi Chevi"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                }
            ]
        },
        {
            "paperId": "5a0573a3c15d094e8b3d488c11a660773f631070",
            "title": "Towards Measuring and Modeling \"Culture\" in LLMs: A Survey",
            "abstract": "We present a survey of more than 90 recent papers that aim to study cultural representation and inclusion in large language models (LLMs). We observe that none of the studies explicitly define\"culture, which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of\"culture\". We call these aspects the proxies of culture, and organize them across two dimensions of demographic and semantic proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of ``culture,'' such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness of probing techniques and situated studies on the impact of cultural mis- and under-representation in LLM-based applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191731497",
                    "name": "Muhammad Farid Adilazuarda"
                },
                {
                    "authorId": "2293359300",
                    "name": "Sagnik Mukherjee"
                },
                {
                    "authorId": "2262446167",
                    "name": "Pradhyumna Lavania"
                },
                {
                    "authorId": "2293352196",
                    "name": "Siddhant Singh"
                },
                {
                    "authorId": "2262445503",
                    "name": "Ashutosh Dwivedi"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2293317227",
                    "name": "Jacki O'Neill"
                },
                {
                    "authorId": "2477939",
                    "name": "Ashutosh Modi"
                },
                {
                    "authorId": "143990839",
                    "name": "M. Choudhury"
                }
            ]
        },
        {
            "paperId": "64c8edfd8db83a893eaf0e2d137acb23eb698fd3",
            "title": "SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages",
            "abstract": "Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader phenomenon of semantic relatedness. In this paper, we present \\textit{SemRel}, a new semantic relatedness dataset collection annotated by native speakers across 13 languages: \\textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Spanish,} and \\textit{Telugu}. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia -- regions characterised by a relatively limited availability of NLP resources. Each instance in the SemRel datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. The scores are obtained using a comparative annotation framework. We describe the data collection and annotation processes, challenges when building the datasets, baseline experiments, and their impact and utility in NLP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3056500",
                    "name": "N. Ousidhoum"
                },
                {
                    "authorId": "7744881",
                    "name": "Shamsuddeen Hassan Muhammad"
                },
                {
                    "authorId": "2283931971",
                    "name": "Mohamed Abdalla"
                },
                {
                    "authorId": "2260237439",
                    "name": "Idris Abdulmumin"
                },
                {
                    "authorId": "153795444",
                    "name": "I. Ahmad"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "71323208",
                    "name": "A. Ayele"
                },
                {
                    "authorId": "2269468034",
                    "name": "Pavan Baswani"
                },
                {
                    "authorId": "2604621",
                    "name": "Meriem Beloucif"
                },
                {
                    "authorId": "1829342",
                    "name": "Christian Biemann"
                },
                {
                    "authorId": "2266839087",
                    "name": "Sofia Bourhim"
                },
                {
                    "authorId": "2047358683",
                    "name": "Christine de Kock"
                },
                {
                    "authorId": "2283935559",
                    "name": "Genet Shanko Dekebo"
                },
                {
                    "authorId": "23245535",
                    "name": "Oumaima Hourrane"
                },
                {
                    "authorId": "2268675106",
                    "name": "Gopichand Kanumolu"
                },
                {
                    "authorId": "2268674912",
                    "name": "Lokesh Madasu"
                },
                {
                    "authorId": "30571646",
                    "name": "Samuel Rutunda"
                },
                {
                    "authorId": "2280905799",
                    "name": "Manish Shrivastava"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "2104748735",
                    "name": "Nirmal Surange"
                },
                {
                    "authorId": "2283932533",
                    "name": "Hailegnaw Getaneh Tilaye"
                },
                {
                    "authorId": "51172231",
                    "name": "Krishnapriya Vishnubhotla"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "3084761",
                    "name": "Seid Muhie Yimam"
                },
                {
                    "authorId": "2261458500",
                    "name": "Saif Mohammad"
                }
            ]
        },
        {
            "paperId": "6ca159dcdf5c4ef22037e3632a317d0c0433c262",
            "title": "Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino",
            "abstract": "Multilingual large language models (LLMs) today may not necessarily provide culturally appropriate and relevant responses to its Filipino users. We introduce Kalahi, a cultural LLM evaluation suite collaboratively created by native Filipino speakers. It is composed of 150 high-quality, handcrafted and nuanced prompts that test LLMs for generations that are relevant to shared Filipino cultural knowledge and values. Strong LLM performance in Kalahi indicates a model's ability to generate responses similar to what an average Filipino would say or do in a given situation. We conducted experiments on LLMs with multilingual and Filipino language support. Results show that Kalahi, while trivial for Filipinos, is challenging for LLMs, with the best model answering only 46.0% of the questions correctly compared to native Filipino performance of 89.10%. Thus, Kalahi can be used to accurately and reliably evaluate Filipino cultural representation in LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "88741020",
                    "name": "J. Montalan"
                },
                {
                    "authorId": "119076558",
                    "name": "Jian Gang Ngui"
                },
                {
                    "authorId": "2140097897",
                    "name": "Wei Qi Leong"
                },
                {
                    "authorId": "2239100505",
                    "name": "Yosephine Susanto"
                },
                {
                    "authorId": "2151003240",
                    "name": "Hamsawardhini Rengarajan"
                },
                {
                    "authorId": "2618006",
                    "name": "William-Chandra Tjhi"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                }
            ]
        },
        {
            "paperId": "8f48c6e1c7107dd19a55661a4d79fb5868d66e39",
            "title": "Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting",
            "abstract": "Socio-demographic prompting is a commonly employed approach to study cultural biases in LLMs as well as for aligning models to certain cultures. In this paper, we systematically probe four LLMs (Llama 3, Mistral v0.2, GPT-3.5 Turbo and GPT-4) with prompts that are conditioned on culturally sensitive and non-sensitive cues, on datasets that are supposed to be culturally sensitive (EtiCor and CALI) or neutral (MMLU and ETHICS). We observe that all models except GPT-4 show significant variations in their responses on both kinds of datasets for both kinds of prompts, casting doubt on the robustness of the culturally-conditioned prompting as a method for eliciting cultural bias in models or as an alignment strategy. The work also calls rethinking the control experiment design to tease apart the cultural conditioning of responses from\"placebo effect\", i.e., random perturbations of model responses due to arbitrary tokens in the prompt.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293359300",
                    "name": "Sagnik Mukherjee"
                },
                {
                    "authorId": "2191731497",
                    "name": "Muhammad Farid Adilazuarda"
                },
                {
                    "authorId": "2256989615",
                    "name": "Sunayana Sitaram"
                },
                {
                    "authorId": "3086996",
                    "name": "Kalika Bali"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "143990839",
                    "name": "M. Choudhury"
                }
            ]
        },
        {
            "paperId": "92940bf82f8163976c0615a97b271b1af71a5b35",
            "title": "SemEval Task 1: Semantic Textual Relatedness for African and Asian Languages",
            "abstract": "We present the first shared task on Semantic Textual Relatedness (STR). While earlier shared tasks primarily focused on semantic similarity, we instead investigate the broader phenomenon of semantic relatedness across 14 languages: Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Punjabi, Spanish, and Telugu. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia \u2013 regions characterised by the relatively limited availability of NLP resources. Each instance in the datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. Participating systems were asked to rank sentence pairs by their closeness in meaning (i.e., their degree of semantic relatedness) in the 14 languages in three main tracks: (a) supervised, (b) unsupervised, and (c) crosslingual. The task attracted 163 participants. We received 70 submissions in total (across all tasks) from 51 different teams, and 38 system description papers. We report on the best-performing systems as well as the most common and the most effective approaches for the three different tracks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3056500",
                    "name": "N. Ousidhoum"
                },
                {
                    "authorId": "7744881",
                    "name": "Shamsuddeen Hassan Muhammad"
                },
                {
                    "authorId": "2283931971",
                    "name": "Mohamed Abdalla"
                },
                {
                    "authorId": "2260237439",
                    "name": "Idris Abdulmumin"
                },
                {
                    "authorId": "153795444",
                    "name": "I. Ahmad"
                },
                {
                    "authorId": "2266387781",
                    "name": "Sanchit Ahuja"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2283931820",
                    "name": "Vladimir Araujo"
                },
                {
                    "authorId": "2604621",
                    "name": "Meriem Beloucif"
                },
                {
                    "authorId": "2047358683",
                    "name": "Christine de Kock"
                },
                {
                    "authorId": "23245535",
                    "name": "Oumaima Hourrane"
                },
                {
                    "authorId": "2280905799",
                    "name": "Manish Shrivastava"
                },
                {
                    "authorId": "1794626",
                    "name": "T. Solorio"
                },
                {
                    "authorId": "2104748735",
                    "name": "Nirmal Surange"
                },
                {
                    "authorId": "2293724273",
                    "name": "Krishnapriya Vishnubhotla"
                },
                {
                    "authorId": "3084761",
                    "name": "Seid Muhie Yimam"
                },
                {
                    "authorId": "2261458500",
                    "name": "Saif Mohammad"
                }
            ]
        },
        {
            "paperId": "ba5284674face6cca3b678fd7a82d691ec29349b",
            "title": "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages",
            "abstract": "Southeast Asia (SEA) is a region rich in linguistic diversity and cultural variety, with over 1,300 indigenous languages and a population of 671 million people. However, prevailing AI models suffer from a significant lack of representation of texts, images, and audio datasets from SEA, compromising the quality of AI models for SEA languages. Evaluating models for SEA languages is challenging due to the scarcity of high-quality datasets, compounded by the dominance of English training data, raising concerns about potential cultural misrepresentation. To address these challenges, we introduce SEACrowd, a collaborative initiative that consolidates a comprehensive resource hub that fills the resource gap by providing standardized corpora in nearly 1,000 SEA languages across three modalities. Through our SEACrowd benchmarks, we assess the quality of AI models on 36 indigenous languages across 13 tasks, offering valuable insights into the current AI landscape in SEA. Furthermore, we propose strategies to facilitate greater AI advancements, maximizing potential utility and resource equity for the future of AI in SEA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "116344405",
                    "name": "Holy Lovenia"
                },
                {
                    "authorId": "1935324",
                    "name": "Rahmad Mahendra"
                },
                {
                    "authorId": "2242161500",
                    "name": "Salsabil Maulana Akbar"
                },
                {
                    "authorId": "13614871",
                    "name": "Lester James Validad Miranda"
                },
                {
                    "authorId": "117696399",
                    "name": "Jennifer Santoso"
                },
                {
                    "authorId": "2306780850",
                    "name": "Elyanah Aco"
                },
                {
                    "authorId": "2306780925",
                    "name": "Akhdan Fadhilah"
                },
                {
                    "authorId": "2218861055",
                    "name": "Jonibek Mansurov"
                },
                {
                    "authorId": "151472158",
                    "name": "Joseph Marvin Imperial"
                },
                {
                    "authorId": "145315291",
                    "name": "Onno P. Kampman"
                },
                {
                    "authorId": "22272110",
                    "name": "Joel Ruben Antony Moniz"
                },
                {
                    "authorId": "2306780704",
                    "name": "Muhammad Ravi Shulthan Habibi"
                },
                {
                    "authorId": "2197090652",
                    "name": "Frederikus Hudi"
                },
                {
                    "authorId": "2306780357",
                    "name": "Railey Montalan"
                },
                {
                    "authorId": "2197071063",
                    "name": "Ryan Ignatius"
                },
                {
                    "authorId": "2265829074",
                    "name": "Joanito Agili Lopo"
                },
                {
                    "authorId": "2306780376",
                    "name": "William Nixon"
                },
                {
                    "authorId": "2047947436",
                    "name": "B\u00f6rje F. Karlsson"
                },
                {
                    "authorId": "2197071075",
                    "name": "James Jaya"
                },
                {
                    "authorId": "2197070752",
                    "name": "Ryandito Diandaru"
                },
                {
                    "authorId": "2258725381",
                    "name": "Yuze Gao"
                },
                {
                    "authorId": "2306258046",
                    "name": "Patrick Amadeus Irawan"
                },
                {
                    "authorId": "2306845506",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2282499634",
                    "name": "Jan Christian Blaise Cruz"
                },
                {
                    "authorId": "2161240241",
                    "name": "Chenxi Whitehouse"
                },
                {
                    "authorId": "134112343",
                    "name": "Ivan Halim Parmonangan"
                },
                {
                    "authorId": "2306780394",
                    "name": "Maria Khelli"
                },
                {
                    "authorId": "2306875069",
                    "name": "Wenyu Zhang"
                },
                {
                    "authorId": "2264978269",
                    "name": "Lucky Susanto"
                },
                {
                    "authorId": "2306781205",
                    "name": "Reynard Adha Ryanda"
                },
                {
                    "authorId": "2306780442",
                    "name": "Sonny Lazuardi Hermawan"
                },
                {
                    "authorId": "1994718316",
                    "name": "Dan John Velasco"
                },
                {
                    "authorId": "2264979805",
                    "name": "Muhammad Dehan Al Kautsar"
                },
                {
                    "authorId": "2093270493",
                    "name": "Willy Fitra Hendria"
                },
                {
                    "authorId": "9400076",
                    "name": "Yasmin Moslem"
                },
                {
                    "authorId": "2306780349",
                    "name": "Noah Flynn"
                },
                {
                    "authorId": "2191731497",
                    "name": "Muhammad Farid Adilazuarda"
                },
                {
                    "authorId": "2188740060",
                    "name": "Haochen Li"
                },
                {
                    "authorId": "2306864026",
                    "name": "Johanes Lee"
                },
                {
                    "authorId": "2162893011",
                    "name": "R. Damanhuri"
                },
                {
                    "authorId": "2307389481",
                    "name": "Shuo Sun"
                },
                {
                    "authorId": "2181162339",
                    "name": "M. Qorib"
                },
                {
                    "authorId": "2261492948",
                    "name": "Amirbek Djanibekov"
                },
                {
                    "authorId": "2140097897",
                    "name": "Wei Qi Leong"
                },
                {
                    "authorId": "2187874252",
                    "name": "Quyet V. Do"
                },
                {
                    "authorId": "2037383772",
                    "name": "Niklas Muennighoff"
                },
                {
                    "authorId": "113610145",
                    "name": "T. Pansuwan"
                },
                {
                    "authorId": "1943296899",
                    "name": "Ilham Firdausi Putra"
                },
                {
                    "authorId": "2286341163",
                    "name": "Yan Xu"
                },
                {
                    "authorId": "2306780314",
                    "name": "Ngee Chia Tai"
                },
                {
                    "authorId": "2257345523",
                    "name": "Ayu Purwarianti"
                },
                {
                    "authorId": "2884561",
                    "name": "Sebastian Ruder"
                },
                {
                    "authorId": "2618006",
                    "name": "William-Chandra Tjhi"
                },
                {
                    "authorId": "1596821065",
                    "name": "Peerat Limkonchotiwat"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "150299584",
                    "name": "Sedrick Scott Keh"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "49775305",
                    "name": "Ruochen Zhang"
                },
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2282475073",
                    "name": "Zheng-Xin Yong"
                },
                {
                    "authorId": "2220548276",
                    "name": "Samuel Cahyawijaya"
                }
            ]
        }
    ]
}