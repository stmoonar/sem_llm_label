{
    "authorId": "98756666",
    "papers": [
        {
            "paperId": "9ab7516ba3dea383cb4f71744bfc993221a1ce35",
            "title": "Evidence Reasoning and Curriculum Learning for Document-Level Relation Extraction",
            "abstract": "Document-level Relation Extraction (RE) is a promising task aiming at identifying relations of multiple entity pairs in a document. Compared with the sentence-level counterpart, it has raised two significant challenges: a) In most cases, a relational fact can be adequately expressed via a small subset of sentences from the document, namely evidence. But the traditional method cannot model such strong semantic correlations between evidence sentences that collaborate to describe a specific relation; b) The data of this task is extremely long-tail in terms of too many NA instances and imbalanced relational types. Such data can mislead the tail prediction bias to the head categories in the RE model. In this paper, we present a novel Evidence reasoning and Curriculum learning method for DocRE (DRE-EC) to address these challenges. Particularly, we first formulate evidence extraction as a sequential decision problem through a crafted reinforcement learning mechanism with an efficient path searching strategy to reduce the action space. Providing the evidence for each entity pair as a customized-filtered document in advance helps infer the relations better. To address the long-tail issue, we further develop a hybrid curriculum learning method at the NA-level (NC) and relation-level (RC) with our customized difficulty measure score. In NC, the NA samples are scheduled in an easy-to-hard scheme and gradually added, resulting in the data distribution from ideal and balanced to real and unbalanced. In RC, the scheme is switched into hard-to-easy to enhance the hard and tail samples. In addition, we propose a new Equalization adaptive Focal Loss(EFLoss) that can adjust to the changing data distribution and focus more on the tail categories. We conduct various experiments on two document-level RE benchmarks and achieve a remarkable improvement over previous competitive baselines. Furthermore, we provide detailed analyses of the advantages and effectiveness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2213778042",
                    "name": "Tianyu Xu"
                },
                {
                    "authorId": "2069479032",
                    "name": "Jianfeng Qu"
                },
                {
                    "authorId": "144051547",
                    "name": "Wen Hua"
                },
                {
                    "authorId": "115419489",
                    "name": "Zhixu Li"
                },
                {
                    "authorId": "3757313",
                    "name": "Jiajie Xu"
                },
                {
                    "authorId": "144675135",
                    "name": "An Liu"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                },
                {
                    "authorId": "2180369166",
                    "name": "Xiaofang Zhou"
                }
            ]
        },
        {
            "paperId": "d162b7e09bf16cd9aa0b7b5304938f49a6b9e6de",
            "title": "Multi-Hop Knowledge Graph Reasoning in Few-Shot Scenarios",
            "abstract": "Reinforcement learning (RL)-based multi-hop reasoning has become an interpretable way for knowledge graph reasoning owing to its persuasive explanations for the predicted results, but the reasoning performance of these methods drops significantly over few-shot relations (only contain few triplets). To address this problem, recent studies introduce meta-learning into RL-based reasoning methods. However, the performance of these studies is still limited due to the following points: (1) the overall reasoning accuracy is impaired due to the low reasoning accuracies over some hard relations; (2) the reasoning process becomes laborious and ineffective owing to the existence of noisy data; (3) the generalizability is negatively affected due to the lack of knowledge-sharing. To tackle these challenges, we propose a novel model HMLS consisting of two modules HHML (Hierarchical Hardness-aware Meta-reinforcement Learning) and HHS (Hierarchical Hardness-aware Sampling). Specifically, HHML contains the following two components: (1) a hardness-aware RL conducts multi-hop reasoning by training hardness-aware batches and reducing noise; (2) a knowledge-sharing meta-learning adapts to few-shot relations by exploiting common features in the hierarchical relation structure. The other module HHS generates hardness-aware batches from relation and relation-cluster levels. The experimental results demonstrate that this work notably outperforms the state-of-the-art approaches in few-shot scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1384404569",
                    "name": "Shangfei Zheng"
                },
                {
                    "authorId": "2154939288",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2109080349",
                    "name": "Weiqing Wang"
                },
                {
                    "authorId": "2927967",
                    "name": "Pengpeng Zhao"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                }
            ]
        },
        {
            "paperId": "121a882fa76a699ab7e0b8517c0ca6d7f297b017",
            "title": "TKGF-NTP: Temporal Knowledge Graph Forecasting via Neural Temporal Point Process",
            "abstract": "Knowledge graphs (KGs) with real-world facts are vital for various downstream applications. However, the incomplete nature of KGs has brought lots of problems to them, and probing missing facts via reasoning or forecasting has become a promising solution. Different from the traditional KG reasoning focusing on static facts, temporal knowledge graph (TKG) forecasting incorporating time information presents more potential in event prediction, as many facts are dynamic in real-world. Despite the significance of TKG forecasting, the following inevitable problems bring great challenges for it. (1) How to alleviate the problem of temporal fact redundancy in the TKG? (2) How to merge the useful fragmented temporal facts for the given query throughout the TKG? To overcome these problems effectively, we propose a novel model entitled TKGF-NTP, which consists of two components. (1) A structural encoder is developed to aggregate the most valuable structural information and filter out the redundant temporal facts from each TKG snapshot. (2) A temporal encoder is designed to capture the evolutions of entities, while the self-attention mechanism is employed to capture the most crucial temporal information throughout the TKG. The effectiveness of TKGF-NTP is evaluated on four public datasets via link prediction, and the results demonstrate its superiority over the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2242899968",
                    "name": "Gaojie Han"
                },
                {
                    "authorId": "2154939288",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2243237415",
                    "name": "Xiaofang Zhang"
                },
                {
                    "authorId": "2242875003",
                    "name": "Jiajie Xu"
                },
                {
                    "authorId": "144806511",
                    "name": "An Liu"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                }
            ]
        },
        {
            "paperId": "2dcc5f6e5e46632c65122790590a330bccf20ceb",
            "title": "Sequential Recommendation with Probabilistic Logical Reasoning",
            "abstract": "Deep learning and symbolic learning are two frequently employed methods in Sequential Recommendation (SR). Recent neural-symbolic SR models demonstrate their potential to enable SR to be equipped with concurrent perception and cognition capacities. However, neural-symbolic SR remains a challenging problem due to open issues like representing users and items in logical reasoning. In this paper, we combine the Deep Neural Network (DNN) SR models with logical reasoning and propose a general framework named Sequential Recommendation with Probabilistic Logical Reasoning (short for SR-PLR). This framework allows SR-PLR to benefit from both similarity matching and logical reasoning by disentangling feature embedding and logic embedding in the DNN and probabilistic logic network. To better capture the uncertainty and evolution of user tastes, SR-PLR embeds users and items with a probabilistic method and conducts probabilistic logical reasoning on users' interaction patterns. Then the feature and logic representations learned from the DNN and logic network are concatenated to make the prediction. Finally, experiments on various sequential recommendation models demonstrate the effectiveness of the SR-PLR. Our code is available at https://github.com/Huanhuaneryuan/SR-PLR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114127495",
                    "name": "Huanhuan Yuan"
                },
                {
                    "authorId": "2927967",
                    "name": "Pengpeng Zhao"
                },
                {
                    "authorId": "2241389",
                    "name": "Xuefeng Xian"
                },
                {
                    "authorId": "8540458",
                    "name": "Guanfeng Liu"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2858764",
                    "name": "Victor S. Sheng"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                }
            ]
        },
        {
            "paperId": "48f101dd68d4a622e04521f21cf019bda4718b77",
            "title": "Mobile crowdsourced test report prioritization based on text and image understanding",
            "abstract": "In the process of mobile crowdsourced testing, a large number of test reports are generated, which often consist of short text and rich image information. One of the critical issues is how to review these reports efficiently. Researchers have recently proposed clustering, classification, and prioritization techniques to solve this problem. However, existing studies directly use related technologies to text description and segment the text content without further understanding of the text content. By deeply digging into the text information and distinguishing it according to its actual meaning, the sentences described in the text can be categorized into two types: Describing abnormal system behavior and describing reproduction steps. This paper proposes a mobile crowdsourced test report prioritization technique to improve performance. First, we use a TextCNN trained on large\u2010scale projects to distinguish the text descriptions of reports, then extract features from the text and screenshot information, respectively. Then we apply a clustering technique to gather similar reports. Finally, the inspection order is sampled from the clustering results. To validate our approach, we conduct experiments on six industrial crowdsourced projects. The results show that our method can detect all bugs faster in a limited time than existing prioritization methods, which can improve the bug reports review efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2129447048",
                    "name": "Yifan Wu"
                },
                {
                    "authorId": "2146874639",
                    "name": "Yao Tong"
                },
                {
                    "authorId": "144675135",
                    "name": "An Liu"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                },
                {
                    "authorId": "2144525635",
                    "name": "Xiaofang Zhang"
                }
            ]
        },
        {
            "paperId": "b7af42cf4221c49cf82d9272d1f84ff9d5d0df1f",
            "title": "Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation",
            "abstract": "Sequential recommendation aims to capture users' dynamic interest and predicts the next item of users' preference. Most sequential recommendation methods use a deep neural network as sequence encoder to generate user and item representations. Existing works mainly center upon designing a stronger sequence encoder. However, few attempts have been made with training an ensemble of networks as sequence encoders, which is more powerful than a single network because an ensemble of parallel networks can yield diverse prediction results and hence better accuracy. In this paper, we present Ensemble Modeling with contrastive Knowledge Distillation for sequential recommendation (EMKD). Our framework adopts multiple parallel networks as an ensemble of sequence encoders and recommends items based on the output distributions of all these networks. To facilitate knowledge transfer between parallel networks, we propose a novel contrastive knowledge distillation approach, which performs knowledge transfer from the representation level via Intra-network Contrastive Learning (ICL) and Cross-network Contrastive Learning (CCL), as well as Knowledge Distillation (KD) from the logits level via minimizing the Kullback-Leibler divergence between the output distributions of the teacher network and the student network. To leverage contextual information, we train the primary masked item prediction task alongside the auxiliary attribute prediction task as a multi-task learning scheme. Extensive experiments on public benchmark datasets show that EMKD achieves a significant improvement compared with the state-of-the-art methods. Besides, we demonstrate that our ensemble method is a generalized approach that can also improve the performance of other sequential recommenders. Our code is available at this link: https://github.com/hw-du/EMKD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065003838",
                    "name": "Hanwen Du"
                },
                {
                    "authorId": "2114127495",
                    "name": "Huanhuan Yuan"
                },
                {
                    "authorId": "2927967",
                    "name": "Pengpeng Zhao"
                },
                {
                    "authorId": "2104266567",
                    "name": "Fuzhen Zhuang"
                },
                {
                    "authorId": "8540458",
                    "name": "Guanfeng Liu"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2172073298",
                    "name": "Victor S. Sheng"
                }
            ]
        },
        {
            "paperId": "16b8d33462f92cf1c27ab589380c1f2fb42209da",
            "title": "Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation",
            "abstract": "Sequential Recommendation aims to predict the next item based on user behaviour. Recently, Self-Supervised Learning (SSL) has been proposed to improve recommendation performance. However, most of existing SSL methods use a uniform data augmentation scheme, which loses the sequence correlation of an original sequence. To this end, in this paper, we propose a Learnable Model Augmentation self-supervised learning for sequential Recommendation (LMA4Rec). Specifically, LMA4Rec first takes model augmentation as a supplementary method for data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli dropout to implement model augmentation learnable operations. Next, self-supervised learning is used between the contrastive views to extract self-supervised signals from an original sequence. Finally, experiments on three public datasets show that the LMA4Rec method effectively improves sequential recommendation performance compared with baseline methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087103417",
                    "name": "Yongjing Hao"
                },
                {
                    "authorId": "2927967",
                    "name": "Pengpeng Zhao"
                },
                {
                    "authorId": "2241389",
                    "name": "Xuefeng Xian"
                },
                {
                    "authorId": "8540458",
                    "name": "Guanfeng Liu"
                },
                {
                    "authorId": "2118962452",
                    "name": "Deqing Wang"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2858764",
                    "name": "Victor S. Sheng"
                }
            ]
        },
        {
            "paperId": "189bbb8865b8060f8cd1fc248b59fbc51f52b656",
            "title": "Hybrid Model with Multi-Level Code Representation for Multi-Label Code Smell Detection (077)",
            "abstract": "Code smell is an indicator of potential problems in a software design that have a negative impact on readability and maintainability. Hence, detecting code smells in a timely and effective manner can provide guides for developers in refactoring. Fortunately, many approaches like metric-based, heuristic-based, machine-learning-based and deep-learning-based have been proposed to detect code smells. However, existing methods, using the simple code representation to describe different code smells unilaterally, cannot efficiently extract enough rich information from source code. In addition, one code snippet often has several code smells at the same time and there is a lack of multi-label code smell detection based on deep learning. In this paper, we present a large-scale dataset for the multi-label code smell detection task since there is still no publicly sufficient dataset for this task. The release of this dataset would push forward the research in this field. Based on it, we propose a hybrid model with multi-level code representation to further optimize the code smell detection. First, we parse the code into the abstract syntax tree (AST) with control and data flow edges and the graph convolution network is applied to get the prediction at the syntactic and semantic level. Then we use the bidirectional long-short term memory network with attention mechanism to analyze the code tokens at the token-level in the meanwhile. Finally, we get the fusion prediction result of the models. Experimental results illustrate that our proposed model outperforms the state-of-the-art methods not only in single code smell detection but also in multi-label code smell detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Yichen Li"
                },
                {
                    "authorId": "144675135",
                    "name": "An Liu"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                },
                {
                    "authorId": "49470221",
                    "name": "Xiaofang Zhang"
                }
            ]
        },
        {
            "paperId": "190cc86d0e6172ea8090f455f3b25fff6358a160",
            "title": "Contrastive Learning with Bidirectional Transformers for Sequential Recommendation",
            "abstract": "Contrastive learning with Transformer-based sequence encoder has gained predominance for sequential recommendation. It maximizes the agreements between paired sequence augmentations that share similar semantics. However, existing contrastive learning approaches in sequential recommendation mainly center upon left-to-right unidirectional Transformers as base encoders, which are suboptimal for sequential recommendation because user behaviors may not be a rigid left-to-right sequence. To tackle that, we propose a novel framework named Contrastive learning with Bidirectional Transformers for sequential recommendation (CBiT). Specifically, we first apply the slide window technique for long user sequences in bidirectional Transformers, which allows for a more fine-grained division of user sequences. Then we combine the cloze task mask and the dropout mask to generate high-quality positive samples and perform multi-pair contrastive learning, which demonstrates better performance and adaptability compared with the normal one-pair contrastive learning. Moreover, we introduce a novel dynamic loss reweighting strategy to balance between the cloze task loss and the contrastive loss. Experiment results on three public benchmark datasets show that our model outperforms state-of-the-art models for sequential recommendation. Our code is available at this link: https://github.com/hw-du/CBiT/tree/master.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065003838",
                    "name": "Hanwen Du"
                },
                {
                    "authorId": "2108701829",
                    "name": "Hui Shi"
                },
                {
                    "authorId": "2927967",
                    "name": "Pengpeng Zhao"
                },
                {
                    "authorId": "2118962452",
                    "name": "Deqing Wang"
                },
                {
                    "authorId": "2858764",
                    "name": "Victor S. Sheng"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "8540458",
                    "name": "Guanfeng Liu"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                }
            ]
        },
        {
            "paperId": "1d3771be40e3a0f80c33267fb3908c279969ecd3",
            "title": "Aries: Accurate Metric-based Representation Learning for Fast Top-k Trajectory Similarity Query",
            "abstract": "With the prevalence of location-based services (LBS), trajectories are being generated rapidly. As is widely used in LBS, top-k trajectory similarity query serves as a key operation, deeply empowering applications such as travel route recommendation and carpooling. Given the rise of deep learning, trajectory representation has been well-proven to speed up this operator. However, existing representation-based computing modes remain two major problems understudied: the low quality of trajectory representation and insufficient support for various trajectory similarity metrics, which make them difficult to apply in practice. Therefore, we propose an Accurate metric-based representation learning approach for fast top-k trajectory similarity query, named Aries. Specifically, Aries has two sophisticated modules: (1) An novel trajectory embedding strategy enhanced by the bidirectional LSTM encoder and spatial attention mechanism, which can extract more precise and comprehensive knowledge. (2) A deep metric learning network aggregating multiple measures for better top-k query. Extensive experiments conducted on real trajectory dataset show that Aries achieves both impressive accuracy and lower training time compared with state-of-the-art solutions. In particular, it achieves 5x-10x speedup and 10%-20% accuracy improvement over Euclidean, Hausdorff, DTW, and EDR measures. Besides, our method can maintain stable performance when handling various scenarios, without repeated training in order to adapt to diverse similarity metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187856868",
                    "name": "Chunhui Feng"
                },
                {
                    "authorId": "50209953",
                    "name": "Zhicheng Pan"
                },
                {
                    "authorId": "2375706",
                    "name": "Junhua Fang"
                },
                {
                    "authorId": "3757313",
                    "name": "Jiajie Xu"
                },
                {
                    "authorId": "2927967",
                    "name": "Pengpeng Zhao"
                },
                {
                    "authorId": "98756666",
                    "name": "Lei Zhao"
                }
            ]
        }
    ]
}