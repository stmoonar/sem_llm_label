{
    "authorId": "2277906",
    "papers": [
        {
            "paperId": "0f356a2d78a5a0c7a047d65b4c4ba129b3cf129f",
            "title": "Observer Patterns for Timed Properties",
            "abstract": "Dwyer et al. proposed qualitative specification patterns that enable the practitioners of model checking tools to write formal specifications mainly used for automatic model checking. Although this involves formalisms that are not always easy to handle by engineers, to facilitate the integration of formal methods based on these definition patterns in the industrial field, several formal techniques and languages have been proposed. This paper studies a domain specific language named CDL which help non-experts writing formal specifications effortlessly. In CDL, a property is transformed into an observer automaton to perform a reachability analysis. The existing CDL patterns allow non-experts to reason about occurrence and order of events, but not enough about their timing. Furthermore, the semantics of patterns and transformations are not ideally formalized and are still complex. This work serves to extend the existing CDL system by patterns related to time. The contribution is illustrated in an industrial embedded system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087158471",
                    "name": "Djamila Baroudi"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "e2dba60f7053e5135294c16503f9158c3b54fe83",
            "title": "Bringing Common Subexpression Problem from the Dark to Light: Towards Large-Scale Workload Optimizations",
            "abstract": "Nowadays large-scale data-centric systems have become an essential element for companies to store, manipulate and derive value from large volumes of data. Capturing this value depends on the ability of these systems in managing large-scale workloads including complex analytical queries. One of the main characteristics of these queries is that they share computations in terms of selections and joins. Materialized views (MV) have shown their force in speeding up queries by exploiting these redundant computations. MV selection problem (VSP) is one of the most studied problems in the database field. A large majority of the existing solutions follow workload-driven approaches since they facilitate the identification of shared computations. Interesting algorithms have been proposed and implemented in commercial DBMSs. But they fail in managing large-scale workloads. In this paper, we presented a comprehensive framework to select the most beneficial materialized views based on the detection of the common subexpressions shared between queries. This framework gives the right place of the problem of selection of common subexpressions representing the causes of the redundancy. The utility of final MV depends strongly on the selected subexpressions. Once selected, a heuristic is given to select the most beneficial materialized views by considering different query ordering. Finally, experiments have been conducted to evaluate the effectiveness and efficiency of our proposal by considering large workloads.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3049138",
                    "name": "Mohamed Kechar"
                },
                {
                    "authorId": "1684379",
                    "name": "Ladjel Bellatreche"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "bd630dc799439fea6294b39ae7dfd0eef113d206",
            "title": "A support architecture to MDA contribution for data mining",
            "abstract": "The data mining process is the sequence of tasks applied to data, in order to discover relations between them to have knowledge. However, the data mining process lacks a formal specification that allows it to be modelled independently of platforms. Model driven architecture (MDA) is an approach for the development of software systems, based on the use of models to improve their productivity. Several research works have been elaborated to align the MDA approach with data mining on data warehouses, to specify the data mining process in a very high level of abstraction. In our work, we propose a support architecture that allows positioning these researches in different abstraction levels, on the basis of several criteria; with the aim to identify strengths for each level, in term of modelling; and to have a clear visibility on the MDA contribution for data mining.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223422",
                    "name": "Fatima Meskine"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "e942493376722401136055f616f0504332abc297",
            "title": "Bringing Together Physical Design and Fast Querying of Large Data Warehouses: A New Data Partitioning Strategy",
            "abstract": "Data partitioning is a well-known technique for decision-support query performance optimization. In this paper, we present a horizontal data partitioning approach tailored to a large data warehouse, interrogated through a high number of queries. The idea behind our approach is to partition horizontally only the large fact table based on partitioning predicates, elected from the set of the selection predicates used by the analytic queries. The partitioning predicates election depends on their numbers of occurrences, their access frequencies, and their selectivities. With the Star Scheme Benchmark under Oracle 12c, we demonstrate that our partitioning technique reduces both query response time and fact partitions number; which is the major drawback of existing partitioning techniques. We also show, that our partitioning algorithm is around 66% faster compared to the primary and derived partitioning techniques based on the genetic algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3049138",
                    "name": "Mohamed Kechar"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "0f255d83249edb4064c51f31168be4533533937e",
            "title": "Multi-criteria-based fusion for clustering texts and images case study on Flickr",
            "abstract": "\nPurpose\nThis study aims to evaluate a new fusion technique of visual and textual clusters of objects from a real multimedia data-driven collection to improve the performance of multimedia applications.\n\n\nDesign/methodology/approach\nThe authors focused on using multi-criteria for clustering texts and images. The algorithm consists of these steps: first is text representation using the statistical method of weighting, second is image representation using a bag of words feature descriptors methods and finally application of multi-criteria clustering.\n\n\nFindings\nAs an application for event detection based on social multimedia data, in particular, Flickr platform. Several experiments were conducted to choose the appropriate parameters for a better scheme of clustering. The new approach achieves better performance when aggregate text clustering is done with image clustering for event detection.\n\n\nResearch limitations/implications\nFurther researches would be investigated on other social media platforms such as Facebook and Twitter for a generalization of the technique.\n\n\nOriginality/value\nThis study contributes to multimedia data mining through the new fusion technique of clustering. The technique has its root in such strong field as the field of multi-criteria clustering and decision-making support.\n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9280878",
                    "name": "N. Khatir"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "12fb22ccae468552b02f560eef0a0e19c5535bc6",
            "title": "Automated Context Formalization for Context-aware Specification Approach",
            "abstract": "Requirement specification is a key element in model-checking verification. The context-aware approach is an effective technique for automating the specification of requirement considering specific environmental conditions. In most of existing approaches, there is no support of this crucial task and are mainly based on the considerable efforts and expertise of engineers. A domain-specific language, called CDL, has been proposed to facilitate the specification of requirement by formalizing contexts. However, the feedback has shown that manually writing CDL is hard, error prone and difficult to grasp on complex systems. In this article, the authors propose an approach to automatically generate CDL models using (IODs) elaborated through transformation chains from textual use cases. They offer an intermediate formalism between informal use cases scenarios and CDL models allowing to engineers to manipulate with familiar artifacts. Thanks to such high-level formalism, the gap between informal and formal requirements is reduced; consequently, the requirement specification is facilitated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10395032",
                    "name": "Amel Benabbou"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "18bfd4457481c5fac93c35785428e175749609c7",
            "title": "Towards Identifying Multicriteria Outliers: An Outranking Relation-Based Approach",
            "abstract": "This article tackles the problem of outlier detection in the multicriteria decision aid (MCDA) field. The authors propose an outlier detection method based on binary outranking relations and Local Outlier Factor (LOF) algorithm. The outlier is detected by applying LOF algorithm on the distribution of the outranking relations generated by a multicriteria outranking method. The proposed approach is illustrated on an artificial example and evaluated on a real life financial problem, the country risk problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2967614",
                    "name": "Baroudi Rouba"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "fea458661dcfd09e9b3579d608a460d5bec8fc2d",
            "title": "Precise use cases in a context-aware model-checking approach",
            "abstract": "Formal verification exhibits well known benefits but comes at the price of formalising precise and sound requirements, what often remains a challenging task for engineers. We propose a high-level formalism for expressing requirements based on interaction overview diagrams, which orchestrate activity diagrams that we automatically derived from use cases. Informal requirements are transformed into scenarios which fuel a context-aware model-checking approach. The approach assumes the availability of a formal model of the system, such as concurrent and communicating automata and a set of requirements specified in the form of contexts, which point out boundaries between the system and its environment. The requirement specification approach blends elaboration and transformation phases. Thanks to this blending, the semantic gap between informal and formal requirements is reduced, while model-checking is improved by contexts modelling. As a consequence, engineers gain support for moving towards formal verification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10395032",
                    "name": "Amel Benabbou"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "2107538",
                    "name": "P. Dhaussy"
                }
            ]
        },
        {
            "paperId": "07af3a8ecc193e345f731e4a5cdc46a9592f33d9",
            "title": "Methodological Sketch of Observer-Based Access Control",
            "abstract": "Access control is an essential component for computer system securing. It accords a definition to the conditions of actions execution in a system by a user. Considering the diverse phases of an access control policy design and its effective application on a deployed system, several steps can introduce undesirable errors or flaws. Therefore, the use of formal methods is a response to those preoccupations in the framework of modelisation of access control policies. The present paperwork introduces a methodology as well as a tool-chain aiming to formalize the properties of security (access control). We describe verification architecture of access control properties using a UACML (Unified access control modeling language), Fiacre, OPB/CDL (Observer-Based Prover/Context Description Language) toolkit. Our approach begins with the semi-formal specification access control rules using UACML activity diagram. The models of activity are then translated into a formal specification expressed in the Fiacre language. The latter will be used to formally check the properties with the OBP explorer tool (model-checking).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "23321213",
                    "name": "Mohammed Walid Krakallah"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "38bd69db4901add479e690898331dcea10f0f3d5",
            "title": "Performance optimisation of the decision-support queries by the horizontal fragmentation of the data warehouse",
            "abstract": "The horizontal fragmentation of the data warehouse is considered as one of the important performance optimisation techniques of the decision-support queries. This optimisation is reached only if the large data volume of the fact table is horizontally fragmented. For that, the fragments of the fact table are always derived from the fragments of the dimension tables. Unfortunately, in this type of fragmentation, the fragments number can dramatically increase, and their maintenance becomes quite hard and costly. Thus, to reduce the number of the fragments and to further optimise the decision-support queries performances, we propose to fragment horizontally only the fact table by exploiting jointly: the selectivities of the selection predicates, their occurrence numbers, and their access frequencies. To prove the effectiveness of our fragmentation technique, we present at the end, a set of experimental results conducted under Oracle 10g on the APB-1 benchmark.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3049138",
                    "name": "Mohamed Kechar"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "de6dccd641aa7a5a5096fcf6116a2f5829de5e2b",
            "title": "Weighted clustering ensemble: Towards learning the weights of the base clusterings",
            "abstract": "Clustering ensemble refers to the problem of obtaining a final clustering of a dataset by combining multiple partitions computed by different clustering algorithms. The clustering ensemble has emerged as a prominent method for improving robustness of unsupervised classification solutions. This problem has been received an increasing attention in recent years but a little attention has been paid to weight the combined clusterings without access the original data. We address in this paper the problem of weighted clustering ensemble problem by defining an unsupervised method to compute the weight of each combined clustering without access the original data. The weight of each base clustering is computed using its quality and the quality of its neighbouring clusterings. The proposed method permits to estimate the right number of clusters of the final clustering before the combining step by exploiting the generated weights.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2967614",
                    "name": "Baroudi Rouba"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "cf8f95cc1f8771466da7d976dcf56b383c5642a1",
            "title": "Context-aware approach for formal verification",
            "abstract": "The Context-aware approach has proven to be an effective technique for software model-checking verification. It focuses \non the explicit modelling of environment as one or more contexts. In this area, specifying precise requirement is a \nchallenged task for engineer since often environmental conditions lack of precision. A DSL, called CDL, has been \nproposed to facilitate the specification of requirement and context. However, such language is still low-level and error \nprone, difficult to grasp on complex models and assessment about its usability is still mitigated. In this paper, we propose a \nhigh level formalism of CDL to facilitate specifying contexts based on interaction overview diagrams that orchestrate \nactivity diagrams automatically transformed from textual use cases. Our approach highlights the boundaries between the \nsystem and its environment. It is qualified as model-checking context-aware that aims to reduce the semantic gap between \ninformal and formal requirements, hence the objective is to assist and encourage engineers to put sufficient details to \naccomplish effectively the specification process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10395032",
                    "name": "Amel Benabbou"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "2107538",
                    "name": "P. Dhaussy"
                }
            ]
        },
        {
            "paperId": "90e4073644fafe9a38eaf4cf43b78a5e359760ac",
            "title": "An Access Control System Architecture for XML Data Warehouse Using XACML",
            "abstract": "Controlling access to the XML data warehouse without affecting the performances of the decision-support queries, allows protecting its XML data against unauthorized access, and helps to a good decision making leading to the growth of the company. In this paper, we propose to secure the XML documents of the warehouse at a fine level without deteriorating its performances. To achieve this, we implement independently of the XML data warehouse, a role based access control system by exploiting both the policy language, and the architecture of the XACML standard.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3049138",
                    "name": "Mohamed Kechar"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "a2428a474547362a4e7ab30d64db308de0c8cda3",
            "title": "Transforming XML documents to OWL ontologies: A survey",
            "abstract": "The aims of XML data conversion to ontologies are the indexing, integration and enrichment of existing ontologies with knowledge acquired from these sources. The contribution of this paper consists in providing a classification of the approaches used for the conversion of XML documents into OWL ontologies. This classification underlines the usage profile of each conversion method, providing a clear description of the advantages and drawbacks belonging to each method. Hence, this paper focuses on two main processes, which are ontology enrichment and ontology population using XML data. Ontology enrichment is related to the schema of the ontology (TBox), and ontology population is related to an individual (Abox). In addition, the ontologies described in these methods are based on formal languages of the Semantic Web such as OWL (Ontology Web Language) or RDF (Resource Description Framework). These languages are formal because the semantics are formally defined and take advantage of the Description Logics. In contrast, XML data sources are without formal semantics. The XML language is used to store, export and share data between processes able to process the specific data structure. However, even if the semantics is not explicitly expressed, data structure contains the universe of discourse by using a qualified vocabulary regarding a consensual agreement. In order to formalize this semantics, the OWL language provides rich logical constraints. Therefore, these logical constraints are evolved in the transformation of XML documents into OWL documents, allowing the enrichment and the population of the target ontology. To design such a transformation, the current research field establishes connections between OWL constructs (classes, predicates, simple or complex data types, etc.) and XML constructs (elements, attributes, element lists, etc.). Two different approaches for the transformation process are exposed. The instance approaches are based on XML documents without any schema associated. The validation approaches are based on the XML schema and document validated by the associated schema. The second approaches benefit from the schema definition to provide automated transformations with logic constraints. Both approaches are discussed in the text.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2591389",
                    "name": "Mokhtaria Hacherouf"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "145378327",
                    "name": "C. Cruz"
                }
            ]
        },
        {
            "paperId": "3544ce4e963b522fb845cf9b98abfc6265d117e8",
            "title": "A Multicriteria Clustering Approach Based on Similarity Indices and Clustering Ensemble Techniques",
            "abstract": "This paper deals with the problem of multicriteria clusters construction. The aim is to propose a multicriteria clustering procedure aiming at discovering data structures from a multicriteria perspective by defining a dissimilarity measure which takes into account the multicriteria nature of the problem. Comparing two objects in the multicriteria context is based on the preference information that expresses whether these objects are indifferent, incomparable or one is preferred to the other. The proposed approach uses this preference information with an agreement\u2013disagreement similarity index to compute a dissimilarity measure. The approach generates, according to the preference relations, a set of clusterings. Each clustering expresses a way of grouping objects according to the preference relation used. A good quality final clustering is obtained by combining the clusterings generated previously using a clustering ensemble technique.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2967614",
                    "name": "Baroudi Rouba"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "3771b63e0404c05a72fc5153da28d0051dd3c13d",
            "title": "Data Analysis of an RFID System for Its Dependability",
            "abstract": "Dependability issues become more and more significant in RFID (Radio Frequency Identification) development and especially in critical domains. However, Operations of reading, detection of readers, and measurements of sensors in a RFID system are inevitably subjected to errors. These factors degrade the overall dependability of RFID systems. The authors study the Fault Tolerance in RFID systems as a means to ensure the dependability. The authors propose to perform a statistical analysis on the RFID tags data, using a confidence interval, at the level of the middleware enabling the detection of erroneous readers and sensors. Data Analysis of an RFID System for Its Dependability",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2085567299",
                    "name": "Imad Belkacem"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "1820870",
                    "name": "O. Aktouf"
                }
            ]
        },
        {
            "paperId": "f1e9def6af04a908b4df489e8eff760895b1e015",
            "title": "An Approach to Diversify Entity Search Results",
            "abstract": "Having named entities (person, country, company...) in response to users' queries is becoming more and more important in search engines. Indeed, in some cases users are not searching for a ranked list of documents, but for specific information (i.e. entities). In this work, we assume that users are interested in finding entities (e.g., name of a politician) and related entities (e.g., country of the politician 'x', name of the wife of the politician 'x'...) and the documents related to each entity. The user can then search entities by keywords or entities. Our goal is to return to the user diverse and relevant entities and documents. We then use the different types of an entity (Washington: city, person) and different categories of documents (Sport, Politics...) to diversify the results. In this paper, we develop a search semantics based on the types and categories of ranked results of entities. This new approach provides a variety of interpretations of relevant results. We conduct user studies to show the effectiveness of our approach and the quality of the results.",
            "fieldsOfStudy": [
                "Computer Science",
                "Political Science"
            ],
            "authors": [
                {
                    "authorId": "47174144",
                    "name": "I. Saidi"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "f771b4e39072d4c22f9ab52299b4c928bac0263d",
            "title": "Hematopoietic cells recognition using clustering algorithms: A survey",
            "abstract": "Given the increasing demand for blood smear analysis in the Hematology department of Oran (Algeria) Hospital and worldwide, in the literature there are some methods directed to the automation of this important problem. This paper presents a state-of-art about the used clustering methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9280878",
                    "name": "N. Khatir"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "1acda0271ce4b3c6dc92b5c1989a1f59b7901a49",
            "title": "Protect user anonymity in query log",
            "abstract": "The query logs provide to the research community a large amount of data which reflect the natural behavior of the user on the web. These data have many values and risks on user privacy. The use of these data has prompted several questions: The query logs owners are concerned by the security of their customers. But, academic, governmental and commercial searchers are interested in acquiring a significant amount of data for their research. The challenge is to ensure the user's privacy by reducing the potential risks without depleting the log query utility. In this paper we give an overview on query log data issue and propose a solution to ensure user anonymity. This solution is based on the replacement of terms relied with user identity. We think that replacing identifying terms like names of persons, and names of places with a significant substitutive, improve protection of the user identity by increasing number of possible identities for this user and at the same time, guarantee more utility than if the identifying terms are deleted.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2079138851",
                    "name": "Anissa Mimi"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "66e79eaf215f72d4dc362777554e9c6a562c2375",
            "title": "An Algorithmic Structuration of a Type System for an Orthogonal Object/Relational Model",
            "abstract": "Date and Darwen have proposed a theory of types, the latter forms the basis of a detailed presentation of a panoply of simple and complex types. However, this proposal has not been structured in a formal system. Specifically, Date and Darwen haven't indicated the formalism of the type system that corresponds to the type theory established. In this paper, we propose a pseudo-algorithmic and grammatical description of a system of types for Date and Darwen's model. Our type system is supposed take into account null values; for such intention, we introduce a particular type noted #, which expresses one or more occurrences of incomplete information in a database. Our algebraic grammar describes in detail the complete specification of an inheritance model and the subryping relation induced, thus the different definitions of related concepts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10395032",
                    "name": "Amel Benabbou"
                },
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "2304487",
                    "name": "Y. Amghar"
                }
            ]
        },
        {
            "paperId": "e92a671c7bf25b23bbe8f19072f5b3ca5da4bbb9",
            "title": "Extension of a Semi Structured Algebra for XML to the Procedures Linked Operators",
            "abstract": "In this paper, we treat requests in XQuery in a system of mediation \"everyXML\".These requests use the operators of an algebra of semi-structured data which already exists and to which. we add a procedural aspect that treats the data of type document XML A mixed approach based on relational operators and models of data under shape of graphs, using timekeepers indexed in the process of reconstruction and course of road, is retained in this paper. One of algebras adopting this approach is algebra deended by G.Gardarin and T.T.D.Ngoc called XAlgebra. This XAlgebra contains at the same time: relational operations to treat the tables of XTuples and the operations of navigation for trees XML. Idea aims to extend this XAlgebra by procedures linked operators.. A type of operator accompanied by its procedures of syntax: Xcext.. add.. by (procedures) is integrated into the functional language XQuery and transforms expression FLWR into FLXCWOR . This extension operates on the table of the XTuples and on the XOperations, extend consequently the XRelation formed by the XTuples and the associated trees. Extension becomes then a extended XOperator and is added to the existing XOperators to treat the XRelation. Syntax, semantics as well as the grammar of the FLXCWOR are studied. The treatment of requests FLXCWOR passes by a syntactic analysis, the construction of a plan of execution as well as a process of evaluation. The construction of a plan of execution passes by several stages, and in the stage of decomposition we adapt the rules of (normalization, canonization and atomisation) to the new expression FLXCWOR. The evaluation of the procedure linked operator requires the conception of a new SAX.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "1957642",
                    "name": "D. Benhamamouch"
                }
            ]
        },
        {
            "paperId": "31dc2070b8a5fc473abc69952973e936c98c254c",
            "title": "Conception and Development of a Dynamic Web Site: Dedicated to a University Library",
            "abstract": "The world wide web is a group of web pages related between them with hypertext links. \nThat forms a huge and complex web mail. A single click allow us to surf from document to another. \nFrom each document we can refer to different types of information: text, sound, video. In most cases, \nfirst sites were static, their principal aim were suggesting products and services. In the opposite, the \nweb pages feed actually more opportunities to make dynamic contacts with users, with allowing data \nexchanges : from and to both sides (server and client).To establish this practices, distinct environment \nand tools were developed such as: Script languages, Database servers,",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                }
            ]
        },
        {
            "paperId": "0ddd19f459bd0a7045cbc5af77960c477b3edadb",
            "title": "A* Algebra for an Extended Object/Relational Model",
            "abstract": "The object relational data model presents both the advantage of Codd's relational calculus power and the characteristics of the object orientation . T wo major approaches have been adopted to satisfy the requirements of new databases applications. A first approach integrates the object characteristics into the new data models with the specification of data constraints and the definition of interrogation language. The second one, called evolutionary approach, keeps Codd's data model enriching with adequate concepts for the coverage of current database applications. In this approach and comparatively with studies presented by Melton, Date and Darwen have proposed the foundations of the object relational model. So, A-algebra consisting of first order logic operators has been defined to express various classes of queries in object relational database. To contribute to the improvement of relational/ob ject models and agebra this paper presents an extension of object relational model to new types generated by operators and the related A*algebra. These operators, called Op, offer a means to specify domains as functions and permit consequently to increase the data model expressiveness. To support this extension, we propose a new data query language, or more precisely a logical data calculation A* as an adapatation of the A-algebra. Our A*-algebra contains algebraic operators which are able to support this new extension.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2277906",
                    "name": "S. N. Bahloul"
                },
                {
                    "authorId": "2288703114",
                    "name": "Youssef Amghar"
                },
                {
                    "authorId": "2288692577",
                    "name": "M. Sayah"
                }
            ]
        }
    ]
}