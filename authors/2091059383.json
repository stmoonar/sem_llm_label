{
    "authorId": "2091059383",
    "papers": [
        {
            "paperId": "0d943463f82fe343e39b1b00148c3debf20dbf69",
            "title": "Detecting Face Synthesis Using a Concealed Fusion Model",
            "abstract": "Face image synthesis is gaining more attention in computer security due to concerns about its potential negative impacts, including those related to fake biometrics. Hence, building models that can detect the synthesized face images is an important challenge to tackle. In this paper, we propose a fusion-based strategy to detect face image synthesis while providing resiliency to several attacks. The proposed strategy uses a late fusion of the outputs computed by several undisclosed models by relying on random polynomial coefficients and exponents to conceal a new feature space. Unlike existing concealing solutions, our strategy requires no quantization, which helps to preserve the feature space. Our experiments reveal that our strategy achieves state-of-the-art performance while providing protection against poisoning, perturbation, backdoor, and reverse model attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145749153",
                    "name": "Roberto Leyva"
                },
                {
                    "authorId": "2193508379",
                    "name": "Victor Sanchez"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                }
            ]
        },
        {
            "paperId": "38cfb057a6fa474b4422b0c1e57a35b20372220d",
            "title": "Resilient Machine Learning: Advancement, Barriers, and Opportunities in the Nuclear Industry",
            "abstract": "The widespread adoption and success of Machine Learning (ML) technologies depend on thorough testing of the resilience and robustness to adversarial attacks. The testing should focus on both the model and the data. It is necessary to build robust and resilient systems to withstand disruptions and remain functional despite the action of adversaries, specifically in the security-sensitive Nuclear Industry (NI), where consequences can be fatal in terms of both human lives and assets. We analyse ML-based research works that have investigated adversaries and defence strategies in the NI. We then present the progress in the adoption of ML techniques, identify use cases where adversaries can threaten the ML-enabled systems, and finally identify the progress on building Resilient Machine Learning (rML) systems entirely focusing on the NI domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181140392",
                    "name": "Anita Khadka"
                },
                {
                    "authorId": "8470513",
                    "name": "Saurav Sthapit"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                }
            ]
        },
        {
            "paperId": "a35617ecdd1f7ffc9812d9a8b8eec27e2d9f2d26",
            "title": "Data-Agnostic Face Image Synthesis Detection Using Bayesian CNNs",
            "abstract": "Face image synthesis detection is considerably gaining attention because of the potential negative impact on society that this type of synthetic data brings. In this paper, we propose a data-agnostic solution to detect the face image synthesis process. Specifically, our solution is based on an anomaly detection framework that requires only real data to learn the inference process. It is therefore data-agnostic in the sense that it requires no synthetic face images. The solution uses the posterior probability with respect to the reference data to determine if new samples are synthetic or not. Our evaluation results using different synthesizers show that our solution is very competitive against the state-of-the-art, which requires synthetic data for training.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145749153",
                    "name": "Roberto Leyva"
                },
                {
                    "authorId": "2193508379",
                    "name": "Victor Sanchez"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                }
            ]
        },
        {
            "paperId": "3373a86a940b10173f90c0843a748433c8c38088",
            "title": "Unsupervised Face Synthesis Based on Human Traits",
            "abstract": "This paper presents a strategy to synthesize face images based on human traits. Specifically, the strategy allows synthesizing face images with similar age, gender, and ethnicity, after discovering groups of people with similar facial features. Our synthesizer is based on unsupervised learning and is capable to generate realistic faces. Our experiments reveal that grouping the training samples according to their similarity can lead to more realistic face images while having semantic control over the synthesis. The proposed strategy achieves competitive performance compared to the state-of-the-art and outperforms the baseline in terms of the Frechet Inception Distance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145749153",
                    "name": "Roberto Leyva"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "2193508379",
                    "name": "Victor Sanchez"
                }
            ]
        },
        {
            "paperId": "41b9a2ef4cf496ed98f4827ac4788d1f5b520019",
            "title": "SaGess: Sampling Graph Denoising Diffusion Model for Scalable Graph Generation",
            "abstract": "Over recent years, denoising diffusion generative models have come to be considered as state-of-the-art methods for synthetic data generation, especially in the case of generating images. These approaches have also proved successful in other applications such as tabular and graph data generation. However, due to computational complexity, to this date, the application of these techniques to graph data has been restricted to small graphs, such as those used in molecular modeling. In this paper, we propose SaGess, a discrete denoising diffusion approach, which is able to generate large real-world networks by augmenting a diffusion model (DiGress) with a generalized divide-and-conquer framework. The algorithm is capable of generating larger graphs by sampling a covering of subgraphs of the initial graph in order to train DiGress. SaGess then constructs a synthetic graph using the subgraphs that have been generated by DiGress. We evaluate the quality of the synthetic data sets against several competitor methods by comparing graph statistics between the original and synthetic samples, as well as evaluating the utility of the synthetic data set produced by using it to train a task-driven model, namely link prediction. In our experiments, SaGess, outperforms most of the one-shot state-of-the-art graph generating methods by a significant factor, both on the graph metrics and on the link prediction task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46182296",
                    "name": "Stratis Limnios"
                },
                {
                    "authorId": "2220825490",
                    "name": "Praveen Selvaraj"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                },
                {
                    "authorId": "2064013905",
                    "name": "Andrew Elliott"
                }
            ]
        },
        {
            "paperId": "5bb03a07aa6ce107e5f36f59d32855a864b98ddb",
            "title": "Leveraging Semantic Relationships to Prioritise Indicators of Compromise in Additive Manufacturing Systems",
            "abstract": "Additive manufacturing (AM) offers numerous benefits, such as manufacturing complex and customised designs quickly and cost-effectively, reducing material waste, and enabling on-demand production. However, several security challenges are associated with AM, making it increasingly attractive to attackers ranging from individual hackers to organised criminal gangs and nation-state actors. This paper addresses the cyber risk in AM to attackers by proposing a novel semantic-based threat prioritisation system for identifying, extracting and ranking indicators of compromise (IOC). The system leverages the heterogeneous information networks (HINs) that automatically extract high-level IOCs from multi-source threat text and identifies semantic relations among the IOCs. It models IOCs with a HIN comprising different meta-paths and meta-graphs to depict semantic relations among diverse IOCs. We introduce a domain-specific recogniser that identifies IOCs in three domains: organisation-specific, regional source-specific, and regional target-specific. A threat assessment uses similarity measures based on meta-paths and meta-graphs to assess semantic relations among IOCs. It prioritises IOCs by measuring their severity based on the frequency of attacks, IOC lifetime, and exploited vulnerabilities in each domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157851928",
                    "name": "Mahender Kumar"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                }
            ]
        },
        {
            "paperId": "5d3944e9a9cc3899205043eb78fa99aeb6a2e201",
            "title": "A Hybrid Methodology to Assess Cyber Resilience of IoT in Energy Management and Connected Sites",
            "abstract": "Cyber threats and vulnerabilities present an increasing risk to the safe and frictionless execution of business operations. Bad actors (\u201chackers\u201d), including state actors, are increasingly targeting the operational technologies (OTs) and industrial control systems (ICSs) used to protect critical national infrastructure (CNI). Minimisations of cyber risk, attack surfaces, data immutability, and interoperability of IoT are some of the main challenges of today\u2019s CNI. Cyber security risk assessment is one of the basic and most important activities to identify and quantify cyber security threats and vulnerabilities. This research presents a novel i-TRACE security-by-design CNI methodology that encompasses CNI key performance indicators (KPIs) and metrics to combat the growing vicarious nature of remote, well-planned, and well-executed cyber-attacks against CNI, as recently exemplified in the current Ukraine conflict (2014\u2013present) on both sides. The proposed methodology offers a hybrid method that specifically identifies the steps required (typically undertaken by those responsible for detecting, deterring, and disrupting cyber attacks on CNI). Furthermore, we present a novel, advanced, and resilient approach that leverages digital twins and distributed ledger technologies for our chosen i-TRACE use cases of energy management and connected sites. The key steps required to achieve the desired level of interoperability and immutability of data are identified, thereby reducing the risk of CNI-specific cyber attacks and minimising the attack vectors and surfaces. Hence, this research aims to provide an extra level of safety for CNI and OT human operatives, i.e., those tasked with and responsible for detecting, deterring, disrupting, and mitigating these cyber-attacks. Our evaluations and comparisons clearly demonstrate that i-TRACE has significant intrinsic advantages compared to existing \u201cstate-of-the-art\u201d mechanisms.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2262012138",
                    "name": "Amjad Mehmood"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "3077221",
                    "name": "Nikolaos Ersotelos"
                },
                {
                    "authorId": "2262050065",
                    "name": "Richard Wiseman"
                }
            ]
        },
        {
            "paperId": "a28b8355ab8a71130f0953ad3cb94307d471df58",
            "title": "The AI Revolution: Opportunities and Challenges for the Finance Sector",
            "abstract": "This report examines Artificial Intelligence (AI) in the financial sector, outlining its potential to revolutionise the industry and identify its challenges. It underscores the criticality of a well-rounded understanding of AI, its capabilities, and its implications to effectively leverage its potential while mitigating associated risks. The potential of AI potential extends from augmenting existing operations to paving the way for novel applications in the finance sector. The application of AI in the financial sector is transforming the industry. Its use spans areas from customer service enhancements, fraud detection, and risk management to credit assessments and high-frequency trading. However, along with these benefits, AI also presents several challenges. These include issues related to transparency, interpretability, fairness, accountability, and trustworthiness. The use of AI in the financial sector further raises critical questions about data privacy and security. A further issue identified in this report is the systemic risk that AI can introduce to the financial sector. Being prone to errors, AI can exacerbate existing systemic risks, potentially leading to financial crises. Regulation is crucial to harnessing the benefits of AI while mitigating its potential risks. Despite the global recognition of this need, there remains a lack of clear guidelines or legislation for AI use in finance. This report discusses key principles that could guide the formation of effective AI regulation in the financial sector, including the need for a risk-based approach, the inclusion of ethical considerations, and the importance of maintaining a balance between innovation and consumer protection. The report provides recommendations for academia, the finance industry, and regulators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "2413018",
                    "name": "L. Szpruch"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                },
                {
                    "authorId": "3087546",
                    "name": "Kalina S. Staykova"
                },
                {
                    "authorId": "2236611605",
                    "name": "Simran Singh"
                },
                {
                    "authorId": "2236694084",
                    "name": "William Penwarden"
                },
                {
                    "authorId": "2236705486",
                    "name": "Yisi Wen"
                },
                {
                    "authorId": "2236871248",
                    "name": "Zijian Wang"
                },
                {
                    "authorId": "2236684664",
                    "name": "Jagdish Hariharan"
                },
                {
                    "authorId": "2215670422",
                    "name": "Pavle Avramovi\u0107"
                }
            ]
        },
        {
            "paperId": "dc75cf17729309cd1ee2021596e5b2b465284091",
            "title": "Analysis of outage performance in a 6G-V2X communications system utilising free-space optical quantum key distribution",
            "abstract": "Quantum\u2010based technologies will provide system engineers with new capabilities for securing data communications. The UK AirQKD project has implemented a Free\u2010Space Optical Quantum Key Distribution (QKD) system to enable the continuous generation of symmetric encryption keys. One of the use cases for the generated keys is to secure Vehicle\u2010to\u2010Everything (V2X) communications. V2X applications would benefit from the certificate\u2010free security provided by QKD for a post\u2010quantum society. How FSO\u2010QKD could integrate into a V2X architecture is examined. An overview of V2X is provided with the role that FSO\u2010QKD could secure V2X data though some obstacles exist. One of the issues with 6G communications is the potential line\u2010of\u2010sight (LOS) considerations between the V2X devices. The modelling required for LOS is examined to analyse the outage performance of the building to infrastructure links in the 6G architecture. The results from the model show that further work is required if 6G LOS communications are going to be relied upon for future safety\u2010critical V2X applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1452823502",
                    "name": "Hu Yuan"
                },
                {
                    "authorId": "40330046",
                    "name": "D. S. Fowler"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                }
            ]
        },
        {
            "paperId": "ea5cd15ac4cb19b3a13aa03eb858a19288e31a07",
            "title": "A Deep-Learning-Based Solution for Securing the Power Grid Against Load Altering Threats by IoT-Enabled Devices",
            "abstract": "The growing integration of high-wattage Internet of Things (IoT)-enabled electrical appliances at the consumer end has created a new attack surface that an adversary can exploit to disrupt power grid operations. Specifically, dynamic load-altering attacks (D-LAAs), accomplished by an abrupt or strategic manipulation of a large number of consumer appliances in a botnet-type attack, have been recognized as major threats that can potentially destabilize power grid control loops. This article introduces a novel approach-based a multioutput network (2-D convolutional neural networks classifier and reconstruction decoder)\u2014called \u201c2DR-CNN\u201d\u2014to detect and localize D-LAAs with high resolution. To achieve this, we leverage the frequency and phase angle data of the generator buses monitored by phasor measurement units (PMUs) installed in the power grid. To verify the effectiveness of the proposed method, simulations are conducted on IEEE 14- and 39-bus systems. The performance of the 2DR-CNN method is compared against several benchmark machine-learning-based approaches. The results confirm that the proposed method outperforms other techniques in detection and localizing D-LAAs with high resolution in a number of practical scenarios, including PMU measurement noises and missing measurements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2203203255",
                    "name": "Hamidreza Jahangir"
                },
                {
                    "authorId": "91446647",
                    "name": "Subhash Lakshminarayana"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "2313102",
                    "name": "Gregory Epiphaniou"
                }
            ]
        }
    ]
}