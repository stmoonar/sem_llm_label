{
    "authorId": "2034351",
    "papers": [
        {
            "paperId": "11894cfc673a9bfa9342122367c5841f34c520f6",
            "title": "The FIGNEWS Shared Task on News Media Narratives",
            "abstract": "We present an overview of the FIGNEWSshared task, organized as part of the Arabic-NLP 2024 conference co-located with ACL2024. The shared task addresses bias and pro-paganda annotation in multilingual news posts.We focus on the early days of the Israel War onGaza as a case study. The task aims to fostercollaboration in developing annotation guide-lines for subjective tasks by creating frame-works for analyzing diverse narratives high-lighting potential bias and propaganda. In aspirit of fostering and encouraging diversity,we address the problem from a multilingualperspective, namely within five languages: En-glish, French, Arabic, Hebrew, and Hindi. Atotal of 17 teams participated in two annota-tion subtasks: bias (16 teams) and propaganda(6 teams). The teams competed in four evalua-tion tracks: guidelines development, annotationquality, annotation quantity, and consistency.Collectively, the teams produced 129,800 datapoints. Key findings and implications for thefield are discussed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2311114234",
                    "name": "Mustafa Jarrar"
                },
                {
                    "authorId": "2256969039",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2063374",
                    "name": "Houda Bouamor"
                },
                {
                    "authorId": "1954563",
                    "name": "I. Zitouni"
                },
                {
                    "authorId": "2288859298",
                    "name": "Mona T. Diab"
                },
                {
                    "authorId": "1399214738",
                    "name": "S. El-Beltagy"
                },
                {
                    "authorId": "20799402",
                    "name": "Muhammed AbuOdeh"
                }
            ]
        },
        {
            "paperId": "44ced112e11d8277e2e284e2ffd6ec77949e2fe9",
            "title": "Chinese Offensive Language Detection: Current Status and Future Directions",
            "abstract": "Despite the considerable efforts being made to monitor and regulate user-generated content on social media platforms, the pervasiveness of offensive language, such as hate speech or cyberbullying, in the digital space remains a significant challenge. Given the importance of maintaining a civilized and respectful online environment, there is an urgent and growing need for automatic systems capable of detecting offensive speech in real time. However, developing effective systems for processing languages such as Chinese presents a significant challenge, owing to the language's complex and nuanced nature, which makes it difficult to process automatically. This paper provides a comprehensive overview of offensive language detection in Chinese, examining current benchmarks and approaches and highlighting specific models and tools for addressing the unique challenges of detecting offensive language in this complex language. The primary objective of this survey is to explore the existing techniques and identify potential avenues for further research that can address the cultural and linguistic complexities of Chinese.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152958412",
                    "name": "Yunze Xiao"
                },
                {
                    "authorId": "2063374",
                    "name": "Houda Bouamor"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        },
        {
            "paperId": "47ccb3c7aa7c20c2a5edbd4fd9c1e04f0ba72e04",
            "title": "MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification",
            "abstract": "This paper focuses on detecting propagandistic spans and persuasion techniques in Arabic text from tweets and news paragraphs. Each entry in the dataset contains a text sample and corresponding labels that indicate the start and end positions of propaganda techniques within the text. Tokens falling within a labeled span were assigned \u2019B\u2019 (Begin) or \u2019I\u2019 (Inside) tags, \u2019O\u2019, corresponding to the specific propaganda technique. Using attention masks, we created uniform lengths for each span and assigned BIO tags to each token based on the provided labels. Then, we used AraBERT-base pre-trained model for Arabic text tokenization and embeddings with a token classification layer to identify propaganda techniques. Our training process involves a two-phase fine-tuning approach. First, we train only the classification layer for a few epochs, followed by full model fine-tuning, updating all parameters. This methodology allows the model to adapt to the specific characteristics of the propaganda detection task while leveraging the knowledge captured by the pretrained AraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd position in the leaderboard of Task 1.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32267310",
                    "name": "Md. Rafiul Biswas"
                },
                {
                    "authorId": "2275236843",
                    "name": "Zubair Shah"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        },
        {
            "paperId": "5de210a9cffd19d20601e1420789d9a3e956438b",
            "title": "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs",
            "abstract": "In the past decade, social media platforms have been used for information dissemination and consumption. While a major portion of the content is posted to promote citizen journalism and public awareness, some content is posted to mislead users. Among different content types such as text, images, and videos, memes (text overlaid on images) are particularly prevalent and can serve as powerful vehicles for propaganda, hate, and humor. In the current literature, there have been efforts to individually detect such content in memes. However, the study of their intersection is very limited. In this study, we explore the intersection between propaganda and hate in memes using a multi-agent LLM-based approach. We extend the propagandistic meme dataset with coarse and fine-grained hate labels. Our finding suggests that there is an association between propaganda and hate in memes. We provide detailed experimental results that can serve as a baseline for future studies. We will make the experimental resources publicly available to the community (https://github.com/firojalam/propaganda-and-hateful-memes).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257274157",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "32267310",
                    "name": "Md. Rafiul Biswas"
                },
                {
                    "authorId": "2320725616",
                    "name": "Uzair Shah"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2320730572",
                    "name": "Georgios Mikros"
                }
            ]
        },
        {
            "paperId": "5f8a9e1c0295f0c698babda620a7135816fff7e4",
            "title": "Narrative Navigators at FIGNEWS 2024 Shared Task: New Frontiers in Bias and Propaganda Annotation Techniques",
            "abstract": "This paper presents our team\u2019s contribution to the FIGNEWS 2024 Shared Task, which involved annotating bias and propaganda in news coverage of the Israel-Palestine conflict. We developed comprehensive guidelines and employed a rigorous methodology to analyze 2,200 news posts from several official Facebook accounts of news websites in multiple languages. Our team, Narrative Navigators, achieved third place in both the Bias Guidelines and Bias Consistency tracks, demonstrating the effectiveness of our approach. We achieved an IAA Kappa score of 39.4 for bias annotation and 12.8 for propaganda detection. These findings and our performance underscore the need for enhanced media literacy and further research to counter the impact of biased and misleading information on public understanding of the conflict.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302558891",
                    "name": "Maryam M. AlEmadi"
                },
                {
                    "authorId": "2315305651",
                    "name": "Jana ElMesselmani"
                },
                {
                    "authorId": "2315313240",
                    "name": "Lyna Bermak"
                },
                {
                    "authorId": "2315306953",
                    "name": "Goumana Abdullah"
                },
                {
                    "authorId": "2315318522",
                    "name": "Esra\u2019a Sharqawi"
                },
                {
                    "authorId": "2315318806",
                    "name": "Anissa Jrad"
                },
                {
                    "authorId": "2315313214",
                    "name": "Zied Zouabi"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        },
        {
            "paperId": "7bfc747ac4c1066f1071c3e4b4908c32b6996b00",
            "title": "So Hateful! Building a Multi-Label Hate Speech Annotated Arabic Dataset",
            "abstract": "Social media enables widespread propagation of hate speech targeting groups based on ethnicity, religion, or other characteristics. With manual content moderation being infeasible given the volume, automatic hate speech detection is essential. This paper analyzes 70,000 Arabic tweets, from which 15,965 tweets were selected and annotated, to identify hate speech patterns and train classification models. Annotators labeled the Arabic tweets for offensive content, hate speech, emotion intensity and type, effect on readers, humor, factuality, and spam. Key findings reveal 15% of tweets contain offensive language while 6% have hate speech, mostly targeted towards groups with common ideological or political affiliations. Annotations capture diverse emotions, and sarcasm is more prevalent than humor. Additionally, 10% of tweets provide verifiable factual claims, and 7% are deemed important. For hate speech detection, deep learning models like AraBERT outperform classical machine learning approaches. By providing insights into hate speech characteristics, this work enables improved content moderation and reduced exposure to online hate. The annotated dataset advances Arabic natural language processing research and resources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "32267310",
                    "name": "Md. Rafiul Biswas"
                }
            ]
        },
        {
            "paperId": "7cc05a25874ab6bad78973062ccc838c8060d160",
            "title": "Overview of the CLEF-2024 CheckThat! Lab Task 2 on Subjectivity in News Articles",
            "abstract": "We present an overview of Task 2 of the seventh edition of the CheckThat! lab at the 2024 iteration of the Conference and Labs of the Evaluation Forum (CLEF). The task focuses on subjectivity detection in news articles and was o\u200cered in \uf6d5ve languages: Arabic, Bulgarian, English, German, and Italian, as well as in a multilingual setting. The datasets for each language were carefully curated and annotated, comprising over 10,000 sentences from news articles. The task challenged participants to develop systems capable of distinguishing between subjective statements (re\uf6d6ecting personal opinions or biases) and objective ones (presenting factual information) at the sentence level. A total of 15 teams participated in the task, submitting 36 valid runs across all language tracks. The participants used a variety of approaches, with transformer-based models being the most popular choice. Strategies included \uf6d5ne-tuning monolingual and multilingual models, and leveraging English models with automatic translation for the non-English datasets. Some teams also explored ensembles, feature engineering, and innovative techniques such as few-shot learning and in-context learning with large language models. The evaluation was based on macro-averaged F1 score. The results varied across languages, with the best performance achieved for Italian and German, followed by English. The Arabic track proved particularly challenging, with no team surpassing an F1 score of 0.50. This task contributes to the broader goal of enhancing the reliability of automated content analysis in the context of misinformation detection and fact-checking. The paper provides detailed insights into the datasets, participant approaches, and results, o\u200cering a benchmark for the current state of subjectivity detection across multiple languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264714",
                    "name": "Julia Maria Stru\u00df"
                },
                {
                    "authorId": "2241527223",
                    "name": "Federico Ruggeri"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "2257274157",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "2291964834",
                    "name": "Dimitar Dimitrov"
                },
                {
                    "authorId": "2316056652",
                    "name": "Andrea Galassi"
                },
                {
                    "authorId": "2239200277",
                    "name": "Georgi Pachov"
                },
                {
                    "authorId": "52553663",
                    "name": "Ivan Koychev"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2261403474",
                    "name": "Melanie Siegel"
                },
                {
                    "authorId": "2261403527",
                    "name": "Michael Wiegand"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "3378399",
                    "name": "Reem Suwaileh"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        },
        {
            "paperId": "8200ab681badf64fba1f13e4c5c859bbd918444c",
            "title": "QCAW 1.0: Building a Qatari Corpus of Student Argumentative Writing",
            "abstract": "This paper presents the creation of the Qatari Corpus of Argumentative Writing (QCAW) as an annotated L1 Arabic and L2 English bilingual writer corpus. It comprises 200,000 tokens of argumentative writing by Qatari university students in L1 Arabic and L2 English. The corpus includes 195 essays written by 195 students, 159 females and 36 males. The students were native Arabic speakers proficient in English as a second language. The corpus is divided into Arabic and English sections, accompanied by part-of-speech annotated files. The Metadata contains information about the students (gender, major, first and second languages) and the essays (text serial numbers, word limits, genre, writing date, time spent, and location). The paper outlines the steps for collecting and analysing the corpus, including details on essay writers, topic selection, pre-analysis text modifications, proficiency level, gender, and major ratings. Statistical analyses were applied to examine the corpus. The QCAW offers a valuable bilingual data source authored by the same students in Arabic and English, with implications for further research",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2279328357",
                    "name": "Abdelhamid M. Ahmed"
                },
                {
                    "authorId": "2279077721",
                    "name": "Xiao Zhang"
                },
                {
                    "authorId": "120144933",
                    "name": "L. Rezk"
                }
            ]
        },
        {
            "paperId": "911a107db0823bfe7059e2afd9420044ed23b6bb",
            "title": "ArAIEval Shared Task: Propagandistic Techniques Detection in Unimodal and Multimodal Arabic Content",
            "abstract": "We present an overview of the second edition of the ArAIEval shared task, organized as part of the ArabicNLP 2024 conference co-located with ACL 2024. In this edition, ArAIEval offers two tasks: (i) detection of propagandistic textual spans with persuasion techniques identification in tweets and news articles, and (ii) distinguishing between propagandistic and non-propagandistic memes. A total of 14 teams participated in the final evaluation phase, with 6 and 9 teams participating in Tasks 1 and 2, respectively. Finally, 11 teams submitted system description papers. Across both tasks, we observed that fine-tuning transformer models such as AraBERT was at the core of the majority of the participating systems. We provide a description of the task setup, including a description of the dataset construction and the evaluation setup. We further provide a brief overview of the participating systems. All datasets and evaluation scripts are released to the research community. We hope this will enable further research on these important tasks in Arabic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "151116677",
                    "name": "Md. Arid Hasan"
                },
                {
                    "authorId": "2266856028",
                    "name": "Fatema Ahmed"
                },
                {
                    "authorId": "3378399",
                    "name": "Reem Suwaileh"
                },
                {
                    "authorId": "32267310",
                    "name": "Md. Rafiul Biswas"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2257274157",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "b75eeb634151f87dcf3ab17a3a2434f0f616e06b",
            "title": "Nullpointer at CheckThat! 2024: Identifying Subjectivity from Multilingual Text Sequence",
            "abstract": "This study addresses a binary classification task to determine whether a text sequence, either a sentence or paragraph, is subjective or objective. The task spans five languages: Arabic, Bulgarian, English, German, and Italian, along with a multilingual category. Our approach involved several key techniques. Initially, we preprocessed the data through parts of speech (POS) tagging, identification of question marks, and application of attention masks. We fine-tuned the sentiment-based Transformer model 'MarieAngeA13/Sentiment-Analysis-BERT' on our dataset. Given the imbalance with more objective data, we implemented a custom classifier that assigned greater weight to objective data. Additionally, we translated non-English data into English to maintain consistency across the dataset. Our model achieved notable results, scoring top marks for the multilingual dataset (Macro F1=0.7121) and German (Macro F1=0.7908). It ranked second for Arabic (Macro F1=0.4908) and Bulgarian (Macro F1=0.7169), third for Italian (Macro F1=0.7430), and ninth for English (Macro F1=0.6893).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32267310",
                    "name": "Md. Rafiul Biswas"
                },
                {
                    "authorId": "2311436866",
                    "name": "A. T. Abir"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                }
            ]
        }
    ]
}