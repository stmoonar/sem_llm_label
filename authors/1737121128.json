{
    "authorId": "1737121128",
    "papers": [
        {
            "paperId": "3e56598ae064345a9689ab39ac0c65b208afc3f4",
            "title": "PyGDebias: A Python Library for Debiasing in Graph Learning",
            "abstract": "Graph-structured data is ubiquitous among a plethora of real-world applications. However, as graph learning algorithms have been increasingly deployed to help decision-making, there has been rising societal concern in the bias these algorithms may exhibit. In certain high-stake decision-making scenarios, the decisions made may be life-changing for the involved individuals. Accordingly, abundant explorations have been made to mitigate the bias for graph learning algorithms in recent years. However, there still lacks a library to collectively consolidate existing debiasing techniques and help practitioners to easily perform bias mitigation for graph learning algorithms. In this paper, we present PyGDebias, an open-source Python library for bias mitigation in graph learning algorithms. As the first comprehensive library of its kind, PyGDebias covers 13 popular debiasing methods under common fairness notions together with 26 commonly used graph datasets. In addition, PyGDebias also comes with comprehensive performance benchmarks and well-documented API designs for both researchers and practitioners. To foster convenient accessibility, PyGDebias is released under a permissive BSD-license together with performance benchmarks, API documentation, and use examples at https://github.com/yushundong/PyGDebias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "2301468051",
                    "name": "Zhenyu Lei"
                },
                {
                    "authorId": "2262086932",
                    "name": "Zaiyi Zheng"
                },
                {
                    "authorId": "2117075272",
                    "name": "Song Wang"
                },
                {
                    "authorId": "2273765881",
                    "name": "Jing Ma"
                },
                {
                    "authorId": "2301215253",
                    "name": "Alex Jing Huang"
                },
                {
                    "authorId": "2127380428",
                    "name": "Chen Chen"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                }
            ]
        },
        {
            "paperId": "147992e6a8d6280628b715a18412bef7f23daa7b",
            "title": "Collaborative Graph Neural Networks for Attributed Network Embedding",
            "abstract": "Graph neural networks (GNNs) have shown prominent performance on attributed network embedding. However, existing efforts mainly focus on exploiting network structures, while the exploitation of node attributes is rather limited as they only serve as node features at the initial layer. This simple strategy impedes the potential of node attributes in augmenting node connections, leading to limited receptive field for inactive nodes with few or even no neighbors. Furthermore, the training objectives (i.e., reconstructing network structures) of most GNNs also do not include node attributes, although studies have shown that reconstructing node attributes is beneficial. Thus, it is encouraging to deeply involve node attributes in the key components of GNNs, including graph convolution operations and training objectives. However, this is a nontrivial task since an appropriate way of integration is required to maintain the merits of GNNs. To bridge the gap, in this paper, we propose COllaborative graph Neural Networks\u2013CONN, a tailored GNN architecture for attribute network embedding. It improves model capacity by 1) selectively diffusing messages from neighboring nodes and involved attribute categories, and 2) jointly reconstructing node-to-node and node-to-attribute-category interactions via cross-correlation. Experiments on real-world networks demonstrate that CONN excels state-of-the-art embedding algorithms with a great margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9747941",
                    "name": "Qiaoyu Tan"
                },
                {
                    "authorId": "2149174861",
                    "name": "Xin Zhang"
                },
                {
                    "authorId": "47933250",
                    "name": "Xiao Huang"
                },
                {
                    "authorId": "50689319",
                    "name": "Haojun Chen"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "2148950326",
                    "name": "Xia Hu"
                }
            ]
        },
        {
            "paperId": "2150e336eee8a886e4a661169b60bfbccd323d51",
            "title": "Empower Post-hoc Graph Explanations with Information Bottleneck: A Pre-training and Fine-tuning Perspective",
            "abstract": "Researchers recently investigated to explain Graph Neural Networks (GNNs) on the access to a task-specific GNN, which may hinder their wide applications in practice. Specifically, task-specific explanation methods are incapable of explaining pretrained GNNs whose downstream tasks are usually inaccessible, not to mention giving explanations for the transferable knowledge in pretrained GNNs. Additionally, task-specific methods only consider target models' output in the label space, which are coarse-grained and insufficient to reflect the model's internal logic. To address these limitations, we consider a two-stage explanation strategy, i.e., explainers are first pretrained in a task-agnostic fashion in the representation space and then further fine-tuned in the task-specific label space and representation space jointly if downstream tasks are accessible. The two-stage explanation strategy endows post-hoc graph explanations with the applicability to pretrained GNNs where downstream tasks are inaccessible and the capacity to explain the transferable knowledge in the pretrained GNNs. Moreover, as the two-stage explanation strategy explains the GNNs in the representation space, the fine-grained information in the representation space also empowers the explanations. Furthermore, to achieve a trade-off between the fidelity and intelligibility of explanations, we propose an explanation framework based on the Information Bottleneck principle, named Explainable Graph Information Bottleneck (EGIB). EGIB subsumes the task-specific explanation and task-agnostic explanation into a unified framework. To optimize EGIB objective, we derive a tractable bound and adopt a simple yet effective explanation generation architecture. Based on the unified framework, we further theoretically prove that task-agnostic explanation is a relaxed sufficient condition of task-specific explanation, which indicates the transferability of task-agnostic explanations. Extensive experimental results demonstrate the effectiveness of our proposed explanation method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109656535",
                    "name": "Jihong Wang"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "47904366",
                    "name": "Yun Lin"
                },
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "2152487387",
                    "name": "J. Dong"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                }
            ]
        },
        {
            "paperId": "26b7e8ddf85185f88e6277082097db0b004759e8",
            "title": "Path-Specific Counterfactual Fairness for Recommender Systems",
            "abstract": "Recommender systems (RSs) have become an indispensable part of online platforms. With the growing concerns of algorithmic fairness, RSs are not only expected to deliver high-quality personalized content, but are also demanded not to discriminate against users based on their demographic information. However, existing RSs could capture undesirable correlations between sensitive features and observed user behaviors, leading to biased recommendations. Most fair RSs tackle this problem by completely blocking the influences of sensitive features on recommendations. But since sensitive features may also affect user interests in a fair manner (e.g., race on culture-based preferences), indiscriminately eliminating all the influences of sensitive features inevitably degenerate the recommendations quality and necessary diversities. To address this challenge, we propose a path-specific fair RS (PSF-RS) for recommendations. Specifically, we summarize all fair and unfair correlations between sensitive features and observed ratings into two latent proxy mediators, where the concept of path-specific bias (PS-Bias) is defined based on path-specific counterfactual inference. Inspired by Pearl's minimal change principle, we address the PS-Bias by minimally transforming the biased factual world into a hypothetically fair world, where a fair RS model can be learned accordingly by solving a constrained optimization problem. For the technical part, we propose a feasible implementation of PSF-RS, i.e., PSF-VAE, with weakly-supervised variational inference, which robustly infers the latent mediators such that unfairness can be mitigated while necessary recommendation diversities can be maximally preserved simultaneously. Experiments conducted on semi-simulated and real-world datasets demonstrate the effectiveness of PSF-RS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153094361",
                    "name": "Yaochen Zhu"
                },
                {
                    "authorId": "2157405959",
                    "name": "Jing Ma"
                },
                {
                    "authorId": "47767741",
                    "name": "Liang Wu"
                },
                {
                    "authorId": "2170992709",
                    "name": "Qilnli Guo"
                },
                {
                    "authorId": "2150205525",
                    "name": "Liang Hong"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                }
            ]
        },
        {
            "paperId": "6067349bce9aeca4c18fc4e2878a1f6d6bff7f55",
            "title": "Fairness in Graph Machine Learning: Recent Advances and Future Prospectives",
            "abstract": "Graph machine learning algorithms have become popular tools in helping us gain a deeper understanding of the ubiquitous graph data. Despite their effectiveness, most graph machine learning algorithms lack considerations for fairness, which can result in discriminatory outcomes against certain demographic subgroups or individuals. As a result, there is a growing societal concern about mitigating the bias exhibited in these algorithms. To tackle the problem of algorithmic bias in graph machine learning algorithms, this tutorial aims to provide a comprehensive overview of recent research progress in measuring and mitigating the bias in machine learning algorithms on graphs. Specifically, this tutorial first introduces several widely-used fairness notions and the corresponding metrics. Then, we present a well-organized review of the theoretical understanding of bias in graph machine learning algorithms, followed by a summary of existing techniques to debias graph machine learning algorithms. Furthermore, we demonstrate how different real-world applications benefit from these graph machine learning algorithms after debiasing. Finally, we provide insights on current research challenges and open questions to encourage further advances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "1411389353",
                    "name": "O. D. Kose"
                },
                {
                    "authorId": "1798830",
                    "name": "Yanning Shen"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                }
            ]
        },
        {
            "paperId": "62420cf61f84cc934a85960e26c615d504c4ee63",
            "title": "Federated Few-shot Learning",
            "abstract": "Federated Learning (FL) enables multiple clients to collaboratively learn a machine learning model without exchanging their own local data. In this way, the server can exploit the computational power of all clients and train the model on a larger set of data samples among all clients. Although such a mechanism is proven to be effective in various fields, existing works generally assume that each client preserves sufficient data for training. In practice, however, certain clients can only contain a limited number of samples (i.e., few-shot samples). For example, the available photo data taken by a specific user with a new mobile device is relatively rare. In this scenario, existing FL efforts typically encounter a significant performance drop on these clients. Therefore, it is urgent to develop a few-shot model that can generalize to clients with limited data under the FL scenario. In this paper, we refer to this novel problem as federated few-shot learning. Nevertheless, the problem remains challenging due to two major reasons: the global data variance among clients (i.e., the difference in data distributions among clients) and the local data insufficiency in each client (i.e., the lack of adequate local data for training). To overcome these two challenges, we propose a novel federated few-shot learning framework with two separately updated models and dedicated training strategies to reduce the adverse impact of global data variance and local data insufficiency. Extensive experiments on four prevalent datasets that cover news articles and images validate the effectiveness of our framework compared with the state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117075272",
                    "name": "Song Wang"
                },
                {
                    "authorId": "2194727743",
                    "name": "Xingbo Fu"
                },
                {
                    "authorId": "66807781",
                    "name": "Kaize Ding"
                },
                {
                    "authorId": "2127380428",
                    "name": "Chen Chen"
                },
                {
                    "authorId": "4760974",
                    "name": "Huiyuan Chen"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                }
            ]
        },
        {
            "paperId": "7ae864d1b0fc002055cddec4a56cc70b5a085f51",
            "title": "RELIANT: Fair Knowledge Distillation for Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) have shown satisfying performance on various graph learning tasks. To achieve better fitting capability, most GNNs are with a large number of parameters, which makes these GNNs computationally expensive. Therefore, it is difficult to deploy them onto edge devices with scarce computational resources, e.g., mobile phones and wearable smart devices. Knowledge Distillation (KD) is a common solution to compress GNNs, where a light-weighted model (i.e., the student model) is encouraged to mimic the behavior of a computationally expensive GNN (i.e., the teacher GNN model). Nevertheless, most existing GNN-based KD methods lack fairness consideration. As a consequence, the student model usually inherits and even exaggerates the bias from the teacher GNN. To handle such a problem, we take initial steps towards fair knowledge distillation for GNNs. Specifically, we first formulate a novel problem of fair knowledge distillation for GNN-based teacher-student frameworks. Then we propose a principled framework named RELIANT to mitigate the bias exhibited by the student model. Notably, the design of RELIANT is decoupled from any specific teacher and student model structures, and thus can be easily adapted to various GNN-based KD frameworks. We perform extensive experiments on multiple real-world datasets, which corroborates that RELIANT achieves less biased GNN knowledge distillation while maintaining high prediction utility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "2134483590",
                    "name": "Binchi Zhang"
                },
                {
                    "authorId": "3363480",
                    "name": "Yiling Yuan"
                },
                {
                    "authorId": "49648991",
                    "name": "Na Zou"
                },
                {
                    "authorId": "2151571252",
                    "name": "Qi Wang"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                }
            ]
        },
        {
            "paperId": "823b3fed6703616af0cf98550f02718f5c629408",
            "title": "Learning Causal Effects on Hypergraphs (Extended Abstract)",
            "abstract": "Hypergraphs provide an effective abstraction for modeling multi-way group interactions among nodes, where each hyperedge can connect any number of nodes. Different from most existing studies which leverage statistical dependencies, we study hypergraphs from the perspective of causality. Specifically, we focus on the problem of individual treatment effect (ITE) estimation on hypergraphs, aiming to estimate how much an intervention (e.g., wearing face covering) would causally affect an outcome (e.g., COVID-19 infection) of each individual node. Existing works on ITE estimation either assume that the outcome of one individual should not be influenced by the treatment of other individuals (i.e., no interference), or assume the interference only exists between connected individuals in an ordinary graph. We argue that these assumptions can be unrealistic on real-world hypergraphs, where higher-order interference can affect the ITE estimations due to group interactions. We investigate high-order interference modeling, and propose a new causality learning framework powered by hypergraph neural networks. Extensive experiments on real-world hypergraphs verify the superiority of our framework over existing baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157405959",
                    "name": "Jing Ma"
                },
                {
                    "authorId": "2127553",
                    "name": "Mengting Wan"
                },
                {
                    "authorId": "49576139",
                    "name": "Longfei Yang"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "2205028602",
                    "name": "Brent Hecht"
                },
                {
                    "authorId": "144113253",
                    "name": "J. Teevan"
                }
            ]
        },
        {
            "paperId": "8b57c1ab78854d2d03cbc611325aa0511b3b225d",
            "title": "RelKD 2023: International Workshop on Resource-Efficient Learning for Knowledge Discovery",
            "abstract": "Modern machine learning techniques, especially deep neural networks, have demonstrated excellent performance for various knowledge discovery and data mining applications. However, the development of many of these techniques still encounters resource constraint challenges in many scenarios, such as limited labeled data (data-level), small model size requirements in real-world computing platforms (model-level), and efficient mapping of the computations to heterogeneous target hardware (system-level). Addressing all of these metrics is critical for the effective and efficient usage of the developed models in a wide variety of real systems, such as large-scale social network analysis, large-scale recommendation systems, and real-time anomaly detection. Therefore, it is desirable to develop efficient learning techniques to tackle challenges of resource limitations from data, model/algorithm, or (and) system/hardware perspectives. The proposed international workshop on \"Resource-Efficient Learning for Knowledge Discovery (RelKD 2023)\" will provide a great venue for academic researchers and industrial practitioners to share challenges, solutions, and future opportunities of resource-efficient learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117879943",
                    "name": "Chuxu Zhang"
                },
                {
                    "authorId": "2116459424",
                    "name": "Dongkuan Xu"
                },
                {
                    "authorId": "51900416",
                    "name": "Mojan Javaheripi"
                },
                {
                    "authorId": "2153292652",
                    "name": "Subhabrata Mukherjee"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "2152153528",
                    "name": "Meng Jiang"
                },
                {
                    "authorId": "2143431718",
                    "name": "Yanzhi Wang"
                }
            ]
        },
        {
            "paperId": "a2223e85a744a61c508d1ab3b6c3901941960485",
            "title": "When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?",
            "abstract": "In recent years, neural models have been repeatedly touted to exhibit state-of-the-art performance in recommendation. Nevertheless, multiple recent studies have revealed that the reported state-of-the-art results of many neural recommendation models cannot be reliably replicated. A primary reason is that existing evaluations are performed under various inconsistent protocols. Correspondingly, these replicability issues make it difficult to understand how much benefit we can actually gain from these neural models. It then becomes clear that a fair and comprehensive performance comparison between traditional and neural models is needed. Motivated by these issues, we perform a large-scale, systematic study to compare recent neural recommendation models against traditional ones in top-n recommendation from implicit data. We propose a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance of recommendation models. We conduct extensive experiments with 13 popular recommendation models (including two neural models and 11 traditional ones as baselines) on nine commonly used datasets. Our experiments demonstrate that even with extensive hyper-parameter searches, neural models do not dominate traditional models in all aspects, e.g., they fare worse in terms of average HitRate. We further find that there are areas where neural models seem to outperform non-neural models, for example, in recommendation diversity and robustness between different subgroups of users and items. Our work illuminates the relative advantages and disadvantages of neural models in recommendation and is therefore an important step towards building better recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "48839531",
                    "name": "Tobias Schnabel"
                }
            ]
        }
    ]
}