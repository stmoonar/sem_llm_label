{
    "authorId": "144081368",
    "papers": [
        {
            "paperId": "19265db4b61efba7a6a882e89dc43f86ba98b3b6",
            "title": "Question Generation Using Sequence-to-Sequence Model with Semantic Role Labels",
            "abstract": "Automatic generation of questions from text has gained increasing attention due to its useful applications. We propose a novel question generation method that combines the benefits of rule-based and neural sequence-to-sequence (Seq2Seq) models. The proposed method can automatically generate multiple questions from an input sentence covering different views of the sentence as in rule-based methods, while more complicated \u201crules\u201d can be learned via the Seq2Seq model. The method utilizes semantic role labeling to convert training examples into their semantic representations, and then trains a Seq2Seq model over the semantic representations. Our extensive experiments on three real-world data sets show that the proposed method significantly improves the state-of-the-art neural question generation approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215612846",
                    "name": "Alireza Naeiji"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "72794065",
                    "name": "Heidar Davoudi"
                },
                {
                    "authorId": "1680504454",
                    "name": "Marjan Delpisheh"
                },
                {
                    "authorId": "3141102",
                    "name": "Muath Alzghool"
                }
            ]
        },
        {
            "paperId": "2717b83c0cf2bfe1fccd5f5ee4c16710e41f0762",
            "title": "Centrality-based Interpretability Measures for Graph Embeddings",
            "abstract": "Many real-world data are considered as graphs, such as computer networks, social networks and protein-protein interaction networks. Graph embedding methods are powerful tools for representing large graphs in various domains. A graph embedding method projects the components of a graph, such as its nodes or edges, into a vector space with a lower dimensionality than the adjacency matrix of the graph, and aims to preserve the characteristics of the graph. The generated embedding vectors have been utilized in various graph mining applications such as node classification, link prediction and anomaly detection. Despite the wide success of the graph embedding methods, little study has been done to facilitate a better understanding of the graph embeddings. In this paper, inspired by advancements in interpreting word embeddings, we propose two interpretability measures to quantify the interpretability of graph embeddings by leveraging useful network centrality properties and perform comparisons of different graph embedding methods. Using these scores, we can provide insights into the representational power of graph embedding methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50627580",
                    "name": "Shima Khoshraftar"
                },
                {
                    "authorId": "2075424406",
                    "name": "Sedigheh Mahdavi"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                }
            ]
        },
        {
            "paperId": "439501231b103a7121ef5862a72abeebf6ee1d0b",
            "title": "Extending Isolation Forest for Anomaly Detection in Big Data via K-Means",
            "abstract": "Industrial Information Technology infrastructures are often vulnerable to cyberattacks. To ensure security to the computer systems in an industrial environment, it is required to build effective intrusion detection systems to monitor the cyber-physical systems (e.g., computer networks) in the industry for malicious activities. This article aims to build such intrusion detection systems to protect the computer networks from cyberattacks. More specifically, we propose a novel unsupervised machine learning approach that combines the K-Means algorithm with the Isolation Forest for anomaly detection in industrial big data scenarios. Since our objective is to build the intrusion detection system for the big data scenario in the industrial domain, we utilize the Apache Spark framework to implement our proposed model that was trained in large network traffic data (about 123 million instances of network traffic) stored in Elasticsearch. Moreover, we evaluate our proposed model on the live streaming data and find that our proposed system can be used for real-time anomaly detection in the industrial setup. In addition, we address different challenges that we face while training our model on large datasets and explicitly describe how these issues were resolved. Based on our empirical evaluation in different use cases for anomaly detection in real-world network traffic data, we observe that our proposed system is effective to detect anomalies in big data scenarios. Finally, we evaluate our proposed model on several academic datasets to compare with other models and find that it provides comparable performance with other state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46437970",
                    "name": "Md Tahmid Rahman Laskar"
                },
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                },
                {
                    "authorId": "2086066216",
                    "name": "Vladan Smetana"
                },
                {
                    "authorId": "2057207050",
                    "name": "Chris Stewart"
                },
                {
                    "authorId": "2086067649",
                    "name": "Kees Pouw"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "145028829",
                    "name": "Steve Chan"
                },
                {
                    "authorId": "2152044904",
                    "name": "Lei Liu"
                }
            ]
        },
        {
            "paperId": "071729733087d54b86f9c361ec25d45e30352eb7",
            "title": "Leveraging Transitions of Emotions for Sarcasm Detection",
            "abstract": "One popular thread of research in computational sarcasm detection involves modeling sarcasm as a contrast between positive and negative sentiment polarities or exploring more fine-grained categories of emotions such as happiness, sadness, surprise, and so on. Most current models, however, treat these affective features independently, without regard for the sequential information encoded among the affective states. In order to explore the role of transitions in affective states, we formulate the task of sarcasm detection as a sequence classification problem by leveraging the natural shifts in various emotions over the course of a piece of text. Experiments conducted on datasets from two different genres suggest that our proposed approach particularly benefits datasets with limited labeled data and longer instances of text.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2628916",
                    "name": "Ameeta Agrawal"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "1695845",
                    "name": "M. Papagelis"
                }
            ]
        },
        {
            "paperId": "51c9131b4ee25c5bf74a9bdab5a4fff91306d288",
            "title": "A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks",
            "abstract": "Affective tasks such as sentiment analysis, emotion classification, and sarcasm detection have been popular in recent years due to an abundance of user-generated data, accurate computational linguistic models, and a broad range of relevant applications in various domains. At the same time, many studies have highlighted the importance of text preprocessing, as an integral step to any natural language processing prediction model and downstream task. While preprocessing in affective systems is well-studied, preprocessing in word vector-based models applied to affective systems, is not. To address this limitation, we conduct a comprehensive analysis of the role of preprocessing techniques in affective analysis based on word vector models. Our analysis is the first of its kind and provides useful insights of the importance of each preprocessing technique when applied at the training phase, commonly ignored in pretrained word vector models, and/or at the downstream task phase.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1523819407",
                    "name": "Nastaran Babanejad"
                },
                {
                    "authorId": "2628916",
                    "name": "Ameeta Agrawal"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "1695845",
                    "name": "M. Papagelis"
                }
            ]
        },
        {
            "paperId": "a1c259191518b062d80ab1c020495236cf7c38cd",
            "title": "Improving humanitarian needs assessments through natural language processing",
            "abstract": "An effective response to humanitarian crises relies on detailed information about the needs of the affected population. Current assessment approaches often require interviewers to convert complex, open-ended responses into simplified quantitative data. More nuanced insights require the use of qualitative methods, but proper transcription and manual coding are hard to conduct rapidly and at scale during a crisis. Natural language processing (NLP), a type of artificial intelligence, may provide potentially important new opportunities to capture qualitative data from voice responses and analyze it for relevant content to better inform more effective and rapid humanitarian assistance operational decisions. This article provides an overview of how NLP can be used to transcribe, translate, and analyze large sets of qualitative responses with a view to improving the quality and effectiveness of humanitarian assistance. We describe the practical and ethical challenges of building on the diffusion of digital data collection platforms and introducing this new technology to the humanitarian context. Finally, we provide an overview of the principles that should be used to anticipate and mitigate risks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36938707",
                    "name": "Tino Kreutzer"
                },
                {
                    "authorId": "4630760",
                    "name": "P. Vinck"
                },
                {
                    "authorId": "1891916",
                    "name": "P. Pham"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "19811117",
                    "name": "Lora Appel"
                },
                {
                    "authorId": "150982728",
                    "name": "Eric DeLuca"
                },
                {
                    "authorId": "104235312",
                    "name": "G. Tang"
                },
                {
                    "authorId": "3141102",
                    "name": "Muath Alzghool"
                },
                {
                    "authorId": "14154791",
                    "name": "K. Hachhethu"
                },
                {
                    "authorId": "1441584238",
                    "name": "Bobi Morris"
                },
                {
                    "authorId": "1442037552",
                    "name": "Sandie L. Walton-Ellery"
                },
                {
                    "authorId": "2056642206",
                    "name": "John Crowley"
                },
                {
                    "authorId": "48747110",
                    "name": "J. Orbinski"
                }
            ]
        },
        {
            "paperId": "c43d0b1fe1762bd5b8a5a4882abcda3394e610c9",
            "title": "Paywall Policy Learning in Digital News Media",
            "abstract": "Subscription-based online newspapers usually offer non-subscribed users a certain number of free articles in a period of time, and then directs them to a page (called paywall) asking for subscription. This approach (also known as metered or fixed paywall) does not consider the user's reading history nor the articles that the user may read in the future, and consequently, it may disengage many potential subscribers. To that end, we propose adaptive paywall mechanisms to make optimal paywall decisions (i.e., showing the article or the paywall) by balancing the benefit of showing the article against that of presenting the paywall. We define the notions of utility and cost which are used to define an objective function for the optimal paywall decision problem. We propose the Lookahead policy (LAP) and QPaywall policy (QP) as two data-driven approaches to solve the adaptive paywall problem. While the LAP method makes paywall decisions on the fly by simulating trajectories of article requests using Monte Carlo sampling, the QP approach is based on reinforcement learning and learns a neural network-based action-value (Q) function for this purpose. We compare advantages of the proposed approaches and discuss the practical considerations of using them in a real environment. Empirical studies on a real dataset from a major newspaper in Canada show that the proposed methods outperform several baseline approaches in terms of various business objectives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72794065",
                    "name": "Heidar Davoudi"
                },
                {
                    "authorId": "71425610",
                    "name": "Zana Rashidi"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "22690431",
                    "name": "Morteza Zihayat"
                },
                {
                    "authorId": "17871627",
                    "name": "Gordon Edall"
                }
            ]
        },
        {
            "paperId": "d4f4cd37879a419536ed5ea348db4647ddebbc42",
            "title": "Affective and Contextual Embedding for Sarcasm Detection",
            "abstract": "Automatic sarcasm detection from text is an important classification task that can help identify the actual sentiment in user-generated data, such as reviews or tweets. Despite its usefulness, sarcasm detection remains a challenging task, due to a lack of any vocal intonation or facial gestures in textual data. To date, most of the approaches to addressing the problem have relied on hand-crafted affect features, or pre-trained models of non-contextual word embeddings, such as Word2vec. However, these models inherit limitations that render them inadequate for the task of sarcasm detection. In this paper, we propose two novel deep neural network models for sarcasm detection, namely ACE 1 and ACE 2. Given as input a text passage, the models predict whether it is sarcastic (or not). Our models extend the architecture of BERT by incorporating both affective and contextual features. To the best of our knowledge, this is the first attempt to directly alter BERT\u2019s architecture and train it from scratch to build a sarcasm classifier. Extensive experiments on different datasets demonstrate that the proposed models outperform state-of-the-art models for sarcasm detection with significant margins.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1523819407",
                    "name": "Nastaran Babanejad"
                },
                {
                    "authorId": "72794065",
                    "name": "Heidar Davoudi"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "1695845",
                    "name": "M. Papagelis"
                }
            ]
        },
        {
            "paperId": "188362998d4ff9d1bd439fc72308bc91db80937b",
            "title": "Dynamic Stale Synchronous Parallel Distributed Training for Deep Learning",
            "abstract": "Deep learning is a popular machine learning technique and has been applied to many real-world problems, ranging from computer vision to natural language processing. However, training a deep neural network is very time-consuming, especially on big data. It has become difficult for a single machine to train a large model over large datasets. A popular solution is to distribute and parallelize the training process across multiple machines using the parameter server framework. In this paper, we present a distributed paradigm on the parameter server framework called Dynamic Stale Synchronous Parallel (DSSP) which improves the state-of-the-art Stale Synchronous Parallel (SSP) paradigm by dynamically determining the staleness threshold at the run time. Conventionally to run distributed training in SSP, the user needs to specify a particular stalenes threshold as a hyper-parameter. However, a user does not usually know how to set the threshold and thus often finds a threshold value through trial and error, which is time-consuming. Based on workers' recent processing time, our approach DSSP adaptively adjusts the threshold per iteration at running time to reduce the waiting time of faster workers for synchronization of the globally shared parameters (the weights of the model), and consequently increases the frequency of parameters updates (increases iteration through-put), which speedups the convergence rate. We compare DSSP with other paradigms such as Bulk Synchronous Parallel (BSP), Asynchronous Parallel (ASP), and SSP by running deep neural networks (DNN) models over GPU clusters in both homogeneous and heterogeneous environments. The results show that in a heterogeneous environment where the cluster consists of mixed models of GPUs, DSSP converges to a higher accuracy much earlier than SSP and BSP and performs similarly to ASP. In a homogeneous distributed cluster, DSSP has more stable and slightly better performance than SSP and ASP, and converges much faster than BSP.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2143710622",
                    "name": "Xing Zhao"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "2108414561",
                    "name": "Junfeng Liu"
                },
                {
                    "authorId": "26348170",
                    "name": "B. Chen"
                }
            ]
        },
        {
            "paperId": "b8319e5034085784534a3e12805bae4c01786c23",
            "title": "Content-based Dwell Time Engagement Prediction Model for News Articles",
            "abstract": "The article dwell time (i.e., expected time that users spend on an article) is among the most important factors showing the article engagement. It is of great interest to predict the dwell time of an article before its release. This allows digital newspapers to make informed decisions and publish more engaging articles. In this paper, we propose a novel content-based approach based on a deep neural network architecture for predicting article dwell times. The proposed model extracts emotion, event and entity features from an article, learns interactions among them, and combines the interactions with the word-based features of the article to learn a model for predicting the dwell time. The experimental results on a real dataset from a major newspaper show that the proposed model outperforms other state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7910450",
                    "name": "Heydar Davoudi"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "17871627",
                    "name": "Gordon Edall"
                }
            ]
        }
    ]
}