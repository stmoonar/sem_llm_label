{
    "authorId": "2189394679",
    "papers": [
        {
            "paperId": "6771b7a44ce0a4573a30a366202c395538e80302",
            "title": "CollabStory: Multi-LLM Collaborative Story Generation and Authorship Analysis",
            "abstract": "The rise of unifying frameworks that enable seamless interoperability of Large Language Models (LLMs) has made LLM-LLM collaboration for open-ended tasks a possibility. Despite this, there have not been efforts to explore such collaborative writing. We take the next step beyond human-LLM collaboration to explore this multi-LLM scenario by generating the first exclusively LLM-generated collaborative stories dataset called CollabStory. We focus on single-author ($N=1$) to multi-author (up to $N=5$) scenarios, where multiple LLMs co-author stories. We generate over 32k stories using open-source instruction-tuned LLMs. Further, we take inspiration from the PAN tasks that have set the standard for human-human multi-author writing tasks and analysis. We extend their authorship-related tasks for multi-LLM settings and present baselines for LLM-LLM collaboration. We find that current baselines are not able to handle this emerging scenario. Thus, CollabStory is a resource that could help propel an understanding as well as the development of techniques to discern the use of multiple LLMs. This is crucial to study in the context of writing tasks since LLM-LLM collaboration could potentially overwhelm ongoing challenges related to plagiarism detection, credit assignment, maintaining academic integrity in educational settings, and addressing copyright infringement concerns. We make our dataset and code available at \\texttt{\\url{https://github.com/saranya-venkatraman/multi_llm_story_writing}}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "66674465",
                    "name": "Nafis Irtiza Tripto"
                },
                {
                    "authorId": "2307219947",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "8baf10d11f02a162667087f276c86d187ff9e919",
            "title": "ALISON: Fast and Effective Stylometric Authorship Obfuscation",
            "abstract": "Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competing tasks of increasing importance in privacy research. Modern AA leverages an author's consistent writing style to match a text to its author using an AA classifier. AO is the corresponding adversarial task, aiming to modify a text in such a way that its semantics are preserved, yet an AA model cannot correctly infer its authorship. To address privacy concerns raised by state-of-the-art (SOTA) AA methods,\nnew AO methods have been proposed but remain largely impractical to use due to their prohibitively slow training and obfuscation speed, often taking hours.\nTo this challenge, we propose a practical AO method, ALISON, that (1) dramatically reduces training/obfuscation time, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2) achieves better obfuscation success through attacking three transformer-based AA methods on two benchmark datasets, typically performing 15% better than competing methods, (3) does not require direct signals from a target AA classifier during obfuscation, and (4) utilizes unique stylometric features, allowing sound model interpretation for explainable obfuscation. We also demonstrate that ALISON can effectively prevent four SOTA AA methods from accurately determining the authorship of ChatGPT-generated texts, all while minimally changing the original text semantics. To ensure the reproducibility of our findings, our code and data are available at: https://github.com/EricX003/ALISON.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276555903",
                    "name": "Eric Xing"
                },
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "2260345102",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "910fe31c02257e88c92ca2468e086f06db0141e6",
            "title": "ClassInSight: Designing Conversation Support Tools to Visualize Classroom Discussion for Personalized Teacher Professional Development",
            "abstract": "Teaching is one of many professions for which personalized feedback and reflection can help improve dialogue and discussion between the professional and those they serve. However, professional development (PD) is often impersonal as human observation is labor-intensive. Data-driven PD tools in teaching are of growing interest, but open questions about how professionals engage with their data in practice remain. In this paper, we present ClassInSight, a tool that visualizes three levels of teachers\u2019 discussion data and structures reflection. Through 22 reflection sessions and interviews with 5 high school science teachers, we found themes related to dissonance, contextualization, and sustainability in how teachers engaged with their data in the tool and in how their professional vision, the use of professional expertise to interpret events, shifted over time. We discuss guidelines for these conversational support tools to support personalized PD in professions beyond teaching where conversation and interaction are important.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2315230069",
                    "name": "Tricia J. Ngoon"
                },
                {
                    "authorId": "2289844467",
                    "name": "S. Sushil"
                },
                {
                    "authorId": "2301062600",
                    "name": "Angela E.B. Stewart"
                },
                {
                    "authorId": "2211336328",
                    "name": "Ung-Sang Lee"
                },
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "2289844447",
                    "name": "Neil Thawani"
                },
                {
                    "authorId": "2289844410",
                    "name": "Prasenjit Mitra"
                },
                {
                    "authorId": "153112148",
                    "name": "S. Clarke"
                },
                {
                    "authorId": "2301076859",
                    "name": "John Zimmerman"
                },
                {
                    "authorId": "2289844206",
                    "name": "Amy Ogan"
                }
            ]
        },
        {
            "paperId": "0aa4579a5e76677ecd2c9c1d21ba84e1959c1180",
            "title": "How do decoding algorithms distribute information in dialogue responses?",
            "abstract": "Humans tend to follow the Uniform Information Density (UID) principle by distributing information evenly in utterances. We study if decoding algorithms implicitly follow this UID principle, and under what conditions adherence to UID might be desirable for dialogue generation. We generate responses using different decoding algorithms with GPT-2 on the Persona-Chat dataset and collect human judgments on their quality using Amazon Mechanical Turk. We find that (i) surprisingly, model-generated responses follow the UID principle to a greater extent than human responses, and (ii) decoding algorithms that promote UID do not generate higher-quality responses. Instead, when we control for surprisal, non-uniformity of information density correlates with the quality of responses with very low/high surprisal. Our findings indicate that encouraging non-uniform responses is a potential solution to the \u201clikelihood trap\u201d problem (quality degradation in very high-likelihood text). Our dataset containing multiple candidate responses per dialog history along with human-annotated quality ratings is available at: https://huggingface.co/datasets/saranya132/dialog_uid_gpt2.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "144533687",
                    "name": "He He"
                },
                {
                    "authorId": "1781409",
                    "name": "D. Reitter"
                }
            ]
        },
        {
            "paperId": "311841075acf5a5b38d807c68fa9f55e4aa274bf",
            "title": "A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts",
            "abstract": "In the realm of text manipulation and linguistic transformation, the question of authorship has been a subject of fascination and philosophical inquiry. Much like the Ship of Theseus paradox, which ponders whether a ship remains the same when each of its original planks is replaced, our research delves into an intriguing question: Does a text retain its original authorship when it undergoes numerous paraphrasing iterations? Specifically, since Large Language Models (LLMs) have demonstrated remarkable proficiency in both the generation of original content and the modification of human-authored texts, a pivotal question emerges concerning the determination of authorship in instances where LLMs or similar paraphrasing tools are employed to rephrase the text--i.e., whether authorship should be attributed to the original human author or the AI-powered tool. Therefore, we embark on a philosophical voyage through the seas of language and authorship to unravel this intricate puzzle. Using a computational approach, we discover that the diminishing performance in text classification models, with each successive paraphrasing iteration, is closely associated with the extent of deviation from the original author's style, thus provoking a reconsideration of the current notion of authorship.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66674465",
                    "name": "Nafis Irtiza Tripto"
                },
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "2260109257",
                    "name": "Dominik Macko"
                },
                {
                    "authorId": "144535025",
                    "name": "R\u00f3bert M\u00f3ro"
                },
                {
                    "authorId": "2129782",
                    "name": "Ivan Srba"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2260345102",
                    "name": "Thai Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        },
        {
            "paperId": "916dc0026896e65cccb3d2ca0ef48185ad10dc06",
            "title": "The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis",
            "abstract": "We conduct an inquiry into the sociotechnical aspects of sentiment analysis (SA) by critically examining 189 peer-reviewed papers on their applications, models, and datasets. Our investigation stems from the recognition that SA has become an integral component of diverse sociotechnical systems, exerting influence on both social and technical users. By delving into sociological and technological literature on sentiment, we unveil distinct conceptualizations of this term in domains such as finance, government, and medicine. Our study exposes a lack of explicit definitions and frameworks for characterizing sentiment, resulting in potential challenges and biases. To tackle this issue, we propose an ethics sheet encompassing critical inquiries to guide practitioners in ensuring equitable utilization of SA. Our findings underscore the significance of adopting an interdisciplinary approach to defining sentiment in SA and offer a pragmatic solution for its implementation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053812167",
                    "name": "Pranav Narayanan Venkit"
                },
                {
                    "authorId": "47467195",
                    "name": "Mukund Srinath"
                },
                {
                    "authorId": "2142840013",
                    "name": "Sanjana Gautam"
                },
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "2110652561",
                    "name": "Vipul Gupta"
                },
                {
                    "authorId": "1703046",
                    "name": "R. Passonneau"
                },
                {
                    "authorId": "31950200",
                    "name": "Shomir Wilson"
                }
            ]
        },
        {
            "paperId": "a00dc9750bca4ddaed171866ce696b5da1fe4cbd",
            "title": "GPT-who: An Information Density-based Machine-Generated Text Detector",
            "abstract": "The Uniform Information Density (UID) principle posits that humans prefer to spread information evenly during language production. We examine if this UID principle can help capture differences between Large Language Models (LLMs)-generated and human-generated texts. We propose GPT-who, the first psycholinguistically-inspired domain-agnostic statistical detector. This detector employs UID-based features to model the unique statistical signature of each LLM and human author for accurate detection. We evaluate our method using 4 large-scale benchmark datasets and find that GPT-who outperforms state-of-the-art detectors (both statistical-&non-statistical) such as GLTR, GPTZero, DetectGPT, OpenAI detector, and ZeroGPT by over $20$% across domains. In addition to better performance, it is computationally inexpensive and utilizes an interpretable representation of text articles. We find that GPT-who can distinguish texts generated by very sophisticated LLMs, even when the overlying text is indiscernible. UID-based measures for all datasets and code are available at https://github.com/saranya-venkatraman/gpt-who.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189394679",
                    "name": "Saranya Venkatraman"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                }
            ]
        }
    ]
}