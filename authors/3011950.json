{
    "authorId": "3011950",
    "papers": [
        {
            "paperId": "16bbe866a849e538dc4cd2b213ca06e50595a23b",
            "title": "Competition or Cooperation? Exploring Unlabeled Data via Challenging Minimax Game for Semi-supervised Relation Extraction",
            "abstract": "Semi-Supervised Relation Extraction aims at learning well-performed RE models with limited labeled and large-scale unlabeled data. Existing methods mainly suffer from semantic drift and insufficient supervision, which severely limit the performance. To address these problems, recent work tends to design dual modules to work cooperatively for mutual enhancement. However, the consensus of two modules greatly restricts the model from exploring diverse relation expressions in unlabeled set, which hinders the performance as well as model generalization. To tackle this problem, in this paper, we propose a novel competition-based method AdvSRE. We set up a challenging minimax game on unlabeled data between two modules, Generator and Discriminator, and assign them with conflicting objectives. During the competition game, one module may find any possible chance to beat the other, which develops two modules' abilities until relation expressions cannot be further explored. To exploit label information, Discriminator is further asked to predict specific relation for each sentence. Experiment results on two benchmarks show new state-of-the-art performance over baselines, demonstrating the effectiveness of proposed AdvSRE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144873792",
                    "name": "Yu Hong"
                },
                {
                    "authorId": "2108959013",
                    "name": "Jiahang Li"
                },
                {
                    "authorId": "9504340",
                    "name": "Jianchuan Feng"
                },
                {
                    "authorId": "2179447409",
                    "name": "C. Huang"
                },
                {
                    "authorId": "115419489",
                    "name": "Zhixu Li"
                },
                {
                    "authorId": "2069479032",
                    "name": "Jianfeng Qu"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                },
                {
                    "authorId": "49337119",
                    "name": "W. Wang"
                }
            ]
        },
        {
            "paperId": "4e62f81ca0f5b8ce67e6eec61034cc772344b939",
            "title": "Prototypical Concept Representation",
            "abstract": "Concepts are building blocks of human thinking. For machines, concept understanding has also been increasingly important, which makes concept representation a fundamental problem in artificial intelligence. While many concepts have their instances, the massive amount of information carried by instances has long been ignored in current concept representation, which limits the usage of these concepts in applications. In this paper, inspired by prototype theory in cognitive science, we propose prototypical concept representation for machines, which represents each concept with a distributed prototype derived from representations of its instances. For prototypical representation learning, we further introduce a novel model named Prototypical Siamese Network (PSN). PSN is trained under the supervision of isA determination, one of the most important concept-related applications. Results of extensive experiments demonstrate that, our method achieves state-of-the-art performance, thus validating the effectiveness of prototypical concept representation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108003209",
                    "name": "Xintao Wang"
                },
                {
                    "authorId": "3366523",
                    "name": "Jiaqing Liang"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                },
                {
                    "authorId": "49337119",
                    "name": "W. Wang"
                }
            ]
        },
        {
            "paperId": "aef7f2de71a76163d6241605038c41d7e01b7156",
            "title": "Towards Fine-Grained Concept Generation",
            "abstract": "Constructing large-scale taxonomies are crucial for many knowledge-rich applications that need concepts to better understand texts. However, current taxonomies suffer from the scarcity of concepts. Specifically, many fine-grained concepts are missing, while these fine-grained concepts play important roles in understanding related instances more deeply. In this paper, we propose an unsupervised fine-grained concept generation framework called FGCGen, which takes advantages of knowledge bases to generate mass of fine-grained concepts. Specifically, instead of extracting concepts from corpus, FGCGen detects entity heads and modifiers from knowledge bases and combines them to generate fine-grained concepts. We identify critical challenges of this generation process and employ three novel modules to solve them. We evaluate proposed methods on both Chinese and English datasets to show the strength of FGCGen, especially on constructing large-scale high-quality fine-grained taxonomies. Extensive experiments are introduced to prove the efficiency and effectiveness of the modules in FGCGen.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128671517",
                    "name": "Chenguang Li"
                },
                {
                    "authorId": "3366523",
                    "name": "Jiaqing Liang"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                },
                {
                    "authorId": "48579460",
                    "name": "Haiyun Jiang"
                }
            ]
        },
        {
            "paperId": "cbbeec670c7697b7b22c4805fb5d0f2488b01c76",
            "title": "Efficient Single-Source SimRank Query by Path Aggregation",
            "abstract": "Single-source SimRank query calculates the similarity between a query node and every node in a graph, which traverses the paths starting from the query node for similarity computation. However, the scale of the paths increases exponentially as path length increases, which decreases the computation efficiency. Sampling-based algorithms reduce computational cost by path sampling, but they need to sample sufficient paths to ensure the accuracy, and the performance might be affected by the large scale of paths. In this paper, we propose VecSim for efficient single-source SimRank query by path aggregation. VecSim first aggregates the paths starting from query node with common arrived nodes step by step to obtain the hitting probabilities, and then aggregates the paths starting from the arrived nodes reversely to obtain the first-meeting probabilities in a similar way, in which only several vectors are maintained. The extra-meeting probabilities are excluded from each step, and an efficient sampling-based algorithm is designed, which estimates the extra-meeting probabilities by sampling paths within a specified length. For further speeding up query processing, we propose a threshold-sieved algorithm, which prunes the entries with small values that contribute little to the final similarity scores by setting a threshold. Extensive experiments are done on four small and four large graphs, which demonstrate that VecSim outperforms the competitors in terms of time and space costs on a comparable accuracy. In particular, VecSim achieves an empirical error of 10-4 level in under 0.1 second over all of these graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215372987",
                    "name": "Mingxi Zhang"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                },
                {
                    "authorId": "49337119",
                    "name": "W. Wang"
                }
            ]
        },
        {
            "paperId": "082a79e7a7618c895647094cff9332ae44dec784",
            "title": "Group Buying Recommendation Model Based on Multi-task Learning",
            "abstract": "In recent years, group buying has become one popular kind of online shopping activities, thanks to its larger sales and lower unit price. Unfortunately, seldom research focuses on the recommendations specifically for group buying by now. Although some recommendation models have been proposed for group recommendation, they can not be directly used to achieve the real-world group buying recommendation, due to the essential difference between group recommendation and group buying recommendation. In this paper, we first formalize the task of group buying recommendation into two sub-tasks. Then, based on our insights into the correlations and interactions between the two sub-tasks, we propose a novel recommendation model for group buying, namely MGBR, which is built mainly with a multi-task learning module. To improve recommendation performance further, we devise some collaborative expert networks and adjusted gates in the multi-task learning module, to promote the information interaction between the two sub-tasks. Furthermore, we propose two auxiliary losses corresponding to the two sub-tasks, to refine the representation learning in our model. Our extensive experiments not only demonstrate that the augmented representations learned in our model result in better performance than previous recommendation models, but also justify the impacts of the specially designed components in our model. To reproduce our model\u2019s recommendation results conveniently, we have provided our model\u2019s source code and dataset on https://github.com/DeqingYang/MGBR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191754141",
                    "name": "Shuoyao Zhai"
                },
                {
                    "authorId": "2116441490",
                    "name": "Baichuan Liu"
                },
                {
                    "authorId": "2089312",
                    "name": "Deqing Yang"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                }
            ]
        },
        {
            "paperId": "0e8f12da99f13db16bcf3e7435958b887f5959b9",
            "title": "Spiral of Silence and Its Application in Recommender Systems",
            "abstract": "It is crucial to model missing ratings in recommender systems since user preferences learnt from only observed ratings are biased. One possible explanation for missing ratings is motivated by the spiral of silence theory. When the majority opinion is formed, a spiral process is triggered where users are more and more likely to show their ratings if they perceive that they are supported by the opinion climate. In this paper we first verify the existence of the spiral process in recommender systems by using a variety of different real-life datasets. We then study the characteristics of two key factors in the spiral process: opinion climate and the hardcore users who will give ratings even when they are minority opinion holders. Based on our empirical findings, we develop four variants to model missing ratings. They mimic different components of the spiral of silence based on the spiral process with global opinion climate, local opinion climate, hardcore users, relationships between hardcore users and items, respectively. We experimentally show that, the presented variants all outperform state-of-the-art recommendation models with missing rating components.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144724978",
                    "name": "Chen Lin"
                },
                {
                    "authorId": "66953961",
                    "name": "Dugang Liu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                }
            ]
        },
        {
            "paperId": "8d088c70e332c09c7ea58d890ab8cc09deb6ceba",
            "title": "A Sequence-to-Sequence Model for Large-scale Chinese Abbreviation Database Construction",
            "abstract": "Abbreviations often used in our daily communication play an important role in natural language processing. Most of the existing studies regard the Chinese abbreviation prediction as a sequence labeling problem. However, sequence labeling models usually ignore label dependencies in the process of abbreviation prediction, and the label prediction of each character should be conditioned on its previous labels. In this paper, we propose to formalize the Chinese abbreviation prediction task as a sequence generation problem, and a novel sequence-to-sequence model is designed. To boost the performance of our deep model, we further propose a multi-level pre-trained model that incorporates character, word, and concept-level embeddings. To evaluate our methods, a new dataset for Chinese abbreviation prediction is automatically built, which contains 81,351 pairs of full forms and abbreviations. Finally, we conduct extensive experiments on a public dataset and the built dataset, and the experimental results on both datasets show that our model outperforms the state-of-the-art methods. More importantly, we build a large-scale database for a specific domain, i.e., life services in Meituan Inc., with high accuracy of about 82.7%, which contains 4,134,142 pairs of full forms and abbreviations. The online A/B testing on Meituan APP and Dianping APP suggests that Click-Through Rate increases by 0.59% and 0.86% respectively when the built database is used in the searching system. We have released our API on http://kw.fudan.edu.cn/ddemos/abbr/ with over 87k API calls in 9 months.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144448869",
                    "name": "Chao Wang"
                },
                {
                    "authorId": "2108343759",
                    "name": "Jingping Liu"
                },
                {
                    "authorId": "1380130279",
                    "name": "Tianyi Zhuang"
                },
                {
                    "authorId": "2108959013",
                    "name": "Jiahang Li"
                },
                {
                    "authorId": "2155365061",
                    "name": "Juntao Liu"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                },
                {
                    "authorId": "2158625822",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "2053425736",
                    "name": "Rui Xie"
                }
            ]
        },
        {
            "paperId": "aefda119caf54f3ebd25f03aa0192da246120c1b",
            "title": "Contextual Information and Commonsense Based Prompt for Emotion Recognition in Conversation",
            "abstract": "Emotion recognition in conversation (ERC) aims to detect the emotion for each utterance in a given conversation. The newly proposed ERC models have leveraged pre-trained language models (PLMs) with the paradigm of pre-training and fine-tuning to obtain good performance. However, these models seldom exploit PLMs' advantages thoroughly, and perform poorly for the conversations lacking explicit emotional expressions. In order to fully leverage the latent knowledge related to the emotional expressions in utterances, we propose a novel ERC model CISPER with the new paradigm of prompt and language model (LM) tuning. Specifically, CISPER is equipped with the prompt blending the contextual information and commonsense related to the interlocutor's utterances, to achieve ERC more effectively. Our extensive experiments demonstrate CISPER's superior performance over the state-of-the-art ERC models, and the effectiveness of leveraging these two kinds of significant prompt information for performance gains. To reproduce our experimental results conveniently, CISPER's sourcecode and the datasets have been shared at https://github.com/DeqingYang/CISPER.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119873627",
                    "name": "Jingjie Yi"
                },
                {
                    "authorId": "1944126000",
                    "name": "Deqing Yang"
                },
                {
                    "authorId": "2145968425",
                    "name": "Siyu Yuan"
                },
                {
                    "authorId": "2179328656",
                    "name": "Caiyan Cao"
                },
                {
                    "authorId": "2179433466",
                    "name": "Zhiyao Zhang"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                }
            ]
        },
        {
            "paperId": "c188274e2caaa726a86154292ec49727df6d5ca2",
            "title": "Learning Dual-view User Representations for Enhanced Sequential Recommendation",
            "abstract": "Sequential recommendation (SR) aims to predict a user\u2019s next interacted item given his/her historical interactions. Most existing sequential recommendation systems model user preferences only with item-level representations, where a user\u2019s interaction sequence are often modeled with sequential or graph-based method to infer the user\u2019s sequential interaction pattern. However, since a user\u2019s preference factors may vary over time, the user modeling on item-level could hardly represent the user\u2019s preference precisely and sufficiently, resulting in suboptimal recommendation performance. In addition, the recommendation results based on the item-level user representations lack the interpretability of preference factors. To address these problems, we propose a novel SR model with dual-view user representations in this article, namely DUVRec, where a user\u2019s preference is learned based on the representations of two distinct views, i.e., item view and factor view. Specifically, the item-view user representation is learned as the previous SR models to encode the user preference of item level, while the factor-view user representation is learned by an coarse-grained graph embedding method to explicitly represent the user in terms of preference factors. As a result, such dual-view user representations are more comprehensive than that in the previous SR models, leading to enhanced SR performance. Furthermore, we design a contrastive learning strategy to achieve mutual complementation between these two views. Our extensive experiments upon three benchmark datasets justify DUVRec\u2019s superior performance over the state-of-the-art SR models, including the advantage of the dual-view contrastive learning. In addition, DUVRec\u2019s capability of providing explanations on recommendation results is also demonstrated through some specific case studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037763096",
                    "name": "Lyuxin Xue"
                },
                {
                    "authorId": "1944126000",
                    "name": "Deqing Yang"
                },
                {
                    "authorId": "2191754141",
                    "name": "Shuoyao Zhai"
                },
                {
                    "authorId": "2191815437",
                    "name": "Yuxin Li"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                }
            ]
        },
        {
            "paperId": "dd5a4b99652ee00c81fc0d8aa116a0ff5d5c65f2",
            "title": "Factorial User Modeling with Hierarchical Graph Neural Network for Enhanced Sequential Recommendation",
            "abstract": "Most sequential recommendation (SR) systems employing graph neural networks (GNNs) only model a user's interaction sequence as a flat graph without hierarchy, overlooking diverse factors in the user's preference. Moreover, the timespan between interacted items is not sufficiently utilized by previous models, restricting SR performance gains. To address these problems, we propose a novel SR system employing a hierarchical graph neural network (HGNN) to model factorial user preferences. Specifically, a timespan-aware sequence graph (TSG) for the target user is first constructed with the timespan among interacted items. Next, all original nodes in TSG are softly clustered into factor nodes, each of which represents a certain factor of the user's preference. At last, all factor nodes' representations are used together to predict SR results. Our extensive experiments upon two datasets justify that our HGNN-based factorial user modeling obtains better SR performance than the state-of-the-art SR models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037763096",
                    "name": "Lyuxin Xue"
                },
                {
                    "authorId": "2089312",
                    "name": "Deqing Yang"
                },
                {
                    "authorId": "3011950",
                    "name": "Yanghua Xiao"
                }
            ]
        }
    ]
}