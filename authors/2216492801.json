{
    "authorId": "2216492801",
    "papers": [
        {
            "paperId": "6784651527c5c25cf7c202124ef55e2fcea58a96",
            "title": "Arabic Automatic Story Generation with Large Language Models",
            "abstract": "Large language models (LLMs) have recently emerged as a powerful tool for a wide range of language generation tasks. Nevertheless, this progress has been slower in Arabic. In this work, we focus on the task of generating stories from LLMs. For our training, we use stories acquired through machine translation (MT) as well as GPT-4. For the MT data, we develop a careful pipeline that ensures we acquire high-quality stories. For our GPT-4 data, we introduce crafted prompts that allow us to generate data well-suited to the Arabic context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian and Moroccan). For example, we generate stories tailored to various Arab countries on a wide host of topics. Our manual evaluation shows that our model fine-tuned on these training datasets can generate coherent stories that adhere to our instructions. We also conduct an extensive automatic and human evaluation comparing our models against state-of-the-art proprietary and open-source models. Our datasets and models will be made publicly available at https://github.com/UBC-NLP/arastories.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "2156914450",
                    "name": "Fakhraddin Alwajih"
                },
                {
                    "authorId": "2065312024",
                    "name": "Muhammad Abdul-Mageed"
                }
            ]
        },
        {
            "paperId": "56a3ec139617b28fea4cc548e792133bffa48aff",
            "title": "Dolphin: A Challenging and Diverse Benchmark for Arabic NLG",
            "abstract": "We present Dolphin, a novel benchmark that addresses the need for a natural language generation (NLG) evaluation framework dedicated to the wide collection of Arabic languages and varieties. The proposed benchmark encompasses a broad range of 13 different NLG tasks, including dialogue generation, question answering, machine translation, summarization, among others. Dolphin comprises a substantial corpus of 40 diverse and representative public datasets across 50 test splits, carefully curated to reflect real-world scenarios and the linguistic richness of Arabic. It sets a new standard for evaluating the performance and generalization capabilities of Arabic and multilingual models, promising to enable researchers to push the boundaries of current methodologies. We provide an extensive analysis of Dolphin, highlighting its diversity and identifying gaps in current Arabic NLG research. We also offer a public leaderboard that is both interactive and modular and evaluate several models on our benchmark, allowing us to set strong baselines against which researchers can compare.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "17771023",
                    "name": "El Moatez Billah Nagoudi"
                },
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "1397289779",
                    "name": "AbdelRahim Elmadany"
                },
                {
                    "authorId": "2065312024",
                    "name": "Muhammad Abdul-Mageed"
                }
            ]
        },
        {
            "paperId": "614e20dd8120a7e127b3dc764122c75472bb26e6",
            "title": "QCRI at SemEval-2023 Task 3: News Genre, Framing and Persuasion Techniques Detection Using Multilingual Models",
            "abstract": "Misinformation spreading in mainstream and social media has been misleading users in different ways. Manual detection and verification efforts by journalists and fact-checkers can no longer cope with the great scale and quick spread of misleading information. This motivated research and industry efforts to develop systems for analyzing and verifying news spreading online. The SemEval-2023 Task 3 is an attempt to address several subtasks under this overarching problem, targeting writing techniques used in news articles to affect readers\u2019 opinions. The task addressed three subtasks with six languages, in addition to three \u201csurprise\u201d test languages, resulting in 27 different test setups. This paper describes our participating system to this task. Our team is one of the 6 teams that successfully submitted runs for all setups. The official results show that our system is ranked among the top 3 systems for 10 out of the 27 setups.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "115999068",
                    "name": "R. N. Nandi"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                }
            ]
        },
        {
            "paperId": "796b894c4e1a3cb46715cc0b45a39e91ee5910e6",
            "title": "TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties",
            "abstract": "Despite the purported multilingual proficiency of instruction-finetuned large language models (LLMs) such as ChatGPT and Bard, the linguistic inclusivity of these models remains insufficiently explored. Considering this constraint, we present a thorough assessment of Bard and ChatGPT (encompassing both GPT-3.5 and GPT-4) regarding their machine translation proficiencies across ten varieties of Arabic. Our evaluation covers diverse Arabic varieties such as Classical Arabic (CA), Modern Standard Arabic (MSA), and several country-level dialectal variants. Our analysis indicates that LLMs may encounter challenges with dialects for which minimal public datasets exist, but on average are better translators of dialects than existing commercial systems. On CA and MSA, instruction-tuned LLMs, however, trail behind commercial systems such as Google Translate. Finally, we undertake a human-centric study to scrutinize the efficacy of the relatively recent model, Bard, in following human instructions during translation tasks. Our analysis reveals a circumscribed capability of Bard in aligning with human instructions in translation contexts. Collectively, our findings underscore that prevailing LLMs remain far from inclusive, with only limited ability to cater for the linguistic and cultural intricacies of diverse communities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121326674",
                    "name": "Karima Kadaoui"
                },
                {
                    "authorId": "148087360",
                    "name": "S. Magdy"
                },
                {
                    "authorId": "2215440985",
                    "name": "Abdul Waheed"
                },
                {
                    "authorId": "118865912",
                    "name": "Md. Tawkat Islam Khondaker"
                },
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "17771023",
                    "name": "El Moatez Billah Nagoudi"
                },
                {
                    "authorId": "2065312024",
                    "name": "Muhammad Abdul-Mageed"
                }
            ]
        },
        {
            "paperId": "c7248f06ce59dad9ddb36db3032d2901f611c3d1",
            "title": "Arabic Fine-Grained Entity Recognition",
            "abstract": "Traditional NER systems are typically trained to recognize coarse-grained categories of entities, and less attention is given to classifying entities into a hierarchy of fine-grained lower-level sub-types. This article aims to advance Arabic NER with fine-grained entities. We chose to extend Wojood (an open-source Nested Arabic Named Entity Corpus) with sub-types. In particular, four main entity types in Wojood (geopolitical entity (GPE), location (LOC), organization (ORG), and facility (FAC) are extended with 31 sub-types of entities. To do this, we first revised Wojood\u2019s annotations of GPE, LOC, ORG, and FAC to be compatible with the LDC\u2019s ACE guidelines, which yielded 5, 614 changes. Second, all mentions of GPE, LOC, ORG, and FAC (~ 44K) in Wojood are manually annotated with the LDC\u2019s ACE subtypes. This extended version of Wojood is called WojoodFine. To evaluate our annotations, we measured the inter-annotator agreement (IAA) using both Cohen\u2019s Kappa and F1 score, resulting in 0.9861 and 0.9889, respectively. To compute the baselines of WojoodFine, we fine-tune three pre-trained Arabic BERT encoders in three settings: flat NER, nested NER and nested NER with sub-types and achieved F1 score of 0.920, 0.866, and 0.885, respectively. Our corpus and models are open source and available at https://sina.birzeit.edu/wojood/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261740556",
                    "name": "Haneen Liqreina"
                },
                {
                    "authorId": "2261672608",
                    "name": "Mustafa Jarrar"
                },
                {
                    "authorId": "121034666",
                    "name": "Mohammed Khalilia"
                },
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "2261739962",
                    "name": "Muhammad AbdulMageed"
                }
            ]
        },
        {
            "paperId": "16156f70b544c1427f56e34042af2916674e200e",
            "title": "Ahmed and Khalil at NADI 2022: Transfer Learning and Addressing Class Imbalance for Arabic Dialect Identification and Sentiment Analysis",
            "abstract": "In this paper, we present our findings in the two subtasks of the 2022 NADI shared task. First, in the Arabic dialect identification subtask, we find that there is heavy class imbalance, and propose to address this issue using focal loss. Our experiments with the focusing hyperparameter confirm that focal loss improves performance. Second, in the Arabic tweet sentiment analysis subtask, we deal with a smaller dataset, where text includes both Arabic dialects and Modern Standard Arabic. We propose to use transfer learning from both pre-trained MSA language models and our own model from the first subtask. Our system ranks in the 5th and 7th best spots of the leaderboards of first and second subtasks respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "46180513",
                    "name": "Khalil Mrini"
                }
            ]
        },
        {
            "paperId": "3199b66e91c87ee17100599a8814896c7cfd59be",
            "title": "Deep Multi-Task Models for Misogyny Identification and Categorization on Arabic Social Media",
            "abstract": "The prevalence of toxic content on social media platforms, such as hate speech, offensive language, and misogyny, presents serious challenges to our interconnected society. These challenging issues have attracted widespread attention in Natural Language Processing (NLP) community. In this paper, we present the submitted systems to the first Arabic Misogyny Identification shared task. We investigate three multi-task learning models as well as their single-task counterparts. In order to encode the input text, our models rely on the pre-trained MARBERT language model. The overall obtained results show that all our submitted models have achieved the best performances (top three ranked submissions) in both misogyny identification and categorization tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3196929",
                    "name": "Abdelkader El Mahdaouy"
                },
                {
                    "authorId": "150911972",
                    "name": "Abdellah El Mekki"
                },
                {
                    "authorId": "2216492801",
                    "name": "Ahmed Oumar El-Shangiti"
                },
                {
                    "authorId": "2431019",
                    "name": "H. Mousannif"
                },
                {
                    "authorId": "2548030",
                    "name": "Ismail Berrada"
                }
            ]
        }
    ]
}