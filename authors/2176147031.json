{
    "authorId": "2176147031",
    "papers": [
        {
            "paperId": "0ad61806b055af61b59595d3ce2ab185da279a91",
            "title": "Enable Natural Tactile Interaction for Robot Dog based on Large-format Distributed Flexible Pressure Sensors",
            "abstract": "Touch is an important channel for human-robot interaction, while it is challenging for robots to recognize human touch accurately and make appropriate responses. In this paper, we design and implement a set of large-format distributed flexible pressure sensors on a robot dog to enable natural human-robot tactile interaction. Through a heuristic study, we sorted out 81 tactile gestures commonly used when humans interact with real dogs and 44 dog reactions. A gesture classification algorithm based on ResNet is proposed to recognize these 81 human gestures, and the classification accuracy reaches 98.7%. In addition, an action prediction algorithm based on Transformer is proposed to predict dog actions from human gestures, reaching a 1-gram BLEU score of 0.87. Finally, we compare the tactile interaction with the voice interaction during a freedom human-robot-dog interactive playing study. The results show that tactile interaction plays a more significant role in alleviating user anxiety, stimulating user excitement and improving the acceptability of robot dogs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2052114898",
                    "name": "Lishuang Zhan"
                },
                {
                    "authorId": "2211587171",
                    "name": "Yancheng Cao"
                },
                {
                    "authorId": "2211591151",
                    "name": "Qitai Chen"
                },
                {
                    "authorId": "2176147031",
                    "name": "Haole Guo"
                },
                {
                    "authorId": "1996101908",
                    "name": "Jiasi Gao"
                },
                {
                    "authorId": "26889828",
                    "name": "Yiyue Luo"
                },
                {
                    "authorId": "2157301149",
                    "name": "Shihui Guo"
                },
                {
                    "authorId": "2153104630",
                    "name": "Guyue Zhou"
                },
                {
                    "authorId": "2235529",
                    "name": "Jiangtao Gong"
                }
            ]
        },
        {
            "paperId": "1baa0e7f4d84eb571b26dc4f8f31ba9c9df459d2",
            "title": "\"I am the follower, also the boss\": Exploring Different Levels of Autonomy and Machine Forms of Guiding Robots for the Visually Impaired",
            "abstract": "Guiding robots, in the form of canes or cars, have recently been explored to assist blind and low vision (BLV) people. Such robots can provide full or partial autonomy when guiding. However, the pros and cons of different forms and autonomy for guiding robots remain unknown. We sought to fill this gap. We designed autonomy-switchable guiding robotic cane and car. We conducted a controlled lab-study (N=12) and a field study (N=9) on BLV. Results showed that full autonomy received better walking performance and subjective ratings in the controlled study, whereas participants used more partial autonomy in the natural environment as demanding more control. Besides, the car robot has demonstrated abilities to provide a higher sense of safety and navigation efficiency compared with the cane robot. Our findings offered empirical evidence about how the BLV community perceived different machine forms and autonomy, which can inform the design of assistive robots.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "2187938715",
                    "name": "ZiangL Li"
                },
                {
                    "authorId": "2176147031",
                    "name": "Haole Guo"
                },
                {
                    "authorId": "2188233907",
                    "name": "Luyao Wang"
                },
                {
                    "authorId": "2187935139",
                    "name": "Qihe Chen"
                },
                {
                    "authorId": "2116486701",
                    "name": "Wen-Wen Jiang"
                },
                {
                    "authorId": "2204644498",
                    "name": "Mingming Fan"
                },
                {
                    "authorId": "2153104630",
                    "name": "Guyue Zhou"
                },
                {
                    "authorId": "2235529",
                    "name": "Jiangtao Gong"
                }
            ]
        },
        {
            "paperId": "766cff591bf3c16b498218016bea618d21ce34de",
            "title": "Real is Better than Perfect: Sim-to-Real Robotic System in Secondary School Education",
            "abstract": "Simulation systems of robots can facilitate the prediction, development, and debugging of robotic systems. However, they seldom applied in robotics education for primary and secondary school students. In this paper, we present a sim-to-real robotic system that enables students to optimize their algorithms in a simulated environment and validate them in a remote physical laboratory with data logs and remote cameras. Moreover, the system employs an automated submit-test-reset subsystem that minimizes the need for human intervention and provides 24/7 testing support. Experimental data from a trial with 28 students in remote areas show that the sim-to-real robotic experimental environment has comparable learning outcomes to a pure real robot environment and is significantly better than a pure simulation environment. Given the results, we validate that our system can substantially reduce the costs of teaching equipment and space while maintaining high-quality robotics education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1996101908",
                    "name": "Jiasi Gao"
                },
                {
                    "authorId": "2176147031",
                    "name": "Haole Guo"
                },
                {
                    "authorId": "2274204337",
                    "name": "Zhanxiang Cao"
                },
                {
                    "authorId": "2244766594",
                    "name": "Pengfei Huang"
                },
                {
                    "authorId": "2274220469",
                    "name": "Guyue Zhou"
                }
            ]
        },
        {
            "paperId": "c2ebf6d451eb1649a995d355a6c8a120efaedf8f",
            "title": "Brick Yourself within 3 Minutes",
            "abstract": "This paper presents an intelligent machine which can automatically convert the captured portrait into a physical gadget made up of LEGO bricks. On the contrary to synthesising a 2D image or a virtual 3D object, generating physical 3D assembly object needs to take physical properties and assembly process into consideration, leading to more challenges. To generate brick models for arbitrary portraits, we formulate the transformation between the attribute space (extracted from 2D images) and the brick model space as a constraint integer programming problem which can be solved with a heuristic search method. Furthermore, as the bricks are physically scattered, we propose an algorithm to generate corresponding assembly instructions for customized figure-featured-bricks to facilitate users' assembly. Meanwhile, we deploy the proposed algorithms on an automatic machine which integrates a camera, a printer, a laptop, and a brick operation unit. Finally, the generated brick models and assembly instructions are evaluated by a large number of users. It is worth noting that the whole system works as an intelligent vending machine, producing a 150-brick-model within 3 minutes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153104630",
                    "name": "Guyue Zhou"
                },
                {
                    "authorId": "2114163630",
                    "name": "Liyi Luo"
                },
                {
                    "authorId": "2108836507",
                    "name": "Hao Xu"
                },
                {
                    "authorId": "2176479028",
                    "name": "Xinliang Zhang"
                },
                {
                    "authorId": "2176147031",
                    "name": "Haole Guo"
                },
                {
                    "authorId": "2176137981",
                    "name": "Hao Zhao"
                }
            ]
        },
        {
            "paperId": "e5c009ba023c50217abd2793a7a010e064bb30b9",
            "title": "Learning with Yourself: a Tangible Twin Robot System to Promote STEM Education",
            "abstract": "This paper presents a customized programmable robotic system, TanTwin (Tangible Twin), designed to promote STEM education for K-12 children. Firstly, TanTwin is implemented based on a wheel-robot with standard LEGO bricks. With several deep neural networks, a child can convert a captured portrait of himself/herself into standard LEGO bricks, therefore he/she can build a tangible twin robot of him-selflherself automatically. Besides, to adapt to the customized appearance, the corresponding visual element and content of the robotic system were also changed by a rule-based adaption algorithm. To demonstrate the effectiveness of TanTwin and to investigate whether tangible twin robots could contribute to children's learning, we conducted a controlled experimental study to compare learning with a TanTwin and with a standard robot system through measuring students' cognitive learning outcomes. The pre-/post- knowledge test results indicated that learning with a tangible twin robot leads to significantly better learning outcomes. Given the results, we validate our system and customization technology can promote STEM education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1996101908",
                    "name": "Jiasi Gao"
                },
                {
                    "authorId": "2235529",
                    "name": "Jiangtao Gong"
                },
                {
                    "authorId": "2153104630",
                    "name": "Guyue Zhou"
                },
                {
                    "authorId": "2176147031",
                    "name": "Haole Guo"
                },
                {
                    "authorId": "2198399255",
                    "name": "Tong Qi"
                }
            ]
        }
    ]
}