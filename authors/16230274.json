{
    "authorId": "16230274",
    "papers": [
        {
            "paperId": "2c5dfb926795f467cbcd143e73cdeddd1d0fa6f6",
            "title": "Now It Sounds Like You: Learning Personalized Vocabulary On Device",
            "abstract": "In recent years, Federated Learning (FL) has shown significant advancements in its ability to perform various natural language processing (NLP) tasks. This work focuses on applying personalized FL for on-device language modeling. Due to limitations of memory and latency, these models cannot support the complexity of sub-word tokenization or beam search decoding, resulting in the decision to deploy a closed-vocabulary language model. However, closed-vocabulary models are unable to handle out-of-vocabulary (OOV) words belonging to specific users. To address this issue, We propose a novel technique called \"OOV expansion\" that improves OOV coverage and increases model accuracy while minimizing the impact on memory and latency. This method introduces a personalized \"OOV adapter\" that effectively transfers knowledge from a central model and learns word embedding for personalized vocabulary. OOV expansion significantly outperforms standard FL personalization methods on a set of common FL benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "2052661789",
                    "name": "Ashish Shenoy"
                },
                {
                    "authorId": "40060585",
                    "name": "P. Chuang"
                },
                {
                    "authorId": "2131399147",
                    "name": "John Nguyen"
                }
            ]
        },
        {
            "paperId": "16b0573b8a99746bd56c725bbbacab985be58557",
            "title": "AutoDim: Field-aware Embedding Dimension Searchin Recommender Systems",
            "abstract": "Practical large-scale recommender systems usually contain thousands of feature fields from users, items, contextual information, and their interactions. Most of them empirically allocate a unified dimension to all feature fields, which is memory inefficient. Thus it is highly desired to assign various embedding dimensions to different feature fields according to their importance and predictability. Due to the large amounts of feature fields and the nuanced relationship between embedding dimensions with feature distributions and neural network architectures, manually allocating embedding dimensions in practical recommender systems can be challenging. To this end, we propose an AutoML-based framework (AutoDim) in this paper, which can automatically select dimensions for different feature fields in a data-driven fashion. Specifically, we first proposed an end-to-end differentiable framework that can calculate the weights over various dimensions in a soft and continuous manner for feature fields, and an AutoML-based optimization algorithm; then, we derive a hard and discrete embedding component architecture according to the maximal weights and retrain the whole recommender framework. We conduct extensive experiments on benchmark datasets to validate the effectiveness of AutoDim.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2109155757",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "1c2c570b78174522268567d545a91e5e377f3bdd",
            "title": "Deep Natural Language Processing for LinkedIn Search Systems",
            "abstract": "Many search systems work with large amounts of natural language data, e.g., search queries, user profiles and documents, where deep learning based natural language processing techniques (deep NLP) can be of great help. In this paper, we introduce a comprehensive study of applying deep NLP techniques to five representative tasks in search engines. Through the model design and experiments of the five tasks, readers can find answers to three important questions: (1) When is deep NLP helpful/not helpful in search systems? (2) How to address latency challenges? (3) How to ensure model robustness? This work builds on existing efforts of LinkedIn search, and is tested at scale on a commercial search engine. We believe our experiences can provide useful insights for the industry and research communities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109155757",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2109116511",
                    "name": "Xiaowei Liu"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "3315931",
                    "name": "Michaeel Kazi"
                },
                {
                    "authorId": "1887610660",
                    "name": "Zhoutong Fu"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "2117241913",
                    "name": "Jun Jia"
                },
                {
                    "authorId": "2146644146",
                    "name": "Liang Zhang"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "3f5185c4c1901517e35c8c5b685bfa23936a07ee",
            "title": "Towards Understanding the Behaviors of Optimal Deep Active Learning Algorithms",
            "abstract": "Active learning (AL) algorithms may achieve better performance with fewer data because the model guides the data selection process. While many algorithms have been proposed, there is little study on what the optimal AL algorithm looks like, which would help researchers understand where their models fall short and iterate on the design. In this paper, we present a simulated annealing algo-rithm to search for this optimal oracle and analyze it for several tasks. We present qualitative and quantitative insights into the behaviors of this oracle, comparing and contrasting them with those of various heuristics. Moreover, we are able to consistently improve the heuristics using one particular insight. We hope that our \ufb01ndings can better inform future active learning research. The code is available at https://github.com/ YilunZhou/optimal-active-learning .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110339246",
                    "name": "Yilun Zhou"
                },
                {
                    "authorId": "3286437",
                    "name": "Adithya Renduchintala"
                },
                {
                    "authorId": "2121291795",
                    "name": "Xian Li"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "2263803",
                    "name": "Yashar Mehdad"
                },
                {
                    "authorId": "2730123",
                    "name": "Asish Ghoshal"
                }
            ]
        },
        {
            "paperId": "490c03c084eb5ef08d959e6cb1aceb0646d33b17",
            "title": "SILG: The Multi-environment Symbolic Interactive Language Grounding Benchmark",
            "abstract": "Existing work in language grounding typically study single environments. How do we build unified models that apply across multiple environments? We propose the multi-environment Symbolic Interactive Language Grounding benchmark (SILG), which unifies a collection of diverse grounded language learning environments under a common interface. SILG consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). Together, these environments provide diverse grounding challenges in richness of observation space, action space, language specification, and plan complexity. In addition, we propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG. Our shared architecture achieves comparable performance to environment-specific architectures. Moreover, we find that many recent modelling advances do not result in significant gains on environments other than the one they were designed for. This highlights the need for a multi-environment benchmark. Finally, the best models significantly underperform humans on SILG, which suggests ample room for future work. We hope SILG enables the community to quickly identify new methodologies for language grounding that generalize to a diverse set of environments and their associated challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3428769",
                    "name": "Victor Zhong"
                },
                {
                    "authorId": "2133448845",
                    "name": "Austin W. Hanjie"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "144958935",
                    "name": "Karthik Narasimhan"
                },
                {
                    "authorId": "1982950",
                    "name": "Luke Zettlemoyer"
                }
            ]
        },
        {
            "paperId": "b84ddb9ff287aa84df1055e73c5dc058525d1a9a",
            "title": "BitextEdit: Automatic Bitext Editing for Improved Low-Resource Machine Translation",
            "abstract": "Mined bitexts can contain imperfect translations that yield unreliable training signals for Neural Machine Translation (NMT). While filtering such pairs out is known to improve final model quality, we argue that it is suboptimal in low-resource conditions where even mined data can be limited. In our work, we propose instead, to refine the mined bitexts via automatic editing: given a sentence in a language xf, and a possibly imperfect translation of it xe, our model generates a revised version xf' or xe' that yields a more equivalent translation pair (i.e.,or). We use a simple editing strategy by (1) mining potentially imperfect translations for each sentence in a given bitext, (2) learning a model to reconstruct the original translations and translate, in a multi-task fashion. Experiments demonstrate that our approach successfully improves the quality of CCMatrix mined bitext for 5 low-resource language-pairs and 10 translation directions by up to ~ 8 BLEU points, in most cases improving upon a competitive back-translation baseline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40914545",
                    "name": "Eleftheria Briakou"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1982950",
                    "name": "Luke Zettlemoyer"
                },
                {
                    "authorId": "2320509",
                    "name": "Marjan Ghazvininejad"
                }
            ]
        },
        {
            "paperId": "110ef8f751d1abf3f18b10ee90f883f2709f2312",
            "title": "DeText: A Deep Text Ranking Framework with BERT",
            "abstract": "Ranking is the most important component in a search system. Most search systems deal with large amounts of natural language data, hence an effective ranking system requires a deep understanding of text semantics. Recently, deep learning based natural language processing (deep NLP) models have generated promising results on ranking systems. BERT is one of the most successful models that learn contextual embedding, which has been applied to capture complex query-document relations for search ranking. However, this is generally done by exhaustively interacting each query word with each document word, which is inefficient for online serving in search product systems. In this paper, we investigate how to build an efficient BERT-based ranking model for industry use cases. The solution is further extended to a general ranking framework, DeText, that is open sourced and can be applied to various ranking productions. Offline and online experiments of DeText on three real-world search systems present significant improvement over state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2109116511",
                    "name": "Xiaowei Liu"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "145630384",
                    "name": "A. Sankar"
                },
                {
                    "authorId": "2111907175",
                    "name": "Zimeng Yang"
                },
                {
                    "authorId": "2153928779",
                    "name": "Qi Guo"
                },
                {
                    "authorId": "2146644146",
                    "name": "Liang Zhang"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "34252531",
                    "name": "Bee-Chung Chen"
                },
                {
                    "authorId": "2596058",
                    "name": "D. Agarwal"
                }
            ]
        },
        {
            "paperId": "5aef91c95e971782f69bb99a1e28c9545dbafde2",
            "title": "Efficient Neural Query Auto Completion",
            "abstract": "Query Auto Completion (QAC), as the starting point of information retrieval tasks, is critical to user experience. Generally it has two steps: generating completed query candidates according to query prefixes, and ranking them based on extracted features. Three major challenges are observed for a query auto completion system: (1) QAC has a strict online latency requirement. For each keystroke, results must be returned within tens of milliseconds, which poses a significant challenge in designing sophisticated language models for it. (2) For unseen queries, generated candidates are of poor quality as contextual information is not fully utilized. (3) Traditional QAC systems heavily rely on handcrafted features such as the query candidate frequency in search logs, lacking sufficient semantic understanding of the candidate. In this paper, we propose an efficient neural QAC system with effective context modeling to overcome these challenges. On the candidate generation side, this system uses as much information as possible in unseen prefixes to generate relevant candidates, increasing the recall by a large margin. On the candidate ranking side, an unnormalized language model is proposed, which effectively captures deep semantics of queries. This approach presents better ranking performance over state-of-the-art neural ranking methods and reduces ~95% latency compared to neural language modeling methods. The empirical results on public datasets show that our model achieves a good balance between accuracy and efficiency. This system is served in LinkedIn job search with significant product impact observed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "e42f14faa8eaf4537f2eca78dbccc150e7b51a0c",
            "title": "Towards Understanding the Optimal Behaviors of Deep Active Learning Algorithms",
            "abstract": "Active learning (AL) algorithms may achieve better performance with fewer data because the model guides the data selection process. While many algorithms have been proposed, there is little study on what the optimal AL algorithm looks like, which would help researchers understand where their models fall short and iterate on the design. In this paper, we present a simulated annealing algorithm to search for this optimal oracle and analyze it for several different tasks. We present several qualitative and quantitative insights into the optimal behavior and contrast this behavior with those of various heuristics. When augmented by with one particular insight, heuristics perform consistently better. We hope that our findings can better inform future active learning research. The code for the experiments is available at https://github.com/YilunZhou/optimal-active-learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110339246",
                    "name": "Yilun Zhou"
                },
                {
                    "authorId": "3286437",
                    "name": "Adithya Renduchintala"
                },
                {
                    "authorId": "2121291795",
                    "name": "Xian Li"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "2263803",
                    "name": "Yashar Mehdad"
                },
                {
                    "authorId": "2730123",
                    "name": "Asish Ghoshal"
                }
            ]
        },
        {
            "paperId": "ea98c1074a20a6e6d2235f7844f70dfb370d1446",
            "title": "Memory-efficient Embedding for Recommendations",
            "abstract": "Practical large-scale recommender systems usually contain thousands of feature fields from users, items, contextual information, and their interactions. Most of them empirically allocate a unified dimension to all feature fields, which is memory inefficient. Thus it is highly desired to assign different embedding dimensions to different feature fields according to their importance and predictability. Due to the large amounts of feature fields and the nuanced relationship between embedding dimensions with feature distributions and neural network architectures, manually allocating embedding dimensions in practical recommender systems can be very difficult. To this end, we propose an AutoML based framework (AutoDim) in this paper, which can automatically select dimensions for different feature fields in a data-driven fashion. Specifically, we first proposed an end-to-end differentiable framework that can calculate the weights over various dimensions for feature fields in a soft and continuous manner with an AutoML based optimization algorithm; then we derive a hard and discrete embedding component architecture according to the maximal weights and retrain the whole recommender framework. We conduct extensive experiments on benchmark datasets to validate the effectiveness of the AutoDim framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        }
    ]
}