{
    "authorId": "48340247",
    "papers": [
        {
            "paperId": "28336cbf2ee3e8fca6b173c91c5ca9628ba1fa4a",
            "title": "Joint Learning of Deep Retrieval Model and Product Quantization based Embedding Index",
            "abstract": "Embedding index that enables fast approximate nearest neighbor(ANN) search, serves as an indispensable component for state-of-the-art deep retrieval systems. Traditional approaches, often separating the two steps of embedding learning and index building, incur additional indexing time and decayed retrieval accuracy. In this paper, we propose a novel method called Poeem, which stands for product quantization based embedding index jointly trained with deep retrieval model, to unify the two separate steps within an end-to-end training, by utilizing a few techniques including the gradient straight-through estimator, warm start strategy, optimal space decomposition and Givens rotation. Extensive experimental results show that the proposed method not only improves retrieval accuracy significantly but also reduces the indexing time to almost none. We have open sourced our approach for the sake of comparison and reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119078075",
                    "name": "Han Zhang"
                },
                {
                    "authorId": "48340247",
                    "name": "Hongwei Shen"
                },
                {
                    "authorId": "2114967623",
                    "name": "Yiming Qiu"
                },
                {
                    "authorId": "2131218",
                    "name": "Yunjiang Jiang"
                },
                {
                    "authorId": "31093111",
                    "name": "Songlin Wang"
                },
                {
                    "authorId": "1752741172",
                    "name": "Sulong Xu"
                },
                {
                    "authorId": "2122427161",
                    "name": "Yun Xiao"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                },
                {
                    "authorId": "49230310",
                    "name": "Wen-Yun Yang"
                }
            ]
        },
        {
            "paperId": "76e130aae31c0c4e1740986b858f1dde9fbdb846",
            "title": "BERT2DNN: BERT Distillation with Massive Unlabeled Data for Online E-Commerce Search",
            "abstract": "Relevance has significant impact on user experience and business profit for e-commerce search platform. In this work, we propose a data-driven framework for search relevance prediction, by distilling knowledge from BERT and related multi-layer Transformer teacher models into simple feed-forward networks with large amount of unlabeled data. The distillation process produces a student model that recovers more than 97% test accuracy of teacher models on new queries, at a serving cost that's several magnitude lower (latency 150x lower than BERT-Base and 15x lower than the most efficient BERT variant, TinyBERT). The applications of temperature rescaling and teacher model stacking further boost model accuracy, without increasing the student model complexity. We present experimental results on both in-house e-commerce search relevance data as well as a public data set on sentiment analysis from the GLUE benchmark. The latter takes advantage of another related public data set of much larger scale, while disregarding its potentially noisy labels. Embedding analysis and case study on the in-house data further highlight the strength of the resulting model. By making the data processing and model training source code public, we hope the techniques presented here can help reduce energy consumption of the state of the art Transformer models and also level the playing field for small organizations lacking access to cutting edge machine learning hardwares.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131218",
                    "name": "Yunjiang Jiang"
                },
                {
                    "authorId": "2053234459",
                    "name": "Yue Shang"
                },
                {
                    "authorId": "39789747",
                    "name": "Ziyang Liu"
                },
                {
                    "authorId": "48340247",
                    "name": "Hongwei Shen"
                },
                {
                    "authorId": "2122427161",
                    "name": "Yun Xiao"
                },
                {
                    "authorId": "2055448780",
                    "name": "Wei Xiong"
                },
                {
                    "authorId": "1752741172",
                    "name": "Sulong Xu"
                },
                {
                    "authorId": "46704879",
                    "name": "Weipeng P. Yan"
                },
                {
                    "authorId": "2068347799",
                    "name": "Di Jin"
                }
            ]
        },
        {
            "paperId": "d1e748f9521a22411bddca50a3d939f31b4a1ac2",
            "title": "Fine-tune BERT for E-commerce Non-Default Search Ranking",
            "abstract": "The quality of non-default ranking on e-commerce platforms, such as based on ascending item price or descending historical sales volume, often suffers from acute relevance problems, since the irrelevant items are much easier to be exposed at the top of the ranking results. In this work, we propose a two-stage ranking scheme, which first recalls wide range of candidate items through refined query/title keyword matching, and then classifies the recalled items using BERT-Large fine-tuned on human label data. We also implemented parallel prediction on multiple GPU hosts and a C++ tokenization custom op of Tensorflow. In this data challenge, our model won the 1st place in the supervised phase (based on overall F1 score) and 2nd place in the final phase (based on average per query F1 score).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131218",
                    "name": "Yunjiang Jiang"
                },
                {
                    "authorId": "2053234459",
                    "name": "Yue Shang"
                },
                {
                    "authorId": "48340247",
                    "name": "Hongwei Shen"
                },
                {
                    "authorId": "49230310",
                    "name": "Wen-Yun Yang"
                },
                {
                    "authorId": "2122427161",
                    "name": "Yun Xiao"
                }
            ]
        },
        {
            "paperId": "5290f5d63edd10c984ddb0fff1877dd607e79ced",
            "title": "XSEDE-enabled high-throughput lesion activity assessment",
            "abstract": "Caries lesion activity assessment has been a routine diagnostic procedure in dental caries management, traditionally employing subjective measurements incorporating visual and tactile inspections. Recently, advances in 2D/3D image processing and analysis methods and microfocus x-ray computerized tomography (\u03bc-CT) hardware, together with increased power of high performance computing, have created a synergic effect that is revolutionizing many fields in dental computing. In this paper, we report such an XSEDE-enabled high-throughput lesion activity assessment workflow that exploits 2D/3D image processing, visual analytics, and high performance computing technologies. Our paper starts with a brief introduction of the image dataset in our dental studies. We then proceed to a family of 2D image analysis, ROI segmentation, and 3D geometric construction methods. By combining dental imaging technology and 2D/3D image processing algorithms, we transform the task of lesion activity assessment into a 3D-time series analysis of computer generated lesion models. Building on the computational algorithms and implementation models, we develop a high-throughput dental computing workflow exploiting MapReduce tasks to parallelize the image analysis of dental CT scans, the segmentation of region-of-interest (ROI), and the 3D construction of lesion volumes. We showcase the employment of 3D-time series analysis and several other information representations that are applied to our lesion activity assessment scenario focusing on large scale dental image data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153728213",
                    "name": "Hui Zhang"
                },
                {
                    "authorId": "1887868",
                    "name": "M. Boyles"
                },
                {
                    "authorId": "3278692",
                    "name": "Guangchen Ruan"
                },
                {
                    "authorId": "2109121305",
                    "name": "Huian Li"
                },
                {
                    "authorId": "48340247",
                    "name": "Hongwei Shen"
                },
                {
                    "authorId": "2495732",
                    "name": "M. Ando"
                }
            ]
        },
        {
            "paperId": "cb9291ee302ba2ab434cd3a71cfaa2f2ce88f57e",
            "title": "Using the head to stabilize action: Reaching by young children",
            "abstract": "Even seemingly simple reaching task requires complex integration or remapping of reference frames with respect to eye, head and hand. Head-centered reference frame and head movement may play important roles in natural tasks and in the development of reaching. To understand the underlying control mechanism that support smooth reaching in particular and the seamless coordination of head and hand movements more generally, a semi-naturalistic experiment is designed for 1 \u00bd to 5 years old children, in which children are free to reach or not reach for the ball coming out from the slots on the puppet show. The fine-grained head and hand motion data were recorded. The analysis results show that (1) All the children participants stabilize their heads right before the reach; (2) During the reach, the head and hands move synergistically in the similar directions. (3) Large and variable head movements co-occur with more variable and jerky reaches. The coupling of the head and hands may suggest a dynamical integration of multiple reference frames.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48340247",
                    "name": "Hongwei Shen"
                },
                {
                    "authorId": "2280477227",
                    "name": "Thomas J. Baker"
                },
                {
                    "authorId": "2280477843",
                    "name": "T. R. Candy"
                },
                {
                    "authorId": "144136729",
                    "name": "Chen Yu"
                },
                {
                    "authorId": "2266235677",
                    "name": "Linda B Smith"
                }
            ]
        },
        {
            "paperId": "25c8f185368b79dabdb4b15c5874df9b4bb9aa79",
            "title": "Active Information Selection: Visual Attention Through the Hands",
            "abstract": "An important goal in studying both human intelligence and artificial intelligence is to understand how a natural or an artificial learning system deals with the uncertainty and ambiguity of the real world. For a natural intelligence system such as a human toddler, the relevant aspects in a learning environment are only those that make contact with the learner's sensory system. In real-world interactions, what the child perceives critically depends on his own actions as these actions bring information into and out of the learner's sensory field. The present analyses indicate how, in the case of a toddler playing with toys, these perception-action loops may simplify the learning environment by selecting relevant information and filtering irrelevant information. This paper reports new findings using a novel method that seeks to describe the visual learning environment from a young child's point of view and measures the visual information that a child perceives in real-time toy play with a parent. The main results are 1) what the child perceives primarily depends on his own actions but also his social partner's actions; 2) manual actions, in particular, play a critical role in creating visual experiences in which one object dominates; 3) this selecting and filtering of visual objects through the actions of the child provides more constrained and clean input that seems likely to facilitate cognitive learning processes. These findings have broad implications for how one studies and thinks about human and artificial learning systems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "144136729",
                    "name": "Chen Yu"
                },
                {
                    "authorId": "2836466",
                    "name": "Linda B. Smith"
                },
                {
                    "authorId": "48340247",
                    "name": "Hongwei Shen"
                },
                {
                    "authorId": "36452320",
                    "name": "A. Pereira"
                },
                {
                    "authorId": "145032356",
                    "name": "Thomas G. Smith"
                }
            ]
        }
    ]
}