{
    "authorId": "2108217022",
    "papers": [
        {
            "paperId": "13df472c3fe81bf1b615238fbd7884c8b45d8d1c",
            "title": "Large Language Models for Time Series: A Survey",
            "abstract": "Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs' original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) aligning techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey offers a comprehensive overview of the existing multimodal time series and text datasets in diverse domains, and discusses the challenges and future opportunities of this emerging field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "3adbca134ac20e69d7215537c703db9faf483b35",
            "title": "Towards Diverse and Coherent Augmentation for Time-Series Forecasting",
            "abstract": "Time-series data augmentation mitigates the issue of insufficient training data for deep learning models. Yet, existing augmentation methods are mainly designed for classification, where class labels can be preserved even if augmentation alters the temporal dynamics. We note that augmentation designed for forecasting requires diversity as well as coherence with the original temporal dynamics. As time-series data generated by real-life physical processes exhibit characteristics in both the time and frequency domains, we propose to combine Spectral and Time Augmentation (STAug) for generating more diverse and coherent samples. Specifically, in the frequency domain, we use the Empirical Mode Decomposition to decompose a time series and reassemble the subcomponents with random weights. This way, we generate diverse samples while being coherent with the original temporal relationships as they contain the same set of base components. In the time domain, we adapt a mix-up strategy that generates diverse as well as linearly in-between coherent samples. Experiments on five real-world time-series datasets demonstrate that STAug outperforms the base models without data augmentation as well as state-of-the-art augmentation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "4c8110f35426d73be2d315c49e2e912d31a27b64",
            "title": "Async-HFL: Efficient and Robust Asynchronous Federated Learning in Hierarchical IoT Networks",
            "abstract": "Federated Learning (FL) has gained increasing interest in recent years as a distributed on-device learning paradigm. However, multiple challenges remain to be addressed for deploying FL in real-world Internet-of-Things (IoT) networks with hierarchies. Although existing works have proposed various approaches to account data heterogeneity, system heterogeneity, unexpected stragglers and scalibility, none of them provides a systematic solution to address all of the challenges in a hierarchical and unreliable IoT network. In this paper, we propose an asynchronous and hierarchical framework (Async-HFL) for performing FL in a common three-tier IoT network architecture. In response to the largely varied networking and system processing delays, Async-HFL employs asynchronous aggregations at both the gateway and cloud levels thus avoids long waiting time. To fully unleash the potential of Async-HFL in converging speed under system heterogeneities and stragglers, we design device selection at the gateway level and device-gateway association at the cloud level. Device selection module chooses diverse and fast edge devices to trigger local training in real-time while device-gateway association module determines the efficient network topology periodically after several cloud epochs, with both modules satisfying bandwidth limitations. We evaluate Async-HFL\u2019s convergence speedup using large-scale simulations based on ns-3 and a network topology from NYCMesh. Our results show that Async-HFL converges 1.08-1.31x faster in wall-clock time and saves up to 21.6% total communication cost compared to state-of-the-art asynchronous FL algorithms (with client selection). We further validate Async-HFL on a physical deployment and observe its robust convergence under unexpected stragglers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48678005",
                    "name": "Xiaofan Yu"
                },
                {
                    "authorId": "145722522",
                    "name": "L. Cherkasova"
                },
                {
                    "authorId": "40188930",
                    "name": "Hars Vardhan"
                },
                {
                    "authorId": "2110591374",
                    "name": "Quanling Zhao"
                },
                {
                    "authorId": "2168026621",
                    "name": "Emily Ekaireb"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "143764713",
                    "name": "A. Mazumdar"
                },
                {
                    "authorId": "1728828",
                    "name": "T. Rosing"
                }
            ]
        },
        {
            "paperId": "681f05c1952ce3e1dc48a4ceb230a6033092be68",
            "title": "Unleashing the Power of Shared Label Structures for Human Activity Recognition",
            "abstract": "Current human activity recognition (HAR) techniques regard activity labels as integer class IDs without explicitly modeling the semantics of class labels. We observe that different activity names often have shared structures. For example, \"open door\" and \"open fridge\" both have \"open\" as the action; \"kicking soccer ball\" and \"playing tennis ball\" both have \"ball\" as the object. Such shared structures in label names can be translated to the similarity in sensory data and modeling common structures would help uncover knowledge across different activities, especially for activities with limited samples. In this paper, we propose SHARE, a HAR framework that takes into account shared structures of label names for different activities. To exploit the shared structures, SHARE comprises an encoder for extracting features from input sensory time series and a decoder for generating label names as a token sequence. We also propose three label augmentation techniques to help the model more effectively capture semantic structures across activities, including a basic token-level augmentation, and two enhanced embedding-level and sequence-level augmentations utilizing the capabilities of pre-trained models. SHARE outperforms state-of-the-art HAR models in extensive experiments on seven HAR benchmark datasets. We also evaluate in few-shot learning and label imbalance settings and observe even more significant performance gap.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "70e5e9bd353d1b1e54b4eebd3a67b58026a13dff",
            "title": "PrimeNet: Pre-training for Irregular Multivariate Time Series",
            "abstract": "Real-world applications often involve irregular time series, for which the time intervals between successive observations are non-uniform. Irregularity across multiple features in a multi-variate time series further results in a different subset of features at any given time (i.e., asynchronicity). Existing pre-training schemes for time-series, however, often assume regularity of time series and make no special treatment of irregularity. We argue that such irregularity offers insight about domain property of the data\u2014for example, frequency of hospital visits may signal patient health condition\u2014that can guide representation learning. In this work, we propose PrimeNet to learn a self-supervised representation for irregular multivariate time-series. Specifically, we design a time sensitive contrastive learning and data reconstruction task to pre-train a model. Irregular time-series exhibits considerable variations in sampling density over time. Hence, our triplet generation strategy follows the density of the original data points, preserving its native irregularity. Moreover, the sampling density variation over time makes data reconstruction difficult for different regions. Therefore, we design a data masking technique that always masks a constant time duration to accommodate reconstruction for regions of different sampling density. We learn with these tasks using unlabeled data to build a pre-trained model and fine-tune on a downstream task with limited labeled data, in contrast with existing fully supervised approach for irregular time-series, requiring large amounts of labeled data. Experiment results show that PrimeNet significantly outperforms state-of-the-art methods on naturally irregular and asynchronous data from Healthcare and IoT applications for several downstream tasks, including classification, interpolation, and regression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "97483167",
                    "name": "Jiacheng Li"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "9d697c46e6fa79f4c3a283c7539cb58f8cd5e2e8",
            "title": "Federated Learning with Client-Exclusive Classes",
            "abstract": "Existing federated classification algorithms typically assume the local annotations at every client cover the same set of classes. In this paper, we aim to lift such an assumption and focus on a more general yet practical non-IID setting where every client can work on non-identical and even disjoint sets of classes (i.e., client-exclusive classes ), and the clients have a common goal which is to build a global classification model to identify the union of these classes. Such heterogeneity in client class sets poses a new challenge: how to ensure different clients are operating in the same latent space so as to avoid the drift after aggregation? We observe that the classes can be described in natural languages (i.e., class names) and these names are typically safe to share with all parties. Thus, we formulate the classification problem as a matching process between data representations and class representations and break the classification model into a data encoder and a label encoder. We leverage the natural-language class names as the common ground to anchor the class representations in the label encoder. In each iteration, the label encoder updates the class representations and regulates the data representations through matching. We further use the updated class representations at each round to annotate data samples for locally-unaware classes according to similarity and distill knowledge to local models. Extensive experiments on four real-world datasets show that the proposed method can outperform various classical and state-of-the-art federated learning methods designed for learning with non-IID data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108130022",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "b26182a81185552efaaec9e79579b333901410bd",
            "title": "Navigating Alignment for Non-identical Client Class Sets: A Label Name-Anchored Federated Learning Framework",
            "abstract": "Traditional federated classification methods, even those designed for non-IID clients, assume that each client annotates its local data with respect to the same universal class set. In this paper, we focus on a more general yet practical setting, non-identical client class sets, where clients focus on their own (different or even non-overlapping) class sets and seek a global model that works for the union of these classes. If one views classification as finding the best match between representations produced by data/label encoder, such heterogeneity in client class sets poses a new significant challenge-local encoders at different clients may operate in different and even independent latent spaces, making it hard to aggregate at the server. We propose a novel framework, FedAlign1, to align the latent spaces across clients from both label and data perspectives. From a label perspective, we leverage the expressive natural language class names as a common ground for label encoders to anchor class representations and guide the data encoder learning across clients. From a data perspective, during local training, we regard the global class representations as anchors and leverage the data points that are close/far enough to the anchors of locally-unaware classes to align the data encoders across clients. Our theoretical analysis of the generalization performance and extensive experiments on four real-world datasets of different tasks confirm that FedAlign outperforms various state-of-the-art (non-IID) federated classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "c26c4bbac1170f7e7fb7c4298c384c859098f71f",
            "title": "Physics-Informed Data Denoising for Real-Life Sensing Systems",
            "abstract": "Sensors measuring real-life physical processes are ubiquitous in today's interconnected world. These sensors inherently bear noise that often adversely affects the performance and reliability of the systems they support. Classic filtering approaches introduce strong assumption on the time or frequency characteristics of sensory measurements, while learning-based denoising approaches typically rely on using ground truth clean data to train a denoising model, which is often challenging or prohibitive to obtain for many real-world applications. We observe that in many scenarios, the relationships between different sensor measurements (e.g., location and acceleration) are analytically described by laws of physics (e.g., second-order differential equation). By incorporating such physics constraints, we can guide the denoising process to improve performance even in the absence of ground truth data. In light of this, we design a physics-informed denoising model that leverages the inherent algebraic relationships between different measurements governed by the underlying physics. By obviating the need for ground truth clean data, our method offers a practical denoising solution for real-world applications. We conducted experiments in various domains, including inertial navigation, CO2 monitoring, and HVAC control, and achieved state-of-the-art performance compared with existing denoising methods. Our method can denoise data in real time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results that closely align with those from high-precision, high-cost alternatives, leading to an efficient, cost-effective approach for more accurate sensor-based systems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2265354336",
                    "name": "Xiaohan Fu"
                },
                {
                    "authorId": "2266398673",
                    "name": "Diyan Teng"
                },
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "2266420695",
                    "name": "Keerthivasan Vijayakumar"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266424978",
                    "name": "Junsheng Han"
                },
                {
                    "authorId": "2266398035",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2266398313",
                    "name": "Rashmi Kulkarni"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                }
            ]
        },
        {
            "paperId": "1a876b4f5c1be5c1471119dbb7fc4f7f13a57d53",
            "title": "ESC-GAN: Extending Spatial Coverage of Physical Sensors",
            "abstract": "Scientific discoveries and studies about our physical world have long benefited from large-scale and planetary sensing, from weather forecasting to wildfire monitoring. However, the limited deployment of sensors in the environment due to cost or physical access constraints has lagged behind our ever-growing need for increased data coverage and higher resolution, impeding timely and precise monitoring and understanding of the environment. Therefore, we seek to extend the spatial coverage of analysis based on existing sensory data, that is, to \"generate\" data for locations where no historical data exists. This problem is fundamentally different and more challenging than the traditional spatio-temporal imputation that assumes data for any particular location are only partially missing across time. Inspired by the success of Generative Adversarial Network (GAN) in imputation, we propose a novel ESC-GAN. We observe that there are local patterns in nearby locations, as well as trends in a global manner (e.g., temperature drops as altitude increases regardless of the location). As local patterns may exhibit at different scales (from meters to kilometers), we employ a multi-branch generator to aggregate information of different granularity. More specifically, each branch in the generator contains 1) randomly masked 3D partial convolutions at different resolutions to capture the local patterns and 2) global attention modules for global similarity. Next, we adversarially train a 3D convolution-based discriminator to distinguish the generator's output from the ground truth. Extensive experiments on three geo-sensor datasets demonstrate that ESC-GAN outperforms state-of-the-art methods on extending spatial coverage and also achieves the best results on a traditional spatio-temporal imputation task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2057080004",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        },
        {
            "paperId": "3848daf38c39983650a3f6ecb4ccd11dbfab757a",
            "title": "TARNet: Task-Aware Reconstruction for Time-Series Transformer",
            "abstract": "Time-series data contains temporal order information that can guide representation learning for predictive end tasks (e.g., classification, regression). Recently, there are some attempts to leverage such order information to first pre-train time-series models by reconstructing time-series values of randomly masked time segments, followed by an end-task fine-tuning on the same dataset, demonstrating improved end-task performance. However, this learning paradigm decouples data reconstruction from the end task. We argue that the representations learnt in this way are not informed by the end task and may, therefore, be sub-optimal for the end-task performance. In fact, the importance of different timestamps can vary significantly in different end tasks. We believe that representations learnt by reconstructing important timestamps would be a better strategy for improving end-task performance. In this work, we propose TARNet, Task-Aware Reconstruction Network, a new model using Transformers to learn task-aware data reconstruction that augments end-task performance. Specifically, we design a data-driven masking strategy that uses self-attention score distribution from end-task training to sample timestamps deemed important by the end task. Then, we mask out data at those timestamps and reconstruct them, thereby making the reconstruction task-aware. This reconstruction task is trained alternately with the end task at every epoch, sharing parameters in a single model, allowing the representation learnt through reconstruction to improve end-task performance. Extensive experiments on tens of classification and regression datasets show that TARNet significantly outperforms state-of-the-art baseline models across all evaluation metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                }
            ]
        }
    ]
}