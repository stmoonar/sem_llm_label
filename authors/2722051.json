{
    "authorId": "2722051",
    "papers": [
        {
            "paperId": "51de1825e0609f03503db76e3267e5a8eaad01d5",
            "title": "Predicting Shifting Individuals Using Text Mining and Graph Machine Learning on Twitter",
            "abstract": "The formation of majorities in public discussions often depends on individuals who shift their opinion over time. The detection and characterization of these type of individuals is therefore extremely important for political analysis of social networks. In this paper, we study changes in individual's affiliations on Twitter using natural language processing techniques and graph machine learning algorithms. In particular, we collected 9 million Twitter messages from 1.5 million users and constructed the retweet networks. We identified communities with explicit political orientation and topics of discussion associated to them which provide the topological representation of the political map on Twitter in the analyzed periods. With that data, we present a machine learning framework for social media users classification which efficiently detects \"shifting users\" (i.e. users that may change their affiliation over time). Moreover, this machine learning framework allows us to identify not only which topics are more persuasive (using low dimensional topic embedding), but also which individuals are more likely to change their affiliation given their topological properties in a Twitter graph.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65935125",
                    "name": "F. Albanese"
                },
                {
                    "authorId": "48512660",
                    "name": "Leandro Lombardi"
                },
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "2471809",
                    "name": "P. Balenzuela"
                }
            ]
        },
        {
            "paperId": "8543504f276bc8128c6849a0ad514d759d6e5db5",
            "title": "Breaking the Communities: Characterizing community changing users using text mining and graph machine learning on Twitter",
            "abstract": "Even though the Internet and social media have increased the amount of news and information people can consume, most users are only exposed to content that reinforces their positions and isolates them from other ideological communities. This environment has real consequences with great impact on our lives like severe political polarization, easy spread of fake news, political extremism, hate groups and the lack of enriching debates, among others. Therefore, encouraging conversations between different groups of users and breaking the closed community is of importance for healthy societies. In this paper, we characterize and study users who break their community on Twitter using natural language processing techniques and graph machine learning algorithms. In particular, we collected 9 million Twitter messages from 1.5 million users and constructed the retweet networks. We identified their communities and topics of discussion associated to them. With this data, we present a machine learning framework for social media users classification which detects\"community breakers\", i.e. users that swing from their closed community to another one. A feature importance analysis in three Twitter polarized political datasets showed that these users have low values of PageRank, suggesting that changes are driven because their messages have no response in their communities. This methodology also allowed us to identify their specific topics of interest, providing a fully characterization of this kind of users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65935125",
                    "name": "F. Albanese"
                },
                {
                    "authorId": "48512660",
                    "name": "Leandro Lombardi"
                },
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "2471809",
                    "name": "P. Balenzuela"
                }
            ]
        },
        {
            "paperId": "b9bd125a5f1ed39026075dbfd6d6c4ed88ded8ee",
            "title": "New algorithms for composite retrieval",
            "abstract": "Internet users constantly make searches to find objects or results of their interest, generally through terms or phrases. Traditional search offers only solutions that take into account just the individual characteristics of the results, and not the relations they have with the rest of the universe. Typically, we are given an ordered list of the results related to the search criterion, which implies the need of changing several times the terms of the query to get to a solution that is more adequate to the intended search goal. As a solution to this problem, Composite Retrieval proposes that the results to a query may be grouped in sets of items (bundles), related through some similarity criterion, but at the same time are complementary. In this work we propose heuristic algorithms for Composite Retrieval which are evaluated experimentally, showing performance improvements over the previous results presented in the literature.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "1412371531",
                    "name": "J. A. Knebel"
                },
                {
                    "authorId": "1398937781",
                    "name": "I. M\u00e9ndez-D\u00edaz"
                },
                {
                    "authorId": "2065132412",
                    "name": "Amit Stein"
                },
                {
                    "authorId": "144535064",
                    "name": "Paula Zabala"
                }
            ]
        },
        {
            "paperId": "4285f0d9b36510a94383a257845846643082e2ea",
            "title": "Using Big Data Analysis to Improve Cache Performance in Search Engines",
            "abstract": "Web Search Engines process huge amounts of data to sup- port search but must run under strong performance requirements (to answer a query in a fraction of a second). To meet that performance they implement dierent optimization techniques such as caching, that may be implemented at several levels. One of these caching levels is the intersection cache, that attempts to exploit frequently occurring pairs of terms by keeping in the memory of the search node the results of in- tersecting the corresponding inverted lists. In this work we propose an optimization step to decide which items should be cached and which not by introducing the usage of data mining techniques. Our preliminary re- sults show that it is possible to achieve extra cost savings in this already hyper-optimized eld.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2084744929",
                    "name": "Gabriel Tolosa"
                },
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                }
            ]
        },
        {
            "paperId": "6f6ee28dfb1ba341dd2b74b5bdcd276357182bab",
            "title": "Composite Retrieval of Diverse and Complementary Bundles",
            "abstract": "Users are often faced with the problem of finding complementary items that together achieve a single common goal (e.g., a starter kit for a novice astronomer, a collection of question/answers related to low-carb nutrition, a set of places to visit on holidays). In this paper, we argue that for some application scenarios returning item bundles is more appropriate than ranked lists. Thus we define composite retrieval as the problem of finding k bundles of complementary items. Beyond complementarity of items, the bundles must be valid w.r.t. a given budget, and the answer set of k bundles must exhibit diversity. We formally define the problem and show that in its general form is NP-hard and that also the special cases in which each bundle is formed by only one item, or only one bundle is sought, are hard. Our characterization however suggests how to adopt a two-phase approach (Produce-and-Choose, or PAC) in which we first produce many valid bundles, and then we choose k among them. For the first phase we devise two ad-hoc clustering algorithms, while for the second phase we adapt heuristics with approximation guarantees for a related problem. We also devise another approach which is based on first finding a k-clustering and then selecting a valid bundle from each of the produced clusters (Cluster-and-Pick, or CAP). We compare experimentally the proposed methods on two real-world data sets: the first data set is given by a sample of touristic attractions in 10 large European cities, while the second is a large database of user-generated restaurant reviews from Yahoo! Local. Our experiments show that when diversity is highly important, CAP is the best option, while when diversity is less important, a PAC approach constructing bundles around randomly chosen pivots, is better.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1705764",
                    "name": "F. Bonchi"
                },
                {
                    "authorId": "153191671",
                    "name": "Carlos Castillo"
                },
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "1398937781",
                    "name": "I. M\u00e9ndez-D\u00edaz"
                },
                {
                    "authorId": "144535064",
                    "name": "Paula Zabala"
                }
            ]
        },
        {
            "paperId": "8b1799915a68b0e504224fca5fd5a21746ebc61c",
            "title": "Cost-aware Intersection Caching and Processing Strategies for In-memory Inverted Indexes",
            "abstract": "We propose and experimentally evaluate several combinations of cost-aware intersection caching policies and evaluation strategies for intersection queries for in-memory inverted indexes We show that some of the combinations can lead to signicative improvements in the performance at the search-node level. Dynamic policies are better than the others achieving on average a 30% time reduction compared with the best hybrid policy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "2084744929",
                    "name": "Gabriel Tolosa"
                }
            ]
        },
        {
            "paperId": "0df446cd02376afcaaa3fe29083dedec70705218",
            "title": "Service Deployment Algorithms for Vertical Search Engines",
            "abstract": "Web search engines are systems devised to cope with highly dynamic and demanding query rates. These systems are composed by several services, each one dedicated to execute a single operation required to solve a query. Services are allocated into thousand of multi-core processors organized in racks. Some services communicate more than others, so it is desirable to put them in the same rack. In this work, we present and evaluate deployment algorithms for a web search engine. In particular, we focus on vertical search engines with specific on-line content which may include shopping, advertisement, etc.. Our goal is to improve the performance of a search engine by reducing communication time. Communication among services is performed by means of a fast and complex network supporting parallel sending and receiving of messages. We propose a communication-graph-based method, in which processors are the nodes of the graph and communication between them is represented as weighted arcs. Results show that our proposal method is able to reduce maximum query response time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1406782075",
                    "name": "V. Gil-Costa"
                },
                {
                    "authorId": "1403898522",
                    "name": "Alonso Inostrosa-Psijas"
                },
                {
                    "authorId": "145246605",
                    "name": "Mauricio Mar\u00edn"
                },
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                }
            ]
        },
        {
            "paperId": "6bc50f0a2ab42047309e82f142e64a196bf39c55",
            "title": "Analysis of Cost-Aware Policies for Intersection Caching in Search Nodes",
            "abstract": "We propose static, dynamic and hybrid cost-awarepolicies for intersection caching and we introduce three different strategies to solve a query computing list intersections. We run experiments over a simulation framework using real data for both document collection and text queries. We observe that: a) cost-aware policies outperform cost-oblivious policies, b) static policies are better than dynamic policies (as in posting list caching), c) hybrid policies outperform the previous ones achieving up to 29% of cost savings and d) computing strategies that try to maximize cache usage have a better performance than the a-priori most efficient ones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "2084744929",
                    "name": "Gabriel Tolosa"
                }
            ]
        },
        {
            "paperId": "92aec6fa5754b503b53158ff304cdcd6ce1c7792",
            "title": "Complexity and algorithms for composite retrieval",
            "abstract": "Online search has become a daily activity and a source of a variety of valuable information, from the finest granularity such as finding the address of a specific restaurant, to more complex tasks like looking for accessories compatible with an iPhone or planning a trip. The latter typically involves running multiple search queries to gather information about different places, reading online reviews to find out about hotels, and checking geographic proximity of places to visit. We refer to this information seeking activity as composite retrieval and propose to organize results into item bundles that together constitute an improved exploratory experience over ranked lists. As a first step towards composite retrieval definition, we need to formalize intuitive desirable properties of item bundles. We distinguish between properties of each bundle in the answer and properties of the answer as a whole. Consider the case of a user selecting the restaurants to try during a visit to a new city. The user has a limited budget which might be either financial, or simply the number of nights spent in the city. The user prefers suggested restaurants to serve different cuisines. The validity of a bundle of restaurants is given by the budget constraint and the complementarity of the restaurants in the bundle w.r.t. the cuisine they serve. Other restaurant attributes could be used for defining valid bundles. For example, instead of cuisines, different dress codes could be required to every restaurant in a single bundle. Moreover, in order to provide meaningful bundles, restaurants forming each bundle must be compatible, e.g., close geographically, or liked by similar reviewers. The degree of compatibility of the items forming a bundle defines the quality of the bundle. Intuitively, in the case geographic distance is used, the closer restaurants are from each other, the higher the quality of the bundle they belong to. Similarly, when common reviewers are used as the",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1705764",
                    "name": "F. Bonchi"
                },
                {
                    "authorId": "153191671",
                    "name": "Carlos Castillo"
                },
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "1398937781",
                    "name": "I. M\u00e9ndez-D\u00edaz"
                },
                {
                    "authorId": "144535064",
                    "name": "Paula Zabala"
                }
            ]
        },
        {
            "paperId": "58b415fab1bc0b0faf5eb5faf29d44e37c1206f8",
            "title": "Truthful Stochastic and Deterministic Auctions for Sponsored Search",
            "abstract": "Incentive compatibility is a central concept in auction theory, and a desirable property of auction mechanisms. In a celebrated result, Aggarwal, Goel and Motwani presented the first truthful deterministic auction for sponsored search (i.e., in a setting where multiple distinct slots are auctioned). Stochastic auctions present several advantages over deterministic ones, as they are less prone to strategic bidding, and increase the diversity of the winning bidders. Meek, Chickering and Wilson presented a family of truthful stochastic auctions for multiple identical items. We present the first class of incentive compatible stochastic auctions for the sponsored search setting. This class subsumes as special cases the laddered auctions and the stochastic auctions with the condex pricing rule, consolidating these two seemingly disconnected mechanisms in a single framework. Moreover, when the price per click depends deterministic ally on the bids the auctions in this class are unique. Accordingly, we give a precise characterization of all truthful auctions for sponsored search, in terms of the expected price that each bidder will pay per click. We also introduce randomized algorithms and pricing rules to derive, given an allocation mechanism for the single- or multiple-identical-slots scenarios, a new mechanism for the multislot framework with distinct slots. These extensions have direct practical applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "3329662",
                    "name": "P. Heiber"
                },
                {
                    "authorId": "2540242",
                    "name": "Marcelo Mydlarz"
                }
            ]
        },
        {
            "paperId": "40c403468cdfd6f2d3271f2532a320b90ae26d10",
            "title": "New Stochastic Algorithms for Scheduling Ads in Sponsored Search",
            "abstract": "We introduce a family of algorithms for the selection of ads in sponsored search that intends to increase the variety of choices, while not significantly reducing revenue and maintaining an incentive for advertisers to keep their bids as high as possible. Diversification of ads may be convenient for many reasons, which we also expose. Our algorithms try to distribute the available slots among all ads, using a proportional mechanism based on the bids and the expected click-through rates of the ads. Although in our experiments we used a simple first-price auction, our algorithms are compatible with strictly incentive-compatible auctions and pricing mechanisms. We have analyzed the performance of our algorithms in two different scenarios: assuming a static intrinsic click-through rate associated to each ad and in the more general case in which those rates may vary dynamically with time. Our main result is an algorithm that performs reasonably well in terms of revenue as the traditionally used, while notably increasing the diversification. In some scenarios, our newly introduced algorithms even outperform the traditional ones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2722051",
                    "name": "E. Feuerstein"
                },
                {
                    "authorId": "3329662",
                    "name": "P. Heiber"
                },
                {
                    "authorId": "1408210896",
                    "name": "Javier Mart\u00ednez-Viademonte"
                },
                {
                    "authorId": "1398035522",
                    "name": "Ricardo Baeza-Yates"
                }
            ]
        }
    ]
}