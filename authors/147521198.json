{
    "authorId": "147521198",
    "papers": [
        {
            "paperId": "1b3142ee576017e5aa34aac94c658f948b75dbcd",
            "title": "Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers",
            "abstract": "Algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. Contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the performance of classifiers across all groups (with increased degradation on the best performing groups). Extending the bias-variance decomposition for classification to fairness, we theoretically explain why the majority of fairness methods designed for low capacity models should not be used in settings involving high-capacity models, a scenario common to computer vision. We corroborate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. Building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52306341",
                    "name": "Dominik Zietlow"
                },
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "47231927",
                    "name": "Guha Balakrishnan"
                },
                {
                    "authorId": "2871632",
                    "name": "Matth\u00e4us Kleindessner"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "1707625",
                    "name": "B. Scholkopf"
                },
                {
                    "authorId": "145485799",
                    "name": "Chris Russell"
                }
            ]
        },
        {
            "paperId": "74270eb578c75d5bdd9c89b047c9f211bd7e15be",
            "title": "Are Two Heads the Same as One? Identifying Disparate Treatment in Fair Neural Networks",
            "abstract": "We show that deep networks trained to satisfy demographic parity often do so through a form of race or gender awareness, and that the more we force a network to be fair, the more accurately we can recover race or gender from the internal state of the network. Based on this observation, we investigate an alternative fairness approach: we add a second classification head to the network to explicitly predict the protected attribute (such as race or gender) alongside the original task. After training the two-headed network, we enforce demographic parity by merging the two heads, creating a network with the same architecture as the original network. We establish a close relationship between existing approaches and our approach by showing (1) that the decisions of a fair classifier are well-approximated by our approach, and (2) that an unfair and optimally accurate classifier can be recovered from a fair classifier and our second head predicting the protected attribute. We use our explicit formulation to argue that the existing fairness approaches, just as ours, demonstrate disparate treatment and that they are likely to be unlawful in a wide range of scenarios under US law.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "2871632",
                    "name": "Matth\u00e4us Kleindessner"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                },
                {
                    "authorId": "9557137",
                    "name": "Francesco Locatello"
                },
                {
                    "authorId": "2052380526",
                    "name": "Chris Russell"
                }
            ]
        },
        {
            "paperId": "dce01c01fa0c46c12ad59672b2d717b1c2bf0197",
            "title": "Too Relaxed to Be Fair",
            "abstract": "The problem of learning fair classi\ufb01ers has mainly been addressed in three ways. First, pre-processing approaches alter We address the problem of classi\ufb01cation under the labels of the examples or their representation to increase fairness constraints. Given a notion of fairness, the intrinsic fairness of a dataset. A classi\ufb01er learned on the goal is to learn a classi\ufb01er that is not discrimi-this modi\ufb01ed data is then more likely to be fair (Feldman natory against a group of individuals. In the liter-et al., 2015; Calmon et al., 2017; Kamiran & Calders, 2012; ature, this problem is often formulated as a con-Dwork et al., 2012; Zemel et al., 2013). Second, post-hoc strained optimization problem and solved using procedures transform existing accurate but unfair classi\ufb01ers relaxations of the fairness constraints. We show into fair classi\ufb01ers (Chzhen et al., 2019; Hardt et al., 2016; that many existing relaxations are unsatisfactory: Woodworth et al., 2017; Kamiran et al., 2010). Finally, di-even if a model satis\ufb01es the relaxed constraint, it rect methods learn a fair and accurate classi\ufb01er in a single can be surprisingly unfair. We propose a princi-step (Kamishima et al., 2012; Zafar et al., 2017b;a; Calders pled framework to solve this problem. This new & Verwer, 2010; Wu et al., 2019; Donini et al., 2018; Cotter approach uses a strongly convex formulation and et al., 2019; Agarwal et al., 2018; Goh et al., 2016). In this comes with theoretical guarantees on the fairness paper, we focus on the latter kind of approaches. of its solution. In practice, we show that this method gives promising results on real data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "32361369",
                    "name": "Micha\u00ebl Perrot"
                },
                {
                    "authorId": "1728654",
                    "name": "U. V. Luxburg"
                }
            ]
        },
        {
            "paperId": "15bc3f1878895709a96cb2b3ab82b0f7d9342cfc",
            "title": "Insights into Ordinal Embedding Algorithms: A Systematic Evaluation",
            "abstract": "The objective of ordinal embedding is to find a Euclidean representation of a set of abstract items, using only answers to triplet comparisons of the form \"Is item $i$ closer to the item $j$ or item $k$?\". In recent years, numerous algorithms have been proposed to solve this problem. However, there does not exist a fair and thorough assessment of these embedding methods and therefore several key questions remain unanswered: Which algorithms scale better with increasing sample size or dimension? Which ones perform better when the embedding dimension is small or few triplet comparisons are available? In our paper, we address these questions and provide the first comprehensive and systematic empirical evaluation of existing algorithms as well as a new neural network approach. In the large triplet regime, we find that simple, relatively unknown, non-convex methods consistently outperform all other algorithms, including elaborate approaches based on neural networks or landmark approaches. This finding can be explained by our insight that many of the non-convex optimization approaches do not suffer from local optima. In the low triplet regime, our neural network approach is either competitive or significantly outperforms all the other methods. Our comprehensive assessment is enabled by our unified library of popular embedding algorithms that leverages GPU resources and allows for fast and accurate embeddings of millions of data points.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3454807",
                    "name": "L. C. Vankadara"
                },
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "1845169",
                    "name": "Siavash Haghiri"
                },
                {
                    "authorId": "3454634",
                    "name": "Faiz Ul Wahab"
                },
                {
                    "authorId": "1728654",
                    "name": "U. V. Luxburg"
                }
            ]
        },
        {
            "paperId": "fd2b966cf7ca51df4fcdcab0fd80d304e71bc2aa",
            "title": "Uncertainty Estimates for Ordinal Embeddings",
            "abstract": "To investigate objects without a describable notion of distance, one can gather ordinal information by asking triplet comparisons of the form \"Is object $x$ closer to $y$ or is $x$ closer to $z$?\" In order to learn from such data, the objects are typically embedded in a Euclidean space while satisfying as many triplet comparisons as possible. In this paper, we introduce empirical uncertainty estimates for standard embedding algorithms when few noisy triplets are available, using a bootstrap and a Bayesian approach. In particular, simulations show that these estimates are well calibrated and can serve to select embedding parameters or to quantify uncertainty in scientific applications.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "147521198",
                    "name": "Michael Lohaus"
                },
                {
                    "authorId": "2517795",
                    "name": "Philipp Hennig"
                },
                {
                    "authorId": "1728654",
                    "name": "U. V. Luxburg"
                }
            ]
        }
    ]
}