{
    "authorId": "1384550891",
    "papers": [
        {
            "paperId": "06396c7cd5d223a1776abf8811359ec7bc05d420",
            "title": "Knowledge-Augmented Methods for Natural Language Processing",
            "abstract": "Knowledge in natural language processing (NLP) has been a rising trend especially after the advent of large scale pre-trained models. NLP models with attention to knowledge can i) access unlimited amount of external information; ii) delegate the task of storing knowledge from its parameter space to knowledge sources; iii) obtain up-to-date information; iv) make prediction results more explainable via selected knowledge. In this tutorial, we will introduce the key steps in integrating knowledge into NLP, including knowledge grounding from text, knowledge representation and fusing. In addition, we will introduce recent state-of-the-art applications in fusing knowledge into language understanding, language generation and commonsense reasoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1456009348",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "51583409",
                    "name": "Bill Yuchen Lin"
                },
                {
                    "authorId": "144812586",
                    "name": "Meng Jiang"
                },
                {
                    "authorId": "70461341",
                    "name": "Wenhao Yu"
                }
            ]
        },
        {
            "paperId": "17b4028bafc6d92a3a1702afecb023bfb798ba3b",
            "title": "Estimating Large Language Model Capabilities without Labeled Test Data",
            "abstract": "Large Language Models (LLMs) have the impressive ability to perform in-context learning (ICL) from only a few examples, but the success of ICL varies widely from task to task. Thus, it is important to quickly determine whether ICL is applicable to a new task, but directly evaluating ICL accuracy can be expensive in situations where test data is expensive to annotate -- the exact situations where ICL is most appealing. In this paper, we propose the task of ICL accuracy estimation, in which we predict the accuracy of an LLM when doing in-context learning on a new task given only unlabeled test data for that task. To perform ICL accuracy estimation, we propose a method that trains a meta-model using LLM confidence scores as features. We compare our method to several strong accuracy estimation baselines on a new benchmark that covers 4 LLMs and 3 task collections. The meta-model improves over all baselines across 8 out of 12 settings and achieves the same estimation performance as directly evaluating on 40 collected labeled test examples per task. At the same time, no existing approach provides an accurate and reliable ICL accuracy estimation in every setting, highlighting the need for better ways to measure the uncertainty of LLM predictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218145644",
                    "name": "Harvey Yiyun Fu"
                },
                {
                    "authorId": "1557391091",
                    "name": "Qinyuan Ye"
                },
                {
                    "authorId": "2064635028",
                    "name": "Albert Xu"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "3422908",
                    "name": "Robin Jia"
                }
            ]
        },
        {
            "paperId": "4f7edcd05d99c6372af60d55526645297422f4b6",
            "title": "FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning",
            "abstract": "Large pre-trained models are capable of few-shot in-context learning (ICL), i.e., performing a new task by prepending a few demonstrations before the test input. However, the concatenated demonstrations are often excessively long and induce additional computation. Inspired by fusion-in-decoder (FiD) models which efficiently aggregate more passages and thus outperforms concatenation-based models in open-domain QA, we hypothesize that similar techniques can be applied to improve the efficiency and end-task performance of ICL. To verify this, we present a comprehensive study on applying three fusion methods\u2014concatenation-based (early fusion), FiD (intermediate), and ensemble-based (late)\u2014to ICL. We adopt a meta-learning setup where a model is first trained to perform ICL on a mixture of tasks using one selected fusion method, then evaluated on held-out tasks for ICL. Results on 11 held-out tasks show that FiD-ICL matches or outperforms the other two fusion methods. Additionally, we show that FiD-ICL (1) is 10x faster at inference time compared to concat-based and ensemble-based ICL, as we can easily pre-compute the representations of in-context examples and reuse them; (2) enables scaling up to meta-training 3B-sized models, which would fail for concat-based ICL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1557391091",
                    "name": "Qinyuan Ye"
                },
                {
                    "authorId": "46181066",
                    "name": "Iz Beltagy"
                },
                {
                    "authorId": "39139825",
                    "name": "Matthew E. Peters"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2548384",
                    "name": "Hannaneh Hajishirzi"
                }
            ]
        },
        {
            "paperId": "66718e87b70de80cbc2a4120050ca36fda49f8d6",
            "title": "Exploring Distributional Shifts in Large Language Models for Code Analysis",
            "abstract": "We systematically study how three large language models with code capabilities - CodeT5, Codex, and ChatGPT - generalize to out-of-domain data. We consider two fundamental applications - code summarization, and code generation. We split data into domains following its natural boundaries - by an organization, by a project, and by a module within the software project. We establish that samples from each new domain present all the models with a significant challenge of distribution shift. We study how established methods adapt models to better generalize to new domains. Our experiments show that while multitask learning alone is a reasonable baseline, combining it with few-shot finetuning on examples retrieved from training data can achieve very strong performance. Moreover, this solution can outperform direct finetuning for very low-data scenarios. Finally, we consider variations of this approach to create a more broadly applicable method to adapt to multiple domains at once. We find that for code generation, a model adapted to multiple domains simultaneously performs on par with those adapted to a single domain",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46221106",
                    "name": "Shushan Arakelyan"
                },
                {
                    "authorId": "2211732585",
                    "name": "Rocktim Jyoti Das"
                },
                {
                    "authorId": "145469202",
                    "name": "Yi Mao"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "993df7df129f8d18816877d69923d7df7b347d85",
            "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion",
            "abstract": "We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2197076899",
                    "name": "Dongfu Jiang"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "51583409",
                    "name": "Bill Yuchen Lin"
                }
            ]
        },
        {
            "paperId": "9bbe868a4d085b579183997af774309a0079e20a",
            "title": "How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench",
            "abstract": "We investigate the predictability of large language model (LLM) capabilities: given records of past experiments using different model families, numbers of parameters, tasks, and numbers of in-context examples, can we accurately predict LLM performance on new experiment configurations? Answering this question has practical implications for LLM users (e.g., deciding which models to try), developers (e.g., prioritizing evaluation on representative tasks), and the research community (e.g., identifying hard-to-predict capabilities that warrant further investigation). We study the performance prediction problem on experiment records from BIG-bench. On a random train-test split, an MLP-based predictor achieves an $R^2$ score greater than 95%, indicating the presence of learnable patterns within the experiment records. We then formulate the problem of searching for\"small-bench,\"an informative subset of BIG-bench tasks from which the performance on the full set can be maximally recovered. We find a subset as informative as BIG-bench Hard for evaluating new model families, while being $3\\times$ smaller. Additionally, we find competitive subsets by clustering task representations learned by our MLP-based predictor and selecting tasks close to cluster centroids, highlighting the importance of task diversity in constructing\"small-bench.\"",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1557391091",
                    "name": "Qinyuan Ye"
                },
                {
                    "authorId": "2218145644",
                    "name": "Harvey Yiyun Fu"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "3422908",
                    "name": "Robin Jia"
                }
            ]
        },
        {
            "paperId": "9dd8d84874b691c0c44fa32873628b6f729520d9",
            "title": "GRILL: Grounded Vision-language Pre-training via Aligning Text and Image Regions",
            "abstract": "Generalization to unseen tasks is an important ability for few-shot learners to achieve better zero-/few-shot performance on diverse tasks. However, such generalization to vision-language tasks including grounding and generation tasks has been under-explored; existing few-shot VL models struggle to handle tasks that involve object grounding and multiple images such as visual commonsense reasoning or NLVR2. In this paper, we introduce GRILL, GRounded vIsion Language aLigning, a novel VL model that can be generalized to diverse tasks including visual question answering, captioning, and grounding tasks with no or very few training instances. Specifically, GRILL learns object grounding and localization by exploiting object-text alignments, which enables it to transfer to grounding tasks in a zero-/few-shot fashion. We evaluate our model on various zero-/few-shot VL tasks and show that it consistently surpasses the state-of-the-art few-shot methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8844876",
                    "name": "Woojeong Jin"
                },
                {
                    "authorId": "2153292652",
                    "name": "Subhabrata Mukherjee"
                },
                {
                    "authorId": "2153510147",
                    "name": "Yu Cheng"
                },
                {
                    "authorId": "1752875",
                    "name": "Yelong Shen"
                },
                {
                    "authorId": "2109136147",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "2072795428",
                    "name": "A. Awadallah"
                },
                {
                    "authorId": "144430856",
                    "name": "Damien Jose"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2",
            "title": "Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning",
            "abstract": "While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50085131",
                    "name": "Ximing Lu"
                },
                {
                    "authorId": "9252833",
                    "name": "Faeze Brahman"
                },
                {
                    "authorId": "119659229",
                    "name": "Peter West"
                },
                {
                    "authorId": "2148334242",
                    "name": "Jaehun Jang"
                },
                {
                    "authorId": "37619618",
                    "name": "Khyathi Raghavi Chandu"
                },
                {
                    "authorId": "3023068",
                    "name": "Abhilasha Ravichander"
                },
                {
                    "authorId": "3444092",
                    "name": "Lianhui Qin"
                },
                {
                    "authorId": "19179135",
                    "name": "Prithviraj Ammanabrolu"
                },
                {
                    "authorId": "2112504145",
                    "name": "Liwei Jiang"
                },
                {
                    "authorId": "1399403094",
                    "name": "Sahana Ramnath"
                },
                {
                    "authorId": "46217681",
                    "name": "Nouha Dziri"
                },
                {
                    "authorId": "33772445",
                    "name": "Jillian R. Fisher"
                },
                {
                    "authorId": "51583409",
                    "name": "Bill Yuchen Lin"
                },
                {
                    "authorId": "1474550731",
                    "name": "Skyler Hallinan"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2129663",
                    "name": "S. Welleck"
                },
                {
                    "authorId": "1699545",
                    "name": "Yejin Choi"
                }
            ]
        },
        {
            "paperId": "d671d62a1eb4d57343e4a0928297266dffc0c118",
            "title": "SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks",
            "abstract": "We introduce SwiftSage, a novel agent framework inspired by the dual-process theory of human cognition, designed to excel in action planning for complex interactive reasoning tasks. SwiftSage integrates the strengths of behavior cloning and prompting large language models (LLMs) to enhance task completion performance. The framework comprises two primary modules: the Swift module, representing fast and intuitive thinking, and the Sage module, emulating deliberate thought processes. The Swift module is a small encoder-decoder LM fine-tuned on the oracle agent's action trajectories, while the Sage module employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a heuristic method to harmoniously integrate the two modules, resulting in a more efficient and robust problem-solving process. In 30 tasks from the ScienceWorld benchmark, SwiftSage significantly outperforms other methods such as SayCan, ReAct, and Reflexion, demonstrating its effectiveness in solving complex interactive tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51583409",
                    "name": "Bill Yuchen Lin"
                },
                {
                    "authorId": "1998914086",
                    "name": "Yicheng Fu"
                },
                {
                    "authorId": "2218576699",
                    "name": "Karina Yang"
                },
                {
                    "authorId": "19179135",
                    "name": "Prithviraj Ammanabrolu"
                },
                {
                    "authorId": "9252833",
                    "name": "Faeze Brahman"
                },
                {
                    "authorId": "9932998",
                    "name": "Shiyu Huang"
                },
                {
                    "authorId": "1857797",
                    "name": "Chandra Bhagavatula"
                },
                {
                    "authorId": "1699545",
                    "name": "Yejin Choi"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                }
            ]
        },
        {
            "paperId": "e06595ebb2fe4d73fe42e566b57d7a109df75615",
            "title": "Instruction-following Evaluation through Verbalizer Manipulation",
            "abstract": "While instruction-tuned models have shown remarkable success in various natural language processing tasks, accurately evaluating their ability to follow instructions remains challenging. Existing benchmarks primarily focus on common instructions that align well with what the model learned during training. However, proficiency in responding to these instructions does not necessarily imply strong ability in instruction following. In this paper, we propose a novel instruction-following evaluation protocol called verbalizer manipulation. It instructs the model to verbalize the task label with words aligning with model priors to different extents, adopting verbalizers from highly aligned (e.g., outputting ``postive'' for positive sentiment), to minimally aligned (e.g., outputting ``negative'' for positive sentiment). Verbalizer manipulation can be seamlessly integrated with any classification benchmark to examine the model's reliance on priors and its ability to override them to accurately follow the instructions. We conduct a comprehensive evaluation of four major model families across nine datasets, employing twelve sets of verbalizers for each of them. We observe that the instruction-following abilities of models, across different families and scales, are significantly distinguished by their performance on less natural verbalizers. Even the strongest GPT-4 model struggles to perform better than random guessing on the most challenging verbalizer, emphasizing the need for continued advancements to improve their instruction-following abilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2129756845",
                    "name": "Shiyang Li"
                },
                {
                    "authorId": "49781448",
                    "name": "Jun Yan"
                },
                {
                    "authorId": "2210954409",
                    "name": "Hai Wang"
                },
                {
                    "authorId": "2112472583",
                    "name": "Zheng Tang"
                },
                {
                    "authorId": "1384550891",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "123514552",
                    "name": "Vijay Srinivasan"
                },
                {
                    "authorId": "2196885587",
                    "name": "Hongxia Jin"
                }
            ]
        }
    ]
}