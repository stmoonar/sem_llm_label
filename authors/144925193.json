{
    "authorId": "144925193",
    "papers": [
        {
            "paperId": "010ec58d4bae268b5da1b8874946aff7c599b9d2",
            "title": "Sheaf4Rec: Sheaf Neural Networks for Graph-based Recommender Systems",
            "abstract": "Recent advancements in Graph Neural Networks (GNN) have facilitated their widespread adoption in various applications, including recommendation systems. GNNs have proven to be effective in addressing the challenges posed by recommendation systems by efficiently modeling graphs in which nodes represent users or items and edges denote preference relationships. However, current GNN techniques represent nodes by means of a single static vector, which may inadequately capture the intricate complexities of users and items. To overcome these limitations, we propose a solution integrating a cutting-edge model inspired by category theory: Sheaf4Rec. Unlike single vector representations, Sheaf Neural Networks and their corresponding Laplacians represent each node (and edge) using a vector space. Our approach takes advantage from this theory and results in a more comprehensive representation that can be effectively exploited during inference, providing a versatile method applicable to a wide range of graph-related tasks and demonstrating unparalleled performance. Our proposed model exhibits a noteworthy relative improvement of up to 8.53% on F1-Score@10 and an impressive increase of up to 11.29% on NDCG@10, outperforming existing state-of-the-art models such as Neural Graph Collaborative Filtering (NGCF), KGTORe and other recently developed GNN-based models. In addition to its superior predictive capabilities, Sheaf4Rec shows remarkable improvements in terms of efficiency: we observe substantial runtime improvements ranging from 2.5% up to 37% when compared to other GNN-based competitor models, indicating a more efficient way of handling information while achieving better performance. Code is available at https://github.com/antoniopurificato/Sheaf4Rec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214617052",
                    "name": "Antonio Purificato"
                },
                {
                    "authorId": "2214630135",
                    "name": "Giulia Cassara"
                },
                {
                    "authorId": "1752951302",
                    "name": "F. Siciliano"
                },
                {
                    "authorId": "2075355155",
                    "name": "Pietro Lio'"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                }
            ]
        },
        {
            "paperId": "c3068e2a9f4cd374c7ff3be1b8f877b3d653e880",
            "title": "Multimodal Neural Databases",
            "abstract": "The rise in loosely-structured data available through text, images, and other modalities has called for new ways of querying them. Multimedia Information Retrieval has filled this gap and has witnessed exciting progress in recent years. Tasks such as search and retrieval of extensive multimedia archives have undergone massive performance improvements, driven to a large extent by recent developments in multimodal deep learning. However, methods in this field remain limited in the kinds of queries they support and, in particular, their inability to answer database-like queries. For this reason, inspired by recent work on neural databases, we propose a new framework, which we name Multimodal Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that involve reasoning over different input modalities, such as text and images, at scale. In this paper, we present the first architecture able to fulfill this set of requirements and test it with several baselines, showing the limitations of currently available models. The results show the potential of these new techniques to process unstructured data coming from different modalities, paving the way for future research in the area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120709579",
                    "name": "Giovanni Trappolini"
                },
                {
                    "authorId": "2065039862",
                    "name": "Andrea Santilli"
                },
                {
                    "authorId": "1796150",
                    "name": "E. Rodol\u00e0"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                }
            ]
        },
        {
            "paperId": "0140b38d66f5ce3910a7cce691240fa8fee83184",
            "title": "FbMultiLingMisinfo: Challenging Large-Scale Multilingual Benchmark for Misinformation Detection",
            "abstract": "According to recent research, geometric deep learning allows to reach unprecedented accuracy for online misinformation detection. By fully leveraging the news social context, URL propagation paths in social networks are first represented as graphs and then classified using Graph Neural Network (GNN) models. Despite these remarkable efforts, researchers are still hampered by the scarcity of high-quality benchmark datasets, and as a result, the efficacy of state-of-the-art approaches could be overestimated. So far, in order to obtain a decent number of third-party fact-checked URLs, researchers have either sampled news from notoriously reliable and unreliable sources using distant supervision, or they have gathered pre-labeled URLs from third-party fact-checking websites. In the former case, resulting datasets can be quite large, but also noisy and biased since pieces of news are labeled as true or false according to their source label, and not individually fact-checked. In the latter case, assigned labels are more reliable, but the included news articles are usually in a single language and they may reflect unknown editorial decisions. As a result, datasets of the latter type are typically small, homogeneous, and thus unrealistically easy for automatic fake news detection models. In this work, we present FbMultiLingMisinfo, a new multilingual benchmark dataset, aimed at a more realistic evaluation of state-of-the-art misinformation detection models. URLs in our dataset come from the Facebook Privacy-Protected Full URLs Data Set, which we augmented with their propagation paths on Twitter. Our experimental results show that, when GNN-based models are tested on FbMultiLingMisinfo, recent misinformation detection results are only partially confirmed. We further show that a sharp reduction in the training size significantly reduces the model accuracy on FbMultiLingMisinfo, but not on two other widely used benchmark datasets for fake news detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "122381506",
                    "name": "Giorgio Barnab\u00f2"
                },
                {
                    "authorId": "1752951302",
                    "name": "F. Siciliano"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "144954554",
                    "name": "S. Leonardi"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "134000266",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                }
            ]
        },
        {
            "paperId": "1ac96f46e61fd187cc791790e9064ea41f076c02",
            "title": "Sparse Vicious Attacks on Graph Neural Networks",
            "abstract": "In this study, we introduce SAVAGE, a novel framework for sparse vicious adversarial link prediction attacks in graph neural networks (GNNs). While GNNs have been successful in link prediction tasks, they are susceptible to adversarial attacks where malicious nodes attempt to manipulate recommendations for a target victim. SAVAGE optimizes the attacker's goal to maximize attack effectiveness while minimizing the required malicious resources. Unlike existing methods with static resource-based upper bounds, SAVAGE employs a sparsity-enforcing mechanism to reduce the number of malicious nodes needed for the attack. Extensive experiments on real-world and synthetic datasets demonstrate the optimal tradeoff achieved by SAVAGE between a high attack success rate and the number of malicious nodes utilized. Furthermore, we demonstrate that SAVAGE can successfully target non-GNN-based link prediction systems, even those unknown at the time of the attack. This showcases the transferability of SAVAGE-generated attacks to other black-box methods for link prediction, highlighting its applicability across different real-world scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120709579",
                    "name": "Giovanni Trappolini"
                },
                {
                    "authorId": "2140400495",
                    "name": "Valentino Maiorca"
                },
                {
                    "authorId": "2185499848",
                    "name": "Silvio Severino"
                },
                {
                    "authorId": "1796150",
                    "name": "E. Rodol\u00e0"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                },
                {
                    "authorId": "2651748",
                    "name": "Gabriele Tolomei"
                }
            ]
        },
        {
            "paperId": "1b5f8d3693ce9dfc07e7606039322b7e7b60270b",
            "title": "Encoding Concepts in Graph Neural Networks",
            "abstract": "The opaque reasoning of Graph Neural Networks induces a lack of human trust. Existing graph network explainers attempt to address this issue by providing post-hoc explanations, however, they fail to make the model itself more interpretable. To fill this gap, we introduce the Concept Encoder Module, the first differentiable concept-discovery approach for graph networks. The proposed approach makes graph networks explainable by design by first discovering graph concepts and then using these to solve the task. Our results demonstrate that this approach allows graph networks to: (i) attain model accuracy comparable with their equivalent vanilla versions, (ii) discover meaningful concepts that achieve high concept completeness and purity scores, (iii) provide high-quality concept-based logic explanations for their prediction, and (iv) support effective interventions at test time: these can increase human trust as well as significantly improve model performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2098834685",
                    "name": "Lucie Charlotte Magister"
                },
                {
                    "authorId": "2123005765",
                    "name": "Pietro Barbiero"
                },
                {
                    "authorId": "1641643092",
                    "name": "Dmitry Kazhdan"
                },
                {
                    "authorId": "1752951302",
                    "name": "F. Siciliano"
                },
                {
                    "authorId": "79277428",
                    "name": "Gabriele Ciravegna"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                },
                {
                    "authorId": "2075355155",
                    "name": "Pietro Lio'"
                },
                {
                    "authorId": "1708741",
                    "name": "M. Jamnik"
                }
            ]
        },
        {
            "paperId": "1dd25d1bc1266f9f1e088c99f8b7f22d038f4d19",
            "title": "Detecting and Understanding Harmful Memes: A Survey",
            "abstract": "The automatic identification of harmful content online is of major concern for social media platforms, policymakers, and society. Researchers have studied textual, visual, and audio content, but typically in isolation. Yet, harmful content often combines multiple modalities, as in the case of memes. With this in mind, here we offer a comprehensive survey with a focus on harmful memes. Based on a systematic analysis of recent literature, we first propose a new typology of harmful memes, and then we highlight and summarize the relevant state of the art. One interesting finding is that many types of harmful memes are not really studied, e.g., such featuring self-harm and extremism, partly due to the lack of suitable datasets. We further find that existing datasets mostly capture multi-class scenarios, which are not inclusive of the affective spectrum that memes can represent. Another observation is that memes can propagate globally through repackaging in different languages and that they can also be multilingual, blending different cultures. We conclude by highlighting several challenges related to multimodal semiotics, technological constraints, and non-trivial social engagement, and we present several open-ended aspects such as delineating online harm and empirically examining related frameworks and assistive interventions, which we believe will motivate and drive future research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1491627343",
                    "name": "Shivam Sharma"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "46815454",
                    "name": "Md. Shad Akhtar"
                },
                {
                    "authorId": "2105813793",
                    "name": "Dimitar I. Dimitrov"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "22593971",
                    "name": "Hamed Firooz"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "144054829",
                    "name": "Tanmoy Chakraborty"
                }
            ]
        },
        {
            "paperId": "ba438e51ec18ab8f8dee9444646c1adf28e0471b",
            "title": "On the Role of Relevance in Natural Language Processing Tasks",
            "abstract": "Many recent Natural Language Processing (NLP) task formulations, such as question answering and fact verification, are implemented as a two-stage cascading architecture. In the first stage an IR system retrieves \"relevant'' documents containing the knowledge, and in the second stage an NLP system performs reasoning to solve the task. Optimizing the IR system for retrieving relevant documents ensures that the NLP system has sufficient information to operate over. These recent NLP task formulations raise interesting and exciting challenges for IR, where the end-user of an IR system is not a human with an information need, but another system exploiting the documents retrieved by the IR system to perform reasoning and address the user information need. Among these challenges, as we will show, is that noise from the IR system, such as retrieving spurious or irrelevant documents, can negatively impact the accuracy of the downstream reasoning module. Hence, there is the need to balance maximizing relevance while minimizing noise in the IR system. This paper presents experimental results on two NLP tasks implemented as a two-stage cascading architecture. We show how spurious or irrelevant retrieved results from the first stage can induce errors in the second stage. We use these results to ground our discussion of the research challenges that the IR community should address in the context of these knowledge-intensive NLP tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175275805",
                    "name": "Artsiom Sauchuk"
                },
                {
                    "authorId": "2053211210",
                    "name": "James Thorne"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2783910",
                    "name": "N. Tonellotto"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                }
            ]
        },
        {
            "paperId": "edbdec562cb1525eafe148b249b75480a284dc59",
            "title": "GREASE: Generate Factual and Counterfactual Explanations for GNN-based Recommendations",
            "abstract": "Recently, graph neural networks (GNNs) have been widely used to develop successful recommender systems. Although powerful, it is very difficult for a GNN-based recommender system to attach tangible explanations of why a specific item ends up in the list of suggestions for a given user. Indeed, explaining GNN-based recommendations is unique, and existing GNN explanation methods are inappropriate for two reasons. First, traditional GNN explanation methods are designed for node, edge, or graph classification tasks rather than ranking, as in recommender systems. Second, standard machine learning explanations are usually intended to support skilled decision-makers. Instead, recommendations are designed for any end-user, and thus their explanations should be provided in user-understandable ways. In this work, we propose GREASE, a novel method for explaining the suggestions provided by any black-box GNN-based recommender system. Specifically, GREASE first trains a surrogate model on a target user-item pair and its $l$-hop neighborhood. Then, it generates both factual and counterfactual explanations by finding optimal adjacency matrix perturbations to capture the sufficient and necessary conditions for an item to be recommended, respectively. Experimental results conducted on real-world datasets demonstrate that GREASE can generate concise and effective explanations for popular GNN-based recommender models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157281262",
                    "name": "Ziheng Chen"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                },
                {
                    "authorId": "2144547216",
                    "name": "Jia Wang"
                },
                {
                    "authorId": "1591136873",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": null,
                    "name": "Zhenhua Huang"
                },
                {
                    "authorId": "34609799",
                    "name": "H. Ahn"
                },
                {
                    "authorId": "2651748",
                    "name": "Gabriele Tolomei"
                }
            ]
        },
        {
            "paperId": "11b9f4729c8e355dec7122993076f6e2788c03c4",
            "title": "CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks",
            "abstract": "Given the increasing promise of graph neural networks (GNNs) in real-world applications, several methods have been developed for explaining their predictions. Existing methods for interpreting predictions from GNNs have primarily focused on generating subgraphs that are especially relevant for a particular prediction. However, such methods are not counterfactual (CF) in nature: given a prediction, we want to understand how the prediction can be changed in order to achieve an alternative outcome. In this work, we propose a method for generating CF explanations for GNNs: the minimal perturbation to the input (graph) data such that the prediction changes. Using only edge deletions, we find that our method, CF-GNNExplainer, can generate CF explanations for the majority of instances across three widely used datasets for GNN explanations, while removing less than 3 edges on average, with at least 94\\% accuracy. This indicates that CF-GNNExplainer primarily removes edges that are crucial for the original predictions, resulting in minimal CF explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38702106",
                    "name": "Ana Lucic"
                },
                {
                    "authorId": "41096186",
                    "name": "Maartje ter Hoeve"
                },
                {
                    "authorId": "2651748",
                    "name": "Gabriele Tolomei"
                },
                {
                    "authorId": "1696030",
                    "name": "M. de Rijke"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                }
            ]
        },
        {
            "paperId": "16529f7194bf7faee8a4e43fd54aefeb8730f236",
            "title": "Database reasoning over text",
            "abstract": "Neural models have shown impressive performance gains in answering queries from natural language text. However, existing works are unable to support database queries, such as \u201cList/Count all female athletes who were born in 20th century\u201d, which require reasoning over sets of relevant facts with operations such as join, filtering and aggregation. We show that while state-of-the-art transformer models perform very well for small databases, they exhibit limitations in processing noisy data, numerical operations, and queries that aggregate facts. We propose a modular architecture to answer these database-style queries over multiple spans from text and aggregating these at scale. We evaluate the architecture using WikiNLDB, a novel dataset for exploring such queries. Our architecture scales to databases containing thousands of facts whereas contemporary models are limited by how many facts can be encoded. In direct comparison on small databases, our approach increases overall answer accuracy from 85% to 90%. On larger databases, our approach retains its accuracy whereas transformer baselines could not encode the context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053211210",
                    "name": "James Thorne"
                },
                {
                    "authorId": "69910001",
                    "name": "Majid Yazdani"
                },
                {
                    "authorId": "2073055",
                    "name": "Marzieh Saeidi"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                },
                {
                    "authorId": "48662861",
                    "name": "Sebastian Riedel"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                }
            ]
        }
    ]
}