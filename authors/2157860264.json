{
    "authorId": "2157860264",
    "papers": [
        {
            "paperId": "3089714fd0711983fad8fad2dc5d447f07b07e7a",
            "title": "RISE: Robust Early-exiting Internal Classifiers for Suicide Risk Evaluation",
            "abstract": "Suicide is a serious public health issue, but it is preventable with timely intervention. Emerging studies have suggested there is a noticeable increase in the number of individuals sharing suicidal thoughts online. As a result, utilising advance Natural Language Processing techniques to build automated systems for risk assessment is a viable alternative. However, existing systems are prone to incorrectly predicting risk severity and have no early detection mechanisms. Therefore, we propose RISE, a novel robust mechanism for accurate early detection of suicide risk by ensembling Hyperbolic Internal Classifiers equipped with an abstention mechanism and early-exit inference capabilities. Through quantitative, qualitative and ablative experiments, we demonstrate RISE as an efficient and robust human-in-the-loop approach for risk assessment over the Columbia Suicide Severity Risk Scale (C-SSRS) and CLPsych 2022 datasets. It is able to successfully abstain from 84% incorrect predictions on Reddit data while out-predicting state of the art models upto 3.5x earlier.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161000447",
                    "name": "Ritesh Soun"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "3238627",
                    "name": "Nikolaos Aletras"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "5fa230579616993cb25c40aac4ed265f745c2926",
            "title": "Saliency-Aware Interpolative Augmentation for Multimodal Financial Prediction",
            "abstract": "Predicting price variations of financial instruments for risk modeling and stock trading is challenging due to the stochastic nature of the stock market. While recent advancements in the Financial AI realm have expanded the scope of data and methods they use, such as textual and audio cues from financial earnings calls, limitations exist. Most datasets are small, and show domain distribution shifts due to the nature of their source, suggesting the exploration for data augmentation for robust augmentation strategies such as Mixup. To tackle such challenges in the financial domain, we propose SH-Mix: Saliency-guided Hierarchical Mixup augmentation technique for multimodal financial prediction tasks. SH-Mix combines multi-level embedding mixup strategies based on the contribution of each modality and context subsequences. Through extensive quantitative and qualitative experiments on financial earnings and conference call datasets consisting of text and speech, we show that SH-Mix outperforms state-of-the-art methods by 3-7%. Additionally, we show that SH-Mix is generalizable across different modalities and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302368303",
                    "name": "Samyak Jain"
                },
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "7dcb732c92e9c5b53aff482e543db4909dfa62dc",
            "title": "Learning Through Interpolative Augmentation of Dynamic Curvature Spaces",
            "abstract": "Mixup is an efficient data augmentation technique, which improves generalization by interpolating random examples. While numerous approaches have been developed for Mixup in the Euclidean and in the hyperbolic space, they do not fully use the intrinsic properties of the examples, i.e., they manually set the geometry (Euclidean or hyperbolic) based on the overall dataset, which may be sub-optimal since each example may require a different geometry. We propose DynaMix, a framework that automatically selects an example-specific geometry and performs Mixup between the different geometries to improve training dynamics and generalization. Through extensive experiments in image and text modalities we show that DynaMix outperforms state-of-the-art methods over six downstream applications. We find that DynaMix is more useful in low-resource and semi-supervised settings likely because it displays a probabilistic view of the geometry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "fa168fe11fa77c9728412e49596f8a808b67a4d8",
            "title": "Early Weight Averaging meets High Learning Rates for LLM Pre-training",
            "abstract": "Training Large Language Models (LLMs) incurs significant cost; hence, any strategy that accelerates model convergence is helpful. In this paper, we investigate the ability of a simple idea checkpoint averaging along the trajectory of a training run to improve both convergence and generalization quite early on during training. Here we show that models trained with high learning rates observe higher gains due to checkpoint averaging. Furthermore, these gains are amplified when checkpoints are sampled with considerable spacing in training steps. Our training recipe outperforms conventional training and popular checkpoint averaging baselines such as exponential moving average (EMA) and stochastic moving average (SWA). We evaluate our training recipe by pre-training LLMs, where high learning rates are inherently preferred due to extremely large batch sizes. Specifically, we pre-trained nanoGPT-2 models of varying sizes, small (125M), medium (335M), and large (770M)on the OpenWebText dataset, comprised of 9B tokens. Additionally, we present results for publicly available Pythia LLMs, ranging from 1B to 12B, which were trained on the PILE-deduped dataset containing 207B tokens.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50456512",
                    "name": "Sunny Sanyal"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "66914903",
                    "name": "Jean Kaddour"
                },
                {
                    "authorId": "2143575928",
                    "name": "Abhishek Kumar"
                },
                {
                    "authorId": "70116942",
                    "name": "Sujay Sanghavi"
                }
            ]
        },
        {
            "paperId": "02dbc34adc6364d698ad530d2957802de1c66c38",
            "title": "Intermix: An Interference-Based Data Augmentation and Regularization Technique for Automatic Deep Sound Classification",
            "abstract": "In this paper, we present InterMix, an interference-based regularization and data augmentation strategy for automatic sound classification. InterMix creates virtual training examples by creating an interference-based mixed representation for a sampled phase difference and mixup ratio. InterMix can be used to train sound classification models with the ability to generate a vast amount of training samples. These are significantly varied compared to that of other mixup strategies due to the introduction of phase difference, a continuous variable. While building on other mixup strategies which use linear interpolation, we perform mixup based on the formula of interference. We demonstrate the utility of InterMix in comparison to standard learning techniques and previously applied mixing strategies through a quantitative analysis. We also demonstrate that InterMix is more robust towards adversarial attacks compared to standard learning and other mixup strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                }
            ]
        },
        {
            "paperId": "2009939f7f8adff27164debdb3c6f0455076b266",
            "title": "Tweet Based Reach Aware Temporal Attention Network for NFT Valuation",
            "abstract": "Non-Fungible Tokens (NFTs) are a relatively unexplored class of assets. Designing strategies to forecast NFT trends is an intricate task due to its extremely volatile nature. The market is largely driven by public sentiment and \"hype\", which in turn has a high correlation with conversations taking place on social media platforms like Twitter. Prior work done for modelling stock market data does not take into account the extent of impact certain highly influential tweets and their authors can have on the market. Building on these limitations and the nature of the NFT market, we propose a novel reach-aware temporal learning approach to make predictions for forecasting future trends in the NFT market. We perform experiments on a new dataset consisting of over 1.3 million tweets and 180 thousand NFT transactions spanning over 15 NFT collections curated by us. Our model (TA-NFT) outperforms other state-of-the-art methods by an average of 36%. Through extensive quantitative and ablative analysis, we demonstrate the ability of our approach as a practical method for predicting NFT trends.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2161000447",
                    "name": "Ritesh Soun"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "144582538",
                    "name": "Vasu Sharma"
                },
                {
                    "authorId": "2047009798",
                    "name": "Dipanwita Guhathakurta"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                }
            ]
        },
        {
            "paperId": "22845aa95461ac27bf2993aee37e9415de9b25ff",
            "title": "The Impact of Differential Privacy on Group Disparity Mitigation",
            "abstract": "The performance cost of differential privacy has, for some applications, been shown to be higher for minority groups fairness, conversely, has been shown to disproportionally compromise the privacy of members of such groups. Most work in this area has been restricted to computer vision and risk assessment. In this paper, we evaluate the impact of differential privacy on fairness across four tasks, focusing on how attempts to mitigate privacy violations and between-group performance differences interact Does privacy inhibit attempts to ensure fairness? To this end, we train epsilon, delta-differentially private models with empirical risk minimization and group distributionally robust training objectives. Consistent with previous findings, we find that differential privacy increases between-group performance differences in the baseline setting but more interestingly, differential privacy reduces between-group performance differences in the robust setting. We explain this by reinterpreting differential privacy as regularization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "148293273",
                    "name": "Victor Petr\u00e9n Bach Hansen"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2125481734",
                    "name": "Lucie Flek"
                },
                {
                    "authorId": "1700187",
                    "name": "Anders S\u00f8gaard"
                }
            ]
        },
        {
            "paperId": "388bc966b38266c4b8df63efb30ffbab65319d5c",
            "title": "How Much User Context Do We Need? Privacy by Design in Mental Health NLP Application",
            "abstract": "Clinical NLP tasks such as mental health assessment from text, must take social constraints into account - the performance maximization must be constrained by the utmost importance of guaranteeing privacy of user data. Consumer protection regulations, such as GDPR, generally handle privacy by restricting data availability, such as requiring to limit user data to 'what is necessary' for a given purpose. In this work, we reason that providing stricter formal privacy guarantees, while increasing the volume of user data in the model, in most cases increases benefit for all parties involved, especially for the user. We demonstrate our arguments on two existing suicide risk assessment datasets of Twitter and Reddit posts. We present the first analysis juxtaposing user history length and differential privacy budgets and elaborate how modeling additional user context enables utility preservation while maintaining acceptable user privacy guarantees.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "2572366",
                    "name": "Ivan Habernal"
                },
                {
                    "authorId": "2125481734",
                    "name": "Lucie Flek"
                }
            ]
        },
        {
            "paperId": "9b18595e2257b1c55eddffe7ea4d2be3e1951aee",
            "title": "A Risk-Averse Mechanism for Suicidality Assessment on Social Media",
            "abstract": "Recent studies have shown that social media has increasingly become a platform for users to express suicidal thoughts outside traditional clinical settings. With advances in Natural Language Processing strategies, it is now possible to design automated systems to assess suicide risk. However, such systems may generate uncertain predictions, leading to severe consequences. We hence reformulate suicide risk assessment as a selective prioritized prediction problem over the Columbia Suicide Severity Risk Scale (C-SSRS). We propose SASI, a risk-averse and self-aware transformer-based hierarchical attention classifier, augmented to refrain from making uncertain predictions. We show that SASI is able to refrain from 83% of incorrect predictions on real-world Reddit data. Furthermore, we discuss the qualitative, practical, and ethical aspects of SASI for suicide risk assessment as a human-in-the-loop framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "1491238594",
                    "name": "Manas Gaur"
                }
            ]
        },
        {
            "paperId": "a73701af64496645a33087c69bc5a06f2fa34ba0",
            "title": "Orthogonal Multi-Manifold Enriching of Directed Networks",
            "abstract": "Directed Acyclic Graphs and trees are widely prevalent in several real-world applications. These hierarchical structures show intriguing properties such as scale-free and bipartite nature, with \ufb01ne-grained temporal irregularities among nodes. Building on advances in geometrical deep learning, we explore a time-aware neural network to model trees and Directed Acyclic Graphs in multiple Riemannian manifolds of varying curvatures. To jointly utilize the strength of these manifolds, we pro-pose M ulti-Manifold R ecursive I nteraction L earning ( MRIL ) on Directed Acyclic Graphs where we introduce an inter-manifold learning mechanism that recursively enriches each manifold with representations from sibling manifolds. We propose the integration of the Stiefel orthogonality constraint which stabilizes the training process in Riemannian manifolds. Through a series of quantitative and exploratory experiments, we show that our method achieves competitive performance and converges much faster on data spanning several domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "2066222462",
                    "name": "K. Pathak"
                }
            ]
        }
    ]
}