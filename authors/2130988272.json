{
    "authorId": "2130988272",
    "papers": [
        {
            "paperId": "c3a377bcee0ff340376820cae7795b0d8bb9ea47",
            "title": "Distributed Learning of Deep Sparse Neural Networks for High-dimensional Classification",
            "abstract": "While analyzing high dimensional data-sets using deep neural network (NN), increased sparsity is desirable but requires careful selection of \"sparsity parameters.\" In this paper, a novel distributed learning methodology is proposed to optimize the NN while addressing this challenge. To address this challenge, the optimal sparsity in the NN is estimated via a two player zero-sum game in the paper. In the proposed game, sparsity parameter is the first player with the aim of increasing sparsity in the NN while NN weights is the second player with the goal of improving its performance in the presence of increased sparsity. To solve the game, additional variables are introduced into the optimization problem such that the output at every layer in the NN depends on this variable instead of the previous layer. Using these additional variables, layer wise cost-functions are derived that are then independently optimized to learn the additional variables, NN weights and the sparsity parameters. To implement the proposed learning procedure in a parallelized and distributed environment, a novel computational algorithm is also proposed. The efficiency of the proposed approach is demonstrated using a total of six data-sets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50064464",
                    "name": "Shweta Garg"
                },
                {
                    "authorId": "2130988272",
                    "name": "R. Krishnan"
                },
                {
                    "authorId": "144991764",
                    "name": "S. Jagannathan"
                },
                {
                    "authorId": "1993956",
                    "name": "V. A. Samaranayake"
                }
            ]
        },
        {
            "paperId": "75eb2c0e6721cd3f938293011733c4bb389cab1b",
            "title": "Deep learning inspired prognostics scheme for applications generating big data",
            "abstract": "In this paper, the relevance of deep neural network (DNN) is studied in big data scenarios, specifically for prognostics applications. It is observed that fault predictions can be performed more efficiently when DNN is used with a pre-processing step. A novel hierarchical dimension reduction (HDR) approach is therefore proposed as a pre-processing step to DNN. This two-step approach is shown to be effective in extracting value from complex and uncertain big data. It is shown that use of HDR prior to DNN improves convergence and allows for the possibility of reduction in model size without any drop in accuracy. A comprehensive methodology is developed to facilitate prognostics using DNN. Simulation results are included to demonstrate the overall methodology using big data-sets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130988272",
                    "name": "R. Krishnan"
                },
                {
                    "authorId": "144991764",
                    "name": "S. Jagannathan"
                },
                {
                    "authorId": "1993956",
                    "name": "V. A. Samaranayake"
                }
            ]
        },
        {
            "paperId": "f0261ac1e5d45e36bfd6902c03d23e4e513981c0",
            "title": "Hierarchical Mahalanobis Distance Clustering Based Technique for Prognostics in Applications Generating Big Data",
            "abstract": "In this paper, a Mahalanobis Distance (MD) based hierarchical clustering technique is proposed for prognostics in applications generating Big Data. This technique is shown to have the ability to overcome certain challenges concerning Big Data analysis. In this technique, Mahalanobis Taguchi Strategy is utilized to organize the MD values into a tree and hierarchical clustering approach is then applied to obtain an overall MD value. This overall MD value is trended over time for prediction. Simulation results are presented to demonstrate the efficiency of the proposed technique.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130988272",
                    "name": "R. Krishnan"
                },
                {
                    "authorId": "144991764",
                    "name": "S. Jagannathan"
                }
            ]
        }
    ]
}