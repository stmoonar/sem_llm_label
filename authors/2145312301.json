{
    "authorId": "2145312301",
    "papers": [
        {
            "paperId": "99ce284f5d01d5284e0b12081b951af6ab20f6d9",
            "title": "Joint-Motion Mutual Learning for Pose Estimation in Videos",
            "abstract": "Human pose estimation in videos has long been a compelling yet challenging task within the realm of computer vision. Nevertheless, this task remains difficult because of the complex video scenes, such as video defocus and self-occlusion. Recent methods strive to integrate multi-frame visual features generated by a backbone network for pose estimation. However, they often ignore the useful joint information encoded in the initial heatmap, which is a by-product of the backbone generation. Comparatively, methods that attempt to refine the initial heatmap fail to consider any spatio-temporal motion features. As a result, the performance of existing methods for pose estimation falls short due to the lack of ability to leverage both local joint (heatmap) information and global motion (feature) dynamics. To address this problem, we propose a novel joint-motion mutual learning framework for pose estimation, which effectively concentrates on both local joint dependency and global pixel-level motion dynamics. Specifically, we introduce a context-aware joint learner that adaptively leverages initial heatmaps and motion flow to retrieve robust local joint feature. Given that local joint feature and global motion flow are complementary, we further propose a progressive joint-motion mutual learning that synergistically exchanges information and interactively learns between joint feature and motion flow to improve the capability of the model. More importantly, to capture more diverse joint and motion cues, we theoretically analyze and propose an information orthogonality objective to avoid learning redundant information from multi-cues. Empirical experiments show our method outperforms prior arts on three challenging benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290801874",
                    "name": "Sifan Wu"
                },
                {
                    "authorId": "2314890867",
                    "name": "Haipeng Chen"
                },
                {
                    "authorId": "2315441073",
                    "name": "Yifang Yin"
                },
                {
                    "authorId": "2314862156",
                    "name": "Sihao Hu"
                },
                {
                    "authorId": "2053521634",
                    "name": "Runyang Feng"
                },
                {
                    "authorId": "2113474",
                    "name": "Yingying Jiao"
                },
                {
                    "authorId": "2315064969",
                    "name": "Ziqi Yang"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                }
            ]
        },
        {
            "paperId": "06d1497141b8f3fc6eeff0c22fa6885a963d04d3",
            "title": "Alleviating Structural Distribution Shift in Graph Anomaly Detection",
            "abstract": "Graph anomaly detection (GAD) is a challenging binary classification problem due to its different structural distribution between anomalies and normal nodes --- abnormal nodes are a minority, therefore holding high heterophily and low homophily compared to normal nodes. Furthermore, due to various time factors and the annotation preferences of human experts, the heterophily and homophily can change across training and testing data, which is called structural distribution shift (SDS) in this paper. The mainstream methods are built on graph neural networks (GNNs), benefiting the classification of normals from aggregating homophilous neighbors, yet ignoring the SDS issue for anomalies and suffering from poor generalization. This work solves the problem from a feature view. We observe that the degree of SDS varies between anomalies and normal nodes. Hence to address the issue, the key lies in resisting high heterophily for anomalies meanwhile benefiting the learning of normals from homophily. Since different labels correspond to the difference of critical anomaly features which make great contributions to the GAD, we tease out the anomaly features on which we constrain to mitigate the effect of heterophilous neighbors and make them invariant. However, the prior distribution of anomaly features is dynamic and hard to estimate, we thus devise a prototype vector to infer and update this distribution during training. For normal nodes, we constrain the remaining features to preserve the connectivity of nodes and reinforce the influence of the homophilous neighborhood. We term our proposed framework asGraph Decomposition Network (GDN). Extensive experiments are conducted on two benchmark datasets, and the proposed framework achieves a remarkable performance boost in GAD, especially in an SDS environment where anomalies have largely different structural distribution across training and testing environments. Codes are open-sourced in https://github.com/blacksingular/wsdm_GDN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143792907",
                    "name": "Yuan Gao"
                },
                {
                    "authorId": "2144796537",
                    "name": "Xiang Wang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "1986484",
                    "name": "Huamin Feng"
                },
                {
                    "authorId": "2164724337",
                    "name": "Yongdong Zhang"
                }
            ]
        },
        {
            "paperId": "2b72efcd2e1e581f9bf0c5c1c824bfd89190b186",
            "title": "Action Recognition with Multi-stream Motion Modeling and Mutual Information Maximization",
            "abstract": "Action recognition has long been a fundamental and intriguing problem in artificial intelligence. The task is challenging due to the high dimensionality nature of an action, as well as the subtle motion details to be considered. Current state-of-the-art approaches typically learn from articulated motion sequences in the straightforward 3D Euclidean space. However, the vanilla Euclidean space is not efficient for modeling important motion characteristics such as the joint-wise angular acceleration, which reveals the driving force behind the motion. Moreover, current methods typically attend to each channel equally and lack theoretical constrains on extracting task-relevant features from the input.\n\n\n\nIn this paper, we seek to tackle these challenges from three aspects: (1) We propose to incorporate an acceleration representation, explicitly modeling the higher-order variations in motion. (2) We introduce a novel Stream-GCN network equipped with multi-stream components and channel attention, where different representations (i.e., streams) supplement each other towards a more precise action recognition while attention capitalizes on those important channels. (3) We explore feature-level supervision for maximizing the extraction of task-relevant information and formulate this into a mutual information loss. Empirically, our approach sets the new state-of-the-art performance on three benchmark datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9006204",
                    "name": "Yu-Huan Yang"
                },
                {
                    "authorId": "2118438627",
                    "name": "Haipeng Chen"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "51290681",
                    "name": "Y. Lyu"
                },
                {
                    "authorId": "1390499303",
                    "name": "Beibei Zhang"
                },
                {
                    "authorId": "2142612001",
                    "name": "Shuang Wu"
                },
                {
                    "authorId": "3623271",
                    "name": "Zhibo Wang"
                },
                {
                    "authorId": "2072596898",
                    "name": "Kui Ren"
                }
            ]
        },
        {
            "paperId": "4a76ea74e48ee96a0b846c58a843b2031da7b9de",
            "title": "Addressing Heterophily in Graph Anomaly Detection: A Perspective of Graph Spectrum",
            "abstract": "Graph anomaly detection (GAD) suffers from heterophily \u2014 abnormal nodes are sparse so that they are connected to vast normal nodes. The current solutions upon Graph Neural Networks (GNNs) blindly smooth the representation of neiboring nodes, thus undermining the discriminative information of the anomalies. To alleviate the issue, recent studies identify and discard inter-class edges through estimating and comparing the node-level representation similarity. However, the representation of a single node can be misleading when the prediction error is high, thus hindering the performance of the edge indicator. In graph signal processing, the smoothness index is a widely adopted metric which plays the role of frequency in classical spectral analysis. Considering the ground truth Y to be a signal on graph, the smoothness index is equivalent to the value of the heterophily ratio. From this perspective, we aim to address the heterophily problem in the spectral domain. First, we point out that heterophily is positively associated with the frequency of a graph. Towards this end, we could prune inter-class edges by simply emphasizing and delineating the high-frequency components of the graph. Recall that graph Laplacian is a high-pass filter, we adopt it to measure the extent of 1-hop label changing of the center node and indicate high-frequency components. As GAD can be formulated as a semi-supervised binary classification problem, only part of the nodes are labeled. As an alternative, we use the prediction of the nodes to estimate it. Through our analysis, we show that prediction errors are less likely to affect the identification process. Extensive empirical evaluations on four benchmarks demonstrate the effectiveness of the indicator over popular homophilic, heterophilic, and tailored fraud detection methods. Our proposed indicator can effectively reduce the heterophily degree of the graph, thus boosting the overall GAD performance. Codes are open-sourced in https://github.com/blacksingular/GHRN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143792907",
                    "name": "Yuan Gao"
                },
                {
                    "authorId": "2144796537",
                    "name": "Xiang Wang"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "1986484",
                    "name": "Huamin Feng"
                },
                {
                    "authorId": "2164724337",
                    "name": "Yongdong Zhang"
                }
            ]
        },
        {
            "paperId": "7d1bff1ca0df5a06820f010c4d4613fe6f6b0f9d",
            "title": "Binary Label Learning for Semi-Supervised Feature Selection",
            "abstract": "Semi-supervised feature selection methods jointly exploit the labelled and unlabelled samples when selecting the features. Under the semi-supervised learning scenario, the number of labelled data significantly impacts the feature selection performance. In this paper, we introduce the label learning with binary hashing to the research field of feature selection and propose a novel Semi-supervised Feature Selection with Binary Label Learning (SFS-BLL) model. Specifically, we learn the binary hash codes as the pseudo labels by specially imposing binary hash constraints on the spectral embedding process to increase the number of labels. Meanwhile, we propose a self-weighted sparse regression module which exploits the learned labels and given manual labels together with importance differentiation to guide the feature selection process. Finally, we develop an effective discrete optimization method based on the Alternating Direction Method of Multipliers (ADMM) to iteratively optimize the binary labels and the feature selection matrix. Extensive experiments on widely tested benchmarks demonstrate the superiority of the proposed method from various aspects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Dan Shi"
                },
                {
                    "authorId": "152366931",
                    "name": "Lei Zhu"
                },
                {
                    "authorId": "2109058078",
                    "name": "Jingjing Li"
                },
                {
                    "authorId": "2113279142",
                    "name": "Zhiyong Cheng"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                }
            ]
        },
        {
            "paperId": "af03380b45c755185d4a754d83fcdeba39541bea",
            "title": "Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia Visual Inspection",
            "abstract": "Early detection of dysplasia of the cervix is critical for cervical cancer treatment. However, automatic cervical dysplasia diagnosis via visual inspection, which is more appropriate in low-resource settings, remains a challenging problem. Though promising results have been obtained by recent deep learning models, their performance is significantly hindered by the limited scale of the available cervix datasets. Distinct from previous methods that learn from a single dataset, we propose to leverage cross-domain cervical images that were collected in different but related clinical studies to improve the model's performance on the targeted cervix dataset. To robustly learn the transferable information across datasets, we propose a novel prototype-based knowledge filtering method to estimate the transferability of cross-domain samples. We further optimize the shared feature space by aligning the cross-domain image representations simultaneously on domain level with early alignment and class level with supervised contrastive learning, which endows model training and knowledge transfer with stronger robustness. The empirical results on three real-world benchmark cervical image datasets show that our proposed method outperforms the state-of-the-art cervical dysplasia visual inspection by an absolute improvement of 4.7% in top-1 accuracy, 7.0% in precision, 1.4% in recall, 4.6% in F1 score, and 0.05 in ROC-AUC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2129513988",
                    "name": "Yichen Zhang"
                },
                {
                    "authorId": "144221742",
                    "name": "Yifang Yin"
                },
                {
                    "authorId": "2153388706",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "50219447",
                    "name": "Zheng Wang"
                },
                {
                    "authorId": "153015119",
                    "name": "Roger Zimmermann"
                }
            ]
        },
        {
            "paperId": "dce62170e8be820bcec51aae2eceed3943ca6c9a",
            "title": "TTIDA: Controllable Generative Data Augmentation via Text-to-Text and Text-to-Image Models",
            "abstract": "Data augmentation has been established as an efficacious approach to supplement useful information for low-resource datasets. Traditional augmentation techniques such as noise injection and image transformations have been widely used. In addition, generative data augmentation (GDA) has been shown to produce more diverse and flexible data. While generative adversarial networks (GANs) have been frequently used for GDA, they lack diversity and controllability compared to text-to-image diffusion models. In this paper, we propose TTIDA (Text-to-Text-to-Image Data Augmentation) to leverage the capabilities of large-scale pre-trained Text-to-Text (T2T) and Text-to-Image (T2I) generative models for data augmentation. By conditioning the T2I model on detailed descriptions produced by T2T models, we are able to generate photo-realistic labeled images in a flexible and controllable manner. Experiments on in-domain classification, cross-domain classification, and image captioning tasks show consistent improvements over other data augmentation baselines. Analytical studies in varied settings, including few-shot, long-tail, and adversarial, further reinforce the effectiveness of TTIDA in enhancing performance and increasing robustness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109472880",
                    "name": "Yuwei Yin"
                },
                {
                    "authorId": "66914903",
                    "name": "Jean Kaddour"
                },
                {
                    "authorId": "48505793",
                    "name": "Xiang Zhang"
                },
                {
                    "authorId": "40383658",
                    "name": "Yixin Nie"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "47648549",
                    "name": "Lingpeng Kong"
                },
                {
                    "authorId": "50384171",
                    "name": "Qi Liu"
                }
            ]
        },
        {
            "paperId": "f328fb7431fdb37522b27cffee069bc1c7533dcc",
            "title": "A Causal View for Item-level Effect of Recommendation on User Preference",
            "abstract": "Recommender systems not only serve users but also affect user preferences through personalized recommendations. Recent researches investigate the effects of the entire recommender system on user preferences, i.e., system-level effects, and find that recommendations may lead to problems such as echo chambers and filter bubbles. To properly alleviate the problems, it is necessary to estimate the effects of recommending a specific item on user preferences, i.e., item-level effects. For example, by understanding whether recommending an item aggravates echo chambers, we can better decide whether to recommend it or not. This work designs a method to estimate the item-level effects from the causal perspective. We resort to causal graphs to characterize the average treatment effect of recommending an item on the preference of another item. The key to estimating the effects lies in mitigating the confounding bias of time and user features without the costly randomized control trials. Towards the goal, we estimate the causal effects from historical observations through a method with stratification and matching to address the two confounders, respectively. Nevertheless, directly implementing stratification and matching is intractable, which requires high computational cost due to the large sample size. We thus propose efficient approximations of stratification and matching to reduce the computation complexity. Extensive experimental results on two real-world datasets validate the effectiveness and efficiency of our method. We also show a simple example of using the item-level effects to provide insights for mitigating echo chambers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113721360",
                    "name": "Wei Cai"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "145196279",
                    "name": "Qifan Wang"
                },
                {
                    "authorId": "2209949178",
                    "name": "Tian Yang"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "1682914",
                    "name": "Congfu Xu"
                }
            ]
        },
        {
            "paperId": "febd6122c6a9c48aaae29296013cb16e07b0c0c7",
            "title": "Transferring Audio Deepfake Detection Capability across Languages",
            "abstract": "The proliferation of deepfake content has motivated a surge of detection studies. However, existing detection methods in the audio area exclusively work in English, and there is a lack of data resources in other languages. Cross-lingual deepfake detection, a critical but rarely explored area, urges more study. This paper conducts the first comprehensive study on the cross-lingual perspective of deepfake detection. We observe that English data enriched in deepfake algorithms can teach a detector the knowledge of various spoofing artifacts, contributing to performing detection across language domains. Based on the observation, we first construct a first-of-its-kind cross-lingual evaluation dataset including heterogeneous spoofed speech uttered in the two most widely spoken languages, then explored domain adaptation (DA) techniques to transfer the artifacts detection capability and propose effective and practical DA strategies fitting the cross-lingual scenario. Our adversarial-based DA paradigm teaches the model to learn real/fake knowledge while losing language dependency. Extensive experiments over 137-hour audio clips validate the adapted models can detect fake audio generated by unseen algorithms in the new domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36890675",
                    "name": "Zhongjie Ba"
                },
                {
                    "authorId": "2215403740",
                    "name": "Qing Wen"
                },
                {
                    "authorId": "2112625800",
                    "name": "Peng Cheng"
                },
                {
                    "authorId": "2125057617",
                    "name": "Yuwei Wang"
                },
                {
                    "authorId": "2087048590",
                    "name": "Feng Lin"
                },
                {
                    "authorId": "2152518508",
                    "name": "Liwang Lu"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                }
            ]
        },
        {
            "paperId": "18935a7b49b18f494ff2947cfcc9c79eb33bf582",
            "title": "3D Human Motion Prediction: A Survey",
            "abstract": "3D human motion prediction, predicting future poses from a given sequence, is an issue of great significance and challenge in computer vision and machine intelligence, which can help machines in understanding human behaviors. Due to the increasing development and understanding of Deep Neural Networks (DNNs) and the availability of large-scale human motion datasets, the human motion prediction has been remarkably advanced with a surge of interest among academia and industrial community. In this context, a comprehensive survey on 3D human motion prediction is conducted for the purpose of retrospecting and analyzing relevant works from existing released literature. In addition, a pertinent taxonomy is constructed to categorize these existing approaches for 3D human motion prediction. In this survey, relevant methods are categorized into three categories: human pose representation, network structure design, and \\textit{prediction target}. We systematically review all relevant journal and conference papers in the field of human motion prediction since 2015, which are presented in detail based on proposed categorizations in this survey. Furthermore, the outline for the public benchmark datasets, evaluation criteria, and performance comparisons are respectively presented in this paper. The limitations of the state-of-the-art methods are discussed as well, hoping for paving the way for future explorations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066420226",
                    "name": "Kedi Lyu"
                },
                {
                    "authorId": "2118438627",
                    "name": "Haipeng Chen"
                },
                {
                    "authorId": "2145312301",
                    "name": "Zhenguang Liu"
                },
                {
                    "authorId": "2157053934",
                    "name": "Beiqi Zhang"
                },
                {
                    "authorId": "2130611728",
                    "name": "Ruili Wang"
                }
            ]
        }
    ]
}