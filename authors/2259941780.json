{
    "authorId": "2259941780",
    "papers": [
        {
            "paperId": "4523a6cc05662360c9c33f2044c47d32c0eb8ae4",
            "title": "Generating Synthetic Fair Syntax-agnostic Data by Learning and Distilling Fair Representation",
            "abstract": "Data Fairness is a crucial topic due to the recent wide usage of AI powered applications. Most of the real-world data is filled with human or machine biases and when those data are being used to train AI models, there is a chance that the model will reflect the bias in the training data. Existing bias-mitigating generative methods based on GANs, Diffusion models need in-processing fairness objectives and fail to consider computational overhead while choosing computationally-heavy architectures, which may lead to high computational demands, instability and poor optimization performance. To mitigate this issue, in this work, we present a fair data generation technique based on knowledge distillation, where we use a small architecture to distill the fair representation in the latent space. The idea of fair latent space distillation enables more flexible and stable training of Fair Generative Models (FGMs). We first learn a syntax-agnostic (for any data type) fair representation of the data, followed by distillation in the latent space into a smaller model. After distillation, we use the distilled fair latent space to generate high-fidelity fair synthetic data. While distilling, we employ quality loss (for fair distillation) and utility loss (for data utility) to ensure that the fairness and data utility characteristics remain in the distilled latent space. Our approaches show a 5%, 5% and 10% rise in performance in fairness, synthetic sample quality and data utility, respectively, than the state-of-the-art fair generative model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30916819",
                    "name": "Md Fahim Sikder"
                },
                {
                    "authorId": "1392792012",
                    "name": "R. Ramachandranpillai"
                },
                {
                    "authorId": "3081699",
                    "name": "Daniel de Leng"
                },
                {
                    "authorId": "2259941780",
                    "name": "Fredrik Heintz"
                }
            ]
        },
        {
            "paperId": "6995779ac582c5f2436cfb82a3c8cf5ca72bae2f",
            "title": "Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks",
            "abstract": "Synthetic data generation offers a promising solution to enhance the usefulness of Electronic Healthcare Records (EHR) by generating realistic de-identified data. However, the existing literature primarily focuses on the quality of synthetic health data, neglecting the crucial aspect of fairness in downstream predictions. Consequently, models trained on synthetic EHR have faced criticism for producing biased outcomes in target tasks. These biases can arise from either spurious correlations between features or the failure of models to accurately represent sub-groups. To address these concerns, we present Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based synthetic data generator specifically designed for the healthcare domain. In order to tackle spurious correlations (i), we propose an information-constrained Data Generation Process (DGP) that enables the generator to learn a fair deterministic transformation based on a well-defined notion of algorithmic fairness. To overcome the challenge of capturing exact sub-group representations (ii), we incentivize the generator to preserve sub-group densities through score-based weighted sampling. This approach compels the generator to learn from underrepresented regions of the data manifold. To evaluate the effectiveness of our proposed method, we conduct extensive experiments using the Medical Information Mart for Intensive Care (MIMIC-III) database. Our results demonstrate that Bt-GAN achieves state-of-the-art accuracy while significantly improving fairness and minimizing bias amplification. Furthermore, we perform an in-depth explainability analysis to provide additional evidence supporting the validity of our study. In conclusion, our research introduces a novel and professional approach to addressing the limitations of synthetic data generation in the healthcare domain. By incorporating fairness considerations and leveraging advanced techniques such as GANs, we pave the way for more reliable and unbiased predictions in healthcare applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1392792012",
                    "name": "R. Ramachandranpillai"
                },
                {
                    "authorId": "30916819",
                    "name": "Md Fahim Sikder"
                },
                {
                    "authorId": "2297771217",
                    "name": "David Bergstrom"
                },
                {
                    "authorId": "2259941780",
                    "name": "Fredrik Heintz"
                }
            ]
        },
        {
            "paperId": "6e83c8a87cf0e5a88f705de4b1d2593c293cacc6",
            "title": "Grounding Stream Reasoning Research",
            "abstract": "In the last decade, there has been a growing interest in applying AI technologies to implement complex data analytics over data streams. To this end, researchers in various fields have been organ-ising a yearly event called the \u201cStream Reasoning Workshop\u201d to share perspectives, challenges",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2303497824",
                    "name": "Pieter Bonte"
                },
                {
                    "authorId": "1795889",
                    "name": "Jean-Paul Calbimonte"
                },
                {
                    "authorId": "2275259056",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "2539248",
                    "name": "Emanuele Della Valle"
                },
                {
                    "authorId": "2303497683",
                    "name": "Thomas Eiter"
                },
                {
                    "authorId": "2218847896",
                    "name": "Federico Giannini"
                },
                {
                    "authorId": "2259941780",
                    "name": "Fredrik Heintz"
                },
                {
                    "authorId": "2303492983",
                    "name": "Konstantin Schekotihin"
                },
                {
                    "authorId": "1409492270",
                    "name": "Danh Le-Phuoc"
                },
                {
                    "authorId": "1758781",
                    "name": "A. Mileo"
                },
                {
                    "authorId": "2303474184",
                    "name": "Patrik Schneider"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "1915156",
                    "name": "Jacopo Urbani"
                },
                {
                    "authorId": "2051295600",
                    "name": "Giacomo Ziffer"
                },
                {
                    "authorId": "3081699",
                    "name": "Daniel de Leng"
                },
                {
                    "authorId": "2290479774",
                    "name": "Della Valle"
                },
                {
                    "authorId": "2275256895",
                    "name": "Aidan Hogan"
                },
                {
                    "authorId": "2299957328",
                    "name": "Ian Horrocks"
                },
                {
                    "authorId": "2299956623",
                    "name": "Andreas Hotho"
                },
                {
                    "authorId": "1735243",
                    "name": "Lalana Kagal"
                }
            ]
        },
        {
            "paperId": "94541b9b7c6d5d73721260daf6cc5f0df8939cbf",
            "title": "Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data Free Distillation",
            "abstract": "This work presents Fair4Free, a novel generative model to generate synthetic fair data using data-free distillation in the latent space. Fair4Free can work on the situation when the data is private or inaccessible. In our approach, we first train a teacher model to create fair representation and then distil the knowledge to a student model (using a smaller architecture). The process of distilling the student model is data-free, i.e. the student model does not have access to the training dataset while distilling. After the distillation, we use the distilled model to generate fair synthetic samples. Our extensive experiments show that our synthetic samples outperform state-of-the-art models in all three criteria (fairness, utility and synthetic quality) with a performance increase of 5% for fairness, 8% for utility and 12% in synthetic quality for both tabular and image datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30916819",
                    "name": "Md Fahim Sikder"
                },
                {
                    "authorId": "3081699",
                    "name": "Daniel de Leng"
                },
                {
                    "authorId": "2259941780",
                    "name": "Fredrik Heintz"
                }
            ]
        },
        {
            "paperId": "c6a0ccda0ccd31ef064497f19a02650e29695826",
            "title": "FairX: A comprehensive benchmarking tool for model analysis using fairness, utility, and explainability",
            "abstract": "We present FairX, an open-source Python-based benchmarking tool designed for the comprehensive analysis of models under the umbrella of fairness, utility, and eXplainability (XAI). FairX enables users to train benchmarking bias-mitigation models and evaluate their fairness using a wide array of fairness metrics, data utility metrics, and generate explanations for model predictions, all within a unified framework. Existing benchmarking tools do not have the way to evaluate synthetic data generated from fair generative models, also they do not have the support for training fair generative models either. In FairX, we add fair generative models in the collection of our fair-model library (pre-processing, in-processing, post-processing) and evaluation metrics for evaluating the quality of synthetic fair data. This version of FairX supports both tabular and image datasets. It also allows users to provide their own custom datasets. The open-source FairX benchmarking package is publicly available at \\url{https://github.com/fahim-sikder/FairX}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30916819",
                    "name": "Md Fahim Sikder"
                },
                {
                    "authorId": "1392792012",
                    "name": "R. Ramachandranpillai"
                },
                {
                    "authorId": "3081699",
                    "name": "Daniel de Leng"
                },
                {
                    "authorId": "2259941780",
                    "name": "Fredrik Heintz"
                }
            ]
        },
        {
            "paperId": "48cfd2b77f096ddbb3130d79488b85c8115786ba",
            "title": "Fair Latent Deep Generative Models (FLDGMs) for Syntax-Agnostic and Fair Synthetic Data Generation",
            "abstract": ". Deep Generative Models (DGMs) for generating synthetic data with properties such as quality, diversity, \ufb01delity, and privacy is an important research topic. Fairness is one particular aspect that has not received the attention it deserves. One dif\ufb01culty is training DGMs with an in-process fairness objective, which can disturb the global convergence characteristics. To address this, we propose Fair Latent Deep Generative Models (FLDGMs) as enablers for more \ufb02exible and stable training of fair DGMs, by \ufb01rst learning a syntax-agnostic, model-agnostic fair latent representation (low dimensional) of the data. This separates the fairness optimization and data generation processes thereby boosting stability and optimization performance. Moreover, data generation in the low dimensional space enhances the accessibility of models by reducing computational demands. We conduct extensive experiments on image and tabular domains us-ing Generative Adversarial Networks (GANs) and Diffusion Models (DMs) and compare them to the state-of-the-art in terms of fairness and utility. Our proposed FLDGMs achieve superior performance in generating high-quality, high-\ufb01delity, and high-diversity fair synthetic data compared to the state-of-the-art fair generative models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1392792012",
                    "name": "R. Ramachandranpillai"
                },
                {
                    "authorId": "30916819",
                    "name": "Md Fahim Sikder"
                },
                {
                    "authorId": "2259941780",
                    "name": "Fredrik Heintz"
                }
            ]
        }
    ]
}