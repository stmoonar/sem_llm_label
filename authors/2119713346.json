{
    "authorId": "2119713346",
    "papers": [
        {
            "paperId": "2993ce1490e96062f9b9020d774eab02b7b00f9e",
            "title": "Everything We Hear: Towards Tackling Misinformation in Podcasts",
            "abstract": "Advances in generative AI, the proliferation of large multimodal models (LMMs), and democratized open access to these technologies have direct implications for the production and diffusion of misinformation. In this prequel, we address tackling misinformation in the unique and increasingly popular context of podcasts. The rise of podcasts as a popular medium for disseminating information across diverse topics necessitates a proactive strategy to combat the spread of misinformation. Inspired by the proven effectiveness of \\textit{auditory alerts} in contexts like collision alerts for drivers and error pings in mobile phones, our work envisions the application of auditory alerts as an effective tool to tackle misinformation in podcasts. We propose the integration of suitable auditory alerts to notify listeners of potential misinformation within the podcasts they are listening to, in real-time and without hampering listening experiences. We identify several opportunities and challenges in this path and aim to provoke novel conversations around instruments, methods, and measures to tackle misinformation in podcasts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2516584",
                    "name": "U. Gadiraju"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "5468a398cbb91b0f126e10e6a827a46ee1eefc9b",
            "title": "Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot",
            "abstract": "Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals\u2019 practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2279801138",
                    "name": "Lin Tian"
                },
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2279785688",
                    "name": "Halil Ali"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "5d750b51dd5371998dfea27f391b4113a7c9aa62",
            "title": "Towards Detecting and Mitigating Cognitive Bias in Spoken Conversational Search",
            "abstract": "Instruments such as eye-tracking devices have contributed to understanding how users interact with screen-based search engines. However, user-system interactions in audio-only channels -- as is the case for Spoken Conversational Search (SCS) -- are harder to characterize, given the lack of instruments to effectively and precisely capture interactions. Furthermore, in this era of information overload, cognitive bias can significantly impact how we seek and consume information -- especially in the context of controversial topics or multiple viewpoints. This paper draws upon insights from multiple disciplines (including information seeking, psychology, cognitive science, and wearable sensors) to provoke novel conversations in the community. To this end, we discuss future opportunities and propose a framework including multimodal instruments and methods for experimental designs and settings. We demonstrate preliminary results as an example. We also outline the challenges and offer suggestions for adopting this multimodal approach, including ethical considerations, to assist future researchers and practitioners in exploring cognitive biases in SCS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2285470234",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "d07549450f134edc015179ef5f28fb1cac1d1fad",
            "title": "Towards Investigating Biases in Spoken Conversational Search",
            "abstract": "Voice-based systems like Amazon Alexa, Google Assistant, and Apple Siri, along with the growing popularity of OpenAI's ChatGPT and Microsoft's Copilot, serve diverse populations, including visually impaired and low-literacy communities. This reflects a shift in user expectations from traditional search to more interactive question-answering models. However, presenting information effectively in voice-only channels remains challenging due to their linear nature. This limitation can impact the presentation of complex queries involving controversial topics with multiple perspectives. Failing to present diverse viewpoints may perpetuate or introduce biases and affect user attitudes. Balancing information load and addressing biases is crucial in designing a fair and effective voice-based system. To address this, we (i) review how biases and user attitude changes have been studied in screen-based web search, (ii) address challenges in studying these changes in voice-based settings like SCS, (iii) outline research questions, and (iv) propose an experimental setup with variables, data, and instruments to explore biases in a voice-based setting like Spoken Conversational Search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "0042d2419291bae774b1c9a201d4e554d829a64c",
            "title": "Fairness-Aware Question Answering for Intelligent Assistants",
            "abstract": "Conversational intelligent assistants, such as Amazon Alexa, Google Assistant, and Apple Siri, are a form of voice-only Question Answering (QA) system and have the potential to address complex information needs. However, at the moment they are mostly limited to answering with facts expressed in a few words. For example, when a user asks Google Assistant if coffee is good for their health, it responds by justifying why it is good for their health without shedding any light on the side effects coffee consumption might have \\citegao2020toward. Such limited exposure to multiple perspectives can lead to change in perceptions, preferences, and attitude of users, as well as to the creation and reinforcement of undesired cognitive biases. Getting such QA systems to provide a fair exposure to complex answers -- including those with opposing perspectives -- is an open research problem. In this research, I aim to address the problem of fairly exposing multiple perspectives and relevant answers to users in a multi-turn conversation without negatively impacting user satisfaction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                }
            ]
        },
        {
            "paperId": "5b0b7e5228029ac741424216183241eb6ec8c1bc",
            "title": "RMIT CIDDA IR at the TREC 2022 Fair Ranking Track",
            "abstract": "This report describes the participation of the RMIT CIDDA IR 1 group at the TREC 2022 Fair Ranking Track (Task 1). We submitted 8 runs with the aim to explore the role of explicit search result diversification, ranking fusion, and the use of a multi-criteria decision-making method to generate fair rankings considering multiple protected attributes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "73067160",
                    "name": "Marwah Alaofi"
                },
                {
                    "authorId": "2235485885",
                    "name": "Reham Abdullah Altalhi"
                },
                {
                    "authorId": "2884094",
                    "name": "Elham Naghizade"
                },
                {
                    "authorId": "1732541",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "48702898",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "1d4bff68f743f5ee5da2c9db84d8dff29722ee43",
            "title": "Evaluating Fairness in Argument Retrieval",
            "abstract": "Existing commercial search engines often struggle to represent different perspectives of a search query. Argument retrieval systems address this limitation of search engines and provide both positive (PRO) and negative (CON) perspectives about a user's information need on a controversial topic (e.g., climate change). The effectiveness of such argument retrieval systems is typically evaluated based on topical relevance and argument quality, without taking into account the often differing number of documents shown for the argument stances (PRO or CON). Therefore, systems may retrieve relevant passages, but with a biased exposure of arguments. In this work, we analyze a range of non-stochastic fairness-aware ranking and diversity metrics to evaluate the extent to which argument stances are fairly exposed in argument retrieval systems. Using the official runs of the argument retrieval task Ttouch\u00e9 at CLEF 2020, as well as synthetic data to control the amount and order of argument stances in the rankings, we show that systems with the best effectiveness in terms of topical relevance are not necessarily the most fair or the most diverse in terms of argument stance. The relationships we found between (un)fairness and diversity metrics shed light on how to evaluate group fairness -- in addition to topical relevance -- in argument retrieval settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "48702898",
                    "name": "Damiano Spina"
                },
                {
                    "authorId": "1732541",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "144456145",
                    "name": "W. Bruce Croft"
                }
            ]
        },
        {
            "paperId": "88c5ecde7a926c2b432d2e1da913984866f537ff",
            "title": "RMIT at TREC 2021 Fair Ranking Track",
            "abstract": "This report describes the data, the assumptions, methodology, and our results involved in the participation at the TREC 2021 Fair Ranking Track. While most of the fairness-aware re-ranking techniques require explicitly defining protected attributes, we tried to leverage the implicit features of the Wikimedia articles by using an implicit diversification technique to study the impact of diversification on a fair ranking problem",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "1732541",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "144456145",
                    "name": "W. Bruce Croft"
                }
            ]
        },
        {
            "paperId": "bd3b2de450b4771b3aaf05de422e9bd76ac2a635",
            "title": "Report on the future conversations workshop at CHIIR 2021",
            "abstract": "The Future Conversations workshop at CHIIR'21 looked to the future of search, recommendation, and information interaction to ask: where are the opportunities for conversational interactions? What do we need to do to get there? Furthermore, who stands to benefit? The workshop was hands-on and interactive. Rather than a series of technical talks, we solicited position statements on opportunities, problems, and solutions in conversational search in all modalities (written, spoken, or multimodal). This paper -co-authored by the organisers and participants of the workshop- summarises the submitted statements and the discussions we had during the two sessions of the workshop. Statements discussed during the workshop are available at https://bit.ly/FutureConversations2021Statements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "41202995",
                    "name": "Paul Thomas"
                },
                {
                    "authorId": "1798501",
                    "name": "Hideo Joho"
                },
                {
                    "authorId": "2231056",
                    "name": "Katriina Bystr\u00f6m"
                },
                {
                    "authorId": "143964550",
                    "name": "L. Clark"
                },
                {
                    "authorId": "2286321420",
                    "name": "Nick Craswell"
                },
                {
                    "authorId": "1817251",
                    "name": "M. Czerwinski"
                },
                {
                    "authorId": "1735704",
                    "name": "David Elsweiler"
                },
                {
                    "authorId": "1485464455",
                    "name": "Alexander Frummet"
                },
                {
                    "authorId": "2116089068",
                    "name": "Souvick Ghosh"
                },
                {
                    "authorId": "1840075",
                    "name": "Johannes Kiesel"
                },
                {
                    "authorId": "1783150",
                    "name": "Irene Lopatovska"
                },
                {
                    "authorId": "1801452",
                    "name": "Daniel J. McDuff"
                },
                {
                    "authorId": "66594372",
                    "name": "Selina Meyer"
                },
                {
                    "authorId": "143832672",
                    "name": "Ahmed Mourad"
                },
                {
                    "authorId": "2105439683",
                    "name": "Paul Owoicho"
                },
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "48936827",
                    "name": "D. Russell"
                },
                {
                    "authorId": "1780364",
                    "name": "Laurianne Sitbon"
                }
            ]
        }
    ]
}