{
    "authorId": "2168240441",
    "papers": [
        {
            "paperId": "52dd29bd1d968e5db8661aa0a9e1d3f5d6c8c827",
            "title": "MCIL: Multimodal Counterfactual Instance Learning for Low-resource Entity-based Multimodal Information Extraction",
            "abstract": "Multimodal information extraction (MIE) is a challenging task which aims to extract the structural information in free text coupled with the image for constructing the multimodal knowledge graph. The entity-based MIE tasks are based on the entity information to complete the specific tasks. However, the existing methods only investigated the entity-based MIE tasks under supervised learning with adequate labeled data. In the real-world scenario, collecting enough data and annotating the entity-based samples are time-consuming, and impractical. Therefore, we propose to investigate the entity-based MIE tasks under the low-resource settings. The conventional models are prone to overfitting on limited labeled data, which can result in poor performance. This is because the models tend to learn the bias existing in the limited samples, which can lead them to model the spurious correlations between multimodal features and task labels. To provide a more comprehensive understanding of the bias inherent in multimodal features of MIE samples, we decompose the features into image, entity, and context factors. Furthermore, we investigate the causal relationships between these factors and model performance, leveraging the structural causal model to delve into the correlations between the input features and output labels. Based on this, we propose the multimodal counterfactual instance learning framework to generate the counterfactual instances by the interventions on the limited observational samples. In the framework, we analyze the causal effect of the counterfactual instances and exploit it as a supervisory signal to maximize the effect for reducing the bias and improving the generalization of the model. Empirically, we evaluate the proposed method on the two public MIE benchmark datasets and the experimental results verify the effectiveness of it.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109060719",
                    "name": "Baohang Zhou"
                },
                {
                    "authorId": "100996634",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "2301654681",
                    "name": "Hongru Wang"
                },
                {
                    "authorId": "2110260640",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "cb5ddabab918e28ed36ab211f6c9ace6e476fb01",
            "title": "MELOV: Multimodal Entity Linking with Optimized Visual Features in Latent Space",
            "abstract": "Multimodal entity linking (MEL), which aligns ambiguous mentions within multimodal contexts to referent entities from multimodal knowledge bases, is essential for many natu-ral language processing applications. Previous MEL methods mainly focus on exploring complex multimodal interaction mechanisms to better capture coherence evidence between mentions and entities by mining complementary information. However, in real-world social media scenarios, vision modality often exhibits low quality, low value, or low relevance to the mention. Integrating such information directly will backfire, leading to a weakened consistency between mentions and their corresponding entities. In this paper, we propose a novel latent space vision feature optimization framework MELOV, which combines inter-modality and intra-modality optimizations to address these challenges. For the inter-modality optimization, we exploit the variational autoencoder to mine shared information and generate text-based visual features. For the intra-modality optimization, we consider the relationships between mentions and build graph convolutional network to aggregate the visual features of semantic similar neighbors. Extensive experiments on three benchmark datasets demonstrate the superiority of our proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "2309833618",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2110260640",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "2109060719",
                    "name": "Baohang Zhou"
                },
                {
                    "authorId": "2314896930",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "0941d750525d6dcea5c4a497ea8d80bd4e7bfba3",
            "title": "Incorporating Object-Level Visual Context for Multimodal Fine-Grained Entity Typing",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "100996634",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2273905684",
                    "name": "Wenbo Fan"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "2110260640",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "9823e7d0bc60968e0bc793593811092c8a0146ef",
            "title": "Selecting Key Views for Zero-Shot Entity Linking",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "100996634",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "2109060719",
                    "name": "Baohang Zhou"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                },
                {
                    "authorId": "2273574757",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "8c739b074de8d664617cdcc56805202ca1596b6e",
            "title": "Improving Zero-Shot Entity Linking Candidate Generation with Ultra-Fine Entity Type Information",
            "abstract": "Entity linking, which aims at aligning ambiguous entity mentions to their referent entities in a knowledge base, plays a key role in multiple natural language processing tasks. Recently, zero-shot entity linking task has become a research hotspot, which links mentions to unseen entities to challenge the generalization ability. For this task, the training set and test set are from different domains, and thus entity linking models tend to be overfitting due to the tendency of memorizing the properties of entities that appear frequently in the training set. We argue that general ultra-fine-grained type information can help the linking models to learn contextual commonality and improve their generalization ability to tackle the overfitting problem. However, in the zero-shot entity linking setting, any type information is not available and entities are only identified by textual descriptions. Thus, we first extract the ultra-fine entity type information from the entity textual descriptions. Then, we propose a hierarchical multi-task model to improve the high-level zero-shot entity linking candidate generation task by utilizing the entity typing task as an auxiliary low-level task, which introduces extracted ultra-fine type information into the candidate generation task. Experimental results demonstrate the effectiveness of utilizing the ultra-fine entity type information and our proposed method achieves state-of-the-art performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "100996634",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "2109060719",
                    "name": "Baohang Zhou"
                },
                {
                    "authorId": "2176479216",
                    "name": "Guoqing Zhao"
                },
                {
                    "authorId": "2007774059",
                    "name": "Xinde Wei"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "db433b75d947ca93bb99955d2e16083c9952e7a1",
            "title": "A Multi-Task Learning Framework for Chinese Medical Procedure Entity Normalization",
            "abstract": "Medical entity normalization is a fundamental task in medical natural language processing and clinical applications. The task aims to map medical mentions to standard entities in a given knowledge base. In this paper, we focus on Chinese medical procedure entity normalization. This task brings an extra multi-implication challenge that a mention may link to multiple standard entities. To perform the task, we propose a novel deep neural multi-task learning framework to jointly model implication number prediction and entity normalization. Our model utilizes the multi-head attention mechanism to provide mutual benefits between the two tasks. Experimental results show that our method achieves comparable performance compared with the baseline methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "2109060719",
                    "name": "Baohang Zhou"
                },
                {
                    "authorId": "100996634",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "e44f73d7ab12479b35d266ba9de5ac686f116daf",
            "title": "Multi-grained Label Refinement Network with Dependency Structures for Joint Intent Detection and Slot Filling",
            "abstract": "Slot filling and intent detection are two fundamental tasks in the field of natural language understanding. Due to the strong correlation between these two tasks, previous studies make efforts on modeling them with multi-task learning or designing feature interaction modules to improve the performance of each task. However, none of the existing approaches consider the relevance between the structural information of sentences and the label semantics of two tasks. The intent and semantic components of a utterance are dependent on the syntactic elements of a sentence. In this paper, we investigate a multi-grained label refinement network, which utilizes dependency structures and label semantic embeddings. Considering to enhance syntactic representations, we introduce the dependency structures of sentences into our model by graph attention layer. To capture the semantic dependency between the syntactic information and task labels, we combine the task specific features with corresponding label embeddings by attention mechanism. The experimental results demonstrate that our model achieves the competitive performance on two public datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109060719",
                    "name": "Baohang Zhou"
                },
                {
                    "authorId": "100996634",
                    "name": "Ying Zhang"
                },
                {
                    "authorId": "2168240441",
                    "name": "Xuhui Sui"
                },
                {
                    "authorId": "2086999859",
                    "name": "Kehui Song"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        }
    ]
}