{
    "authorId": "69863469",
    "papers": [
        {
            "paperId": "0c65dfacc858102af978debc10b56536fa186f20",
            "title": "Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration",
            "abstract": "Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel data-aware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "47099153",
                    "name": "Xiaoyu Qi"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2155699322",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "26bc0739dd4e21a58e1fa97f519e135258f76697",
            "title": "Reading Strategies for Graph Visualizations that Wrap Around in Torus Topology",
            "abstract": "We investigate reading strategies for node-link diagrams that wrap around the boundaries in a flattened torus topology by examining eye tracking data recorded in a previous controlled study. Prior work showed that torus drawing affords greater flexibility in clutter reduction than traditional node-link representations, but impedes link-and-path exploration tasks, while repeating tiles around boundaries aids comprehension. However, it remains unclear what strategies users apply in different wrapping settings. This is important for design implications for future work on more effective wrapped visualizations for network applications, and cyclic data that could benefit from wrapping. We perform visual-exploratory data analysis of gaze data, and conduct statistical tests derived from the patterns identified. Results show distinguishable gaze behaviors, with more visual glances and transitions between areas of interest in the non-replicated layout. Full-context has more successful visual searches than partial-context, but the gaze allocation indicates that the layout could be more space-efficient.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110719712",
                    "name": "Kun-Ting Chen"
                },
                {
                    "authorId": "31599161",
                    "name": "Quynh Quang Ngo"
                },
                {
                    "authorId": "1733564",
                    "name": "K. Kurzhals"
                },
                {
                    "authorId": "143885729",
                    "name": "K. Marriott"
                },
                {
                    "authorId": "145835767",
                    "name": "Tim Dwyer"
                },
                {
                    "authorId": "3020591",
                    "name": "M. Sedlmair"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "4e10e2e77d2dee62bc8496adc4753b973ce497ce",
            "title": "Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition",
            "abstract": "Datamation is designed to animate an analysis pipeline step by step, which is an intuitive and effective way to interpret the results from data analysis. However, creating a datamation is not easy. A qualified datamation needs to not only provide a correct analysis result but also ensure that the data flow and animation are coherent. Existing animation authoring tools focus on either leveraging algorithms to automatically generate an animation based on user-provided charts or building graphical user interfaces to provide a programming-free authoring environment for users. None of them are able to help users translate an analysis task into a series of data operations to form an analysis pipeline and visualize them as a datamation. To fill this gap, we introduce Datamator, an intelligent authoring tool developed to support datamation design and generation. It leverages a novel data query decomposition model to allow users to generate an initial datamation by simply inputting a data query in natural language. The initial datamation can be refined via rich interactions and a feedback mechanism is utilized to update the decomposition model based on user knowledge and preferences. Our system produces an animated sequence of visualizations driven by a set of low-level data actions. It supports unit visualizations, which provide a mapping from each data item to a unique visual mark. We demonstrate the effectiveness of Datamator via a series of evaluations including case studies, performance validation, and a controlled user study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118270393",
                    "name": "Yi Guo"
                },
                {
                    "authorId": "2059201609",
                    "name": "Nana Cao"
                },
                {
                    "authorId": "1410503485",
                    "name": "Ligan Cai"
                },
                {
                    "authorId": "2134152070",
                    "name": "Yanqiu Wu"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                },
                {
                    "authorId": "2064971223",
                    "name": "Danqing Shi"
                },
                {
                    "authorId": "2152520175",
                    "name": "Qing Chen"
                }
            ]
        },
        {
            "paperId": "d7031e46987b09b46e50dd9851a4c5ef4b100b34",
            "title": "Configuring augmented reality users: analysing YouTube commercials to understand industry expectations",
            "abstract": "ABSTRACT Commercial videos are often used to familiarise potential buyers and users with new technologies and their possibilities. In addition, presenting visions of future applications is a way to configure users and define social worlds of technology use. We analyse 30 YouTube videos featuring augmented reality (AR) devices in industrial manufacturing and construction, to explore how these commercial videos situate AR technology and future users by showcasing techno-euphoric promises and imagined use cases. With a video analysis based on Grounded Theory and Situational Analysis, we untangle the promises of AR for manufacturing and construction work; second, we present two prevailing configurations of AR users: \u2018experts in situ\u2019 and \u2018smart dummies\u2019; and third, we discuss how YouTube videos put forward developmental expectations. In addition, we identify discrepancies between expectations and foreseeable requirements in construction work. Finally, our research could contribute to a more holistic understanding of workplaces and socially robust AR applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121373872",
                    "name": "Ann-Kathrin Wortmeier"
                },
                {
                    "authorId": "1693399289",
                    "name": "Aim\u00e9e Sousa Calepso"
                },
                {
                    "authorId": "2072095954",
                    "name": "Cordula Kropp"
                },
                {
                    "authorId": "3020591",
                    "name": "M. Sedlmair"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "fa11e683e942382452a148f7d7c9b3ccae2cc184",
            "title": "Gazealytics: A Unified and Flexible Visual Toolkit for Exploratory and Comparative Gaze Analysis",
            "abstract": "We present a novel, web-based visual eye-tracking analytics tool called Gazealytics. Our open-source toolkit features a unified combination of gaze analytics features that support flexible exploratory analysis, along with annotation of areas of interest (AOI) and filter options based on multiple criteria to visually analyse eye tracking data across time and space. Gazealytics features coordinated views unifying spatiotemporal exploration of fixations and scanpaths for various analytical tasks. A novel matrix representation allows analysis of relationships between such spatial or temporal features. Data can be grouped across samples, user-defined AOIs or time windows of interest (TWIs) to support aggregate or filtered analysis of gaze activity. This approach exceeds the capabilities of existing systems by supporting flexible comparison between and within subjects, hypothesis generation, data analysis and communication of insights. We demonstrate in a walkthrough that Gazealytics supports multiple types of eye tracking datasets and analytical tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110719712",
                    "name": "Kun-Ting Chen"
                },
                {
                    "authorId": "2408484",
                    "name": "Arnaud Prouzeau"
                },
                {
                    "authorId": "147098636",
                    "name": "Joshua Langmead"
                },
                {
                    "authorId": "2159173436",
                    "name": "Ryan Whitelock-Jones"
                },
                {
                    "authorId": "2159175594",
                    "name": "Lee Lawrence"
                },
                {
                    "authorId": "145835767",
                    "name": "Tim Dwyer"
                },
                {
                    "authorId": "2433007",
                    "name": "C. Hurter"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                },
                {
                    "authorId": "25167169",
                    "name": "Sarah Goodwin"
                }
            ]
        },
        {
            "paperId": "05fc3f1ce154aad007fb4ada6fe005db287de8bb",
            "title": "Scalability in Visualization",
            "abstract": "We introduce a conceptual model for scalability designed for visualization research. With this model, we systematically analyze over 120 visualization publications from 1990 to 2020 to characterize the different notions of scalability in these works. While many article have addressed scalability issues, our survey identifies a lack of consistency in the use of the term in the visualization research community. We address this issue by introducing a consistent terminology meant to help visualization researchers better characterize the scalability aspects in their research. It also helps in providing multiple methods for supporting the claim that a work is \u201cscalable.\u201d Our model is centered around an effort function with inputs and outputs. The inputs are the problem size and resources, whereas the outputs are the actual efforts, for instance, in terms of computational run time or visual clutter. We select representative examples to illustrate different approaches and facets of what scalability can mean in visualization literature. Finally, targeting the diverse crowd of visualization researchers without a scalability tradition, we provide a set of recommendations for how scalability can be presented in a clear and consistent way to improve fair comparison between visualization techniques and systems and foster reproducibility.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49338946",
                    "name": "Ga\u00eblle Richer"
                },
                {
                    "authorId": "1379976631",
                    "name": "A. Pister"
                },
                {
                    "authorId": "2030899622",
                    "name": "Moataz Abdelaal"
                },
                {
                    "authorId": "144381703",
                    "name": "Jean-Daniel Fekete"
                },
                {
                    "authorId": "3020591",
                    "name": "M. Sedlmair"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "0c7853af737acae5b293554d976059b61118296b",
            "title": "Efficient Update of Redundancy Matrices for Truss and Frame Structures",
            "abstract": "Redundancy matrices provide insights into the load carrying behavior of\nstatically indeterminate structures. This information can be employed for the\ndesign and analysis of structures with regard to certain objectives, for\nexample reliability, robustness, or adaptability. In this context, the\nstructure is often iteratively examined with the help of slight adjustments.\nHowever, this procedure generally requires a high computational effort for the\nrecalculation of the redundancy matrix due to the necessity of costly matrix\noperations. This paper addresses this problem by providing generic algebraic\nformulations for efficiently updating the redundancy matrix (and related\nmatrices). The formulations include various modifications like adding,\nremoving, and exchanging elements and are applicable to truss and frame\nstructures. With several examples, we demonstrate the interaction between the\nformulas and their mechanical interpretation. Finally, a performance test for a\nscaleable structure is presented.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1388776013",
                    "name": "Tim Krake"
                },
                {
                    "authorId": "46191618",
                    "name": "M. V. Scheven"
                },
                {
                    "authorId": "51218811",
                    "name": "Jan Gade"
                },
                {
                    "authorId": "2030899622",
                    "name": "Moataz Abdelaal"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                },
                {
                    "authorId": "49941157",
                    "name": "M. Bischoff"
                }
            ]
        },
        {
            "paperId": "12e5980d64c6532f09da34c3cdf40704a996092a",
            "title": "Uncertainty Visualization: Concepts, Methods, and Applications in Biological Data Visualization",
            "abstract": "This paper provides an overview of uncertainty visualization in general, along with specific examples of applications in bioinformatics. Starting from a processing and interaction pipeline of visualization, components are discussed that are relevant for handling and visualizing uncertainty introduced with the original data and at later stages in the pipeline, which shows the importance of making the stages of the pipeline aware of uncertainty and allowing them to propagate uncertainty. We detail concepts and methods for visual mappings of uncertainty, distinguishing between explicit and implict representations of distributions, different ways to show summary statistics, and combined or hybrid visualizations. The basic concepts are illustrated for several examples of graph visualization under uncertainty. Finally, this review paper discusses implications for the visualization of biological data and future research directions.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        },
        {
            "paperId": "15e6169e60c1c8caf0f5757aab51760c4cace7d2",
            "title": "Impact of Gaze Uncertainty on AOIs in Information Visualisations",
            "abstract": "Gaze-based analysis of areas of interest (AOIs) is widely used in information visualisation research to understand how people explore visualisations or assess the quality of visualisations concerning key characteristics such as memorability. However, nearby AOIs in visualisations amplify the uncertainty caused by the gaze estimation error, which strongly influences the mapping between gaze samples or fixations and different AOIs. We contribute a novel investigation into gaze uncertainty and quantify its impact on AOI-based analysis on visualisations using two novel metrics: the Flipping Candidate Rate (FCR) and Hit Any AOI Rate (HAAR). Our analysis of 40 real-world visualisations, including human gaze and AOI annotations, shows that gaze uncertainty frequently and significantly impacts the analysis conducted in AOI-based studies. Moreover, we analysed four visualisation types and found that bar and scatter plots are usually designed in a way that causes more uncertainty than line and pie plots in gaze-based analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144276894",
                    "name": "Yao Wang"
                },
                {
                    "authorId": "46206249",
                    "name": "Maurice Koch"
                },
                {
                    "authorId": "31944767",
                    "name": "Mihai B\u00e2ce"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                },
                {
                    "authorId": "3194727",
                    "name": "A. Bulling"
                }
            ]
        },
        {
            "paperId": "1d1198106540e92d4f5522005fcddd72e26212b8",
            "title": "Reduced Connectivity for Local Bilinear Jacobi Sets",
            "abstract": "We present a new topological connection method for the local bilinear computation of Jacobi sets that improves the visual representation while preserving the topological structure and geometric configuration. To this end, the topological structure of the local bilinear method is utilized, which is given by the nerve complex of the traditional piecewise linear method. Since the nerve complex consists of higher-dimensional simplices, the local bilinear method (visually represented by the 1-skeleton of the nerve complex) leads to clutter via crossings of line segments. Therefore, we propose a homotopy-equivalent representation that uses different collapses and edge contractions to remove such artifacts. Our new connectivity method is easy to implement, comes with only little overhead, and results in a less cluttered representation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181503084",
                    "name": "Daniel Klotzl"
                },
                {
                    "authorId": "1388776013",
                    "name": "Tim Krake"
                },
                {
                    "authorId": "24803086",
                    "name": "Youjia Zhou"
                },
                {
                    "authorId": "21667279",
                    "name": "J. Stober"
                },
                {
                    "authorId": "2056592395",
                    "name": "K. Schulte"
                },
                {
                    "authorId": "1706029",
                    "name": "I. Hotz"
                },
                {
                    "authorId": "2143669503",
                    "name": "Bei Wang"
                },
                {
                    "authorId": "69863469",
                    "name": "D. Weiskopf"
                }
            ]
        }
    ]
}