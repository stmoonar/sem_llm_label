{
    "authorId": "2298899402",
    "papers": [
        {
            "paperId": "4de94c928ad1d7c5b481178dd4f31c3a7570be49",
            "title": "FALE: Fairness-Aware ALE Plots for Auditing Bias in Subgroups",
            "abstract": "Fairness is steadily becoming a crucial requirement of Machine Learning (ML) systems. A particularly important notion is subgroup fairness, i.e., fairness in subgroups of individuals that are defined by more than one attributes. Identifying bias in subgroups can become both computationally challenging, as well as problematic with respect to comprehensibility and intuitiveness of the finding to end users. In this work we focus on the latter aspects; we propose an explainability method tailored to identifying potential bias in subgroups and visualizing the findings in a user friendly manner to end users. In particular, we extend the ALE plots explainability method, proposing FALE (Fairness aware Accumulated Local Effects) plots, a method for measuring the change in fairness for an affected population corresponding to different values of a feature (attribute). We envision FALE to function as an efficient, user friendly, comprehensible and reliable first-stage tool for identifying subgroups with potential bias issues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2298899402",
                    "name": "Nikolas Theologitis"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                }
            ]
        }
    ]
}