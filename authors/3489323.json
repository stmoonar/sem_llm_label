{
    "authorId": "3489323",
    "papers": [
        {
            "paperId": "6e9847b18e2a606d77485a1e27dc64d7ee320101",
            "title": "Ontolo-CI: Continuous data validation with ShEx",
            "abstract": "The amount of public linked data published on the Web has been growing more and more over the last years. In order to keep the consistency of this continuously-growing base of datasets, data validation is a necessity for data publishers and maintainers. To address such validation of ontologies, there are mainly two shapes-based languages, e.g. ShEx and SHACL. The former is pointed out as a concise, formal, modeling approach, while the second is a W3C recommendation for data validation. SHACL already has available tools to perform validation on the fly, but ShEx still lacks this feature. In order to reduce this gap, this work presents Ontolo-CI: a tool for automated data validation, capable of accepting ShEx shapes as input, allowing users to validate their data on the fly through an CI/CD approach, by using GitHub Actions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "1729679",
                    "name": "Jose Emilio Labra Gayo"
                },
                {
                    "authorId": "2008181010",
                    "name": "Guillermo Facundo Colunga"
                },
                {
                    "authorId": "2057696866",
                    "name": "Pablo Menendez"
                }
            ]
        },
        {
            "paperId": "21785c2ecacfd60ecf5c74703ed74a14a2d55106",
            "title": "A Visual SHACL Shapes Editor Based On OntoPad",
            "abstract": "On the Semantic Web, vocabularies and ontologies play a fundamental role to express the terminology and rules of certain domains. New technologies like SHACL provide the possibility to express data schemata specific to certain data sets, applications, and domains. However, the domain modeling process is collaborative and when using RDF, it requires technical knowledge. In this paper, we present a tool to support a two-step-process to model a terminology and a schema with a combined graphical RDF Schema editor and visual SHACL editor. This tool allows domain experts to create a terminology and schema without the need for a deep understanding of RDF Schema or SHACL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258592",
                    "name": "Natanael Arndt"
                },
                {
                    "authorId": "39460549",
                    "name": "Andr\u00e9 Valdestilhas"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "2016113016",
                    "name": "Andrea Cimmino Arriaga"
                },
                {
                    "authorId": "1749965",
                    "name": "Konrad H\u00f6ffner"
                },
                {
                    "authorId": "29356676",
                    "name": "Thomas Riechert"
                }
            ]
        },
        {
            "paperId": "969bab88baf803ee686663d988f9ea55b3601461",
            "title": "Where is Linked Data in Question Answering over Linked Data?",
            "abstract": "We argue that \"Question Answering with Knowledge Base\" and \"Question Answering over Linked Data\" are currently two instances of the same problem, despite one explicitly declares to deal with Linked Data. We point out the lack of existing methods to evaluate question answering on datasets which exploit external links to the rest of the cloud or share common schema. To this end, we propose the creation of new evaluation settings to leverage the advantages of the Semantic Web to achieve AI-complete question answering.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1869895",
                    "name": "Tommaso Soru"
                },
                {
                    "authorId": "2522516",
                    "name": "Edgard Marx"
                },
                {
                    "authorId": "39460549",
                    "name": "Andr\u00e9 Valdestilhas"
                },
                {
                    "authorId": "2705621",
                    "name": "Diego Moussallem"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "144126658",
                    "name": "Mohammad Saleem"
                }
            ]
        },
        {
            "paperId": "37e73c72ea1813e993ab01b4602d19b0d7a6798a",
            "title": "Neural Machine Translation for Query Construction and Composition",
            "abstract": "Research on question answering with knowledge base has recently seen an increasing use of deep architectures. In this extended abstract, we study the application of the neural machine translation paradigm for question parsing. We employ a sequence-to-sequence model to learn graph patterns in the SPARQL graph query language and their compositions. Instead of inducing the programs through question-answer pairs, we expect a semi-supervised approach, where alignments between questions and queries are built through templates. We argue that the coverage of language utterances can be expanded using late notable works in natural language generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1869895",
                    "name": "Tommaso Soru"
                },
                {
                    "authorId": "2522516",
                    "name": "Edgard Marx"
                },
                {
                    "authorId": "39460549",
                    "name": "Andr\u00e9 Valdestilhas"
                },
                {
                    "authorId": "145538480",
                    "name": "Diego Esteves"
                },
                {
                    "authorId": "2705621",
                    "name": "Diego Moussallem"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                }
            ]
        },
        {
            "paperId": "814b9ca695a861dea036ae62a56d2d31dcbcb57b",
            "title": "ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies",
            "abstract": "The ML-Schema, proposed by the W3C Machine Learning Schema Community Group, is a top-level ontology that provides a set of classes, properties, and restrictions for representing and interchanging information on machine learning algorithms, datasets, and experiments. It can be easily extended and specialized and it is also mapped to other more domain-specific ontologies developed in the area of machine learning and data mining. In this paper we overview existing state-of-the-art machine learning interchange formats and present the first release of ML-Schema, a canonical format resulted of more than seven years of experience among different research institutions. We argue that exposing semantics of machine learning algorithms, models, and experiments through a canonical format may pave the way to better interpretability and to realistically achieve the full interoperability of experiments regardless of platform or adopted workflow solution.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "145538480",
                    "name": "Diego Esteves"
                },
                {
                    "authorId": "1975411",
                    "name": "Agnieszka Lawrynowicz"
                },
                {
                    "authorId": "145066785",
                    "name": "P. Panov"
                },
                {
                    "authorId": "3284305",
                    "name": "L. Soldatova"
                },
                {
                    "authorId": "1869895",
                    "name": "Tommaso Soru"
                },
                {
                    "authorId": "1717534",
                    "name": "J. Vanschoren"
                },
                {
                    "authorId": "46195484",
                    "name": "Hamid Zafar"
                }
            ]
        },
        {
            "paperId": "00bff0b686adf6b17a7a058fc5811c1e5d7694ab",
            "title": "SPARQL as a Foreign Language",
            "abstract": "In the last years, the Linked Data Cloud has achieved a size of more than 100 billion facts pertaining to a multitude of domains. However, accessing this information has been significantly challenging for lay users. Approaches to problems such as Question Answering on Linked Data and Link Discovery have notably played a role in increasing information access. These approaches are often based on handcrafted and/or statistical models derived from data observation. Recently, Deep Learning architectures based on Neural Networks called seq2seq have shown to achieve state-of-the-art results at translating sequences into sequences. In this direction, we propose Neural SPARQL Machines, end-to-end deep architectures to translate any natural language expression into sentences encoding SPARQL queries. Our preliminary results, restricted on selected DBpedia classes, show that Neural SPARQL Machines are a promising approach for Question Answering on Linked Data, as they can deal with known problems such as vocabulary mismatch and perform graph pattern composition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1869895",
                    "name": "Tommaso Soru"
                },
                {
                    "authorId": "2522516",
                    "name": "Edgard Marx"
                },
                {
                    "authorId": "2705621",
                    "name": "Diego Moussallem"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "39460549",
                    "name": "Andr\u00e9 Valdestilhas"
                },
                {
                    "authorId": "145538480",
                    "name": "Diego Esteves"
                },
                {
                    "authorId": "32124073",
                    "name": "C. Baron"
                }
            ]
        },
        {
            "paperId": "0b9c2d76835f45639a20b4a8a9d6818897916f84",
            "title": "IDOL: Comprehensive & Complete LOD Insights",
            "abstract": "Over the last decade, we observed a steadily increasing amount of RDF datasets made available on the web of data. The decentralized nature of the web, however, makes it hard to identify all these datasets. Even more so, when downloadable data distributions are discovered, only insufficient metadata is available to describe the datasets properly, thus posing barriers on its usefulness and reuse. In this paper, we describe an attempt to exhaustively identify the whole linked open data cloud by harvesting metadata from multiple sources, providing insights about duplicated data and the general quality of the available metadata. This was only possible by using a probabilistic data structure called Bloom filter. Finally, we published a dump file containing metadata which can further be used to enrich existent datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32124073",
                    "name": "C. Baron"
                },
                {
                    "authorId": "2627116",
                    "name": "D. Kontokostas"
                },
                {
                    "authorId": "35114918",
                    "name": "Amit Kirschenbaum"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "145538480",
                    "name": "Diego Esteves"
                },
                {
                    "authorId": "2024066",
                    "name": "Sebastian Hellmann"
                }
            ]
        },
        {
            "paperId": "17ee2a0d2507639c28788c0bd29ad23ec3814219",
            "title": "Investigating Explorability of DBpedia and its Ontology",
            "abstract": "DBpedia has existed for almost over a decade now. Although the data and the community created ontology have received immense investment, good tools to query and explore the data are still rare. In this paper, we present a prototype that attempts to break down complexity of graph querying into simple and guided steps. During the implementation of our DBpedia Explorer, we faced many barriers that can be traced back to a lack of data quality as well as the design of the DBpedia Ontology. We investigated these problems in detail based on a small sub-graph of DBpedia and gained valuable insights that will hopefully allow us to apply data transformation and fixes to DBpedia that will be beneficial for browsing and querying of the data in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37386609",
                    "name": "J. Forberg"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "2024066",
                    "name": "Sebastian Hellmann"
                }
            ]
        },
        {
            "paperId": "c485e410f586a64feaf8a3f6e1d2e0d52e80af0c",
            "title": "TANKER: Distributed Architecture for Named EntityRecognition and Disambiguation",
            "abstract": "Named Entity Recognition and Disambiguation (NERD) systems have recently been widely researched to deal with the significant growth of the Web. NERD systems are crucial for several Natural Language Processing (NLP) tasks such as summarization, understanding, and machine translation. However, there is no standard interface specification, i.e. these systems may vary significantly either for exporting their outputs or for processing the inputs. Thus, when a given company desires to implement more than one NERD system, the process is quite exhaustive and prone to failure. In addition, industrial solutions demand critical requirements, e.g., large-scale processing, completeness, versatility, and licenses. Commonly, these requirements impose a limitation, making good NERD models to be ignored by companies. This paper presents TANKER, a distributed architecture which aims to overcome scalability, reliability and failure tolerance limitations related to industrial needs by combining NERD systems. To this end, TANKER relies on a micro-services oriented architecture, which enables agile development and delivery of complex enterprise applications. In addition, TANKER provides a standardized API which makes possible to combine several NERD systems at once.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144318941",
                    "name": "Sandro Coelho"
                },
                {
                    "authorId": "2705621",
                    "name": "Diego Moussallem"
                },
                {
                    "authorId": "3489323",
                    "name": "G. Publio"
                },
                {
                    "authorId": "145538480",
                    "name": "Diego Esteves"
                }
            ]
        }
    ]
}