{
    "authorId": "2275185317",
    "papers": [
        {
            "paperId": "1fbbaa475e93c2d851344c5181a0e39a99324aca",
            "title": "Multi-view Content-aware Indexing for Long Document Retrieval",
            "abstract": "Long document question answering (DocQA) aims to answer questions from long documents over 10k words. They usually contain content structures such as sections, sub-sections, and paragraph demarcations. However, the indexing methods of long documents remain under-explored, while existing systems generally employ fixed-length chunking. As they do not consider content structures, the resultant chunks can exclude vital information or include irrelevant content. Motivated by this, we propose the Multi-view Content-aware indexing (MC-indexing) for more effective long DocQA via (i) segment structured document into content chunks, and (ii) represent each content chunk in raw-text, keywords, and summary views. We highlight that MC-indexing requires neither training nor fine-tuning. Having plug-and-play capability, it can be seamlessly integrated with any retrievers to boost their performance. Besides, we propose a long DocQA dataset that includes not only question-answer pair, but also document structure and answer scope. When compared to state-of-art chunking schemes, MC-indexing has significantly increased the recall by 42.8%, 30.0%, 23.9%, and 16.3% via top k= 1.5, 3, 5, and 10 respectively. These improved scores are the average of 8 widely used retrievers (2 sparse and 6 dense) via extensive experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2151790894",
                    "name": "Derrick-Goh-Xin Deik"
                },
                {
                    "authorId": "2297951506",
                    "name": "Yi Quan Lee"
                },
                {
                    "authorId": "2298263602",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2297935844",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2284302963",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "2297898895",
                    "name": "Yong Liu"
                }
            ]
        },
        {
            "paperId": "3b0b63bccb427de01c3502326f15719b97c9e9bf",
            "title": "Aligning Crowd Feedback via Distributional Preference Reward Modeling",
            "abstract": "Deep Reinforcement Learning is widely used for aligning Large Language Models (LLM) with human preference. However, the conventional reward modelling is predominantly dependent on human annotations provided by a select cohort of individuals. Such dependence may unintentionally result in skewed models that reflect the inclinations of these annotators, thereby failing to adequately represent the wider population's expectations. We propose the Distributional Preference Reward Model (DPRM), a simple yet effective framework to align large language models with diverse human preferences. To this end, we characterize multiple preferences by a categorical distribution and introduce a Bayesian updater to accommodate shifted or new preferences. On top of that, we design an optimal-transportation-based loss to calibrate DPRM to align with the preference distribution. Finally, the expected reward is utilized to fine-tune an LLM policy to generate responses favoured by the population. Our experiments show that DPRM significantly enhances the alignment of LLMs with population preference, yielding more accurate, unbiased, and contextually appropriate responses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284449061",
                    "name": "Dexun Li"
                },
                {
                    "authorId": "2284302963",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2151790894",
                    "name": "Derrick-Goh-Xin Deik"
                },
                {
                    "authorId": "2284295184",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2293939763",
                    "name": "Yong Liu"
                }
            ]
        },
        {
            "paperId": "462d7a06a8f0c608a5bd79931cee067c7cd47902",
            "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control",
            "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution for mitigating hallucinations of large language models (LLMs) with retrieved external knowledge. Adaptive RAG enhances this approach by enabling dynamic retrieval during generation, activating retrieval only when the query exceeds LLM's internal knowledge. Existing methods primarily focus on detecting LLM's confidence via statistical uncertainty. Instead, we present the first attempts to solve adaptive RAG from a representation perspective and develop an inherent control-based framework, termed \\name. Specifically, we extract the features that represent the honesty and confidence directions of LLM and adopt them to control LLM behavior and guide retrieval timing decisions. We also design a simple yet effective query formulation strategy to support adaptive retrieval. Experiments show that \\name is superior to existing adaptive RAG methods on a diverse set of tasks, the honesty steering can effectively make LLMs more honest and confidence monitoring is a promising indicator of retrieval trigger.Our code is available at \\url{https://github.com/HSLiu-Initial/CtrlA}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Huanshuo Liu"
                },
                {
                    "authorId": "2298263602",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2324709485",
                    "name": "Zhijiang Guo"
                },
                {
                    "authorId": "2324530716",
                    "name": "Jing Wang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2297935844",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2297951506",
                    "name": "Yi Quan Lee"
                },
                {
                    "authorId": "2284302963",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": null,
                    "name": "Yong Liu"
                }
            ]
        },
        {
            "paperId": "57a3d2f141f4ed5348c47f2f98601cf68aedd403",
            "title": "Collaborative Cross-modal Fusion with Large Language Model for Recommendation",
            "abstract": "Despite the success of conventional collaborative filtering (CF) approaches for recommendation systems, they exhibit limitations in leveraging semantic knowledge within the textual attributes of users and items. Recent focus on the application of large language models for recommendation (LLM4Rec) has highlighted their capability for effective semantic knowledge capture. However, these methods often overlook the collaborative signals in user behaviors. Some simply instruct-tune a language model, while others directly inject the embeddings of a CF-based model, lacking a synergistic fusion of different modalities. To address these issues, we propose a framework of Collaborative Cross-modal Fusion with Large Language Models, termed CCF-LLM, for recommendation. In this framework, we translate the user-item interactions into a hybrid prompt to encode both semantic knowledge and collaborative signals, and then employ an attentive cross-modal fusion strategy to effectively fuse latent embeddings of both modalities. Extensive experiments demonstrate that CCF-LLM outperforms existing methods by effectively utilizing semantic and collaborative signals in the LLM4Rec context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189874901",
                    "name": "Zhong-Yang Liu"
                },
                {
                    "authorId": "2316357146",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2316390997",
                    "name": "Yuan Fang"
                }
            ]
        },
        {
            "paperId": "ac457964969cdf99650acacb65cd84985eb84863",
            "title": "Tired of Plugins? Large Language Models Can Be End-To-End Recommenders",
            "abstract": "Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose a novel strategy to structure all items into an item tree, which can be dynamically updated and effectively retrieved. UniLLMRec shows promising zero-shot results in comparison with conventional supervised models. Additionally, it boasts high efficiency, reducing the input token need by 86% compared to existing LLM-based models. Such efficiency not only accelerates task completion but also optimizes resource utilization. To facilitate model understanding and to ensure reproducibility, we have made our code publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294381452",
                    "name": "Wenlin Zhang"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "cb1bfd79445b7c4838cf59b6a93c898a8270f42e",
            "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control",
            "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution for mitigating hallucinations of large language models (LLMs) with retrieved exter-nal knowledge. Adaptive RAG enhances this approach by dynamically assessing the retrieval necessity, aiming to balance external and internal knowledge usage. However, existing adaptive RAG methods primarily realize retrieval on demand by relying on superficially verbalize-based or probability-based feedback of LLMs, or directly fine-tuning LLMs via carefully crafted datasets, resulting in unreliable retrieval necessity decisions, heavy extra costs, and sub-optimal response generation. We present the first attempts to delve into the internal states of LLMs to mitigate such issues by introducing an effective probe-guided adaptive RAG framework, termed C TRL A. Specifically, C TRL A employs an honesty probe to regulate the LLM\u2019s behavior by manipulating its representations for increased honesty, and a confidence probe to monitor the internal states of LLM and assess confidence levels, determining the retrieval necessity during generation. Experiments show that C TRL A is superior to existing adaptive RAG methods on a diverse set of tasks, the honesty control can effectively make LLMs more honest and confidence monitoring is proven to be a promising indicator of retrieval trigger. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2167046956",
                    "name": "Huanshuo Liu"
                },
                {
                    "authorId": "2298263602",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2681038",
                    "name": "Zhijiang Guo"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2297935844",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2297951506",
                    "name": "Yi Quan Lee"
                },
                {
                    "authorId": "2284302963",
                    "name": "Cong Zhang"
                },
                {
                    "authorId": "2297898895",
                    "name": "Yong Liu"
                }
            ]
        },
        {
            "paperId": "de9f15655b268a052b94d15d23646758637d8cae",
            "title": "CoIR: A Comprehensive Benchmark for Code Information Retrieval Models",
            "abstract": "Despite the substantial success of Information Retrieval (IR) in various NLP tasks, most IR systems predominantly handle queries and corpora in natural language, neglecting the domain of code retrieval. Code retrieval is critically important yet remains under-explored, with existing methods and benchmarks inadequately representing the diversity of code in various domains and tasks. Addressing this gap, we present \\textbf{\\name} (\\textbf{Co}de \\textbf{I}nformation \\textbf{R}etrieval Benchmark), a robust and comprehensive benchmark specifically designed to assess code retrieval capabilities. \\name comprises \\textbf{ten} meticulously curated code datasets, spanning \\textbf{eight} distinctive retrieval tasks across \\textbf{seven} diverse domains. We first discuss the construction of \\name and its diverse dataset composition. Further, we evaluate nine widely used retrieval models using \\name, uncovering significant difficulties in performing code retrieval tasks even with state-of-the-art systems. To facilitate easy adoption and integration within existing research workflows, \\name has been developed as a user-friendly Python framework, readily installable via pip. It shares same data schema as other popular benchmarks like MTEB and BEIR, enabling seamless cross-benchmark evaluations. Through \\name, we aim to invigorate research in the code retrieval domain, providing a versatile benchmarking tool that encourages further development and exploration of code retrieval systems\\footnote{\\url{ https://github.com/CoIR-team/coir}}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2297935844",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2297951506",
                    "name": "Yi Quan Lee"
                },
                {
                    "authorId": "2154454480",
                    "name": "Wei Xia"
                },
                {
                    "authorId": "2310196106",
                    "name": "Yichun Yin"
                },
                {
                    "authorId": "2298263602",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "2297898895",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2282544603",
                    "name": "Yasheng Wang"
                },
                {
                    "authorId": "2284295184",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "b6bc1590ae632fd8325fab23edf5c333a9a7723c",
            "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
            "abstract": "Click-Through Rate (CTR) prediction is a crucial task in online recommendation platforms as it involves estimating the probability of user engagement with advertisements or items by clicking on them. Given the availability of various services like online shopping, ride-sharing, food delivery, and professional services on commercial platforms, recommendation systems in these platforms are required to make CTR predictions across multiple domains rather than just a single domain. However, multi-domain click-through rate (MDCTR) prediction remains a challenging task in online recommendation due to the complex mutual influence between domains. Traditional MDCTR models typically encode domains as discrete identifiers, ignoring rich semantic information underlying. Consequently, they can hardly generalize to new domains. Besides, existing models can be easily dominated by some specific domains, which results in significant performance drops in the other domains (i.e. the\"seesaw phenomenon\"). In this paper, we propose a novel solution Uni-CTR to address the above challenges. Uni-CTR leverages a backbone Large Language Model (LLM) to learn layer-wise semantic representations that capture commonalities between domains. Uni-CTR also uses several domain-specific networks to capture the characteristics of each domain. Note that we design a masked loss strategy so that these domain-specific networks are decoupled from backbone LLM. This allows domain-specific networks to remain unchanged when incorporating new or removing domains, thereby enhancing the flexibility and scalability of the system significantly. Experimental results on three public datasets show that Uni-CTR outperforms the state-of-the-art (SOTA) MDCTR models significantly. Furthermore, Uni-CTR demonstrates remarkable effectiveness in zero-shot prediction. We have applied Uni-CTR in industrial scenarios, confirming its efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275537250",
                    "name": "Zichuan Fu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2275119462",
                    "name": "Mengchen Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        }
    ]
}