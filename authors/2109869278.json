{
    "authorId": "2109869278",
    "papers": [
        {
            "paperId": "087e1ceb9e62b2e3732247caa84beb223804178e",
            "title": "Rating Distribution Calibration for Selection Bias Mitigation in Recommendations",
            "abstract": "Real-world recommendation datasets have been shown to be subject to selection bias, which can challenge recommendation models to learn real preferences of users, so as to make accurate recommendations. Existing approaches to mitigate selection bias, such as data imputation and inverse propensity score, are sensitive to the quality of the additional imputation or propensity estimation models. To break these limitations, in this work, we propose a novel self-supervised learning (SSL) framework, i.e., Rating Distribution Calibration (RDC), to tackle selection bias without introducing additional models. In addition to the original training objective, we introduce a rating distribution calibration loss. It aims to correct the predicted rating distribution of biased users by taking advantage of that of their similar unbiased users. We empirically evaluate RDC on two real-world datasets and one synthetic dataset. The experimental results show that RDC outperforms the original model as well as the state-of-the-art debiasing approaches by a significant margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "97705488",
                    "name": "Da Tang"
                },
                {
                    "authorId": "2109869278",
                    "name": "Ji Yang"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "73416451",
                    "name": "Youlong Cheng"
                }
            ]
        },
        {
            "paperId": "6dc8b0018bbc183c8d15747e5f6cc3fb14678a9f",
            "title": "Toward Annotator Group Bias in Crowdsourcing",
            "abstract": "Crowdsourcing has emerged as a popular approach for collecting annotated data to train supervised machine learning models. However, annotator bias can lead to defective annotations. Though there are a few works investigating individual annotator bias, the group effects in annotators are largely overlooked. In this work, we reveal that annotators within the same demographic group tend to show consistent group bias in annotation tasks and thus we conduct an initial study on annotator group bias. We first empirically verify the existence of annotator group bias in various real-world crowdsourcing datasets. Then, we develop a novel probabilistic graphical framework GroupAnno to capture annotator group bias with an extended Expectation Maximization (EM) algorithm. We conduct experiments on both synthetic and real-world datasets. Experimental results demonstrate the effectiveness of our model in modeling annotator group bias in label aggregation and model learning over competitive baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143856455",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "80601470",
                    "name": "J. Thekinen"
                },
                {
                    "authorId": "2315117721",
                    "name": "Sinem Mollaoglu"
                },
                {
                    "authorId": "97705488",
                    "name": "Da Tang"
                },
                {
                    "authorId": "2109869278",
                    "name": "Ji Yang"
                },
                {
                    "authorId": "73416451",
                    "name": "Youlong Cheng"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "29f080a1bb6df6f45afd82c443f72da745983bee",
            "title": "Mixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations",
            "abstract": "Learning query and item representations is important for building large scale recommendation systems. In many real applications where there is a huge catalog of items to recommend, the problem of efficiently retrieving top k items given user\u2019s query from deep corpus leads to a family of factorized modeling approaches where queries and items are jointly embedded into a low-dimensional space. In this paper, we first showcase how to apply a two-tower neural network framework, which is also known as dual encoder in the natural language community, to improve a large-scale, production app recommendation system. Furthermore, we offer a novel negative sampling approach called Mixed Negative Sampling (MNS). In particular, different from commonly used batch or unigram sampling methods, MNS uses a mixture of batch and uniformly sampled negatives to tackle the selection bias of implicit user feedback. We conduct extensive offline experiments using large-scale production dataset and show that MNS outperforms other baseline sampling methods. We also conduct online A/B testing and demonstrate that the two-tower retrieval model based on MNS significantly improves retrieval quality by encouraging more high-quality app installs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109869278",
                    "name": "Ji Yang"
                },
                {
                    "authorId": "2838461",
                    "name": "Xinyang Yi"
                },
                {
                    "authorId": "48573272",
                    "name": "D. Cheng"
                },
                {
                    "authorId": "2217278",
                    "name": "Lichan Hong"
                },
                {
                    "authorId": "98177814",
                    "name": "Y. Li"
                },
                {
                    "authorId": "2116422324",
                    "name": "Simon Xiaoming Wang"
                },
                {
                    "authorId": "81047418",
                    "name": "Taibai Xu"
                },
                {
                    "authorId": "2226805",
                    "name": "Ed H. Chi"
                }
            ]
        },
        {
            "paperId": "d321d39cd0780b4ce6e0817cee64fc664d8d6a21",
            "title": "Off-policy Learning in Two-stage Recommender Systems",
            "abstract": "Many real-world recommender systems need to be highly scalable: matching millions of items with billions of users, with milliseconds latency. The scalability requirement has led to widely used two-stage recommender systems, consisting of efficient candidate generation model(s) in the first stage and a more powerful ranking model in the second stage. Logged user feedback, e.g., user clicks or dwell time, are often used to build both candidate generation and ranking models for recommender systems. While it\u2019s easy to collect large amount of such data, they are inherently biased because the feedback can only be observed on items recommended by the previous systems. Recently, off-policy correction on such biases have attracted increasing interest in the field of recommender system research. However, most existing work either assumed that the recommender system is a single-stage system or only studied how to apply off-policy correction to the candidate generation stage of the system without explicitly considering the interactions between the two stages. In this work, we propose a two-stage off-policy policy gradient method, and showcase that ignoring the interaction between the two stages leads to a sub-optimal policy in two-stage recommender systems. The proposed method explicitly takes into account the ranking model when training the candidate generation model, which helps improve the performance of the whole system. We conduct experiments on real-world datasets with large item space and demonstrate the effectiveness of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47793019",
                    "name": "Jiaqi Ma"
                },
                {
                    "authorId": "3029211",
                    "name": "A. Arbor"
                },
                {
                    "authorId": "48634137",
                    "name": "Zhe Zhao"
                },
                {
                    "authorId": "2838461",
                    "name": "Xinyang Yi"
                },
                {
                    "authorId": "2109869278",
                    "name": "Ji Yang"
                },
                {
                    "authorId": "1743082",
                    "name": "Minmin Chen"
                },
                {
                    "authorId": "3431394",
                    "name": "Jiaxi Tang"
                },
                {
                    "authorId": "2217278",
                    "name": "Lichan Hong"
                },
                {
                    "authorId": "2226805",
                    "name": "Ed H. Chi"
                }
            ]
        },
        {
            "paperId": "41a08dd12ab4495a8f617174833302484dcce055",
            "title": "Sampling-bias-corrected neural modeling for large corpus item recommendations",
            "abstract": "Many recommendation systems retrieve and score items from a very large corpus. A common recipe to handle data sparsity and power-law item distribution is to learn item representations from its content features. Apart from many content-aware systems based on matrix factorization, we consider a modeling framework using two-tower neural net, with one of the towers (item tower) encoding a wide variety of item content features. A general recipe of training such two-tower models is to optimize loss functions calculated from in-batch negatives, which are items sampled from a random mini-batch. However, in-batch loss is subject to sampling biases, potentially hurting model performance, particularly in the case of highly skewed distribution. In this paper, we present a novel algorithm for estimating item frequency from streaming data. Through theoretical analysis and simulation, we show that the proposed algorithm can work without requiring fixed item vocabulary, and is capable of producing unbiased estimation and being adaptive to item distribution change. We then apply the sampling-bias-corrected modeling approach to build a large scale neural retrieval system for YouTube recommendations. The system is deployed to retrieve personalized suggestions from a corpus with tens of millions of videos. We demonstrate the effectiveness of sampling-bias correction through offline experiments on two real-world datasets. We also conduct live A/B testings to show that the neural retrieval system leads to improved recommendation quality for YouTube.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2838461",
                    "name": "Xinyang Yi"
                },
                {
                    "authorId": "2109869278",
                    "name": "Ji Yang"
                },
                {
                    "authorId": "2217278",
                    "name": "Lichan Hong"
                },
                {
                    "authorId": "48573272",
                    "name": "D. Cheng"
                },
                {
                    "authorId": "37914278",
                    "name": "L. Heldt"
                },
                {
                    "authorId": "1394490096",
                    "name": "A. Kumthekar"
                },
                {
                    "authorId": "48634137",
                    "name": "Zhe Zhao"
                },
                {
                    "authorId": "2113554448",
                    "name": "Li Wei"
                },
                {
                    "authorId": "2226805",
                    "name": "Ed H. Chi"
                }
            ]
        }
    ]
}