{
    "authorId": "6964082",
    "papers": [
        {
            "paperId": "5c4a3d8f93138cd1bd19ad231919505b49b528cd",
            "title": "NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics",
            "abstract": "Machine learning provides a valuable tool for analyzing high-dimensional functional neuroimaging data, and is proving effective in predicting various neurological conditions, psychiatric disorders, and cognitive patterns. In functional magnetic resonance imaging (MRI) research, interactions between brain regions are commonly modeled using graph-based representations. The potency of graph machine learning methods has been established across myriad domains, marking a transformative step in data interpretation and predictive modeling. Yet, despite their promise, the transposition of these techniques to the neuroimaging domain has been challenging due to the expansive number of potential preprocessing pipelines and the large parameter search space for graph-based dataset construction. In this paper, we introduce NeuroGraph1, a collection of graph-based neuroimaging datasets, and demonstrated its utility for predicting multiple categories of behavioral and cognitive traits. We delve deeply into the dataset generation search space by crafting 35 datasets that encompass static and dynamic brain connectivity, running in excess of 15 baseline methods for benchmarking. Additionally, we provide generic frameworks for learning on both static and dynamic graphs. Our extensive experiments lead to several key observations. Notably, using correlation vectors as node features, incorporating larger number of regions of interest, and employing sparser graphs lead to improved performance. To foster further advancements in graph-based data driven neuroimaging analysis, we offer a comprehensive open-source Python package that includes the benchmark datasets, baseline implementations, model training, and standard evaluation.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "50192588",
                    "name": "Anwar Said"
                },
                {
                    "authorId": "52038221",
                    "name": "Roza G. Bayrak"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                },
                {
                    "authorId": "38776168",
                    "name": "Mudassir Shabbir"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "2157872630",
                    "name": "Catie Chang"
                },
                {
                    "authorId": "1727409",
                    "name": "X. Koutsoukos"
                }
            ]
        },
        {
            "paperId": "fe8a38cf73bb5a4a8758621f21e2cdc920d23d58",
            "title": "Convolutional-recurrent neural networks approximate diffusion tractography from T1-weighted MRI and associated anatomical context",
            "abstract": "Diffusion MRI (dMRI) streamline tractography is the gold-standard for in vivo estimation of white matter (WM) pathways in the brain. However, the high angular resolution dMRI acquisitions capable of fitting the microstructural models needed for tractography are often time-consuming and not routinely collected clinically, restricting the scope of tractography analyses. To address this limitation, we build on recent advances in deep learning which have demonstrated that streamline propagation can be learned from dMRI directly without traditional model fitting. Specifically, we propose learning the streamline propagator from T1w MRI to facilitate arbitrary tractography analyses when dMRI is unavailable. To do so, we present a novel convolutional-recurrent neural network (CoRNN) trained in a teacher-student framework that leverages T1w MRI, associated anatomical context, and streamline memory from data acquired for the Human Connectome Project. We characterize our approach under two common tractography paradigms, WM bundle analysis and structural connectomics, and find approximately a 5-15% difference between measures computed from streamlines generated with our approach and those generated using traditional dMRI tractography. When placed in the literature, these results suggest that the accuracy of WM measures computed from T1w MRI with our method is on the level of scan-rescan dMRI variability and raise an important question: is tractography truly a microstructural phenomenon, or has dMRI merely facilitated its discovery and implementation?",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "47236750",
                    "name": "L. Cai"
                },
                {
                    "authorId": "2110756308",
                    "name": "Ho Hin Lee"
                },
                {
                    "authorId": "2094729366",
                    "name": "N. Newlin"
                },
                {
                    "authorId": "52142290",
                    "name": "Cailey I. Kerley"
                },
                {
                    "authorId": "1704893173",
                    "name": "Praitayini Kanakaraj"
                },
                {
                    "authorId": "2109122615",
                    "name": "Qi Yang"
                },
                {
                    "authorId": "79539753",
                    "name": "Graham W. Johnson"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "143667969",
                    "name": "K. Schilling"
                },
                {
                    "authorId": "51294781",
                    "name": "F. Rheault"
                },
                {
                    "authorId": "2133475009",
                    "name": "Bennett A. Landman"
                }
            ]
        },
        {
            "paperId": "4e32b01a2f28d6e0c3154219532e2991c8ac63d2",
            "title": "SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI",
            "abstract": "Volumetric reconstruction of fetal brains from multiple stacks of MR slices, acquired in the presence of almost unpredictable and often severe subject motion, is a challenging task that is highly sensitive to the initialization of slice-to-volume transformations. We propose a novel slice-to-volume registration method using Transformers trained on synthetically transformed data, which model multiple stacks of MR slices as a sequence. With the attention mechanism, our model automatically detects the relevance between slices and predicts the transformation of one slice using information from other slices. We also estimate the underlying 3D volume to assist slice-to-volume registration and update the volume and transformations alternately to improve accuracy. Results on synthetic data show that our method achieves lower registration error and better reconstruction quality compared with existing state-of-the-art methods. Experiments with real-world MRI data are also performed to demonstrate the ability of the proposed model to improve the quality of 3D reconstruction under severe fetal motion.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "32499984",
                    "name": "Junshen Xu"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "2249910331",
                    "name": "P. Grant"
                },
                {
                    "authorId": "1729630",
                    "name": "P. Golland"
                },
                {
                    "authorId": "1786793",
                    "name": "J. E. Iglesias"
                },
                {
                    "authorId": "2141260",
                    "name": "E. Adalsteinsson"
                }
            ]
        },
        {
            "paperId": "9e101c16158de767df00e4706a255a2cc435fc76",
            "title": "Harmonization and the Worst Scanner Syndrome",
            "abstract": "We show that for a wide class of harmonization/domain-invariance schemes several undesirable properties are unavoidable. If a predictive machine is made invariant to a set of domains, the accuracy of the output predictions (as measured by mutual information) is limited by the domain with the least amount of information to begin with. If a real label value is highly informative about the source domain, it cannot be accurately predicted by an invariant predictor. These results are simple and intuitive, but we believe that it is beneficial to state them for medical imaging harmonization.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Biology",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "1729630",
                    "name": "P. Golland"
                }
            ]
        },
        {
            "paperId": "b857de0923ffbc2174455ce33f73f3acd0efafc1",
            "title": "Image Classification with Consistent Supporting Evidence",
            "abstract": "Adoption of machine learning models in healthcare requires end users' trust in the system. Models that provide additional supportive evidence for their predictions promise to facilitate adoption. We define consistent evidence to be both compatible and sufficient with respect to model predictions. We propose measures of model inconsistency and regularizers that promote more consistent evidence. We demonstrate our ideas in the context of edema severity grading from chest radiographs. We demonstrate empirically that consistent models provide competitive performance while supporting interpretation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46808649",
                    "name": "Peiqi Wang"
                },
                {
                    "authorId": "145459249",
                    "name": "Ruizhi Liao"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "50567644",
                    "name": "S. Berkowitz"
                },
                {
                    "authorId": "2986398",
                    "name": "S. Horng"
                },
                {
                    "authorId": "1729630",
                    "name": "P. Golland"
                }
            ]
        },
        {
            "paperId": "4ba94e43c023cc7432e533d4b60b7ff2f72404d2",
            "title": "DEMI: Discriminative Estimator of Mutual Information",
            "abstract": "Estimating mutual information between continuous random variables is often intractable and extremely challenging for high-dimensional data. Recent progress has leveraged neural networks to optimize variational lower bounds on mutual information. Although showing promise for this difficult problem, the variational methods have been theoretically and empirically proven to have serious statistical limitations: 1) most of the approaches cannot make accurate estimates when the underlying mutual information is either low or high; 2) the resulting estimators may suffer from high variance. Our approach is based on training a classifier that provides the probability whether a data sample pair is drawn from the joint distribution or from the product of its marginal distributions. We use this probabilistic prediction to estimate mutual information. We show theoretically that our method and other variational approaches are equivalent when they achieve their optimum, while our approach does not optimize a variational bound. Empirical results demonstrate high accuracy and a good bias/variance tradeoff using our approach.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "145459249",
                    "name": "Ruizhi Liao"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "1729630",
                    "name": "P. Golland"
                },
                {
                    "authorId": "1785317",
                    "name": "W. Wells"
                }
            ]
        },
        {
            "paperId": "7f5c765301746cfc12a9a06c485b3844e7a4a7c7",
            "title": "Optimizing Connectivity-Driven Brain Parcellation Using Ensemble Clustering",
            "abstract": "This work addresses the problem of constructing a unified, topologically optimal connectivity-based brain atlas. The proposed approach aggregates an ensemble partition from individual parcellations without label agreement, providing a balance between sufficiently flexible individual parcellations and intuitive representation of the average topological structure of the connectome. The methods exploit a previously proposed dense connectivity representation, first performing graph-based hierarchical parcellation of individual brains, and subsequently aggregating the individual parcellations into a consensus parcellation. The search for consensus\u2014based on the hard ensemble (HE) algorithm\u2014approximately minimizes the sum of cluster membership distances, effectively estimating a pseudo-Karcher mean of individual parcellations. Computational stability, graph structure preservation, and biological relevance of the simplified representation resulting from the proposed parcellation are assessed on the Human Connectome Project data set. These aspects are assessed using (1) edge weight distribution divergence with respect to the dense connectome representation, (2) interhemispheric symmetry, (3) network characteristics' stability and agreement with respect to individually and anatomically parcellated networks, and (4) performance of the simplified connectome in a biological sex classification task. Ensemble parcellation was found to be highly stable with respect to subject sampling, outperforming anatomical atlases and other connectome-based parcellations in classification as well as preserving global connectome properties. The HE-based parcellation also showed a degree of symmetry comparable with anatomical atlases and a high degree of spatial contiguity without using explicit priors.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2064871637",
                    "name": "Anvar Kurmukov"
                },
                {
                    "authorId": "1393156796",
                    "name": "Ayagoz Mussabaeva"
                },
                {
                    "authorId": "87844604",
                    "name": "Yu. L. Denisova"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "1721831",
                    "name": "N. Jahanshad"
                },
                {
                    "authorId": "2300186380",
                    "name": "P. Thompson"
                },
                {
                    "authorId": "1740974",
                    "name": "B. Gutman"
                }
            ]
        },
        {
            "paperId": "e799021e4d5d29195e91abc5544c04edea33716e",
            "title": "Overview of Scanner Invariant Representations",
            "abstract": "Pooled imaging data from multiple sources is subject to bias from each source. Studies that do not correct for these scanner/site biases at best lose statistical power, and at worst leave spurious correlations in their data. Estimation of the bias effects is non-trivial due to the paucity of data with correspondence across sites, so called \"traveling phantom\" data, which is expensive to collect. Nevertheless, numerous solutions leveraging direct correspondence have been proposed. In contrast to this, Moyer et al. (2019) proposes an unsupervised solution using invariant representations, one which does not require correspondence and thus does not require paired images. By leveraging the data processing inequality, an invariant representation can then be used to create an image reconstruction that is uninformative of its original source, yet still faithful to the underlying structure. In the present abstract we provide an overview of this method.",
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "1719898",
                    "name": "G. V. Steeg"
                },
                {
                    "authorId": "2300186380",
                    "name": "P. Thompson"
                }
            ]
        },
        {
            "paperId": "f806fab08100fe9d3bd4f919d3e852794025e51f",
            "title": "Bayesian Image Reconstruction using Deep Generative Models",
            "abstract": "Machine learning models are commonly trained end-to-end and in a supervised setting, using paired (input, output) data. Classical examples include recent super-resolution methods that train on pairs of (low-resolution, high-resolution) images. However, these end-to-end approaches require re-training every time there is a distribution shift in the inputs (e.g., night images vs daylight) or relevant latent variables (e.g., camera blur or hand motion). In this work, we leverage state-of-the-art (SOTA) generative models (here StyleGAN2) for building powerful image priors, which enable application of Bayes' theorem for many downstream reconstruction tasks. Our method, called Bayesian Reconstruction through Generative Models (BRGM), uses a single pre-trained generator model to solve different image restoration tasks, i.e., super-resolution and in-painting, by combining it with different forward corruption models. We demonstrate BRGM on three large, yet diverse, datasets that enable us to build powerful priors: (i) 60,000 images from the Flick Faces High Quality dataset \\cite{karras2019style} (ii) 240,000 chest X-rays from MIMIC III and (iii) a combined collection of 5 brain MRI datasets with 7,329 scans. Across all three datasets and without any dataset-specific hyperparameter tuning, our approach yields state-of-the-art performance on super-resolution, particularly at low-resolution levels, as well as inpainting, compared to state-of-the-art methods that are specific to each reconstruction task. We will make our code and pre-trained models available online.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "32126180",
                    "name": "Razvan V. Marinescu"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "1729630",
                    "name": "P. Golland"
                }
            ]
        },
        {
            "paperId": "2f5ff4adf91dcb4efe3fe95e330d9078f41c18c8",
            "title": "Exact Rate-Distortion in Autoencoders via Echo Noise",
            "abstract": "Compression is at the heart of effective representation learning. However, lossy compression is typically achieved through simple parametric models like Gaussian noise to preserve analytic tractability, and the limitations this imposes on learning are largely unexplored. Further, the Gaussian prior assumptions in models such as variational autoencoders (VAEs) provide only an upper bound on the compression rate in general. We introduce a new noise channel, \\emph{Echo noise}, that admits a simple, exact expression for mutual information for arbitrary input distributions. The noise is constructed in a data-driven fashion that does not require restrictive distributional assumptions. With its complex encoding mechanism and exact rate regularization, Echo leads to improved bounds on log-likelihood and dominates $\\beta$-VAEs across the achievable range of rate-distortion trade-offs. Further, we show that Echo noise can outperform flow-based methods without the need to train additional distributional transformations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "27633668",
                    "name": "Rob Brekelmans"
                },
                {
                    "authorId": "6964082",
                    "name": "Daniel Moyer"
                },
                {
                    "authorId": "143728483",
                    "name": "A. Galstyan"
                },
                {
                    "authorId": "1719898",
                    "name": "G. V. Steeg"
                }
            ]
        }
    ]
}