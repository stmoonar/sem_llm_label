{
    "authorId": "2666765",
    "papers": [
        {
            "paperId": "0c52589c3472f2694530147595f5bd5800fa799a",
            "title": "SteinGen: Generating Fidelitous and Diverse Graph Samples",
            "abstract": "Generating graphs that preserve characteristic structures while promoting sample diversity can be challenging, especially when the number of graph observations is small. Here, we tackle the problem of graph generation from only one observed graph. The classical approach of graph generation from parametric models relies on the estimation of parameters, which can be inconsistent or expensive to compute due to intractable normalisation constants. Generative modelling based on machine learning techniques to generate high-quality graph samples avoids parameter estimation but usually requires abundant training samples. Our proposed generating procedure, SteinGen, which is phrased in the setting of graphs as realisations of exponential random graph models, combines ideas from Stein's method and MCMC by employing Markovian dynamics which are based on a Stein operator for the target model. SteinGen uses the Glauber dynamics associated with an estimated Stein operator to generate a sample, and re-estimates the Stein operator from the sample after every sampling step. We show that on a class of exponential random graph models this novel\"estimation and re-estimation\"generation strategy yields high distributional similarity (high fidelity) to the original data, combined with high sample diversity.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                },
                {
                    "authorId": "2293764224",
                    "name": "Wenkai Xu"
                }
            ]
        },
        {
            "paperId": "658dfd1f241166ccb49c3e19af454012d61b7257",
            "title": "Generalization Error of Graph Neural Networks in the Mean-field Regime",
            "abstract": "This work provides a theoretical framework for assessing the generalization error of graph neural networks in the over-parameterized regime, where the number of parameters surpasses the quantity of data points. We explore two widely utilized types of graph neural networks: graph convolutional neural networks and message passing graph neural networks. Prior to this study, existing bounds on the generalization error in the over-parametrized regime were uninformative, limiting our understanding of over-parameterized network performance. Our novel approach involves deriving upper bounds within the mean-field regime for evaluating the generalization error of these graph neural networks. We establish upper bounds with a convergence rate of $O(1/n)$, where $n$ is the number of graph samples. These upper bounds offer a theoretical assurance of the networks' performance on unseen data in the challenging over-parameterized regime and overall contribute to our understanding of their performance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1762580",
                    "name": "Gholamali Aminian"
                },
                {
                    "authorId": "2283842644",
                    "name": "Yixuan He"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                },
                {
                    "authorId": "2269329149",
                    "name": "Lukasz Szpruch"
                },
                {
                    "authorId": "2164352216",
                    "name": "Samuel N. Cohen"
                }
            ]
        },
        {
            "paperId": "8794f5a598a4ec0e57c1f88367dc6433ecc8f634",
            "title": "L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders",
            "abstract": "For analysing real-world networks, graph representation learning is a popular tool. These methods, such as a graph autoencoder (GAE), typically rely on low-dimensional representations, also called embeddings, which are obtained through minimising a loss function; these embeddings are used with a decoder for downstream tasks such as node classification and edge prediction. While GAEs tend to be fairly accurate, they suffer from scalability issues. For improved speed, a Local2Global approach, which combines graph patch embeddings based on eigenvector synchronisation, was shown to be fast and achieve good accuracy. Here we propose L2G2G, a Local2Global method which improves GAE accuracy without sacrificing scalability. This improvement is achieved by dynamically synchronising the latent node representations, while training the GAEs. It also benefits from the decoder computing an only local patch loss. Hence, aligning the local embeddings in each epoch utilises more information from the graph than a single post-training alignment does, while maintaining scalability. We illustrate on synthetic benchmarks, as well as real-world examples, that L2G2G achieves higher accuracy than the standard Local2Global approach and scales efficiently on the larger data sets. We find that for large and dense networks, it even outperforms the slow, but assumed more accurate, GAEs.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2282469344",
                    "name": "Ruikang Ouyang"
                },
                {
                    "authorId": "2064013905",
                    "name": "Andrew Elliott"
                },
                {
                    "authorId": "46182296",
                    "name": "Stratis Limnios"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                }
            ]
        },
        {
            "paperId": "8b5f4e013bc2baad97c6c82be21abf2616f7228d",
            "title": "Split Conformal Prediction under Data Contamination",
            "abstract": "Conformal prediction is a non-parametric technique for constructing prediction intervals or sets from arbitrary predictive models under the assumption that the data is exchangeable. It is popular as it comes with theoretical guarantees on the marginal coverage of the prediction sets and the split conformal prediction variant has a very low computational cost compared to model training. We study the robustness of split conformal prediction in a data contamination setting, where we assume a small fraction of the calibration scores are drawn from a different distribution than the bulk. We quantify the impact of the corrupted data on the coverage and efficiency of the constructed sets when evaluated on\"clean\"test points, and verify our results with numerical experiments. Moreover, we propose an adjustment in the classification setting which we call Contamination Robust Conformal Prediction, and verify the efficacy of our approach using both synthetic and real datasets.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2310607712",
                    "name": "Jase Clarkson"
                },
                {
                    "authorId": "2293764224",
                    "name": "Wenkai Xu"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                }
            ]
        },
        {
            "paperId": "36fbfe8b415d0e18fd144bc65a0a574b5adac61f",
            "title": "Robust Angular Synchronization via Directed Graph Neural Networks",
            "abstract": "The angular synchronization problem aims to accurately estimate (up to a constant additive phase) a set of unknown angles $\\theta_1, \\dots, \\theta_n\\in[0, 2\\pi)$ from $m$ noisy measurements of their offsets $\\theta_i-\\theta_j \\;\\mbox{mod} \\; 2\\pi.$ Applications include, for example, sensor network localization, phase retrieval, and distributed clock synchronization. An extension of the problem to the heterogeneous setting (dubbed $k$-synchronization) is to estimate $k$ groups of angles simultaneously, given noisy observations (with unknown group assignment) from each group. Existing methods for angular synchronization usually perform poorly in high-noise regimes, which are common in applications. In this paper, we leverage neural networks for the angular synchronization problem, and its heterogeneous extension, by proposing GNNSync, a theoretically-grounded end-to-end trainable framework using directed graph neural networks. In addition, new loss functions are devised to encode synchronization objectives. Experimental results on extensive data sets demonstrate that GNNSync attains competitive, and often superior, performance against a comprehensive set of baselines for the angular synchronization problem and its extension, validating the robustness of GNNSync even at high noise levels.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2118917694",
                    "name": "Yixuan He"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                },
                {
                    "authorId": "2256992062",
                    "name": "David Wipf"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                }
            ]
        },
        {
            "paperId": "41b9a2ef4cf496ed98f4827ac4788d1f5b520019",
            "title": "SaGess: Sampling Graph Denoising Diffusion Model for Scalable Graph Generation",
            "abstract": "Over recent years, denoising diffusion generative models have come to be considered as state-of-the-art methods for synthetic data generation, especially in the case of generating images. These approaches have also proved successful in other applications such as tabular and graph data generation. However, due to computational complexity, to this date, the application of these techniques to graph data has been restricted to small graphs, such as those used in molecular modeling. In this paper, we propose SaGess, a discrete denoising diffusion approach, which is able to generate large real-world networks by augmenting a diffusion model (DiGress) with a generalized divide-and-conquer framework. The algorithm is capable of generating larger graphs by sampling a covering of subgraphs of the initial graph in order to train DiGress. SaGess then constructs a synthetic graph using the subgraphs that have been generated by DiGress. We evaluate the quality of the synthetic data sets against several competitor methods by comparing graph statistics between the original and synthetic samples, as well as evaluating the utility of the synthetic data set produced by using it to train a task-driven model, namely link prediction. In our experiments, SaGess, outperforms most of the one-shot state-of-the-art graph generating methods by a significant factor, both on the graph metrics and on the link prediction task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46182296",
                    "name": "Stratis Limnios"
                },
                {
                    "authorId": "2220825490",
                    "name": "Praveen Selvaraj"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                },
                {
                    "authorId": "2091059383",
                    "name": "C. Maple"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                },
                {
                    "authorId": "2064013905",
                    "name": "Andrew Elliott"
                }
            ]
        },
        {
            "paperId": "7d8544ef342b62754cf0f6132b8cfb209a45988a",
            "title": "The GNAR-edge model: a network autoregressive model for networks with time-varying edge weights",
            "abstract": "\n In economic and financial applications, there is often the need for analysing multivariate time series, comprising of time series for a range of quantities. In some applications, such complex systems can be associated with some underlying network describing pairwise relationships among the quantities. Accounting for the underlying network structure for the analysis of this type of multivariate time series is required for assessing estimation error and can be particularly informative for forecasting. Our work is motivated by a dataset consisting of time series of industry-to-industry transactions. In this example, pairwise relationships between Standard Industrial Classification (SIC) codes can be represented using a network, with SIC codes as nodes and pairwise transactions between SIC codes as edges, while the observed time series of the amounts of the transactions for each pair of SIC codes can be regarded as time-varying weights on the edges. Inspired by Knight et al. (2020, J. Stat. Softw., 96, 1\u201336), we introduce the GNAR-edge model which allows modelling of multiple time series utilizing the network structure, assuming that each edge weight depends not only on its past values, but also on past values of its neighbouring edges, for a range of neighbourhood stages. The method is validated through simulations. Results from the implementation of the GNAR-edge model on the real industry-to-industry data show good fitting and predictive performance of the model. The predictive performance is improved when sparsifying the network using a lead\u2013lag analysis and thresholding edges according to a lead\u2013lag score.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2140449993",
                    "name": "Anastasia Mantziou"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                },
                {
                    "authorId": "52219997",
                    "name": "Victor Meirinhos"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                }
            ]
        },
        {
            "paperId": "234e9aa81efab18f4ebcdb21ca7e9f797ff77a47",
            "title": "A Kernelised Stein Statistic for Assessing Implicit Generative Models",
            "abstract": "Synthetic data generation has become a key ingredient for training machine learning procedures, addressing tasks such as data augmentation, analysing privacy-sensitive data, or visualising representative samples. Assessing the quality of such synthetic data generators hence has to be addressed. As (deep) generative models for synthetic data often do not admit explicit probability distributions, classical statistical procedures for assessing model goodness-of-fit may not be applicable. In this paper, we propose a principled procedure to assess the quality of a synthetic data generator. The procedure is a kernelised Stein discrepancy (KSD)-type test which is based on a non-parametric Stein operator for the synthetic data generator of interest. This operator is estimated from samples which are obtained from the synthetic data generator and hence can be applied even when the model is only implicit. In contrast to classical testing, the sample size from the synthetic data generator can be as large as desired, while the size of the observed data, which the generator aims to emulate is fixed. Experimental results on synthetic distributions and trained generative models on synthetic and real datasets illustrate that the method shows improved power performance compared to existing approaches.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2152923472",
                    "name": "Wenkai Xu"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                }
            ]
        },
        {
            "paperId": "369b01b8b0b73c021c89c9991e1b6d38b1fd7d7c",
            "title": "GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks",
            "abstract": "Recovering global rankings from pairwise comparisons has wide applications from time synchronization to sports team ranking. Pairwise comparisons corresponding to matches in a competition can be construed as edges in a directed graph (digraph), whose nodes represent e.g. competitors with an unknown rank. In this paper, we introduce neural networks into the ranking recovery problem by proposing the so-called GNNRank, a trainable GNN-based framework with digraph embedding. Moreover, new objectives are devised to encode ranking upsets/violations. The framework involves a ranking score estimation approach, and adds an inductive bias by unfolding the Fiedler vector computation of the graph constructed from a learnable similarity matrix. Experimental results on extensive data sets show that our methods attain competitive and often superior performance against baselines, as well as showing promising transfer ability. Codes and preprocessed data are at: \\url{https://github.com/SherylHYX/GNNRank}.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2118917694",
                    "name": "Yixuan He"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "2242717",
                    "name": "D. Wipf"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                },
                {
                    "authorId": "3063894",
                    "name": "Junchi Yan"
                },
                {
                    "authorId": "2264879492",
                    "name": "Mihai Cucuringu"
                }
            ]
        },
        {
            "paperId": "3b91cf7c9888b4a603465d2716890b94a915552e",
            "title": "Extracting Information from Gene Coexpression Networks of Rhizobium leguminosarum",
            "abstract": "Nitrogen uptake in legumes is facilitated by bacteria such as Rhizobium leguminosarum. For this bacterium, gene expression data are available, but functional gene annotation is less well developed than for other model organisms. More annotations could lead to a better understanding of the pathways for growth, plant colonization, and nitrogen fixation in R. leguminosarum. In this study, we present a pipeline that combines novel scores from gene coexpression network analysis in a principled way to identify the genes that are associated with certain growth conditions or highly coexpressed with a predefined set of genes of interest. This association may lead to putative functional annotation or to a prioritized list of genes for further study.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1754020792",
                    "name": "Javier Pardo-Diaz"
                },
                {
                    "authorId": "1402765126",
                    "name": "Mariano Beguerisse-D\u00edaz"
                },
                {
                    "authorId": "34258855",
                    "name": "P. Poole"
                },
                {
                    "authorId": "145808074",
                    "name": "C. Deane"
                },
                {
                    "authorId": "2666765",
                    "name": "G. Reinert"
                }
            ]
        }
    ]
}