{
    "authorId": "152179862",
    "papers": [
        {
            "paperId": "15eb2be5fcdd499dc1b41c712e110aa8c286f444",
            "title": "Tracking Machine Learning Bias Creep in Traditional and Online Lending Systems with Covariance Analysis",
            "abstract": "Machine Learning (ML) algorithms are embedded within online banking services, proposing decisions about consumers\u2019 credit cards, car loans, and mortgages. These algorithms are sometimes biased, resulting in unfair decisions toward certain groups. One common approach for addressing such bias is simply dropping the sensitive attributes from the training data (e.g. gender). However, sensitive attributes can indirectly be represented by other attributes in the data (e.g. maternity leave taken). This paper addresses the problem of identifying attributes that can mimic sensitive attributes by proposing a new approach based on covariance analysis. Our evaluation conducted on two different credit datasets, extracted from a traditional and an online banking institution respectively, shows how our approach: (i) effectively identifies the attributes from the data that encapsulate sensitive information and, (ii) leads to the reduction of biases in ML models, while maintaining their overall performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2179337410",
                    "name": "\u00c1ngel Pav\u00f3n P\u00e9rez"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "1403825149",
                    "name": "H. Al-Madfai"
                },
                {
                    "authorId": "3165334",
                    "name": "Gr\u00e9goire Burel"
                },
                {
                    "authorId": "145842685",
                    "name": "Harith Alani"
                }
            ]
        },
        {
            "paperId": "b9ba10445df667e9780a1f2991ef05f9ce1a33b3",
            "title": "Understanding Misogynoir: A Study of Annotators\u2019 Perspectives",
            "abstract": "\u201cMisogynoir\" is the anti-Black racist misogyny experienced by Black women, which is characterised by components of both racism and sexism. Misogynoir is challenging to detect due to its inherent subjectivity and its intersectional nature, and people\u2019s opinions and interpretations of such hate might vary, which adds to the challenges of understanding it. In this paper, we explored how and some potential why\u2019s different annotator characteristics influence how they interpret and annotate a dataset for potential cases of Misogynoir and Allyship. We sampled tweets containing public responses to self-reported misogynoir cases by four prominent Black women in technology, designed an online annotation task study, and recruited annotators of diverse ethnicities and genders from the Prolific crowdsourcing platform. We found that participants\u2019 sources of evidence in judging and interpreting content for potential cases of Misogynoir and Allyship, even in circumstances where they all agree on a prospective label, vary across different factors, such as different ethnicity, lived experiences and gender. In addition, we present a variety of plausible interpretations influenced by the various annotators\u2019 characteristics. This study demonstrates the relevance of different annotator perspectives and content comprehension in hate speech and the need for further efforts to understand intersectional hate better.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "74733212",
                    "name": "Joseph Kwarteng"
                },
                {
                    "authorId": "3165334",
                    "name": "Gr\u00e9goire Burel"
                },
                {
                    "authorId": "2190195962",
                    "name": "Aisling Third"
                },
                {
                    "authorId": "145118333",
                    "name": "T. Farrell"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                }
            ]
        },
        {
            "paperId": "1e233e90dd65e075d1833d2b817f1fc64f1af780",
            "title": "Estimating Ground Truth in a Low-labelled Data Regime: A Study of Racism Detection in Spanish",
            "abstract": "Obtaining reliable and quality training datasets is resource-intensive, especially in interpretation and human judgment tasks, such as racism detection. Related work reveals that annotators subjected to hate are more sensitive to labelling something as offensive and advocate giving more voice to these collectives. This study analyses a new dataset for detecting racism in Spanish, focusing on solving a ground truth estimate given a few labels and high disagreement. Most an-notators may not have previous experience with racism, as only three belong to the Black community. Our empirical re-sults show better performance at lower thresholds for classifying messages as racist, which may be due to how annotators being permissive in identifying racist content propagates to the model. This analysis can be crucial for tailoring a general model to the specific needs of a particular individual or group. Especially in applications such as online abuse, detection models that reflect the viewpoint of crowdworkers may not be sufficient to detect all the intricacies of these social challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144649123",
                    "name": "P. Lobo"
                },
                {
                    "authorId": "40977598",
                    "name": "Martino Mensio"
                },
                {
                    "authorId": "2170232681",
                    "name": "Angel Pavon Perez"
                },
                {
                    "authorId": "7552603",
                    "name": "Vaclav Bayer"
                },
                {
                    "authorId": "74733212",
                    "name": "Joseph Kwarteng"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "3256660",
                    "name": "E. Daga"
                },
                {
                    "authorId": "145842685",
                    "name": "Harith Alani"
                }
            ]
        },
        {
            "paperId": "81e05518d03aa5362fae22d87df779fc9c3e3369",
            "title": "Semantic Web technologies and bias in artificial intelligence: A systematic literature review",
            "abstract": "Bias in Artificial Intelligence (AI) is a critical and timely issue due to its sociological, economic and legal impact, as decisions made by biased algorithms could lead to unfair treatment of specific individuals or groups. Multiple surveys have emerged to provide a multidisciplinary view of bias or to review bias in specific areas such as social sciences, business research, criminal justice, or data mining. Given the ability of Semantic Web (SW) technologies to support multiple AI systems, we review the extent to which semantics can be a \u201ctool\u201d to address bias in different algorithmic scenarios. We provide an in-depth categorisation and analysis of bias assessment, representation, and mitigation approaches that use SW technologies. We discuss their potential in dealing with issues such as representing disparities of specific demographics or reducing data drifts, sparsity, and missing values. We find research works on AI bias that apply semantics mainly in information retrieval, recommendation and natural language processing applications and argue through multiple use cases that semantics can help deal with technical, sociological, and psychological challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2165944178",
                    "name": "Paula Reyero-Lobo"
                },
                {
                    "authorId": "3256660",
                    "name": "E. Daga"
                },
                {
                    "authorId": "145842685",
                    "name": "Harith Alani"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                }
            ]
        },
        {
            "paperId": "6bb9b3e4803666d145a0ffca14ddbdfabcf178ee",
            "title": "Misogynoir: public online response towards self-reported misogynoir",
            "abstract": "\"Misogynoir\" refers to the specific forms of misogyny that Black women experience, which couple racism and sexism together. To better understand the online manifestations of this type of hate, and to propose methods that can automatically identify it, in this paper, we conduct a study on 4 cases of Black women in Tech reporting experiences of misogynoir on the Twitter platform. We follow the reactions to these cases (both supportive and non-supportive responses), and categorise them within a model of misogynoir that highlights experiences of Tone Policing, White Centring, Racial Gaslighting and Defensiveness. As an intersectional form of abusive or hateful speech, we investigate the possibilities and challenges to detect online instances of misogynoir in an automated way. We then conduct a closer qualitative analysis on messages of support and non-support to look at some of these categories in more detail. The purpose of this investigation is to understand responses to misogynoir online, including doubling down on misogynoir, engaging in performative allyship, and showing solidarity with Black women in tech.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "116759269",
                    "name": "J. Kwarteng"
                },
                {
                    "authorId": "3448651",
                    "name": "S. Perfumi"
                },
                {
                    "authorId": "145118333",
                    "name": "T. Farrell"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                }
            ]
        },
        {
            "paperId": "c325a7c27b63fd0e1ebff251d77d901b3e01ebc8",
            "title": "Automatic Intent-based Classification of Citizen-to-Government Tweets",
            "abstract": ": Social networking technologies offer opportunities for governments to engage with citizens. However, the inability to filter relevant citizens' messages out of the vast amount of available social media content lessens their impact. In this paper, we propose a set of categories encapsulating the different citizens' intents when directing messages to public institutions, e",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150712835",
                    "name": "Jos\u00e9 L. Lavado"
                },
                {
                    "authorId": "2128657465",
                    "name": "Iv\u00e1n Cantador"
                },
                {
                    "authorId": "1410081124",
                    "name": "Mar\u00eda E. Cort\u00e9s-Cediel"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                }
            ]
        },
        {
            "paperId": "10003727c93fbd920f49bfadcd973ea36eced6c9",
            "title": "On the use of Jargon and Word Embeddings to Explore Subculture within the Reddit\u2019s Manosphere",
            "abstract": "Understanding the identities, needs, realities and development of subcultures has been a long term target of sociology and cultural studies. Socio-cultural linguistics, in particular, examines the use of language and, in particular, the existence and use of neologisms, slang and jargon. These terms capture concepts and expressions that are not in common use and represent the new realities, norms and values of subcommunities. Identifying and understanding such terms, however, is a very complex task, particularly considering the vast amount of content that is currently available online for many such groups. In this paper, we propose a combination of computational and socio-linguistic methods to automatically extract new terminology from large amounts of data, using word-embeddings to semantically contextualise their meaning. As a use case, we explore subculture on the platform Reddit. More specifically, we investigate groups considered part of the manosphere, a loose online community where men\u2019s perspectives, gripes, frustrations and desires are explicitly expressed and where women are typically targets of hostility. Characterisations of this group as a subculture are then provided, based on an in-depth analysis of the identified jargon.",
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145118333",
                    "name": "T. Farrell"
                },
                {
                    "authorId": "1999125",
                    "name": "\u00d3scar Araque"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "145842687",
                    "name": "Harith Alani"
                }
            ]
        },
        {
            "paperId": "17f423a5e542a4bd4de0243548e127038dea6ab5",
            "title": "Bias in data\u2010driven artificial intelligence systems\u2014An introductory survey",
            "abstract": "Artificial Intelligence (AI)\u2010based systems are widely employed nowadays to make decisions that have far\u2010reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well\u2010grounded in a legal frame. In this survey, we focus on data\u2010driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1804618",
                    "name": "Eirini Ntoutsi"
                },
                {
                    "authorId": "2393008",
                    "name": "P. Fafalios"
                },
                {
                    "authorId": "2516584",
                    "name": "U. Gadiraju"
                },
                {
                    "authorId": "3176896",
                    "name": "Vasileios Iosifidis"
                },
                {
                    "authorId": "1744808",
                    "name": "W. Nejdl"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "1707206",
                    "name": "F. Turini"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "119661806",
                    "name": "I. Kompatsiaris"
                },
                {
                    "authorId": "1404596968",
                    "name": "K. Kinder-Kurlanda"
                },
                {
                    "authorId": "144065562",
                    "name": "Claudia Wagner"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "145842687",
                    "name": "Harith Alani"
                },
                {
                    "authorId": "2990203",
                    "name": "Bettina Berendt"
                },
                {
                    "authorId": "3144221",
                    "name": "Tina Kruegel"
                },
                {
                    "authorId": "49729602",
                    "name": "C. Heinze"
                },
                {
                    "authorId": "2102011",
                    "name": "Klaus Broelemann"
                },
                {
                    "authorId": "1686448",
                    "name": "Gjergji Kasneci"
                },
                {
                    "authorId": "1726746",
                    "name": "T. Tiropanis"
                },
                {
                    "authorId": "1752093",
                    "name": "Steffen Staab"
                }
            ]
        },
        {
            "paperId": "287a6cbb9f2d5bbb1dbcedfcab75978a1c960d11",
            "title": "Capturing and Exploiting Citation Knowledge for Recommending Recently Published Papers",
            "abstract": "With the continuous growth of scientific literature, discovering relevant academic papers for a researcher has become a challenging task, especially when looking for the latest, most recent papers. In this case, traditional collaborative filtering systems are ineffective, since they are unable to recommend items not previously seen, rated or cited. This is known as the item cold-start problem. In this paper, we explore the potential of exploiting citation knowledge to provide a given user with relevant suggestions about recent scientific publications. A novel hybrid recommendation method that encapsulates such citation knowledge is proposed. Experimental results show improvements over baseline methods, evidencing benefits of using citation knowledge to recommend recently published papers in a personalised way. Moreover, as a result of our work, we also provide a unique dataset that, differently to previous corpora, contains detailed paper citation information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22610347",
                    "name": "Anita Khadka"
                },
                {
                    "authorId": "1737406",
                    "name": "Iv\u00e1n Cantador"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                }
            ]
        },
        {
            "paperId": "58a60c0e2896402db0883dd41250caaed10c7c9f",
            "title": "Recommender Systems and Misinformation: The Problem or the Solution?",
            "abstract": "Recommender Systems have been pointed as one of the major culprits of misinformation spreading in the digital sphere. These systems have recently gone under heavy criticism for promoting the creation of filter bubbles, lowering the diversity of information users are exposed to and the social contacts they create. This influences the dynamics of social news sharing, and particularly the ways misinformation initiates and propagates. However, while Recommender Systems have been accused of fuelling the spread of misinformation, it is still unclear which particular types of recommender algorithms are more prone to recommend misinforming news, and if, and how, existing recommendation algorithms and evaluation metrics, can be modified or adapted to mitigate the misinformation spreading effect. In this position paper, we describe some of the key challenges behind assessing and measuring the effect of existing recommendation algorithms on the recommendation of misinforming articles and how such algorithms could be adapted, modified, and evaluated to counter this effect based on existing social science and psychology research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "1738219",
                    "name": "Alejandro Bellog\u00edn"
                }
            ]
        }
    ]
}