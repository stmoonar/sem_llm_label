{
    "authorId": "2114100776",
    "papers": [
        {
            "paperId": "72f38d513a8ab095a3d4f459958cbb31b1f7cdc4",
            "title": "Universal Time-Series Representation Learning: A Survey",
            "abstract": "Time-series data exists in every corner of real-world systems and services, ranging from satellites in the sky to wearable devices on human bodies. Learning representations by extracting and inferring valuable information from these time series is crucial for understanding the complex dynamics of particular phenomena and enabling informed decisions. With the learned representations, we can perform numerous downstream analyses more effectively. Among several approaches, deep learning has demonstrated remarkable performance in extracting hidden patterns and features from time-series data without manual feature engineering. This survey first presents a novel taxonomy based on three fundamental elements in designing state-of-the-art universal representation learning methods for time series. According to the proposed taxonomy, we comprehensively review existing studies and discuss their intuitions and insights into how these methods enhance the quality of learned representations. Finally, as a guideline for future studies, we summarize commonly used experimental setups and datasets and discuss several promising research directions. An up-to-date corresponding resource is available at https://github.com/itouchz/awesome-deep-time-series-representations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "134607506",
                    "name": "Patara Trirat"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "153041205",
                    "name": "Junhyeok Kang"
                },
                {
                    "authorId": "1900303688",
                    "name": "Youngeun Nam"
                },
                {
                    "authorId": "2278435709",
                    "name": "Jihye Na"
                },
                {
                    "authorId": "2278437886",
                    "name": "Minyoung Bae"
                },
                {
                    "authorId": "2278590857",
                    "name": "Joeun Kim"
                },
                {
                    "authorId": "2196449069",
                    "name": "Byunghyun Kim"
                },
                {
                    "authorId": "2222379427",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "a65df3205cc9f0380cf4f5c46ca58033d7caab65",
            "title": "Breaking the Time-Frequency Granularity Discrepancy in Time-Series Anomaly Detection",
            "abstract": "In light of the remarkable advancements made in time-series anomaly detection(TSAD), recent emphasis has been placed on exploiting the frequency domain as well as the time domain to address the difficulties in precisely detecting pattern-wise anomalies. However, in terms of anomaly scores, the window granularity of the frequency domain is inherently distinct from the data-point granularity of the time domain. Owing to this discrepancy, the anomaly information in the frequency domain has not been utilized to its full potential for TSAD. In this paper, we propose a TSAD framework, Dual-TF, that simultaneously uses both the time and frequency domains while breaking the time-frequency granularity discrepancy. To this end, our framework employs nested-sliding windows, with the outer and inner windows responsible for the time and frequency domains, respectively, and aligns the anomaly scores of the two domains. As a result of the high resolution of the aligned scores, the boundaries of pattern-wise anomalies can be identified more precisely. In six benchmark datasets, our framework outperforms state-of-the-art methods by 12.0--147%, as demonstrated by experimental results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1900303688",
                    "name": "Youngeun Nam"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2278437886",
                    "name": "Minyoung Bae"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2222379427",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "2179670697",
                    "name": "Byung Suk Lee"
                }
            ]
        },
        {
            "paperId": "9736cc2d5b52bb2c9fd305d07f23b4a6c70cefc9",
            "title": "Context Consistency Regularization for Label Sparsity in Time Series",
            "abstract": "Labels are typically sparse in real-world time series due to the high annotation cost. Recently, consistency regularization techniques have been used to generate artificial labels from unlabeled augmented instances. To fully exploit the sequential characteristic of time series in consistency regularization, we propose a novel method of data augmentation called context-attached augmentation , which adds preceding and succeeding instances to a target instance to form its augmented instance. Unlike the existing augmentation techniques that modify a target instance by directly perturbing its attributes, the context-attached augmentation generates instances augmented with varying contexts while maintaining the target instance. Based on our augmentation method, we propose a context consistency regularization framework, which first adds different contexts to a target instance sampled from a given time series and then shares unitary reliability-based cross-window labels across the augmented instances to maintain consistency. We demonstrate that the proposed framework outperforms the existing state-of-the-art consistency regularization frameworks through comprehensive experiments on real-world time-series datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2196449069",
                    "name": "Byunghyun Kim"
                },
                {
                    "authorId": "2143422249",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "2152439884",
                    "name": "Byung Suk Lee"
                }
            ]
        },
        {
            "paperId": "eaab62c1865f2359e98117f063e1190d16ec602a",
            "title": "Adaptive Shortcut Debiasing for Online Continual Learning",
            "abstract": "We propose a novel framework DropTop that suppresses the shortcut bias in online continual learning (OCL) while being adaptive to the varying degree of the shortcut bias incurred by continuously changing environment. By the observed high-attention property of the shortcut bias, highly-activated features are considered candidates for debiasing. More importantly, resolving the limitation of the online environment where prior knowledge and auxiliary data are not ready, two novel techniques---feature map fusion and adaptive intensity shifting---enable us to automatically determine the appropriate level and proportion of the candidate shortcut features to be dropped. Extensive experiments on five benchmark datasets demonstrate that, when combined with various OCL algorithms, DropTop increases the average accuracy by up to 10.4% and decreases the forgetting by up to 63.2%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47181890",
                    "name": "Doyoung Kim"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2267360301",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "11ba4fc174d7a571e9f8ea16b3c6e814fac44c14",
            "title": "Meta-Query-Net: Resolving Purity-Informativeness Dilemma in Open-set Active Learning",
            "abstract": "Unlabeled data examples awaiting annotations contain open-set noise inevitably. A few active learning studies have attempted to deal with this open-set noise for sample selection by filtering out the noisy examples. However, because focusing on the purity of examples in a query set leads to overlooking the informativeness of the examples, the best balancing of purity and informativeness remains an important question. In this paper, to solve this purity-informativeness dilemma in open-set active learning, we propose a novel Meta-Query-Net,(MQ-Net) that adaptively finds the best balancing between the two factors. Specifically, by leveraging the multi-round property of active learning, we train MQ-Net using a query set without an additional validation set. Furthermore, a clear dominance relationship between unlabeled examples is effectively captured by MQ-Net through a novel skyline regularization. Extensive experiments on multiple open-set active learning scenarios demonstrate that the proposed MQ-Net achieves 20.14% improvement in terms of accuracy, compared with the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "50860637",
                    "name": "Jihwan Bang"
                },
                {
                    "authorId": "2145439766",
                    "name": "Youngjune Lee"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "d3a88b229ee1eba9a350b75ef58cf41c4d1b1479",
            "title": "Meta-Learning for Online Update of Recommender Systems",
            "abstract": "Online recommender systems should be always aligned with users' current interest to accurately suggest items that each user would like. Since user interest usually evolves over time, the update strategy should be flexible to quickly catch users' current interest from continuously generated new user-item interactions. Existing update strategies focus either on the importance of each user-item interaction or the learning rate for each recommender parameter, but such one-directional flexibility is insufficient to adapt to varying relationships between interactions and parameters. In this paper, we propose MeLON, a meta-learning based novel online recommender update strategy that supports two-directional flexibility. It is featured with an adaptive learning rate for each parameter-interaction pair for inducing a recommender to quickly learn users' up-to-date interest. The procedure of MeLON is optimized following a meta-learning approach: it learns how a recommender learns to generate the optimal learning rates for future updates. Specifically, MeLON first enriches the meaning of each interaction based on previous interactions and identifies the role of each parameter for the interaction; and then combines these two pieces of information to generate an adaptive learning rate. Theoretical analysis and extensive evaluation on three real-world online recommender datasets validate the effectiveness of MeLON.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "ebcccfde75e54bcb412f8399ec9f01b6cb403ef3",
            "title": "Multiple Dynamic Outlier-Detection from a Data Stream by Exploiting Duality of Data and Queries",
            "abstract": "Real-time outlier detection from a data stream has become increasingly important in the current hyperconnected world. This paper focuses on an important yet unaddressed challenge in continuous outlier detection: the multiplicity and dynamicity of queries. This challenge arises from various contexts of outliers evolving over time, but the state-of-the-art algorithms cannot handle the challenge effectively, as they can only process a fixed set of outlier detection queries for each data point separately. In this paper, we propose a novel algorithm, abbreviated as MDUAL, based on a new idea called duality-based unified processing. The underlying rationale is to exploit the duality of data and queries so that a group of similar data points are processed together by a group of similar queries incrementally. Two main techniques embodying the idea, data-query grouping and prioritized group processing, are employed. Comprehensive experiments showed that MDUAL runs 216 to 221 times faster while consuming 11 to 13 times less memory than the state-of-the-art algorithms through its efficient and effective handling of the multiplicity-dynamicity challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3396235",
                    "name": "Susik Yoon"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2143422249",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "145056611",
                    "name": "B. Lee"
                }
            ]
        },
        {
            "paperId": "24b9615636962dfd90109cdbb575da34cf54b506",
            "title": "Robust Learning by Self-Transition for Handling Noisy Labels",
            "abstract": "Real-world data inevitably contains noisy labels, which induce the poor generalization of deep neural networks. It is known that the network typically begins to rapidly memorize false-labeled samples after a certain point of training. Thus, to counter the label noise challenge, we propose a novel self-transitional learning method called MORPH, which automatically switches its learning phase at the transition point from seeding to evolution. In the seeding phase, the network is updated using all the samples to collect a seed of clean samples. Then, in the evolution phase, the network is updated using only the set of arguably clean samples, which precisely keeps expanding by the updated network. Thus, MORPH effectively avoids the overfitting to false-labeled samples throughout the entire training period. Extensive experiments using five real-world or synthetic benchmark datasets demonstrate substantial improvements over state-of-the-art methods in terms of robustness and efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e",
            "title": "Learning From Noisy Labels With Deep Neural Networks: A Survey",
            "abstract": "Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "22656934",
                    "name": "Hwanjun Song"
                },
                {
                    "authorId": "2116505638",
                    "name": "Minseok Kim"
                },
                {
                    "authorId": "2122896649",
                    "name": "Dongmin Park"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2143422191",
                    "name": "Jae-Gil Lee"
                }
            ]
        },
        {
            "paperId": "854caeff401a85ea22d1321f8eb077806208d035",
            "title": "Accurate and Fast Federated Learning via IID and Communication-Aware Grouping",
            "abstract": "Federated learning has emerged as a new paradigm of collaborative machine learning; however, it has also faced several challenges such as non-independent and identically distributed(IID) data and high communication cost. To this end, we propose a novel framework of IID and communication-aware group federated learning that simultaneously maximizes both accuracy and communication speed by grouping nodes based on data distributions and physical locations of the nodes. Furthermore, we provide a formal convergence analysis and an efficient optimization algorithm called FedAvg-IC. Experimental results show that, compared with the state-of-the-art algorithms, FedAvg-IC improved the test accuracy by up to 22.2% and simultaneously reduced the communication time to as small as 12%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108524459",
                    "name": "Jin-Woo Lee"
                },
                {
                    "authorId": "46299565",
                    "name": "Jaehoon Oh"
                },
                {
                    "authorId": "2114100776",
                    "name": "Yooju Shin"
                },
                {
                    "authorId": "2143422249",
                    "name": "Jae-Gil Lee"
                },
                {
                    "authorId": "1748903557",
                    "name": "Seyoul Yoon"
                }
            ]
        }
    ]
}