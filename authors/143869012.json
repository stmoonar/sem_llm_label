{
    "authorId": "143869012",
    "papers": [
        {
            "paperId": "0cc9d031ca2f85c1412d5eab9449416c47b8cacd",
            "title": "Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning",
            "abstract": "Mathematical reasoning is one of the crucial abilities of general artificial intelligence, which requires machines to master mathematical logic and knowledge from solving problems. However, existing approaches are not transparent (thus not interpretable) in terms of what knowledge has been learned and applied in the reasoning process. In this paper, we propose a general Learning by Applying (LeAp) framework to enhance existing models (backbones) in a principled way by explicit knowledge learning. In LeAp, we perform knowledge learning in a novel problem-knowledge-expression paradigm, with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge Decoder to apply knowledge for expression reasoning. The learned mathematical knowledge, including word-word relations and word-operator relations, forms an explicit knowledge graph, which bridges the knowledge \u201clearning\u201d and \u201capplying\u201d organically. Moreover, for problem solving, we design a semantics-enhanced module and a reasoning-enhanced module that apply knowledge to improve the problem comprehension and symbol reasoning abilities of any backbone, respectively. We theoretically prove the superiority of LeAp's autonomous learning mechanism. Experiments on three real-world datasets show that LeAp improves all backbones' performances, learns accurate knowledge, and achieves a more interpretable reasoning process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2178815482",
                    "name": "Jia-Yin Liu"
                },
                {
                    "authorId": "3374015",
                    "name": "Zhenya Huang"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                },
                {
                    "authorId": "2187904641",
                    "name": "Qi Liu"
                }
            ]
        },
        {
            "paperId": "1f78eb8e03774209cff65dba4bfd3b95aef77ded",
            "title": "oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes",
            "abstract": "In this paper, we introduce the range of oBERTa language models, an easy-to-use set of language models which allows Natural Language Processing (NLP) practitioners to obtain between 3.8 and 24.3 times faster models without expertise in model compression. Specifically, oBERTa extends existing work on pruning, knowledge distillation, and quantization and leverages frozen embeddings improves distillation and model initialization to deliver higher accuracy on a broad range of transfer tasks. In generating oBERTa, we explore how the highly optimized RoBERTa differs from the BERT for pruning during pre-training and finetuning. We find it less amenable to compression during fine-tuning. We explore the use of oBERTa on seven representative NLP tasks and find that the improved compression techniques allow a pruned oBERTa model to match the performance of BERTbase and exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering dataset, despite being 8x and 2x, respectively faster in inference. We release our code, training regimes, and associated model for broad usage to encourage usage and experimentation",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144081089",
                    "name": "Daniel Fernando Campos"
                },
                {
                    "authorId": "2166312585",
                    "name": "Alexandre Marques"
                },
                {
                    "authorId": "2070446213",
                    "name": "Mark Kurtz"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "4be694b101230da39a035c0cf4ebb90aa569879c",
            "title": "Quick Dense Retrievers Consume KALE: Post Training KullbackLeibler Alignment of Embeddings for Asymmetrical dual encoders",
            "abstract": "In this paper, we consider the problem of improving the inference latency of language model-based dense retrieval systems by introducing structural compression and model size asymmetry between the context and query encoders. First, we investigate the impact of pre and post-training compression on the MSMARCO, Natural Questions, TriviaQA, SQUAD, and SCIFACT, finding that asymmetry in the dual encoders in dense retrieval can lead to improved inference efficiency. Knowing this, we introduce Kullback Leibler Alignment of Embeddings (KALE), an efficient and accurate method for increasing the inference efficiency of dense retrieval methods by pruning and aligning the query encoder after training. Specifically, KALE extends traditional Knowledge Distillation after bi-encoder training, allowing for effective query encoder compression without full retraining or index generation. Using KALE and asymmetric training, we can generate models which exceed the performance of DistilBERT despite having 3x faster inference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144081089",
                    "name": "Daniel Fernando Campos"
                },
                {
                    "authorId": "2079082945",
                    "name": "Alessandro Magnani"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "5ccd5045e5cddc213eafecabb6e4d06d69d2380c",
            "title": "C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation",
            "abstract": "Existing reference-free turn-level evaluation metrics for chatbots inadequately capture the interaction between the user and the system. Consequently, they often correlate poorly with human evaluations. To address this issue, we propose a novel model-agnostic approach that leverages Conditional Pointwise Mutual Information (C-PMI) to measure the turn-level interaction between the system and the user based on a given evaluation dimension. Experimental results on the widely used FED dialogue evaluation dataset demonstrate that our approach significantly improves the correlation with human judgment compared with existing evaluation systems. By replacing the negative log-likelihood-based scorer with our proposed C-PMI scorer, we achieve a relative 60.5% higher Spearman correlation on average for the FED evaluation metric. Our code is publicly available at https://github.com/renll/C-PMI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46177458",
                    "name": "Liliang Ren"
                },
                {
                    "authorId": "2192788718",
                    "name": "Mankeerat Sidhu"
                },
                {
                    "authorId": "145653969",
                    "name": "Qi Zeng"
                },
                {
                    "authorId": "2113583612",
                    "name": "R. Reddy"
                },
                {
                    "authorId": "2072975661",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "8f4e198467de15fdbb305d0982ff6f15565ab601",
            "title": "To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency",
            "abstract": "Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144081089",
                    "name": "Daniel Fernando Campos"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "8f57052eeeb3cc04159655583cb9ed2396ade233",
            "title": "Competence-Based Analysis of Language Models",
            "abstract": "Despite the recent success of large pretrained language models (LMs) on a variety of prompting tasks, these models can be alarmingly brittle to small changes in inputs or application contexts. To better understand such behavior and motivate the design of more robust LMs, we propose a general experimental framework, CALM (Competence-based Analysis of Language Models), where targeted causal interventions are utilized to damage an LM's internal representation of various linguistic properties in order to evaluate its use of each representation in performing a given task. We implement these interventions as gradient-based adversarial attacks, which (in contrast to prior causal probing methodologies) are able to target arbitrarily-encoded representations of relational properties, and carry out a case study of this approach to analyze how BERT-like LMs use representations of several relational properties in performing associated relation prompting tasks. We find that, while the representations LMs leverage in performing each task are highly entangled, they may be meaningfully interpreted in terms of the tasks where they are most utilized; and more broadly, that CALM enables an expanded scope of inquiry in LM analysis that may be useful in predicting and explaining weaknesses of existing LMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065357535",
                    "name": "Adam Davies"
                },
                {
                    "authorId": "144931659",
                    "name": "Jize Jiang"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "ad6a1ef3f75bcfda9f7a3567d45f0b5ac108e431",
            "title": "CAM: A Large Language Model-based Creative Analogy Mining Framework",
            "abstract": "Analogies inspire creative solutions to problems, and facilitate the creative expression of ideas and the explanation of complex concepts. They have widespread applications in scientific innovation, creative writing, and education. The ability to discover creative analogies that are not explicitly mentioned but can be inferred from the web is highly desirable to power all such applications dynamically and augment human creativity. Recently, Large Pre-trained Language Models (PLMs), trained on massive Web data, have shown great promise in generating mostly known analogies that are explicitly mentioned on the Web. However, it is unclear how they could be leveraged for mining creative analogies not explicitly mentioned on the Web. We address this challenge and propose Creative Analogy Mining (CAM), a novel framework for mining creative analogies, which consists of the following three main steps: 1) Generate analogies using PLMs with effectively designed prompts, 2) Evaluate their quality using scoring functions, and 3) Refine the low-quality analogies by another round of prompt-based generation. We propose both unsupervised and supervised instantiations of the framework so that it can be used even without any annotated data. Based on human evaluation using Amazon Mechanical Turk, we find that our unsupervised framework can mine 13.7% highly-creative and 56.37% somewhat-creative analogies. Moreover, our supervised scores are generally better than the unsupervised ones and correlate moderately with human evaluators, indicating that they would be even more effective at mining creative analogies. These findings also shed light on the creativity of PLMs 1.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2080053811",
                    "name": "B. Bhavya"
                },
                {
                    "authorId": "145042856",
                    "name": "Jinjun Xiong"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "d2d0371158803df93a249c9f7237ffd79b875816",
            "title": "Sparse Modular Activation for Efficient Sequence Modeling",
            "abstract": "Linear State Space Models (SSMs) have demonstrated strong performance in a variety of sequence modeling tasks due to their efficient encoding of the recurrent structure. However, in more comprehensive tasks like language modeling and machine translation, self-attention-based models still outperform SSMs. Hybrid models employing both SSM and self-attention generally show promising performance, but current approaches apply attention modules statically and uniformly to all elements in the input sequences, leading to sub-optimal quality-efficiency trade-offs. In this work, we introduce Sparse Modular Activation (SMA), a general mechanism enabling neural networks to sparsely and dynamically activate sub-modules for sequence elements in a differentiable manner. Through allowing each element to skip non-activated sub-modules, SMA reduces computation and memory consumption at both training and inference stages of sequence modeling. As a specific instantiation of SMA, we design a novel neural architecture, SeqBoat, which employs SMA to sparsely activate a Gated Attention Unit (GAU) based on the state representations learned from an SSM. By constraining the GAU to only conduct local attention on the activated inputs, SeqBoat can achieve linear inference complexity with theoretically infinite attention span, and provide substantially better quality-efficiency trade-off than the chunking-based models. With experiments on a wide range of tasks, including language modeling, speech classification and long-range arena, SeqBoat brings new state-of-the-art results among hybrid models with linear complexity and reveals the amount of attention needed for each task through the learned sparse activation patterns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46177458",
                    "name": "Liliang Ren"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2146294891",
                    "name": "Shuo Wang"
                },
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                }
            ]
        },
        {
            "paperId": "0a562b4fdc4fe032efdef7f6e6b9cf57aa41c7ba",
            "title": "When to Use What: An In-Depth Comparative Empirical Analysis of OpenIE Systems for Downstream Applications",
            "abstract": "Open Information Extraction (OpenIE) has been used in the pipelines of various NLP tasks. Unfortunately, there is no clear consensus on which models to use in which tasks. Muddying things further is the lack of comparisons that take differing training sets into account. In this paper, we present an application-focused empirical survey of neural OpenIE models, training sets, and benchmarks in an effort to help users choose the most suitable OpenIE systems for their applications. We find that the different assumptions made by different models and datasets have a statistically significant effect on performance, making it important to choose the most appropriate model for one\u2019s applications. We demonstrate the applicability of our recommendations on a downstream Complex QA application.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064980098",
                    "name": "Kevin Pei"
                },
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "143922493",
                    "name": "K. Chang"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "41c1fcccb6609be71475aee3e2fa9bd4e425e977",
            "title": "Incorporating Task-Specific Concept Knowledge into Script Learning",
            "abstract": "In this paper, we present Tetris, a new task of Goal-Oriented Script Completion. Unlike previous work, it considers a more realistic and general setting, where the input includes not only the goal but also additional user context, including preferences and history. To address this problem, we propose a novel approach, which uses two techniques to improve performance: (1) concept prompting, and (2) script-oriented contrastive learning that addresses step repetition and hallucination problems. On our WikiHow-based dataset, we find that both methods improve performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118831287",
                    "name": "Chenkai Sun"
                },
                {
                    "authorId": "50383834",
                    "name": "Tie Xu"
                },
                {
                    "authorId": "143869012",
                    "name": "Chengxiang Zhai"
                },
                {
                    "authorId": "2072975661",
                    "name": "Heng Ji"
                }
            ]
        }
    ]
}