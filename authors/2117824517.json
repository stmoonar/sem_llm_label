{
    "authorId": "2117824517",
    "papers": [
        {
            "paperId": "1b5efd5e81b1c098116d06a1f4cdef5e111d5dca",
            "title": "Manipulating Recommender Systems: A Survey of Poisoning Attacks and Countermeasures",
            "abstract": "Recommender systems have become an integral part of online services due to their ability to help users locate specific information in a sea of data. However, existing studies show that some recommender systems are vulnerable to poisoning attacks particularly those that involve learning schemes. A poisoning attack is where an adversary injects carefully crafted data into the process of training a model, with the goal of manipulating the system\u2019s final recommendations. Based on recent advancements in artificial intelligence (AI), such attacks have gained importance recently. At present, we do not have a full and clear picture of why adversaries mount such attacks, nor do we have comprehensive knowledge of the full capacity to which such attacks can undermine a model or the impacts that might have. While numerous countermeasures to poisoning attacks have been developed, they have not yet been systematically linked to the properties of the attacks. Consequently, assessing the respective risks and potential success of mitigation strategies is difficult, if not impossible. This survey aims to fill this gap by primarily focusing on poisoning attacks and their countermeasures. This is in contrast to prior surveys that mainly focus on attacks and their detection methods. Through an exhaustive literature review, we provide a novel taxonomy for poisoning attacks, formalise its dimensions, and accordingly organise 31 attacks described in the literature. Further, we review 43 countermeasures to detect and/or prevent poisoning attacks, evaluating their effectiveness against specific types of attacks. This comprehensive survey should serve as a point of reference for protecting recommender systems against poisoning attacks. The article concludes with a discussion on open issues in the field and impactful directions for future research. A rich repository of resources associated with poisoning attacks is available at https://github.com/tamlhp/awesome-recsys-poisoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152639787",
                    "name": "Thanh Toan Nguyen"
                },
                {
                    "authorId": "2264230011",
                    "name": "Quoc Viet Hung Nguyen"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2257265858",
                    "name": "Matthias Weidlich"
                },
                {
                    "authorId": "2278795560",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "40f8cbaf22910eaa37e6dea63af2bf5f9680cca9",
            "title": "Heterogeneous Hypergraph Embedding for Recommendation Systems",
            "abstract": "Recent advancements in recommender systems have focused on integrating knowledge graphs (KGs) to leverage their auxiliary information. The core idea of KG-enhanced recommenders is to incorporate rich semantic information for more accurate recommendations. However, two main challenges persist: i) Neglecting complex higher-order interactions in the KG-based user-item network, potentially leading to sub-optimal recommendations, and ii) Dealing with the heterogeneous modalities of input sources, such as user-item bipartite graphs and KGs, which may introduce noise and inaccuracies. To address these issues, we present a novel Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). KHGRec captures group-wise characteristics of both the interaction network and the KG, modeling complex connections in the KG. Using a collaborative knowledge heterogeneous hypergraph (CKHG), it employs two hypergraph encoders to model group-wise interdependencies and ensure explainability. Additionally, it fuses signals from the input graphs with cross-view self-supervised learning and attention mechanisms. Extensive experiments on four real-world datasets show our model's superiority over various state-of-the-art baselines, with an average 5.18\\% relative improvement. Additional tests on noise resilience, missing data, and cold-start problems demonstrate the robustness of our KHGRec framework. Our model and evaluation datasets are publicly available at \\url{https://github.com/viethungvu1998/KHGRec}.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2037793264",
                    "name": "Darnbi Sakong"
                },
                {
                    "authorId": "2188254328",
                    "name": "Viet Hung Vu"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2290449405",
                    "name": "Phi Le Nguyen"
                },
                {
                    "authorId": "2278795560",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                }
            ]
        },
        {
            "paperId": "5063d1b976c20853a966d3a29b78ffd7302c9f22",
            "title": "Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew Resilience",
            "abstract": "Federated learning (FL) has recently emerged as a compelling machine learning paradigm, prioritizing the protection of privacy for training data. The increasing demand to address issues such as ``the right to be forgotten'' and combat data poisoning attacks highlights the importance of techniques, known as \\textit{unlearning}, which facilitate the removal of specific training data from trained FL models. Despite numerous unlearning methods proposed for centralized learning, they often prove inapplicable to FL due to fundamental differences in the operation of the two learning paradigms. Consequently, unlearning in FL remains in its early stages, presenting several challenges. Many existing unlearning solutions in FL require a costly retraining process, which can be burdensome for clients. Moreover, these methods are primarily validated through experiments, lacking theoretical assurances. In this study, we introduce Fast-FedUL, a tailored unlearning method for FL, which eliminates the need for retraining entirely. Through meticulous analysis of the target client's influence on the global model in each round, we develop an algorithm to systematically remove the impact of the target client from the trained model. In addition to presenting empirical findings, we offer a theoretical analysis delineating the upper bound of our unlearned model and the exact retrained model (the one obtained through retraining using untargeted clients). Experimental results with backdoor attack scenarios indicate that Fast-FedUL effectively removes almost all traces of the target client, while retaining the knowledge of untargeted clients (obtaining a high accuracy of up to 98\\% on the main task). Significantly, Fast-FedUL attains the lowest time complexity, providing a speed that is 1000 times faster than retraining. Our source code is publicly available at \\url{https://github.com/thanhtrunghuynh93/fastFedUL}.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2223074507",
                    "name": "Trong Bang Nguyen"
                },
                {
                    "authorId": "2290449405",
                    "name": "Phi Le Nguyen"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2257265858",
                    "name": "Matthias Weidlich"
                },
                {
                    "authorId": "2264230011",
                    "name": "Quoc Viet Hung Nguyen"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                }
            ]
        },
        {
            "paperId": "780c60e01189ebc18ad2d1f6b9edaeb3b33dd2d1",
            "title": "A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures",
            "abstract": "As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have established an online resource repository, which will be continuously updated with new and relevant findings. Interested readers are encouraged to access our repository at https://github.com/tamlhp/awesome-privex.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2210372166",
                    "name": "Zhao Ren"
                },
                {
                    "authorId": "2152639787",
                    "name": "Thanh Toan Nguyen"
                },
                {
                    "authorId": "2290449405",
                    "name": "Phi Le Nguyen"
                },
                {
                    "authorId": "2278795560",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "b451d72b5f3e71afafc6e09167914e99868b6db4",
            "title": "A dual benchmarking study of facial forgery and facial forensics",
            "abstract": "In recent years, visual facial forgery has reached a level of sophistication that humans cannot identify fraud, which poses a significant threat to information security. A wide range of malicious applications have emerged, such as deepfake, fake news, defamation or blackmailing of celebrities, impersonation of politicians in political warfare, and the spreading of rumours to attract views. As a result, a rich body of visual forensic techniques has been proposed in an attempt to stop this dangerous trend. However, there is no comprehensive, fair, and unified performance evaluation to enlighten the community on best performing methods. The authors present a systematic benchmark beyond traditional surveys that provides in\u2010depth insights into facial forgery and facial forensics, grounding on robustness tests such as contrast, brightness, noise, resolution, missing information, and compression. The authors also provide a practical guideline of the benchmarking results, to determine the characteristics of the methods that serve as a comparative reference in this never\u2010ending war between measures and countermeasures. The authors\u2019 source code is open to the public.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "36d916c261e18b91577730d10d5cd23a0464f046",
            "title": "Efficient and Effective Multi-Modal Queries through Heterogeneous Network Embedding (Extended Abstract)",
            "abstract": "Recent information retrieval (IR) systems answer a multi-modal query by considering it as a set of separate uni-modal queries. However, depending on the chosen operationalisation, such an approach is inefficient or ineffective. It either requires multiple passes over the data or leads to inaccuracies since the relations between data modalities are neglected in the relevance assessment. To mitigate these challenges, we present an IR system that has been designed to answer genuine multi-modal queries. It relies on a heterogeneous network embedding, so that features from diverse modalities can be incorporated when representing both, a query and the data over which it shall be evaluated. An experimental evaluation using diverse real-world and synthetic datasets illustrates that our approach returns twice the amount of relevant information compared to baseline techniques, while scaling to large multi-modal databases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "39822639",
                    "name": "Chi Thang Duong"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2315762",
                    "name": "M. Weidlich"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "bc0988820ac81e16b703168355858c2fd6d5762a",
            "title": "Isomorphic Graph Embedding for Progressive Maximal Frequent Subgraph Mining",
            "abstract": "Maximal frequent subgraph mining (MFSM) is the task of mining only maximal frequent subgraphs, i.e., subgraphs that are not a part of other frequent subgraphs. Although many intelligent systems require MFSM, MFSM is challenging compared to frequent subgraph mining (FSM), as maximal frequent subgraphs lie in the middle of graph lattice, and FSM algorithms must explore an exponential space and an NP-hard subroutine of frequency counting. Different from prior research, which primarily focused on optimal solutions, we introduce pmMine, a progressive graph neural framework designed for MFSM in a single large graph to attain an approximate solution. The framework combines isomorphic graph embedding, non-parametric partitioning, and an efficiently top-down pattern searching strategy. The critical insight that makes pmMine work is to define the concepts of rooted subgraph and isomorphic graph embedding, in which the costly isomorphism subroutine can be efficiently performed using similarity estimation in embedding space. In addition, pmMine returns the patterns identified during the mining process in a progressive manner. We validate the efficiency and effectiveness of our technique through extensive experiments on a variety of datasets spanning various domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152639787",
                    "name": "Thanh Toan Nguyen"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2290276091",
                    "name": "Thanh Hung Nguyen"
                },
                {
                    "authorId": "2257288106",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2093140094",
                    "name": "Jun Jo"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "f1c876ecdc210b013af96a86d636c380d5b8788b",
            "title": "Complex Representation Learning with Graph Convolutional Networks for Knowledge Graph Alignment",
            "abstract": "The task of discovering equivalent entities in knowledge graphs (KGs), so-called KG entity alignment, has drawn much attention to overcome the incompleteness problem of KGs. The majority of existing techniques learns the pointwise representations of entities in the Euclidean space with translation assumption and graph neural network approaches. However, real vectors inherently neglect the complex relation structures and lack the expressiveness of embeddings; hence, they may guide the embeddings to be falsely generated which results in alignment performance degradation. To overcome these problems, we propose a novel KG alignment framework, ComplexGCN, which learns the embeddings of both entities and relations in complex spaces while capturing both semantic and neighborhood information simultaneously. The proposed model ensures richer expressiveness and more accurate embeddings by successfully capturing various relation structures in complex spaces with high-level computation. The model further incorporates relation label and direction information with a low degree of freedom. To compare our proposal against the state-of-the-art baseline techniques, we conducted extensive experiments on real-world datasets. The empirical results show the efficiency and effectiveness of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037793264",
                    "name": "Darnbi Sakong"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2152639787",
                    "name": "Thanh Toan Nguyen"
                },
                {
                    "authorId": "2093140094",
                    "name": "Jun Jo"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "16f57be1a600374e6777020827438a04f28e56ee",
            "title": "exRumourLens: Auditable Rumour Detection with Multi-View Explanations",
            "abstract": "Hundreds of thousands of rumours emerge every day. Algorithmic models shall therefore support users of social platforms and provide alerts to prevent users from accidentally spreading rumours. However, existing alerting mechanisms are limited to post-hoc classification, and rumours are often detected after the damage has been done. This paper presents exRumourLens, a system that enables tracking and auditing of potential rumours as they emerge. To this end, it identifies local anomalies related to individual entities, as well as global anomalies on the level of subgraphs of a network of entities. exRumourLens provides various views on such local and global anomalies, thereby providing detailed explanations on emerging rumours and supporting their critical exploration. The source code is available at https://rumourlens.github.io/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "104260487",
                    "name": "Thanh Cong Phan"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2315762",
                    "name": "M. Weidlich"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2093140094",
                    "name": "Jun Jo"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "4c00c0ac0051fb68e637a5c8bbf13d79154633f0",
            "title": "Poisoning GNN-based Recommender Systems with Generative Surrogate-based Attacks",
            "abstract": "With recent advancements in graph neural networks (GNN), GNN-based recommender systems (gRS) have achieved remarkable success in the past few years. Despite this success, existing research reveals that gRSs are still vulnerable to poison attacks, in which the attackers inject fake data to manipulate recommendation results as they desire. This might be due to the fact that existing poison attacks (and countermeasures) are either model-agnostic or specifically designed for traditional recommender algorithms (e.g., neighborhood-based, matrix-factorization-based, or deep-learning-based RSs) that are not gRS. As gRSs are widely adopted in the industry, the problem of how to design poison attacks for gRSs has become a need for robust user experience. Herein, we focus on the use of poison attacks to manipulate item promotion in gRSs. Compared to standard GNNs, attacking gRSs is more challenging due to the heterogeneity of network structure and the entanglement between users and items. To overcome such challenges, we propose GSPAttack\u2014a generative surrogate-based poison attack framework for gRSs. GSPAttack tailors a learning process to surrogate a recommendation model as well as generate fake users and user-item interactions while preserving the data correlation between users and items for recommendation accuracy. Although maintaining high accuracy for other items rather than the target item seems counterintuitive, it is equally crucial to the success of a poison attack. Extensive evaluations on four real-world datasets revealed that GSPAttack outperforms all baselines with competent recommendation performance and is resistant to various countermeasures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216506480",
                    "name": "Toan Nguyen Thanh"
                },
                {
                    "authorId": "2162010010",
                    "name": "Nguyen Duc Khang Quach"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2188254328",
                    "name": "Viet Hung Vu"
                },
                {
                    "authorId": "2143967163",
                    "name": "Phi-Le Nguyen"
                },
                {
                    "authorId": "2093140094",
                    "name": "Jun Jo"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        }
    ]
}