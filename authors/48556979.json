{
    "authorId": "48556979",
    "papers": [
        {
            "paperId": "07c53cf78f0ec5b95e89dd4fc4f5774ab486c4b5",
            "title": "DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages",
            "abstract": "Language technologies should be judged on their usefulness in real-world use cases. An often overlooked aspect in natural language processing (NLP) research and evaluation is language variation in the form of non-standard dialects or language varieties (hereafter, varieties). Most NLP benchmarks are limited to standard language varieties. To fill this gap, we propose DIALECTBENCH, the first-ever large-scale benchmark for NLP on varieties, which aggregates an extensive set of task-varied variety datasets (10 text-level tasks covering 281 varieties). This allows for a comprehensive evaluation of NLP system performance on different language varieties. We provide substantial evidence of performance disparities between standard and non-standard language varieties, and we also identify language clusters with large performance divergence across tasks. We believe DIALECTBENCH provides a comprehensive view of the current state of NLP for language varieties and one step towards advancing it further. Code/data: https://github.com/ffaisal93/DialectBench",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "1452686038",
                    "name": "Orevaoghene Ahia"
                },
                {
                    "authorId": "2169175069",
                    "name": "Aarohi Srivastava"
                },
                {
                    "authorId": "52154863",
                    "name": "Kabir Ahuja"
                },
                {
                    "authorId": "2263760783",
                    "name": "David Chiang"
                },
                {
                    "authorId": "2287930119",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "2273733474",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "291dec375a9db2108d219fb26a631deed917deb6",
            "title": "Data-Augmentation-Based Dialectal Adaptation for LLMs",
            "abstract": "This report presents gmnlp\u2019s participation to the Dialect-Copa shared task at VarDial 2024 (Chifu et al., 2024), which focuses on evaluating the commonsense reasoning capabilities of large language models (LLMs) on South Slavic micro-dialects. The task aims to assess how well LLMs can handle non-standard dialectal varieties, as their performance on standard languages is already well-established. We propose an approach that combines the strengths of different types of language models and leverages data augmentation techniques to improve task performance on three South Slavic dialects: Chakavian, Cherkano, and Torlak. We conduct experiments using a language-family-focused encoder-based model (BERTi\u0107) and a domain-agnostic multilingual model (AYA-101). Our results demonstrate that the proposed data augmentation techniques lead to substantial performance gains across all three test datasets in the open-source model category. This work highlights the practical utility of data augmentation and the potential of LLMs in handling non-standard dialectal varieties, contributing to the broader goal of advancing natural language understanding in low-resource and dialectal settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "2273733474",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "41173fa8cb93f51a4f8e2c023a2767c4f03e2ad0",
            "title": "An Efficient Approach for Studying Cross-Lingual Transfer in Multilingual Language Models",
            "abstract": "The capacity and effectiveness of pre-trained multilingual models (MLMs) for zero-shot cross-lingual transfer is well established. However, phenomena of positive or negative transfer, and the effect of language choice still need to be fully understood, especially in the complex setting of massively multilingual LMs. We propose an \\textit{efficient} method to study transfer language influence in zero-shot performance on another target language. Unlike previous work, our approach disentangles downstream tasks from language, using dedicated adapter units. Our findings suggest that some languages do not largely affect others, while some languages, especially ones unseen during pre-training, can be extremely beneficial or detrimental for different target languages. We find that no transfer language is beneficial for all target languages. We do, curiously, observe languages previously unseen by MLMs consistently benefit from transfer from almost any language. We additionally use our modular approach to quantify negative interference efficiently and categorize languages accordingly. Furthermore, we provide a list of promising transfer-target language configurations that consistently lead to target language performance improvements. Code and data are publicly available: https://github.com/ffaisal93/neg_inf",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "2273733474",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "17605c43ca3eb982c99642052ddc21a93d116594",
            "title": "GlobalBench: A Benchmark for Global Progress in Natural Language Processing",
            "abstract": "Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "148310739",
                    "name": "Yueqi Song"
                },
                {
                    "authorId": "2218206121",
                    "name": "Catherine Cui"
                },
                {
                    "authorId": "1452678825",
                    "name": "Simran Khanuja"
                },
                {
                    "authorId": "144118452",
                    "name": "Pengfei Liu"
                },
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "1475670743",
                    "name": "Alissa Ostapenko"
                },
                {
                    "authorId": "9162688",
                    "name": "Genta Indra Winata"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "66986482",
                    "name": "Samuel Cahyawijaya"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                },
                {
                    "authorId": "1700325",
                    "name": "Graham Neubig"
                }
            ]
        },
        {
            "paperId": "5bd254c0775d18cdc30cb85be61e080484ee6713",
            "title": "Multilingual Text Representation",
            "abstract": "Modern NLP breakthrough includes large multilingual models capable of performing tasks across more than 100 languages. State-of-the-art language models came a long way, starting from the simple one-hot representation of words capable of performing tasks like natural language understanding, common-sense reasoning, or question-answering, thus capturing both the syntax and semantics of texts. At the same time, language models are expanding beyond our known language boundary, even competitively performing over very low-resource dialects of endangered languages. However, there are still problems to solve to ensure an equitable representation of texts through a unified modeling space across language and speakers. In this survey, we shed light on this iterative progression of multilingual text representation and discuss the driving factors that ultimately led to the current state-of-the-art. Subsequently, we discuss how the full potential of language democratization could be obtained, reaching beyond the known limits and what is the scope of improvement in that space.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                }
            ]
        },
        {
            "paperId": "75f55ca627dbf08fac0d96c060d346e40af0626a",
            "title": "A Gradient Boosted ML Approach to Feature Selection for Wireless Intrusion Detection",
            "abstract": "The regular discovery of new attacks on 802.11 wireless devices emphasizes the importance of developing ML-based intrusion detection systems that generalize to such attacks. Class-imbalance issues in intrusion datasets pose a learning problem for ML solutions. Our methodology directly incorporates the class-imbalance issues to learn better feature importance measures. With features extracted using this technique from the AWID dataset, we use a gradient-boosted model to show that these features are necessary to generalize to new attack types in the AWID test dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2230356674",
                    "name": "Birupaxha Mondal"
                },
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "2231606205",
                    "name": "Zeba Tusnia Towshi"
                },
                {
                    "authorId": "2231636982",
                    "name": "Md Fahad Monir"
                },
                {
                    "authorId": "3332620",
                    "name": "Tarem Ahmed"
                }
            ]
        },
        {
            "paperId": "997cebb936d88577da59ba460a9141bdd5dcb36f",
            "title": "To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer",
            "abstract": "Choosing an appropriate tokenization scheme is often a bottleneck in low-resource cross-lingual transfer. To understand the downstream implications of text representation choices, we perform a comparative analysis on language models having diverse text representation modalities including 2 segmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model (\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we propose a scoring Language Quotient (LQ) metric capable of providing a weighted representation of both zero-shot and few-shot evaluation combined. Utilizing this metric, we perform experiments comprising 19 source languages and 133 target languages on three tasks (POS tagging, Dependency parsing, and NER). Our analysis reveals that image-based models excel in cross-lingual transfer when languages are closely related and share visually similar scripts. However, for tasks biased toward word meaning (POS, NER), segmentation-based models prove to be superior. Furthermore, in dependency parsing tasks where word relationships play a crucial role, models with their character-level focus, outperform others. Finally, we propose a recommendation scheme based on our findings to guide model selection according to task and language requirements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257374612",
                    "name": "Md Mushfiqur Rahman"
                },
                {
                    "authorId": "2190105207",
                    "name": "Fardin Ahsan Sakib"
                },
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        },
        {
            "paperId": "9bf03cddb68bf46b61f2461c8c34ad7842f851ef",
            "title": "Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors",
            "abstract": "Superconductors have been among the most fascinating substances, as the fundamental concept of superconductivity as well as the correlation of critical temperature and superconductive materials have been the focus of extensive investigation since their discovery. However, superconductors at normal temperatures have yet to be identified. Additionally, there are still many unknown factors and gaps of understanding regarding this unique phenomenon, particularly the connection between superconductivity and the fundamental criteria to estimate the critical temperature. To bridge the gap, numerous machine learning techniques have been established to estimate critical temperatures as it is extremely challenging to determine. Furthermore, the need for a sophisticated and feasible method for determining the temperature range that goes beyond the scope of the standard empirical formula appears to be strongly emphasized by various machine-learning approaches. This paper uses a stacking machine learning approach to train itself on the complex characteristics of superconductive materials in order to accurately predict critical temperatures. In comparison to other previous accessible research investigations, this model demonstrated a promising performance with an RMSE of 9.68 and an R2 score of 0.922. The findings presented here could be a viable technique to shed new insight on the efficient implementation of the stacking ensemble method with hyperparameter optimization (HPO).",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2229569788",
                    "name": "Fatin Abrar Shams"
                },
                {
                    "authorId": "2219559349",
                    "name": "Rashed Hasan Ratul"
                },
                {
                    "authorId": "2229575099",
                    "name": "Ahnaf Islam Naf"
                },
                {
                    "authorId": "2228915667",
                    "name": "Syed Shaek Hossain Samir"
                },
                {
                    "authorId": "65795675",
                    "name": "M. M. Nishat"
                },
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "40962800",
                    "name": "Md. Murshadul Hoque"
                }
            ]
        },
        {
            "paperId": "d42678de01b3fb66b8b3d9429b93da24da04d6e1",
            "title": "A Machine Learning Approach for Analyzing and Predicting Suicidal Thoughts and Behaviors",
            "abstract": "Suicide is a significant public health concern, and there is growing interest in using machine learning techniques to identify people who are at a high risk of committing suicide. In this paper, a review of the current state-of-the-art in suicide prediction is given using machine learning. Various features are investigated with data sources used in earlier studies, such as text-based data from social media, electronic health records, and demographic data. Also, different machine learning techniques are analyzed that are employed including neural networks. We compare the different machine learning models based on errors and find that Support Vector Regression (SVR) to be the most suitable for this purpose. We conclude by emphasizing the potential of machine learning to improve suicide prevention efforts and addressing the ethical concerns that must be discussed when implementing such models in practice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "65795675",
                    "name": "M. M. Nishat"
                },
                {
                    "authorId": "2230598376",
                    "name": "Kazi Raine Raihan"
                },
                {
                    "authorId": "46224436",
                    "name": "Ahmad Shafiullah"
                },
                {
                    "authorId": "2115366678",
                    "name": "Sanjida Ali"
                }
            ]
        },
        {
            "paperId": "ee2c4670fc3ed9d6f6b3e583dde19340bdc0e71b",
            "title": "GMNLP at SemEval-2023 Task 12: Sentiment Analysis with Phylogeny-Based Adapters",
            "abstract": "This report describes GMU\u2019s sentiment analysis system for the SemEval-2023 shared task AfriSenti-SemEval. We participated in all three sub-tasks: Monolingual, Multilingual, and Zero-Shot. Our approach uses models initialized with AfroXLMR-large, a pre-trained multilingual language model trained on African languages and fine-tuned correspondingly. We also introduce augmented training data along with original training data. Alongside finetuning, we perform phylogeny-based adapter-tuning to create several models and ensemble the best models for the final submission. Our system achieves the best F1-score on track 5: Amharic, with 6.2 points higher F1-score than the second-best performing system on this track. Overall, our system ranks 5th among the 10 systems participating in all 15 tracks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007788331",
                    "name": "Md Mahfuz Ibn Alam"
                },
                {
                    "authorId": "2202470985",
                    "name": "Ruoyu Xie"
                },
                {
                    "authorId": "48556979",
                    "name": "FAHIM FAISAL"
                },
                {
                    "authorId": "49513989",
                    "name": "Antonios Anastasopoulos"
                }
            ]
        }
    ]
}