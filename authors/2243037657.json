{
    "authorId": "2243037657",
    "papers": [
        {
            "paperId": "1fd57ba49bacc54358231931e1659648181e14c6",
            "title": "Bidirectional Gated Mamba for Sequential Recommendation",
            "abstract": "In various domains, Sequential Recommender Systems (SRS) have become essential due to their superior capability to discern intricate user preferences. Typically, SRS utilize transformer-based architectures to forecast the subsequent item within a sequence. Nevertheless, the quadratic computational complexity inherent in these models often leads to inefficiencies, hindering the achievement of real-time recommendations. Mamba, a recent advancement, has exhibited exceptional performance in time series prediction, significantly enhancing both efficiency and accuracy. However, integrating Mamba directly into SRS poses several challenges. Its inherently unidirectional nature may constrain the model's capacity to capture the full context of user-item interactions, while its instability in state estimation can compromise its ability to detect short-term patterns within interaction sequences. To overcome these issues, we introduce a new framework named Selective Gated Mamba (SIGMA) for Sequential Recommendation. This framework leverages a Partially Flipped Mamba (PF-Mamba) to construct a bidirectional architecture specifically tailored to improve contextual modeling. Additionally, an input-sensitive Dense Selective Gate (DS Gate) is employed to optimize directional weights and enhance the processing of sequential information in PF-Mamba. For short sequence modeling, we have also developed a Feature Extract GRU (FE-GRU) to efficiently capture short-term dependencies. Empirical results indicate that SIGMA outperforms current models on five real-world datasets. Our implementation code is available at https://github.com/ziwliu-cityu/SIMGA to ease reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2316826974",
                    "name": "Ziwei Liu"
                },
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2264224432",
                    "name": "Pengyue Jia"
                },
                {
                    "authorId": "2262447141",
                    "name": "Maolin Wang"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2316790244",
                    "name": "Yi Chang"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                }
            ]
        },
        {
            "paperId": "37741a9e9a2cb964ca3c7ab034c3e077baf66c8c",
            "title": "BiVRec: Bidirectional View-based Multimodal Sequential Recommendation",
            "abstract": "The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we first construct structured user interest representations and then learn the synergistic relationship between them. Specifically, BivRec comprises three modules: Multi-scale Interest Embedding, comprehensively modeling user interests by expanding user interaction sequences with multi-scale patching; Intra-View Interest Decomposition, constructing highly structured interest representations using carefully designed Gaussian attention and Cluster attention; and Cross-View Interest Learning, learning the synergistic relationship between the two recommendation views through coarse-grained overall semantic similarity and fine-grained interest allocation similarity BiVRec achieves state-of-the-art performance on five datasets and showcases various practical advantages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284730172",
                    "name": "Jiaxi Hu"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2284735864",
                    "name": "Yuehong Hu"
                },
                {
                    "authorId": "2289093854",
                    "name": "Yuxuan Liang"
                },
                {
                    "authorId": "2282243915",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2287901729",
                    "name": "Ming He"
                },
                {
                    "authorId": "2260835602",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2282271789",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "2235030b6265e9b78924355fcbf8595fa664dafb",
            "title": "PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction",
            "abstract": "In the era of information explosion, spatio-temporal data mining serves as a critical part of urban management. Considering the various fields demanding attention, e.g., traffic state, human activity, and social event, predicting multiple spatio-temporal attributes simultaneously can alleviate regulatory pressure and foster smart city construction. However, current research can not handle the spatio-temporal multi-attribute prediction well due to the complex relationships between diverse attributes. The key challenge lies in how to address the common spatio-temporal patterns while tackling their distinctions. In this paper, we propose an effective solution for spatio-temporal multi-attribute prediction, PromptST. We devise a spatio-temporal transformer and a parameter-sharing training scheme to address the common knowledge among different spatio-temporal attributes. Then, we elaborate a spatio-temporal prompt tuning strategy to fit the specific attributes in a lightweight manner. Through the pretrain and prompt tuning phases, our PromptST is able to enhance the specific spatio-temoral characteristic capture by prompting the backbone model to fit the specific target attribute while maintaining the learned common knowledge. Extensive experiments on real-world datasets verify that our PromptST attains state-of-the-art performance. Furthermore, we also prove PromptST owns good transferability on unseen spatio-temporal attributes, which brings promising application potential in urban computing. The implementation code is available to ease reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47295030",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "7923634",
                    "name": "Chunxu Zhang"
                },
                {
                    "authorId": "2244129522",
                    "name": "Qian Ma"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2146230626",
                    "name": "Hongwei Zhao"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "3195628",
                    "name": "Zitao Liu"
                }
            ]
        },
        {
            "paperId": "780c8dbd962ff7e4c45dd46e8a53484b17ecdb96",
            "title": "Rethinking Sensors Modeling: Hierarchical Information Enhanced Traffic Forecasting",
            "abstract": "With the acceleration of urbanization, traffic forecasting has become an essential role in smart city construction. In the context of spatio-temporal prediction, the key lies in how to model the dependencies of sensors. However, existing works basically only consider the micro relationships between sensors, where the sensors are treated equally, and their macroscopic dependencies are neglected. In this paper, we argue to rethink the sensor's dependency modeling from two hierarchies: regional and global perspectives. Particularly, we merge original sensors with high intra-region correlation as a region node to preserve the inter-region dependency. Then, we generate representative and common spatio-temporal patterns as global nodes to reflect a global dependency between sensors and provide auxiliary information for spatio-temporal dependency learning. In pursuit of the generality and reality of node representations, we incorporate a Meta GCN to calibrate the regional and global nodes in the physical data space. Furthermore, we devise the cross-hierarchy graph convolution to propagate information from different hierarchies. In a nutshell, we propose a Hierarchical Information Enhanced Spatio-Temporal prediction method, HIEST, to create and utilize the regional dependency and common spatio-temporal patterns. Extensive experiments have verified the leading performance of our HIEST against state-of-the-art baselines. We publicize the code to ease reproducibility1.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2244129522",
                    "name": "Qian Ma"
                },
                {
                    "authorId": "2187882131",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2244140667",
                    "name": "Haoliang Li"
                },
                {
                    "authorId": "2244169478",
                    "name": "Hongwei Zhao"
                },
                {
                    "authorId": "2108941389",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "3195628",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                }
            ]
        },
        {
            "paperId": "eae4ec5ca2686acbff971fdd509c1241a75b9e2f",
            "title": "MLPST: MLP is All You Need for Spatio-Temporal Prediction",
            "abstract": "Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187882131",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2109582755",
                    "name": "Ze Huang"
                },
                {
                    "authorId": "2246043330",
                    "name": "Zhiwei Hu"
                },
                {
                    "authorId": "2243037657",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "3195628",
                    "name": "Zitao Liu"
                },
                {
                    "authorId": "2238390764",
                    "name": "Junbo Zhang"
                },
                {
                    "authorId": "48330637",
                    "name": "S. Qin"
                },
                {
                    "authorId": "2010138167",
                    "name": "Hongwei Zhao"
                }
            ]
        }
    ]
}