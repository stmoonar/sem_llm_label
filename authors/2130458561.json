{
    "authorId": "2130458561",
    "papers": [
        {
            "paperId": "5468a398cbb91b0f126e10e6a827a46ee1eefc9b",
            "title": "Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot",
            "abstract": "Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals\u2019 practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119713346",
                    "name": "Sachin Pathiyan Cherumanal"
                },
                {
                    "authorId": "2279801138",
                    "name": "Lin Tian"
                },
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1657652841",
                    "name": "Angel Felipe Magnoss\u00e3o de Paula"
                },
                {
                    "authorId": "2238022819",
                    "name": "Kaixin Ji"
                },
                {
                    "authorId": "2125483087",
                    "name": "Danula Hettiachchi"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "2279785688",
                    "name": "Halil Ali"
                },
                {
                    "authorId": "2256152195",
                    "name": "Falk Scholer"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                }
            ]
        },
        {
            "paperId": "248581d85b2d4578c3771261ccf209bf38b68efc",
            "title": "SeqLink: A Robust Neural-ODE Architecture for Modelling Partially Observed Time Series",
            "abstract": "Ordinary Differential Equations (ODE) based models have become popular as foundation models for solving many time series problems. Combining neural ODEs with traditional RNN models has provided the best representation for irregular time series. However, ODE-based models typically require the trajectory of hidden states to be defined based on either the initial observed value or the most recent observation, raising questions about their effectiveness when dealing with longer sequences and extended time intervals. In this article, we explore the behaviour of the ODE models in the context of time series data with varying degrees of sparsity. We introduce SeqLink, an innovative neural architecture designed to enhance the robustness of sequence representation. Unlike traditional approaches that solely rely on the hidden state generated from the last observed value, SeqLink leverages ODE latent representations derived from multiple data samples, enabling it to generate robust data representations regardless of sequence length or data sparsity level. The core concept behind our model is the definition of hidden states for the unobserved values based on the relationships between samples (links between sequences). Through extensive experiments on partially observed synthetic and real-world datasets, we demonstrate that SeqLink improves the modelling of intermittent time series, consistently outperforming state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1560895396",
                    "name": "Hao Xue"
                },
                {
                    "authorId": "7800596",
                    "name": "Yongli Ren"
                },
                {
                    "authorId": "144954586",
                    "name": "Flora D. Salim"
                }
            ]
        },
        {
            "paperId": "a9629aef7d60cff8088ecbbcb37bad54a75cac18",
            "title": "PIETS: Parallelised Irregularity Encoders for Forecasting with Heterogeneous Time-Series",
            "abstract": "Heterogeneity and irregularity of multi-source data sets present a significant challenge to time-series analysis. In the literature, the fusion of multi-source time-series has been achieved either by using ensemble learning models which ignore temporal patterns and correlation within features or by defining a fixed-size window to select specific parts of the data sets. On the other hand, many studies have shown major improvement to handle the irregularity of time-series, yet none of these studies has been applied to multi-source data. In this work, we design a novel architecture, PIETS, to model heterogeneous time-series. PIETS has the following characteristics: (1) irregularity encoders for multi-source samples that can leverage all available information and accelerate the convergence of the model; (2) parallelised neural networks to enable flexibility and avoid information overwhelming; and (3) attention mechanism that highlights different information and gives high importance to the most related data. Through extensive experiments on real-world data sets related to COVID-19, we show that the proposed architecture is able to effectively model heterogeneous temporal data and outperforms other state-of-the-art approaches in the prediction task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130458561",
                    "name": "Futoon M. Abushaqra"
                },
                {
                    "authorId": "1560895396",
                    "name": "Hao Xue"
                },
                {
                    "authorId": "7800596",
                    "name": "Yongli Ren"
                },
                {
                    "authorId": "144954586",
                    "name": "Flora D. Salim"
                }
            ]
        }
    ]
}