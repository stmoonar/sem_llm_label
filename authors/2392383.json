{
    "authorId": "2392383",
    "papers": [
        {
            "paperId": "a8117bfdad88e1b9492b948296882af5cc29314a",
            "title": "Ask Questions with Double Hints: Visual Question Generation with Answer-awareness and Region-reference",
            "abstract": "The visual question generation\u00a0(VQG) task aims to generate human-like questions from an image and potentially other side information (e.g. answer type). Previous works on VQG fall in two aspects: i) They suffer from one image to many questions mapping problem, which leads to the failure of generating referential and meaningful questions from an image. ii) They fail to model complex implicit relations among the visual objects in an image and also overlook potential interactions between the side information and image. To address these limitations, we first propose a novel learning paradigm to generate visual questions with answer-awareness and region-reference. Concretely, we aim to ask the right visual questions with Double Hints - textual answers and visual regions of interests, which could effectively mitigate the existing one-to-many mapping issue. Particularly, we develop a simple methodology to self-learn the visual hints without introducing any additional human annotations. Furthermore, to capture these sophisticated relationships, we propose a new double-hints guided Graph-to-Sequence learning framework, which first models them as a dynamic graph and learns the implicit topology end-to-end, and then utilizes a graph-to-sequence model to generate the questions with double hints. Experimental results demonstrate the priority of our proposed method.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305681470",
                    "name": "Kai Shen"
                },
                {
                    "authorId": "2263988064",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2276402838",
                    "name": "Siliang Tang"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2257044304",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2253660817",
                    "name": "Yueting Zhuang"
                },
                {
                    "authorId": "2257049357",
                    "name": "Jian Pei"
                }
            ]
        },
        {
            "paperId": "b3fceb8807367ca2c6e454749708470061c9ee5c",
            "title": "Multi-Interest Multi-Round Conversational Recommendation System with Fuzzy Feedback based User Simulator",
            "abstract": "Conversational recommendation system (CRS) is able to obtain fine-grained and dynamic user preferences based on interactive dialogue. Previous CRS assumes that the user has a clear target item, which often deviates from the real scenario. The user may have a clear single preference for some attribute types (e.g. brand) of items, while for other attribute types (e.g. color), the user may have multiple preferences or even no clear preferences, which leads to multiple acceptable items under multiple combinations of attribute instances. Furthermore, previous works assume that users would provide clear responses to any questions asked by the system. And they also assume that users would be dedicated to the target item, that is, user would answer \u201dyes\u201d to the attribute corresponding to the target item and answer \u201dno\u201d to other attributes. However, users\u2019 responses to attributes are not completely dependent on target items, but also influenced by users\u2019 inherent interests. Besides, for some over-specific or equivocal questions, the feedback of user might not be clear (\u201dyes\u201d/\u201dno\u201d) and user might give some fuzzy response like \u201dI don\u2019t know\u201d. To address the aforementioned issues, we first propose a more realistic conversational recommendation learning setting, namely Multi-Interest Multi-round Conversational Recommendation (MIMCR), where users may have multiple interests in attribute instance combinations and accept multiple items with partially overlapped combinations of attribute instances. To effectively cope with MIMCR, we propose a novel learning framework, namely Multiple Choice questions based Multi-Interest Policy Learning. Moreover, we further propose a more realistic User-centric User Simulator with Fuzzy Feedback (UUSFF), which naturally calibrates the user response with additional fuzzy feedback based on user\u2018s inherent preference. To better match the new scenario UUSFF, we propose a simple but effective adaption method for different backbones. Extensive experimental results on several datasets demonstrate the superiority of our methods for the proposed settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069022639",
                    "name": "Qi Shen"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2108440508",
                    "name": "Yiming Zhang"
                },
                {
                    "authorId": "1726045339",
                    "name": "Yitong Pang"
                },
                {
                    "authorId": "2115565247",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2149160832",
                    "name": "Jiangsen Pei"
                }
            ]
        },
        {
            "paperId": "746f2b1d9e5c84c184cdd7e5323c19da396f2e22",
            "title": "Feeding What You Need by Understanding What You Learned",
            "abstract": "Machine Reading Comprehension (MRC) reveals the ability to understand a given text passage and answer questions based on it. Existing research works in MRC rely heavily on large-size models and corpus to improve the performance evaluated by metrics such as Exact Match (EM) and F_1. However, such a paradigm lacks sufficient interpretation to model capability and can not efficiently train a model with a large corpus. In this paper, we argue that a deep understanding of model capabilities and data properties can help us feed a model with appropriate training data based on its learning status. Specifically, we design an MRC capability assessment framework that assesses model capabilities in an explainable and multi-dimensional manner. Based on it, we further uncover and disentangle the connections between various data properties and model performance. Finally, to verify the effectiveness of the proposed MRC capability assessment framework, we incorporate it into a curriculum learning pipeline and devise a Capability Boundary Breakthrough Curriculum (CBBC) strategy, which performs a model capability-based training to maximize the data value and improve training efficiency. Extensive experiments demonstrate that our approach significantly improves performance, achieving up to an 11.22% / 8.71% improvement of EM / F_1 on MRC tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108158210",
                    "name": "Xiaoqiang Wang"
                },
                {
                    "authorId": "2116441692",
                    "name": "Bang Liu"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2064502840",
                    "name": "Bowei Long"
                },
                {
                    "authorId": "2118071462",
                    "name": "Siliang Tang"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                }
            ]
        },
        {
            "paperId": "21e944eabd1323a2865f9fd0de8aa64abbed026c",
            "title": "RDF-to-Text Generation with Reinforcement Learning Based Graph-augmented Structural Neural Encoders",
            "abstract": "Considering a collection of RDF triples, the RDF-to-text generation task aims to generate a text description. Most previous methods solve this task using a sequence-to-sequence model or using a graph-based model to encode RDF triples and to generate a text sequence. Nevertheless, these approaches fail to clearly model the local and global structural information between and within RDF triples. Moreover, the previous methods also face the non-negligible problem of low faithfulness of the generated text, which seriously affects the overall performance of these models. To solve these problems, we propose a model combining two new graph-augmented structural neural encoders to jointly learn both local and global structural information in the input RDF triples. To further improve text faithfulness, we innovatively introduce a reinforcement learning (RL) reward based on information extraction (IE). We first extract triples from the generated text using a pretrained IE model and regard the correct number of the extracted triples as the additional RL reward. Experimental results on two benchmark datasets demonstrate that our proposed model outperforms the state-of-the-art baselines, and the additional reinforcement learning reward does help to improve the faithfulness of the generated text.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "116267999",
                    "name": "Hanning Gao"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2152319586",
                    "name": "Po Hu"
                },
                {
                    "authorId": "143628849",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "6994323e2825b3318a6d560c833ea8dea6cdc715",
            "title": "Multiple Choice Questions based Multi-Interest Policy Learning for Conversational Recommendation",
            "abstract": "Conversational recommendation system (CRS) is able to obtain fine-grained and dynamic user preferences based on interactive dialogue. Previous CRS assumes that the user has a clear target item, which often deviates from the real scenario, that is for many users who resort to CRS, they might not have a clear idea about what they really like. Specifically, the user may have a clear single preference for some attribute types (e.g. brand) of items, while for other attribute types (e.g. color), the user may have multiple preferences or even no clear preferences, which leads to multiple acceptable attribute instances (e.g. black and red) of one attribute type. Therefore, the users could show their preferences over items under multiple combinations of attribute instances rather than a single item with unique combination of all attribute instances. As a result, we first propose a more realistic conversational recommendation learning setting, namely Multi-Interest Multi-round Conversational Recommendation (MIMCR), where users may have multiple interests in attribute instance combinations and accept multiple items with partially overlapped combinations of attribute instances. To effectively cope with the new CRS learning setting, in this paper, we propose a novel learning framework, namely Multiple Choice questions based Multi-Interest Policy Learning (MCMIPL). In order to obtain user preferences more efficiently, the agent generates multiple choice questions rather than binary yes/no ones on specific attribute instance. Furthermore, we propose a union set strategy to select candidate items instead of existing intersection set strategy in order to overcome over-filtering items during the conversation. Finally, we design a Multi-Interest Policy Learning (MIPL) module, which utilizes captured multiple interests of the user to decide next action, either asking attribute instances or recommending items. Extensive experimental results on four datasets demonstrate the superiority of our method for the proposed MIMCR setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Yiming Zhang"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2069022639",
                    "name": "Qi Shen"
                },
                {
                    "authorId": "1726045339",
                    "name": "Yitong Pang"
                },
                {
                    "authorId": "143628849",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2143960747",
                    "name": "Jian Pei"
                }
            ]
        },
        {
            "paperId": "6ee2dc6ed02c811c508071e64071da4545ff7be3",
            "title": "Heterogeneous Global Graph Neural Networks for Personalized Session-based Recommendation",
            "abstract": "Predicting the next interaction of a short-term interaction session is a challenging task in session-based recommendation. Almost all existing works rely on item transition patterns, and neglect user historical sessions while modeling user preference, which often leads to non-personalized recommendation. And existing personalized session-based recommenders are limited to sessions of the current user, and ignore the useful item-transition patterns from other user's historical sessions. To address these issues, we propose a novel Heterogeneous Global Graph Neural Networks (HG-GNN) to exploit the item transitions over all sessions in a subtle manner for better inferring user preference from the current and historical sessions. To effectively exploit the item transitions over all sessions from users, our global graph contains item transitions of sessions, user-item interactions and global co-occurrence items. Moreover, to capture user preference from sessions comprehensively, we propose a graph augmented preference encoder to learn the session representation. Specifically, we design a novel heterogeneous graph neural network (HGNN) on heterogeneous global graph to learn long-term user preference and item representations with rich semantics. Based on the HGNN, we propose the Personalized Session Encoder to combine the general user preference and temporal interest of the current session to generate the personalized session representation for recommendation. Extensive experimental results on three real-world datasets show that our model outperforms other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1726045339",
                    "name": "Yitong Pang"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2069022639",
                    "name": "Qi Shen"
                },
                {
                    "authorId": null,
                    "name": "Yiming Zhang"
                },
                {
                    "authorId": "143628849",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2118132485",
                    "name": "Ethan Chang"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "71bf8828da1a5d13e96c4a5ef8dc78006d5db8a3",
            "title": "Multi-behavior Graph Contextual Aware Network for Session-based Recommendation",
            "abstract": "Predicting the next interaction of a short-term sequence is a challenging task in session-based recommendation (SBR).Multi-behavior session recommendation considers session sequence with multiple interaction types, such as click and purchase, to capture more effective user intention representation sufficiently.Despite the superior performance of existing multi-behavior based methods for SBR, there are still several severe limitations:(i) Almost all existing works concentrate on single target type of next behavior and fail to model multiplex behavior sessions uniformly.(ii) Previous methods also ignore the semantic relations between various next behavior and historical behavior sequence, which are significant signals to obtain current latent intention for SBR.(iii) The global cross-session item-item graph established by some existing models may incorporate semantics and context level noise for multi-behavior session-based recommendation. To overcome the limitations (i) and (ii), we propose two novel tasks for SBR, which require the incorporation of both historical behaviors and next behaviors into unified multi-behavior recommendation modeling. To this end, we design a Multi-behavior Graph Contextual Aware Network (MGCNet) for multi-behavior session-based recommendation for the two proposed tasks. Specifically, we build a multi-behavior global item transition graph based on all sessions involving all interaction types. Based on the global graph, MGCNet attaches the global interest representation to final item representation based on local contextual intention to address the limitation (iii). In the end, we utilize the next behavior information explicitly to guide the learning of general interest and current intention for SBR. Experiments on three public benchmark datasets show that MGCNet can outperform state-of-the-art models for multi-behavior session-based recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069022639",
                    "name": "Qi Shen"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "1726045339",
                    "name": "Yitong Pang"
                },
                {
                    "authorId": null,
                    "name": "Yiming Zhang"
                },
                {
                    "authorId": "143628849",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "77583edbeac7fb4f5056243a9fd978b08ccb87ab",
            "title": "Constructing Contrastive samples via Summarization for Text Classification with limited annotations",
            "abstract": "Contrastive Learning has emerged as a powerful representation learning method and facilitates various downstream tasks especially when supervised data is limited. How to construct efficient contrastive samples through data augmentation is key to its success. Unlike vision tasks, the data augmentation method for contrastive learning has not been investigated sufficiently in language tasks. In this paper, we propose a novel approach to construct contrastive samples for language tasks using text summarization. We use these samples for supervised contrastive learning to gain better text representations which greatly benefit text classification tasks with limited annotations. To further improve the method, we mix up samples from different classes and add an extra regularization, named Mixsum, in addition to the cross-entropy-loss. Experiments on real-world text classification datasets (Amazon-5, Yelp-5, AG News, and IMDb) demonstrate the effectiveness of the proposed contrastive learning framework with summarization-based data augmentation and Mixsum regularization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111936104",
                    "name": "Yangkai Du"
                },
                {
                    "authorId": "40411766",
                    "name": "Tengfei Ma"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "49469875",
                    "name": "Xuhong Zhang"
                },
                {
                    "authorId": "2081160",
                    "name": "S. Ji"
                }
            ]
        },
        {
            "paperId": "8045b6c7af4d4f1bdce152d5ff9597492d5ebb0d",
            "title": "Triples-to-Text Generation with Reinforcement Learning Based Graph-augmented Neural Networks",
            "abstract": "Considering a collection of RDF triples, the RDF-to-text generation task aims to generate a text description. Most previous methods solve this task using a sequence-to-sequence model or using a graph-based model to encode RDF triples and to generate a text sequence. Nevertheless, these approaches fail to clearly model the local and global structural information between and within RDF triples. Moreover, the previous methods also face the non-negligible problem of low faithfulness of the generated text, which seriously affects the overall performance of these models. To solve these problems, we propose a model combining two new graph-augmented structural neural encoders to jointly learn both local and global structural information in the input RDF triples. To further improve text faithfulness, we innovatively introduce a reinforcement learning (RL) reward based on information extraction (IE). We first extract triples from the generated text using a pretrained IE model and regard the correct number of the extracted triples as the additional RL reward. Experimental results on two benchmark datasets demonstrate that our proposed model outperforms the state-of-the-art baselines, and the additional reinforcement learning reward does help to improve the faithfulness of the generated text.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "116267999",
                    "name": "Hanning Gao"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2108879245",
                    "name": "Hongyun Zhang"
                },
                {
                    "authorId": "143628849",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2152319586",
                    "name": "Po Hu"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "b94f05e35a4f4420a95c35d8089314bcd13ece49",
            "title": "Graph Learning Augmented Heterogeneous Graph Neural Network for Social Recommendation",
            "abstract": "Social recommendation based on social network has achieved great success in improving the performance of the recommendation system. Since social network (user-user relations) and user-item interactions are both naturally represented as graph-structured data, Graph Neural Networks (GNNs) have thus been widely applied for social recommendation. Despite the superior performance of existing GNNs-based methods, there are still several severe limitations: (i) Few existing GNNs-based methods have considered a single heterogeneous global graph which takes into account user-user relations, user-item interactions, and item-item similarities simultaneously. That may lead to a lack of complex semantic information and rich topological information when encoding users and items based on GNN. (ii) Furthermore, previous methods tend to overlook the reliability of the original user-user relations which may be noisy and incomplete. (iii) More importantly, the item-item connections established by a few existing methods merely using initial rating attributes or extra attributes (such as category) of items, may be inaccurate or sub-optimal with respect to social recommendation. In order to address these issues, we propose an end-to-end heterogeneous global graph learning framework, namely Graph Learning Augmented Heterogeneous Graph Neural Network (GL-HGNN) for social recommendation. GL-HGNN aims to learn a heterogeneous global graph that makes full use of user-user relations, user-item interactions and item-item similarities in a unified perspective. To this end, we design a Graph Learner (GL) method to learn and optimize user-user and item-item connections separately. Moreover, we employ a Heterogeneous Graph Neural Network (HGNN) to capture the high-order complex semantic relations from our learned heterogeneous global graph. To scale up the computation of graph learning, we further present the Anchor-based Graph Learner (AGL) to reduce computational complexity. Extensive experiments on four real-world datasets demonstrate the effectiveness of our model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Yiming Zhang"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2069022639",
                    "name": "Qi Shen"
                },
                {
                    "authorId": "1726045339",
                    "name": "Yitong Pang"
                },
                {
                    "authorId": "143628849",
                    "name": "Zhihua Wei"
                },
                {
                    "authorId": "2392383",
                    "name": "Fangli Xu"
                },
                {
                    "authorId": "2118132485",
                    "name": "Ethan Chang"
                },
                {
                    "authorId": "2052143728",
                    "name": "Bo Long"
                }
            ]
        }
    ]
}