{
    "authorId": "2111106416",
    "papers": [
        {
            "paperId": "76be63767799fa50357fab6516b668960b67aa78",
            "title": "Taxonomy Completion via Triplet Matching Network",
            "abstract": "Automatically constructing taxonomy finds many applications in e-commerce and web search. One critical challenge is as data and business scope grow in real applications, new concepts are emerging and needed to be added to the existing taxonomy. Previous approaches focus on the taxonomy expansion, i.e. finding an appropriate hypernym concept from the taxonomy for a new query concept. In this paper, we formulate a new task, \u201ctaxonomy completion\u201d, by discovering both the hypernym and hyponym concepts for a query. We propose Triplet Matching Network (TMN), to find the appropriate pairs for a given query concept. TMN consists of one primal scorer and multiple auxiliary scorers. These auxiliary scorers capture various fine-grained signals (e.g., query to hypernym or query to hyponym semantics), and the primal scorer makes a holistic prediction on triplet based on the internal feature representations of all auxiliary scorers. Also, an innovative channel-wise gating mechanism that retains task-specific information in concept representations is introduced to further boost model performance. Experiments on four real-world large-scale datasets show that TMN achieves the best performance on both taxonomy completion task and the previous taxonomy expansion task, outperforming existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47540245",
                    "name": "Jieyu Zhang"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "2111106416",
                    "name": "Ying Zeng"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "3363642",
                    "name": "Jiaming Shen"
                },
                {
                    "authorId": "3375249",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "000c1bdf07b5511e9326cdeb695610f0fbe7b2dc",
            "title": "Xiaomingbot: A Multilingual Robot News Reporter",
            "abstract": "This paper proposes the building of Xiaomingbot, an intelligent, multilingual and multimodal software robot equipped with four inte- gral capabilities: news generation, news translation, news reading and avatar animation. Its system summarizes Chinese news that it automatically generates from data tables. Next, it translates the summary or the full article into multiple languages, and reads the multi- lingual rendition through synthesized speech. Notably, Xiaomingbot utilizes a voice cloning technology to synthesize the speech trained from a real person\u2019s voice data in one input language. The proposed system enjoys several merits: it has an animated avatar, and is able to generate and read multilingual news. Since it was put into practice, Xiaomingbot has written over 600,000 articles, and gained over 150,000 followers on social media platforms.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "1748844142",
                    "name": "Runxin Xu"
                },
                {
                    "authorId": "2109830278",
                    "name": "Jun Cao"
                },
                {
                    "authorId": "2067908",
                    "name": "Mingxuan Wang"
                },
                {
                    "authorId": "2108182762",
                    "name": "Jiaze Chen"
                },
                {
                    "authorId": "2111824520",
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "2111106416",
                    "name": "Ying Zeng"
                },
                {
                    "authorId": "2130355791",
                    "name": "Yuping Wang"
                },
                {
                    "authorId": "152875291",
                    "name": "L. Chen"
                },
                {
                    "authorId": "145158503",
                    "name": "Xiang Yin"
                },
                {
                    "authorId": "2160890063",
                    "name": "Xijin Zhang"
                },
                {
                    "authorId": "2220923064",
                    "name": "Songcheng Jiang"
                },
                {
                    "authorId": "2115828379",
                    "name": "Yuxuan Wang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "b64be95928b43424f520b45d5fb6128311d5ef12",
            "title": "Importance-Aware Learning for Neural Headline Editing",
            "abstract": "Many social media news writers are not professionally trained. Therefore, social media platforms have to hire professional editors to adjust amateur headlines to attract more readers. We propose to automate this headline editing process through neural network models to provide more immediate writing support for these social media news writers. To train such a neural headline editing model, we collected a dataset which contains articles with original headlines and professionally edited headlines. However, it is expensive to collect a large number of professionally edited headlines. To solve this low-resource problem, we design an encoder-decoder model which leverages large scale pre-trained language models. We further improve the pre-trained model's quality by introducing a headline generation task as an intermediate task before the headline editing task. Also, we propose Self Importance-Aware (SIA) loss to address the different levels of editing in the dataset by down-weighting the importance of easily classified tokens and sentences. With the help of Pre-training, Adaptation, and SIA, the model learns to generate headlines in the professional editor's style. Experimental results show that our method significantly improves the quality of headline editing comparing against previous methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31060482",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2111824520",
                    "name": "Hao Zhou"
                },
                {
                    "authorId": "2111106416",
                    "name": "Ying Zeng"
                },
                {
                    "authorId": "1564034697",
                    "name": "Zhou Yu"
                }
            ]
        }
    ]
}