{
    "authorId": "1682679",
    "papers": [
        {
            "paperId": "89a073d4606c3d308c208c1113d8e0b333d1e2c4",
            "title": "Systematic Use of Random Self-Reducibility against Physical Attacks",
            "abstract": "This work presents a novel, black-box software-based countermeasure against physical attacks including power side-channel and fault-injection attacks. The approach uses the concept of random self-reducibility and self-correctness to add randomness and redundancy in the execution for protection. Our approach is at the operation level, is not algorithm-specific, and thus, can be applied for protecting a wide range of algorithms. The countermeasure is empirically evaluated against attacks over operations like modular exponentiation, modular multiplication, polynomial multiplication, and number theoretic transforms. An end-to-end implementation of this countermeasure is demonstrated for RSA-CRT signature algorithm and Kyber Key Generation public key cryptosystems. The countermeasure reduced the power side-channel leakage by two orders of magnitude, to an acceptably secure level in TVLA analysis. For fault injection, the countermeasure reduces the number of faults to 95.4% in average.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2202037",
                    "name": "Ferhat Erata"
                },
                {
                    "authorId": "2261938852",
                    "name": "Tinghung Chiu"
                },
                {
                    "authorId": "2078617138",
                    "name": "Anthony Etim"
                },
                {
                    "authorId": "2300285200",
                    "name": "Srilalith Nampally"
                },
                {
                    "authorId": "2300285226",
                    "name": "Tejas Raju"
                },
                {
                    "authorId": "2300285482",
                    "name": "Rajashree Ramu"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "143757557",
                    "name": "Wenjie Xiong"
                },
                {
                    "authorId": "2239104177",
                    "name": "Jakub Szefer"
                }
            ]
        },
        {
            "paperId": "a3eacbe7f70240a5c8830ec729ad786d018b922e",
            "title": "Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
            "abstract": "Benchmarks are critical for measuring progress of math reasoning abilities of Large Language Models (LLMs). However, existing widely-used benchmarks such as GSM8K have been rendered less useful as multiple cutting-edge LLMs achieve over 94% accuracy. While harder benchmarks have been proposed, their creation is often manual and expensive. We present Scheherazade, an automated approach for producing challenging mathematical reasoning benchmarks by logically chaining mathematical reasoning problems. We propose two different chaining methods, forward chaining and backward chaining, which require reasoning forward and backward through the chain respectively. We apply Scheherazade on GSM8K to create GSM8K-Scheherazade and evaluate 3 frontier LLMs and OpenAI's o1-preview on it. We show that while frontier models' performance declines precipitously at only a few questions chained, a preliminary evaluation suggests o1-preview performance persists up to 5 questions chained backwards. In addition, while all other models perform worse when problems are chained backwards, o1-preview performs better on backward-chained benchmarks. We will release the dataset and code publicly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2323744364",
                    "name": "Stephen Miner"
                },
                {
                    "authorId": "2323754343",
                    "name": "Yoshiki Takashima"
                },
                {
                    "authorId": "2323760832",
                    "name": "Simeng Han"
                },
                {
                    "authorId": "2202037",
                    "name": "Ferhat Erata"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "2288001761",
                    "name": "Scott J. Shapiro"
                }
            ]
        },
        {
            "paperId": "019e9e2a92d516590ca396a11dd92d0d297d4732",
            "title": "Analyzing Intentional Behavior in Autonomous Agents under Uncertainty",
            "abstract": "Principled accountability for autonomous decision-making in uncertain environments requires distinguishing intentional outcomes from negligent designs from actual accidents. We propose analyzing the behavior of autonomous agents through a quantitative measure of the evidence of intentional behavior. We model an uncertain environment as a Markov Decision Process (MDP). For a given scenario, we rely on probabilistic model checking to compute the ability of the agent to influence reaching a certain event. We call this the scope of agency. We say that there is evidence of intentional behavior if the scope of agency is high and the decisions of the agent are close to being optimal for reaching the event. Our method applies counterfactual reasoning to automatically generate relevant scenarios that can be analyzed to increase the confidence of our assessment. In a case study, we show how our method can distinguish between 'intentional' and 'accidental' traffic collisions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2221140085",
                    "name": "Filip Cano C'ordoba"
                },
                {
                    "authorId": "2007693530",
                    "name": "Samuel Judson"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "2219943761",
                    "name": "Katrine Bj\u00f8rner"
                },
                {
                    "authorId": "2073173217",
                    "name": "Nicholas Shoemaker"
                },
                {
                    "authorId": "39095165",
                    "name": "Scott J. Shapiro"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "2278439482",
                    "name": "Bettina K\u00f6nighofer"
                }
            ]
        },
        {
            "paperId": "0e2d94dc044191825c0137817a928cae7ea95a7f",
            "title": "Ou: Automating the Parallelization of Zero-Knowledge Protocols",
            "abstract": "A zero-knowledge proof (ZKP) is a powerful cryptographic primitive used in many decentralized or privacy-focused applications. However, the high overhead of ZKPs can restrict their practical applicability. We design a programming language, Ou, aimed at easing the programmer's burden when writing efficient ZKPs, and a compiler framework, Lian, that automates the analysis and distribution of statements to a computing cluster. Ou uses programming language semantics, formal methods, and combinatorial optimization to automatically partition an Ou program into efficiently sized chunks for parallel ZK-proving and/or verification. We contribute: (1) A front-end language where users can write proof statements as imperative programs in a familiar syntax; (2) A compiler architecture and implementation that automatically analyzes the program and compiles it into an optimized IR that can be lifted to a variety of ZKP constructions; and (3) A cutting algorithm, based on Pseudo-Boolean optimization and Integer Linear Programming, that reorders instructions and then partitions the program into efficiently sized chunks for parallel evaluation and efficient state reconciliation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1380151268",
                    "name": "Yuyang Sang"
                },
                {
                    "authorId": "2065660489",
                    "name": "Ning Luo"
                },
                {
                    "authorId": "2007693530",
                    "name": "Samuel Judson"
                },
                {
                    "authorId": "2219634695",
                    "name": "Ben Chaimberg"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "144656147",
                    "name": "Zhong Shao"
                }
            ]
        },
        {
            "paperId": "3a60f65ce078fae43519855458e2a0d319ef1d74",
            "title": "ZKSMT: A VM for Proving SMT Theorems in Zero Knowledge",
            "abstract": "Verification of program safety is often reducible to proving the unsatisfiability (i.e., validity) of a formula in Satisfiability Modulo Theories (SMT): Boolean logic combined with theories that formalize arbitrary first-order fragments. Zero-knowledge (ZK) proofs allow SMT formulas to be validated without revealing the underlying formulas or their proofs to other parties, which is a crucial building block for proving the safety of proprietary programs. Recently, Luo et al. (CCS 2022) studied the simpler problem of proving the unsatisfia-bility of pure Boolean formulas but does not support proofs generated by SMT solvers. This work presents ZKSMT , a novel framework for proving the validity of SMT formulas in ZK. We design a virtual machine (VM) tailored to efficiently represent the verification process of SMT validity proofs in ZK. Our VM can support the vast majority of popular theories when proving program safety while being complete and sound. To demonstrate this, we instantiate the commonly used theories of equality and linear integer arithmetic in our VM with theory-specific optimizations for proving them in ZK. ZKSMT achieves high practicality even when running on realistic SMT formulas generated by Boogie, a common tool for software verification. It achieves a three-order-of-magnitude improvement compared to",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268079351",
                    "name": "Daniel Luick"
                },
                {
                    "authorId": "2168012965",
                    "name": "John C. Kolesar"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "2271486021",
                    "name": "William R. Harris"
                },
                {
                    "authorId": "2268083269",
                    "name": "James Parker"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "2337345",
                    "name": "Eran Tromer"
                },
                {
                    "authorId": "2268173877",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2065660489",
                    "name": "Ning Luo"
                }
            ]
        },
        {
            "paperId": "3d59dcd089bbcb0f2cc074abbc24733ed8dc709b",
            "title": "DrNLA: Extending Verification to Non-linear Programs through Dual Re-writing",
            "abstract": "For many decades, advances in static verification have focused on linear integer arithmetic (LIA) programs. Many real-world programs are, however, written with non-linear integer arithmetic (NLA) expressions, such as programs that model physical events, control systems, or nonlinear activation functions in neural networks. While there are some approaches to reasoning about such NLA programs, still many verification tools fall short when trying to analyze them. To expand the scope of existing tools, we introduce a new method of converting programs with NLA expressions into semantically equivalent LIA programs via a technique we call dual rewriting. Dual rewriting discovers a linear replacement for an NLA Boolean expression (e.g. as found in conditional branching), simultaneously exploring both the positive and negative side of the condition, and using a combination of static validation and dynamic generalization of counterexamples. While perhaps surprising at first, this is often possible because the truth value of a Boolean NLA expression can be characterized in terms of a Boolean combination of linearly-described regions/intervals where the expression is true and those where it is false. The upshot is that rewriting NLA expressions to LIA expressions beforehand enables off-the-shelf LIA tools to be applied to the wider class of NLA programs. We built a new tool DrNLA and show it can discover LIA replacements for a variety of NLA programs. We then applied our work to branching-time verification of NLA programs, creating the first set of such benchmarks (92 in total) and showing that DrNLA's rewriting enable tools such as FuncTion and T2 to verify CTL properties of 42 programs that previously could not be verified. We also show a potential use of DrNLA assisting Frama-C in program slicing, and report that execution speed is not impacted much by rewriting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47908543",
                    "name": "Y. Liu"
                },
                {
                    "authorId": "2833947",
                    "name": "T. Le"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "33681628",
                    "name": "Eric Koskinen"
                },
                {
                    "authorId": "152411981",
                    "name": "Thanh Tung Nguyen"
                }
            ]
        },
        {
            "paperId": "784ae05d89c8a350976d77de222ef72366e4f7f2",
            "title": "'Put the Car on the Stand': SMT-based Oracles for Investigating Decisions",
            "abstract": "Principled accountability in the aftermath of harms is essential to the trustworthy design and governance of algorithmic decision making. Legal theory offers a paramount method for assessing culpability: putting the agent 'on the stand' to subject their actions and intentions to cross-examination. We show that under minimal assumptions automated reasoning can rigorously interrogate algorithmic behaviors as in the adversarial process of legal fact finding. We use the formal methods of symbolic execution and satisfiability modulo theories (SMT) solving to discharge queries about agent behavior in factual and counterfactual scenarios, as adaptively formulated by a human investigator. We implement our framework and demonstrate its utility on an illustrative car crash scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007693530",
                    "name": "Samuel Judson"
                },
                {
                    "authorId": "2216720098",
                    "name": "Matthew Elacqua"
                },
                {
                    "authorId": "2288007300",
                    "name": "Filip Cano"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "2278439482",
                    "name": "Bettina K\u00f6nighofer"
                },
                {
                    "authorId": "39095165",
                    "name": "Scott J. Shapiro"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                }
            ]
        },
        {
            "paperId": "14dceacda0278b823d11340d77ce4f0d611e1c05",
            "title": "IVeri: Privacy-Preserving Interdomain Verification",
            "abstract": "In an interdomain network, autonomous systems (ASes) often establish peering agreements, so that one AS (agreement consumer) can influence the routing policies of the other AS (agreement provider). Peering agreements are implemented in the BGP configuration of the agreement provider. It is crucial to verify their implementation because one error can lead to disastrous consequences. However, the fundamental challenge for peering agreement verification is how to preserve the privacy of both ASes involved in the agreement. To this end, this paper presents IVeri, the first privacy-preserving interdomain agreement verification system. IVeri models the interdomain agreement verification problem as a SAT formula, and develops a novel, efficient, privacy-serving SAT solver, which uses oblivious shuffling and garbled circuits as the key building blocks to let the agreement consumer and provider collaboratively verify the implementation of interdomain peering agreements without exposing their private information. A prototype of IVeri is implemented and evaluated extensively. Results show that IVeri achieves accurate, privacy-preserving interdomain agreement verification with reasonable overhead.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065660489",
                    "name": "Ning Luo"
                },
                {
                    "authorId": "2955716",
                    "name": "Qiao Xiang"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "145756439",
                    "name": "Y. Yang"
                },
                {
                    "authorId": "1678308",
                    "name": "Franck Le"
                }
            ]
        },
        {
            "paperId": "2565ea47daef463a1a8db42818930ddcb65cdbc7",
            "title": "Proving UNSAT in Zero Knowledge",
            "abstract": "Zero-knowledge (ZK) protocols enable one party to prove to others that it knows a fact without revealing any information about the evidence for such knowledge. There exist ZK protocols for all problems in NP, and recent works developed highly efficient protocols for proving knowledge of satisfying assignments to Boolean formulas, circuits and other NP formalisms. This work shows an efficient protocol for the converse: proving formula unsatisfiability in ZK (when the prover posses a non-ZK proof). An immediate practical application is efficiently proving safety of secret programs. The key insight is to prove, in ZK, the validity of resolution proofs of unsatisfiability. This is efficiently realized using an algebraic representation that exploits resolution proofs' structure to represent formula clauses as low-degree polynomials, combined with ZK random-access arguments. Only the proof's dimensions are revealed. We implemented our protocol and used it to prove unsatisfiability of formulas that encode combinatoric problems and program correctness conditions in standard verification benchmarks, including Linux kernel drivers and Intel cryptography modules. The results demonstrate both that our protocol has practical utility, and that its aggressive optimizations, based on non-trivial encodings, significantly improve practical performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065660489",
                    "name": "Ning Luo"
                },
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "144740804",
                    "name": "William R. Harris"
                },
                {
                    "authorId": "2869954",
                    "name": "R. Piskac"
                },
                {
                    "authorId": "2337345",
                    "name": "Eran Tromer"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                }
            ]
        },
        {
            "paperId": "63a46048fdf4d45e92121c74490d0b66218fcf26",
            "title": "An Algebra of Alignment for Relational Verification",
            "abstract": "Relational verification encompasses information flow security, regression verification, translation validation for compilers, and more. Effective alignment of the programs and computations to be related facilitates use of simpler relational invariants and relational procedure specs, which in turn enables automation and modular reasoning. Alignment has been explored in terms of trace pairs, deductive rules of relational Hoare logics (RHL), and several forms of product automata. This article shows how a simple extension of Kleene Algebra with Tests (KAT), called BiKAT, subsumes prior formulations, including alignment witnesses for forall-exists properties, which brings to light new RHL-style rules for such properties. Alignments can be discovered algorithmically or devised manually but, in either case, their adequacy with respect to the original programs must be proved; an explicit algebra enables constructive proof by equational reasoning. Furthermore our approach inherits algorithmic benefits from existing KAT-based techniques and tools, which are applicable to a range of semantic models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1682679",
                    "name": "Timos Antonopoulos"
                },
                {
                    "authorId": "33681628",
                    "name": "Eric Koskinen"
                },
                {
                    "authorId": "2833947",
                    "name": "T. Le"
                },
                {
                    "authorId": "2007666246",
                    "name": "Ramana Nagasamudram"
                },
                {
                    "authorId": "1680406",
                    "name": "D. Naumann"
                },
                {
                    "authorId": "143782932",
                    "name": "Minh Ngo"
                }
            ]
        }
    ]
}