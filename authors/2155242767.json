{
    "authorId": "2155242767",
    "papers": [
        {
            "paperId": "1a12095913360f056a682d104f7c0d0a85f26dc7",
            "title": "Joint learning of text alignment and abstractive summarization for long documents via unbalanced optimal transport",
            "abstract": "Abstract Recently, neural abstractive text summarization (NATS) models based on sequence-to-sequence architecture have drawn a lot of attention. Real-world texts that need to be summarized range from short news with dozens of words to long reports with thousands of words. However, most existing NATS models are not good at summarizing long documents, due to the inherent limitations of their underlying neural architectures. In this paper, we focus on the task of long document summarization (LDS). Based on the inherent section structures of source documents, we divide an abstractive LDS problem into several smaller-sized problems. In this circumstance, how to provide a less-biased target summary as the supervision for each section is vital for the model\u2019s performance. As a preliminary, we formally describe the section-to-summary-sentence (S2SS) alignment for LDS. Based on this, we propose a novel NATS framework for the LDS task. Our framework is built based on the theory of unbalanced optimal transport (UOT), and it is named as UOTSumm. It jointly learns three targets in a unified training objective, including the optimal S2SS alignment, a section-level NATS summarizer, and the number of aligned summary sentences for each section. In this way, UOTSumm directly learns the text alignment from summarization data, without resorting to any biased tool such as ROUGE. UOTSumm can be easily adapted to most existing NATS models. And we implement two versions of UOTSumm, with and without the pretrain-finetune technique. We evaluate UOTSumm on three publicly available LDS benchmarks: PubMed, arXiv, and GovReport. UOTSumm obviously outperforms its counterparts that use ROUGE for the text alignment. When combined with UOTSumm, the performance of two vanilla NATS models improves by a large margin. Besides, UOTSumm achieves better or comparable performance when compared with some recent strong baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Xin Shen"
                },
                {
                    "authorId": "2055478524",
                    "name": "Wai Lam"
                },
                {
                    "authorId": "2118869059",
                    "name": "Shumin Ma"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                }
            ]
        },
        {
            "paperId": "25e48d36c34d958c89244953501638cfcb7a2839",
            "title": "Language-Specific Representation of Emotion-Concept Knowledge Causally Supports Emotion Inference",
            "abstract": "Humans no doubt use language to communicate about their emotional experiences, but does language in turn help humans understand emotions, or is language just a vehicle of communication? This study used a form of artificial intelligence (AI) known as large language models (LLMs) to assess whether language-based representations of emotion causally contribute to the AI's ability to generate inferences about the emotional meaning of novel situations. Fourteen attributes of human emotion concept representation were found to be represented by the LLM's distinct artificial neuron populations. By manipulating these attribute-related neurons, we in turn demonstrated the role of emotion concept knowledge in generative emotion inference. The attribute-specific performance deterioration was related to the importance of different attributes in human mental space. Our findings provide a proof-in-concept that even a LLM can learn about emotions in the absence of sensory-motor representations and highlight the contribution of language-derived emotion-concept knowledge for emotion inference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2222963088",
                    "name": "Ming Li"
                },
                {
                    "authorId": "48576745",
                    "name": "Yusheng Su"
                },
                {
                    "authorId": "2209072917",
                    "name": "Hsiu-Yuan Huang"
                },
                {
                    "authorId": "2210063335",
                    "name": "Jiali Cheng"
                },
                {
                    "authorId": "2110048706",
                    "name": "Xin Hu"
                },
                {
                    "authorId": "2208908966",
                    "name": "Xinmiao Zhang"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "48631777",
                    "name": "Xiaozhi Wang"
                },
                {
                    "authorId": "46270592",
                    "name": "Zhi-Yun Liu"
                },
                {
                    "authorId": "2122440589",
                    "name": "Dan Zhang"
                }
            ]
        },
        {
            "paperId": "352420ee61a8da783ca7750170793613b18b8d9c",
            "title": "Tool Learning with Foundation Models",
            "abstract": "Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool learning framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate the generalization in tool learning. Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 18 representative tools and show the potential of current foundation models in skillfully utilizing tools. Finally, we discuss several open problems that require further investigation for tool learning. In general, we hope this paper could inspire future research in integrating tools with foundation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "1576223501",
                    "name": "Shengding Hu"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "2109136284",
                    "name": "Weize Chen"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "52297757",
                    "name": "Ganqu Cui"
                },
                {
                    "authorId": "1633538428",
                    "name": "Zheni Zeng"
                },
                {
                    "authorId": "2115640120",
                    "name": "Yufei Huang"
                },
                {
                    "authorId": "51131083",
                    "name": "Chaojun Xiao"
                },
                {
                    "authorId": "2118642562",
                    "name": "Chi Han"
                },
                {
                    "authorId": "51135899",
                    "name": "Y. Fung"
                },
                {
                    "authorId": "48576745",
                    "name": "Yusheng Su"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "2082473972",
                    "name": "Cheng Qian"
                },
                {
                    "authorId": "2214603370",
                    "name": "Runchu Tian"
                },
                {
                    "authorId": "2214586034",
                    "name": "Kunlun Zhu"
                },
                {
                    "authorId": "2163374235",
                    "name": "Shi Liang"
                },
                {
                    "authorId": "145781166",
                    "name": "Xingyu Shen"
                },
                {
                    "authorId": "2052218689",
                    "name": "Bokai Xu"
                },
                {
                    "authorId": "2170500945",
                    "name": "Zhen Zhang"
                },
                {
                    "authorId": "2114059497",
                    "name": "Yining Ye"
                },
                {
                    "authorId": "2155882844",
                    "name": "Bo Li"
                },
                {
                    "authorId": "2214664440",
                    "name": "Ziwei Tang"
                },
                {
                    "authorId": "2106388389",
                    "name": "Jing Yi"
                },
                {
                    "authorId": "2109388429",
                    "name": "Yu Zhu"
                },
                {
                    "authorId": "2146517842",
                    "name": "Zhenning Dai"
                },
                {
                    "authorId": "2214613855",
                    "name": "Lan Yan"
                },
                {
                    "authorId": "2214579778",
                    "name": "Xin Cong"
                },
                {
                    "authorId": "2191753738",
                    "name": "Ya-Ting Lu"
                },
                {
                    "authorId": "2150606888",
                    "name": "Weilin Zhao"
                },
                {
                    "authorId": "2214586078",
                    "name": "Yuxiang Huang"
                },
                {
                    "authorId": "2213334016",
                    "name": "Jun-Han Yan"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2143570016",
                    "name": "Xian Sun"
                },
                {
                    "authorId": "2144118403",
                    "name": "Dahai Li"
                },
                {
                    "authorId": "80842917",
                    "name": "Jason Phang"
                },
                {
                    "authorId": "3443627",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "2116417519",
                    "name": "Tongshuang Wu"
                },
                {
                    "authorId": "2072975663",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "46ac88bb0acbf736840ff8a392cec2bf43d917e1",
            "title": "Exploring Format Consistency for Instruction Tuning",
            "abstract": "Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. In this work, we propose a framework named Unified Instruction Tuning (UIT), which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets such as PromptSource, FLAN and CrossFit. With the framework, we (1) demonstrate the necessity of maintaining format consistency in instruction tuning; (2) improve the generalization performance on unseen instructions on T5-LM-xl; (3) provide a novel perplexity-based denoising method to reduce the noise of automatic format transfer to make the UIT framework more practical and a smaller offline model based on GPT-J that achieves comparable format transfer capability to OpenAI APIs to reduce costs in practice. Further analysis regarding variations of targeted formats and other effects is intended.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2163374235",
                    "name": "Shi Liang"
                },
                {
                    "authorId": "2214586034",
                    "name": "Kunlun Zhu"
                },
                {
                    "authorId": "2214603370",
                    "name": "Runchu Tian"
                },
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "2214579778",
                    "name": "Xin Cong"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "3028405",
                    "name": "Xiaojiang Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                }
            ]
        },
        {
            "paperId": "4a8fe7ecf225e5bada08642fcd77d3cbb322b967",
            "title": "Human Emotion Knowledge Representation Emerges in Large Language Model and Supports Discrete Emotion Inference",
            "abstract": "How humans infer discrete emotions is a fundamental research question in the field of psychology. While conceptual knowledge about emotions (emotion knowledge) has been suggested to be essential for emotion inference, evidence to date is mostly indirect and inconclusive. As the large language models (LLMs) have been shown to support effective representations of various human conceptual knowledge, the present study further employed artificial neurons in LLMs to investigate the mechanism of human emotion inference. With artificial neurons activated by prompts, the LLM (RoBERTa) demonstrated a similar conceptual structure of 27 discrete emotions as that of human behaviors. Furthermore, the LLM-based conceptual structure revealed a human-like reliance on 14 underlying conceptual attributes of emotions for emotion inference. Most importantly, by manipulating attribute-specific neurons, we found that the corresponding LLM's emotion inference performance deteriorated, and the performance deterioration was correlated to the effectiveness of representations of the conceptual attributes on the human side. Our findings provide direct evidence for the emergence of emotion knowledge representation in large language models and suggest its casual support for discrete emotion inference. # These authors contributed equally: liming16@tsinghua.org.cn, yushengsu.thu@gmail.com * Corresponding authors: {liuzy, dzhang}@tsinghua.edu.cn The source code can be obtained from https://github.com/thunlp/Model_Emotion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150653116",
                    "name": "Ming Li"
                },
                {
                    "authorId": "48576745",
                    "name": "Yusheng Su"
                },
                {
                    "authorId": "2209072917",
                    "name": "Hsiu-Yuan Huang"
                },
                {
                    "authorId": "2210063335",
                    "name": "Jiali Cheng"
                },
                {
                    "authorId": "2110048706",
                    "name": "Xin Hu"
                },
                {
                    "authorId": "2208908966",
                    "name": "Xinmiao Zhang"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "48631777",
                    "name": "Xiaozhi Wang"
                },
                {
                    "authorId": "46270592",
                    "name": "Zhi-Yun Liu"
                },
                {
                    "authorId": "2122440589",
                    "name": "Dan Zhang"
                }
            ]
        },
        {
            "paperId": "a368c72e09c805ec9fb3e17a93852b8f607fbd40",
            "title": "Land Use and Land Cover Mapping in China Using Multimodal Fine-Grained Dual Network",
            "abstract": "With the advancement of geo-systems and the increased availability of satellite data, a plethora of land-use and land-cover (LULC) products have been developed. The existing LULC products primarily relied on time-series imagery to classify land by pixel-based classifiers, allowing for local analysis and accurate boundary detection. However, the advent of deep learning has shifted toward the use of patch-based CNN models for generating land cover maps. In this article: 1) we create a training dataset for China using a voting strategy based on three off-the-shelf available LULC products, avoiding the labor-intensive manual annotation. 2) We design a novel CNN-based model for the LULC task, called multimodal fine-grained dual network (dubbed as Dual-Net), which takes dual-date images to generate final maps and reduces the need for gap-free temporal sequences or separate cloud detection. To leverage the correlation between location, date, and category, we embed modal information (dates and geo-locations) into the model. Furthermore, by incorporating low-level constraints and using pseudolabel refinement, we continually improve the performance and achieve more refined segmentation. 3) Due to the lack of a suitable validation dataset for China, we create a new validation dataset called the China Sentinel2 Validation Dataset (CSVD) by manually annotating 733 finely labeled images of $1024 \\times 1024$ pixels of China-specific Sentinel2 data. 4) Extensive experiments demonstrate that our model outperforms existing LULC products and produces more fine-grained segmentation results comparable to other patch-based products. Finally, we release annual LULC maps for China in 2020\u20132022 and also make our model accessible online for real-time results export.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220842282",
                    "name": "Shang Liu"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "2189586856",
                    "name": "Yuan Hu"
                },
                {
                    "authorId": "2221149490",
                    "name": "Mengting Zhang"
                },
                {
                    "authorId": "2118318560",
                    "name": "Yixuan Zhu"
                },
                {
                    "authorId": "2189200382",
                    "name": "Zhibin Wang"
                },
                {
                    "authorId": "2219262212",
                    "name": "Dongyang Li"
                },
                {
                    "authorId": "2221146638",
                    "name": "Mingyang Yang"
                },
                {
                    "authorId": "49451350",
                    "name": "Fan Wang"
                }
            ]
        },
        {
            "paperId": "afba884feb37ffc83a6d06144d6a1505f84366da",
            "title": "Plug-and-Play Knowledge Injection for Pre-trained Language Models",
            "abstract": "Injecting external knowledge can improve the performance of pre-trained language models (PLMs) on various downstream NLP tasks. However, massive retraining is required to deploy new knowledge injection methods or knowledge bases for downstream tasks. In this work, we are the first to study how to improve the flexibility and efficiency of knowledge injection by reusing existing downstream models. To this end, we explore a new paradigm plug-and-play knowledge injection, where knowledge bases are injected into frozen existing downstream models by a knowledge plugin. Correspondingly, we propose a plug-and-play injection method map-tuning, which trains a mapping of knowledge embeddings to enrich model inputs with mapped embeddings while keeping model parameters frozen. Experimental results on three knowledge-driven NLP tasks show that existing injection methods are not suitable for the new paradigm, while map-tuning effectively improves the performance of downstream models. Moreover, we show that a frozen downstream model can be well adapted to different domains with different mapping networks of domain knowledge. Our code and models are available at https://github.com/THUNLP/Knowledge-Plugin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2621696",
                    "name": "Zhengyan Zhang"
                },
                {
                    "authorId": "2150468823",
                    "name": "Zhiyuan Zeng"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "50816334",
                    "name": "Deming Ye"
                },
                {
                    "authorId": "51131083",
                    "name": "Chaojun Xiao"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "2209965245",
                    "name": "Peng Li"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                },
                {
                    "authorId": "49640256",
                    "name": "Jie Zhou"
                }
            ]
        },
        {
            "paperId": "b05cfda924a147dfc100dc0b3eea451c6db32868",
            "title": "Recyclable Tuning for Continual Pre-training",
            "abstract": "Continual pre-training is the paradigm where pre-trained language models (PLMs) continually acquire fresh knowledge from growing data and gradually get upgraded. Before an upgraded PLM is released, we may have tuned the original PLM for various tasks and stored the adapted weights. However, when tuning the upgraded PLM, these outdated adapted weights will typically be ignored and discarded, causing a potential waste of resources. We bring this issue to the forefront and contend that proper algorithms for recycling outdated adapted weights should be developed. To this end, we formulate the task of recyclable tuning for continual pre-training. In pilot studies, we find that after continual pre-training, the upgraded PLM remains compatible with the outdated adapted weights to some extent. Motivated by this finding, we analyze the connection between continually pre-trained PLMs from two novel aspects, i.e., mode connectivity, and functional similarity. Based on the corresponding findings, we propose both an initialization-based method and a distillation-based method for our task. We demonstrate their feasibility in improving the convergence and performance for tuning the upgraded PLM. We also show that both methods can be combined to achieve better performance. The source codes are publicly available at https://github.com/thunlp/RecyclableTuning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "2082473972",
                    "name": "Cheng Qian"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "2427350",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "3360722",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                },
                {
                    "authorId": "49640256",
                    "name": "Jie Zhou"
                }
            ]
        },
        {
            "paperId": "c3ed333a37a6d9a0fcf1dad3106a114f66a45b99",
            "title": "WebCPM: Interactive Web Search for Chinese Long-form Question Answering",
            "abstract": "Long-form question answering (LFQA) aims at answering complex, open-ended questions with detailed, paragraph-length responses. The de facto paradigm of LFQA necessitates two procedures: information retrieval, which searches for relevant supporting facts, and information synthesis, which integrates these facts into a coherent answer. In this paper, we introduce WebCPM, the first Chinese LFQA dataset. One unique feature of WebCPM is that its information retrieval is based on interactive web search, which engages with a search engine in real time. Following WebGPT, we develop a web search interface. We recruit annotators to search for relevant information using our interface and then answer questions. Meanwhile, the web search behaviors of our annotators would be recorded. In total, we collect 5,500 high-quality question-answer pairs, together with 15,372 supporting facts and 125,954 web search actions. We fine-tune pre-trained language models to imitate human behaviors for web search and to generate answers based on the collected facts. Our LFQA pipeline, built on these fine-tuned models, generates answers that are no worse than human-written ones in 32.5% and 47.5% of the cases on our dataset and DuReader, respectively. The interface, dataset, and codes are publicly available at https://github.com/thunlp/WebCPM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "2113441349",
                    "name": "Zihan Cai"
                },
                {
                    "authorId": "1860892",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2214613855",
                    "name": "Lan Yan"
                },
                {
                    "authorId": "2163374235",
                    "name": "Shi Liang"
                },
                {
                    "authorId": "2214586034",
                    "name": "Kunlun Zhu"
                },
                {
                    "authorId": "2149202150",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "48506411",
                    "name": "Xu Han"
                },
                {
                    "authorId": "46649145",
                    "name": "Ning Ding"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "3360722",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "51466208",
                    "name": "Fanchao Qi"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                },
                {
                    "authorId": "49640256",
                    "name": "Jie Zhou"
                }
            ]
        },
        {
            "paperId": "d416ebeee27c2cb6c25acd35fc65f7453398aee9",
            "title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
            "abstract": "From ancient water wheels to robotic process automation (RPA), automation technology has evolved throughout history to liberate human beings from arduous tasks. Yet, RPA struggles with tasks needing human-like intelligence, especially in elaborate design of workflow construction and dynamic decision-making in workflow execution. As Large Language Models (LLMs) have emerged human-like intelligence, this paper introduces Agentic Process Automation (APA), a groundbreaking automation paradigm using LLM-based agents for advanced automation by offloading the human labor to agents associated with construction and execution. We then instantiate ProAgent, an LLM-based agent designed to craft workflows from human instructions and make intricate decisions by coordinating specialized agents. Empirical experiments are conducted to detail its construction and execution procedure of workflow, showcasing the feasibility of APA, unveiling the possibility of a new paradigm of automation driven by agents. Our code is public at https://github.com/OpenBMB/ProAgent.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114059497",
                    "name": "Yining Ye"
                },
                {
                    "authorId": "2214579778",
                    "name": "Xin Cong"
                },
                {
                    "authorId": "2267335977",
                    "name": "Shizuo Tian"
                },
                {
                    "authorId": "2268482142",
                    "name": "Jian Cao"
                },
                {
                    "authorId": "2267445794",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "50625437",
                    "name": "Yujia Qin"
                },
                {
                    "authorId": "2191753738",
                    "name": "Ya-Ting Lu"
                },
                {
                    "authorId": "2257104073",
                    "name": "Heyang Yu"
                },
                {
                    "authorId": "2155242767",
                    "name": "Huadong Wang"
                },
                {
                    "authorId": "2427350",
                    "name": "Yankai Lin"
                },
                {
                    "authorId": "2141313179",
                    "name": "Zhiyuan Liu"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                }
            ]
        }
    ]
}