{
    "authorId": "7583867",
    "papers": [
        {
            "paperId": "5485e2390a8657cd81d49ca9cae7de3f9da7da55",
            "title": "Quantifying uncertainty in graph neural network explanations",
            "abstract": "In recent years, analyzing the explanation for the prediction of Graph Neural Networks (GNNs) has attracted increasing attention. Despite this progress, most existing methods do not adequately consider the inherent uncertainties stemming from the randomness of model parameters and graph data, which may lead to overconfidence and misguiding explanations. However, it is challenging for most of GNN explanation methods to quantify these uncertainties since they obtain the prediction explanation in a post-hoc and model-agnostic manner without considering the randomness of graph data and model parameters. To address the above problems, this paper proposes a novel uncertainty quantification framework for GNN explanations. For mitigating the randomness of graph data in the explanation, our framework accounts for two distinct data uncertainties, allowing for a direct assessment of the uncertainty in GNN explanations. For mitigating the randomness of learned model parameters, our method learns the parameter distribution directly from the data, obviating the need for assumptions about specific distributions. Moreover, the explanation uncertainty within model parameters is also quantified based on the learned parameter distributions. This holistic approach can integrate with any post-hoc GNN explanation methods. Empirical results from our study show that our proposed method sets a new standard for GNN explanation performance across diverse real-world graph benchmarks.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157887017",
                    "name": "Junji Jiang"
                },
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2300683683",
                    "name": "Hongyi Li"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2255325982",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2284637383",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "5f09b1184b72754935747662028c53b1f6714289",
            "title": "Continuous Temporal Domain Generalization",
            "abstract": "Temporal Domain Generalization (TDG) addresses the challenge of training predictive models under temporally varying data distributions. Traditional TDG approaches typically focus on domain data collected at fixed, discrete time intervals, which limits their capability to capture the inherent dynamics within continuous-evolving and irregularly-observed temporal domains. To overcome this, this work formalizes the concept of Continuous Temporal Domain Generalization (CTDG), where domain data are derived from continuous times and are collected at arbitrary times. CTDG tackles critical challenges including: 1) Characterizing the continuous dynamics of both data and models, 2) Learning complex high-dimensional nonlinear dynamics, and 3) Optimizing and controlling the generalization across continuous temporal domains. To address them, we propose a Koopman operator-driven continuous temporal domain generalization (Koodos) framework. We formulate the problem within a continuous dynamic system and leverage the Koopman theory to learn the underlying dynamics; the framework is further enhanced with a comprehensive optimization strategy equipped with analysis and control driven by prior knowledge of the dynamics patterns. Extensive experiments demonstrate the effectiveness and efficiency of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48569716",
                    "name": "Z. Cai"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "31279896",
                    "name": "Renhe Jiang"
                },
                {
                    "authorId": "2112276021",
                    "name": "Xuan Song"
                },
                {
                    "authorId": "2303428706",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "6348aeb405a496ca1729f3cc6e5eb6f12d0bc151",
            "title": "Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models",
            "abstract": "The burgeoning field of Large Language Models (LLMs), exemplified by sophisticated models like OpenAI's ChatGPT, represents a significant advancement in artificial intelligence. These models, however, bring forth substantial challenges in the high consumption of computational, memory, energy, and financial resources, especially in environments with limited resource capabilities. This survey aims to systematically address these challenges by reviewing a broad spectrum of techniques designed to enhance the resource efficiency of LLMs. We categorize methods based on their optimization focus: computational, memory, energy, financial, and network resources and their applicability across various stages of an LLM's lifecycle, including architecture design, pretraining, finetuning, and system design. Additionally, the survey introduces a nuanced categorization of resource efficiency techniques by their specific resource types, which uncovers the intricate relationships and mappings between various resources and corresponding optimization techniques. A standardized set of evaluation metrics and datasets is also presented to facilitate consistent and fair comparisons across different models and techniques. By offering a comprehensive overview of the current sota and identifying open research avenues, this survey serves as a foundational reference for researchers and practitioners, aiding them in developing more sustainable and efficient LLMs in a rapidly evolving landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "1712184172",
                    "name": "Zheng Chai"
                },
                {
                    "authorId": "2219702470",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2130352205",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "2277715552",
                    "name": "Jiaying Lu"
                },
                {
                    "authorId": "2277696647",
                    "name": "Nan Zhang"
                },
                {
                    "authorId": "2277246146",
                    "name": "Tingwei Shi"
                },
                {
                    "authorId": "2220480304",
                    "name": "Ziyang Yu"
                },
                {
                    "authorId": "2277246079",
                    "name": "Mengdan Zhu"
                },
                {
                    "authorId": "2225551885",
                    "name": "Yifei Zhang"
                },
                {
                    "authorId": "2238138844",
                    "name": "Carl Yang"
                },
                {
                    "authorId": "2257750793",
                    "name": "Yue Cheng"
                },
                {
                    "authorId": "2253942086",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "7adb88771376c2a31688e3b0395b0550a35b824d",
            "title": "Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models",
            "abstract": "In-context learning has emerged as a ground-breaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM\u2019s response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM\u2019s response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model\u2019s configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-context learning in a plug-and-play fashion. Extensive experiments are conducted to demonstrate the effectiveness of the decomposition. The code and data are available at: https://github. com/lingchen0331/UQ_ICL .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2255325982",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2249879747",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2238385975",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2283302224",
                    "name": "Yiyou Sun"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2265519247",
                    "name": "Mika Oishi"
                },
                {
                    "authorId": "2238209691",
                    "name": "Takao Osaki"
                },
                {
                    "authorId": "2057662658",
                    "name": "Katsushi Matsuda"
                },
                {
                    "authorId": "2284299533",
                    "name": "Jie Ji"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2282545112",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "8838bebd9c84c861b79ca3be476435c022000426",
            "title": "Deep Causal Generative Models with Property Control",
            "abstract": "Generating data with properties of interest by external users while following the right causation among its intrinsic factors is important yet has not been well addressed jointly. This is due to the long-lasting challenge of jointly identifying key latent variables, their causal relations, and their correlation with properties of interest, as well as how to leverage their discoveries toward causally controlled data generation. To address these challenges, we propose a novel deep generative framework called the Correlation-aware Causal Variational Auto-encoder (C2VAE). This framework simultaneously recovers the correlation and causal relationships between properties using disentangled latent vectors. Specifically, causality is captured by learning the causal graph on latent variables through a structural causal model, while correlation is learned via a novel correlation pooling algorithm. Extensive experiments demonstrate C2VAE's ability to accurately recover true causality and correlation, as well as its superiority in controllable data generation compared to baseline models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2256983619",
                    "name": "Qilong Zhao"
                },
                {
                    "authorId": "2130352205",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2257038621",
                    "name": "Bo Pan"
                },
                {
                    "authorId": "2217973499",
                    "name": "Zhaohui Qin"
                },
                {
                    "authorId": "2303428706",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "a688f7d6d79eefebdfd6b55d626f9a083be5e0ba",
            "title": "Gradient-Free Adaptive Global Pruning for Pre-trained Language Models",
            "abstract": "The transformative impact of large language models (LLMs) like LLaMA and GPT on nat-ural language processing is countered by their prohibitive computational demands. Pruning has emerged as a pivotal compression strategy, introducing sparsity to enhance both memory and computational efficiency. Yet, traditional global pruning is impractical for LLMs due to scalability issues, while local pruning, despite its efficiency, leads to suboptimal solutions. Ad-dressing these challenges, we propose Adaptive Global Pruning (AdaGP), a novel framework that redefines the global pruning process into manageable, coordinated subproblems, allowing for resource-efficient optimization with global optimality. AdaGP\u2019s approach, which conceptualizes LLMs as a chain of modular functions and leverages auxiliary variables for problem decomposition, not only facilitates a pragmatic application on LLMs but also demonstrates significant performance improvements, particularly in high-sparsity regimes where it surpasses current state-of-the-art methods. The source code of AdaGP is available at https: //github.com/BaiTheBest/AdaGP .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2288037157",
                    "name": "Yijiang Li"
                },
                {
                    "authorId": "2284591355",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2288023827",
                    "name": "Kibaek Kim"
                },
                {
                    "authorId": "2303428706",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "be8c90bca14d59f180f40a41126b7cd8c29c5d4e",
            "title": "Uncertainty Quantification for In-Context Learning of Large Language Models",
            "abstract": "In-context learning has emerged as a groundbreaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM\u2019s response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM\u2019s response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model\u2019s configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-context learning in a plug-and-play fashion. Extensive experiments are conducted to demonstrate the effectiveness of the decomposition. The code and data are available at: https://github.com/lingchen0331/UQ_ICL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238210413",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2255325982",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "2249879747",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2238385975",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2283302224",
                    "name": "Yiyou Sun"
                },
                {
                    "authorId": "2048981220",
                    "name": "Xuchao Zhang"
                },
                {
                    "authorId": "2265519247",
                    "name": "Mika Oishi"
                },
                {
                    "authorId": "2238209691",
                    "name": "Takao Osaki"
                },
                {
                    "authorId": "2057662658",
                    "name": "Katsushi Matsuda"
                },
                {
                    "authorId": "2284299533",
                    "name": "Jie Ji"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2151579859",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2204622281",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "eb87c11618e2de4f1287320c22cedcc9ad1af761",
            "title": "SparseLLM: Towards Global Pruning for Pre-trained Language Models",
            "abstract": "The transformative impact of large language models (LLMs) like LLaMA and GPT on natural language processing is countered by their prohibitive computational demands. Pruning has emerged as a pivotal compression strategy, introducing sparsity to enhance both memory and computational efficiency. Yet, traditional global pruning is impractical for LLMs due to scalability issues, while local pruning, despite its efficiency, leads to suboptimal solutions. Addressing these challenges, we propose SparseLLM, a novel framework that redefines the global pruning process into manageable, coordinated subproblems, allowing for resource-efficient optimization with global optimality. SparseLLM's approach, which conceptualizes LLMs as a chain of modular functions and leverages auxiliary variables for problem decomposition, not only facilitates a pragmatic application on LLMs but also demonstrates significant performance improvements, particularly in high-sparsity regimes where it surpasses current state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2288037157",
                    "name": "Yijiang Li"
                },
                {
                    "authorId": "2284591355",
                    "name": "Chen Ling"
                },
                {
                    "authorId": "2288023827",
                    "name": "Kibaek Kim"
                },
                {
                    "authorId": "2284637383",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "3b59fabd3f0f8f34a33508943d09c91c720c0281",
            "title": "Domain Generalization Deep Graph Transformation",
            "abstract": "Graph transformation that predicts graph transition from one mode to another is an important and common problem. Despite much progress in developing advanced graph transformation techniques in recent years, the fundamental assumption typically required in machine-learning models that the testing and training data preserve the same distribution does not always hold. As a result, domain generalization graph transformation that predicts graphs not available in the training data is under-explored, with multiple key challenges to be addressed including (1) the extreme space complexity when training on all input-output mode combinations, (2) difference of graph topologies between the input and the output modes, and (3) how to generalize the model to (unseen) target domains that are not in the training data. To fill the gap, we propose a multi-input, multi-output, hypernetwork-based graph neural network (MultiHyperGNN) that employs a encoder and a decoder to encode topologies of both input and output modes and semi-supervised link prediction to enhance the graph transformation task. Instead of training on all mode combinations, MultiHyperGNN preserves a constant space complexity with the encoder and the decoder produced by two novel hypernetworks. Comprehensive experiments show that MultiHyperGNN has a superior performance than competing models in both prediction and domain generalization tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130352205",
                    "name": "Shiyu Wang"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "144400492",
                    "name": "Qi Zhu"
                },
                {
                    "authorId": "2217973499",
                    "name": "Zhaohui Qin"
                },
                {
                    "authorId": "144000223",
                    "name": "Liang Zhao"
                }
            ]
        },
        {
            "paperId": "79853389c5fe1cc03cfde961779e145628d8d4b2",
            "title": "Visual Attention-Prompted Prediction and Learning",
            "abstract": "Visual explanation (attention)-guided learning uses not only labels but also explanations to guide the model reasoning process. While visual attention-guided learning has shown promising results, it requires a large number of explanation annotations that are time-consuming to prepare. However, in many real-world situations, it is usually desired to prompt the model with visual attention without model retraining. For example, when doing AI-assisted cancer classification on a medical image, users (e.g., clinicians) can provide the AI model with visual attention prompts on which areas are indispensable and which are precluded. Despite its promising objectives, achieving visual attention-prompted prediction presents several major challenges: 1) How can the visual prompt be effectively integrated into the model's reasoning process? 2) How should the model handle samples that lack visual prompts? 3) What is the impact on the model's performance when a visual prompt is imperfect? This paper introduces a novel framework for visual attention prompted prediction and learning, utilizing visual prompts to steer the model's reasoning process. To improve performance in non-prompted situations and align it with prompted scenarios, we propose a co-training approach for both non-prompted and prompted models, ensuring they share similar parameters and activation. Additionally, for instances where the visual prompt does not encompass the entire input image, we have developed innovative attention prompt refinement methods. These methods interpolate the incomplete prompts while maintaining alignment with the model's explanations. Extensive experiments on four datasets demonstrate the effectiveness of our proposed framework in enhancing predictions for samples both with and without prompt.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2225551885",
                    "name": "Yifei Zhang"
                },
                {
                    "authorId": "2257346836",
                    "name": "Siyi Gu"
                },
                {
                    "authorId": "2257038621",
                    "name": "Bo Pan"
                },
                {
                    "authorId": "7583867",
                    "name": "Guangji Bai"
                },
                {
                    "authorId": "2257374792",
                    "name": "Xiaofeng Yang"
                },
                {
                    "authorId": "2253942086",
                    "name": "Liang Zhao"
                }
            ]
        }
    ]
}