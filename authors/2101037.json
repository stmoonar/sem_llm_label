{
    "authorId": "2101037",
    "papers": [
        {
            "paperId": "822f94dadb65d7cc0ab680efd65301aa26cd09f8",
            "title": "ReSi: A Comprehensive Benchmark for Representational Similarity Measures",
            "abstract": "Measuring the similarity of different representations of neural architectures is a fundamental task and an open research challenge for the machine learning community. This paper presents the first comprehensive benchmark for evaluating representational similarity measures based on well-defined groundings of similarity. The representational similarity (ReSi) benchmark consists of (i) six carefully designed tests for similarity measures, (ii) 23 similarity measures, (iii) eleven neural network architectures, and (iv) six datasets, spanning over the graph, language, and vision domains. The benchmark opens up several important avenues of research on representational similarity that enable novel explorations and applications of neural architectures. We demonstrate the utility of the ReSi benchmark by conducting experiments on various neural network architectures, real world datasets and similarity measures. All components of the benchmark are publicly available and thereby facilitate systematic reproduction and production of research results. The benchmark is extensible, future research can build on and further expand it. We believe that the ReSi benchmark can serve as a sound platform catalyzing future research that aims to systematically evaluate existing and explore novel ways of comparing representations of neural architectures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1707027340",
                    "name": "Max Klabunde"
                },
                {
                    "authorId": "2057486434",
                    "name": "Tassilo Wald"
                },
                {
                    "authorId": "39124179",
                    "name": "Tobias Schumacher"
                },
                {
                    "authorId": "2277887121",
                    "name": "Klaus H. Maier-Hein"
                },
                {
                    "authorId": "2270367871",
                    "name": "Markus Strohmaier"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                }
            ]
        },
        {
            "paperId": "2742460c702206fe19c0b5ceae97fef3499bdf76",
            "title": "Similarity of Neural Network Models: A Survey of Functional and Representational Measures",
            "abstract": "Measuring similarity of neural networks to understand and improve their behavior has become an issue of great importance and research interest. In this survey, we provide a comprehensive overview of two complementary perspectives of measuring neural network similarity: (i) representational similarity, which considers how activations of intermediate layers differ, and (ii) functional similarity, which considers how models differ in their outputs. In addition to providing detailed descriptions of existing measures, we summarize and discuss results on the properties of and relationships between these measures, and point to open research problems. We hope our work lays a foundation for more systematic research on the properties and applicability of similarity measures for neural network models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1707027340",
                    "name": "Max Klabunde"
                },
                {
                    "authorId": "39124179",
                    "name": "Tobias Schumacher"
                },
                {
                    "authorId": "1743043",
                    "name": "M. Strohmaier"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                }
            ]
        },
        {
            "paperId": "3aaa6355a10e2630de6bd0693057556d46d39eeb",
            "title": "Bayesian estimation of decay parameters in Hawkes processes",
            "abstract": "Hawkes processes with exponential kernels are a ubiquitous tool for modeling and predicting event times. However, estimating their decay parameter is challenging, and there is a remarkable variability among decay parameter estimates. Moreover, this variability increases substantially in cases of a small number of realizations of the process or due to sudden changes to a system under study, for example, in the presence of exogenous shocks. In this work, we demonstrate that these estimation difficulties relate to the noisy, non-convex shape of the Hawkes process\u2019 log-likelihood as a function of the decay. To address uncertainty in the estimates, we propose to use a Bayesian approach to learn more about likely decay values. We show that our approach alleviates the decay estimation problem across a range of experiments with synthetic and real-world data. With our work, we support researchers and practitioners in their applications of Hawkes processes in general and in their interpretation of Hawkes process parameters in particular.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143623207",
                    "name": "Tiago Santos"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                },
                {
                    "authorId": "1747800",
                    "name": "D. Helic"
                }
            ]
        },
        {
            "paperId": "8f3492053904484a6cc76b35e0c3fc4d441563e4",
            "title": "Towards Measuring Representational Similarity of Large Language Models",
            "abstract": "Understanding the similarity of the numerous released large language models (LLMs) has many uses, e.g., simplifying model selection, detecting illegal model reuse, and advancing our understanding of what makes LLMs perform well. In this work, we measure the similarity of representations of a set of LLMs with 7B parameters. Our results suggest that some LLMs are substantially different from others. We identify challenges of using representational similarity measures that suggest the need of careful study of similarity scores to avoid false conclusions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1707027340",
                    "name": "Max Klabunde"
                },
                {
                    "authorId": "2074055134",
                    "name": "Mehdi Ben Amor"
                },
                {
                    "authorId": "2259357506",
                    "name": "Michael Granitzer"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                }
            ]
        },
        {
            "paperId": "56e39d150d2e36119450e7e91cba4c530610cc08",
            "title": "GetFair: Generalized Fairness Tuning of Classification Models",
            "abstract": "We present GetFair, a novel framework for tuning fairness of classification models. The fair classification problem deals with training models for a given classification task where data points have sensitive attributes. The goal of fair classification models is to not only generate accurate classification results but also to prevent discrimination against subpopulations (i.e., individuals with a specific value for the sensitive attribute). Existing methods for enhancing fairness of classification models, however, are often specifically designed for a particular fairness metric or a classifier model. They may also not be suitable for scenarios with incomplete training data or where optimizing for multiple fairness metrics is important. GetFair represents a general solution to this problem. The GetFair approach works in the following way: First, a given classifier is trained on training data without any fairness objective. This is followed by a reinforcement learning inspired tuning procedure which updates the parameters of the learned model on a given fairness objective. This disentangles classifier training from fairness tuning, making our framework more general and allowing for the adoption of any parameterized classifier model. Because fairness metrics are designed as reward functions during tuning, GetFair generalizes across any fairness metric. We demonstrate the generalizability of GetFair via evaluation over a benchmark suite of datasets, classification models, and fairness metrics. In addition, GetFair can also be deployed in settings where the training data is incomplete or the classifier needs to be tuned on multiple fairness metrics. GetFair not only contributes a flexible method to the repertoire of tools available to improve the fairness of classification models, it also seamlessly adapts to settings where existing fair classification methods may not be suitable or applicable.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2632448",
                    "name": "Sandipan Sikdar"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                },
                {
                    "authorId": "1743043",
                    "name": "M. Strohmaier"
                }
            ]
        },
        {
            "paperId": "9152a7d7da47ce08d1e6885497b1394e193c2f1d",
            "title": "Estimating the Pruned Search Space Size of Subgroup Discovery",
            "abstract": "Subgroup discovery (SD) is a well-established supervised pattern mining approach. A key practical challenge \u2014in particular considering interactive mining strategies\u2014 is that it is difficult to estimate the runtime of an exhaustive search algorithm before actually running the algorithm even for experienced practitioners. This is due to the exponential explosion of the candidate search space, sophisticated pruning strategies, and implementation specifics that can all affect the runtime by orders of magnitude depending on the dataset and the exact mining task parameters. A subgroup discovery run could take mere minutes or literal years. We would not know until afterwards. In this paper, we study the estimation of the complexity and runtime of subgroup discovery algorithms by estimating the pruned search space size, i.e., the number of actually evaluated candidate subgroups. We propose a sampling-based algorithm called SDFASTEST. SDFASTEST can effectively estimate the pruned search space size of a search algorithm. In our extensive evaluation on 1026 different tasks with 2 search algorithms, SDFASTEST was able to reduce the average mean absolute log error of the search space size estimation by ca. 94% compared to the best baseline, a depth-based upper bound.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2183888638",
                    "name": "Lennart Purucker"
                },
                {
                    "authorId": "2000792611",
                    "name": "Felix I. Stamm"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                },
                {
                    "authorId": "2137867216",
                    "name": "Joeran Beel"
                }
            ]
        },
        {
            "paperId": "bb72cceaa0ae0bb82d02d55e84e8207f8bcad1ee",
            "title": "On the Prediction Instability of Graph Neural Networks",
            "abstract": "Instability of trained models, i.e., the dependence of individual node predictions on random factors, can affect reproducibility, reliability, and trust in machine learning systems. In this paper, we systematically assess the prediction instability of node classification with state-of-the-art Graph Neural Networks (GNNs). With our experiments, we establish that multiple instantiations of popular GNN models trained on the same data with the same model hyperparameters result in almost identical aggregated performance but display substantial disagreement in the predictions for individual nodes. We find that up to one third of the incorrectly classified nodes differ across algorithm runs. We identify correlations between hyperparameters, node properties, and the size of the training set with the stability of predictions. In general, maximizing model performance implicitly also reduces model instability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1707027340",
                    "name": "Max Klabunde"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                }
            ]
        },
        {
            "paperId": "11e56575750245eb9b8215dba9033fc5d1c97c32",
            "title": "Updating Embeddings for Dynamic Knowledge Graphs",
            "abstract": "Data in Knowledge Graphs often represents part of the current state of the real world. Thus, to stay up-to-date the graph data needs to be updated frequently. To utilize information from Knowledge Graphs, many state-of-the-art machine learning approaches use embedding techniques. These techniques typically compute an embedding, i.e., vector representations of the nodes as input for the main machine learning algorithm. If a graph update occurs later on \u2014 specifically when nodes are added or removed \u2014 the training has to be done all over again. This is undesirable, because of the time it takes and also because downstream models which were trained with these embeddings have to be retrained if they change significantly. In this paper, we investigate embedding updates that do not require full retraining and evaluate them in combination with various embedding models on real dynamic Knowledge Graphs covering multiple use cases. We study approaches that place newly appearing nodes optimally according to local information, but notice that this does not work well. However, we find that if we continue the training of the old embedding, interleaved with epochs during which we only optimize for the added and removed parts, we obtain good results in terms of typical metrics used in link prediction. This performance is obtained much faster than with a complete retraining and hence makes it possible to maintain embeddings for dynamic Knowledge Graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238207797",
                    "name": "Christopher Wewer"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                },
                {
                    "authorId": "1708906",
                    "name": "Michael Cochez"
                }
            ]
        },
        {
            "paperId": "1500ae185eae87854d4cc6dd0a8402e25b9b5687",
            "title": "Redescription Model Mining",
            "abstract": "This paper introduces Redescription Model Mining, a novel approach to identify interpretable patterns across two datasets that share only a subset of attributes and have no common instances. In particular, Redescription Model Mining aims to find pairs of describable data subsets -- one for each dataset -- that induce similar exceptional models with respect to a prespecified model class. To achieve this, we combine two previously separate research areas: Exceptional Model Mining and Redescription Mining. For this new problem setting, we develop interestingness measures to select promising patterns, propose efficient algorithms, and demonstrate their potential on synthetic and real-world data. Uncovered patterns can hint at common underlying phenomena that manifest themselves across datasets, enabling the discovery of possible associations between (combinations of) attributes that do not appear in the same dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2000792611",
                    "name": "Felix I. Stamm"
                },
                {
                    "authorId": "38822389",
                    "name": "Martin Becker"
                },
                {
                    "authorId": "1743043",
                    "name": "M. Strohmaier"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                }
            ]
        },
        {
            "paperId": "246a08cd60f7c6b3dbe9ae5436f11c887ee6ed22",
            "title": "Extracting Semantics from Random Walks on Wikipedia: Comparing Learning and Counting Methods",
            "abstract": "\n \n Semantic relatedness between words has been extracted from a variety of sources.In this ongoing work, we explore and compare several options for determining if semantic relatedness can be extracted from navigation structures in Wikipedia. In that direction, we first investigate the potential of representation learning techniques such as DeepWalk in comparison to previously applied methods based on counting co-occurrences. Since both methods are based on (random) paths in the network, we also study different approaches to generate paths from Wikipedia link structure. For this task, we do not only consider the link structure of Wikipedia, but also actual navigation behavior of users. Finally, we analyze if semantics can also be extracted from smaller subsets of the Wikipedia link network. As a result we find that representation learning techniques mostly outperform the investigated co-occurrence counting methods on the Wikipedia network. However, we find that this is not the case for paths sampled from human navigation behavior.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3257345",
                    "name": "Alexander Dallmann"
                },
                {
                    "authorId": "2502754",
                    "name": "Thomas Niebler"
                },
                {
                    "authorId": "2101037",
                    "name": "Florian Lemmerich"
                },
                {
                    "authorId": "1792623",
                    "name": "A. Hotho"
                }
            ]
        }
    ]
}