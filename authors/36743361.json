{
    "authorId": "36743361",
    "papers": [
        {
            "paperId": "16259d44c317342758a81a8765f08504736da163",
            "title": "Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children\u2019s Fairy Tales",
            "abstract": "Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora. Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story\u2019s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes. Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40521719",
                    "name": "Paulina Toro Isaza"
                },
                {
                    "authorId": "2007669250",
                    "name": "Guangxuan Xu"
                },
                {
                    "authorId": "2181812178",
                    "name": "Akintoye Oloko"
                },
                {
                    "authorId": null,
                    "name": "Yufang Hou"
                },
                {
                    "authorId": "3157053",
                    "name": "Nanyun Peng"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                }
            ]
        },
        {
            "paperId": "5e684f5015dfd9e4ee773d39336cc219276eb79d",
            "title": "Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design",
            "abstract": "Machine learning practitioners often end up tunneling on low-level technical details like model architectures and performance metrics. Could early model development instead focus on high-level questions of which factors a model ought to pay attention to? Inspired by the practice of sketching in design, which distills ideas to their minimal representation, we introduce model sketching: a technical framework for iteratively and rapidly authoring functional approximations of a machine learning model\u2019s decision-making logic. Model sketching refocuses practitioner attention on composing high-level, human-understandable concepts that the model is expected to reason over (e.g., profanity, racism, or sarcasm in a content moderation task) using zero-shot concept instantiation. In an evaluation with 17 ML practitioners, model sketching reframed thinking from implementation to higher-level exploration, prompted iteration on a broader range of model designs, and helped identify gaps in the problem formulation\u2014all in a fraction of the time ordinarily required to build a model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2003820466",
                    "name": "Michelle S. Lam"
                },
                {
                    "authorId": "2149504559",
                    "name": "Zixian Ma"
                },
                {
                    "authorId": "2210844999",
                    "name": "Anne Li"
                },
                {
                    "authorId": "2210799990",
                    "name": "Izequiel Freitas"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "9522307",
                    "name": "J. Landay"
                },
                {
                    "authorId": "145879842",
                    "name": "Michael S. Bernstein"
                }
            ]
        },
        {
            "paperId": "6518bef04d03515b80e7f6600ccfb508b9976746",
            "title": "Exploring the Use of Personalized AI for Identifying Misinformation on Social Media",
            "abstract": "This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user\u2019s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users\u2019 judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10757000",
                    "name": "Farnaz Jahanbakhsh"
                },
                {
                    "authorId": "2208580",
                    "name": "Yannis Katsis"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "145378077",
                    "name": "Lucian Popa"
                },
                {
                    "authorId": "144247826",
                    "name": "Michael J. Muller"
                }
            ]
        },
        {
            "paperId": "8efdc85c069c07bbf845ab9a24e3d2e7267740fd",
            "title": "Human-centered design and evaluation of AI-empowered clinical decision support systems: a systematic review",
            "abstract": "Introduction Artificial intelligence (AI) technologies are increasingly applied to empower clinical decision support systems (CDSS), providing patient-specific recommendations to improve clinical work. Equally important to technical advancement is human, social, and contextual factors that impact the successful implementation and user adoption of AI-empowered CDSS (AI-CDSS). With the growing interest in human-centered design and evaluation of such tools, it is critical to synthesize the knowledge and experiences reported in prior work and shed light on future work. Methods Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we conducted a systematic review to gain an in-depth understanding of how AI-empowered CDSS was used, designed, and evaluated, and how clinician users perceived such systems. We performed literature search in five databases for articles published between the years 2011 and 2022. A total of 19874 articles were retrieved and screened, with 20 articles included for in-depth analysis. Results The reviewed studies assessed different aspects of AI-CDSS, including effectiveness (e.g., improved patient evaluation and work efficiency), user needs (e.g., informational and technological needs), user experience (e.g., satisfaction, trust, usability, workload, and understandability), and other dimensions (e.g., the impact of AI-CDSS on workflow and patient-provider relationship). Despite the promising nature of AI-CDSS, our findings highlighted six major challenges of implementing such systems, including technical limitation, workflow misalignment, attitudinal barriers, informational barriers, usability issues, and environmental barriers. These sociotechnical challenges prevent the effective use of AI-based CDSS interventions in clinical settings. Discussion Our study highlights the paucity of studies examining the user needs, perceptions, and experiences of AI-CDSS. Based on the findings, we discuss design implications and future research directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108551996",
                    "name": "Liuping Wang"
                },
                {
                    "authorId": "1989034331",
                    "name": "Zhan Zhang"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "2047896043",
                    "name": "Weidan Cao"
                },
                {
                    "authorId": "2110801298",
                    "name": "Xiaomu Zhou"
                },
                {
                    "authorId": "2157210033",
                    "name": "Ping Zhang"
                },
                {
                    "authorId": "2218857324",
                    "name": "Jianxing Liu"
                },
                {
                    "authorId": "2117801491",
                    "name": "Xiang-hong Fan"
                },
                {
                    "authorId": "2052643314",
                    "name": "Feng Tian"
                }
            ]
        },
        {
            "paperId": "d6f49f602154ab154687bd9f93959b3010c60351",
            "title": "SHAI 2023: Workshop on Designing for Safety in Human-AI Interactions",
            "abstract": "Generative ML models present a novel opportunity for a wider group of societal members to engage with AI, imagine new use cases, and applications with an increasing ability to disseminate the outcomes of such endeavors to larger audiences. However, owing to the novelty and despite best intentions, inadvertent outcomes might accrue leading to harms, especially to marginalized groups in society. As this field of Human AI Interaction advances, academic/industry researchers, and industry practitioners have an opportunity to brainstorm how to best utilize this new technology. Our workshop is aimed at such practitioners and researchers at the intersection of AI and HCI who are interested in collaboratively identifying challenges, and solutions to create safer outcomes with Generative ML models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40571524",
                    "name": "Nitesh Goyal"
                },
                {
                    "authorId": "2309766",
                    "name": "Sungsoo Ray Hong"
                },
                {
                    "authorId": "1788745",
                    "name": "R. Mandryk"
                },
                {
                    "authorId": "34997918",
                    "name": "Toby Jia-Jun Li"
                },
                {
                    "authorId": "144647604",
                    "name": "Kurt Luther"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                }
            ]
        },
        {
            "paperId": "fc659f06ffabddb1ba0af4bb3d9e185fc4f18f0f",
            "title": "Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations",
            "abstract": "Human-annotated labels and explanations are critical for training explainable NLP models. However, unlike human-annotated labels whose quality is easier to calibrate (e.g., with a majority vote), human-crafted free-form explanations can be quite subjective. Before blindly using them as ground truth to train ML models, a vital question needs to be asked: How do we evaluate a human-annotated explanation\u2019s quality? In this paper, we build on the view that the quality of a human-annotated explanation can be measured based on its helpfulness (or impairment) to the ML models\u2019 performance for the desired NLP tasks for which the annotations were collected. In comparison to the commonly used Simulatability score, we define a new metric that can take into consideration the helpfulness of an explanation for model performance at both fine-tuning and inference. With the help of a unified dataset format, we evaluated the proposed metric on five datasets (e.g., e-SNLI) against two model architectures (T5 and BART), and the results show that our proposed metric can objectively evaluate the quality of human-annotated explanations, while Simulatability falls short.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1490485182",
                    "name": "Bingsheng Yao"
                },
                {
                    "authorId": "40655309",
                    "name": "Prithviraj Sen"
                },
                {
                    "authorId": "145378077",
                    "name": "Lucian Popa"
                },
                {
                    "authorId": "1701341",
                    "name": "J. Hendler"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                }
            ]
        },
        {
            "paperId": "257040c29fb9e7067d4ed1fa77ab73366687e835",
            "title": "Educational Question Generation of Children Storybooks via Question Type Distribution Learning and Event-centric Summarization",
            "abstract": "Generating educational questions of fairytales or storybooks is vital for improving children\u2019s literacy ability. However, it is challenging to generate questions that capture the interesting aspects of a fairytale story with educational meaningfulness. In this paper, we propose a novel question generation method that first learns the question type distribution of an input story paragraph, and then summarizes salient events which can be used to generate high-cognitive-demand questions. To train the event-centric summarizer, we finetune a pre-trained transformer-based sequence-to-sequence model using silver samples composed by educational question-answer pairs. On a newly proposed educational question-answering dataset FairytaleQA, we show good performance of our method on both automatic and human evaluation metrics. Our work indicates the necessity of decomposing question type distribution learning and event-centric summary generation for educational question generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152618823",
                    "name": "Zhenjie Zhao"
                },
                {
                    "authorId": "39517968",
                    "name": "Yufang Hou"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "2110318482",
                    "name": "Mo Yu"
                },
                {
                    "authorId": "2156639193",
                    "name": "Chengzhong Liu"
                },
                {
                    "authorId": "2159536581",
                    "name": "Xiaojuan Ma"
                }
            ]
        },
        {
            "paperId": "3a95297c191257af856e660e8865a1cd65abe4d6",
            "title": "NECE: Narrative Event Chain Extraction Toolkit",
            "abstract": "To understand a narrative, it is essential to comprehend the temporal event flows, especially those associated with main characters; however, this can be challenging with lengthy and unstructured narrative texts. To address this, we introduce NECE, an open-access, document-level toolkit that automatically extracts and aligns narrative events in the temporal order of their occurrence. Through extensive evaluations, we show the high quality of the NECE toolkit and demonstrates its downstream application in analyzing narrative bias regarding gender. We also openly discuss the shortcomings of the current approach, and potential of leveraging generative models in future works. Lastly the NECE toolkit includes both a Python library and a user-friendly web interface, which offer equal access to professionals and layman audience alike, to visualize event chain, obtain narrative flows, or study narrative bias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007669250",
                    "name": "Guangxuan Xu"
                },
                {
                    "authorId": "40521719",
                    "name": "Paulina Toro Isaza"
                },
                {
                    "authorId": "2181798057",
                    "name": "Moshi Li"
                },
                {
                    "authorId": "2181812178",
                    "name": "Akintoye Oloko"
                },
                {
                    "authorId": "1490485182",
                    "name": "Bingsheng Yao"
                },
                {
                    "authorId": "2181811027",
                    "name": "Aminat Adebeyi"
                },
                {
                    "authorId": null,
                    "name": "Yufang Hou"
                },
                {
                    "authorId": "3157053",
                    "name": "Nanyun Peng"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                }
            ]
        },
        {
            "paperId": "6f00dceaf0717e83f3b75c209b48936db1faf4ac",
            "title": "Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours",
            "abstract": "Text classification can be useful in many real-world scenarios, saving a lot of time for end users. However, building a custom classifier typically requires coding skills and ML knowledge, which poses a significant barrier for many potential users. To lift this barrier, we introduce Label Sleuth, a free open source system for labeling and creating text classifiers. This system is unique for (a) being a no-code system, making NLP accessible to non-experts, (b) guiding users through the entire labeling process until they obtain a custom classifier, making the process efficient -- from cold start to classifier in a few hours, and (c) being open for configuration and extension by developers. By open sourcing Label Sleuth we hope to build a community of users and developers that will broaden the utilization of NLP models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1734246",
                    "name": "Eyal Shnarch"
                },
                {
                    "authorId": "41127252",
                    "name": "Alon Halfon"
                },
                {
                    "authorId": "48835746",
                    "name": "Ariel Gera"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "2208580",
                    "name": "Yannis Katsis"
                },
                {
                    "authorId": "41019330",
                    "name": "Leshem Choshen"
                },
                {
                    "authorId": "2106505319",
                    "name": "M. Cooper"
                },
                {
                    "authorId": "2180021780",
                    "name": "Dina Epelboim"
                },
                {
                    "authorId": "2148906676",
                    "name": "Zheng Zhang"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "2171374727",
                    "name": "Lucy Yip"
                },
                {
                    "authorId": "1402680837",
                    "name": "L. Ein-Dor"
                },
                {
                    "authorId": "2839128",
                    "name": "Lena Dankin"
                },
                {
                    "authorId": "2627091",
                    "name": "Ilya Shnayderman"
                },
                {
                    "authorId": "48361424",
                    "name": "R. Aharonov"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2089779821",
                    "name": "Naftali Liberman"
                },
                {
                    "authorId": "2180023871",
                    "name": "Philip Levin Slesarev"
                },
                {
                    "authorId": "2104532982",
                    "name": "Gwilym Newton"
                },
                {
                    "authorId": "1405604910",
                    "name": "Shila Ofek-Koifman"
                },
                {
                    "authorId": "1766595",
                    "name": "N. Slonim"
                },
                {
                    "authorId": "1722434",
                    "name": "Yoav Katz"
                }
            ]
        },
        {
            "paperId": "7a6836d67156228f6693d14c67e1b7e97ddc04c3",
            "title": "Telling Stories from Computational Notebooks: AI-Assisted Presentation Slides Creation for Presenting Data Science Work",
            "abstract": "Creating presentation slides is a critical but time-consuming task for data scientists. While researchers have proposed many AI techniques to lift data scientists\u2019 burden on data preparation and model selection, few have targeted the presentation creation task. Based on the needs identified from a formative study, this paper presents NB2Slides, an AI system that facilitates users to compose presentations of their data science work. NB2Slides uses deep learning methods as well as example-based prompts to generate slides from computational notebooks, and take users\u2019 input (e.g., audience background) to structure the slides. NB2Slides also provides an interactive visualization that links the slides with the notebook to help users further edit the slides. A follow-up user evaluation with 12 data scientists shows that participants believed NB2Slides can improve efficiency and reduces the complexity of creating slides. Yet, participants questioned the future of full automation and suggested a human-AI collaboration paradigm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153619689",
                    "name": "Chengbo Zheng"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "2159536581",
                    "name": "Xiaojuan Ma"
                }
            ]
        }
    ]
}