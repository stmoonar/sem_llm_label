{
    "authorId": "2145734886",
    "papers": [
        {
            "paperId": "b027cb327be4a5051f00f0b84d936e8b2d3b653c",
            "title": "Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment",
            "abstract": "Generalizing a deep learning model to new domains is crucial for computer-aided medical diagnosis systems. Most existing unsupervised domain adaptation methods have made significant progress in reducing the domain distribution gap through adversarial training. However, these methods may still produce overconfident but erroneous results on unseen target images. This paper proposes a new unsupervised domain adaptation framework for cross-modality medical image segmentation. Specifically, We first introduce two data augmentation approaches to generate two sets of semantics-preserving augmented images. Based on the model's predictive consistency on these two sets of augmented images, we identify reliable and unreliable pixels. We then perform a selective entropy constraint: we minimize the entropy of reliable pixels to increase their confidence while maximizing the entropy of unreliable pixels to reduce their confidence. Based on the identified reliable and unreliable pixels, we further propose an adaptive semantic alignment module which performs class-level distribution adaptation by minimizing the distance between same class prototypes between domains, where unreliable pixels are removed to derive more accurate prototypes. We have conducted extensive experiments on the cross-modality cardiac structure segmentation task. The experimental results show that the proposed method significantly outperforms the state-of-the-art comparison algorithms. Our code and data are available at https://github.com/fengweie/SE_ASA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114326503",
                    "name": "Wei Feng"
                },
                {
                    "authorId": "50884038",
                    "name": "Lie Ju"
                },
                {
                    "authorId": "2144734256",
                    "name": "Lin Wang"
                },
                {
                    "authorId": "2147337543",
                    "name": "Kaimin Song"
                },
                {
                    "authorId": "2145734886",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "2111742544",
                    "name": "Z. Ge"
                }
            ]
        },
        {
            "paperId": "856a0839f8ef4e1c8cd26faf82b8592c771d5395",
            "title": "Three-dimensional Microstructural Image Synthesis from 2D Backscattered Electron Image of Cement Paste",
            "abstract": "This paper proposes a deep learning-based method for generating 3D microstructures from a single two-dimensional (2D) image, capable of producing high-quality, realistic 3D images at low cost. In the method, a framework (CEM3DMG) is designed to synthesize 3D images by learning microstructural information from a 2D backscattered electron (BSE) image. Experimental results show that CEM3DMG can generate realistic 3D images of arbitrary size with a resolution of 0.47 $\\mu m$ per pixel. Visual observation confirms that the generated 3D images exhibit similar microstructural features to the 2D images, including pores and particles morphology. Furthermore, quantitative analysis reveals that these 3D microstructures closely match the real 2D microstructure in terms of gray level histogram, phase proportions, and pore size distribution.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145734886",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "2117920766",
                    "name": "Xu Wu"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "92069083",
                    "name": "P. Hou"
                },
                {
                    "authorId": "2161491560",
                    "name": "Qinfei Li"
                },
                {
                    "authorId": "2145067578",
                    "name": "Yuxuan Zhang"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                }
            ]
        },
        {
            "paperId": "7102417cddf26d581591780aaa2f2066cb282ad9",
            "title": "Solid Texture Synthesis using Generative Adversarial Networks",
            "abstract": "Solid texture synthesis (STS), as an effective way to extend 2D exemplar to a 3D solid volume, exhibits advantages in numerous application domains. However, existing methods generally synthesize solid texture with speci\ufb01c features, which may result in the failure of capturing diversi\ufb01ed textural information. In this paper, we propose a novel generative adversarial nets-based approach (STS-GAN) to hierarchically learn solid texture with a feature-free nature. Our multi-scale discriminators evaluate the similarity between patch from exemplar and slice from the generated volume, promoting the generator to synthesize realistic solid textures. Experimental results demonstrate that the proposed method can generate high-quality solid textures with similar visual characteristics to the exemplar.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145734886",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "48169697",
                    "name": "Lin Wang"
                },
                {
                    "authorId": "15563174",
                    "name": "Jifeng Guo"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2115843401",
                    "name": "Junteng Zheng"
                },
                {
                    "authorId": "2146329569",
                    "name": "Fanqi Li"
                }
            ]
        },
        {
            "paperId": "89ce04c63050703c57983abe866543a0020015d9",
            "title": "STS-GAN: Can We Synthesize Solid Texture with High Fidelity from Arbitrary 2D Exemplar?",
            "abstract": "Solid texture synthesis (STS), an effective way to extend a 2D exemplar to a 3D solid volume, exhibits advantages in computational photography. However, existing methods generally fail to accurately learn arbitrary textures, which may result in the failure to synthesize solid textures with high fidelity. In this paper, we propose a novel generative adversarial nets-based framework (STS-GAN) to extend the given 2D exemplar to arbitrary 3D solid textures. In STS-GAN, multi-scale 2D texture discriminators evaluate the similarity between the given 2D exemplar and slices from the generated 3D texture, promoting the 3D texture generator synthesizing realistic solid textures. Finally, experiments demonstrate that the proposed method can generate high-fidelity solid textures with similar visual characteristics to the 2D exemplar.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2145734886",
                    "name": "Xin Zhao"
                },
                {
                    "authorId": "15563174",
                    "name": "Jifeng Guo"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2146329569",
                    "name": "Fanqi Li"
                },
                {
                    "authorId": "2115843401",
                    "name": "Junteng Zheng"
                },
                {
                    "authorId": "2119658606",
                    "name": "Bo Yang"
                }
            ]
        }
    ]
}