{
    "authorId": "2210047886",
    "papers": [
        {
            "paperId": "0b5970fd876b52b676f878079b52e7289dc56025",
            "title": "DeepFixCX: Explainable privacy\u2010preserving image compression for medical image analysis",
            "abstract": "Explanations of a model's biases or predictions are essential to medical image analysis. Yet, explainable machine learning approaches for medical image analysis are challenged by needs to preserve privacy of patient data, and by current trends in deep learning to use unsustainably large models and large datasets. We propose DeepFixCX for explainable and privacy\u2010preserving medical image compression that is nimble and performant. We contribute a review of the field and a conceptual framework for simultaneous privacy and explainability via tools of compression. DeepFixCX compresses images without learning by removing or obscuring spatial and edge information. DeepFixCX is ante\u2010hoc explainable and gives privatized post hoc explanations of spatial and edge bias without accessing the original image. DeepFixCX privatizes images to prevent image reconstruction and mitigate patient re\u2010identification. DeepFixCX is nimble. Compression can occur on a laptop CPU or GPU to compress and privatize 1700 images per second of size 320\u2009\u00d7\u2009320. DeepFixCX enables use of low memory MLP classifiers for vision data; permitting small performance loss gives end\u2010to\u2010end MLP performance over 70\u00d7 faster and batch size over 100\u00d7 larger. DeepFixCX consistently improves predictive classification performance of a Deep Neural Network (DNN) by 0.02 AUC ROC on Glaucoma and Cervix Type detection datasets, and can improve multi\u2010label chest x\u2010ray classification performance in seven of 10 tested settings. In all three datasets, compression to less than 5% of original number of pixels gives matching or improved performance. Our main novelty is to define an explainability versus privacy problem and address it with lossy compression.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152888952",
                    "name": "Alex Gaudio"
                },
                {
                    "authorId": "1772588",
                    "name": "A. Smailagic"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "2186979527",
                    "name": "Shreshta Mohan"
                },
                {
                    "authorId": "1998967224",
                    "name": "Elvin Johnson"
                },
                {
                    "authorId": "2210047886",
                    "name": "Yuhao Liu"
                },
                {
                    "authorId": "145668048",
                    "name": "P. Costa"
                },
                {
                    "authorId": "36054719",
                    "name": "A. Campilho"
                }
            ]
        },
        {
            "paperId": "a5b953526f23c8fc322ca494cd6199cc5070d9ef",
            "title": "Do as You Say: Consistency Detection of Data Practice in Program Code and Privacy Policy in Mini-App",
            "abstract": "Mini-app is an emerging form of mobile application that combines web technology with native capabilities. Its features, e.g., no need to download and no installation, have made it popular rapidly. However, privacy issues that violate the laws or regulations are breeding in the swiftly expanding mini-app ecosystem. The consistency between what the mini-app does about the data in the program code and what it declares in its privacy policy description is important. But no work has systematically investigated the privacy problem of the mini-app before. In this paper, to our best knowledge, we are the first to conduct the compliance detection of data practice and policy description in mini-apps. In this paper, we first customize a taint analysis method based on data entity dependency network to adapt to the characteristics of the JavaScript language in the mini-apps. Then, we transform data types and data operations to data practices in program codes and privacy policies, so as to finish a fine-grained consistency matching model.We crawl 100,000 mini-apps on WeChat client in the wild and extract 2,998 with a privacy policy. Among them, only 318 meet the consistency requirements, 2,680 are inconsistent, and the proportion of inconsistencies is as high as 89.4%. The inconsistency in the mini-app is very serious. Based on 6 real-world cases analyzed, in order to reduce this potential data leakage risk, we suggest that the developer should reduce the collection of irrelevant information and the straightforward use of templates, and the platform should provide data flow detection tools and privacy policy writing support.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2210251122",
                    "name": "Yin Wang"
                },
                {
                    "authorId": "153441905",
                    "name": "Ming Fan"
                },
                {
                    "authorId": "2210041454",
                    "name": "Junfeng Liu"
                },
                {
                    "authorId": "121863497",
                    "name": "Junjie Tao"
                },
                {
                    "authorId": "7651458",
                    "name": "Wuxia Jin"
                },
                {
                    "authorId": "2071147843",
                    "name": "Qi Xiong"
                },
                {
                    "authorId": "2210047886",
                    "name": "Yuhao Liu"
                },
                {
                    "authorId": "2154412030",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "2150695993",
                    "name": "Ting Liu"
                }
            ]
        }
    ]
}