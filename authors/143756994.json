{
    "authorId": "143756994",
    "papers": [
        {
            "paperId": "eac877c27e940bfde277b8123e89f6db32cad6e5",
            "title": "Streaming Zero-Knowledge Proofs",
            "abstract": "Streaming interactive proofs (SIPs) enable a space-bounded algorithm with one-pass access to a massive stream of data to verify a computation that requires large space, by communicating with a powerful but untrusted prover. This work initiates the study of zero-knowledge proofs for data streams. We define the notion of zero-knowledge in the streaming setting and construct zero-knowledge SIPs for the two main algorithmic building blocks in the streaming interactive proofs literature: the sumcheck and polynomial evaluation protocols. To the best of our knowledge all known streaming interactive proofs are based on either of these tools, and indeed, this allows us to obtain zero-knowledge SIPs for central streaming problems such as index, point and range queries, median, frequency moments, and inner product. Our protocols are efficient in terms of time and space, as well as communication: the verifier algorithm's space complexity is $\\mathrm{polylog}(n)$ and, after a non-interactive setup that uses a random string of near-linear length, the remaining parameters are $n^{o(1)}$. En route, we develop an algorithmic toolkit for designing zero-knowledge data stream protocols, consisting of an algebraic streaming commitment protocol and a temporal commitment protocol.Our analyses rely on delicate algebraic and information-theoretic arguments and reductions from average-case communication complexity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "2076323150",
                    "name": "M. Dall'Agnol"
                },
                {
                    "authorId": "1774258",
                    "name": "Tom Gur"
                },
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                }
            ]
        },
        {
            "paperId": "625752c9da4a436bb2a48541ab1e6a04d2d5c8de",
            "title": "Hierarchical Color Learning in Convolutional Neural Networks",
            "abstract": "Empirical evidence suggests that color categories emerge in a universal, recurrent, hierarchical pattern across different cultures. This pattern is referred to as the \"Color Hierarchy\". Over two experiments, the present study examines whether there is evidence for such hierarchical color category learning patterns in Convolutional Neural Networks (CNNs). Experiment A investigated whether color categories are learned randomly, or in a fixed, hierarchical fashion. Results show that colors higher up the Color Hierarchy (e.g. red) were generally learned before colors lower down the hierarchy (e.g. brown, orange, gray). Experiment B examined whether object color affects recall in object detection. Similar to Experiment A, results found that object recall was noticeably impacted by color, with colors higher up the Color Hierarchy generally showing better recall. Additionally, objects whose color can be described by adjectives that emphasise colorfulness (e.g. Vivid, Brilliant, Deep) show better recall than those which de-emphasise colorfulness (e.g. Dark, Pale, Light). These results highlight similarities between humans and CNNs in color perception, and provide insight into factors that influence object detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                },
                {
                    "authorId": "1692756",
                    "name": "Byoung-Tak Zhang"
                }
            ]
        },
        {
            "paperId": "3e1f854ff3777710ebd0a175129cd6e7de68154d",
            "title": "Problem Difficulty in Arithmetic Cognition: Humans and Connectionist Models",
            "abstract": "In mathematical cognition, problem difficulty is a central variable. In the present study, problem difficulty was operationalized through five arithmetic operators --- addition, subtraction, multiplication, division, and modulo --- and through the number of carries required to correctly solve a problem. The present study collected data from human participants solving arithmetic problems, and from multilayer perceptrons (MLPs) that learn arithmetic problems. Binary numeral problems were chosen in order to minimize other criteria that may affect problem difficulty, such as problem familiarity and the problem size effect. In both humans and MLPs, problem difficulty was highest for multiplication, followed by modulo and then subtraction. The human study found that problem difficulty was monotonically increasing with respect to the number of carries, across all five operators. Furthermore, a strict increase was also observed for addition in the MLP study.",
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "authors": [
                {
                    "authorId": "2149158133",
                    "name": "Sungjae Cho"
                },
                {
                    "authorId": "70262116",
                    "name": "Jaeseo Lim"
                },
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                },
                {
                    "authorId": "1692756",
                    "name": "Byoung-Tak Zhang"
                }
            ]
        },
        {
            "paperId": "49dc5d31a450000ec3c023d30ef66bb8822c8629",
            "title": "Simulating Problem Difficulty in Arithmetic Cognition Through Dynamic Connectionist Models",
            "abstract": "The present study aims to investigate similarities between how humans and connectionist models experience difficulty in arithmetic problems. Problem difficulty was operationalized by the number of carries involved in solving a given problem. Problem difficulty was measured in humans by response time, and in models by computational steps. The present study found that both humans and connectionist models experience difficulty similarly when solving binary addition and subtraction. Specifically, both agents found difficulty to be strictly increasing with respect to the number of carries. Another notable similarity is that problem difficulty increases more steeply in subtraction than in addition, for both humans and connectionist models. Further investigation on two model hyperparameters --- confidence threshold and hidden dimension --- shows higher confidence thresholds cause the model to take more computational steps to arrive at the correct answer. Likewise, larger hidden dimensions cause the model to take more computational steps to correctly answer arithmetic problems; however, this effect by hidden dimensions is negligible.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2149158133",
                    "name": "Sungjae Cho"
                },
                {
                    "authorId": "70262116",
                    "name": "Jaeseo Lim"
                },
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                },
                {
                    "authorId": null,
                    "name": "Jung Ae Park"
                },
                {
                    "authorId": "1692756",
                    "name": "Byoung-Tak Zhang"
                }
            ]
        },
        {
            "paperId": "bc7242f8d658b98f24c263095b8511ed84d2a172",
            "title": "Efficient Interactive Proofs for Linear Algebra",
            "abstract": "8 Motivated by the growth in outsourced data analysis, we describe methods for verifying basic linear 9 algebra operations performed by a cloud service without having to recalculate the entire result. 10 We provide novel protocols in the streaming setting for inner product, matrix multiplication and 11 vector-matrix-vector multiplication where the number of rounds of interaction can be adjusted to 12 tradeoff space, communication, and duration of the protocol. Previous work suggests that the costs 13 of these interactive protocols are optimized by choosing O(logn) rounds. However, we argue that 14 we can reduce the number of rounds without incurring a significant time penalty by considering the 15 total end-to-end time, so fewer rounds and larger messages are preferable. We confirm this claim 16 with an experimental study that shows that a constant number of rounds gives the fastest protocol. 17 2012 ACM Subject Classification Theory of Computation \u2192 Models of Computation 18",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                }
            ]
        },
        {
            "paperId": "2f0c8abf7c1ff0017de6005761b95f5ec34c8ad1",
            "title": "You Can Check Others' Work More Quickly Than Doing It Yourself",
            "abstract": "Much of computer science involves problems where it is considered to be easier to check that an answer is correct than to find a correct answer (the complexity class NP). In this talk, we outline results that apply this notion to checking outsourced computations for data analytics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                },
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                }
            ]
        },
        {
            "paperId": "ca2bc58040b3d291145d7b39354f46a26cbddc21",
            "title": "Cheap Checking for Cloud Computing: Statistical Analysis via Annotated Data Streams",
            "abstract": "As the popularity of outsourced computation increases, questions of accuracy and trust between the client and the cloud computing services become ever more relevant. Our work aims to provide fast and practical methods to verify analysis of large data sets, where the client\u2019s computation and memory costs are kept to a minimum. Our verification protocols are based on defining \u201cproofs\u201d which are easy to create and check. These add only a small overhead to reporting the result of the computation itself. We build up a series of protocols for elementary statistical methods, to create more complex protocols for Ordinary Least Squares, Principal Component Analysis and Linear Discriminant Analysis, and show them to be very efficient in practice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143756994",
                    "name": "Chris Hickey"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                }
            ]
        }
    ]
}