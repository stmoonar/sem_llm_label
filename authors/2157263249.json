{
    "authorId": "2157263249",
    "papers": [
        {
            "paperId": "47bd285cca2c6491391f49af4d979cb513a028ac",
            "title": "Decoupling the Class Label and the Target Concept in Machine Unlearning",
            "abstract": "Machine unlearning as an emerging research topic for data regulations, aims to adjust a trained model to approximate a retrained one that excludes a portion of training data. Previous studies showed that class-wise unlearning is successful in forgetting the knowledge of a target class, through gradient ascent on the forgetting data or fine-tuning with the remaining data. However, while these methods are useful, they are insufficient as the class label and the target concept are often considered to coincide. In this work, we decouple them by considering the label domain mismatch and investigate three problems beyond the conventional all matched forgetting, e.g., target mismatch, model mismatch, and data mismatch forgetting. We systematically analyze the new challenges in restrictively forgetting the target concept and also reveal crucial forgetting dynamics in the representation level to realize these tasks. Based on that, we propose a general framework, namely, TARget-aware Forgetting (TARF). It enables the additional tasks to actively forget the target concept while maintaining the rest part, by simultaneously conducting annealed gradient ascent on the forgetting data and selected gradient descent on the hard-to-affect remaining data. Empirically, various experiments under the newly introduced settings are conducted to demonstrate the effectiveness of our TARF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143475848",
                    "name": "Jianing Zhu"
                },
                {
                    "authorId": "2301791087",
                    "name": "Bo Han"
                },
                {
                    "authorId": "2110069725",
                    "name": "Jiangchao Yao"
                },
                {
                    "authorId": "2157263249",
                    "name": "Jianliang Xu"
                },
                {
                    "authorId": "47537639",
                    "name": "Gang Niu"
                },
                {
                    "authorId": "67154907",
                    "name": "Masashi Sugiyama"
                }
            ]
        },
        {
            "paperId": "25ffa7c814856551843025632f092239152aa43e",
            "title": "Combating Exacerbated Heterogeneity for Robust Models in Federated Learning",
            "abstract": "Privacy and security concerns in real-world applications have led to the development of adversarially robust federated models. However, the straightforward combination between adversarial training and federated learning in one framework can lead to the undesired robustness deterioration. We discover that the attribution behind this phenomenon is that the generated adversarial data could exacerbate the data heterogeneity among local clients, making the wrapped federated learning perform poorly. To deal with this problem, we propose a novel framework called Slack Federated Adversarial Training (SFAT), assigning the client-wise slack during aggregation to combat the intensified heterogeneity. Theoretically, we analyze the convergence of the proposed method to properly relax the objective when combining federated learning and adversarial training. Experimentally, we verify the rationality and effectiveness of SFAT on various benchmarked and real-world datasets with different adversarial training and federated optimization methods. The code is publicly available at https://github.com/ZFancy/SFAT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143475848",
                    "name": "Jianing Zhu"
                },
                {
                    "authorId": "2110069725",
                    "name": "Jiangchao Yao"
                },
                {
                    "authorId": "121698214",
                    "name": "Tongliang Liu"
                },
                {
                    "authorId": "3259992",
                    "name": "Quanming Yao"
                },
                {
                    "authorId": "2157263249",
                    "name": "Jianliang Xu"
                },
                {
                    "authorId": "2087238859",
                    "name": "Bo Han"
                }
            ]
        },
        {
            "paperId": "3d8bbb4869ab69f2735d08f8f339aa4d554d4295",
            "title": "From Large Language Models to Databases and Back: A Discussion on Research and Education",
            "abstract": "In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1699192",
                    "name": "A. Bonifati"
                },
                {
                    "authorId": "2146071014",
                    "name": "Lei Chen"
                },
                {
                    "authorId": "2217441359",
                    "name": "Guoliang Li"
                },
                {
                    "authorId": "144232630",
                    "name": "Kyuseok Shim"
                },
                {
                    "authorId": "2157263249",
                    "name": "Jianliang Xu"
                },
                {
                    "authorId": "2204051805",
                    "name": "Xiaochun Yang"
                }
            ]
        },
        {
            "paperId": "8505cb57677d296351a1b86d15c843410778daca",
            "title": "Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability",
            "abstract": "Out-of-distribution (OOD) detection is an indispensable aspect of secure AI when deploying machine learning models in real-world applications. Previous paradigms either explore better scoring functions or utilize the knowledge of outliers to equip the models with the ability of OOD detection. However, few of them pay attention to the intrinsic OOD detection capability of the given model. In this work, we generally discover the existence of an intermediate stage of a model trained on in-distribution (ID) data having higher OOD detection performance than that of its final stage across different settings, and further identify one critical data-level attribution to be learning with the atypical samples. Based on such insights, we propose a novel method, Unleashing Mask, which aims to restore the OOD discriminative capabilities of the well-trained model with ID data. Our method utilizes a mask to figure out the memorized atypical samples, and then finetune the model or prune it with the introduced mask to forget them. Extensive experiments and analysis demonstrate the effectiveness of our method. The code is available at: https://github.com/tmlr-group/Unleashing-Mask.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143475848",
                    "name": "Jianing Zhu"
                },
                {
                    "authorId": "2219270734",
                    "name": "Hengzhuang Li"
                },
                {
                    "authorId": "2110069725",
                    "name": "Jiangchao Yao"
                },
                {
                    "authorId": "121698214",
                    "name": "Tongliang Liu"
                },
                {
                    "authorId": "2157263249",
                    "name": "Jianliang Xu"
                },
                {
                    "authorId": "2087238859",
                    "name": "Bo Han"
                }
            ]
        },
        {
            "paperId": "54dcb57ef0b554466d8183bd181e948e297520c3",
            "title": "MooFuzz: Many-Objective Optimization Seed Schedule for Fuzzer",
            "abstract": "Coverage-based Greybox Fuzzing (CGF) is a practical and effective solution for finding bugs and vulnerabilities in software. A key challenge of CGF is how to select conducive seeds and allocate accurate energy. To address this problem, we propose a novel many-objective optimization solution, MooFuzz, which can identify different states of the seed pool and continuously gather different information about seeds to guide seed schedule and energy allocation. First, MooFuzz conducts risk marking in dangerous positions of the source code. Second, it can automatically update the collected information, including the path risk, the path frequency, and the mutation information. Next, MooFuzz classifies seed pool into three states and adopts different objectives to select seeds. Finally, we design an energy recovery mechanism to monitor energy usage in the fuzzing process and reduce energy consumption. We implement our fuzzing framework and evaluate it on seven real-world programs. The experimental results show that MooFuzz outperforms other state-of-the-art fuzzers, including AFL, AFLFast, FairFuzz, and PerfFuzz, in terms of path discovery and bug detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144312460",
                    "name": "Xiaoqi Zhao"
                },
                {
                    "authorId": "47938824",
                    "name": "H. Qu"
                },
                {
                    "authorId": "51380871",
                    "name": "Wenjie Lv"
                },
                {
                    "authorId": "40804183",
                    "name": "S. Li"
                },
                {
                    "authorId": "2157263249",
                    "name": "Jianliang Xu"
                }
            ]
        }
    ]
}