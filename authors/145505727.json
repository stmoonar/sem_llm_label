{
    "authorId": "145505727",
    "papers": [
        {
            "paperId": "b3b3f3656d44dd3852387f8a865ace935bceefb6",
            "title": "Recall-Augmented Ranking: Enhancing Click-Through Rate Prediction Accuracy with Cross-Stage Data",
            "abstract": "Click-through rate (CTR) prediction plays an indispensable role in online recommendation and advertising platforms. Numerous deep learning based models have been proposed to improve CTR prediction accuracy, and they typically leverage user behavior sequences to capture users' shifting preferences. However, these historical sequences of user interactions often suffer from severe homogeneity and scarcity compared to the extensive item pool. Relying solely on such sequences for user representations is inherently restrictive, as user interests extend beyond the scope of items they have previously engaged with. To address this challenge, we propose a data-driven approach to enrich user representations.We recognize user profiling and recall items as two ideal data sources within the cross-stage framework, encompassing the u2u (user-to-user) and i2i (item-to-item) aspects, respectively, because of their higher relevance to target users and ranking items, as well as their greater diversity. In this paper, we propose a novel architecture named Recall-Augmented Ranking (RAR).RAR consists of two key sub-modules, namely the Cross-Stage User and Item Selection Module and the Co-Interaction Module. These sub-modules synergistically gather information from a vast pool of look-alike users and recall items, resulting in enriched user representations. Notably, RAR is orthogonal to many existing CTR models, allowing for seamless integration and consistent performance improvements in a plug-and-play manner. Extensive experiments are conducted on CTR prediction benchmarks, which verify the efficacy and compatibility of RAR against state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "24140498",
                    "name": "Guohao Cai"
                },
                {
                    "authorId": "2240695630",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2237958078",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "0d5b4e9fee9f209cca96d31bad752a064ce01f95",
            "title": "ReLoop2: Building Self-Adaptive Recommendation Models via Responsive Error Compensation Loop",
            "abstract": "Industrial recommender systems face the challenge of operating in non-stationary environments, where data distribution shifts arise from evolving user behaviors over time. To tackle this challenge, a common approach is to periodically re-train or incrementally update deployed deep models with newly observed data, resulting in a continual learning process. However, the conventional learning paradigm of neural networks relies on iterative gradient-based updates with a small learning rate, making it slow for large recommendation models to adapt. In this paper, we introduce ReLoop2, a self-correcting learning loop that facilitates fast model adaptation in online recommender systems through responsive error compensation. Inspired by the slow-fast complementary learning system observed in human brains, we propose an error memory module that directly stores error samples from incoming data streams. These stored samples are subsequently leveraged to compensate for model prediction errors during testing, particularly under distribution shifts. The error memory module is designed with fast access capabilities and undergoes continual refreshing with newly observed data samples during the model serving phase to support fast model adaptation. We evaluate the effectiveness of ReLoop2 on three open benchmark datasets as well as a real-world production dataset. The results demonstrate the potential of ReLoop2 in enhancing the responsiveness and adaptiveness of recommender systems operating in non-stationary environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "24140498",
                    "name": "Guohao Cai"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                }
            ]
        },
        {
            "paperId": "33ad70aed45fc0439363038853c6880bd4a37174",
            "title": "MSQA: An Unsupervised Domain-Adapted Question Answering Method Based on Multiple Source Domains",
            "abstract": "In recent years, with the development of knowledge bases and crowdsourcing,researchers have successfully proposed several high-quality, large-scaledatasets. The rise of pre-trained language models has extensively promoted theprogress of machine reading comprehension tasks. Even so, the need for large-scaletraining data is one of the critical challenges in this field. Existingmethods: one is to improve the transferability of downstream tasks byoptimizing and improving pre-trained language models; the other is to usemultiple existing datasets to build a more extensive dataset or generatesynthetic data. However, the effect is not ideal and lacks specific logicalgeneralization abilities. In this paper, we propose a new domain adaptationframework based on BERT, called Multi-Source Domain Adaptive QA (MSQA), whichutilizes multiple existing large datasets and uses adversarial domaintechniques to narrow the distribution of multiple sources and target domains,thereby improving performance on target domain datasets. Extensive experimentson multiple widely used English datasets demonstrate that our method exhibitssuperior adaptive performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2068929703",
                    "name": "Tao Peng"
                },
                {
                    "authorId": "2220376648",
                    "name": "Xincheng Zhang"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "1390977737",
                    "name": "Junping Liu"
                },
                {
                    "authorId": "2110048745",
                    "name": "Xinrong Hu"
                },
                {
                    "authorId": "96606895",
                    "name": "R. He"
                }
            ]
        },
        {
            "paperId": "4bc275b87cf16c5603a988b2de851b9fa3839aa4",
            "title": "Log-based Anomaly Detection based on EVT Theory with feedback",
            "abstract": "System logs play a critical role in maintaining the reliability of software systems. Fruitful studies have explored automatic log-based anomaly detection and achieved notable accuracy on benchmark datasets. However, when applied to large-scale cloud systems, these solutions face limitations due to high resource consumption and lack of adaptability to evolving logs. In this paper, we present an accurate, lightweight, and adaptive log-based anomaly detection framework, referred to as SeaLog. Our method introduces a Trie-based Detection Agent (TDA) that employs a lightweight, dynamically-growing trie structure for real-time anomaly detection. To enhance TDA's accuracy in response to evolving log data, we enable it to receive feedback from experts. Interestingly, our findings suggest that contemporary large language models, such as ChatGPT, can provide feedback with a level of consistency comparable to human experts, which can potentially reduce manual verification efforts. We extensively evaluate SeaLog on two public datasets and an industrial dataset. The results show that SeaLog outperforms all baseline methods in terms of effectiveness, runs 2X to 10X faster and only consumes 5% to 41% of the memory resource.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108510525",
                    "name": "Jinyang Liu"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "2036553451",
                    "name": "Yintong Huo"
                },
                {
                    "authorId": "47653892",
                    "name": "Zhihan Jiang"
                },
                {
                    "authorId": "2216587231",
                    "name": "Jia-Yuan Gu"
                },
                {
                    "authorId": "9220842",
                    "name": "Zhuangbin Chen"
                },
                {
                    "authorId": "2219751380",
                    "name": "Cong Feng"
                },
                {
                    "authorId": "2955814",
                    "name": "Minzhi Yan"
                },
                {
                    "authorId": "2217490665",
                    "name": "Michael R. Lyu"
                }
            ]
        },
        {
            "paperId": "7f4245744bfdb59019f91f98e0918b7017330094",
            "title": "HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text Classification",
            "abstract": "Hierarchical text classification (HTC) is a challenging subtask of multi-label classification as the labels form a complex hierarchical structure. Existing dual-encoder methods in HTC achieve weak performance gains with huge memory overheads and their structure encoders heavily rely on domain knowledge. Under such observation, we tend to investigate the feasibility of a memory-friendly model with strong generalization capability that could boost the performance of HTC without prior statistics or label semantics. In this paper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance the text representations with only syntactic information of the label hierarchy. Specifically, we convert the label hierarchy into an unweighted tree structure, termed coding tree, with the guidance of structural entropy. Then we design a structure encoder to incorporate hierarchy-aware information in the coding tree into text representations. Besides the text encoder, HiTIN only contains a few multi-layer perceptions and linear transformations, which greatly saves memory. We conduct experiments on three commonly used datasets and the results demonstrate that HiTIN could achieve better test performance and less memory consumption than state-of-the-art (SOTA) methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117693954",
                    "name": "He Zhu"
                },
                {
                    "authorId": "2144015636",
                    "name": "Chong Zhang"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "113210882",
                    "name": "Junran Wu"
                },
                {
                    "authorId": "2117101322",
                    "name": "Ke Xu"
                }
            ]
        },
        {
            "paperId": "b50309efcbb5fddd54ee4ab22dfb32c30e7693fc",
            "title": "Prism: Revealing Hidden Functional Clusters from Massive Instances in Cloud Systems",
            "abstract": "Ensuring the reliability of cloud systems is critical for both cloud vendors and customers. Cloud systems often rely on virtualization techniques to create instances of hardware resources, such as virtual machines. However, virtualization hinders the observability of cloud systems, making it challenging to diagnose platform-level issues. To improve system observability, we propose to infer functional clusters of instances, i.e., groups of instances having similar functionalities. We first conduct a pilot study on a large-scale cloud system, i.e., Huawei Cloud, demonstrating that instances having similar functionalities share similar communication and resource usage patterns. Motivated by these findings, we formulate the identification of functional clusters as a clustering problem and propose a non-intrusive solution called Prism. Prism adopts a coarse-to-fine clustering strategy. It first partitions instances into coarse-grained chunks based on communication patterns. Within each chunk, Prism further groups instances with similar resource usage patterns to produce fine-grained functional clusters. Such a design reduces noises in the data and allows Prism to process massive instances efficiently. We evaluate Prism on two datasets collected from the real-world production environment of Huawei Cloud. Our experiments show that Prism achieves a v-measure of \u223c0.95, surpassing existing state-of-the-art solutions. Additionally, we illustrate the integration of Prism within monitoring systems for enhanced cloud reliability through two real-world use cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108510525",
                    "name": "Jinyang Liu"
                },
                {
                    "authorId": "47653892",
                    "name": "Zhihan Jiang"
                },
                {
                    "authorId": "3452998",
                    "name": "Jiazhen Gu"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "9220842",
                    "name": "Zhuangbin Chen"
                },
                {
                    "authorId": "2219751380",
                    "name": "Cong Feng"
                },
                {
                    "authorId": "10686906",
                    "name": "Zengyin Yang"
                },
                {
                    "authorId": "2143041965",
                    "name": "Yongqiang Yang"
                },
                {
                    "authorId": "2217490665",
                    "name": "Michael R. Lyu"
                }
            ]
        },
        {
            "paperId": "dcf84c82d922f056ef9765ae667205b3b7c50725",
            "title": "A Large-Scale Evaluation for Log Parsing Techniques: How Far Are We?",
            "abstract": "Log data have facilitated various tasks of software development and maintenance, such as testing, debugging and diagnosing. Due to the unstructured nature of logs, log parsing is typically required to transform log messages into structured data for automated log analysis. Given the abundance of log parsers that employ various techniques, evaluating these tools to comprehend their characteristics and performance becomes imperative. Loghub serves as a commonly used dataset for benchmarking log parsers, but it suffers from limited scale and representativeness, posing significant challenges for studies to comprehensively evaluate existing log parsers or develop new methods. This limitation is particularly pronounced when assessing these log parsers for production use. To address these limitations, we provide a new collection of annotated log datasets, denoted Loghub-2.0, which can better reflect the characteristics of log data in real-world software systems. Loghub-2.0 comprises 14 datasets with an average of 3.6 million log lines in each dataset. Based on Loghub-2.0, we conduct a thorough re-evaluation of 15 state-of-the-art log parsers in a more rigorous and practical setting. Particularly, we introduce a new evaluation metric to mitigate the sensitivity of existing metrics to imbalanced data distributions. We are also the first to investigate the granular performance of log parsers on logs that represent rare system events, offering in-depth details for software diagnosis. Accurately parsing such logs is essential, yet it remains a challenge. We believe this work could shed light on the evaluation and design of log parsers in practical settings, thereby facilitating their deployment in production systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143104391",
                    "name": "Zhihan Jiang"
                },
                {
                    "authorId": "2108510525",
                    "name": "Jinyang Liu"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": null,
                    "name": "Yichen Li"
                },
                {
                    "authorId": "2036553451",
                    "name": "Yintong Huo"
                },
                {
                    "authorId": "2216587231",
                    "name": "Jia-Yuan Gu"
                },
                {
                    "authorId": "9220842",
                    "name": "Zhuangbin Chen"
                },
                {
                    "authorId": "2108997533",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2217490665",
                    "name": "Michael R. Lyu"
                }
            ]
        },
        {
            "paperId": "6f8ffdf8493323baadb2eb4b8c70f2d7084474f8",
            "title": "Mixed-modality Representation Learning and Pre-training for Joint Table-and-Text Retrieval in OpenQA",
            "abstract": "Retrieving evidences from tabular and textual resources is essential for open-domain question answering (OpenQA), which provides more comprehensive information. However, training an effective dense table-text retriever is difficult due to the challenges of table-text discrepancy and data sparsity problem. To address the above challenges, we introduce an optimized OpenQA Table-Text Retriever (OTTeR) to jointly retrieve tabular and textual evidences. Firstly, we propose to enhance mixed-modality representation learning via two mechanisms: modality-enhanced representation and mixed-modality negative sampling strategy. Secondly, to alleviate data sparsity problem and enhance the general retrieval ability, we conduct retrieval-centric mixed-modality synthetic pre-training. Experimental results demonstrate that OTTeR substantially improves the performance of table-and-text retrieval on the OTT-QA dataset. Comprehensive analyses examine the effectiveness of all the proposed mechanisms. Besides, equipped with OTTeR, our OpenQA system achieves the state-of-the-art result on the downstream QA task, with 10.1% absolute improvement in terms of the exact match over the previous best system. All the code and data are available at https://github.com/Jun-jie-Huang/OTTeR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "81970097",
                    "name": "Wanjun Zhong"
                },
                {
                    "authorId": "2145484051",
                    "name": "Qianchu Liu"
                },
                {
                    "authorId": "50175330",
                    "name": "Ming Gong"
                },
                {
                    "authorId": "71790825",
                    "name": "Daxin Jiang"
                },
                {
                    "authorId": "46429989",
                    "name": "Nan Duan"
                }
            ]
        },
        {
            "paperId": "8aa23a86603f7dd4eceda3d2e0337ba90dff7f4f",
            "title": "CodeExp: Explanatory Code Document Generation",
            "abstract": "Developing models that can automatically generate detailed code explanation can greatly benefit software maintenance and programming education. However, existing code-to-text generation models often produce only high-level summaries of code that do not capture implementation-level choices essential for these scenarios. To fill in this gap, we propose the code explanation generation task. We first conducted a human study to identify the criteria for high-quality explanatory docstring for code. Based on that, we collected and refined a large-scale code docstring corpus and formulated automatic evaluation metrics that best match human assessments. Finally, we present a multi-stage fine-tuning strategy and baseline models for the task. Our experiments show that (1) our refined training dataset lets models achieve better performance in the explanation generation tasks compared to larger unrefined data (15x larger), and (2) fine-tuned models can generate well-structured long docstrings comparable to human-written ones. We envision our training dataset, human-evaluation protocol, recommended metrics, and fine-tuning strategy can boost future code explanation research. The code and annotated data are available at https://github.com/subercui/CodeExp.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "14726743",
                    "name": "Haotian Cui"
                },
                {
                    "authorId": "2144523164",
                    "name": "Chenglong Wang"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "1827015",
                    "name": "J. Inala"
                },
                {
                    "authorId": "1731438",
                    "name": "Todd Mytkowicz"
                },
                {
                    "authorId": "2156959212",
                    "name": "Bolong Wang"
                },
                {
                    "authorId": "2149258793",
                    "name": "Jian Gao"
                },
                {
                    "authorId": "46429989",
                    "name": "Nan Duan"
                }
            ]
        },
        {
            "paperId": "c7cf2ed6b9ca5aff7d2db7769b6cafaf22ef6ad3",
            "title": "Reasoning over Hybrid Chain for Table-and-Text Open Domain Question Answering",
            "abstract": "Tabular and textual question answering requires systems to perform reasoning over heterogeneous information, considering table structure, and the connections among table and text. In this paper, we propose a ChAin-centric Reasoning and Pre-training framework (CARP). CARP utilizes hybrid chain to model the explicit intermediate reasoning process across table and text for question answering. We also propose a novel chain-centric pre-training method, to enhance the pre-trained model in identifying the cross-modality reasoning process and alleviating the data sparsity problem. This method constructs the large-scale reasoning corpus by synthesizing pseudo heterogeneous reasoning paths from Wikipedia and generating corresponding questions. We evaluate our system on OTT-QA, a large-scale table-and-text open-domain question answering benchmark, and our system achieves the state-of-the-art performance. Further analyses illustrate that the explicit hybrid chain offers substantial performance improvement and interpretablity of the intermediate reasoning process, and the chain-centric pre-training boosts the performance on the chain extraction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "81970097",
                    "name": "Wanjun Zhong"
                },
                {
                    "authorId": "145505727",
                    "name": "Junjie Huang"
                },
                {
                    "authorId": "1409707585",
                    "name": "Qian Liu"
                },
                {
                    "authorId": "92660691",
                    "name": "Ming Zhou"
                },
                {
                    "authorId": "2815388",
                    "name": "Jiahai Wang"
                },
                {
                    "authorId": "2152938031",
                    "name": "Jian Yin"
                },
                {
                    "authorId": "46429989",
                    "name": "Nan Duan"
                }
            ]
        }
    ]
}