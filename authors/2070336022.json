{
    "authorId": "2070336022",
    "papers": [
        {
            "paperId": "b9be82f021feb35c8dc66fdf5e94a6193218ba78",
            "title": "FIRE: A Dataset for Financial Relation Extraction",
            "abstract": "This paper introduces FIRE ( FI nancial 001 R elation E xtraction), a sentence-level dataset 002 of named entities and relations within the 003 financial sector. Comprising 3,025 instances, 004 the dataset encapsulates 13 named entity types 005 along with 18 relation types. The textual data 006 was collected from public financial reports and 007 financial news articles, effectively capturing 008 a wide array of financial information about a 009 business including, but not limited to, corporate 010 structure, business model, revenue streams, 011 and market activities such as acquisitions. 012 The full dataset was labeled by a single 013 annotator to minimize labeling noise. Detailed 014 annotation guidelines are provided, as well as 015 an open-source, web-based text labeling tool 016 aimed at streamlining annotation. The labeling 017 time for each sentence was recorded during the 018 labeling process. We show how this feature, 019 along with curriculum learning techniques, can 020 be used to improved a model\u2019s performance. 021 The FIRE dataset is designed to serve as a 022 valuable resource for training and evaluating 023 machine learning algorithms in the domain of 024 financial information extraction, as well as a 025 resource for financial analysts to automatically 026 and efficiently extract critical information 027 from financial documents. The dataset and 028 the code to reproduce our experimental 029 results are available at https://github. 030 com/blinded_for_review . The repository 031 for the labeling tool can be found at https: 032 //github.com",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2313550078",
                    "name": "Hassan Hamad"
                },
                {
                    "authorId": "2070336022",
                    "name": "A. Thakur"
                },
                {
                    "authorId": "2313548692",
                    "name": "Nijil Kolleri"
                },
                {
                    "authorId": "2313550237",
                    "name": "Sujith Pulikodan"
                },
                {
                    "authorId": "2313548649",
                    "name": "Keith Chugg"
                }
            ]
        },
        {
            "paperId": "160762eaab73ef24bc15668e13fcf836735fe45e",
            "title": "Explainable Classification of Internet Memes",
            "abstract": "Nowadays, the integrity of online conversations is faced with a variety of threats, ranging from hateful content to manufactured media. In such a context, Internet Memes make the scalable automation of moderation interventions increasingly more challenging, given their inherently complex and multimodal nature. Existing work on Internet Meme classification has focused on black-box methods that do not explicitly consider the semantics of the memes or the context of their creation. This paper proposes a modular and explainable architecture for Internet Meme classification and understanding. We design and implement multimodal classification methods that perform exampleand prototype-based reasoning over training cases, while leveraging both textual and visual SOTA models to represent the individual cases. We study the relevance of our modular and explainable models in detecting harmful memes on two existing tasks: Hate Speech Detection and Misogyny Classification. We compare the performance between exampleand prototype-based methods, and between text, vision, and multimodal models, across different categories of harmfulness (e.g., stereotype and objectification). We devise a user-friendly interface that facilitates the comparative analysis of examples retrieved by all of our models for any given meme, informing the community about the strengths and limitations of these explainable methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070336022",
                    "name": "A. Thakur"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2282974137",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        },
        {
            "paperId": "de7dbffe5622ada1b83e80a4fbae34375771d4f9",
            "title": "Multimodal and Explainable Internet Meme Classification",
            "abstract": "In the current context where online platforms have been effectively weaponized in a variety of geo-political events and social issues, Internet memes make fair content moderation at scale even more difficult. Existing work on meme classification and tracking has focused on black-box methods that do not explicitly consider the semantics of the memes or the context of their creation. In this paper, we pursue a modular and explainable architecture for Internet meme understanding. We design and implement multimodal classification methods that perform example- and prototype-based reasoning over training cases, while leveraging both textual and visual SOTA models to represent the individual cases. We study the relevance of our modular and explainable models in detecting harmful memes on two existing tasks: Hate Speech Detection and Misogyny Classification. We compare the performance between example- and prototype-based methods, and between text, vision, and multimodal models, across different categories of harmfulness (e.g., stereotype and objectification). We devise a user-friendly interface that facilitates the comparative analysis of examples retrieved by all of our models for any given meme, informing the community about the strengths and limitations of these explainable methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070336022",
                    "name": "A. Thakur"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                },
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2282974137",
                    "name": "Luca Luceri"
                },
                {
                    "authorId": "2195355964",
                    "name": "Riccardo Tommasini"
                }
            ]
        },
        {
            "paperId": "f31c2746f018dee717da4d938843ac6f4f5a4ad1",
            "title": "Secure Video Steganography based on Discrete Wavelet Transform and Arnold Transform",
            "abstract": "nternet has made so easy to transfer the large amount of data in different parts of the world. So, the security and safety of information has become the major concern. This problem has led to the development of steganography techniques. This paper deals with data hiding technique in which the secret data is embedded into the cover video. Firstly, cover video is decomposed into different frames. A single level Discrete Wavelet transform is applied on selected frame and on secret image. A private key is used during the process of encoding and decoding to provide high security. Then the Inverse Discrete Wavelet Transformation (IDWT) is applied to get the stego-video. The performance parameters like Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE) can be calculated to determine the quality of stego video. The results show that the proposed algorithm for steganography is highly secured with good perceptual invisibility. A methodology based on Least Significant Bit (LSB) was introduced (5) in which secret data is embedded into the LSB of the host video frame. The quality of the stego video can be measured by using performance parameters like Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE). A secure technique of video steganography was proposed (6). This method provides index to secret data and the index is then placed in a video frame. At the receiving end, inspite of searching the whole video, the secret data can be retrieved from stego video with the help of index. This will reduced the computational time as compare to other existing methods. An improved method of data hiding based on back propagation neural network method was proposed (7). In this method, neural network is used to perform XOR operation. Secret data is embedded into avi video format by using LSB substitution technique.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2070336022",
                    "name": "A. Thakur"
                },
                {
                    "authorId": "49064761",
                    "name": "Harbinder Singh"
                },
                {
                    "authorId": "51441794",
                    "name": "Shikha Sharda"
                }
            ]
        }
    ]
}