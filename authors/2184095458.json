{
    "authorId": "2184095458",
    "papers": [
        {
            "paperId": "c259b05da12062cdb1e96cd3994b71a1b4841e89",
            "title": "Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift",
            "abstract": "The non-stationary nature of real-world Multivariate Time Series (MTS) data presents forecasting models with a formidable challenge of the time-variant distribution of time series, referred to as distribution shift. Existing studies on the distribution shift mostly adhere to adaptive normalization techniques for alleviating temporal mean and covariance shifts or time-variant modeling for capturing temporal shifts. Despite improving model generalization, these normalization-based methods often assume a time-invariant transition between outputs and inputs but disregard specific intra-/inter-series correlations, while time-variant models overlook the intrinsic causes of the distribution shift. This limits model expressiveness and interpretability of tackling the distribution shift for MTS forecasting. To mitigate such a dilemma, we present a unified Probabilistic Graphical Model to Jointly capturing intra-/inter-series correlations and modeling the time-variant transitional distribution, and instantiate a neural framework called JointPGM for non-stationary MTS forecasting. Specifically, JointPGM first employs multiple Fourier basis functions to learn dynamic time factors and designs two distinct learners: intra-series and inter-series learners. The intra-series learner effectively captures temporal dynamics by utilizing temporal gates, while the inter-series learner explicitly models spatial dynamics through multi-hop propagation, incorporating Gumbel-softmax sampling. These two types of series dynamics are subsequently fused into a latent variable, which is inversely employed to infer time factors, generate final prediction, and perform reconstruction. We validate the effectiveness and efficiency of JointPGM through extensive experiments on six highly non-stationary MTS datasets, achieving state-of-the-art forecasting performance of MTS forecasting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2265687729",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2265619390",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "2312111081",
                    "name": "Xiaojun Xue"
                },
                {
                    "authorId": "2266355264",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2274216292",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                }
            ]
        },
        {
            "paperId": "2399d1111999c67a711017d9c3a8314190adb15e",
            "title": "MTSNet: Deep Probabilistic Cross-multivariate Time Series Modeling with External Factors for COVID-19",
            "abstract": "Complex intelligent systems such as for tackling the COVID-19 pandemic involve multiple multivariate time series (MTSs), where both target variables (such as COVID-19 infected, confirmed, and recovered cases) and external factors (such as virus mutation and infectivity, vaccination, and government intervention influence) are coupled. Forecasting such MTSs with multiple external MTS factors needs to model both within and between MTS interactions and handle their uncertainty, heterogeneity, and dynamics. Existing shallow to deep MTS modelers, including regressors, deep recurrent neural networks such as DeepAR, deep state space models, and deep factor models, do not jointly characterize these issues in a probabilistic manner across MTSs. We propose an end-to-end deep probabilistic cross-MTS learning network MTSNet. MTSNet incorporates a tensor input with scaled target and external MTSs. It then vertically and horizontally stacks long-short memory networks for encoding and decoding target MTSs and enhances uncertainty modeling, generalization and forecasting robustness by residual connection, variational zoneout, and probabilistic forecasting. The tensor input is projected to a probability distribution for target MTS forecasting. MTSNet outperforms the SOTA deep probabilistic MTS networks in forecasting COVID-19 confirmed cases and ICU patient numbers for six countries by involving virus mutation, vaccination, government interventions, and infectivity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2226493785",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                }
            ]
        },
        {
            "paperId": "377bb27f5069dcd526f1c4bb1cab70fa471e3452",
            "title": "Modeling User Demand Evolution for Next-Basket Prediction",
            "abstract": "Users\u2019 purchase behaviors are complex and dynamic, which are usually driven by various personal demands evolving with time. According to psychology and economic theories, user demands can be satisfied with a sequence of purchase behaviors, resulting in a basket of items. However, most of the existing works simply predict the next basket from a shallow perspective of (purchase) sequence data modeling without deep insight into the underlying factors which drive user purchase behaviors. In fact, filling a basket with multiple items is a process to incrementally satisfy a user's demand. Therefore, the key challenges to predict a user's next basket lie in (1) how to track the changes of the user's demand, and (2) how to satisfy her demand at a given moment. To this end, we propose an Evolving DEmand SAtisfaction (EvoDESA) model to model a user's demand evolution for next-basket prediction. In EvoDESA, a demand evolution module learns the dynamics of user demand over a sequence of basket-purchase behaviors. Then, a next-basket planning module effectively packs an optimal combination of items to best satisfy the user's current demand. Extensive experiments on three real-world transaction datasets demonstrate the considerable superiority of EvoDESA over the state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2152541925",
                    "name": "Yan Wang"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "1485105824",
                    "name": "Xiuzhen Zhang"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "1713128",
                    "name": "Quan Z. Sheng"
                },
                {
                    "authorId": "145572420",
                    "name": "M. Orgun"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                }
            ]
        },
        {
            "paperId": "7c1a118083a6f78f0f6bae631489253a97cc9b66",
            "title": "Copula Variational LSTM for High-dimensional Cross-market Multivariate Dependence Modeling",
            "abstract": "We address a challenging problem-modeling high-dimensional, long-range dependencies between nonnormal multivariates, which is important for demanding applications such as cross-market modeling (CMM). With heterogeneous indicators and markets, CMM aims to capture between-market financial couplings and influence over time and within-market interactions between financial variables. We make the first attempt to integrate deep variational sequential learning with copula-based statistical dependence modeling and characterize both temporal dependence degrees and structures between hidden variables representing nonnormal multivariates. Our copula variational learning network weighted partial regular vine copula-based variational long short-term memory (WPVC-VLSTM) integrates variational long short-term memory (LSTM) networks and regular vine copula to model variational sequential dependence degrees and structures. The regular vine copula models nonnormal distributional dependence degrees and structures. VLSTM captures variational long-range dependencies coupling high-dimensional dynamic hidden variables without strong hypotheses and multivariate constraints. WPVC-VLSTM outperforms benchmarks, including linear models, stochastic volatility models, deep neural networks, and variational recurrent networks in terms of both technical significance and portfolio forecasting performance. WPVC-VLSTM shows a step-forward for CMM and deep variational learning.",
            "fieldsOfStudy": [
                "Medicine",
                "Economics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2135196826",
                    "name": "Jia Xu"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                }
            ]
        },
        {
            "paperId": "9297502c3b1eaa528e8a8fb85a83842d0577fdc6",
            "title": "Frequency-domain MLPs are More Effective Learners in Time Series Forecasting",
            "abstract": "Time series forecasting has played the key role in different industrial, including finance, traffic, energy, and healthcare domains. While existing literatures have designed many sophisticated architectures based on RNNs, GNNs, or Transformers, another kind of approaches based on multi-layer perceptrons (MLPs) are proposed with simple structure, low complexity, and {superior performance}. However, most MLP-based forecasting methods suffer from the point-wise mappings and information bottleneck, which largely hinders the forecasting performance. To overcome this problem, we explore a novel direction of applying MLPs in the frequency domain for time series forecasting. We investigate the learned patterns of frequency-domain MLPs and discover their two inherent characteristic benefiting forecasting, (i) global view: frequency spectrum makes MLPs own a complete view for signals and learn global dependencies more easily, and (ii) energy compaction: frequency-domain MLPs concentrate on smaller key part of frequency components with compact signal energy. Then, we propose FreTS, a simple yet effective architecture built upon Frequency-domain MLPs for Time Series forecasting. FreTS mainly involves two stages, (i) Domain Conversion, that transforms time-domain signals into complex numbers of frequency domain; (ii) Frequency Learning, that performs our redesigned MLPs for the learning of real and imaginary part of frequency components. The above stages operated on both inter-series and intra-series scales further contribute to channel-wise and time-wise dependency learning. Extensive experiments on 13 real-world benchmarks (including 7 benchmarks for short-term forecasting and 6 benchmarks for long-term forecasting) demonstrate our consistent superiority over state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265619390",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "2265687729",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2266387012",
                    "name": "Wei Fan"
                },
                {
                    "authorId": "2266355264",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2266377754",
                    "name": "Pengyang Wang"
                },
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2266241113",
                    "name": "Defu Lian"
                },
                {
                    "authorId": "2266238649",
                    "name": "Ning An"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                },
                {
                    "authorId": "2226485679",
                    "name": "Zhendong Niu"
                }
            ]
        },
        {
            "paperId": "9dbcb0893d05e6176353eee401afa4929b570cf6",
            "title": "FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective",
            "abstract": "Multivariate time series (MTS) forecasting has shown great importance in numerous industries. Current state-of-the-art graph neural network (GNN)-based forecasting methods usually require both graph networks (e.g., GCN) and temporal networks (e.g., LSTM) to capture inter-series (spatial) dynamics and intra-series (temporal) dependencies, respectively. However, the uncertain compatibility of the two networks puts an extra burden on handcrafted model designs. Moreover, the separate spatial and temporal modeling naturally violates the unified spatiotemporal inter-dependencies in real world, which largely hinders the forecasting performance. To overcome these problems, we explore an interesting direction of directly applying graph networks and rethink MTS forecasting from a pure graph perspective. We first define a novel data structure, hypervariate graph, which regards each series value (regardless of variates or timestamps) as a graph node, and represents sliding windows as space-time fully-connected graphs. This perspective considers spatiotemporal dynamics unitedly and reformulates classic MTS forecasting into the predictions on hypervariate graphs. Then, we propose a novel architecture Fourier Graph Neural Network (FourierGNN) by stacking our proposed Fourier Graph Operator (FGO) to perform matrix multiplications in Fourier space. FourierGNN accommodates adequate expressiveness and achieves much lower complexity, which can effectively and efficiently accomplish the forecasting. Besides, our theoretical analysis reveals FGO's equivalence to graph convolutions in the time domain, which further verifies the validity of FourierGNN. Extensive experiments on seven datasets have demonstrated our superior performance with higher efficiency and fewer parameters compared with state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265619390",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "2265687729",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2266387012",
                    "name": "Wei Fan"
                },
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2274216292",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2266377754",
                    "name": "Pengyang Wang"
                },
                {
                    "authorId": "2266238649",
                    "name": "Ning An"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                },
                {
                    "authorId": "2226485679",
                    "name": "Zhendong Niu"
                }
            ]
        },
        {
            "paperId": "d17771d1e83304b0072ebc7536b638c89efe0f95",
            "title": "Learning Informative Representation for Fairness-Aware Multivariate Time-Series Forecasting: A Group-Based Perspective",
            "abstract": "Multivariate time series (MTS) forecasting penetrates various aspects of our economy and society, whose roles become increasingly recognized. However, often MTS forecasting is unfair, not only degrading their practical benefits but even incurring potential risk. Unfair MTS forecasting may be attributed to disparities relating to advantaged and disadvantaged variables, which has rarely been studied in the MTS forecasting. In this work, we formulate the MTS fairness modeling problem as learning informative representations attending to both advantaged and disadvantaged variables. Accordingly, we propose a novel framework, named <italic>FairFor</italic>, for fairness-aware MTS forecasting, i.e., <italic>fair MTS forecasting</italic>. <italic>FairFor</italic> uses adversarial learning to generate both group-irrelevant and -relevant representations for downstream forecasting. <italic>FairFor</italic> first adopts recurrent graph convolution to capture spatio-temporal variable correlations and to group variables by leveraging a spectral relaxation of the K-means objective. Then, it utilizes a novel filtering <inline-formula><tex-math notation=\"LaTeX\">$ \\& $</tex-math><alternatives><mml:math><mml:mo>&</mml:mo></mml:math><inline-graphic xlink:href=\"zhang-ieq1-3323956.gif\"/></alternatives></inline-formula> fusion module to filter group-relevant information and generate group-irrelevant representations by orthogonality regularization. The group-irrelevant and -relevant representations form highly informative representations, facilitating to share the knowledge from advantaged variables to disadvantaged variables and guarantee the fairness of forecasting. Extensive experiments on four public datasets demonstrate the <italic>FairFor</italic> effectiveness for fair forecasting and significant performance improvement.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2060200167",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "8253080",
                    "name": "Zhendong Niu"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                }
            ]
        },
        {
            "paperId": "57ba68e866ce4eca123b9afd13d9b32acfed348e",
            "title": "Distributional Drift Adaptation with Temporal Conditional Variational Autoencoder for Multivariate Time Series Forecasting",
            "abstract": "Due to the nonstationary nature, the distribution of real-world multivariate time series (MTS) changes over time, which is known as distribution drift. Most existing MTS forecasting models greatly suffer from distribution drift and degrade the forecasting performance over time. Existing methods address distribution drift via adapting to the latest arrived data or self-correcting per the meta knowledge derived from future data. Despite their great success in MTS forecasting, these methods hardly capture the intrinsic distribution changes, especially from a distributional perspective. Accordingly, we propose a novel framework temporal conditional variational autoencoder (TCVAE) to model the dynamic distributional dependencies over time between historical observations and future data in MTSs and infer the dependencies as a temporal conditional distribution to leverage latent variables. Specifically, a novel temporal Hawkes attention (THA) mechanism represents temporal factors that subsequently fed into feedforward networks to estimate the prior Gaussian distribution of latent variables. The representation of temporal factors further dynamically adjusts the structures of Transformer-based encoder and decoder to distribution changes by leveraging a gated attention mechanism (GAM). Moreover, we introduce conditional continuous normalization flow (CCNF) to transform the prior Gaussian to a complex and form-free distribution to facilitate flexible inference of the temporal conditional distribution. Extensive experiments conducted on six real-world MTS datasets demonstrate the TCVAE's superior robustness and effectiveness over the state-of-the-art MTS forecasting baselines. We further illustrate the TCVAE applicability through multifaceted case studies and visualization in real-world scenarios.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "49346854",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2060200167",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "102590513",
                    "name": "Kaize Shi"
                },
                {
                    "authorId": "8253080",
                    "name": "Zhendong Niu"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                }
            ]
        },
        {
            "paperId": "ae29545c4edc6a0461848f6846759fd5b3a741af",
            "title": "Shallow and Deep Non-IID Learning on Complex Data",
            "abstract": "Non-IID (i.i.d.) data holds complex non-IIDness, e.g., couplings and interactions (non-independent) and heterogeneities (not IID drawn from a given distribution). Non-IID learning emerges as a major challenge to shallow and deep learning, including classic statistical learning, mathematical modeling, shallow machine learning, and deep neural learning. Here, we outline the problem, research map, main challenges and topics of shallow and deep non-IID learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                },
                {
                    "authorId": "144019071",
                    "name": "Philip S. Yu"
                },
                {
                    "authorId": "2146630691",
                    "name": "Zhilin Zhao"
                }
            ]
        }
    ]
}