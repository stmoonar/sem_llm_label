{
    "authorId": "2258802492",
    "papers": [
        {
            "paperId": "16e989b9094c3653972c82b10b7004b6f0b42927",
            "title": "Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation",
            "abstract": "Emotional Support Conversation (ESC) is a task aimed at alleviating individuals' emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover, we conduct a methodological study to offer insights into the necessary approaches for LLMs to serve as proficient emotional supporters. Our findings emphasize that (1) low preference for specific strategies hinders the progress of emotional support, (2) external assistance helps reduce preference bias, and (3) existing LLMs alone cannot become good emotional supporters. These insights suggest promising avenues for future research to enhance the emotional intelligence of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266420525",
                    "name": "Dongjin Kang"
                },
                {
                    "authorId": "2284823818",
                    "name": "Sunghwan Kim"
                },
                {
                    "authorId": "2258722263",
                    "name": "Taeyoon Kwon"
                },
                {
                    "authorId": "2266717741",
                    "name": "Seungjun Moon"
                },
                {
                    "authorId": "2284988495",
                    "name": "Hyunsouk Cho"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "378702db60e4e9761dcdb0b73f0b9a1549bbbb58",
            "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
            "abstract": "Recently, the demand for psychological counseling has significantly increased as more individuals express concerns about their mental health. This surge has accelerated efforts to improve the accessibility of counseling by using large language models (LLMs) as counselors. To ensure client privacy, training open-source LLMs faces a key challenge: the absence of realistic counseling datasets. To address this, we introduce Cactus, a multi-turn dialogue dataset that emulates real-life interactions using the goal-oriented and structured approach of Cognitive Behavioral Therapy (CBT). We create a diverse and realistic dataset by designing clients with varied, specific personas, and having counselors systematically apply CBT techniques in their interactions. To assess the quality of our data, we benchmark against established psychological criteria used to evaluate real counseling sessions, ensuring alignment with expert evaluations. Experimental results demonstrate that Camel, a model trained with Cactus, outperforms other models in counseling skills, highlighting its effectiveness and potential as a counseling agent. We make our data, model, and code publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2287822199",
                    "name": "Suyeon Lee"
                },
                {
                    "authorId": "2284823818",
                    "name": "Sunghwan Kim"
                },
                {
                    "authorId": "2261077753",
                    "name": "Minju Kim"
                },
                {
                    "authorId": "2266420525",
                    "name": "Dongjin Kang"
                },
                {
                    "authorId": "2309659264",
                    "name": "Dongil Yang"
                },
                {
                    "authorId": "2287875032",
                    "name": "Harim Kim"
                },
                {
                    "authorId": "2309787428",
                    "name": "Minseok Kang"
                },
                {
                    "authorId": "2309481707",
                    "name": "Dayi Jung"
                },
                {
                    "authorId": "2309504727",
                    "name": "Min Hee Kim"
                },
                {
                    "authorId": "2307987815",
                    "name": "Seungbeen Lee"
                },
                {
                    "authorId": "2287828497",
                    "name": "Kyoung-Mee Chung"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        },
        {
            "paperId": "5657d6f4fd14099623a48a042d21767f56908039",
            "title": "i-SRT: Aligning Large Multimodal Models for Videos by Iterative Self-Retrospective Judgment",
            "abstract": "Aligning Video Large Multimodal Models (VLMMs) face challenges such as modality misalignment and verbose responses. Although iterative approaches such as self-rewarding or iterative direct preference optimization (DPO) recently showed a significant improvement in language model alignment, particularly on reasoning tasks, self-aligned models applied to large video-language models often result in lengthy and irrelevant responses. To address these challenges, we propose a novel method that employs self-retrospection to enhance both response generation and preference modeling, and call iterative self-retrospective judgment (i-SRT). By revisiting and evaluating already generated content and preference in loop, i-SRT improves the alignment between textual and visual modalities, reduce verbosity, and enhances content relevance. Our empirical evaluations across diverse video question answering benchmarks demonstrate that i-SRT significantly outperforms prior arts. We are committed to opensourcing our code, models, and datasets to encourage further investigation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131876149",
                    "name": "Daechul Ahn"
                },
                {
                    "authorId": "2282961855",
                    "name": "Yura Choi"
                },
                {
                    "authorId": "2307030461",
                    "name": "San Kim"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2307578330",
                    "name": "Dongyeop Kang"
                },
                {
                    "authorId": "2283130535",
                    "name": "Jonghyun Choi"
                }
            ]
        },
        {
            "paperId": "6b9699058152912efedd9a6d724ec08e0c4c9319",
            "title": "Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset",
            "abstract": "Conversational recommender system is an emerging area that has garnered an increasing interest in the community, especially with the advancements in large language models (LLMs) that enable diverse reasoning over conversational input. Despite the progress, the field has many aspects left to explore. The currently available public datasets for conversational recommendation lack specific user preferences and explanations for recommendations, hindering high-quality recommendations. To address such challenges, we present a novel conversational recommendation dataset named PEARL, synthesized with persona- and knowledge-augmented LLM simulators. We obtain detailed persona and knowledge from real-world reviews and construct a large-scale dataset with over 57k dialogues. Our experimental results demonstrate that utterances in PEARL include more specific user preferences, show expertise in the target domain, and provide recommendations more relevant to the dialogue context than those in prior datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117956135",
                    "name": "Minjin Kim"
                },
                {
                    "authorId": "2110104000",
                    "name": "Minju Kim"
                },
                {
                    "authorId": "2281098420",
                    "name": "Hana Kim"
                },
                {
                    "authorId": "2151245501",
                    "name": "Beong-woo Kwak"
                },
                {
                    "authorId": "2290185769",
                    "name": "Soyeon Chun"
                },
                {
                    "authorId": "2290213007",
                    "name": "Hyunseo Kim"
                },
                {
                    "authorId": "71965979",
                    "name": "SeongKu Kang"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                },
                {
                    "authorId": "3067773",
                    "name": "Dongha Lee"
                }
            ]
        },
        {
            "paperId": "badaaee23c1ee33fa747165acb179662598ec6bd",
            "title": "Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback",
            "abstract": "Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). The previous approaches for VLMMs involved Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and adding additional learnable modules. Video and text multimodal alignment remains challenging, primarily due to the deficient volume and quality of multimodal instruction-tune data compared to text-only data. We present a novel alignment strategy that employs multimodal AI system to oversee itself called Reinforcement Learning from AI Feedback (RLAIF), providing self-preference feedback to refine itself and facilitating the alignment of video and text modalities. In specific, we propose context-aware reward modeling by providing detailed video descriptions as context during the generation of preference feedback in order to enrich the understanding of video content. Demonstrating enhanced performance across diverse video benchmarks, our multimodal RLAIF approach, VLM-RLAIF, outperforms existing approaches, including the SFT model. We commit to open-sourcing our code, models, and datasets to foster further research in this area.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2131876149",
                    "name": "Daechul Ahn"
                },
                {
                    "authorId": "2282961855",
                    "name": "Yura Choi"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "48493368",
                    "name": "Dongyeop Kang"
                },
                {
                    "authorId": "2283130535",
                    "name": "Jonghyun Choi"
                }
            ]
        },
        {
            "paperId": "13244fdc42a091f87bc08eaaac2bcfd5883e8d0c",
            "title": "Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents",
            "abstract": "Human-like chatbots necessitate the use of commonsense reasoning in order to effectively comprehend and respond to implicit information present within conversations. Achieving such coherence and informativeness in responses, however, is a non-trivial task. Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge. This complexity arises because such evidence is scattered across multiple turns in a conversation, thus necessitating integration over multiple hops. Hence, our focus is to facilitate such multi-hop reasoning over a dialogue context, namely dialogue chain-of-thought (CoT) reasoning. To this end, we propose a knowledge distillation framework that leverages LLMs as unreliable teachers and selectively distills consistent and helpful rationales via alignment filters. We further present DOCTOR, a DialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for response generation. We conduct extensive experiments to show that enhancing dialogue agents with high-quality rationales from DOCTOR significantly improves the quality of their responses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184029886",
                    "name": "Hyungjoo Chae"
                },
                {
                    "authorId": "2188768271",
                    "name": "Yongho Song"
                },
                {
                    "authorId": "2210267033",
                    "name": "Kai Tzu-iunn Ong"
                },
                {
                    "authorId": "2258722263",
                    "name": "Taeyoon Kwon"
                },
                {
                    "authorId": "2117956135",
                    "name": "Minjin Kim"
                },
                {
                    "authorId": "2258802492",
                    "name": "Youngjae Yu"
                },
                {
                    "authorId": "2258907627",
                    "name": "Dongha Lee"
                },
                {
                    "authorId": "48493368",
                    "name": "Dongyeop Kang"
                },
                {
                    "authorId": "2258712913",
                    "name": "Jinyoung Yeo"
                }
            ]
        }
    ]
}