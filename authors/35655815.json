{
    "authorId": "35655815",
    "papers": [
        {
            "paperId": "a96979e00c5f7ebf8acd8e9ad81837f8a409d9e5",
            "title": "The EMPWR Platform: Data and Knowledge-Driven Processes for the Knowledge Graph Lifecycle",
            "abstract": "The unparalleled volume of data generated has heightened the need for approaches that can consume these data in a scalable and automated fashion. Although modern data-driven, deep-learning-based systems are cost-efficient and can learn complex patterns, they are black boxes in nature, and the underlying input data highly dictate their world model. Knowledge graphs (KGs), as one such technology, have surfaced as a compelling approach for using structured knowledge representation to support the integration of knowledge from diverse sources and formats. We present Empower (EMPWR), a comprehensive KG development and lifecycle support platform that uses a broad variety of techniques from symbolic and modern data-driven systems. We discuss the sets of system design guiding principles used to develop EMPWR, its system architectures, and workflow components. We illustrate some of EMPWR\u2019s abilities by describing a process of creating and maintaining a KG for the pharmaceuticals domain.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                },
                {
                    "authorId": "2275146214",
                    "name": "Amit Sheth"
                }
            ]
        },
        {
            "paperId": "1904c44570c76ba1f35e739775d2a1221208d94b",
            "title": "RESTORE: Graph Embedding Assessment Through Reconstruction",
            "abstract": "Following the success of Word2Vec embeddings, graph embeddings (GEs) have gained substantial traction. GEs are commonly generated and evaluated extrinsically on downstream applications, but intrinsic evaluations of the original graph properties in terms of topological structure and semantic information have been lacking. Understanding these will help identify the deficiency of the various families of GE methods when vectorizing graphs in terms of preserving the relevant knowledge or learning incorrect knowledge. To address this, we propose RESTORE, a framework for intrinsic GEs assessment through graph reconstruction. We show that reconstructing the original graph from the underlying GEs yields insights into the relative amount of information preserved in a given vector form. We first introduce the graph reconstruction task. We generate GEs from three GE families based on factorization methods, random walks, and deep learning (with representative algorithms from each family) on the CommonSense Knowledge Graph (CSKG). We analyze their effectiveness in preserving the (a) topological structure of node-level graph reconstruction with an increasing number of hops and (b) semantic information on various word semantic and analogy tests. Our evaluations show deep learning-based GE algorithm (SDNE) is overall better at preserving (a) with a mean average precision (mAP) of 0.54 and 0.35 for 2 and 3-hop reconstruction respectively, while the factorization-based algorithm (HOPE) is better at encapsulating (b) with an average Euclidean distance of 0.14, 0.17, and 0.11 for 1, 2, and 3-hop reconstruction respectively. The modest performance of these GEs leaves room for further research avenues on better graph representation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "2234370426",
                    "name": "Chidaksh Ravuru"
                },
                {
                    "authorId": "2234370491",
                    "name": "Neelabha Banerjee"
                },
                {
                    "authorId": "2162249888",
                    "name": "S. Jha"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "6b1c1bafe67521f0fddd8ffb73700c88978e0a44",
            "title": "Knowledge Graph Empowered Machine Learning Pipelines for Improved Efficiency, Reusability, and Explainability",
            "abstract": "Artificial intelligence (AI) pipelines are complex, heavily parameterized, and expensive to execute in terms of time and computational resources. Consequently, it is onerous to run experiments with all possible parameter combinations to achieve an optimal solution. However, these AI experiments can be optimized by recommending relevant parameters to commence the experiments, reducing search space significantly, which can be fine tuned further. The relevant parameters can be identified by observing the metadata of pipelines executed in the past, and the relevant pipeline with relevant parameters can be recommended to the user. Currently, there are various metadata frameworks that automatically record the metadata of AI pipelines. Developing a recommendation system requires understanding pipeline metadata components and their interactions. There is a need to represent the metadata generated by these AI pipelines that capture the relationship among these pipeline entities. This article presents a knowledge-infused recommender that utilizes prior knowledge and metadata of already executed pipelines represented using the proposed metadata schema to recommend a relevant pipeline per user queries. Unlike black-box models, the use of knowledge graphs makes recommendations explainable, improving transparency and trustworthiness for the users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51180669",
                    "name": "R. Venkataramanan"
                },
                {
                    "authorId": "2643562",
                    "name": "Aalap Tripathy"
                },
                {
                    "authorId": "1443779643",
                    "name": "M. Foltin"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "2205970689",
                    "name": "Annmary Justine"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                }
            ]
        },
        {
            "paperId": "0d1aacf97cb67c6b4af9f7297f6affbdf559caa8",
            "title": "UBERT: A Novel Language Model for Synonymy Prediction at Scale in the UMLS Metathesaurus",
            "abstract": "The UMLS Metathesaurus integrates more than 200 biomedical source vocabularies. During the Metathesaurus construction process, synonymous terms are clustered into concepts by human editors, assisted by lexical similarity algorithms. This process is error-prone and time-consuming. Recently, a deep learning model (LexLM) has been developed for the UMLS Vocabulary Alignment (UVA) task. This work introduces UBERT, a BERT-based language model, pretrained on UMLS terms via a supervised Synonymy Prediction (SP) task replacing the original Next Sentence Prediction (NSP) task. The effectiveness of UBERT for UMLS Metathesaurus construction process is evaluated using the UMLS Vocabulary Alignment (UVA) task. We show that UBERT outperforms the LexLM, as well as biomedical BERT-based models. Key to the performance of UBERT are the synonymy prediction task specifically developed for UBERT, the tight alignment of training data to the UVA task, and the similarity of the models used for pretrained UBERT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "27549522",
                    "name": "Goonmeet Bajaj"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "79596923",
                    "name": "Vishesh Javangula"
                },
                {
                    "authorId": "2012953",
                    "name": "Yuqing Mao"
                },
                {
                    "authorId": "33407506",
                    "name": "K. Fung"
                },
                {
                    "authorId": "2739353",
                    "name": "Srinivas Parthasarathy"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "493677b136a9c37cf375364759dea267a49a0267",
            "title": "Context-Enriched Learning Models for Aligning Biomedical Vocabularies at Scale in the UMLS Metathesaurus",
            "abstract": "The Unified Medical Language System (UMLS) Metathesaurus construction process mainly relies on lexical algorithms and manual expert curation for integrating over 200 biomedical vocabularies. A lexical-based learning model (LexLM) was developed to predict synonymy among Metathesaurus terms and largely outperforms a rule-based approach (RBA) that approximates the current construction process. However, the LexLM has the potential for being improved further because it only uses lexical information from the source vocabularies, while the RBA also takes advantage of contextual information. We investigate the role of multiple types of contextual information available to the UMLS editors, namely source synonymy (SS), source semantic group (SG), and source hierarchical relations (HR), for the UMLS vocabulary alignment (UVA) problem. In this paper, we develop multiple variants of context-enriched learning models (ConLMs) by adding to the LexLM the types of contextual information listed above. We represent these context types in context-enriched knowledge graphs (ConKGs) with four variants ConSS, ConSG, ConHR, and ConAll. We train these ConKG embeddings using seven KG embedding techniques. We create the ConLMs by concatenating the ConKG embedding vectors with the word embedding vectors from the LexLM. We evaluate the performance of the ConLMs using the UVA generalization test datasets with hundreds of millions of pairs. Our extensive experiments show a significant performance improvement from the ConLMs over the LexLM, namely +5.0% in precision (93.75%), +0.69% in recall (93.23%), +2.88% in F1 (93.49%) for the best ConLM. Our experiments also show that the ConAll variant including the three context types takes more time, but does not always perform better than other variants with a single context type. Finally, our experiments show that the pairs of terms with high lexical similarity benefit most from adding contextual information, namely +6.56% in precision (94.97%), +2.13% in recall (93.23%), +4.35% in F1 (94.09%) for the best ConLM. The pairs with lower degrees of lexical similarity also show performance improvement with +0.85% in F1 (96%) for low similarity and +1.31% in F1 (96.34%) for no similarity. These results demonstrate the importance of using contextual information in the UVA problem.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "27549522",
                    "name": "Goonmeet Bajaj"
                },
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "79596923",
                    "name": "Vishesh Javangula"
                },
                {
                    "authorId": "2739353",
                    "name": "Srinivas Parthasarathy"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "7bb115c518eab1e3a421b7fa3823159455fadbb6",
            "title": "Evaluating Biomedical Word Embeddings for Vocabulary Alignment at Scale in the UMLS Metathesaurus Using Siamese Networks",
            "abstract": "Recent work uses a Siamese Network, initialized with BioWordVec embeddings (distributed word embeddings), for predicting synonymy among biomedical terms to automate a part of the UMLS (Unified Medical Language System) Metathesaurus construction process. We evaluate the use of contextualized word embeddings extracted from nine different biomedical BERT-based models for synonym prediction in the UMLS by replacing BioWordVec embeddings with embeddings extracted from each biomedical BERT model using different feature extraction methods. Finally, we conduct a thorough grid search, which prior work lacks, to find the best set of hyperparameters. Surprisingly, we find that Siamese Networks initialized with BioWordVec embeddings still out perform the Siamese Networks initialized with embedding extracted from biomedical BERT model.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "27549522",
                    "name": "Goonmeet Bajaj"
                },
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "79596923",
                    "name": "Vishesh Javangula"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2739353",
                    "name": "Srinivas Parthasarathy"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "325cb1fd2aff335c4aa04d95e1d9d14e9a6b5b2d",
            "title": "Evaluating Biomedical BERT Models for Vocabulary Alignment at Scale in the UMLS Metathesaurus",
            "abstract": "The current UMLS (Unified Medical Language System) Metathesaurus construction process for integrating over 200 biomedical source vocabularies is expensive and error-prone as it relies on the lexical algorithms and human editors for deciding if the two biomedical terms are synonymous. Recent advances in Natural Language Processing such as Transformer models like BERT and its biomedical variants with contextualized word embeddings have achieved state-of-the-art (SOTA) performance on downstream tasks. We aim to validate if these approaches using the BERT models can actually outperform the existing approaches for predicting synonymy in the UMLS Metathesaurus. In the existing Siamese Networks with LSTM and BioWordVec embeddings, we replace the BioWordVec embeddings with the biomedical BERT embeddings extracted from each BERT model using different ways of extraction. In the Transformer architecture, we evaluate the use of the different biomedical BERT models that have been pre-trained using different datasets and tasks. Given the SOTA performance of these BERT models for other downstream tasks, our experiments yield surprisingly interesting results: (1) in both model architectures, the approaches employing these biomedical BERT-based models do not outperform the existing approaches using Siamese Network with BioWordVec embeddings for the UMLS synonymy prediction task, (2) the original BioBERT large model that has not been pre-trained with the UMLS outperforms the SapBERT models that have been pre-trained with the UMLS, and (3) using the Siamese Networks yields better performance for synonymy prediction when compared to using the biomedical BERT models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27549522",
                    "name": "Goonmeet Bajaj"
                },
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "2066216451",
                    "name": "Thilini Wijesiriwardene"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "79596923",
                    "name": "Vishesh Javangula"
                },
                {
                    "authorId": "145022640",
                    "name": "S. Parthasarathy"
                },
                {
                    "authorId": "144463965",
                    "name": "A. Sheth"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "d85a6be2b314f9016d1fe1c9c97ca9f6da924f82",
            "title": "Biomedical Vocabulary Alignment at Scale in the UMLS Metathesaurus",
            "abstract": "With 214 source vocabularies, the construction and maintenance process of the UMLS (Unified Medical Language System) Metathesaurus terminology integration system is costly, time-consuming, and error-prone as it primarily relies on (1) lexical and semantic processing for suggesting groupings of synonymous terms, and (2) the expertise of UMLS editors for curating these synonymy predictions. This paper aims to improve the UMLS Metathesaurus construction process by developing a novel supervised learning approach for improving the task of suggesting synonymous pairs that can scale to the size and diversity of the UMLS source vocabularies. We evaluate this deep learning (DL) approach against a rule-based approach (RBA) that approximates the current UMLS Metathesaurus construction process. The key to the generalizability of our approach is the use of various degrees of lexical similarity in negative pairs during the training process. Our initial experiments demonstrate the strong performance across multiple datasets of our DL approach in terms of recall (91-92%), precision (88-99%), and F1 score (89-95%). Our DL approach largely outperforms the RBA method in recall (+23%), precision (+2.4%), and F1 score (+14.1%). This novel approach has great potential for improving the UMLS Metathesaurus construction process by providing better synonymy suggestions to the UMLS editors.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "c9a98a19ab129101ca21ec4b3ce6987a264d11e3",
            "title": "Siamese KG-LSTM: A deep learning model for enriching UMLS Metathesaurus synonymy",
            "abstract": "The Unified Medical Language System, or UMLS, is a repository of medical terminology developed by the U.S. National Library of Medicine for improving the computer system\u2019s ability of understanding the biomedical and health languages. The UMLS Metathesaurus is one of the three UMLS knowledge sources, containing medical terms and their relationships. Due to the rapid increase in the number of medical terms recently, the current construction of UMLS Metathesaurus, which heavily depends on lexical tools and human editors, is error-prone and time-consuming. This paper takes advantages of the emerging deep learning models for learning to predict the synonyms and non-synonyms between the pairs of biomedical terms in the Metathesaurus. Our learning approach focuses a subset of specific terms instead of the whole Metathesaurus corpus. Particularly, we train the models with biomedical terms from the Disorders semantic group. To strengthen the models, we enrich the inputs with different strategies, including synonyms and hierarchical relationships from source vocabularies. Our deep learning model adopts the Siamese KG-LSTM (Siamese Knowledge Graph - Long Short-Term Memory) in the architecture. The experimental results show that this approach yields excellent performance when handling the task of synonym detection for Disorders semantic group in the Metathesaurus. This shows the potential of applying machine learning techniques in the UMLS Metathesaurus construction process. Although the work in this paper focuses only on specific semantic group of Disorders, we believe that the proposed method can be applied to other semantic groups in the UMLS Metathesaurus.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144091472",
                    "name": "Tien Tran"
                },
                {
                    "authorId": "2038505737",
                    "name": "Sy V. Nghiem"
                },
                {
                    "authorId": "2092666312",
                    "name": "Van T. Le"
                },
                {
                    "authorId": "2342041",
                    "name": "T. Quan"
                },
                {
                    "authorId": "144913250",
                    "name": "Vinh Nguyen"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        },
        {
            "paperId": "39af4070dca3221d275898c55884167bc03fe73d",
            "title": "Singleton Property Graph: Adding A Semantic Web Abstraction Layer to Graph Databases",
            "abstract": ". Property graph databases provide e\ufb03cient implementations of graph traversal operations, while Semantic Web technologies provide expressive symbolic representation, querying, and reasoning tasks. De-spite the di\ufb00erences between the goals of the two data models, they do share similar graph characteristics. In this paper, we attempt to combine the bene\ufb01ts of each model into a single graph abstraction layer called Singleton Property Graph (SPG). The SPG layer sits on top of the RDF and simulates the property graph model. We describe the SPG model and its queries, which are Semantic Web-compliant, to be executed inside property graph databases such as TinkerPop. We have tested the prototype and evaluated the experiments with the two datasets BKR and PubChem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35089024",
                    "name": "Vinh Phu Nguyen"
                },
                {
                    "authorId": "35655815",
                    "name": "H. Y. Yip"
                },
                {
                    "authorId": "144245703",
                    "name": "Harsh Thakkar"
                },
                {
                    "authorId": "2108047195",
                    "name": "Qingliang Li"
                },
                {
                    "authorId": "2083295023",
                    "name": "Evan"
                },
                {
                    "authorId": "2080434643",
                    "name": "Bolton"
                },
                {
                    "authorId": "1950081",
                    "name": "O. Bodenreider"
                }
            ]
        }
    ]
}