{
    "authorId": "143909445",
    "papers": [
        {
            "paperId": "24133198b34d05bf2181998b75be99407ff7acc0",
            "title": "Pairwise Loss Regularization for Recommendations Explanation",
            "abstract": "Recommendersystemsarenotoriouslycomplexsystemsforwhichprovidingalocalexplanationonwhyacertainitemisproposedtoaspecificuserisstillachallengingtask .Mostexplanation approachesfocusonpredictingtheratingofitemstherebymin-imizingsomediscrepancywiththerealratingsbymeansof traditionallossfunctions(e.g.,sumofsquareserror).However, mostofthetimes,ratingsmaynotfullyembraceuserpreferences concerningtherankingofitems.Tobetterembraceuserpref-erences,methodsbasedonrankinglosseshavebeenproposed eithertorecommendortoexplainwhyanitemisrecommended. Although effective at identifying the most prominent items, these methods fail to capture a realistic value for the rating attached to their explanation. This loss attached to the semantic of the recommendation can in turn arm the trust of a user in the explanation. In this paper, we propose and discuss experimental results of a simple yet effective novel loss schema that balances ranking and rating losses to provide a best of both world explanation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35156108",
                    "name": "Alexandre Chanson"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "73774797",
                    "name": "Willeme Verdeaux"
                }
            ]
        },
        {
            "paperId": "248512f2c283ec21e7018439c9a52f2fbfc527d9",
            "title": "Assessment Methods for the Interestingness of Cube Queries",
            "abstract": "In this paper, we discuss methods to assess the interestingness of a query in an environment of data cubes. We assume a hierarchical multidimensional database, storing data cubes and level hierarchies. We focus our approach on a taxonomy of the dimensions of interestingness, and specifically, relevance, surprise, novelty",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193798492",
                    "name": "Dimos Gkitsakis"
                },
                {
                    "authorId": "2193803645",
                    "name": "Spyridon Kaloudis"
                },
                {
                    "authorId": "2193798982",
                    "name": "Eirini Mouselli"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                }
            ]
        },
        {
            "paperId": "76424e827058716a2705e13c5a1a3a33699157fe",
            "title": "Using Regression to Explain Cube Measures",
            "abstract": "The Intentional Analytics Model (IAM) has been devised to couple OLAP and analytics by (i) letting users express their analysis intentions on multidimensional data cubes and (ii) returning enhanced cubes, i.e., multidimensional data annotated with knowledge insights in the form of models (e.g., correlations). Five intention operators were proposed to this end; of these, describe and assess have been investigated in previous papers. In this work we enrich the IAM picture by focusing on the explain operator, whose goal is to provide an answer to the user asking \u201cwhy does measure \ud835\udc5a show these values?\u201d. Specifically, we propose a syntax for the operator and discuss how enhanced cubes are built by (i) finding the polynomials that best approximate the relationship between \ud835\udc5a and the other cube measures, and (ii) highlighting the most interesting one. Finally, we test the operator implementation in terms of efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36486438",
                    "name": "Matteo Francia"
                },
                {
                    "authorId": "2239539357",
                    "name": "Stefano Rizzi"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "817db70aa4fa977f3765e966fcdb525a2f0f1d2d",
            "title": "A declarative approach to data narration",
            "abstract": "This vision paper lays the preliminary foundations for Data Narrative Management Systems (DNMS), systems that enable the storage, sharing, and manipulation of data narratives. We motivate the need for such formal foundations and introduce a simple logical framework inspired by the relational model. The core of this framework is a Data Narrative Manipulation Language inspired by the extended relational algebra. We illustrate its use via examples and discuss the main challenges for the implementation of this vision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "2007368576",
                    "name": "Faten El Outa"
                },
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                }
            ]
        },
        {
            "paperId": "9c7f2de8c88925d764a133013d59e0c95b4520de",
            "title": "Data Narration for the People: Challenges and Opportunities",
            "abstract": "Data narration is the process of telling stories with insights extracted from data. It is an instance of data science [4] where the pipeline focuses on data collection and exploration, answering questions, structuring answers, and finally presenting them to stakeholders [16, 17]. This tutorial reviews the challenges and opportunities of the full and semi-automation of these steps. In doing so, it draws from the extensive literature in data narration, data exploration and data visualization. In particular, we point out key theoretical and practical contributions in each domain such as next-step recommendation and policy learning for data exploration, insight interestingness and evaluation frameworks, and the crafting of data stories for the people who will exploit them. We also identify topics that are still worth investigating, such as the inclusion of different stakeholders\u2019 profiles in designing data pipelines with the goal of providing data narration for all.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                }
            ]
        },
        {
            "paperId": "bbddad7a89987e98877c054155a5beda715113ac",
            "title": "The Whys and Wherefores of Cubes",
            "abstract": "The Intentional Analytics Model (IAM) has been devised to couple OLAP and analytics by (i) letting users express their analysis intentions on multidimensional data cubes and (ii) returning enhanced cubes, i.e., multidimensional data annotated with knowledge insights in the form of models (e.g., correlations). Five intention operators were proposed to this end; of these, describe and assess have been investigated in previous papers. In this work we enrich the IAM picture by focusing on the explain operator, whose goal is to provide an answer to the user asking \u201cwhy does measure \ud835\udc5a show these values?\u201d. Specifically, we pro-pose a syntax for the operator and discuss how enhanced cubes are built by (i) finding the polynomials that best approximate the relationship between \ud835\udc5a and the other cube measures, and (ii) highlighting the most interesting one. Finally, we test the operator implementation in terms of efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36486438",
                    "name": "Matteo Francia"
                },
                {
                    "authorId": "2652412",
                    "name": "S. Rizzi"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "30f331273338bcf2d85387ee817321e278348a49",
            "title": "Use of Context in Data Quality Management: a Systematic Literature Review",
            "abstract": "The importance of context in data quality (DQ) was shown many years ago and nowadays is widely accepted. Early approaches and surveys defined DQ as fitness for use and showed the influence of context on DQ. This paper presents a Systematic Literature Review (SLR) for investigating how context is taken into account in recent proposals for DQ management (DQM). We specifically present the planning and execution of the SLR, the analysis criteria and our results reflecting the relationship between context and DQ in the state of the art and, particularly, how this context is defined and used for DQM. The SLR is instrumental to the identification of context components and the design of a context formal model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145020960",
                    "name": "Flavia Serra"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "48916890",
                    "name": "Adriana Marotta"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "381e87eb80c99bc558e0184bf05748ec077bebea",
            "title": "Describing Multidimensional Data Through Highlights",
            "abstract": "The Intentional Analytics Model (IAM) is a new paradigm to couple OLAP and analytics. It relies on two ideas: (i) letting the user explore data by expressing his/her analysis intentions rather than the data (s)he needs, and (ii) returning enhanced cubes, i.e., multidimensional data annotated with knowledge insights in the form of model components (e",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36486438",
                    "name": "Matteo Francia"
                },
                {
                    "authorId": "1824724",
                    "name": "E. Gallinucci"
                },
                {
                    "authorId": "1711320",
                    "name": "M. Golfarelli"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "2652412",
                    "name": "S. Rizzi"
                }
            ]
        },
        {
            "paperId": "81ac50f85b6cb9e434144e3f81ac003847e8283d",
            "title": "Generating Personalized Data Narrations from EDA Notebooks",
            "abstract": "In this short paper, we present our preliminary results for generating personalized data narrations by extracting messages from a collection of Exploratory Data Analysis (EDA) notebooks over a given dataset. The approach consists of extracting features from notebooks to learn what interesting messages they expose. Based on those interesting messages, we formalize the problem of producing a user-tailored data narration, i.e., a coherent sequence of messages matching a given user profile. We developed a proof of concept and experimented with Kaggle.com notebooks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35156108",
                    "name": "Alexandre Chanson"
                },
                {
                    "authorId": "2007368576",
                    "name": "Faten El Outa"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "73774797",
                    "name": "Willeme Verdeaux"
                },
                {
                    "authorId": "2163555723",
                    "name": "Lucile Jacquemart"
                }
            ]
        },
        {
            "paperId": "06c084a0983deebe601600348b93d537c8ed7149",
            "title": "Assess Queries for Interactive Analysis of Data Cubes",
            "abstract": "Assessment is the process of comparing the actual to the expected behavior of a business phenomenon and judging the outcome of the comparison. In this paper we propose assess , a novel querying operator that supports assessment based on the results of a query on a data cube. This operator requires (1) the specification of an OLAP query over a measure of a data cube, to define the target cube to be assessed; (2) the specification of a reference cube of comparison (benchmark), which represents the expected performance of the measure; (3) the specification of how to perform the comparison between the target cube and the benchmark, and (4) a labeling function that classifies the result of this comparison using a set of labels. After introducing an SQL-like syntax for our operator, we formally define its semantics in terms of a set of logical operators. To support the computation of assess we propose a basic plan as well as some optimization strategies, then we experimentally evaluate their performance using a prototype.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "36486438",
                    "name": "Matteo Francia"
                },
                {
                    "authorId": "1711320",
                    "name": "M. Golfarelli"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2652412",
                    "name": "S. Rizzi"
                },
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                }
            ]
        },
        {
            "paperId": "0f303f25ebe1d003c0df23f49f54e8831d5a13af",
            "title": "Causality based explanations in multi-stakeholder recommendations",
            "abstract": "This paper introduces two novel contributions in the context of multi-stakeholder recommender system. First, we present a simple and intuitive method for multi-objective and multi-stakeholder recommendation that relies on preferences for each stakeholder. The second contribution is the adaptation of Halpern and Pearl's definition of causality to introduce definitions of causes and explanations for multi-stakeholder recommender systems. Experiments conducted on real data study the tractability of such explanation approach in the context of RS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "73774797",
                    "name": "Willeme Verdeaux"
                },
                {
                    "authorId": "2059499321",
                    "name": "Cl\u00e9ment Moreau"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "591f8f5092f29ae7f8ac48197656b6848bd03bca",
            "title": "To Each His Own: Accommodating Data Variety by a Multimodel Star Schema",
            "abstract": "Recent approaches adopt multimodel databases (MMDBs) to natively handle the variety issues arising from the increasing amounts of heterogeneous data (structured, semi-structured, graph-based, etc.) made available. However, when it comes to analyzing these data, traditional data warehouses (DWs) and OLAP systems fall short because they rely on relational Database Management Systems (DBMSs) for storage and querying, thus constraining data variety into the rigidity of a structured schema. This paper provides a preliminary investigation of the performance of an MMDB when used to store multidimensional data for OLAP analysis. A multimodel DW would store each of its elements according to its native model; among the benefits we envision for this solution, that of bridging the architectural gap between data lakes and DWs, that of reducing the cost for ETL data transformations , and that of ensuring better flexibility, extensibility, and evolvability thanks to the use of schemaless models. To support our investigation we present an implementation, based on the UniBench benchmark dataset, that extends a star schema with JSON, XML, spatial, and key-value data; we also define a sample OLAP workload and use it to test the performance of our solution and compare it with that of a classical star schema. As expected, the full-relational implementation performs better, but we believe that this gap could be balanced by the benefits of multimodel in dealing with variety. Finally, we give our perspective view of the research on this topic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1719976",
                    "name": "S. Bimonte"
                },
                {
                    "authorId": "1565752666",
                    "name": "Yassine Hifdi"
                },
                {
                    "authorId": "1565738605",
                    "name": "Mohammed Maliari"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2652412",
                    "name": "S. Rizzi"
                }
            ]
        },
        {
            "paperId": "5ebd9424889d8ffdbec9193bde53f98fd3f8ed8b",
            "title": "Learning Analysis Patterns using a Contextual Edit Distance",
            "abstract": "This paper presents a proposal for learning users\u2019 behavior patterns when they interactively analyse data. Users\u2019 explorations (sequences of queries) are compared looking for subsequences of common actions or operations performed by the users during data analysis. We use a hierarchical clustering algorithm to retrieve groups of similar explorations. The main difficulty is to devise a similarity measure suitable to measure similarities between sequences of human actions. We propose to use a Contextual Edit Distance (CED), a generalization of Edit Distance that manages context-dependent edition costs. CED compares two users\u2019 explorations, making special emphasis in the similarity of queries with nearby queries in the exploration, which determines a local context. We test our approach on three workloads of real users\u2019 explorations, extracting common analysis patterns, both in explorations devised by students and expert analysts. We also experiment on an artificial workload, generated with CubeLoad [19], showing that our approach is able to identify the patterns imposed by the generator. To the best of our knowledge, this is the first attempt to characterize human analysis behavior in workloads of data explorations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059499321",
                    "name": "Cl\u00e9ment Moreau"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "35156108",
                    "name": "Alexandre Chanson"
                },
                {
                    "authorId": "2085528",
                    "name": "T. Devogele"
                }
            ]
        },
        {
            "paperId": "aeea79eb52b17fea5c6a68bb57030d155d1fe4bd",
            "title": "The Traveling Analyst Problem: Definition and Preliminary Study",
            "abstract": "This paper introduces the Traveling Analyst Problem (TAP), an original strongly NP-hard problem where an automated algo-rithm assists an analyst to explore a dataset, by suggesting the most interesting and coherent set of queries that are estimated to be completed under a time constraint. We motivate the problem, study its complexity, propose a simple heuristic under simplifying assumptions for approximating it, and run preliminary tests to observe the behavior of this heuristic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35156108",
                    "name": "Alexandre Chanson"
                },
                {
                    "authorId": "73769911",
                    "name": "Ben Crulis"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "2652412",
                    "name": "S. Rizzi"
                },
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                }
            ]
        },
        {
            "paperId": "f8cf9d56787c4e115008ae7462e4c54da0a3f883",
            "title": "Supporting the Generation of Data Narratives",
            "abstract": ". Data narration has received increasing interest in several communities while lacking models and tools for handling, building and structuring data narratives. We present a simple prototype for supporting data narrative, based on a conceptual model de\ufb01ned in [4]. It guides a data narrator from scratch: fetch and explore data, abstract important messages based on an intentional goal, structure the contents of the data story, and render it in a visual manner. This prototype is implemented in Java as a web application using Spring, d3.js, JFreeChart and Apache PDFBox.",
            "fieldsOfStudy": [
                "History",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2007368576",
                    "name": "Faten El Outa"
                },
                {
                    "authorId": "36486438",
                    "name": "Matteo Francia"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                }
            ]
        },
        {
            "paperId": "325db60b2c592e0a06dadadc81bd933e52c18211",
            "title": "Qualitative Analysis of the SQLShareWorkload for Session Segmentation",
            "abstract": "This paper presents an ongoing work aiming at better understanding the workload of SQLShare [9]. SQLShare is database-asa-service platform targeting scientists and data scientists with minimal database experience, whose workload was made available to the research community. According to the authors of [9], this workload is the only one containing primarily ad-hoc handwritten queries over user-uploaded datasets. We analyzed this workload by extracting features that characterize SQL queries and we show how to use these features to separate sequences of SQL queries into meaningful sessions. We ran a few test over various query workloads to validate empirically our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "73774797",
                    "name": "Willeme Verdeaux"
                },
                {
                    "authorId": "73768955",
                    "name": "Yann Raimont"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "7342d134974fcdf29a29ceb1aea3a1ee7a85e46d",
            "title": "Qualitative Analysis of the SQLShare Workload for Session Segmentation",
            "abstract": "This paper presents an ongoing work aiming at better understanding the workload of SQLShare [9]. SQLShare is database-as-a-service platform targeting scientists and data scientists with minimal database experience, whose workload was made available to the research community. According to the authors of [9], this workload is the only one containing primarily ad-hoc handwritten queries over user-uploaded datasets. We analyzed this workload by extracting features that characterize SQL queries and we show how to use these features to separate sequences of SQL queries into meaningful sessions. We ran a few test over various query workloads to validate empirically our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "73774797",
                    "name": "Willeme Verdeaux"
                },
                {
                    "authorId": "73768955",
                    "name": "Yann Raimont"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "8fda7ea8f874f08fe8d650eb16e6bf9dba3a2f58",
            "title": "A Subjective Interestingness measure for Business Intelligence explorations",
            "abstract": "This paper addresses the problem of defining a subjective interestingness measure for BI exploration. Such a measure involves prior modeling of the belief of the user. The complexity of this problem lies in the impossibility to ask the user about the degree of belief in each element composing their knowledge prior to the writing of a query. To this aim, we propose to automatically infer this user belief based on the user's past interactions over a data cube, the cube schema and other users past activities. We express the belief under the form of a probability distribution over all the query parts potentially accessible to the user, and use a random walk to learn this distribution. This belief is then used to define a first Subjective Interestingness measure over multidimensional queries. Experiments conducted on simulated and real explorations show how this new subjective interestingness measure relates to prototypical and real user behaviors, and that query parts offer a reasonable proxy to infer user belief.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35156108",
                    "name": "Alexandre Chanson"
                },
                {
                    "authorId": "73769911",
                    "name": "Ben Crulis"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "933d5f100f0e35c10a7ec3fa9089ab0a41c089bf",
            "title": "Profiling User Belief in BI Exploration for Measuring Subjective Interestingness",
            "abstract": "This paper addresses the long-term problem of defining a subjective interestingness measure for BI exploration. Such a measure involves prior modeling of the belief of the user. The complexity of this problem lies in the impossibility to ask the user about the degree of belief in each element composing their knowledge prior to the writing of a query. To this aim, we propose to automatically infer this user belief based on the user\u2019s past interactions over a data cube, the cube schema and other users\u2019 past activities. We express the belief under the form of a probability distribution over all the query parts potentially accessible to the user. This distribution is learned using a random walk approach, and more specifically an adapted topic-specific PageRank. The resulting belief provides the foundations for the definition of subjective interestingness measures that can be use to improve the user\u2019s experience in their explorations. In the absence of ground truth for user belief, we simulate in our tests different users and their belief distributions with artificial cube explorations and evaluate our proposal based on qualitative evaluation. We finally propose a preliminary usage of our belief estimation in the context of query recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35156108",
                    "name": "Alexandre Chanson"
                },
                {
                    "authorId": "73769911",
                    "name": "Ben Crulis"
                },
                {
                    "authorId": "11186423",
                    "name": "Krista Drushku"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "9f3209e15bbd958dfc000a430c87a69528ffa9ac",
            "title": "Towards a Benefit-based Optimizer for Interactive Data Analysis",
            "abstract": "This vision paper introduces several ideas around the optimization of Interactive Data Analysis (IDA) tasks. With an eye on traditional query optimization (QO) in Relational DataBase Management Systems (RDBMS), we suggest that IDA tasks should be specified through high-level statements and optimized globally, particularly by maximizing the number and significance of insights that can be automatically collected for the task. We envision an architecture for IDA and propose in the context of IDA what corresponds to statistics, cost model and execution plan pruning strategy in relational systems. We give elements pertaining to the feasibility of the vision and draw perspectives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                }
            ]
        },
        {
            "paperId": "2b402de8530413c40374b1beab5b31066bdea69e",
            "title": "Can Models Learned from a Dataset Reflect Acquisition of Procedural Knowledge? An Experiment with Automatic Measurement of Online Review Quality",
            "abstract": "Can models learned from a dataset reflect how good are humans at mastering a particular skill? This paper studies this question in the context of online reviews writing, where the skill corresponds to the procedural knowledge needed to write helpful reviews. To this end, we model the quality of a review by a combination of various metrics stemming from text analysis (like readability, polarity, spelling errors or length) and we use customer declared helpfulness as a ground truth for constructing the model. We use Knowledge Tracing, a popular model of skill acquisition, to measure the evolution of the ability to write reviews of good quality over a period of time. While recent studies have tried to measure the quality of a review and correlate it to helpfulness, to the best of our knowledge, our work is the first to address this question as the exercise of a reviewer\u2019s skill over a sequence of reviews. Our experiments on a set of 41,681 Amazon book reviews show that it is possible to accurately assess the individual skill acquisition of writing a helpful review, based on a statistical model of the procedural knowledge at hand rather than human evaluations prone to subjectivity and variations over time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2096575189",
                    "name": "Martina Megasari"
                },
                {
                    "authorId": "144160561",
                    "name": "Pandu Wicaksono"
                },
                {
                    "authorId": "15060396",
                    "name": "Chiao-Yun Li"
                },
                {
                    "authorId": "40385867",
                    "name": "Cl\u00e9ment Chaussade"
                },
                {
                    "authorId": "2048659368",
                    "name": "Shibo Cheng"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                }
            ]
        },
        {
            "paperId": "998600c5f1e42f87318faf3600e52f02a14857b7",
            "title": "The Road to Highlights is Paved with Good Intentions: Envisioning a Paradigm Shift in OLAP Modeling",
            "abstract": "In this vision paper we structure a vision for the Business Intelligence of the near future in terms of a model with novel concepts and operators. We envision systems where the end-user requests information at a very high level, expressed as his intention to discover information, and the system transforms this request to the concrete execution of algorithms in order to compute, visualize and comment data and important highlights among them as an answer to the information request made by the end-user.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144996383",
                    "name": "Panos Vassiliadis"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "84178435b5c1bce0849fa43e6addbece579d0417",
            "title": "A benchmark for assessing OLAP exploration assistants",
            "abstract": ". In this demonstration paper, we present InDExBench , a benchmark designed and developed for evaluating and comparing Interactive Database Ex-ploration (IDE) assistant systems in the context of OLAP. We brie\ufb02y recall how InDExBench works behind the scenes. Then, we explain how it can be used in practice by considering the case of Sam , an OLAP IDE assistant author who wants to evaluate how her system performs, and how it compares to competitors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2299529",
                    "name": "Mahfoud Djedaini"
                },
                {
                    "authorId": "1714938",
                    "name": "Nicolas Labroche"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                }
            ]
        },
        {
            "paperId": "92603fae86949970151c5302526ed918e6cea6d7",
            "title": "An Approach for Alert Raising in Real-Time Data Warehouses",
            "abstract": "This work proposes an approach for alert raising within a real-time data warehouse environment. It is based on the calculation of confidence intervals for measures from historical facts. As new facts arrive to the data warehouse on a real-time basis, they are systematically compared with their appropriate confidence intervals and alerts are raised when anomalies are detected. The interest of this approach is illustrated using the particular real world use case of technical analysis of stock data.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1938339",
                    "name": "M. L\u00f3pez"
                },
                {
                    "authorId": "36761081",
                    "name": "S. Nadal"
                },
                {
                    "authorId": "2299529",
                    "name": "Mahfoud Djedaini"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                },
                {
                    "authorId": "143796776",
                    "name": "P. Furtado"
                }
            ]
        },
        {
            "paperId": "7661f446fef394c647e03820ea6f960244152282",
            "title": "20 years of pattern mining: a bibliometric survey",
            "abstract": "In 1993, Rakesh Agrawal, Tomasz Imielinski and Arun N. Swami published one of the founding papers of Pattern Mining: \"Mining Association Rules between Sets of Items in Large Databases\". Beyond the introduction to a new problem, it introduced a new methodology in terms of resolution and evaluation. For two decades, Pattern Mining has been one of the most active fields in Knowledge Discovery in Databases. This paper provides a bibliometric survey of the literature relying on 1,087 publications from five major international conferences: KDD, PKDD, PAKDD, ICDM and SDM. We first measured a slowdown of research dedicated to Pattern Mining while the KDD field continues to grow. Then, we quantified the main contributions with respect to languages, constraints and condensed representations to outline the current directions. We observe a sophistication of languages over the last 20 years, although association rules and itemsets are so far the most studied ones. As expected, the minimal support constraint predominates the extraction of patterns with approximately 50% of the publications. Finally, condensed representations used in 10% of the papers had relative success particularly between 2005 and 2008.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "2244733",
                    "name": "Dominique H. Li"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2955369",
                    "name": "Arnaud Soulet"
                }
            ]
        },
        {
            "paperId": "79421078556dc5833f96ec434d85d9618f408cca",
            "title": "Log-driven user-centric OLAP",
            "abstract": "While OLAP (On-Line Analytical Processing) is now a mature, efficient technology, very little attention has been paid to the effectiveness of the analysis and the user-friendliness of a technology often considered tedious of use. This work summarizes various contributions to developing user-centric OLAP, focusing on the use of former queries to enhance subsequent analyses. We first introduce a logical model to describe and manipulate queries and logs, including a language parametrized by binary relations over analytical sessions. In particular, these relations can be specialization relations or based on similarity measures tailored for OLAP queries and sessions. We then describe how logs can be mined for knowledge representing the user behavior. This knowledge includes simple preferences, navigational habits and discoveries made during former explorations. We show how it can be used in various query personalization or query recommendation approaches, that vary in terms of formulation effort, proactiveness, prescriptiveness and expressive power. Finally, we remark that the models and approaches introduced can be seen as a starting point for assessing the effectiveness of analytical sessions, and bridging the gap between OLAP and exploratory search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "e86c4adcf1a132269a740f16169c849aaa1f7292",
            "title": "A Holistic Approach to OLAP Sessions Composition: The Falseto Experience",
            "abstract": "OLAP is the main paradigm for flexible and effective exploration of multidimensional cubes in data warehouses. During an OLAP session the user analyzes the results of a query and determines a new query that will give her a better understanding of information. Given the huge size of the data space, this exploration process is often tedious and may leave the user disoriented and frustrated. This paper presents an OLAP tool named Falseto (Former AnalyticaL Sessions for lEss Tedious Olap), that is meant to assist query and session composition, by letting the user summarize, browse, query, and reuse former analytical sessions. Falseto's implementation on top of a formal framework is detailed. We also report the experiments we run to obtain and analyze real OLAP sessions and assess Falseto with them. Finally, we discuss how Falseto can be seen as a starting point for bridging OLAP with exploratory search, a search paradigm centered on the user and the evolution of her knowledge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3342952",
                    "name": "Julien Aligon"
                },
                {
                    "authorId": "2937418",
                    "name": "Kamal Boulil"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "39719048",
                    "name": "Ver\u00f3nika Peralta"
                }
            ]
        },
        {
            "paperId": "b3a93448a72078dae5977d6ac50c78ac8e6e0526",
            "title": "An Envisioned Approach for Modeling and Supporting User-Centric Query Activities on Data Warehouses",
            "abstract": "In this vision paper, the authors discuss models and techniques for integrating, processing and querying data, information and knowledge within data warehouses in a user-centric manner. The user-centric emphasis allows us to achieve a number of clear advantages with respect to classical data warehouse architectures, whose most relevant ones are the following: i a unified and meaningful representation of multidimensional data and knowledge patterns throughout the data warehouse layers i.e., loading, storage, metadata, etc; ii advanced query mechanisms and guidance that are capable of extracting targeted information and knowledge by means of innovative information retrieval and data mining techniques. Following this main framework, the authors first outline the importance of knowledge representation and management in data warehouses, where knowledge is expressed by existing ontology or patterns discovered from data. Then, the authors propose a user-centric architecture for OLAP query processing, which is the typical applicative interface to data warehouse systems. Finally, the authors propose insights towards cooperative query answering that make use of knowledge management principles and exploit the peculiarities of data warehouses e.g., multidimensionality, multi-resolution, and so forth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1679110",
                    "name": "Marie-Aude Aufaure"
                },
                {
                    "authorId": "145046124",
                    "name": "A. Cuzzocrea"
                },
                {
                    "authorId": "2065394520",
                    "name": "C\u00e9cile Favre"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "1735147",
                    "name": "R. Missaoui"
                }
            ]
        },
        {
            "paperId": "38f933eea52221c33724772c82f0372c5ca6cc05",
            "title": "Summarizing former sessions for user-centric OLAP",
            "abstract": "We propose a framework for summarizing former analyses to assist the user exploring a data cube. In this framework, simple operators are used for automatically summarizing log files consisted of sequences of unevaluated OLAP queries. We provide a simple implementation of the framework for summarizing logs of OLAP queries, and we test it with respect to a query personalization technique based on mining a query log.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3342952",
                    "name": "Julien Aligon"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "f8835af42ac23c3e5a6372d5d6a909f0babbbc3e",
            "title": "Towards intensional answers to OLAP queries for analytical sessions",
            "abstract": "One of the problems in analyzing large multidimensional databases through OLAP sessions is that decision makers can be overwhelmed by the size of query answers, while they need a concise summary of data. Intensional query answering can help by providing a concise description of extensional answers (i.e., the sets of retrieved facts), generally relying on knowledge like integrity constraints, taxonomies, or patterns discovered from data. This paper proposes a framework for computing an intensional answer to an OLAP query by leveraging on the previous queries in the current session. Such intensional answer is concise and semantically rich, and allows the size of the extensional answers returned to be reduced, so as to achieve an effective trade-off between conciseness and informational content. After describing the general framework, we propose a specific instantiation that relies on previous contributions in cube modeling and intensional query answering.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "1735147",
                    "name": "R. Missaoui"
                },
                {
                    "authorId": "2652412",
                    "name": "S. Rizzi"
                }
            ]
        },
        {
            "paperId": "05f0c11bcf9429e0fd0fdb2bf8970b7f1ab85d7b",
            "title": "A survey of query recommendation techniques for data warehouse exploration",
            "abstract": "Lots of data are gathered in datawarehouses that are navigated andexplored for analytical purposes. Only recently has the problem of recommending a datawarehouse query to a datawarehouse user attracted attention. In this paper, we propose a simple formal framework for expressing datawarehouse queryrecommendations. We propose to see the problem of recommending a datawarehouse query for exploration purposes as a function computing a set of queriesand associated ratings given a query log, a session, a user profile, a datawarehouse instance, and an expectation function. The rating computed indicates theusefulness of each query for a session. With this viewpoint, we review and categorize the few techniques that, to the best of our knowledge, have been proposedand we illustrate them with a case study.",
            "fieldsOfStudy": [
                "Computer Science",
                "Geography"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "46826110",
                    "name": "E. Negre"
                }
            ]
        },
        {
            "paperId": "3cdb11333854b1aff6c6826bedaa5935cc51aa14",
            "title": "A framework for summarizing a log of OLAP queries",
            "abstract": "Leveraging query logs benefits the users analyzing large data warehouses. But so far nothing exists to allow the user to have concise and usable representation of what is in the log. In this paper, we propose a framework for summarizing OLAP query logs. This framework is based on the idea that a query can summarize another query and that a log can summarize another log. It includes a simple language to declaratively specify a summary, a measure to assess the quality of a summary and an algorithm for automatically computing a good quality summary of a query log.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3342952",
                    "name": "Julien Aligon"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "46826110",
                    "name": "E. Negre"
                }
            ]
        },
        {
            "paperId": "31286332d87845a0e7bc49523ca5201ac787edeb",
            "title": "OLAP query suggestion and discovery driven analysis",
            "abstract": ". Interactive analysis of datacube, in which a user navigates a cube with a sequence of queries to \ufb01nd and understand unexpected data, is often tedious. To better support this process, we propose in this paper to connect two techniques proposed earlier in this domain. These techniques are, on the one hand, discovery driven analysis, that guides the user towards regions of the cube they will \ufb01nd of interest, and on the other hand, query recommendation, that takes advantage of what the other users did during former analyses. Bene\ufb01t-ing from these techniques we propose a framework for recommending OLAP queries to the user by taking into account what previous users found of interest and the explanation they worked out.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "44c258013abec58da6e4a52a707d127c2ea1b985",
            "title": "Query recommendations for OLAP discovery driven analysis",
            "abstract": "Recommending database queries is an emerging and promising field of investigation. This is of particular interest in the domain of OLAP systems where the user is left with the tedious process of navigating large datacubes. In this paper we present a framework for a recommender system for OLAP users, that leverages former users' investigations to enhance discovery driven analysis. The main idea is to recommend to the user the discoveries detected in those former sessions that investigated the same unexpected data as the current session.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "46826110",
                    "name": "E. Negre"
                },
                {
                    "authorId": "2955369",
                    "name": "Arnaud Soulet"
                }
            ]
        },
        {
            "paperId": "a67579aa476b6a02dd4dea3dccf820374a037585",
            "title": "A Generic Framework for Rule-Based Classification",
            "abstract": "Classification is an important field of data mining problems. Given a set of labeled training examples the classification task constructs a classifier. A classifier is a global model which is used to predict the class label for data objects that are unlabeled. Many approaches have been proposed for the classification problem. Among them, rule-induction, associative and instance-centric approaches have been closely integrated with constraint-based data mining. There also exist several classification methods based on each of these approaches, e.g. AQ, CBA and HAR-MONY respectively. Moreover, each classification method may provide one or more algorithms that exploit particular local pattern extraction techniques to construct a classifier. In this paper, we proposed a generic classification framework that encompasses all the mentioned approaches. Based on our framework we present a formal context to define basic concepts, operators for classifier construction, composition of classifiers, and class prediction. Moreover, we proposed a generic classifier construction algorithm (ICCA) that incrementally constructs a classifier using the proposed operators. This algorithm is generic in the sense that it can uniformly represent a large class of existing classification algorithms. We also present the properties under which different optimization possibilities are provided in the generic algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "2944759",
                    "name": "Eynollah Khanjari Miyaneh"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2955369",
                    "name": "Arnaud Soulet"
                }
            ]
        },
        {
            "paperId": "bc749ed1e03e9fb38c50971de9d4fce70f5fe1f6",
            "title": "A framework for recommending OLAP queries",
            "abstract": "An OLAP analysis session can be defined as an interactive session during which a user launches queries to navigate within a cube. Very often choosing which part of the cube to navigate further, and thus designing the forthcoming query, is a difficult task. In this paper, we propose to use what the OLAP users did during their former exploration of the cube as a basis for recommending OLAP queries to the user. We present a generic framework that allows to recommend OLAP queries based on the OLAP server query log. This framework is generic in the sense that changing its parameters changes the way the recommendations are computed. We show how to use this framework for recommending simple MDX queries and we provide some experimental results to validate our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "46826110",
                    "name": "E. Negre"
                }
            ]
        },
        {
            "paperId": "18f1c67e274d275324d71a3b0be2fb50ce61bccc",
            "title": "Context-based exploitation of data warehouses",
            "abstract": "An OLAP analysis can be defined as an interactive session during \nwhich an user launches queries over a data warehouse. The launched queries \nare often interdependent, and they can be either newly defined queries or they \ncan be existing ones that are browsed and reused. Moreover, in a collaborative \nenvironment, queries may be shared among users. This notion of OLAP analysis \nhas never been formally defined. In this paper, we propose a clear definition of \nthis notion, by introducing a model for sharing, browsing and reusing OLAP \nqueries over a data warehouse.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1904071",
                    "name": "Y. W. Choong"
                },
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "39612641",
                    "name": "D. Laurent"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "46826110",
                    "name": "E. Negre"
                },
                {
                    "authorId": "2908101",
                    "name": "N. Spyratos"
                }
            ]
        },
        {
            "paperId": "d421ee5ad177dddf7600e3e7d37a0cdfbc0f4713",
            "title": "Personalization of MDX Queries",
            "abstract": "Answers of OLAP queries often cannot be visualized entirely and the user has to navigate through them to find relevant facts. One possible way to solve this problem is to personalize the queries. The basic idea behind the process of query personalization is that different users may find and see the facts they prefer without having to navigate. In this paper, we propose a framework for personalizing MDX queries. MDX allows the user to express complex queries on multidi- mensional data and to specify how the result will be presented on the screen. In this work, we present a preference model which allows the user to define his preferred dimensions and members. In addition, we provide an algorithm that, given an MDX query, a user profile and a visualization constraint, computes and displays the best answer to a user w.r.t. his (her) preferences and the constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2990547",
                    "name": "H. Mouloudi"
                },
                {
                    "authorId": "1684379",
                    "name": "Ladjel Bellatreche"
                },
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "9ef7ddd436e5ee7ae1ba9705b19ea9ca5ec1d3bb",
            "title": "A personalization framework for OLAP queries",
            "abstract": "OLAP users heavily rely on visualization of query answers for their interactive analysis of massive amounts of data. Very often, these answers cannot be visualized entirely and the user has to navigate through them to find relevant facts.In this paper, we propose a framework for personalizing OLAP queries. In this framework, the user is asked to give his (her) preferences and a visualization constraint, that can be for instance the limitations imposed by the device used to display the answer to a query. Given this, for each query, our method computes the part of the answer that respects both the user preferences and the visualization constraint. In addition, a personalized structure for the visualization is proposed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1684379",
                    "name": "Ladjel Bellatreche"
                },
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2990547",
                    "name": "H. Mouloudi"
                },
                {
                    "authorId": "39612641",
                    "name": "D. Laurent"
                }
            ]
        },
        {
            "paperId": "642f58e4278fbc42085d7041184cde38b18828ce",
            "title": "A new way of optimizing OLAP queries",
            "abstract": "For around 10 years, the academic research in database has attempted to define a commonly agreed logical modeling for the multidimensional and hierarchical nature of data manipulated with OLAP treatments (called datacube, or cube for short). But only recently has the concept of representation of a cube on a screen, or the optimization of OLAP queries at a logical level, been taken into account in this study. As many others, we believe that these two concepts are essential for the definition of a multidimensional query language. In this article, we propose to consider representations of cubes as first class citizens for query optimisation at the logical level. To reach this goal, we formally define the concept of representation by using the model of complex values [ABI 95]. This allows to have a single model for manipulating both cubes and their representations through typical OLAP operations. These typical operations are studied to propose rewrite rules in order to optimize OLAP queries. R\u00c9SUM\u00c9.Depuis environ 10 ans, la d\u00e9finition d\u2019un mod\u00e8le concensuel englobant la nature multidimensionnelle et hi\u00e9rarchis\u00e9e des donn\u00e9es manipul\u00e9es par les traitements OLAP (appel\u00e9es cube de donn\u00e9es) est \u00e0 l\u2019\u00e9tude. Mais c\u2019est seulement r\u00e9cemment que les concepts de repr\u00e9sentation d\u2019un cube \u00e0 l\u2019\u00e9cran et d\u2019optimisation de requ\u00eates OLAP \u00e0 un niveau logique ont \u00e9t\u00e9 pris en compte dans cette \u00e9tude. Nous pensons, comme beaucoup, que ces concepts sont essentiels \u00e0 la d\u00e9finition d\u2019un langage de requ\u00eates pour OLAP. Dans cet article, nous proposons de consid\u00e9rer les repr\u00e9sentations de cubes de donn\u00e9es comme une base pour l\u2019optimisation de requ\u00eates au niveau logique. Pour ce faire, nous d\u00e9finissons formellement le concept de repr\u00e9sentation en utilisant le mod\u00e8le des valeurs complexes [ABI 95]. Cela permet d\u2019avoir un mod\u00e8le unique pour manipuler un cube et ses repr\u00e9sentations via les op\u00e9rations OLAP usuelles. L\u2019\u00e9tude de ces op\u00e9rations nous permet de donner des r\u00e8gles de r\u00e9\u00e9criture pour optimiser les requ\u00eates OLAP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31498998",
                    "name": "A. Giacometti"
                },
                {
                    "authorId": "39612641",
                    "name": "D. Laurent"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2990547",
                    "name": "H. Mouloudi"
                }
            ]
        },
        {
            "paperId": "24c9fa1ab59947e3a4ff37040ac511ca5a9fd4b8",
            "title": "Computing appropriate representations for multidimensional data",
            "abstract": "On-Line Analytical Processing (OLAP) provides an interactive query-driven analysis of multidimensional data based on a set of navigational operators like roll-up or slice and dice. In most cases, the analyst is expected to use these operations intuitively to find interesting patterns in a huge amount of data of high dimensionality.In this paper, we propose an approach to enhance this analysis by preparing the data set so that the analyst can explore it in a more systematic and effective manner. More precisely we define a measurement of the quality of the representation of multidimensional data and we present a framework for investigating the computation of appropriate representations. We identify the problems of computing such representations and study them w.r.t. an OLAP restructuring operator.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1904071",
                    "name": "Y. W. Choong"
                },
                {
                    "authorId": "39612641",
                    "name": "D. Laurent"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "62e142bd3a4d651092cef62b43ab13bde9f75c08",
            "title": "Query-Driven Knowledge Discovery via OLAP manipulations",
            "abstract": "We study KDD (Knowledge Discovery in Databases) processes on OLAP (multidimensional and multilevel) data from a query point of view. Focusing on association rule mining, we consider typical queries to cope with the pre-processing of multidimensional data and the post-processing of the discovered patterns as well. We use a model and a rule-based language stemming from the OLAP representation and manipulation, and argue that such a language fits well for writing KDD queries on multidimensional and multilevel data. Using an homogeneous data model and our language for expressing queries at every phase of the process appears as a valuable step towards a better understanding of interactivity during the whole process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1698567",
                    "name": "Jean-Fran\u00e7ois Boulicaut"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2255299",
                    "name": "C. Rigotti"
                }
            ]
        },
        {
            "paperId": "24af21bc5f83b5116a5b9bf889cf90287778cf12",
            "title": "Modeling and querying multidimensional databases: an overview",
            "abstract": "Cet article presente un apercu des concepts de bases de donnees multidimensionnelles et d'analyse en ligne de donnees (OLAP), utilises dans le contexte de l'aide a la decision. Il aborde principalement les modeles de donnees multidimensionnels et la manipulation de donnees multidimensionnelles. Nous proposons a la fois un inventaire et une classification des operations elementaires a la base des traitements OLAP, Nous decrivons quelques manipulations complexes typiques utilisant ces operations elementaires. L'article est organise de maniere a presenter les concepts informels provenant des besoins des utilisateurs et les contreparties academiques elaborees en reponse a ces besoins. Il constitue ainsi un point d'entree dans le domaine de la modelisation et de l'interrogation pour l'analyse en ligne de donnees.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                }
            ]
        },
        {
            "paperId": "e7261f7cb8e578808a9d800e62a32a7ea85e6e9c",
            "title": "Query driven knowledge discovery in multidimensional data",
            "abstract": "We study KDD (Knowledge Discovery in Databases) processes on multidimensional data from a query point of view. Focusing on association rule mining, we consider typical queries to cope with the pre-processing of multidimensional data and the post-processing of the discovered patterns as well. We use a model and a rule-based language stemming from the OLAP multidimensional representation, and demonstrate that such a language fits well for writing KDD queries on multidimensional data. Using an homogeneous data model and our language for expressing queries at every phase of the process appears as a valuable step towards a better understanding of interactivity during the whole process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1698567",
                    "name": "Jean-Fran\u00e7ois Boulicaut"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "2255299",
                    "name": "C. Rigotti"
                }
            ]
        },
        {
            "paperId": "2687d9e339d07c7000faeb9d1bb1df25ff1e8d3d",
            "title": "Spreadsheet Generation from Rule-Based Specifications",
            "abstract": "Experimental studies have pointed out that operational spreadsheets contain a lot of errors. In this paper, we propose to use a multidimensional rule-based data manipulation language to specify spreadsheets. This language allows formal declarative deenition of spreadsheet tabular data treatments. The main contribution of this paper is to show t h a t from textual rule-based speciications, we can generate the corresponding spreadsheet. This generation of a spreadsheet from its logical deenition is a promising way to reduce encoding errors. The technique presented has been implemented in a crude running prototype.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1698567",
                    "name": "Jean-Fran\u00e7ois Boulicaut"
                },
                {
                    "authorId": "143909445",
                    "name": "Patrick Marcel"
                },
                {
                    "authorId": "32648390",
                    "name": "F. Pinet"
                },
                {
                    "authorId": "2255299",
                    "name": "C. Rigotti"
                }
            ]
        }
    ]
}