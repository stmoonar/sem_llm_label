{
    "authorId": "2798149",
    "papers": [
        {
            "paperId": "8d0ddeab6ef624d15db320eaa38df282c4dfa33a",
            "title": "FPI: Failure Point Isolation in Large-scale Conversational Assistants",
            "abstract": "Large-scale conversational assistants such as Cortana, Alexa, Google Assistant and Siri process requests through a series of modules for wake word detection, speech recognition, language understanding and response generation. An error in one of these modules can cascade through the system. Given the large traffic volumes in these assistants, it is infeasible to manually analyze the data, identify requests with processing errors and isolate the source of error. We present a machine learning system to address this challenge. First, we embed the incoming request and context, such as system response and subsequent turns, using pre-trained transformer models. Then, we combine these embeddings with encodings of additional metadata features (such as confidence scores from different modules in the online system) using a \u201cmixing-encoder\u201d to output the failure point predictions. Our system obtains 92.2% of human performance on this task while scaling to analyze the entire traffic in 8 different languages of a large-scale conversational assistant. We present detailed ablation studies analyzing the impact of different modeling choices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145964537",
                    "name": "R. Khaziev"
                },
                {
                    "authorId": "3164047",
                    "name": "Usman Shahid"
                },
                {
                    "authorId": "2240075710",
                    "name": "Tobias R\u00f6ding"
                },
                {
                    "authorId": "147887099",
                    "name": "Rakesh Chada"
                },
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                }
            ]
        },
        {
            "paperId": "5b2630c6b9c9607d789efe4b98f334d5291bd0c4",
            "title": "A Junction Tree Propagation Algorithm for Bayesian Networks with Second-Order Uncertainties",
            "abstract": "Bayesian networks (BNs) have been widely used as a model for knowledge representation and probabilistic inferences. However, the single probability representation of conditional dependencies has been proven to be over-constrained in realistic applications. Many efforts have proposed to represent the dependencies using probability intervals instead of single probabilities. In this paper, we move one step further and adopt a probability distribution schema. This results in a higher order representation of uncertainties in a BN. We formulate probabilistic inferences in this context and then propose a mean/covariance propagation algorithm based on the well-known junction tree propagation for standard BNs. For algorithm validation, we develop a two-layered Markov likelihood weighting approach that handles high-order uncertainties and provides \"ground-truth\" solutions to inferences, albeit very slowly. Our experiments show that the mean/covariance propagation algorithm can efficiently produce high-quality solutions that compare favorably to results obtained through painstaking sampling",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40454266",
                    "name": "Maurizio Borsotto"
                },
                {
                    "authorId": "2108075512",
                    "name": "Weihong Zhang"
                },
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "145668856",
                    "name": "Avi Pfeffer"
                },
                {
                    "authorId": "1802703",
                    "name": "C. Crick"
                }
            ]
        },
        {
            "paperId": "e252d228cc8a89673242ef5ef7864eae9e549ff7",
            "title": "Signal-to-Score Music Transcription using Graphical Models",
            "abstract": "We present a transcription system that takes a music signal as input and returns its musical score. Two stages of processing are used. The first employs a fundamental frequency detector and an onset detector to transform input signals into a sequence of sound events. The onset detection is inherently noisy. This paper focuses on the second stage, going from sound events to a notated score. We use a family of graphical models for this task. We allow the results of onset detection to be noisy, necessitating a search over possible segmentations of the sound events. We use a large corpus of monophonic vocal music to evaluate our system. Our results show that our approach is well-suited to the problem of music transcription. The initial onset detection reduces the number of observations and makes the system less instrument specific. The search over segmentations corrects the errors in the onset detection. Without such reasoning, these errors are magnified in subsequent rhythm transcription.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "145668856",
                    "name": "Avi Pfeffer"
                }
            ]
        },
        {
            "paperId": "fa533a92b1356e229792decd9837f1cdb96e24f3",
            "title": "A Hierarchical Approach to Onset Detection",
            "abstract": "Onset detection in vocal music and many other instruments is complicated by the possibility of soft transitions between notes. Most systems try to identify onsets within a short-time window as it is easier to define transition functions over a restricted space. However, it may not be possible to detect soft onsets without considering a long-time window, for which defining and computing the transition function can be hard and computationally costly. We present a method which looks for onsets between locations of increasing distance and is able to capture such onsets without considering all the points within the window. For the onset identification function we use both a simple manual function and support vector machines trained using a labelled corpus.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "145668856",
                    "name": "Avi Pfeffer"
                }
            ]
        },
        {
            "paperId": "b58bcfaf068f60aa61cf7e146f0b7842053c25ef",
            "title": "Learning Style-Specific Rhythmic Structures",
            "abstract": "The goal of computational music modeling is to construct models that capture the structure of music. We present our work on learning style-specific models for the rhythmic structure on a single line of music. The task by which the model is evaluated is to predict the duration of the next note given the sequence of durations leading to that note. We construct several different models that we train using works by a given composer (Palestrina), and assess the success of our models by looking at the prediction accuracy on unseen works by the same composer. We show that introducing style-specific musical knowledge improves the predictive ability of our models. proficient in transcription, trying to reproduce a musical score, where one musician has never listened to that specific style, and the other is an expert in that style. It is reasonable that the expert will be more accurate and faster in this task. We therefore suggest that methods for transcription of music in a particular style should be supported with a rhythm model that is specific to that style. Such models are more likely to produce accurate and fast (speed is especially important for online systems) rhythm quantifiers. An additional benefit of having a successful rhythm quantifier is that it will help in resolving uncertainty during tempo tracking, since the two problems are highly connected.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2798149",
                    "name": "Emir Kapanci"
                },
                {
                    "authorId": "145668856",
                    "name": "Avi Pfeffer"
                }
            ]
        }
    ]
}