{
    "authorId": "143941894",
    "papers": [
        {
            "paperId": "261d721fecae2c81b212ee65c57ad0ee40dff9a0",
            "title": "Reaching Between Worlds: Calibration and Transfer of Perceived Affordances from Virtual to Real Environments",
            "abstract": "Accurate perception of one\u2019s action capabilities, or affordance perception, is essential for successful interaction with both real and virtual environments. Affordance perception can potentially be improved by receiving feedback. It is unknown what specific types of feedback are needed for improvements in affordance perception to occur, particularly in virtual environments where cues may be impoverished. The current work studied perception of horizontal reachability in virtual and augmented reality (VR and AR), specifically whether it would improve with feedback, and if any improvement transferred to the real world. Multiple types of feedback were studied in VR or AR: exploratory behavior, static outcome, and action outcome feedback. Our results indicate that exploratory behavior is sufficient for improvement in perceived reachability in VR, but in AR, outcome feedback is necessary. In both VR and AR, outcome feedback was required for improvement in perceived reachability to transfer to the real world. These findings have practical implications for training in virtual environments. If virtual environments are used for training actions that ultimately need to be performed in the real world, outcome feedback should be provided.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1416508706",
                    "name": "Holly C. Gagnon"
                },
                {
                    "authorId": "51250076",
                    "name": "Hunter Finney"
                },
                {
                    "authorId": "2270657788",
                    "name": "Jeanine Stefanucci"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                },
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                }
            ]
        },
        {
            "paperId": "15ba4787e9ef2d0228599f15e87f7e2a60c8b663",
            "title": "Does Teleporting Length Affect Spatial Awareness?",
            "abstract": "Teleporting, or jumping, is a common method of moving through virtual environments. It provides a simple user interface, but deprives users of self-motion cues that are important to acquiring spatial knowledge. This paper examines one parameter of the teleportation interface, the teleportation or jump distance, and how that may affect spatial knowledge acquisition. We report the results of an experiment that examined the effects of two different, but fixed teleportation distances on how users could acquire knowledge of landmarks and routes. The results suggest that the teleport distance does not matter, hence teleportation as an interface is robust. However, use of teleportation resulted in significantly increased simulator sickness, a surprising result.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2269834282",
                    "name": "Qinchen Yao"
                },
                {
                    "authorId": "2110261266",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                },
                {
                    "authorId": "2270657788",
                    "name": "Jeanine Stefanucci"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                }
            ]
        },
        {
            "paperId": "21e695564ed093f67daf8307cb1b3077fd39f039",
            "title": "Calibrated Passability Perception in Virtual Reality Transfers to Augmented Reality",
            "abstract": "As applications for virtual reality (VR) and augmented reality (AR) technology increase, it will be important to understand how users perceive their action capabilities in virtual environments. Feedback about actions may help to calibrate perception for action opportunities (affordances) so that action judgments in VR and AR mirror actors\u2019 real abilities. Previous work indicates that walking through a virtual doorway while wielding an object can calibrate the perception of one\u2019s passability through feedback from collisions. In the current study, we aimed to replicate this calibration through feedback using a different paradigm in VR while also testing whether this calibration transfers to AR. Participants held a pole at 45\u00b0and made passability judgments in AR (pretest phase). Then, they made passability judgments in VR and received feedback on those judgments by walking through a virtual doorway while holding the pole (calibration phase). Participants then returned to AR to make posttest passability judgments. Results indicate that feedback calibrated participants\u2019 judgments in VR. Moreover, this calibration transferred to the AR environment. In other words, after experiencing feedback in VR, passability judgments in VR and in AR became closer to an actor\u2019s actual ability, which could make training applications in these technologies more effective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1416508706",
                    "name": "Holly C. Gagnon"
                },
                {
                    "authorId": "2154596162",
                    "name": "Jeanine Stefanucci"
                },
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                }
            ]
        },
        {
            "paperId": "27789898ee7b9f4e91ac44bef6e4e1cbdaf29b4b",
            "title": "Automatic Joint Parameter Estimation from Magnetic Motion Capture Data",
            "abstract": "This paper describes a technique for using magnetic motion capture data to determine the joint parameters of an articulated hierarchy. This technique makes it possible to determine limb lengths, joint locations, and sensor placement for a human subject without external measurements. Instead, the joint parameters are inferred with high accuracy from the motion data acquired during the capture session. The parameters are computed by performing a linear least squares fit of a rotary joint model to the input data. A hierarchical structure for the articulated model can also be determined in situations where the topology of the model is not known. Once the system topology and joint parameters have been recovered, the resulting model can be used to perform forward and inverse kinematic procedures. We present the results of using the algorithm on human motion capture data, as well as validation results obtained with data from a simulation and a wooden linkage of known dimensions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1394768078",
                    "name": "J. F. O'Brien"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                },
                {
                    "authorId": "3309893",
                    "name": "G. Brostow"
                },
                {
                    "authorId": "1788773",
                    "name": "J. Hodgins"
                }
            ]
        },
        {
            "paperId": "58657bd42ac95991a4e8bb819e5b0ebecd40e953",
            "title": "Evaluating Threat Cues for the Enhancement of Safety in Virtual Navigation",
            "abstract": "Augmented Reality (AR) can enhance safety in navigation by providing feedback for threatening areas to avoid. We developed a virtual city where participants were tasked with avoiding a pre-defined threat while navigating to a beacon. We implemented two simulated AR cues in the virtual city that indicated threat areas: (1) a world-locked cue that color coded the ground area (GA) to delineate the boundaries of the threat, or (2) a screen-locked cue that provided dynamic text to indicate numeric distance to the threat (DT). Participants were instructed to complete each trial by freely navigating to a beacon in an efficient but safe manner. They navigated to 6 target beacons twice (in random order), once with each cue type in place. The GA cue resulted in the lowest time spent in danger areas (safer navigation), while the DT cue resulted in more efficient navigation. We argue that the GA cue was worth this safety versus efficiency trade-off since the loss of efficiency was minimal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2271300394",
                    "name": "Ashley M. Buzard"
                },
                {
                    "authorId": "2270268281",
                    "name": "Jordan A. Davidson"
                },
                {
                    "authorId": "2277610789",
                    "name": "Edward Tighe"
                },
                {
                    "authorId": "2110261266",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                },
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                },
                {
                    "authorId": "2270657788",
                    "name": "Jeanine Stefanucci"
                }
            ]
        },
        {
            "paperId": "e52d8968562718a2faafa60e8f9beda0c41365c7",
            "title": "Evaluating Augmented Reality Landmark Cues and Frame of Reference Displays with Virtual Reality",
            "abstract": "Daily travel usually demands navigation on foot across a variety of different application domains, including tasks like search and rescue or commuting. Head-mounted augmented reality (AR) displays provide a preview of future navigation systems on foot, but designing them is still an open problem. In this paper, we look at two choices that such AR systems can make for navigation: 1) whether to denote landmarks with AR cues and 2) how to convey navigation instructions. Specifically, instructions can be given via a head-referenced display (screen-fixed frame of reference) or by giving directions fixed to global positions in the world (world-fixed frame of reference). Given limitations with the tracking stability, field of view, and brightness of most currently available head-mounted AR displays for lengthy routes outdoors, we decided to simulate these conditions in virtual reality. In the current study, participants navigated an urban virtual environment and their spatial knowledge acquisition was assessed. We experimented with whether or not landmarks in the environment were cued, as well as how navigation instructions were displayed (i.e., via screen-fixed or world-fixed directions). We found that the world-fixed frame of reference resulted in better spatial learning when there were no landmarks cued; adding AR landmark cues marginally improved spatial learning in the screen-fixed condition. These benefits in learning were also correlated with participants' reported sense of direction. Our findings have implications for the design of future cognition-driven navigation systems.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110261266",
                    "name": "Yu Zhao"
                },
                {
                    "authorId": "2154596162",
                    "name": "Jeanine Stefanucci"
                },
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                }
            ]
        },
        {
            "paperId": "e8e4518c51f6c78314de8420d9e0e122af870656",
            "title": "Perceiving Absolute Distance in Augmented Reality Displays with Realistic and Non-realistic Shadows",
            "abstract": "Although distance perception to Augmented Reality (AR) objects has been studied for decades, little is known about absolute distance perception with the newest available AR displays. One significant distinction in categories of head-worn AR displays is whether they are optical see-through (OST) or video see-through (VST). These two types of devices have different methods of rendering that could affect the cues available for perceiving distance. Specifically, rendering cast shadows can be challenging, especially in OST displays that rely on additive light for rendering, and there may be alternative shadow shading methods that are equally as effective for conveying cues to depth. The current study tests absolute egocentric distance judgments to targets 3-6 meters away from an observer with two types of shadows, in two types of AR displays, the Hololens 2 (OST) and the Varjo XR-3 (VST). Shadows were realistic cast shadows or non-realistic shadows in the form of a stylized ring placed beneath the object. Participants verbally reported perceived distance to spherical virtual targets presented on or above the ground, viewed through the displays in a real world classroom. We found overall distance underestimation in both devices, but that estimations were more accurate with the Hololens 2 compared to the Varjo XR-3. There was little support for a difference in accuracy of estimations between shadow conditions or position on or above the ground (confirmed by a Bayesian analysis), suggesting that non-realistic shadows may be a good option for providing additional shading cues for depth in AR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                },
                {
                    "authorId": "33692377",
                    "name": "Haley Adams"
                },
                {
                    "authorId": "1390091979",
                    "name": "Mirinda M Whitaker"
                },
                {
                    "authorId": "2154596162",
                    "name": "Jeanine Stefanucci"
                },
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                }
            ]
        },
        {
            "paperId": "0ada408ef4f0ce9d6ea452799d11844b9c9c175d",
            "title": "Perceiving Affordances for Passing Through Apertures: A Discussion of Factors Influencing Replication Across Extended Reality",
            "abstract": "A growing body of work suggests that affordances- perceived capabilities for action- are a useful measure for testing theoretical and applied questions in both the real world and extended realities (XR). In this review, we discuss replications across studies suggesting that affordances for passability are perceived similarly in XR environments when compared to real world judgments. Further, representations of the body in these environments can recalibrate passability affordance judgments as well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1400971914",
                    "name": "Sarah H. Creem-Regehr"
                },
                {
                    "authorId": "1720140",
                    "name": "Jeanine K. Stefanucci"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                }
            ]
        },
        {
            "paperId": "0cd9d6a07dc742575debe875673be2c658be9694",
            "title": "Experience Orchestra: Manipulating Musical Instruments in VR",
            "abstract": "Fine-grained grasping and interaction can be frustrating and discouraging in a conventional virtual reality system with standard handheld controllers. Experience Orchestra is an immersive application in which users can experience playing orchestral instruments, either individually or in an ensemble, in realistic ways. We describe how conventional grasping methods were modified to make the experience more realistic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2162994691",
                    "name": "Kristine Choi"
                },
                {
                    "authorId": "2162975417",
                    "name": "Garrett Crumb"
                },
                {
                    "authorId": "2163050428",
                    "name": "Richard Li"
                },
                {
                    "authorId": "2133191460",
                    "name": "Raahul Natarrajan"
                },
                {
                    "authorId": "2162973243",
                    "name": "Patrick Tong"
                },
                {
                    "authorId": "103781853",
                    "name": "Ole Molvig"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                }
            ]
        },
        {
            "paperId": "153d88779d8b6542fe049c2c6ca039eecef72e9c",
            "title": "Evaluating the Impact of Limited Physical Space on the Navigation Performance of Two Locomotion Methods in Immersive Virtual Environments",
            "abstract": "Consumer level virtual experiences almost always occur when physical space is limited, either by the constraints of an indoor space or of a tracked area. This observation coupled with the need for movement through large virtual spaces has resulted in a proliferation of research into locomotion interfaces that decouples movement through the virtual environment from movement in the real world. While many locomotion interfaces support movement of some kind in the real world, some do not. This paper examines the effect of the amount of physical space used in the real world on one popular locomotion interface, resetting, when compared to a locomotion interface that requires minimal physical space, walking in place. The metric used to compare the two locomotion interfaces was navigation performance, specifically, the acquisition of survey knowledge. We find that, while there are trade-offs between the two methods, walking in place is preferable in small spaces.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40010600",
                    "name": "Richard A. Paris"
                },
                {
                    "authorId": "1693375988",
                    "name": "Lauren E. Buck"
                },
                {
                    "authorId": "2298875",
                    "name": "T. McNamara"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                }
            ]
        }
    ]
}