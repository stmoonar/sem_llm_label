{
    "authorId": "144330453",
    "papers": [
        {
            "paperId": "168e224059bf6d917da0515a90f150c2c7db7bef",
            "title": "Multi-View Maximum Margin Clustering With Privileged Information Learning",
            "abstract": "Maximum margin clustering (MMC) is a typical clustering method which aims to maximize the margin between different clusters. However, in practical applications, a data object may be represented by multiple feature sets (views), with each feature set representing different information of the underlying data. The traditional MMC methods can handle only the data from a single view and are unable to utilize the multi-view data to enhance the clustering model. In multi-view clustering, there are two basic principles: the consensus principle and complementarity principle. Most multi-view clustering methods implement mainly the consensus principle, while the complementarity principle has not been sufficiently taken into account. Distinguished from the existing methods, <inline-formula> <tex-math notation=\"LaTeX\">$\\text {M}^{3}\\text {CP}$ </tex-math></inline-formula> introduces the idea of privileged information learning into multi-view clustering and implements both of the consensus principle and complementarity principle. Based on privileged information learning, <inline-formula> <tex-math notation=\"LaTeX\">$\\text {M}^{3}\\text {CP}$ </tex-math></inline-formula> embodies the complementarity principle by considering one view as the main learning information and the other views as the privileged information, so that multiple views can provide information to complement each other. The derived learning problem is then solved by applying the constrained concave\u2013convex procedure and cutting plane techniques. By employing these techniques, the computational time of <inline-formula> <tex-math notation=\"LaTeX\">$\\text {M}^{3}\\text {CP}$ </tex-math></inline-formula> is able to scale linearly with respect to the dataset size. Numerical experiments on real-life multi-view datasets demonstrate that <inline-formula> <tex-math notation=\"LaTeX\">$\\text {M}^{3}\\text {CP}$ </tex-math></inline-formula> is able to achieve better clustering accuracy and meanwhile needs less computational time, compared to state-of-the-art multi-view clustering methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                },
                {
                    "authorId": "2237383558",
                    "name": "Jianwei Zhang"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "151470822",
                    "name": "Xiangjun Kong"
                },
                {
                    "authorId": "2237239788",
                    "name": "Zhifeng Hao"
                }
            ]
        },
        {
            "paperId": "41da56883769b28916500f3efad4a2aa1805876a",
            "title": "Few-Shot Object Counting With Dynamic Similarity-Aware in Latent Space",
            "abstract": "Few-shot object counting (FSOC) estimates object quantities in query images using a few of support information. Unlike traditional counting methods, FSOC prioritizes more discriminative and generalized similarity measures between query and support data. This facilitates counting objects from new categories without extensive dataset creation or costly retraining. However, existing approaches often rely on fixed similarity rules, leading to spatial information loss. Limited training data can yield sparse similarity feature distribution, hampering the model\u2019s learning and its ability to handle objects with large intraclass differences. In this study, we introduce a novel FSOC network named DSALVANet that comprises the dynamic similarity-aware module (DSAM) and the latent variable augmentation module (LVAM). DSAM establishes adaptive metric rules for support features to find similar regions in the metric space for accurate object counting. LVAM utilizes prior similarity knowledge from DSAM to model the latent distribution of the density map, improving the decoder\u2019s robustness by sampling diverse latent variables during training. Extensive experiments on the FSOC benchmark and remote-sensing datasets demonstrate our method\u2019s effectiveness and state-of-the-art performance. The code and model are available at DSALVANet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278096300",
                    "name": "Jinghui He"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "2278055005",
                    "name": "Fan Cao"
                },
                {
                    "authorId": "2278215859",
                    "name": "Jian Xu"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                }
            ]
        },
        {
            "paperId": "cfb77076fe0908ad903b83b5dda0688f55a29474",
            "title": "Dictionary-Based Multi-View Learning With Privileged Information",
            "abstract": "Multi-view learning can improve classification performance by combining information between different views. Due to the similarity in different views of the dataset, sometimes the features obtained are highly limited and redundant. At the same time, different views accumulate a large amount of noisy information, which will affect the classification performance of the model. To solve these problems, we embed privileged information in the model and introduce dictionary learning, and proposed a new dictionary-based multi-view learning method with privileged information (MVDL-PI). First, two sets of dictionaries (synthetic dictionary and analysis dictionary) and sparse representation matrices of different information domains are obtained for each view information and privilege information through dictionary learning. Then, we obtain consistency information from the regularization terms of the two different sets of synthetic dictionaries and construct a LUPI (Learning using privileged information) classifier by the sparse representation. In addition, we use alternating convex optimization and Lagrange multiplier methods to optimize the model and prove its convergence. In the experiment, we did a number of experiments comparing this method with similar recent methods. The experimental results show that the MVDL-PI method is superior to other methods in terms of stability and classification accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "2075417413",
                    "name": "Peng Sun"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                },
                {
                    "authorId": "3236193",
                    "name": "Shilei Zhao"
                },
                {
                    "authorId": "2203933631",
                    "name": "Xiaokai Li"
                },
                {
                    "authorId": "2068930595",
                    "name": "Tiantian Peng"
                },
                {
                    "authorId": "2203965391",
                    "name": "Zhiyu Zheng"
                },
                {
                    "authorId": "2156084056",
                    "name": "Yong-yi Huang"
                }
            ]
        },
        {
            "paperId": "450ee516b104e3d276283bc366a7695474c1f2ef",
            "title": "A Variational Inference Method for Few-Shot Learning",
            "abstract": "Existing few-shot learning (FSL) methods usually treat each sample as a single feature point or utilize intra-class feature transformation to augment features. However, few-shot novel features are always vulnerable to noise, intra-class features have large variance and the direction of intra-class feature transformations is uncontrollable, which result in degradation of FSL models. Besides, existing FSL methods are one-generation based which do not utilize the prior knowledge obtained in the prior generation model to generate more robust posterior model in FSL and lack the interpretability in FSL. In this paper, we propose a novel two-generation based Latent Feature Augmentation and Distribution Regularization framework (LFADR) including prior relation net (PRN) and vae-based posterior relation net (VPORN) to generate a more robust VPORN based on PRN by transferring the prior knowledge in FSL. Firstly, we utilize a simple single-original-feature-point-based PRN to generate the more informative prior knowledge. We then propose a regularized-distribution-based VPORN driven by VAE to augment latent features by sampling from regularized class-specific distribution based on the prior knowledge transferred from PRN in order to guarantee and control the diversity of intra-class features which avoids uncontrollable feature transformations and reduces the variance of intra-class features and the impact of noise. As a result, LFADR can learn more key and robust intra-class and discriminative inter-class features and make decision boundary clearer in FSL, which is optimized as a variational inference problem. Furthermore, we analyse the feasibility and effectiveness of our framework based on Hoeffding\u2019s inequality and Chernoff\u2019s bounding method. Finally, experimental results validate our theoretical analysis and the effectiveness of our proposed FSL framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2137881041",
                    "name": "Jian Xu"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                }
            ]
        },
        {
            "paperId": "967da3a7fa32e316c05fd2745cc79fd388861f23",
            "title": "Ordinal Regression With Pinball Loss",
            "abstract": "Ordinal regression (OR) aims to solve multiclass classification problems with ordinal classes. Support vector OR (SVOR) is a typical OR algorithm and has been extensively used in OR problems. In this article, based on the characteristics of OR problems, we propose a novel pinball loss function and present an SVOR method with pinball loss (pin-SVOR). Pin-SVOR is fundamentally different from traditional SVOR with hinge loss. Traditional SVOR employs the hinge loss function, and the classifier is determined by only a few data points near the class boundary, called support vectors, which may lead to a noise sensitive and re-sampling unstable classifier. Distinctively, pin-SVOR employs the pinball loss function. It attaches an extra penalty to correctly classified data that lies inside the class, such that all the training data is involved in deciding the classifier. The data near the middle of each class has a small penalty, and that near the class boundary has a large penalty. Thus, the training data tend to lie near the middle of each class instead of on the class boundary, which leads to scatter minimization in the middle of each class and noise insensitivity. The experimental results show that pin-SVOR has better classification performance than state-of-the-art OR methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2190296671",
                    "name": "Guangzheng Zhong"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "151470822",
                    "name": "Xiangjun Kong"
                }
            ]
        },
        {
            "paperId": "b7f9a2fd91a44ba5a4458d37050e2e9ee1e3f6d5",
            "title": "A Ranking Based Multi-View Method for Positive and Unlabeled Graph Classification",
            "abstract": "Graph classification becomes an active research problem in these years, since it can deal with the situation where objects contain structure and rich content information. Most of the previous works focus on graph classification by assuming both positive graphs and negative graphs are available. However, in some case of real-world applications, we always collect the positive graphs and a number of the unlabeled graphs, which is referred as the positive and unlabeled graph learning. Moreover, existing graph classification methods are limited to the case where the graph is described from one perspective. In order to address these problems, this paper proposes a new approach, called multi-view positive and unlabeled graph classification (MVPUG). It combines the strategy of cost-sensitive by introducing similarity weight of graphs, which can control the preference of the penalty for different graphs. And it incorporates the different representations of the graph, which exploits the consensus principle and the complementarity principle among different views of graphs. Extensive experiments on real life datasets have shown that our proposed MVPUG can achieve a better performance for multi-view positive and unlabeled graph classification in comparison to the state-of-the-art graph classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1380211807",
                    "name": "Zhiyong Che"
                },
                {
                    "authorId": "2064916754",
                    "name": "Haowen Zhong"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                }
            ]
        },
        {
            "paperId": "f408ece61ff06460a0ddbb6c2278744f67ecb7cd",
            "title": "An Efficient Transfer Learning Method with Auxiliary Information",
            "abstract": "Transfer learning (TL) is an information reuse learning tool, which can help us learn better classification effect than traditional single task learning, because transfer learning can share information within the task-to-task model. Most TL algorithms are studied in the field of data improvement, doing some data extraction and transformation. However, it ignores that existing the additional information to improve the model\u2019s accuracy, like Universum samples in the training data with privileged information. In this article, we focus on considering prior data to improve the TL algorithm, and the additional features also called privileged information are incorporated into the learning to improve the learning paradigm. In addition, we also carry out the Universum samples which do not belong to any indicated categories into the transfer learning paradigm to improve the utilization of prior knowledge. We propose a new TL Model (PU-TLSVM), in which each task with corresponding privileged features and Universum data is considered in the proposed model, so as to apply tasks with a priori data to the training stage. Then, we use Lagrange duality theorem to optimize our model to obtain the optimal discriminant for target task classification. Finally, we make a lot of predictions and tests to compare the actual effectiveness of the proposed method with the previous methods. The experiment results indicate that the proposed method is more effective and robust than other baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "2179441160",
                    "name": "Liangjiao Li"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                },
                {
                    "authorId": "2148897802",
                    "name": "Kai Wang"
                },
                {
                    "authorId": "2230666594",
                    "name": "Jian Hu"
                },
                {
                    "authorId": "2155882061",
                    "name": "Junrui Liu"
                },
                {
                    "authorId": "2109279821",
                    "name": "Qihang Chen"
                },
                {
                    "authorId": "40372969",
                    "name": "Ruihong Huang"
                }
            ]
        },
        {
            "paperId": "16f20c1d3fcf71a04eebd69efd32e68f186737d5",
            "title": "A Multitask Latent Feature Augmentation Method for Few-Shot Learning",
            "abstract": "Few-shot learning (FSL) aims to learn novel concepts quickly from a few novel labeled samples with the transferable knowledge learned from base dataset. The existing FSL methods usually treat each sample as a single feature point in embedding space and classify through one single comparison task. However, the few-shot single feature points on the novel meta-testing episode are still vulnerable to noise easily although with the good transferable knowledge, because the novel categories are never seen on base dataset. Besides, the existing FSL models are trained by only one single comparison task and ignore that different semantic feature maps have different weights on different comparison objects and tasks, which cannot take full advantage of the valuable information from different multiple comparison tasks and objects to make the latent features (LFs) more robust based on only few-shot samples. In this article, we propose a novel multitask LF augmentation (MTLFA) framework to learn the meta-knowledge of generalizing key intraclass and distinguishable interclass sample features from only few-shot samples through an LF augmentation (LFA) module and a multitask (MT) framework. Our MTLFA treats the support features as sampling from the class-specific LF distribution, enhancing the diversity of support features and reducing the impact of noise based on few-shot support samples. Furthermore, an MT framework is introduced to obtain more valuable comparison-task-related and episode-related comparison information from multiple different comparison tasks in which different semantic feature maps have different weights, adjusting the prior LFs and generating the more robust and effective episode-related classifier. Besides, we analyze the feasibility and effectiveness of MTLFA from theoretical views based on the Hoeffding\u2019s inequality and the Chernoff\u2019s bounding method. Extensive experiments conducted on three benchmark datasets demonstrate that the MTLFA achieves the state-of-the-art performance in FSL. The experimental results verify our theoretical analysis and the effectiveness and robustness of MTLFA framework in FSL.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2137881041",
                    "name": "Jian Xu"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                }
            ]
        },
        {
            "paperId": "3b82944d8f0ef6aa1649f758cc759b702a9c9b6a",
            "title": "A Separating Embedding Space Based Relation Network with RGB Modality Only for Cloth-Changing Person Re-Identification",
            "abstract": "The Cloth-changing person re-identification (CC-ReID) is more challenging than person re-identification (Re-ID) since the cloth-relevant features are unreliable. The current CC-ReID methods usually utilize some human parsing techniques such as semantic segmentation to guide the model to learn more cloth-irrelevant feature cues. However, the human parsing models are not necessarily reliable. For this, we propose a Separating Embedding Space based Relation Network (SESRN) for CC-ReID. Firstly, we use pairs of images as input of the model and consider the relation between them in SESRN instead of a single image that the existing CC-ReID models use. Secondly, we propose to separate the common feature embedding space outputted from the common backbone into two embedding subspaces including the cloth-irrelevant feature embedding subspace and cloth-related feature embedding subspace without using any human parsing techniques since we think that they are unreliable and introduce noise into model. Thirdly, we generate the different feature map weights on different subspaces or different comparison pairs on the same subspace, which is a simple and effective feature map visualization and analysis framework in CC-ReID. Finally, the extensive experiments show the effectiveness and robustness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2137880778",
                    "name": "Jian Xu"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                }
            ]
        },
        {
            "paperId": "5d0977661ec97d1d7a94481b6b966c98cc596864",
            "title": "A Convex Model for Support Vector Distance Metric Learning",
            "abstract": "Distance metric learning (DML) aims to learn a distance metric to process the data distribution. However, most of the existing methods are <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>NN DML methods and employ the <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>NN model to classify the test instances. The drawback of <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>NN DML is that all training instances need to be accessed and stored to classify the test instances, and the classification performance is influenced by the setting of the nearest neighbor number <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>. To solve these problems, there are several DML methods that employ the SVM model to classify the test instances. However, all of them are nonconvex and the convex support vector DML method has not been explicitly proposed. In this article, we propose a convex model for support vector DML (CSV-DML), which is capable of replacing the <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>NN model of DML with the SVM model. To make CSV-DML can use the most kernel functions of the existing SVM methods, a nonlinear mapping is used to map the original instances into a feature space. Since the explicit form of nonlinear mapped instances is unknown, the original instances are further transformed into the kernel form, which can be calculated explicitly. CSV-DML is constructed to work directly on the kernel-transformed instances. Specifically, we learn a specific Mahalanobis distance metric from the kernel-transformed training instances and train a DML-based separating hyperplane based on it. An iterated approach is formulated to optimize CSV-DML, which is based on generalized block coordinate descent and can converge to the global optimum. In CSV-DML, since the dimension of kernel-transformed instances is only related to the number of original training instances, we develop a novel parameter reduction scheme for reducing the feature dimension. Extensive experiments show that the proposed CSV-DML method outperforms the previous methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "32715231",
                    "name": "Yibang Ruan"
                },
                {
                    "authorId": "1720010",
                    "name": "Yanshan Xiao"
                },
                {
                    "authorId": "145586380",
                    "name": "Z. Hao"
                },
                {
                    "authorId": "144330453",
                    "name": "Bo Liu"
                }
            ]
        }
    ]
}