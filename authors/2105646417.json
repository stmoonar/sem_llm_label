{
    "authorId": "2105646417",
    "papers": [
        {
            "paperId": "04a2b2ef2d5efcb71a745e72f61435a6d799d9ce",
            "title": "Utility-oriented Reranking with Counterfactual Context",
            "abstract": "As a critical task for large-scale commercial recommender systems, reranking rearranges items in the initial ranking lists from the previous ranking stage to better meet users\u2019 demands. Foundational work in reranking has shown the potential of improving recommendation results by uncovering mutual influence among items. However, rather than considering the context of initial lists as most existing methods do, an ideal reranking algorithm should consider the counterfactual context \u2013 the position and the alignment of the items in the reranked lists. In this work, we propose a novel pairwise reranking framework, Utility-oriented Reranking with Counterfactual Context (URCC), which maximizes the overall utility after reranking efficiently. Specifically, we first design a utility-oriented evaluator, which applies Bi-LSTM and graph attention mechanism to estimate the listwise utility via the counterfactual context modeling. Then, under the guidance of the evaluator, we propose a pairwise reranker model to find the most suitable position for each item by swapping misplaced item pairs. Extensive experiments on two benchmark datasets and a proprietary real-world dataset demonstrate that URCC significantly outperforms the state-of-the-art models in terms of both relevance-based metrics and utility-based metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056826850",
                    "name": "Yunjia Xi"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2240536007",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2116621589",
                    "name": "Qing Liu"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2237958078",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "092f833b61414b6fe314b9695367df9f8a1cf324",
            "title": "Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation",
            "abstract": "We primarily focus on the field of large language models (LLMs) for recommendation, which has been actively explored recently and poses a significant challenge in effectively enhancing recommender systems with logical reasoning abilities and open-world knowledge. Current mainstream efforts mainly center around injecting personalized information from recommendation models into LLMs by customizing input templates or aligning representations between semantic and recommendation spaces at the prediction layer. However, they face three significant limitations: (1) LoRA is mostly used as a core component in existing works, but personalization is not well established in LoRA parameters as the LoRA matrix shared by every user may not cater to different users' characteristics, leading to suboptimal performance. (2) Although lifelong personalized behavior sequences are ideal for personalization, their use raises effectiveness and efficiency issues since LLMs require escalating training and inference time to extend text lengths. (3) Existing approaches aren't scalable for large datasets due to training efficiency constraints. Thus, LLMs only see a small fraction of the datasets (e.g., less than 10%) instead of the whole datasets, limiting their exposure to the full training space. To address these problems, we propose RecLoRA. This model incorporates a Personalized LoRA module that maintains independent LoRAs for different users and a Long-Short Modality Retriever that retrieves different history lengths for different modalities, significantly improving performance while adding minimal time cost. Furthermore, we design a Few2Many Learning Strategy, using a conventional recommendation model as a lens to magnify small training spaces to full spaces. Extensive experiments on public datasets demonstrate the efficacy of our RecLoRA compared to existing baseline models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296232413",
                    "name": "Jiachen Zhu"
                },
                {
                    "authorId": "2144908858",
                    "name": "Jianghao Lin"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2304552745",
                    "name": "Rong Shan"
                },
                {
                    "authorId": "2315165729",
                    "name": "Jieming Zhu"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2237958078",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                }
            ]
        },
        {
            "paperId": "1cffb1289d048caecb939ebbbb143ed863d6712f",
            "title": "RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation",
            "abstract": "LLM agents enhanced by tree search algorithms have yielded notable performances in code generation. However, current search algorithms in this domain suffer from low search quality due to several reasons: 1) Ineffective design of the search space for the high-reasoning demands of code generation tasks, 2) Inadequate integration of code feedback with the search algorithm, and 3) Poor handling of negative feedback during the search, leading to reduced search efficiency and quality. To address these challenges, we propose to search for the reasoning process of the code and use the detailed feedback of code execution to refine erroneous thoughts during the search. In this paper, we introduce RethinkMCTS, which employs the Monte Carlo Tree Search (MCTS) algorithm to conduct thought-level searches before generating code, thereby exploring a wider range of strategies. More importantly, we construct verbal feedback from fine-grained code execution feedback to refine erroneous thoughts during the search. This ensures that the search progresses along the correct reasoning paths, thus improving the overall search quality of the tree by leveraging execution feedback. Through extensive experiments, we demonstrate that RethinkMCTS outperforms previous search-based and feedback-based code generation baselines. On the HumanEval dataset, it improves the pass@1 of GPT-3.5-turbo from 70.12 to 89.02 and GPT-4o-mini from 87.20 to 94.51. It effectively conducts more thorough exploration through thought-level searches and enhances the search quality of the entire tree by incorporating rethink operation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260837684",
                    "name": "Qingyao Li"
                },
                {
                    "authorId": "2154454480",
                    "name": "Wei Xia"
                },
                {
                    "authorId": "1780721965",
                    "name": "Kounianhua Du"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2282544603",
                    "name": "Yasheng Wang"
                },
                {
                    "authorId": "2317033414",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                }
            ]
        },
        {
            "paperId": "4d24f1dcf52cea69277ede519b3c27969fa93a47",
            "title": "Large Language Models Make Sample-Efficient Recommender Systems",
            "abstract": "Large language models (LLMs) have achieved remarkable progress in the field of natural language processing (NLP), demonstrating remarkable abilities in producing text that resembles human language for various tasks. This opens up new opportunities for employing them in recommender systems (RSs). In this paper, we specifically examine the sample efficiency of LLM-enhanced recommender systems, which pertains to the model's capacity to attain superior performance with a limited quantity of training data. Conventional recommendation models (CRMs) often need a large amount of training data because of the sparsity of features and interactions. Hence, we propose and verify our core viewpoint: Large Language Models Make Sample-Efficient Recommender Systems. We propose a simple yet effective framework (i.e., Laser) to validate the viewpoint from two aspects: (1) LLMs themselves are sample-efficient recommenders; and (2) LLMs, as feature generators and encoders, make CRMs more sample-efficient. Extensive experiments on two public datasets show that Laser requires only a small fraction of training samples to match or even surpass CRMs that are trained on the entire training set, demonstrating superior sample efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144908858",
                    "name": "Jianghao Lin"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2304552745",
                    "name": "Rong Shan"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2237958078",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                }
            ]
        },
        {
            "paperId": "52dc538cf0f0b979105712ae073ca125602cda25",
            "title": "AIE: Auction Information Enhanced Framework for CTR Prediction in Online Advertising",
            "abstract": "Click-Through Rate (CTR) prediction is a fundamental technique for online advertising recommendation and the complex online competitive auction process also brings many difficulties to CTR optimization. Recent studies have shown that introducing posterior auction information contributes to the performance of CTR prediction. However, existing work doesn't fully capitalize on the benefits of auction information and overlooks the data bias brought by the auction, leading to biased and suboptimal results. To address these limitations, we propose Auction Information Enhanced Framework (AIE) for CTR prediction in online advertising, which delves into the problem of insufficient utilization of auction signals and first reveals the auction bias. Specifically, AIE introduces two pluggable modules, namely Adaptive Market-price Auxiliary Module (AM2) and Bid Calibration Module (BCM), which work collaboratively to excavate the posterior auction signals better and enhance the performance of CTR prediction. Furthermore, the two proposed modules are lightweight, model-agnostic, and friendly to inference latency. Extensive experiments are conducted on a public dataset and an industrial dataset to demonstrate the effectiveness and compatibility of AIE. Besides, a one-month online A/B test in a large-scale advertising platform shows that AIE improves the base model by 5.76% and 2.44% in terms of eCPM and CTR, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290248265",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2115802321",
                    "name": "Chenxu Zhu"
                },
                {
                    "authorId": "2238203237",
                    "name": "Menghui Zhu"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2287873067",
                    "name": "Muyu Zhang"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "a350aa4ee586cac36b92cb8d1a8adc070a90ccb6",
            "title": "DisCo: Towards Harmonious Disentanglement and Collaboration between Tabular and Semantic Space for Recommendation",
            "abstract": "Recommender systems play important roles in various applications such as e-commerce, social media, etc. Conventional recommendation methods usually model the collaborative signals within the tabular representation space. Despite the personalization modeling and the efficiency, the latent semantic dependencies are omitted. Methods that introduce semantics into recommendation then emerge, injecting knowledge from the semantic representation space where the general language understanding are compressed. However, existing semantic-enhanced recommendation methods focus on aligning the two spaces, during which the representations of the two spaces tend to get close while the unique patterns are discarded and not well explored. In this paper, we propose DisCo to Disentangle the unique patterns from the two representation spaces and Collaborate the two spaces for recommendation enhancement, where both the specificity and the consistency of the two spaces are captured. Concretely, we propose 1) a dual-side attentive network to capture the intra-domain patterns and the inter-domain patterns, 2) a sufficiency constraint to preserve the task-relevant information of each representation space and filter out the noise, and 3) a disentanglement constraint to avoid the model from discarding the unique information. These modules strike a balance between disentanglement and collaboration of the two representation spaces to produce informative pattern vectors, which could serve as extra features and be appended to arbitrary recommendation backbones for enhancement. Experiment results validate the superiority of our method against different models and the compatibility of DisCo over different backbones. Various ablation studies and efficiency analysis are also conducted to justify each model component.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1780721965",
                    "name": "Kounianhua Du"
                },
                {
                    "authorId": "2304517128",
                    "name": "Jizheng Chen"
                },
                {
                    "authorId": "2144908858",
                    "name": "Jianghao Lin"
                },
                {
                    "authorId": "2056826850",
                    "name": "Yunjia Xi"
                },
                {
                    "authorId": "2283141638",
                    "name": "Hangyu Wang"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                }
            ]
        },
        {
            "paperId": "ac457964969cdf99650acacb65cd84985eb84863",
            "title": "Tired of Plugins? Large Language Models Can Be End-To-End Recommenders",
            "abstract": "Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose a novel strategy to structure all items into an item tree, which can be dynamically updated and effectively retrieved. UniLLMRec shows promising zero-shot results in comparison with conventional supervised models. Additionally, it boasts high efficiency, reducing the input token need by 86% compared to existing LLM-based models. Such efficiency not only accelerates task completion but also optimizes resource utilization. To facilitate model understanding and to ensure reproducibility, we have made our code publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294381452",
                    "name": "Wenlin Zhang"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "ae1cd3e1db5268dd77d10924717b87c7eb8b7c7a",
            "title": "All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era",
            "abstract": "Recommender systems (RS) are vital for managing information overload and delivering personalized content, responding to users' diverse information needs. The emergence of large language models (LLMs) offers a new horizon for redefining recommender systems with vast general knowledge and reasoning capabilities. Standing across this LLM era, we aim to integrate recommender systems into a broader picture, and pave the way for more comprehensive solutions for future research. Therefore, we first offer a comprehensive overview of the technical progression of recommender systems, particularly focusing on language foundation models and their applications in recommendation. We identify two evolution paths of modern recommender systems -- via list-wise recommendation and conversational recommendation. These two paths finally converge at LLM agents with superior capabilities of long-term memory, reflection, and tool intelligence. Along these two paths, we point out that the information effectiveness of the recommendation is increased, while the user's acquisition cost is decreased. Technical features, research methodologies, and inherent challenges for each milestone along the path are carefully investigated -- from traditional list-wise recommendation to LLM-enhanced recommendation to recommendation with LLM agents. Finally, we highlight several unresolved challenges crucial for the development of future personalization technologies and interfaces and discuss the future prospects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2290027703",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2260810851",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2297898895",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "79494403",
                    "name": "Jiarui Qin"
                },
                {
                    "authorId": "2284295184",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2311410517",
                    "name": "Yaxiong Wu"
                },
                {
                    "authorId": "2298987734",
                    "name": "Hao Zhang"
                }
            ]
        },
        {
            "paperId": "5fa0581fb09717a0966a4afbeceae5fab529115a",
            "title": "Personalized Diversification for Neural Re-ranking in Recommendation",
            "abstract": "Re-ranking, as the final stage of the multi-stage recommender systems (MRS), aims at modeling the listwise context and the cross-item interactions between the candidate items. The objective is usually the overall utility (e.g., total clicks or revenue) of the re-ranked list, which is determined not only by the relevance, but also by the diversity of the list. However, existing methods equally promote diversity for all users and often compromise the relevance ranking. In reality, users have different diversity preferences and we should diversify the list tailored to individual users\u2019 interests and needs. Users\u2019 behavior history contains rich information which may be used for inferring their diversity preferences, but has rarely been explored in existing work. In this work, we propose a novel neural re-ranking with personalized diversification method (dubbed RAPID) to address the above challenge. RAPID explicitly models each user\u2019s preference distribution over different topics by exploiting the intra- and inter-topic interactions from the user\u2019s behavior history. The personalized diversity gain brought by each candidate item is then measured by the item\u2019s marginal diversity and the learned personalized preference. The relevance and the personalized diversity are jointly optimized in an end-to-end manner to automatically manage the relevance-diversity tradeoff. Experimental results on two public datasets and a proprietary dataset show that RAPID outperforms the state-of-the-art with the highest utility and the best relevance-diversity tradeoff. We further prove that RAPID has a regret bound of $\\tilde O(\\sqrt n )$ on utility, which provides theoretical guarantee that its performance is near-optimal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2056826850",
                    "name": "Yunjia Xi"
                },
                {
                    "authorId": "79494403",
                    "name": "Jiarui Qin"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "1491648207",
                    "name": "Shuai Li"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "144142354",
                    "name": "Rui Zhang"
                }
            ]
        },
        {
            "paperId": "62253f0dc5f6c210d56cef3e7231e7e033997620",
            "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction",
            "abstract": "With the widespread application of online advertising systems, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume (e.g., billions of user click logs). The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since click signals are not sufficient enough for the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs and learn more robust and effective representations. However, current works on this line are still preliminary and rudimentary, leaving self-supervised learning for CTR prediction still an open question. To this end, we propose a Model-agnostic Pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and we also introduce Noise Contrastive Estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world million-level datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods over several strong baselines, and achieve new state-of-the-art in terms of both performance and efficiency for CTR prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144908858",
                    "name": "Jianghao Lin"
                },
                {
                    "authorId": "3404968",
                    "name": "Yanru Qu"
                },
                {
                    "authorId": "2109155646",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2156098229",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                }
            ]
        }
    ]
}