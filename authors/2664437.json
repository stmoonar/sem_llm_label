{
    "authorId": "2664437",
    "papers": [
        {
            "paperId": "4a78b5a53bec06aeaecb3fdf5951a476884a8645",
            "title": "Concept Discovery for Fast Adapatation",
            "abstract": "The advances in deep learning have enabled machine learning methods to outperform human beings in various areas, but it remains a great challenge for a well-trained model to quickly adapt to a new task. One promising solution to realize this goal is through meta-learning, also known as learning to learn, which has achieved promising results in few-shot learning. However, current approaches are still enormously different from human beings' learning process, especially in the ability to extract structural and transferable knowledge. This drawback makes current meta-learning frameworks non-interpretable and hard to extend to more complex tasks. We tackle this problem by introducing concept discovery to the few-shot learning problem, where we achieve more effective adaptation by meta-learning the structure among the data features, leading to a composite representation of the data. Our proposed method Concept-Based Model-Agnostic Meta-Learning (COMAML) has been shown to achieve consistent improvements in the structured data for both synthesized datasets and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "0d8353b8b756d4453301650bbed2977e0d46ef1b",
            "title": "Adversarial Graph Contrastive Learning with Information Regularization",
            "abstract": "Contrastive learning is an effective unsupervised method in graph representation learning. Recently, the data augmentation based contrastive learning method has been extended from images to graphs. However, most prior works are directly adapted from the models designed for images. Unlike the data augmentation on images, the data augmentation on graphs is far less intuitive and much harder to provide high-quality contrastive samples, which are the key to the performance of contrastive learning models. This leaves much space for improvement over the existing graph contrastive learning frameworks. In this work, by introducing an adversarial graph view and an information regularizer, we propose a simple but effective method, Adversarial Graph Contrastive Learning (ArieL), to extract informative contrastive samples within a reasonable constraint. It consistently outperforms the current graph contrastive learning methods in the node classification task over various real-world datasets and further improves the robustness of graph contrastive learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "e9d6cd3ef8d05f509121ad30f193f8c8fddf2d64",
            "title": "ArieL: Adversarial Graph Contrastive Learning",
            "abstract": "Contrastive learning is an effective unsupervised method in graph representation learning. The key component of contrastive learning lies in the construction of positive and negative samples. Previous methods usually utilize the proximity of nodes in the graph as the principle. Recently, the data-augmentation-based contrastive learning method has advanced to show great power in the visual domain, and some works have extended this method from images to graphs. However, unlike the data augmentation on images, the data augmentation on graphs is far less intuitive and it is much harder to provide high-quality contrastive samples, which leaves much space for improvement. In this work, by introducing an adversarial graph view for data augmentation, we propose a simple but effective method, Adversarial Graph Contrastive Learning (ArieL), to extract informative contrastive samples within reasonable constraints. We develop a new technique called information regularization for stable training and use subgraph sampling for scalability. We generalize our method from node-level contrastive learning to the graph level by treating each graph instance as a super-node. ArieL consistently outperforms the current graph contrastive learning methods for both node-level and graph-level classification tasks on real-world datasets. We further demonstrate that ArieL is more robust in the face of adversarial attacks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "24018646",
                    "name": "Yada Zhu"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "245d2b50f0a8b6d60a5741e87b64d881f85ec01d",
            "title": "X-GOAL: Multiplex Heterogeneous Graph Prototypical Contrastive Learning",
            "abstract": "Graphs are powerful representations for relations among objects, which have attracted plenty of attention in both academia and industry. A fundamental challenge for graph learning is how to train an effective Graph Neural Network (GNN) encoder without labels, which are expensive and time consuming to obtain. Contrastive Learning (CL) is one of the most popular paradigms to address this challenge, which trains GNNs by discriminating positive and negative node pairs. Despite the success of recent CL methods, there are still two under-explored problems. Firstly, how to reduce the semantic error introduced by random topology based data augmentations. Traditional CL defines positive and negative node pairs via the node-level topological proximity, which is solely based on the graph topology regardless of the semantic information of node attributes, and thus some semantically similar nodes could be wrongly treated as negative pairs. Secondly, how to effectively model the multiplexity of the real-world graphs, where nodes are connected by various relations and each relation could form a homogeneous graph layer. To solve these problems, we propose a novel multiplex heterogeneous graph prototypical contrastive leaning (X-GOAL) framework to extract node embeddings. X-GOAL is comprised of two components: the GOAL framework, which learns node embeddings for each homogeneous graph layer, and an alignment regularization, which jointly models different layers by aligning layer-specific node embeddings. Specifically, the GOAL framework captures the node-level information by a succinct graph transformation technique, and captures the cluster-level information by pulling nodes within the same semantic cluster closer in the embedding space. The alignment regularization aligns embeddings across layers at both node level and cluster level. We evaluate the proposed X-GOAL on a variety of real-world datasets and downstream tasks to demonstrate the effectiveness of the X-GOAL framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29860450",
                    "name": "Baoyu Jing"
                },
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "51178762",
                    "name": "Yuejia Xiang"
                },
                {
                    "authorId": "2145308154",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "2144837573",
                    "name": "Yu Chen"
                },
                {
                    "authorId": "8163721",
                    "name": "Hanghang Tong"
                }
            ]
        },
        {
            "paperId": "272b596bdb375906274a58fee14f22085bcf974f",
            "title": "Exploiting Long-Term Dependencies for Generating Dynamic Scene Graphs",
            "abstract": "Dynamic scene graph generation from a video is challenging due to the temporal dynamics of the scene and the inherent temporal fluctuations of predictions. We hypothesize that capturing long-term temporal dependencies is the key to effective generation of dynamic scene graphs. We propose to learn the long-term dependencies in a video by capturing the object-level consistency and inter-object relationship dynamics over object-level long-term tracklets using transformers. Experimental results demonstrate that our Dynamic Scene Graph Detection Transformer (DSG- DETR) outperforms state-of-the-art methods by a significant margin on the benchmark dataset Action Genome. Our ablation studies validate the effectiveness of each component of the proposed approach. The source code is available at https://github.com/Shengyu-Feng/DS G-DETR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "2906509",
                    "name": "Subarna Tripathi"
                },
                {
                    "authorId": "34516897",
                    "name": "H. Mostafa"
                },
                {
                    "authorId": "1678319",
                    "name": "M. Nassar"
                },
                {
                    "authorId": "2413238",
                    "name": "Somdeb Majumdar"
                }
            ]
        },
        {
            "paperId": "69e40b090c15a426957f2a8879fdfaa7f45052ff",
            "title": "Batch Reinforcement Learning Through Continuation Method",
            "abstract": "Many real-world applications of reinforcement learning (RL) require the agent to learn from a \ufb01xed set of trajectories, without collecting new interactions. Policy optimization under this setting is extremely challenging as: 1) the geometry of the objective function is hard to optimize ef\ufb01ciently; 2) the shift of data distributions causes high noise in the value estimation. In this work, we propose a simple yet effective policy iteration approach to batch RL using global optimization techniques known as continuation. By constraining the difference between the learned policy and the behavior policy that generates the \ufb01xed trajectories",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1857914",
                    "name": "Yijie Guo"
                },
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "7245737",
                    "name": "Nicolas Le Roux"
                },
                {
                    "authorId": "2226805",
                    "name": "Ed H. Chi"
                },
                {
                    "authorId": "2118338545",
                    "name": "Honglak Lee"
                },
                {
                    "authorId": "1743082",
                    "name": "Minmin Chen"
                }
            ]
        },
        {
            "paperId": "a28899f255c1ca35b6254adc1a0cd64fc20c2ce9",
            "title": "Memory Based Trajectory-conditioned Policies for Learning from Sparse Rewards",
            "abstract": "Reinforcement learning with sparse rewards is challenging because an agent can rarely obtain non-zero rewards and hence, gradient-based optimization of parameterized policies can be incremental and slow. Recent work demonstrated that using a memory buffer of previous successful trajectories can result in more effective policies. However, existing methods may overly exploit past successful experiences, which can encourage the agent to adopt sub-optimal and myopic behaviors. In this work, instead of focusing on good experiences with limited diversity, we propose to learn a trajectory-conditioned policy to follow and expand diverse past trajectories from a memory buffer. Our method allows the agent to reach diverse regions in the state space and improve upon the past trajectories to reach new states. We empirically show that our approach significantly outperforms count-based exploration methods (parametric approach) and self-imitation learning (parametric approach with non-parametric memory) on various complex tasks with local optima. In particular, without using expert demonstrations or resetting to arbitrary states, we achieve the state-of-the-art scores under five billion number of frames, on challenging Atari games such as Montezuma\u2019s Revenge and Pitfall.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1857914",
                    "name": "Yijie Guo"
                },
                {
                    "authorId": "2031471973",
                    "name": "Jongwook Choi"
                },
                {
                    "authorId": "3009779",
                    "name": "Marcin Moczulski"
                },
                {
                    "authorId": "2664437",
                    "name": "Shengyu Feng"
                },
                {
                    "authorId": "1751569",
                    "name": "Samy Bengio"
                },
                {
                    "authorId": "144739074",
                    "name": "Mohammad Norouzi"
                },
                {
                    "authorId": "1697141",
                    "name": "Honglak Lee"
                }
            ]
        }
    ]
}