{
    "authorId": "152252333",
    "papers": [
        {
            "paperId": "7687dcf2495c3d70ff0309592a3697d358f209d4",
            "title": "Ten Years after ImageNet: A 360{\\deg} Perspective on AI",
            "abstract": "It is ten years since neural networks made their spectacular comeback. Prompted by this anniversary, we take a holistic perspective on Artificial Intelligence (AI). Supervised Learning for cognitive tasks is effectively solved - provided we have enough high-quality labeled data. However, deep neural network models are not easily interpretable, and thus the debate between blackbox and whitebox modeling has come to the fore. The rise of attention networks, self-supervised learning, generative modeling, and graph neural networks has widened the application space of AI. Deep Learning has also propelled the return of reinforcement learning as a core building block of autonomous decision making systems. The possible harms made possible by new AI technologies have raised socio-technical issues such as transparency, fairness, and accountability. The dominance of AI by Big-Tech who control talent, computing resources, and most importantly, data may lead to an extreme AI divide. Failure to meet high expectations in high profile, and much heralded flagship projects like self-driving vehicles could trigger another AI winter.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2141768778",
                    "name": "Ahmed Ali"
                },
                {
                    "authorId": "152252333",
                    "name": "Wendy Hall"
                },
                {
                    "authorId": "2186981636",
                    "name": "Issa M. Khalil"
                },
                {
                    "authorId": "2187086383",
                    "name": "Xiaosong Ma"
                },
                {
                    "authorId": "1772206",
                    "name": "H. Sencar"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "2059979016",
                    "name": "Michael Wooldridge"
                },
                {
                    "authorId": "2151684774",
                    "name": "Tingyue Yu"
                }
            ]
        },
        {
            "paperId": "42d66c012d9f9327c737e16a3ed9e6d954b93ec9",
            "title": "Graph-Based Visual-Semantic Entanglement Network for Zero-Shot Image Recognition",
            "abstract": "Zero-shot learning uses semantic attributes to connect the search space of unseen objects. In recent years, although the deep convolutional network brings powerful visual modeling capabilities to the ZSL task, its visual features have severe pattern inertia and lack of representation of semantic relationships, which leads to severe bias and ambiguity. In response to this, we propose the Graph-based Visual-Semantic Entanglement Network to conduct graph modeling of visual features, which is mapped to semantic attributes by using a knowledge graph, it contains several novel designs: 1. it establishes a multi-path entangled network with the convolutional neural network (CNN) and the graph convolutional network (GCN), which input the visual features from CNN to GCN to model the implicit semantic relations, then GCN feedback the graph modeled information to CNN features; 2. it uses attribute word vectors as the target for the graph semantic modeling of GCN, which forms a self-consistent regression for graph modeling and supervise GCN to learn more personalized attribute relations; 3. it fuses and supplements the hierarchical visual-semantic features refined by graph modeling into visual embedding. Our method outperforms state-of-the-art approaches on multiple representative ZSL datasets: AwA2, CUB, and SUN by promoting the semantic linkage modelling of visual features.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2113664446",
                    "name": "Yang Hu"
                },
                {
                    "authorId": "9725901",
                    "name": "Guihua Wen"
                },
                {
                    "authorId": "144030084",
                    "name": "Adriane P. Chapman"
                },
                {
                    "authorId": "144599541",
                    "name": "Pei Yang"
                },
                {
                    "authorId": "51149455",
                    "name": "Mingnan Luo"
                },
                {
                    "authorId": "48615798",
                    "name": "Yingxue Xu"
                },
                {
                    "authorId": "46925647",
                    "name": "Dan Dai"
                },
                {
                    "authorId": "152252333",
                    "name": "Wendy Hall"
                }
            ]
        },
        {
            "paperId": "8d1a392200066bc7ef2ac1c78ecea6d2d5ac630d",
            "title": "Semantic Graph-enhanced Visual Network for Zero-shot Learning",
            "abstract": "Zero-shot learning uses semantic attributes to connect the search space of unseen objects. In recent years, although the deep convolutional network brings powerful visual modeling capabilities to the ZSL task, its visual features have severe pattern inertia and lack of representation of semantic relationships, which leads to severe bias and ambiguity. In response to this, we propose the Graph-based Visual-Semantic Entanglement Network to conduct graph modeling of visual features, which is mapped to semantic attributes by using a knowledge graph, it contains several novel designs: 1. it establishes a multi-path entangled network with the convolutional neural network (CNN) and the graph convolutional network (GCN), which input the visual features from CNN to GCN to model the implicit semantic relations, then GCN feedback the graph modeled information to CNN features; 2. it uses attribute word vectors as the target for the graph semantic modeling of GCN, which forms a self-consistent regression for graph modeling and supervise GCN to learn more personalized attribute relations; 3. it fuses and supplements the hierarchical visual-semantic features refined by graph modeling into visual embedding. By promoting the semantic linkage modeling of visual features, our method outperforms state-of-the-art approaches on multiple representative ZSL datasets: AwA2, CUB, and SUN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113664446",
                    "name": "Yang Hu"
                },
                {
                    "authorId": "9725901",
                    "name": "Guihua Wen"
                },
                {
                    "authorId": "144030084",
                    "name": "Adriane P. Chapman"
                },
                {
                    "authorId": "144599541",
                    "name": "Pei Yang"
                },
                {
                    "authorId": "51149455",
                    "name": "Mingnan Luo"
                },
                {
                    "authorId": "48615798",
                    "name": "Yingxue Xu"
                },
                {
                    "authorId": "46925647",
                    "name": "Dan Dai"
                },
                {
                    "authorId": "152252333",
                    "name": "Wendy Hall"
                }
            ]
        },
        {
            "paperId": "63d2a2f5661bcfde442185b082cff59d58e3b952",
            "title": "Inner-Imaging Networks: Put Lenses Into Convolutional Structure",
            "abstract": "Despite the tremendous success in computer vision, deep convolutional networks suffer from serious computation costs and redundancies. Although previous works address that by enhancing the diversities of filters, they have not considered the complementarity and the completeness of the internal convolutional structure. To respond to this problem, we propose a novel inner-imaging (InI) architecture, which allows relationships between channels to meet the above requirement. Specifically, we organize the channel signal points in groups using convolutional kernels to model both the intragroup and intergroup relationships simultaneously. A convolutional filter is a powerful tool for modeling spatial relations and organizing grouped signals, so the proposed methods map the channel signals onto a pseudoimage, like putting a lens into the internal convolution structure. Consequently, not only is the diversity of channels increased but also the complementarity and completeness can be explicitly enhanced. The proposed architecture is lightweight and easy to be implement. It provides an efficient self-organization strategy for convolutional networks to improve their performance. Extensive experiments are conducted on multiple benchmark datasets, including CIFAR, SVHN, and ImageNet. Experimental results verify the effectiveness of the InI mechanism with the most popular convolutional networks as the backbones.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113664446",
                    "name": "Yang Hu"
                },
                {
                    "authorId": "9725901",
                    "name": "Guihua Wen"
                },
                {
                    "authorId": "51149455",
                    "name": "Mingnan Luo"
                },
                {
                    "authorId": "46925647",
                    "name": "Dan Dai"
                },
                {
                    "authorId": "47415977",
                    "name": "Wenming Cao"
                },
                {
                    "authorId": "144861834",
                    "name": "Zhiwen Yu"
                },
                {
                    "authorId": "152252333",
                    "name": "Wendy Hall"
                }
            ]
        }
    ]
}