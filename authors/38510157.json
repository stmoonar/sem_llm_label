{
    "authorId": "38510157",
    "papers": [
        {
            "paperId": "4f452e6a453f4ccd8f6c1960a8291a0ad8e4c2ee",
            "title": "Exploring the Limitations of Detecting Machine-Generated Text",
            "abstract": "Recent improvements in the quality of the generations by large language models have spurred research into identifying machine-generated text. Systems proposed for the task often achieve high performance. However, humans and machines can produce text in different styles and in different domains, and it remains unclear whether machine generated-text detection models favour particular styles or domains. In this paper, we critically examine the classification performance for detecting machine-generated text by evaluating on texts with varying writing styles. We find that classifiers are highly sensitive to stylistic changes and differences in text complexity, and in some cases degrade entirely to random classifiers. We further find that detection systems are particularly susceptible to misclassify easy-to-read texts while they have high performance for complex texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "49843300",
                    "name": "Osama Mohammed Afzal"
                },
                {
                    "authorId": "2261493094",
                    "name": "Hawau Olamide Toyin"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2138053020",
                    "name": "Zeerak Talat"
                }
            ]
        },
        {
            "paperId": "9ff25b04f81d21f700deb5b386857840b81a1f23",
            "title": "ArabicMMLU: Assessing Massive Multitask Language Understanding in Arabic",
            "abstract": "The focus of language model evaluation has transitioned towards reasoning and knowledge-intensive tasks, driven by advancements in pretraining large models. While state-of-the-art models are partially trained on large Arabic texts, evaluating their performance in Arabic remains challenging due to the limited availability of relevant datasets. To bridge this gap, we present \\datasetname{}, the first multi-task language understanding benchmark for the Arabic language, sourced from school exams across diverse educational levels in different countries spanning North Africa, the Levant, and the Gulf regions. Our data comprises 40 tasks and 14,575 multiple-choice questions in Modern Standard Arabic (MSA) and is carefully constructed by collaborating with native speakers in the region. Our comprehensive evaluations of 35 models reveal substantial room for improvement, particularly among the best open-source models. Notably, BLOOMZ, mT0, LLaMA2, and Falcon struggle to achieve a score of 50%, while even the top-performing Arabic-centric model only achieves a score of 62.3%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2274084215",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2210193043",
                    "name": "Sara Shatnawi"
                },
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "2233498337",
                    "name": "Abdelrahman Boda Sadallah"
                },
                {
                    "authorId": "2284767001",
                    "name": "Aisha Alraeesi"
                },
                {
                    "authorId": "2284765679",
                    "name": "Khalid Almubarak"
                },
                {
                    "authorId": "25098419",
                    "name": "Zaid Alyafeai"
                },
                {
                    "authorId": "2284771123",
                    "name": "Neha Sengupta"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "114aefa57df10504967f23841f9c5f46271d8fca",
            "title": "FairGauge: A Modularized Evaluation of Bias in Masked Language Models",
            "abstract": "Prejudice is a pre-conceived depiction of an entity within a person's mind. It tends to devalue people as a consequence of their perceived membership in a social group. The origin of prejudice can be traced back to the categorization process people use to form a plausible perception of their surroundings. The process of constructing these perceptions generally results in prejudices, which authorizes inequalities to develop across a variety of social groups. In all their forms, biases can be relayed in language by generalizing a negative adjective onto an social group as a function of prejudgement. Using this reduced linguistic formulation, we set out to (1) create a benchmark of 23,736 prejudiced sentences that encompass a plethora of bias types including racism, sexism, classism, ethnic discrimination, and religious discrimination; (2) propose a prejudice score that incorporates both the masked prediction probability and the top-k index (rank) of the matched word; (3) conduct a case study, using our benchmark, to evaluate bias in three pre-trained language models: BERT, DistilBERT, and Context-Debias DistilBERT.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2264150375",
                    "name": "Fakhri Karray"
                }
            ]
        },
        {
            "paperId": "32614148882a0fc36fb7b22b5d201cc19d28eb5e",
            "title": "Multi-Plane Neural Radiance Fields for Novel View Synthesis",
            "abstract": "Novel view synthesis is a long-standing problem that revolves around rendering frames of scenes from novel camera viewpoints. Volumetric approaches provide a solution for modeling occlusions through the explicit 3D representation of the camera frustum. Multi-plane Images (MPI) are volumetric methods that represent the scene using front-parallel planes at distinct depths but suffer from depth discretization leading to a 2.D scene representation. Another line of approach relies on implicit 3D scene representations. Neural Radiance Fields (NeRF) utilize neural networks for encapsulating the continuous 3D scene structure within the network weights achieving photorealistic synthesis results, however, methods are constrained to per-scene optimization settings which are inefficient in practice. Multi-plane Neural Radiance Fields (MINE) open the door for combining implicit and explicit scene representations. It enables continuous 3D scene representations, especially in the depth dimension, while utilizing the input image features to avoid per-scene optimization. The main drawback of the current literature work in this domain is being constrained to single-view input, limiting the synthesis ability to narrow viewpoint ranges. In this work, we thoroughly examine the performance, generalization, and efficiency of single-view multi-plane neural radiance fields. In addition, we propose a new multiplane NeRF architecture that accepts multiple views to improve the synthesis results and expand the viewing range. Features from the input source frames are effectively fused through a proposed attention-aware fusion module to highlight important information from different viewpoints. Experiments show the effectiveness of attention-based fusion and the promising outcomes of our proposed method when compared to multi-view NeRF and MPI techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191239866",
                    "name": "Youssef Abdelkareem"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "1696863",
                    "name": "F. Karray"
                }
            ]
        },
        {
            "paperId": "397f42c604daaa393ab5d0b10525c57806fbddbb",
            "title": "GenLayNeRF: Generalizable Layered Representations with 3D Model Alignment for Multi-Human View Synthesis",
            "abstract": "Novel view synthesis (NVS) of multi-human scenes imposes challenges due to the complex inter-human occlusions. Layered representations handle the complexities by dividing the scene into multi-layered radiance fields, however, they are mainly constrained to per-scene optimization making them inefficient. Generalizable human view synthesis methods combine the pre-fitted 3D human meshes with image features to reach generalization, yet they are mainly designed to operate on single-human scenes. Another drawback is the reliance on multi-step optimization techniques for parametric pre-fitting of the 3D body models that suffer from misalignment with the images in sparse view settings causing hallucinations in synthesized views. In this work, we propose, GenLayNeRF, a generalizable layered scene representation for free-viewpoint rendering of multiple human subjects which requires no per-scene optimization and very sparse views as input. We divide the scene into multi-human layers anchored by the 3D body meshes. We then ensure pixel-level alignment of the body models with the input views through a novel end-to-end trainable module that carries out iterative parametric correction coupled with multi-view feature fusion to produce aligned 3D models. For NVS, we extract point-wise image-aligned and human-anchored features which are correlated and fused using self-attention and cross-attention modules. We augment low-level RGB values into the features with an attention-based RGB fusion module. To evaluate our approach, we construct two multi-human view synthesis datasets; DeepMultiSyn and ZJU-MultiHuman. The results indicate that our proposed approach outperforms generalizable and non-human per-scene NeRF methods while performing at par with layered per-scene methods without test time optimization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191239866",
                    "name": "Youssef Abdelkareem"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "1696863",
                    "name": "F. Karray"
                }
            ]
        },
        {
            "paperId": "8a53a8be83f1472b1f8c9bec04bc430d2bebda81",
            "title": "Can a Prediction\u2019s Rank Offer a More Accurate Quantification of Bias? A Case Study Measuring Sexism in Debiased Language Models",
            "abstract": "Pre-trained language models are known to inherit a plethora of contextual biases from their training data. These biases have proven to be projected onto a variety of downstream applications, making their detection and mitigation imminent. Limited research has been conducted to quantify specific bias types, such as benevolent sexism, which may be subtly present within the inferred connotations of a sentence. To this extent, our work aims to: (1) provide a benchmark of sexism sentences; (2) adapt two bias metrics: mean probability score and mean normalized rank; (3) conduct a case study to quantify and analyze sexism in base and de-biased masked language models. We find that debiasing, even in its most effective form (Auto-Debias), solely nullifies the probability score of biasing tokens, while retaining them in high ranks. Auto-Debias illustrates a 90%-96% reduction in mean probability scores from base to debiased models, while only a 3%-16% reduction in mean normalized ranks. Similar to the application of non-parametric statistical tests for data that does not follow a normal distribution, operating on the ranks of predictions rather than their probability scores offers a more representative bias measure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "1452348515",
                    "name": "Leen Al Qadi"
                },
                {
                    "authorId": "2292591921",
                    "name": "Youssef Nafea"
                },
                {
                    "authorId": "1696863",
                    "name": "F. Karray"
                }
            ]
        },
        {
            "paperId": "a1657fcbebeb1136bda71079b17ec117dc895329",
            "title": "Enhancing Video-based Learning Using Knowledge Tracing: Personalizing Students\u2019 Learning Experience with ORBITS",
            "abstract": "As the world regains its footing following the COVID-19 pandemic, academia is striving to consolidate the gains made in students\u2019 education experience. New technologies such as video-based learning have shown some early improvement in student learning and engagement. In this paper, we present ORBITS predictive engine at YOURIKA company, a video-based student support platform powered by knowledge tracing. In an exploratory case study of one master\u2019s level Speech Processing course at the Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI) in Abu Dhabi, half the students used the system while the other half did not. Student qualitative feedback was universally positive and compared the system favorably against current available methods. These findings support the use of artificial intelligence techniques to improve the student learning experience.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "8717625",
                    "name": "D. S. Calonge"
                },
                {
                    "authorId": "49205141",
                    "name": "P. Purnell"
                },
                {
                    "authorId": "2221316174",
                    "name": "Mark Thompson"
                }
            ]
        },
        {
            "paperId": "b5e754e2b53b6820a0c5895b56302c0e5389881c",
            "title": "Detecting Propaganda Techniques in Code-Switched Social Media Text",
            "abstract": "Propaganda is a form of communication intended to influence the opinions and the mindset of the public to promote a particular agenda. With the rise of social media, propaganda has spread rapidly, leading to the need for automatic propaganda detection systems. Most work on propaganda detection has focused on high-resource languages, such as English, and little effort has been made to detect propaganda for low-resource languages. Yet, it is common to find a mix of multiple languages in social media communication, a phenomenon known as code-switching. Code-switching combines different languages within the same text, which poses a challenge for automatic systems. With this in mind, here we propose the novel task of detecting propaganda techniques in code-switched text. To support this task, we create a corpus of 1,030 texts code-switching between English and Roman Urdu, annotated with 20 propaganda techniques, which we make publicly available. We perform a number of experiments contrasting different experimental setups, and we find that it is important to model the multilinguality directly (rather than using translation) as well as to use the right fine-tuning strategy. The code and the dataset are publicly available at https://github.com/mbzuai-nlp/propaganda-codeswitched-text",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134469787",
                    "name": "Muhammad Salman"
                },
                {
                    "authorId": "2057897896",
                    "name": "Asif Hanif"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "c175253d07a07e62815d9d902da8b92adaf1ab31",
            "title": "Arabic Dysarthric Speech Recognition Using Adversarial and Signal-Based Augmentation",
            "abstract": "Despite major advancements in Automatic Speech Recognition (ASR), the state-of-the-art ASR systems struggle to deal with impaired speech even with high-resource languages. In Arabic, this challenge gets amplified, with added complexities in collecting data from dysarthric speakers. In this paper, we aim to improve the performance of Arabic dysarthric automatic speech recognition through a multi-stage augmentation approach. To this effect, we first propose a signal-based approach to generate dysarthric Arabic speech from healthy Arabic speech by modifying its speed and tempo. We also propose a second stage Parallel Wave Generative (PWG) adversarial model that is trained on an English dysarthric dataset to capture language-independant dysarthric speech patterns and further augment the signal-adjusted speech samples. Furthermore, we propose a fine-tuning and text-correction strategies for Arabic Conformer at different dysarthric speech severity levels. Our fine-tuned Conformer achieved 18% Word Error Rate (WER) and 17.2% Character Error Rate (CER) on synthetically generated dysarthric speech from the Arabic commonvoice speech dataset. This shows significant WER improvement of 81.8% compared to the baseline model trained solely on healthy data. We perform further validation on real English dysarthric speech showing a WER improvement of 124% compared to the baseline trained only on healthy English LJSpeech dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1380273855",
                    "name": "Massa Baali"
                },
                {
                    "authorId": "2292194335",
                    "name": "Ibrahim Almakky"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "1696863",
                    "name": "F. Karray"
                }
            ]
        },
        {
            "paperId": "b0726dd009bae5f602a4e71ac5f9e8f53b6e385c",
            "title": "Advances in Preference-based Reinforcement Learning: A Review",
            "abstract": "Reinforcement Learning (RL) algorithms suffer from the dependency on accurately engineered reward functions to properly guide the learning agents to do the required tasks. Preference-based reinforcement learning (PbRL) addresses that by utilizing human preferences as feedback from the experts instead of numeric rewards. Due to its promising advantage over traditional RL, PbRL has gained more focus in recent years with many significant advances. In this survey, we present a unified PbRL framework to include the newly emerging approaches that improve the scalability and efficiency of PbRL. In addition, we give a detailed overview of the theoretical guarantees and benchmarking work done in the field, while presenting its recent applications in complex real-world tasks. Lastly, we go over the limitations of the current approaches and the proposed future research directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191239866",
                    "name": "Youssef Abdelkareem"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "1696863",
                    "name": "F. Karray"
                }
            ]
        }
    ]
}