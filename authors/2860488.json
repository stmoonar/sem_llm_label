{
    "authorId": "2860488",
    "papers": [
        {
            "paperId": "278927c0bdc11c778dcd2d9f91667d1f1db005b2",
            "title": "\u2018Eyes of a Hawk and Ears of a Fox\u2019: Part Prototype Network for Generalized Zero-Shot Learning",
            "abstract": "Many approaches in Generalized Zero-Shot Learning (GZSL) are built upon base models which consider only a single class attribute vector representation over the entire image. This is an oversimplification of the process of novel category recognition, where different regions of the image may have properties from different seen classes and thus have different predominant attributes. With this in mind, we take a fundamentally different approach: a pre-trained Vision-Language detector (VINVL) sensitive to attribute information is employed to efficiently obtain region features. A learned function maps the region features to region-specific attribute attention used to construct class part prototypes. We conduct experiments on a popular GZSL benchmark consisting of the CUB, SUN, and AWA2 datasets where our proposed Part Prototype Network (PPN) achieves promising results when compared with other popular base models. Corresponding ablation studies and analysis show that our approach is highly practical and has a distinct advantage over global attribute attention when localized proposals are available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150143507",
                    "name": "Joshua Forster Feinglass"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2292179537",
                    "name": "T. S. Jayram"
                },
                {
                    "authorId": "2237606621",
                    "name": "Yezhou Yang"
                }
            ]
        },
        {
            "paperId": "7954ab2cc4984b71467049ac6713f30645fbd2e3",
            "title": "On the Use of Anchoring for Training Vision Models",
            "abstract": "Anchoring is a recent, architecture-agnostic principle for training deep neural networks that has been shown to significantly improve uncertainty estimation, calibration, and extrapolation capabilities. In this paper, we systematically explore anchoring as a general protocol for training vision models, providing fundamental insights into its training and inference processes and their implications for generalization and safety. Despite its promise, we identify a critical problem in anchored training that can lead to an increased risk of learning undesirable shortcuts, thereby limiting its generalization capabilities. To address this, we introduce a new anchored training protocol that employs a simple regularizer to mitigate this issue and significantly enhances generalization. We empirically evaluate our proposed approach across datasets and architectures of varying scales and complexities, demonstrating substantial performance gains in generalization and safety metrics compared to the standard training protocol.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2123725394",
                    "name": "Kowshik Thopalli"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2121317308",
                    "name": "Yamen Mubarka"
                },
                {
                    "authorId": "3178630",
                    "name": "W. Sakla"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "9962ea51df04ca28df40f102575ea72770b93dfd",
            "title": "The Double-Edged Sword Of Ai Safety: Balancing Anomaly Detection and OOD Generalization Via Model Anchoring",
            "abstract": "Safe deployment of AI systems requires models to accurately flag anomalous or semantically unrelated data, while also generalizing to unseen shifts in the data distribution. While both these problems have been extensively studied, there is a risk for undesirable trade-off when exclusively optimizing for one of the objectives. In this paper, we systematically study this trade-off under the lens of model anchoring. Anchoring is a recently proposed training methodology that involves reparameterizing input data into anchor-residual pairs (anchors are drawn from the training data itself), thus establishing a combinatorial relationship with other samples in the training data. We make a surprising finding that the dual objectives of generalization and anomaly detection can be controlled by independently regularizing the model\u2019s dependency on the distribution of anchors and residuals respectively. This enables, for the first time, a finer control of the detection-generalization trade-off without requiring any additional data (e.g., outlier exposure) or computationally intensive modeling strategies (e.g., deep ensembling).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "e8c784ed09e1cdc546a281b541316a5b29813bd5",
            "title": "Exploring the Utility of Clip Priors for Visual Relationship Prediction",
            "abstract": "This work explores the challenges of leveraging large-scale vision language models, such as CLIP, for visual relationship prediction (VRP), a task vital in understanding the relations between objects in a scene based on both image features and text descriptors. Despite its potential, we find that CLIP\u2019s language priors are restrictive in effectively differentiating between various predicates for VRP. Towards this, we present CREPE (CLIP Representation Enhanced Predicate Estimation), which utilizes learnable prompts and a unique contrastive training strategy to derive reliable CLIP representations suited for VRP. CREPE can be seamlessly integrated into any VRP method. Our evaluations on the Visual Genome benchmark illustrate that using representations from CREPE significantly enhances the performance of vanilla VRP methods, such as UVTransE and VCTree. This enhancement is notable as CREPE can be seamlessly integrated into any VRP method, even without the need for additional calibration techniques, showcasing its efficacy as a powerful solution to VRP. CREPE\u2019s performance on the Unrel benchmark reveals strong generalization to diverse and previously unseen predicate occurrences, despite lacking explicit training on such examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2175280217",
                    "name": "Rakshith Subramanyam"
                },
                {
                    "authorId": "2292179537",
                    "name": "T. S. Jayram"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "0254468083ed3c8f079dfaf9f7fae3009b981f53",
            "title": "Exploring Inlier and Outlier Specification for Improved Medical OOD Detection",
            "abstract": "We address the crucial task of developing well-calibrated out-of-distribution (OOD) detectors, in order to enable safe deployment of medical image classifiers. Calibration enables deep networks to protect against trivial decision rules and controls over-generalization, thereby supporting model reliability. Given the challenges involved in curating appropriate calibration datasets, synthetic augmentations have gained significant popularity for inlier/outlier specification. Despite the rapid progress in data augmentation techniques, our study reveals a remarkable finding: the synthesis space and augmentation type play a pivotal role in effectively calibrating OOD detectors. Using the popular energy-based OOD detection framework, we find that the optimal protocol is to synthesize latent-space inliers along with diverse pixel-space outliers. Through extensive empirical studies conducted on multiple medical imaging benchmarks, we consistently demonstrate the superiority of our approach, achieving substantial improvements of 15% - 35% in AUROC compared to the state-of-the-art across various open-set recognition settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "2121317308",
                    "name": "Yamen Mubarka"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "145882781",
                    "name": "Deepta Rajan"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "089690f093eedcc1b2bffef145c2eae72dfedee1",
            "title": "PAGER: A Framework for Failure Analysis of Deep Regression Models",
            "abstract": "Safe deployment of AI models requires proactive detection of failures to prevent costly errors. To this end, we study the important problem of detecting failures in deep regression models. Existing approaches rely on epistemic uncertainty estimates or inconsistency w.r.t the training data to identify failure. Interestingly, we find that while uncertainties are necessary they are insufficient to accurately characterize failure in practice. Hence, we introduce PAGER (Principled Analysis of Generalization Errors in Regressors), a framework to systematically detect and characterize failures in deep regressors. Built upon the principle of anchored training in deep models, PAGER unifies both epistemic uncertainty and complementary manifold non-conformity scores to accurately organize samples into different risk regimes.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                },
                {
                    "authorId": "51881215",
                    "name": "V. Narayanaswamy"
                },
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                }
            ]
        },
        {
            "paperId": "0eab64bef16c50399d297ab2544e019487511e4d",
            "title": "Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks",
            "abstract": "While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$\\Delta$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced by our anchoring strategies when sampling hypotheses renders this unnecessary and allows us to support G-$\\Delta$UQ on pretrained models. Indeed, through extensive evaluation under covariate, concept and graph size shifts, we show that G-$\\Delta$UQ leads to better calibrated GNNs for node and graph classification. Further, it also improves performance on the uncertainty-based tasks of out-of-distribution detection and generalization gap estimation. Overall, our work provides insights into uncertainty estimation for GNNs, and demonstrates the utility of G-$\\Delta$UQ in obtaining reliable estimates.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "35505461",
                    "name": "Mark Heimann"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "28d71a7ecab18e598f088670581fa338718b13bc",
            "title": "The Surprising Effectiveness of Deep Orthogonal Procrustes Alignment in Unsupervised Domain Adaptation",
            "abstract": "Unsupervised domain adaptation (UDA) aims to transfer and adapt knowledge from a labeled source domain to an unlabeled target domain. Traditionally, geometry-based alignment methods, e.g., Orthogonal Procrustes Alignment (OPA), formed an important class of solutions to this problem. Despite their mathematical tractability, they rarely produce effective adaptation performance with the recent benchmarks. Instead, state-of-the-art approaches rely on sophisticated distribution alignment strategies such as adversarial training. In this paper, we show that, conventional OPA, when coupled with powerful deep feature extractors and a novel bi-level optimization formulation, is indeed an effective choice for handling challenging distribution shifts. When compared to existing UDA methods, our approach offers the following benefits: computational efficiency: Through the isolation of alignment and classifier training steps during adaptation, and the use of deep OPA, our approach is computationally very effective (typically requiring only 700 K parameters more than the base feature extractor as compared to millions of extra parameters required by state-of-the-art UDA baselines); (ii) data efficiency: Our approach does not require updating our feature extractor during adaptation and hence can be effective even with limited target data; (iii) improved generalization: The resulting models are intrinsically well-regularized and demonstrate effective generalization even in the challenging partial DA setting, i.e., target domain contains only a subset of the classes observed in the source domain.; and (iv) incremental training: Our approach allows progressive adaptation of models to novel domains (unseen during training) without requiring retraining of the model from scratch.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123725394",
                    "name": "Kowshik Thopalli"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "143655174",
                    "name": "P. Turaga"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                }
            ]
        },
        {
            "paperId": "5690d0e664c78ad3eced65f60a0a7f04926a3425",
            "title": "Cross-GAN Auditing: Unsupervised Identification of Attribute Level Similarities and Differences Between Pretrained Generative Models",
            "abstract": "Generative Adversarial Networks (GANs) are notoriously difficult to train especially for complex distributions and with limited data. This has driven the need for tools to audit trained networks in human intelligible format, for example, to identify biases or ensure fairness. Existing GAN audit tools are restricted to coarse-grained, modeldata comparisons based on summary statistics such as FID or recall. In this paper, we propose an alternative approach that compares a newly developed GAN against a prior baseline. To this end, we introduce Cross-GAN Auditing (xGA) that, given an established \u201creference\u201d GAN and a newly proposed \u201cclient\u201d GAN, jointly identifies intelligible attributes that are either common across both GANs, novel to the client GAN, or missing from the client GAN. This provides both users and model developers an intuitive assessment of similarity and differences between GANs. We introduce novel metrics to evaluate attribute-based GAN auditing approaches and use these metrics to demonstrate quantitatively that xGA outperforms baseline approaches. We also include qualitative results that illustrate the common, novel and missing attributes identified by xGA from GANs trained on a variety of image datasets 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2058026244",
                    "name": "Matthew Lyle Olson"
                },
                {
                    "authorId": "47130096",
                    "name": "Shusen Liu"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                },
                {
                    "authorId": "145466013",
                    "name": "P. Bremer"
                },
                {
                    "authorId": "37535697",
                    "name": "Weng-Keen Wong"
                }
            ]
        },
        {
            "paperId": "ba08f8521d6a60e6b2685e515e49b0724ecdfdef",
            "title": "Transformer-powered surrogates close the ICF simulation-experiment gap with extremely limited data",
            "abstract": "Recent advances in machine learning, specifically transformer architecture, have led to significant advancements in commercial domains. These powerful models have demonstrated superior capability to learn complex relationships and often generalize better to new data and problems. This paper presents a novel transformer-powered approach for enhancing prediction accuracy in multi-modal output scenarios, where sparse experimental data is supplemented with simulation data. The proposed approach integrates transformer-based architecture with a novel graph-based hyper-parameter optimization technique. The resulting system not only effectively reduces simulation bias, but also achieves superior prediction accuracy compared to the prior method. We demonstrate the efficacy of our approach on inertial confinement fusion experiments, where only 10 shots of real-world data are available, as well as synthetic versions of these experiments.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2270004310",
                    "name": "M. Olson"
                },
                {
                    "authorId": "2271340192",
                    "name": "Shusen Liu"
                },
                {
                    "authorId": "2064767378",
                    "name": "J. Thiagarajan"
                },
                {
                    "authorId": "69944782",
                    "name": "B. Kustowski"
                },
                {
                    "authorId": "2269823258",
                    "name": "Weng-Keen Wong"
                },
                {
                    "authorId": "2860488",
                    "name": "Rushil Anirudh"
                }
            ]
        }
    ]
}