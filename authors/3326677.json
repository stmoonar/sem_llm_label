{
    "authorId": "3326677",
    "papers": [
        {
            "paperId": "2d5cf32e524f5ffa635cb819ac78667212411544",
            "title": "Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval",
            "abstract": "Collecting well-matched multimedia datasets is crucial for training cross-modal retrieval models. However, in real-world scenarios, massive multimodal data are harvested from the Internet, which inevitably contains Partially Mis-matched Pairs (PMPs). Undoubtedly, such semantical irrelevant data will remarkably harm the cross-modal retrieval performance. Previous efforts tend to mitigate this problem by estimating a soft correspondence to down-weight the contribution of PMPs. In this paper, we aim to address this challenge from a new perspective: the potential semantic similarity among unpaired samples makes it possible to excavate useful knowledge from mismatched pairs. To achieve this, we propose L2RM, a general framework based on Optimal Transport (OT) that learns to rematch mismatched pairs. In detail, L2RM aims to generate refined alignments by seeking a minimal-cost transport plan across different modalities. To formalize the rematching idea in OT, first, we propose a self-supervised cost function that automatically learns from explicit similarity-cost mapping relation. Second, we present to model a partial OT problem while restricting the transport among false positives to further boost refined alignments. Extensive experiments on three benchmarks demonstrate our L2RM significantly improves the robustness against PMPs for existing models. The code is available at https://github.com/hhc1997/L2RM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2148302310",
                    "name": "Haocheng Han"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "1486400091",
                    "name": "Guangwen Dai"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2265463017",
                    "name": "Jingdong Wang"
                }
            ]
        },
        {
            "paperId": "d51475858cdefe1ecfba357a24a39850083f5399",
            "title": "MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts",
            "abstract": "Online movie review websites are valuable for information and discussion about movies. However, the massive spoiler reviews detract from the movie-watching experience, making spoiler detection an important task. Previous methods simply focus on reviews' text content, ignoring the heterogeneity of information in the platform. For instance, the metadata and the corresponding user's information of a review could be helpful. Besides, the spoiler language of movie reviews tends to be genre-specific, thus posing a domain generalization challenge for existing methods. To this end, we propose MMoE, a multi-modal network that utilizes information from multiple modalities to facilitate robust spoiler detection and adopts Mixture-of-Experts to enhance domain generalization. MMoE first extracts graph, text, and meta feature from the user-movie network, the review's textual content, and the review's metadata respectively. To handle genre-specific spoilers, we then adopt Mixture-of-Experts architecture to process information in three modalities to promote robustness. Finally, we use an expert fusion layer to integrate the features from different perspectives and make predictions based on the fused embedding. Experiments demonstrate that MMoE achieves state-of-the-art performance on two widely-used spoiler detection datasets, surpassing previous SOTA methods by 2.56% and 8.41% in terms of accuracy and F1-score. Further experiments also demonstrate MMoE's superiority in robustness and generalization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2290590861",
                    "name": "Zinan Zeng"
                },
                {
                    "authorId": "2220405893",
                    "name": "Sen Ye"
                },
                {
                    "authorId": "2290487420",
                    "name": "Zijian Cai"
                },
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2290529879",
                    "name": "Yuhan Liu"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "05cd2fdfd5ff9a7ccabeb0e99a0d5c726b95b5f0",
            "title": "Towards Real-Time Person Search with Invariant Feature Learning",
            "abstract": "Person search aims to locate a query person in a gallery of unconstrained scene images, which has many real-world applications. However, existing methods directly build off of advances in object detection for better performance rather than efficiency. Complex designs in heavy-weight detectors are redundant for person search. Furthermore, challenges in person search force existing methods to employ additional modules, which greatly deteriorates models\u2019 efficiency. In this paper, we propose a novel real-time framework for both effective and efficient person search, termed as InvarPS. InvarPS optimizes the over-designed network with invariant feature learning. Specifically, considering the main challenges (i.e., appearance changes, scale variations, and conflicting tasks) in person search, we propose an improved backbone, a Single-Scale Feature Fusion (SSFF) module and a Hierarchical Decoupling Head (HDH) to facilitate the model learning appearance, scale, and task invariant features, respectively. Extensive experiments demonstrate that our method achieves state-of-the-art performance with real-time speed (>100 FPS), which is significantly faster than any previous competitive approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2147134586",
                    "name": "Chengyou Jia"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2192703079",
                    "name": "Zhuohang Dang"
                },
                {
                    "authorId": "2840330",
                    "name": "Xiao Chang"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                }
            ]
        },
        {
            "paperId": "0c2d2ee6390f65f012f17897507bead26a2417c9",
            "title": "PSDiff: Diffusion Model for Person Search with Iterative and Collaborative Refinement",
            "abstract": "Dominant Person Search methods aim to localize and recognize query persons in a unified network, which jointly optimizes two sub-tasks, \\ie, pedestrian detection and Re-IDentification (ReID). Despite significant progress, current methods face two primary challenges: 1) the pedestrian candidates learned within detectors are suboptimal for the ReID task. 2) the potential for collaboration between two sub-tasks is overlooked. To address these issues, we present a novel Person Search framework based on the Diffusion model, PSDiff. PSDiff formulates the person search as a dual denoising process from noisy boxes and ReID embeddings to ground truths. Distinct from the conventional Detection-to-ReID approach, our denoising paradigm discards prior pedestrian candidates generated by detectors, thereby avoiding the local optimum problem of the ReID task. Following the new paradigm, we further design a new Collaborative Denoising Layer (CDL) to optimize detection and ReID sub-tasks in an iterative and collaborative way, which makes two sub-tasks mutually beneficial. Extensive experiments on the standard benchmarks show that PSDiff achieves state-of-the-art performance with fewer parameters and elastic computing overhead.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2147134586",
                    "name": "Chengyou Jia"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2192703079",
                    "name": "Zhuohang Dang"
                },
                {
                    "authorId": "1486400091",
                    "name": "Guangwen Dai"
                },
                {
                    "authorId": "2840330",
                    "name": "Xiao Chang"
                },
                {
                    "authorId": "1688516",
                    "name": "Jingdong Wang"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                }
            ]
        },
        {
            "paperId": "163a60d12dae7fc4781932d7dd7a3e8e9f0cec8a",
            "title": "HOFA: Twitter Bot Detection with Homophily-Oriented Augmentation and Frequency Adaptive Attention",
            "abstract": "Twitter bot detection has become an increasingly important and challenging task to combat online misinformation, facilitate social content moderation, and safeguard the integrity of social platforms. Though existing graph-based Twitter bot detection methods achieved state-of-the-art performance, they are all based on the homophily assumption, which assumes users with the same label are more likely to be connected, making it easy for Twitter bots to disguise themselves by following a large number of genuine users. To address this issue, we proposed HOFA, a novel graph-based Twitter bot detection framework that combats the heterophilous disguise challenge with a homophily-oriented graph augmentation module (Homo-Aug) and a frequency adaptive attention module (FaAt). Specifically, the Homo-Aug extracts user representations and computes a k-NN graph using an MLP and improves Twitter's homophily by injecting the k-NN graph. For the FaAt, we propose an attention mechanism that adaptively serves as a low-pass filter along a homophilic edge and a high-pass filter along a heterophilic edge, preventing user features from being over-smoothed by their neighborhood. We also introduce a weight guidance loss to guide the frequency adaptive attention module. Our experiments demonstrate that HOFA achieves state-of-the-art performance on three widely-acknowledged Twitter bot detection benchmarks, which significantly outperforms vanilla graph-based bot detection techniques and strong heterophilic baselines. Furthermore, extensive studies confirm the effectiveness of our Homo-Aug and FaAt module, and HOFA's ability to demystify the heterophilous disguise challenge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220405893",
                    "name": "Sen Ye"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2161968765",
                    "name": "Zhenyu Lei"
                },
                {
                    "authorId": "2053866609",
                    "name": "Ruijie He"
                },
                {
                    "authorId": "2169403637",
                    "name": "Hongrui Wang"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        },
        {
            "paperId": "1bc0dc96d745325d89ec5bee1da1541255e6d1eb",
            "title": "BotPercent: Estimating Twitter Bot Populations from Groups to Crowds",
            "abstract": "Twitter bot detection has become increasingly important in combating misinformation, identifying malicious online cam-paigns, and protecting the integrity of social media discourse. While existing bot detection literature mostly focuses on identifying individual bots, it remains underexplored how to estimate the proportion of bots within speci\ufb01c communities and social networks, which has great implications for both content moderators and day-to-day users. In this work, we propose community-level bot detection , a novel approach to estimating the amount of malicious interference in online communities by estimating the percentage of bot accounts. Speci\ufb01cally, we introduce BotPercent , an amalgamation of Twitter bot-detection datasets and feature, text, and graph-based models that overcome generalization issues in existing individual-level models, resulting in a more accurate community-level bot estimation. Experiments demonstrate that BotPercent achieves state-of-the-art community-level bot detection performance on the TwiBot-22 benchmark while showing great robustness towards the tampering of speci\ufb01c user features. Armed with BotPercent , we analyze bot rates in different Twitter groups and communities, such as all active Twitter users, users that interact with partisan news media, users that participate in Elon Musk\u2019s content moderation votes, and the political communities in different countries and regions. Our experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more. The BotPercent implementation is available at https://github.com/TamSiuhin/BotPercent",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "1947172233",
                    "name": "Melanie Sclar"
                },
                {
                    "authorId": "2114831715",
                    "name": "Herun Wan"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "1699545",
                    "name": "Yejin Choi"
                },
                {
                    "authorId": "2073587169",
                    "name": "Yulia Tsvetkov"
                }
            ]
        },
        {
            "paperId": "2150e336eee8a886e4a661169b60bfbccd323d51",
            "title": "Empower Post-hoc Graph Explanations with Information Bottleneck: A Pre-training and Fine-tuning Perspective",
            "abstract": "Researchers recently investigated to explain Graph Neural Networks (GNNs) on the access to a task-specific GNN, which may hinder their wide applications in practice. Specifically, task-specific explanation methods are incapable of explaining pretrained GNNs whose downstream tasks are usually inaccessible, not to mention giving explanations for the transferable knowledge in pretrained GNNs. Additionally, task-specific methods only consider target models' output in the label space, which are coarse-grained and insufficient to reflect the model's internal logic. To address these limitations, we consider a two-stage explanation strategy, i.e., explainers are first pretrained in a task-agnostic fashion in the representation space and then further fine-tuned in the task-specific label space and representation space jointly if downstream tasks are accessible. The two-stage explanation strategy endows post-hoc graph explanations with the applicability to pretrained GNNs where downstream tasks are inaccessible and the capacity to explain the transferable knowledge in the pretrained GNNs. Moreover, as the two-stage explanation strategy explains the GNNs in the representation space, the fine-grained information in the representation space also empowers the explanations. Furthermore, to achieve a trade-off between the fidelity and intelligibility of explanations, we propose an explanation framework based on the Information Bottleneck principle, named Explainable Graph Information Bottleneck (EGIB). EGIB subsumes the task-specific explanation and task-agnostic explanation into a unified framework. To optimize EGIB objective, we derive a tractable bound and adopt a simple yet effective explanation generation architecture. Based on the unified framework, we further theoretically prove that task-agnostic explanation is a relaxed sufficient condition of task-specific explanation, which indicates the transferability of task-agnostic explanations. Extensive experimental results demonstrate the effectiveness of our proposed explanation method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109656535",
                    "name": "Jihong Wang"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "47904366",
                    "name": "Yun Lin"
                },
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "2152487387",
                    "name": "J. Dong"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                }
            ]
        },
        {
            "paperId": "575f52846d0d7d7011fce462cbf31d82fdd67825",
            "title": "A Deep Multi-View Framework for Anomaly Detection on Attributed Networks (Extended Abstract)",
            "abstract": "Many existing anomaly detection methods on attributed networks do not seriously tackle the inherent multi-view property in attribute space but concatenate multiple views into a single feature vector, which inevitably ignores the incompatibility between heterogeneous views caused by their own statistical properties. In practice, the distinct but complementary information brought by multi-view data promises the potential for more effective anomaly detection than the efforts only based on single-view data. Furthermore, abnormal patterns naturally behave diversely in different views, which coincides with people\u2019s desire to discover specific abnormalities according to their preferences for views (attributes). Most existing methods cannot adapt to people\u2019s requirements as they fail to consider the idiosyncrasy of user preferences. Thus, in this paper, we propose a multi-view framework ALARM to incorporate user preferences into anomaly detection and simultaneously tackle heterogeneous attribute characteristics through multiple graph encoders and a well-designed aggregator that supports self-learning and user-guided learning. Experiments on synthetic and real-world datasets corroborate the desirable performance of ALARM and its effectiveness in supporting user-oriented anomaly detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1390961830",
                    "name": "Zhen Peng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2040455",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "51461421",
                    "name": "Luguo Xue"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                }
            ]
        },
        {
            "paperId": "661b0eb92213674c60c69139fdbdb8d80755cd3e",
            "title": "Counterfactual Generation Framework for Few-Shot Learning",
            "abstract": "Few-shot learning (FSL) that aims to recognize novel classes with few labeled samples is troubled by its data scarcity. Though recent works tackle FSL with data augmentation-based methods, these models fail to maintain the discrimination and diversity of the generated samples due to the distribution shift and intra-class bias caused by the data scarcity, therefore greatly undermining the performance. To this end, we use causal mechanisms, which are constant among independent variables across data distribution, to alleviate such effects. In this sense, we decompose the image information into two independent components: sample-specific and class-agnostic information, and further propose a novel Counterfactual Generation Framework (CGF) to learn the underlying causal mechanisms to synthesize faithful samples for FSL. Specifically, based on the counterfactual inference, we design a class-agnostic feature extractor to capture the sample-specific information, together with a counterfactual generation network to simulate the data generation process from a causal perspective. Moreover, to leverage the power of CGF in counterfactual inference, we further develop a novel classifier that classifies samples based on their distributions of counterfactual generations. Extensive experiments demonstrate the effectiveness of CGF on four FSL benchmarks, e.g., 80.12/86.13% accuracy on 5-way 1/5-shot miniImageNet FSL tasks, significantly improving the performance. Our codes and models are available at https://github.com/eric-hang/CGF.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2192703079",
                    "name": "Zhuohang Dang"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                },
                {
                    "authorId": "2147134586",
                    "name": "Chengyou Jia"
                },
                {
                    "authorId": "152299623",
                    "name": "Caixia Yan"
                },
                {
                    "authorId": "2840330",
                    "name": "Xiao Chang"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                }
            ]
        },
        {
            "paperId": "9e190a86b861cfb612ef36eb3baeec24bf51c776",
            "title": "Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks",
            "abstract": "Online movie review platforms are providing crowdsourced feedback for the film industry and the general public, while spoiler reviews greatly compromise user experience. Although preliminary research efforts were made to automatically identify spoilers, they merely focus on the review content itself, while robust spoiler detection requires putting the review into the context of facts and knowledge regarding movies, user behavior on film review platforms, and more. In light of these challenges, we first curate a large-scale network-based spoiler detection dataset LCS and a comprehensive and up-to-date movie knowledge base UKM. We then propose MVSD, a novel Multi-View Spoiler Detection framework that takes into account the external knowledge about movies and user activities on movie review platforms. Specifically, MVSD constructs three interconnecting heterogeneous information networks to model diverse data sources and their multi-view attributes, while we design and employ a novel heterogeneous graph neural network architecture for spoiler detection as node-level classification. Extensive experiments demonstrate that MVSD advances the state-of-the-art on two spoiler detection datasets, while the introduction of external knowledge and user interactions help ground robust spoiler detection. Our data and code are available at https://github.com/Arthur-Heng/Spoiler-Detection",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256778370",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "49039233",
                    "name": "Wenqian Zhang"
                },
                {
                    "authorId": "2170130468",
                    "name": "Yuyang Bai"
                },
                {
                    "authorId": "2093186816",
                    "name": "Zhaoxuan Tan"
                },
                {
                    "authorId": "2114887261",
                    "name": "Shangbin Feng"
                },
                {
                    "authorId": "2152099796",
                    "name": "Qinghua Zheng"
                },
                {
                    "authorId": "3326677",
                    "name": "Minnan Luo"
                }
            ]
        }
    ]
}