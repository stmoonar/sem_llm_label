{
    "authorId": "2634786",
    "papers": [
        {
            "paperId": "110e0bc1a9c4894ee4060d772833ff1cbc302c56",
            "title": "Integrating Pre-Trained Language Model with Physical Layer Communications",
            "abstract": "The burgeoning field of on-device AI communication, where devices exchange information directly through embedded foundation models, such as language models (LMs), requires robust, efficient, and generalizable communication frameworks. However, integrating these frameworks with existing wireless systems and effectively managing noise and bit errors pose significant challenges. In this work, we introduce a practical ondevice AI communication framework, integrated with physical layer (PHY) communication functions, demonstrated through its performance on a link-level simulator. Our framework incorporates end-to-end training with channel noise to enhance resilience, incorporates vector quantized variational autoencoders (VQ-VAE) for efficient and robust communication, and utilizes pre-trained encoder-decoder transformers for improved generalization capabilities. Simulations, across various communication scenarios, reveal that our framework achieves a 50% reduction in transmission size while demonstrating substantial generalization ability and noise robustness under standardized 3GPP channel models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2263554844",
                    "name": "Ju-Hyung Lee"
                },
                {
                    "authorId": "2115475530",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "2265488361",
                    "name": "Joohan Lee"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "d2a01f9b2a565070ce64ff38eb7cdc26f3ed992a",
            "title": "Self-Discover: Large Language Models Self-Compose Reasoning Structures",
            "abstract": "We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods. Core to the framework is a self-discovery process where LLMs select multiple atomic reasoning modules such as critical thinking and step-by-step thinking, and compose them into an explicit reasoning structure for LLMs to follow during decoding. SELF-DISCOVER substantially improves GPT-4 and PaLM 2's performance on challenging reasoning benchmarks such as BigBench-Hard, grounded agent reasoning, and MATH, by as much as 32% compared to Chain of Thought (CoT). Furthermore, SELF-DISCOVER outperforms inference-intensive methods such as CoT-Self-Consistency by more than 20%, while requiring 10-40x fewer inference compute. Finally, we show that the self-discovered reasoning structures are universally applicable across model families: from PaLM 2-L to GPT-4, and from GPT-4 to Llama2, and share commonalities with human reasoning patterns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2283250532",
                    "name": "Pei Zhou"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "2256826104",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2238263119",
                    "name": "Xinyun Chen"
                },
                {
                    "authorId": "2257129838",
                    "name": "Heng-Tze Cheng"
                },
                {
                    "authorId": "2256995069",
                    "name": "Quoc V. Le"
                },
                {
                    "authorId": "2253469026",
                    "name": "E. Chi"
                },
                {
                    "authorId": "2256313467",
                    "name": "Denny Zhou"
                },
                {
                    "authorId": "1817207",
                    "name": "Swaroop Mishra"
                },
                {
                    "authorId": "2253804927",
                    "name": "Huaixiu Steven Zheng"
                }
            ]
        },
        {
            "paperId": "439f1aacbcb32cba6da8f75bd9b15f7ea35e9d4d",
            "title": "Making Large Language Models Better Data Creators",
            "abstract": "Although large language models (LLMs) have advanced the state-of-the-art in NLP significantly, deploying them for downstream applications is still challenging due to cost, responsiveness, control, or concerns around privacy and security. As such, trainable models are still the preferred option in some cases. However, these models still require human-labeled data for optimal performance, which is expensive and time-consuming to obtain. In order to address this issue, several techniques to reduce human effort involve labeling or generating data using LLMs. Although these methods are effective for certain applications, in practice they encounter difficulties in real-world scenarios. Labeling data requires careful data selection, while generating data necessitates task-specific prompt engineering. In this paper, we propose a unified data creation pipeline that requires only a single formatting example, and which is applicable to a broad range of tasks, including traditionally problematic ones with semantically devoid label spaces. In our experiments we demonstrate that instruction-following LLMs are highly cost-effective data creators, and that models trained with these data exhibit performance better than those trained with human-labeled data (by up to 17.5%) on out-of-distribution evaluation, while maintaining comparable performance on in-distribution tasks. These results have important implications for the robustness of NLP systems deployed in the real-world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115475530",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "2138408476",
                    "name": "Mohit Sewak"
                },
                {
                    "authorId": "2264224760",
                    "name": "Ryen W. White"
                },
                {
                    "authorId": "3001990",
                    "name": "S. Jauhar"
                }
            ]
        },
        {
            "paperId": "64fcc4ccc5cecc63f3456558f6deb8a1e89923c7",
            "title": "PubGraph: A Large-Scale Scientific Knowledge Graph",
            "abstract": "Research publications are the primary vehicle for sharing scientific progress in the form of new discoveries, methods, techniques, and insights. Unfortunately, the lack of a large-scale, comprehensive, and easy-to-use resource capturing the myriad relationships between publications, their authors, and venues presents a barrier to applications for gaining a deeper understanding of science. In this paper, we present PubGraph, a new resource for studying scientific progress that takes the form of a large-scale knowledge graph (KG) with more than 385M entities, 13B main edges, and 1.5B qualifier edges. PubGraph is comprehensive and unifies data from various sources, including Wikidata, OpenAlex, and Semantic Scholar, using the Wikidata ontology. Beyond the metadata available from these sources, PubGraph includes outputs from auxiliary community detection algorithms and large language models. To further support studies on reasoning over scientific networks, we create several large-scale benchmarks extracted from PubGraph for the core task of knowledge graph completion (KGC). These benchmarks present many challenges for knowledge graph embedding models, including an adversarial community-based KGC evaluation setting, zero-shot inductive learning, and large-scale learning. All of the aforementioned resources are accessible at https://pubgraph.isi.edu/ and released under the CC-BY-SA license. We plan to update PubGraph quarterly to accommodate the release of new publications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2152944834",
                    "name": "Xinwei Du"
                },
                {
                    "authorId": "1850429085",
                    "name": "Richard Delwin Myloth"
                },
                {
                    "authorId": "2204572135",
                    "name": "Arun Baalaaji Sankar Ananthan"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "b647872ea2f3589e20dae7a5b04b1961861fa215",
            "title": "Analyzing Norm Violations in Live-Stream Chat",
            "abstract": "Toxic language, such as hate speech, can deter users from participating in online communities and enjoying popular platforms. Previous approaches to detecting toxic language and norm violations have been primarily concerned with conversations from online forums and social media, such as Reddit and Twitter. These approaches are less effective when applied to conversations on live-streaming platforms, such as Twitch and YouTube Live, as each comment is only visible for a limited time and lacks a thread structure that establishes its relationship with other comments. In this work, we share the first NLP study dedicated to detecting norm violations in conversations on live-streaming platforms. We define norm violation categories in live-stream chats and annotate 4,583 moderated comments from Twitch. We articulate several facets of live-stream data that differ from other forums, and demonstrate that existing models perform poorly in this setting. By conducting a user study, we identify the informational context humans use in live-stream moderation, and train models leveraging context to identify norm violations. Our results show that appropriate contextual information can boost moderation performance by 35\\%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2105675738",
                    "name": "Jihyung Moon"
                },
                {
                    "authorId": "73037511",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "91009922",
                    "name": "Hyundong Justin Cho"
                },
                {
                    "authorId": "8844876",
                    "name": "Woojeong Jin"
                },
                {
                    "authorId": "50487261",
                    "name": "Chan Young Park"
                },
                {
                    "authorId": "2220431613",
                    "name": "MinWoo Kim"
                },
                {
                    "authorId": "143823227",
                    "name": "Jonathan May"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "9149651",
                    "name": "Sungjoon Park"
                }
            ]
        },
        {
            "paperId": "c9f83c0fa1425d61c5b16aadc4492ad53e4fbda2",
            "title": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning",
            "abstract": "Temporal knowledge graph (TKG) forecasting benchmarks challenge models to predict future facts using knowledge of past facts. In this paper, we apply large language models (LLMs) to these benchmarks using in-context learning (ICL). We investigate whether and to what extent LLMs can be used for TKG forecasting, especially without any fine-tuning or explicit modules for capturing structural and temporal information. For our experiments, we present a framework that converts relevant historical facts into prompts and generates ranked predictions using token probabilities. Surprisingly, we observe that LLMs, out-of-the-box, perform on par with state-of-the-art TKG models carefully designed and trained for TKG forecasting. Our extensive evaluation presents performances across several models and datasets with different characteristics, compares alternative heuristics for preparing contextual information, and contrasts to prominent TKG methods and simple frequency and recency baselines. We also discover that using numerical indices instead of entity/relation names, i.e., hiding semantic information, does not significantly affect the performance ($\\pm$0.4\\% Hit@1). This shows that prior semantic knowledge is unnecessary; instead, LLMs can leverage the existing patterns in the context to achieve such performance. Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond simple predictions based on common or recent information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115475530",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "8844876",
                    "name": "Woojeong Jin"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "e6fba323a73d7c829b490e5b09dc136f3919c827",
            "title": "PubGraph: A Large Scale Scientific Temporal Knowledge Graph",
            "abstract": "Research publications are the primary vehicle for sharing sci-enti\ufb01c progress in the form of new discoveries, methods, techniques, and insights. Publications have been studied from the perspectives of both content analysis and bibliometric structure, but a barrier to more comprehensive studies of scien-ti\ufb01c research is a lack of publicly accessible large-scale data and resources. In this paper, we present PubGraph , a new resource for studying scienti\ufb01c progress that takes the form of a large-scale temporal knowledge graph (KG). It contains more than 432M nodes and 15.49B edges mapped to the popular Wikidata ontology. We extract three KGs with varying sizes from PubGraph to allow experimentation at different scales. Using these KGs, we introduce a new link prediction benchmark for transductive and inductive settings with temporally-aligned training, validation, and testing partitions. Moreover, we develop two new inductive learning methods better suited to PubGraph, operating on unseen nodes without explicit features, scaling to large KGs, and outperforming existing models. Our results demonstrate that structural features of past citations are suf\ufb01cient to produce high-quality predictions about new publications. We also identify new challenges for KG models, including an adversarial community-based link prediction setting, zero-shot inductive learning, and large-scale learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "32732621",
                    "name": "Kian Ahrabian"
                },
                {
                    "authorId": "2152944834",
                    "name": "Xinwei Du"
                },
                {
                    "authorId": "1850429085",
                    "name": "Richard Delwin Myloth"
                },
                {
                    "authorId": "2204572135",
                    "name": "Arun Baalaaji Sankar Ananthan"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "ed40889e11e812ef33578506844be06d713f6092",
            "title": "How FaR Are Large Language Models From Agents with Theory-of-Mind?",
            "abstract": "\"Thinking is for Doing.\"Humans can infer other people's mental states from observations--an ability called Theory-of-Mind (ToM)--and subsequently act pragmatically on those inferences. Existing question answering benchmarks such as ToMi ask models questions to make inferences about beliefs of characters in a story, but do not test whether models can then use these inferences to guide their actions. We propose a new evaluation paradigm for large language models (LLMs): Thinking for Doing (T4D), which requires models to connect inferences about others' mental states to actions in social scenarios. Experiments on T4D demonstrate that LLMs such as GPT-4 and PaLM 2 seemingly excel at tracking characters' beliefs in stories, but they struggle to translate this capability into strategic action. Our analysis reveals the core challenge for LLMs lies in identifying the implicit inferences about mental states without being explicitly asked about as in ToMi, that lead to choosing the correct action in T4D. To bridge this gap, we introduce a zero-shot prompting framework, Foresee and Reflect (FaR), which provides a reasoning structure that encourages LLMs to anticipate future challenges and reason about potential actions. FaR boosts GPT-4's performance from 50% to 71% on T4D, outperforming other prompting methods such as Chain-of-Thought and Self-Ask. Moreover, FaR generalizes to diverse out-of-distribution story structures and scenarios that also require ToM inferences to choose an action, consistently outperforming other methods including few-shot in-context learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1557324013",
                    "name": "Pei Zhou"
                },
                {
                    "authorId": "21626987",
                    "name": "Aman Madaan"
                },
                {
                    "authorId": "52226135",
                    "name": "Srividya Pranavi Potharaju"
                },
                {
                    "authorId": "2254858472",
                    "name": "Aditya Gupta"
                },
                {
                    "authorId": "2254265159",
                    "name": "Kevin R. McKee"
                },
                {
                    "authorId": "2257034335",
                    "name": "Ari Holtzman"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "2256826104",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "1817207",
                    "name": "Swaroop Mishra"
                },
                {
                    "authorId": "2254268473",
                    "name": "Aida Nematzadeh"
                },
                {
                    "authorId": "2254265068",
                    "name": "Shyam Upadhyay"
                },
                {
                    "authorId": "1779225",
                    "name": "Manaal Faruqui"
                }
            ]
        },
        {
            "paperId": "04220fc47381875f6aba4f5d80adaef7e23eee16",
            "title": "Evaluating Machine Common Sense via Cloze Testing",
            "abstract": "Language models (LMs) show state of the art performance for common sense (CS) question answering, but whether this ability implies a human-level mastery of CS remains an open question. Understanding the limitations and strengths of LMs can help researchers improve these models, potentially by developing novel ways of integrating external CS knowledge. We devise a series of tests and measurements to systematically quantify their performance on different aspects of CS. We propose the use of cloze testing combined with word embeddings to measure the LM's robustness and confidence. Our results show than although language models tend to achieve human-like accuracy, their confidence is subpar. Future work can leverage this information to build more complex systems, such as an ensemble of symbolic and distributed knowledge.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2064322437",
                    "name": "Ehsan Qasemi"
                },
                {
                    "authorId": "51132560",
                    "name": "Lee Kezar"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                },
                {
                    "authorId": "144171096",
                    "name": "Pedro A. Szekely"
                }
            ]
        },
        {
            "paperId": "16de1cb7971ca2b0bcd463417e8f780d9b083b31",
            "title": "Assessing Scientific Research Papers with Knowledge Graphs",
            "abstract": "In recent decades, the growing scale of scientific research has led to numerous novel findings. Reproducing these findings is the foundation of future research. However, due to the complexity of experiments, manually assessing scientific research is laborious and time-intensive, especially in social and behavioral sciences. Although increasing reproducibility studies have garnered increased attention in the research community, there is still a lack of systematic ways for evaluating scientific research at scale. In this paper, we propose a novel approach towards automatically assessing scientific publications by constructing a knowledge graph (KG) that captures a holistic view of the research contributions. Specifically, during the KG construction, we combine information from two different perspectives: micro-level features that capture knowledge from published articles such as sample sizes, effect sizes, and experimental models, and macro-level features that comprise relationships between entities such as authorship and reference information. We then learn low-dimensional representations using language models and knowledge graph embeddings for entities (nodes in KGs), which are further used for the assessments. A comprehensive set of experiments on two benchmark datasets shows the usefulness of leveraging KGs for scoring scientific research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35329068",
                    "name": "Kexuan Sun"
                },
                {
                    "authorId": "2175275027",
                    "name": "Zhiqiang Qiu"
                },
                {
                    "authorId": "2071206993",
                    "name": "A. Salinas"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "73037511",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "2052360522",
                    "name": "Daniel M. Benjamin"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "2149473952",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2073018730",
                    "name": "Kristina Lerman"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        }
    ]
}