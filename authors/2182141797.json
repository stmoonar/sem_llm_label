{
    "authorId": "2182141797",
    "papers": [
        {
            "paperId": "0071604cdf29429e0fa3d8a58d66b3874eb5645f",
            "title": "Multimodal Emotion Recognition Based on Feature Fusion",
            "abstract": "In the field of human-computer interaction, human emotion recognition is a challenging problem, and it is also a key link to achieve barrier-free communication between human and machine. At present, most of the emotion recognition algorithms are constructed based on single modal social information, and the recognition results are one-sided and easily disturbed. The recognition accuracy is often difficult to meet the practical requirements after being separated from specific social environment conditions. Based on the above situation and problems, this paper adopts multimodal input and simultaneously includes three modal information of audio, text and facial expression to recognition emotion. Three single modal emotion recognition models are proposed based on three different input information, and the multimodal emotion recognition model are constructed by different feature fusion methods. The experimental results showed that the accuracy of multimodal model on the CH-SIMS dataset was 93.92%. In addition, compared with other emotion recognition models, the effectiveness of the proposed method is verified.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2182141797",
                    "name": "Yurui Xu"
                },
                {
                    "authorId": "2157134824",
                    "name": "Xiao Wu"
                },
                {
                    "authorId": "2087042688",
                    "name": "Hang Su"
                },
                {
                    "authorId": "1390612725",
                    "name": "Xiaorui Liu"
                }
            ]
        }
    ]
}