{
    "authorId": "46812189",
    "papers": [
        {
            "paperId": "04f87c405cf8814dcd9185e6ef9751086a4b916c",
            "title": "EMO2-DETR: Efficient-Matching Oriented Object Detection With Transformers",
            "abstract": "Object detection in remote sensing is a challenging task due to the arbitrary orientations of objects and the vast variation in the number of objects within a single image. For instance, one image may contain hundreds of small vehicles, while another may only have a single football field. Recently, DEtection TRansformer (DETR) and its variants have achieved great success in object detection by setting a fixed number of object queries and using bipartite graph matching for one-to-one label assignment. However, we have observed that bipartite graph matching can result in relative redundancy of object queries when the number of objects changes dramatically in an image. This relative redundancy can cause two problems: slower convergence during training and redundant bounding boxes during inference. To analyze the aforementioned problems, we proposed a metric, redundancy of object query (ROQ), to quantitatively analyze the redundancy. Through experiments, we discovered that the reason for the two issues is the difficulty in distinguishing between high-quality negative samples and positive samples. In this article, we proposed efficient-matching oriented object detection with transformers (EMO2-DETR) consisting of three dedicated components to address the aforementioned issues. Specifically, reassign bipartite graph matching (RBGM) is proposed to extract high-quality negative samples from the negative samples. And ignored sample predicted head (ISPH) is proposed to predict high-quality negative samples. Then, reassigned Hungarian loss is used to better involve high-quality negative samples in the update of model parameters. Extensive experiments on DOTAv1 and DOTAv1.5 datasets demonstrated that our proposed method achieves the competitive results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2120292868",
                    "name": "Zhijia Yang"
                },
                {
                    "authorId": "2320516419",
                    "name": "Chenrui Li"
                },
                {
                    "authorId": "122009001",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "71a5d0af83695d4623286460910af63da2ce940a",
            "title": "AF-OSD: An Anchor-Free Oriented Ship Detector Based on Multi-Scale Dense-Point Rotation Gaussian Heatmap",
            "abstract": "Due to the complexity of airborne remote sensing scenes, strong background and noise interference, positive and negative sample imbalance, and multiple ship scales, ship detection is a critical and challenging task in remote sensing. This work proposes an end-to-end anchor-free oriented ship detector (AF-OSD) framework based on a multi-scale dense-point rotation Gaussian heatmap (MDP-RGH) to tackle these aforementioned challenges. First, to solve the sample imbalance problem and suppress the interference of negative samples such as background and noise, the oriented ship is modeled via the proposed MDP-RGH according to its shape and direction to generate ship labels with more accurate information, while the imbalance between positive and negative samples is adaptively learned for the ships with different scales. Then, the AF-OSD based on MDP-RGH is further devised to detect the multi-scale oriented ship, which is the accurate identification and information extraction for multi-scale vessels. Finally, a multi-task object size adaptive loss function is designed to guide the training process, improving its detection quality and performance for multi-scale oriented ships. Simulation results show that extensive experiments on HRSC2016 and DOTA ship datasets reveal that the proposed method achieves significantly outperforms the compared state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "2143803197",
                    "name": "Gaofeng Pan"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2592481",
                    "name": "Hengchao Li"
                },
                {
                    "authorId": "2144320648",
                    "name": "Su Chen"
                }
            ]
        },
        {
            "paperId": "9fcc1fcea64dc049b64b5ccf20ee701c3d871292",
            "title": "Hyperspectral Time-Series Target Detection Based on Spectral Perception and Spatial\u2013Temporal Tensor Decomposition",
            "abstract": "The detection of camouflaged targets in the complex background is a hot topic of current research. The existing hyperspectral target detection algorithms do not take advantage of spatial information and rarely use temporal information. It is difficult to obtain the required targets, and the detection performance in hyperspectral sequences with complex background will be low. Therefore, a hyperspectral time-series target detection method based on spectral perception and spatial\u2013temporal tensor (SPSTT) decomposition is proposed. First, a sparse target perception strategy based on spectral matching is proposed. To initially acquire the sparse targets, the matching results are adjusted by using the correlation mean of the prior spectrum, the pixel to be measured, and the four-neighborhood pixel spectra. The separation of target and background is enhanced by making full use of local spatial structure information through local topology graph representation of the pixel to be measured. Second, in order to obtain a more accurate rank and make full use of temporal continuity and spatial correlation, a spatial\u2013temporal tensor (STT) model based on the gamma norm and $L_{2,1}$ norm is constructed. Furthermore, an excellent alternating direction method of multipliers (ADMM) is proposed to solve this model. Finally, spectral matching is fused with STT decomposition in order to reduce false alarms and retain more right targets. A 176-band Beijing Institute of Technology hyperspectral image sequence - I (BIT-HSIS-I) dataset is collected for the hyperspectral target detection task. It is found by testing on the collected dataset that the proposed SPSTT has superior performance over the state-of-the-art algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051261924",
                    "name": "Xiaobin Zhao"
                },
                {
                    "authorId": "49599759",
                    "name": "Kai Liu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "50135244",
                    "name": "Wei Li"
                }
            ]
        },
        {
            "paperId": "e6b8b8cee6fe4f570dc32f6da56fb833f4c6461f",
            "title": "Computer Vision-Aided mmWave UAV Communication Systems",
            "abstract": "Unmanned aerial vehicle (UAV) communication systems usually operate in harsh scenarios, which require accurate information about the topology and wireless channel to achieve the desired transmission performance. Therefore, when millimeter-wave (mmWave) communication with its intrinsic Line-of-Sight (LoS) condition is adopted, accurate target localization is essential to determine the spatial relationship between the UAV and the grounded receivers (Rxs). In this article, a computer-vision (CV)-aided jointly optimization scheme of flight trajectory and power allocation is designed for mmWave UAV communication systems by utilizing the visual information captured via cameras equipped at the UAV. Compared with traditional schemes, the implementation cost and overhead can be greatly saved as no radio frequency transmissions are required in the proposed localization scheme. In addition, the transmit power at the UAV is jointly optimized with its flight trajectory in two different cases. Finally, simulation results are presented to demonstrate the efficiency of the proposed schemes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "1471101683",
                    "name": "Yang Lu"
                },
                {
                    "authorId": "2143803197",
                    "name": "Gaofeng Pan"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "34825558",
                    "name": "D. B. D. Costa"
                },
                {
                    "authorId": "2144320648",
                    "name": "Su Chen"
                }
            ]
        },
        {
            "paperId": "ed8a7d0bd4525de885d789a23e46f1423e1ecb8c",
            "title": "Successive Clustering-Based Outlier Resistant Band Selection Method for Hyperspectral Images With Spatial Information Difference Metrics",
            "abstract": "In hyperspectral classification applications, band selection (BS) is an effective preprocessing method that reduces image redundancy without changing the original data. The property whereby different objects can be spatially separated is used for image classification, but BS methods based on quantitation of this property have not gotten enough attention. A cluster-based BS method that uses the dilation distances (DDs) with respect to the metric of spatial distances has been proposed, but the DD is strongly affected by outliers and calculating DD is time-consuming. Moreover, there is a mismatch between DD and the method of clustering and selecting representative band. In this letter, we propose a BS method based on pixel sorting-feature-based DD (SFDD) to accurately determine spatial information differences (SIDs) metric and design a method of successive clustering as well as a method of representative BS to match the features of this metric. We optimize the method to calculate the SFDD to reduce the time needed for it. In contrast to most BS methods, the bands selected by our method have a large SID among them such that objects at different positions are clearly differentiated in the spectral dimension after dimension reduction. The results of experiments showed that the proposed approach provides results that are competitive with those of several state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152251406",
                    "name": "Zhiyong Tian"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "46749248",
                    "name": "Yunpeng Feng"
                }
            ]
        },
        {
            "paperId": "2d19ea2b8099ca0c104ad05e38a169b500f1295a",
            "title": "Focal Cosine Metric and Adaptive Attention Module for Remote Sensing Scene Classification With Siamese Convolutional Neural Networks",
            "abstract": "Convolutional neural networks (CNNs) have been widely used in remote sensing (RS) scene classification tasks due to their remarkable feature representation and inference capability. The complexity of RS images not only brings the challenges of high inter-class similarity and large intra-class diversity, but also introduces the problem that category-relevant regions are insufficiently prominent in feature extraction. Siamese CNNs with feature similarity measurement are chosen in some applications to overcome the former issue, but most ignore the randomness of input sample pairs. This makes the Siamese CNNs not focus enough on challenging samples, which limits the training efficiency. We propose the focal cosine metric (FCM) block that combines the cosine similarity metric and the threshold control to achieve sample selection, thereby completing network learning more efficiently. FCM only permits the misclassified focal samples to participate in similarity measurement based on Siamese CNN. It flexibly mitigates the misclassification caused by the high inter-class similarity and large intra-class diversity. Moreover, the adaptive attention (AA) module is designed to stress the pivotal target regions and assist in the similarity measurement of Siamese CNN. This is realized by adaptively assigning high weights to key targets with learnable guided vectors. It enables the model to focus on the details of intra-class similarities or inter-class differences in sample pairs, and thus reduces the difficulty of model optimization. Encouraging experimental results on three public data sets demonstrate the effectiveness of the novel Siamese CNN-based method with FCM and AA and show its superiority compared to other state-of-the-art scene classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "49528487",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                },
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                }
            ]
        },
        {
            "paperId": "58815d046026f2996e38a23b1cd47b7c1e75195e",
            "title": "Siamese Network Ensembles for Hyperspectral Target Detection with Pseudo Data Generation",
            "abstract": "Target detection in hyperspectral images (HSIs) aims to distinguish target pixels from the background using knowledge gleaned from prior spectra. Most traditional methods are based on certain assumptions and utilize handcrafted classifiers. These simple models and assumptions\u2019 failure restrict the detection performance under complicated background interference. Recently, based on the convolutional networks, many supervised deep learning detectors have outperformed the traditional methods. However, these methods suffer from unstable detection, heavy computation burden, and optimization difficulty. This paper proposes a Siamese fully connected based target detector (SFCTD) that comprises nonlinear feature extraction modules (NFEMs) and cosine distance classifiers. Two NFEMs, which extract discriminative spectral features of input spectra-pairs, are based on fully connected layers for efficient computing and share the parameters to ease the optimization. To solve the few samples problem, we propose a pseudo data generation method based on the linear mixed model and the assumption that background pixels are dominant in HSIs. For mitigating the impact of stochastic suboptimal initialization, we parallelly optimize several Siamese detectors with small computation burdens and aggregate them as ensembles in the inference time. The network ensembles outperform every detector in terms of stability and achieve an outstanding balance between background suppression and detection rate. Experiments on multiple data sets demonstrate that the proposed detector is superior to the state-of-the-art detectors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2260820793",
                    "name": "Pengyu Wang"
                }
            ]
        },
        {
            "paperId": "5d6a6cc361cbf5c44c11c24ee426037627352818",
            "title": "Constrained-Target Band Selection Based on Band Combination for Hyperspectral Target Detection Using CEM",
            "abstract": "Selecting an appropriate band subset is a vital problem for hyperspectral target detection. The constrained-target band selection method, derived from constrained energy minimization (CEM), can select different band subsets according to different targets. The selected band will be used to detect the target by CEM. However, the current methods did not consider the adaptation of the selected band with CEM. We propose a constrained target band selection method based on band combination, which treats the selected band as a whole to match the input requirements of CEM to detect the specific target. Firstly, Criteria for evaluating band combination is proposed based on the constrained-target band selection method. Secondly, the features of these band combinations are proposed. Thirdly, the key band set is proposed to reduce the range of search band combinations from the whole band to a subset of the whole band, based on these features and the sparse constrained band selection (SCBS) method. Finally, the desired band combination is searched in the key band set based on these features. Experiments show that the proposed method offers promising results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152251406",
                    "name": "Zhiyong Tian"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                }
            ]
        },
        {
            "paperId": "8fc2548ae8f31a148b29281e359ea3151d2115ed",
            "title": "Triplet-Metric-Guided Multi-Scale Attention for Remote Sensing Image Scene Classification with a Convolutional Neural Network",
            "abstract": "Remote sensing image scene classification (RSISC) plays a vital role in remote sensing applications. Recent methods based on convolutional neural networks (CNNs) have driven the development of RSISC. However, these approaches are not adequate considering the contributions of different features to the global decision. In this paper, triplet-metric-guided multi-scale attention (TMGMA) is proposed to enhance task-related salient features and suppress task-unrelated salient and redundant features. Firstly, we design the multi-scale attention module (MAM) guided by multi-scale feature maps to adaptively emphasize salient features and simultaneously fuse multi-scale and contextual information. Secondly, to capture task-related salient features, we use the triplet metric (TM) to optimize the learning of MAM under the constraint that the distance of the negative pair is supposed to be larger than the distance of the positive pair. Notably, the MAM and TM collaboration can enforce learning a more discriminative model. As such, our TMGMA can avoid the classification confusion caused by only using the attention mechanism and the excessive correction of features caused by only using the metric learning. Extensive experiments demonstrate that our TMGMA outperforms the ResNet50 baseline by 0.47% on the UC Merced, 1.46% on the AID, and 1.55% on the NWPU-RESISC45 dataset, respectively, and achieves performance that is competitive with other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "1574346529",
                    "name": "Yuxuan Mao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "15368955",
                    "name": "Zibo Hu"
                },
                {
                    "authorId": "2130182524",
                    "name": "Yutong Liu"
                }
            ]
        },
        {
            "paperId": "b238a7513097c03a2d29d8a1044efb6c546fadfb",
            "title": "Gradient Enhanced Dual Regression Network: Perception-Preserving Super-Resolution for Multi-Sensor Remote Sensing Imagery",
            "abstract": "Most existing learning-based single image super-resolution (SISR) methods mainly focus on improving reconstruction accuracy, but they always generate overly smoothed results that fail to match the visual perception. Although perceptual quality can be greatly improved via introducing adversarial loss, image fidelity may decrease to some extent. Moreover, most methods are trained and evaluated on simulated datasets and their performance would drop significantly on real remote sensing imagery. To solve the above problems, we propose a new SISR algorithm named gradient enhanced dual regression network (GEDRN). Based on the dual regression framework, we use share-source residual structure and non-local operation to learn abundant low-frequency information and long-distance spatial correlations. Besides, we not only introduce additional gradient information to avoid blurry results but also apply gradient loss and perceptual loss to further improve the perceptual quality. Our GEDRN is trained and tested on real-world multi-sensor satellite images. Experimental results demonstrate the superiority of the proposed method in achieving much better perceptual quality and ensuring high fidelity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "2006501898",
                    "name": "Lei Min"
                },
                {
                    "authorId": "2151129927",
                    "name": "Shijing Ji"
                },
                {
                    "authorId": "2064176746",
                    "name": "Chong Ni"
                },
                {
                    "authorId": "2133809172",
                    "name": "Dayu Chen"
                }
            ]
        }
    ]
}