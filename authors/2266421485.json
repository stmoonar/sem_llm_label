{
    "authorId": "2266421485",
    "papers": [
        {
            "paperId": "5931539cb2c6c2865e6776688d3e0a42bca5ebd3",
            "title": "How Few Davids Improve One Goliath: Federated Learning in Resource-Skewed Edge Computing Environments",
            "abstract": "Real-world deployment of federated learning requires orchestrating clients with widely varied compute resources, from strong enterprise-grade devices in data centers to weak mobile and Web-of-Things devices. Prior works have attempted to downscale large models for weak devices and aggregate shared parts among heterogeneous models. A typical architectural assumption is that there are equally many strong and weak devices. In reality, however, we often encounter resource skew where a few (1 or 2) strong devices hold substantial data resources, alongside many weak devices. This poses challenges-the unshared portion of the large model rarely receives updates or gains benefits from weak collaborators. We aim to facilitate reciprocal benefits between strong and weak devices in resource-skewed environments. We propose RecipFL, a novel framework featuring a server-side graph hypernetwork. This hypernetwork is trained to produce parameters for personalized client models adapted to device capacity and unique data distribution. It effectively generalizes knowledge about parameters across different model architectures by encoding computational graphs. Notably, RecipFL is agnostic to model scaling strategies and supports collaboration among arbitrary neural networks. We establish the generalization bound of RecipFL through theoretical analysis and conduct extensive experiments with various model architectures. Results show that RecipFL improves accuracy by 4.5% and 7.4% for strong and weak devices respectively, incentivizing both devices to actively engage in federated learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2254819301",
                    "name": "Shuheng Li"
                },
                {
                    "authorId": "2300831536",
                    "name": "Haiyu Huang"
                },
                {
                    "authorId": "2255392604",
                    "name": "Zihan Wang"
                },
                {
                    "authorId": "2265354336",
                    "name": "Xiaohan Fu"
                },
                {
                    "authorId": "2266398035",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2265359074",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "adfac93d6b6ccc9a83e2e37c337f1cb9c69392df",
            "title": "Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving",
            "abstract": "Recent advances in Automated Theorem Proving have shown the effectiveness of leveraging a (large) language model that generates tactics (i.e. proof steps) to search through proof states. The current model, while trained solely on successful proof paths, faces a discrepancy at the inference stage, as it must sample and try various tactics at each proof state until finding success, unlike its training which does not incorporate learning from failed attempts. Intuitively, a tactic that leads to a failed search path would indicate that similar tactics should receive less attention during the following trials. In this paper, we demonstrate the benefit of training models that additionally learn from failed search paths. Facing the lack of such trial-and-error data in existing open-source theorem-proving datasets, we curate a dataset on intuitionistic propositional logic theorems and formalize it in Lean, such that we can reliably check the correctness of proofs. We compare our model trained on relatively short trial-and-error information (TrialMaster) with models trained only on the correct paths and discover that the former solves more unseen theorems with lower trial searches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2295988926",
                    "name": "Chenyang An"
                },
                {
                    "authorId": "2296028330",
                    "name": "Zhibo Chen"
                },
                {
                    "authorId": "2295990997",
                    "name": "Qihao Ye"
                },
                {
                    "authorId": "2295988294",
                    "name": "Emily First"
                },
                {
                    "authorId": "2265617343",
                    "name": "Letian Peng"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2255392606",
                    "name": "Zihan Wang"
                },
                {
                    "authorId": "2295988080",
                    "name": "Sorin Lerner"
                },
                {
                    "authorId": "2254284383",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "681f05c1952ce3e1dc48a4ceb230a6033092be68",
            "title": "Unleashing the Power of Shared Label Structures for Human Activity Recognition",
            "abstract": "Current human activity recognition (HAR) techniques regard activity labels as integer class IDs without explicitly modeling the semantics of class labels. We observe that different activity names often have shared structures. For example, \"open door\" and \"open fridge\" both have \"open\" as the action; \"kicking soccer ball\" and \"playing tennis ball\" both have \"ball\" as the object. Such shared structures in label names can be translated to the similarity in sensory data and modeling common structures would help uncover knowledge across different activities, especially for activities with limited samples. In this paper, we propose SHARE, a HAR framework that takes into account shared structures of label names for different activities. To exploit the shared structures, SHARE comprises an encoder for extracting features from input sensory time series and a decoder for generating label names as a token sequence. We also propose three label augmentation techniques to help the model more effectively capture semantic structures across activities, including a basic token-level augmentation, and two enhanced embedding-level and sequence-level augmentations utilizing the capabilities of pre-trained models. SHARE outperforms state-of-the-art HAR models in extensive experiments on seven HAR benchmark datasets. We also evaluate in few-shot learning and label imbalance settings and observe even more significant performance gap.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "9bf1a897c6d6f959b0160c0cc1675f528b974b28",
            "title": "Minimally Supervised Contextual Inference from Human Mobility: An Iterative Collaborative Distillation Framework",
            "abstract": "The context about trips and users from mobility data is valuable for mobile service providers to understand their customers and improve their services. Existing inference methods require a large number of labels for training, which is hard to meet in practice. In this paper, we study a more practical yet challenging setting\u2014contextual inference using mobility data with minimal supervision (i.e., a few labels per class and massive unlabeled data). A typical solution is to apply semi-supervised methods that follow a self-training framework to bootstrap a model based on all features. However, using a limited labeled set brings high risk of overfitting to self-training, leading to unsatisfactory performance. We propose a novel collaborative distillation framework STCOLAB. It sequentially trains spatial and temporal modules at each iteration following the supervision of ground-truth labels. In addition, it distills knowledge to the module being trained using the logits produced by the latest trained module of the other modality, thereby mutually calibrating the two modules and combining the knowledge from both modalities. Extensive experiments on two real-world datasets show STCOLAB achieves significantly more accurate contextual inference than various baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "b26182a81185552efaaec9e79579b333901410bd",
            "title": "Navigating Alignment for Non-identical Client Class Sets: A Label Name-Anchored Federated Learning Framework",
            "abstract": "Traditional federated classification methods, even those designed for non-IID clients, assume that each client annotates its local data with respect to the same universal class set. In this paper, we focus on a more general yet practical setting, non-identical client class sets, where clients focus on their own (different or even non-overlapping) class sets and seek a global model that works for the union of these classes. If one views classification as finding the best match between representations produced by data/label encoder, such heterogeneity in client class sets poses a new significant challenge-local encoders at different clients may operate in different and even independent latent spaces, making it hard to aggregate at the server. We propose a novel framework, FedAlign1, to align the latent spaces across clients from both label and data perspectives. From a label perspective, we leverage the expressive natural language class names as a common ground for label encoders to anchor class representations and guide the data encoder learning across clients. From a data perspective, during local training, we regard the global class representations as anchors and leverage the data points that are close/far enough to the anchors of locally-unaware classes to align the data encoders across clients. Our theoretical analysis of the generalization performance and extensive experiments on four real-world datasets of different tasks confirm that FedAlign outperforms various state-of-the-art (non-IID) federated classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2505157",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                },
                {
                    "authorId": "2884976",
                    "name": "Jingbo Shang"
                }
            ]
        },
        {
            "paperId": "c26c4bbac1170f7e7fb7c4298c384c859098f71f",
            "title": "Physics-Informed Data Denoising for Real-Life Sensing Systems",
            "abstract": "Sensors measuring real-life physical processes are ubiquitous in today's interconnected world. These sensors inherently bear noise that often adversely affects the performance and reliability of the systems they support. Classic filtering approaches introduce strong assumption on the time or frequency characteristics of sensory measurements, while learning-based denoising approaches typically rely on using ground truth clean data to train a denoising model, which is often challenging or prohibitive to obtain for many real-world applications. We observe that in many scenarios, the relationships between different sensor measurements (e.g., location and acceleration) are analytically described by laws of physics (e.g., second-order differential equation). By incorporating such physics constraints, we can guide the denoising process to improve performance even in the absence of ground truth data. In light of this, we design a physics-informed denoising model that leverages the inherent algebraic relationships between different measurements governed by the underlying physics. By obviating the need for ground truth clean data, our method offers a practical denoising solution for real-world applications. We conducted experiments in various domains, including inertial navigation, CO2 monitoring, and HVAC control, and achieved state-of-the-art performance compared with existing denoising methods. Our method can denoise data in real time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results that closely align with those from high-precision, high-cost alternatives, leading to an efficient, cost-effective approach for more accurate sensor-based systems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2108217022",
                    "name": "Xiyuan Zhang"
                },
                {
                    "authorId": "2265354336",
                    "name": "Xiaohan Fu"
                },
                {
                    "authorId": "2266398673",
                    "name": "Diyan Teng"
                },
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "2266420695",
                    "name": "Keerthivasan Vijayakumar"
                },
                {
                    "authorId": "2266421485",
                    "name": "Jiayun Zhang"
                },
                {
                    "authorId": "134629191",
                    "name": "Ranak Roy Chowdhury"
                },
                {
                    "authorId": "2266424978",
                    "name": "Junsheng Han"
                },
                {
                    "authorId": "2266398035",
                    "name": "Dezhi Hong"
                },
                {
                    "authorId": "2266398313",
                    "name": "Rashmi Kulkarni"
                },
                {
                    "authorId": "2163679367",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2110343779",
                    "name": "Rajesh K. Gupta"
                }
            ]
        }
    ]
}