{
    "authorId": "2216647510",
    "papers": [
        {
            "paperId": "65ad28f7f9ec087f973860f1d71e2bb9fded8ff7",
            "title": "EmojiCrypt: Prompt Encryption for Secure Communication with Large Language Models",
            "abstract": "Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications. While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services. To address these concerns, this paper proposes a simple yet effective mechanism EmojiCrypt to protect user privacy. It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the model's performance remains unaffected. We conduct experiments on three tasks, personalized recommendation, sentiment analysis, and tabular data analysis. Experiment results reveal that EmojiCrypt can encrypt personal information within prompts in such a manner that not only prevents the discernment of sensitive data by humans or LLM itself, but also maintains or even improves the precision without further tuning, achieving comparable or even better task accuracy than directly prompting the LLM without prompt encryption. These results highlight the practicality of adopting encryption measures that safeguard user privacy without compromising the functional integrity and performance of LLMs. Code and dataset are available at https://github.com/agiresearch/EmojiCrypt.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216647510",
                    "name": "Guo Lin"
                },
                {
                    "authorId": "2007245028",
                    "name": "Wenyue Hua"
                },
                {
                    "authorId": "2278014082",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "19c31a72016985ef977ebb7f67671b364a64f884",
            "title": "Sparks of Artificial General Recommender (AGR): Early Experiments with ChatGPT",
            "abstract": "This study investigates the feasibility of developing an Artificial General Recommender (AGR), facilitated by recent advancements in Large Language Models (LLMs). An AGR comprises both conversationality and universality to engage in natural dialogues and generate recommendations across various domains. We propose ten fundamental principles that an AGR should adhere to, each with its corresponding testing protocols. We proceed to assess whether ChatGPT, a sophisticated LLM, can comply with the proposed principles by engaging in recommendation-oriented dialogues with the model while observing its behavior. Our findings demonstrate the potential for ChatGPT to serve as an AGR, though several limitations and areas for improvement are identified.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216647510",
                    "name": "Guo Lin"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "418989d33e575ba506bae45e32372b80484a9a72",
            "title": "Sparks of Artificial General Recommender (AGR): Experiments with ChatGPT",
            "abstract": "This study investigates the feasibility of developing an Artificial General Recommender (AGR), facilitated by recent advancements in Large Language Models (LLMs). An AGR comprises both conversationality and universality to engage in natural dialogues and generate recommendations across various domains. We propose ten fundamental principles that an AGR should adhere to, each with its corresponding testing protocol. We proceed to assess whether ChatGPT, a sophisticated LLM, can comply with the proposed principles by engaging in recommendation-oriented dialogues with the model while observing its behavior. Our findings demonstrate the potential for ChatGPT to serve as an AGR, though several limitations and areas for improvement are identified.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216647510",
                    "name": "Guo Lin"
                },
                {
                    "authorId": "2278014082",
                    "name": "Yongfeng Zhang"
                }
            ]
        }
    ]
}