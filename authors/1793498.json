{
    "authorId": "1793498",
    "papers": [
        {
            "paperId": "0d9b6925ee1f0c6bf199e5fb5bef27a60b1e2c51",
            "title": "Learning-based Identification of Coding Best Practices from Software Documentation",
            "abstract": "Automatic identification of coding best practices can scale the development of code and application analyzers. We present Doc2BP, a deep learning tool to identify coding best practices in software documentation. Natural language descriptions are mapped to an informative embedding space, optimized under the dual objectives of binary and few shot classification. The binary objective powers general classification into known best practice categories using a deep learning classifier. The few shot objective facilitates example-based classification into novel categories by matching embeddings with user-provided examples at run-time, without having to retrain the underlying model. We analyze the effects of manually and synthetically labeled examples, context, and cross-domain information.We have applied Doc2BP to Java, Python, AWS Java SDK, and AWS CloudFormation documentations. With respect to prior works that primarily leverage keyword heuristics and our own parts of speech pattern baselines, we obtain 3-5% F1 score improvement for Java and Python, and 15-20% for AWS Java SDK and AWS CloudFormation. Experiments with four few shot use-cases show promising results (5-shot accuracy of 99%+ for Java NullPointerException and AWS Java metrics, 65% for AWS CloudFormation numerics, and 35% for Python best practices).Doc2BP has contributed new rules and improved specifications in Amazon's code and application analyzers: (a) 500+ new checks in cfn-lint, an open-source AWS CloudFormation linter, (b) over 97% automated coverage of metrics APIs and related practices in Amazon DevOps Guru, (c) support for nullable AWS APIs in Amazon CodeGuru's Java NullPointerException (NPE) detector, (d) 200+ new best practices for Java, Python, and respective AWS SDKs in Amazon CodeGuru, and (e) 2% reduction in false positives in Amazon CodeGuru's Java resource leak detector.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                }
            ]
        },
        {
            "paperId": "3a91403fe3e8f2724fa6b008e8dce4f7c1587d16",
            "title": "Code Compliance Assessment as a Learning Problem",
            "abstract": "Manual code reviews and static code analyzers are the traditional mechanisms to verify if source code complies with coding policies. However, they are hard to scale. We formulate code compliance assessment as a machine learning (ML) problem, to take as input a natural language policy and code, and generate a prediction on the code\u2019s compliance, non-compliance, or irrelevance. Our intention for ML-based automation is to scale the development of Amazon CodeGuru, a commercial code analyzer. We explore key research questions on model formulation, training data, and evaluation setup. We obtain a joint code-text representation space (embeddings) which preserves compliance relationships via the vector distance of code and policy embeddings. As there is no task-specific data, we re-interpret and filter commonly available software datasets with additional pre-training and pre-finetuning tasks that reduce the semantic gap. We benchmarked our approach on two listings of coding policies (CWE and CBP). This is a zero-shot evaluation as none of the policies occur in the training set. On CWE and CBP respectively, our tool Policy2Code achieves classification accuracies of (59%, 71%) and search MRR of (0.05, 0.21) compared to CodeBERT with classification accuracies of (37%, 54%) and MRR of (0.02, 0.02). In a user study, 24% Policy2Code detections were accepted compared to 7% for CodeBERT. Policy2Code is considered a useful ML-based aid to supplement manual efforts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                }
            ]
        },
        {
            "paperId": "22379f988c7b4b3f5be3b5c74730610682193db2",
            "title": "Contextual Multi-Armed Bandits for Causal Marketing",
            "abstract": "This work explores the idea of a causal contextual multi-armed bandit approach to automated marketing, where we estimate and optimize the causal (incremental) effects. Focusing on causal effect leads to better return on investment (ROI) by targeting only the persuadable customers who wouldn't have taken the action organically. Our approach draws on strengths of causal inference, uplift modeling, and multi-armed bandits. It optimizes on causal treatment effects rather than pure outcome, and incorporates counterfactual generation within data collection. Following uplift modeling results, we optimize over the incremental business metric. Multi-armed bandit methods allow us to scale to multiple treatments and to perform off-policy policy evaluation on logged data. The Thompson sampling strategy in particular enables exploration of treatments on similar customer contexts and materialization of counterfactual outcomes. Preliminary offline experiments on a retail Fashion marketing dataset show merits of our proposal.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "83062607",
                    "name": "C. Namballa"
                },
                {
                    "authorId": "2074296975",
                    "name": "Narayanan Sadagopan"
                },
                {
                    "authorId": "2226304",
                    "name": "Houssam Nassif"
                }
            ]
        },
        {
            "paperId": "218b2c5c9d011eb4432be4728b54e39f366354c1",
            "title": "Enhancing Training Collections for Image Annotation: An Instance-Weighted Mixture Modeling Approach",
            "abstract": "Tagged Web images provide an abundance of labeled training examples for visual concept learning. However, the performance of automatic training data selection is susceptible to highly inaccurate tags and atypical images. Consequently, manually curated training data sets are still a preferred choice for many image annotation systems. This paper introduces ARTEMIS - a scheme to enhance automatic selection of training images using an instance-weighted mixture modeling framework. An optimization algorithm is derived to learn instance-weights in addition to mixture parameter estimation, essentially adapting to the noise associated with each example. The mechanism of hypothetical local mapping is evoked so that data in diverse mathematical forms or modalities can be cohesively treated as the system maintains tractability in optimization. Finally, training examples are selected from top-ranked images of a likelihood-based image ranking. Experiments indicate that ARTEMIS exhibits higher resilience to noise than several baselines for large training data collection. The performance of ARTEMIS-trained image annotation system is comparable with usage of manually curated data sets.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "48094094",
                    "name": "James Ze Wang"
                },
                {
                    "authorId": "40116905",
                    "name": "Jia Li"
                }
            ]
        },
        {
            "paperId": "04f6aa7b73bf96c71cfab76a332758947d40ca9f",
            "title": "Federating geovisual analytic tools for cyber security analysis",
            "abstract": "For the 2012 VAST Challenge, we federate a number of tools together and exploit the best capabilities of each to analyze geolocated cyber security data. We augment the geographic tools with our own custom-designed frequency analysis plots developed in the Processing programming language. This combination of tools provides access to the best features of each and implies design criteria for future cyber security toolkits.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152528018",
                    "name": "Mingyi Zhao"
                },
                {
                    "authorId": "2052185399",
                    "name": "Chen Zhong"
                },
                {
                    "authorId": "2927340",
                    "name": "Richard Ciamaichelo"
                },
                {
                    "authorId": "2043235",
                    "name": "Michael Konek"
                },
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "2812689",
                    "name": "Nicklaus A. Giacobe"
                }
            ]
        },
        {
            "paperId": "183972c0b25d81f6578f636fd039abba1943e9b9",
            "title": "Modeling tagged photos for automatic image annotation",
            "abstract": "A semantic concept can be a physical object (e.g., 'car', 'zebra-fish'), an activity (e.g., 'demonstration', 'running') or an obscure category (e.g., 'historical', 'autumn'). In automatic image annotation, machines are taught to infer such semantic concepts by training with hundreds of manually selected images that contain those concepts. So far, remarkable progress has been made in the areas of visual feature extraction and machine learning algorithms that relate features to concepts. Now the new challenge is to scale the inference and annotation capacity to thousands of semantic concepts in the real world. The key to large-scale machine annotation lies in automatic training data selection from user-tagged photos shared on social websites. To learn an annotation model for a concept such as 'car', one can exploit the fact that 'car' is also a common tag associated with photos of day-to-day activities. We may consider the concept to be illustrated by the collection of all photos thus annotated. The photos can be retrieved through a text-search interface and readily used to train the annotation model. While this seems like a straightforward idea, a few ramifications have to be considered: Substandard images: Tagging is an uncontrolled activity not geared towards scientific computation, but guided by personal motivations and communal influences. Tags may be incorrect or incomplete and some images may be poor examples of the target concept. Such substandard training images may hamper the annotation performance. Modeling constraints: As tags as well as visual features determine the quality of training data, a joint analysis of visual-textual features is necessary. Additionally, a diverse set of features need to be effectively combined even if some features are incapable of modeling specific concepts in the large annotation vocabulary. Efficient computing techniques and infrastructure is necessary to maintain scalability and adaptability to new concepts and training data. We recently surveyed the application of tagged photographs for image annotation [2]. The literature was organized to address four main annotation types: (a) general-purpose concepts, (b) names of people, (c) names of locations, and (d) events. An important observation was that a majority of studies resorted to semi-supervised learning to annotate an unlabeled (or partially labeled) image. Specifically, content based retrieval techniques were used to identify similar images and a tag-ranking model was developed to transfer the annotations of the retrieved results on to the query image. Such data-driven techniques can potentially access an arbitrarily large annotation vocabulary. However, they do not conform to the idea of model-based vision and only work if large labeled image sets can be analyzed at run-time. We adopted a supervised learning approach to large-scale image annotation where training data was selected from Flickr images [3]. The selection process was designed to reject substandard images. Annotation models were trained and stored for 1000 words, so that only pixel information of test images needed to be analyzed at run-time. The time required to select training data for a single concept from 10,000 images (634-dimensional feature) using a single CPU of 2.66 GHz speed and 24.4 GB memory was under 5 minutes. Also, the results as compared to a state-of-the-art annotation system showed marked diversity and accuracy. The supervised annotation approach can only predict the concepts used in its training. In this sense, the approach does not cater to the preferred vocabularies of users. To address this issue, we developed a personalized tagging extension [1]. We proposed a transfer learning model to translate the set of machine annotations to a user's vocabulary using a Na\u00efve Bayes formulation. The highlight of the technique was the computation of the translation model from the collective tagging behavior of the user's local social network. In conclusion, the proposed research harnesses user-tagged images and social interactions on photo sharing websites to develop a practical image annotation system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                }
            ]
        },
        {
            "paperId": "a463425e9a703f082eb6f57c90ca979def66cb39",
            "title": "Analysis of cypriot icon faces using ICA-enhanced active shape model representation",
            "abstract": "Religious iconography is an integral component of the cultural heritage of Cyprus, which was once a part of the great Byzantine empire. On one hand, icons exhibit strict adherence to conventional symbols, poses and apparel. On the other hand, there is a great variety in the style of depiction that can be attributed to different schools and periods. This paper proposes an active shape model (ASM) based technique for icon face representation that can be used for style comparison and attribution. For centuries-old icons suffering from loss of paint, cracks and added noise from digitization artifacts, we apply an independent component analysis (ICA) technique to enhance the paintings' original work. The experimental results show that our method can effectively characterize Cypriot icons.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274907",
                    "name": "Guifang Duan"
                },
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "48094094",
                    "name": "James Ze Wang"
                },
                {
                    "authorId": "36550388",
                    "name": "D. Snow"
                },
                {
                    "authorId": "48024122",
                    "name": "Danni Ai"
                },
                {
                    "authorId": "7377952",
                    "name": "Yenwei Chen"
                }
            ]
        },
        {
            "paperId": "4c89c36e98cf98f3ecd5cfa83e648eabc3821b2b",
            "title": "Quest for relevant tags using local interaction networks and visual content",
            "abstract": "Typical tag recommendation systems for photos shared on social networks such as Flickr, use visual content analysis, collaborative filtering or personalization strategies to produce annotations. However, the dependence on manual intervention and the knowledge of sufficient personal preferences coupled with the folksonomic issues limit the scope of these strategies. In this paper, we present a fully automatic and folksonomically scalable tag recommendation model that can recommend tags for a user's photos without an explicit knowledge of the user's personal tagging preferences. The model is learned using the collective tagging behavior of other users in the user's local interaction network, which we believe approximates the user's preferences, at least partially. The tag recommendation model generates content-based annotations and then uses a Na\u00efve Bayes formulation to translate these annotations to a set of folksonomic tags selected from the tags used by the users in the local interaction network. Quantitative and qualitative comparisons with 890 Flickr networks show that this approach is highly useful for tag recommendation in the presence of insufficient information of a user's own preferences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                },
                {
                    "authorId": "40490812",
                    "name": "R. Datta"
                },
                {
                    "authorId": "40116905",
                    "name": "Jia Li"
                },
                {
                    "authorId": "48094094",
                    "name": "James Ze Wang"
                }
            ]
        },
        {
            "paperId": "955fe9a0ba02d82e469c5e719bbde9a5f14a3d32",
            "title": "AT&T Research at TRECVID 2010",
            "abstract": "AT&T participated in two tasks at TRECVID 2010: contentbased copy detection (CCD) and instance-based search (INS). The CCD system developed for TRECVID 2009 was enhanced for eciency and scale and was augmented by audio features [1]. As a pilot task, participation in INS was meant to evaluate a number of algorithms traditionally used for search in a fully automated setting. In this paper, we report the enhancement of our CCD system and propose a system for INS that attempts to leverage retrieval techniques from dierent audio, video, and textual cues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109167204",
                    "name": "Zhu Liu"
                },
                {
                    "authorId": "2900213",
                    "name": "E. Zavesky"
                },
                {
                    "authorId": "2413848",
                    "name": "B. Shahraray"
                },
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                }
            ]
        },
        {
            "paperId": "d84a19d685c7bed1501705c1c285162ce48822b7",
            "title": "Finding near-duplicate images on the web using fingerprints",
            "abstract": "The traditional near-duplicate detection systems developed for digital photo management and copyright protection are not applicable for the de-duplication of large-scale web image corpus. In this paper, we present a fast, accurate and highly scalable image fingerprinting technique suited for near-duplicate detection at the web-scale. The image fingerprint is a compact 130 bit representation computed using Fourier-Mellin transform. Near-duplicate images are detected in O(1) time using fingerprint equality and is faster than fast approximate near-neighbor searches like LSH.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1757518",
                    "name": "Srinivasan H. Sengamedu"
                },
                {
                    "authorId": "1793498",
                    "name": "Neela Sawant"
                }
            ]
        }
    ]
}