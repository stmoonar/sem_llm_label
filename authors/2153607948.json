{
    "authorId": "2153607948",
    "papers": [
        {
            "paperId": "1cf840852ed070e7985e5676a07019dbc7eb566a",
            "title": "A Topological Perspective on Demystifying GNN-Based Link Prediction Performance",
            "abstract": "Graph Neural Networks (GNNs) have shown great promise in learning node embeddings for link prediction (LP). While numerous studies aim to improve the overall LP performance of GNNs, none have explored its varying performance across different nodes and its underlying reasons. To this end, we aim to demystify which nodes will perform better from the perspective of their local topology. Despite the widespread belief that low-degree nodes exhibit poorer LP performance, our empirical findings provide nuances to this viewpoint and prompt us to propose a better metric, Topological Concentration (TC), based on the intersection of the local subgraph of each node with the ones of its neighbors. We empirically demonstrate that TC has a higher correlation with LP performance than other node-level topological metrics like degree and subgraph density, offering a better way to identify low-performing nodes than using cold-start. With TC, we discover a novel topological distribution shift issue in which newly joined neighbors of a node tend to become less interactive with that node's existing neighbors, compromising the generalizability of node embeddings for LP at testing time. To make the computation of TC scalable, We further propose Approximated Topological Concentration (ATC) and theoretically/empirically justify its efficacy in approximating TC and reducing the computation complexity. Given the positive correlation between node TC and its LP performance, we explore the potential of boosting LP performance via enhancing TC by re-weighting edges in the message-passing and discuss its effectiveness with limitations. Our code is publicly available at https://github.com/YuWVandy/Topo_LP_GNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2256340293",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "2124210729",
                    "name": "Yuying Zhao"
                },
                {
                    "authorId": "2027660089",
                    "name": "Yunchao Liu"
                },
                {
                    "authorId": "2226196831",
                    "name": "Xueqi Cheng"
                },
                {
                    "authorId": "2253409421",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "2067148039",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "3630de1ddd8832540c1ebd027d70497766db7153",
            "title": "Fairness and Diversity in Recommender Systems: A Survey",
            "abstract": "Recommender systems (RS) are effective tools for mitigating information overload and have seen extensive applications across various domains. However, the single focus on utility goals proves to be inadequate in addressing real-world concerns, leading to increasing attention to fairness-aware and diversity-aware RS. While most existing studies explore fairness and diversity independently, we identify strong connections between these two domains. In this survey, we first discuss each of them individually and then dive into their connections. Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level. With this expanded perspective on user and item-level diversity, we re-interpret fairness studies from the viewpoint of diversity. This fresh perspective enhances our understanding of fairness-related work and paves the way for potential future research directions. Papers discussed in this survey along with public code links are available at: https://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2124210729",
                    "name": "Yuying Zhao"
                },
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2027660089",
                    "name": "Yunchao Liu"
                },
                {
                    "authorId": "1717004",
                    "name": "Xueqi Cheng"
                },
                {
                    "authorId": "2166048911",
                    "name": "Charu Aggarwal"
                },
                {
                    "authorId": "2067148039",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "629f44f5fb78ec390ef66633dc627f1d04f3eb85",
            "title": "Knowledge Graph Prompting for Multi-Document Question Answering",
            "abstract": "The `pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or document structural relations. For graph traversal, we design an LLM-based graph traversal agent that navigates across nodes and gathers supporting passages assisting LLMs in MD-QA. The constructed graph serves as the global ruler that regulates the transitional space among passages and reduces retrieval latency. Concurrently, the graph traversal agent acts as a local navigator that gathers pertinent context to progressively approach the question and guarantee retrieval quality. Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the potential of leveraging graphs in enhancing the prompt design and retrieval augmented generation for LLMs. Our code: https://github.com/YuWVandy/KG-LLM-MDQA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1793409",
                    "name": "Nedim Lipka"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2233085914",
                    "name": "Alexa F. Siu"
                },
                {
                    "authorId": "1390533012",
                    "name": "Ruiyi Zhang"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "e7987503524dfbcf118c4ccdd303cc798bb90b47",
            "title": "A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications",
            "abstract": "Graph Neural Networks (GNNs) have gained significant attention owing to their ability to handle graph-structured data and the improvement in practical applications. However, many of these models prioritize high utility performance, such as accuracy, with a lack of privacy consideration, which is a major concern in modern society where privacy attacks are rampant. To address this issue, researchers have started to develop privacy-preserving GNNs. Despite this progress, there is a lack of a comprehensive overview of the attacks and the techniques for preserving privacy in the graph domain. In this survey, we aim to address this gap by summarizing the attacks on graph data according to the targeted information, categorizing the privacy preservation techniques in GNNs, and reviewing the datasets and applications that could be used for analyzing/solving privacy issues in GNNs. We also outline potential directions for future research in order to build better privacy-preserving GNNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153911450",
                    "name": "Yi Zhang"
                },
                {
                    "authorId": "2124210729",
                    "name": "Yuying Zhao"
                },
                {
                    "authorId": "2236698799",
                    "name": "Zhaoqing Li"
                },
                {
                    "authorId": "2226196831",
                    "name": "Xueqi Cheng"
                },
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "7731413",
                    "name": "O. Kotevska"
                },
                {
                    "authorId": "2721708",
                    "name": "P. Yu"
                },
                {
                    "authorId": "2067148039",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "f0606e2d975cda134392877e4064924a13915301",
            "title": "Fairness-Aware Graph Neural Networks: A Survey",
            "abstract": "Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. We categorize these techniques by whether they focus on improving fairness in the pre-processing, in-processing (during training), or post-processing phases. We discuss how such techniques can be used together whenever appropriate and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics, including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fairness metrics. In addition, graph datasets that are useful for benchmarking the fairness of GNN models are summarized succinctly. Finally, we highlight key open problems and challenges that remain to be addressed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2198208547",
                    "name": "April Chen"
                },
                {
                    "authorId": "2066337266",
                    "name": "Ryan A. Rossi"
                },
                {
                    "authorId": "2867343",
                    "name": "Namyong Park"
                },
                {
                    "authorId": "30440868",
                    "name": "Puja Trivedi"
                },
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2109571021",
                    "name": "Sungchul Kim"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "144741751",
                    "name": "Nesreen K. Ahmed"
                }
            ]
        },
        {
            "paperId": "0a8f340f094da212dcb50f310e3bd5fb676e2454",
            "title": "Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage",
            "abstract": "Graph Neural Networks (GNNs) have shown great power in learning node representations on graphs. However, they may inherit historical prejudices from training data, leading to discriminatory bias in predictions. Although some work has developed fair GNNs, most of them directly borrow fair representation learning techniques from non-graph domains without considering the potential problem of sensitive attribute leakage caused by feature propagation in GNNs. However, we empirically observe that feature propagation could vary the correlation of previously innocuous non-sensitive features to the sensitive ones. This can be viewed as a leakage of sensitive information which could further exacerbate discrimination in predictions. Thus, we design two feature masking strategies according to feature correlations to highlight the importance of considering feature propagation and correlation variation in alleviating discrimination. Motivated by our analysis, we propose Fair View Graph Neural Network (FairVGNN) to generate fair views of features by automatically identifying and masking sensitive-correlated features considering correlation variation after feature propagation. Given the learned fair views, we adaptively clamp weights of the encoder to avoid using sensitive-related features. Experiments on real-world datasets demonstrate that FairVGNN enjoys a better trade-off between model utility and fairness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2124210729",
                    "name": "Yuying Zhao"
                },
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "4760974",
                    "name": "Huiyuan Chen"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "19e83a60ed705144729d312c854cd91086303243",
            "title": "On Structural Explanation of Bias in Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) have shown satisfying performance in various graph analytical problems. Hence, they have become the de facto solution in a variety of decision-making scenarios. However, GNNs could yield biased results against certain demographic subgroups. Some recent works have empirically shown that the biased structure of the input network is a significant source of bias for GNNs. Nevertheless, no studies have systematically scrutinized which part of the input network structure leads to biased predictions for any given node. The low transparency on how the structure of the input network influences the bias in GNN outcome largely limits the safe adoption of GNNs in various decision-critical scenarios. In this paper, we study a novel research problem of structural explanation of bias in GNNs. Specifically, we propose a novel post-hoc explanation framework to identify two edge sets that can maximally account for the exhibited bias and maximally contribute to the fairness level of the GNN prediction for any given node, respectively. Such explanations not only provide a comprehensive understanding of bias/fairness of GNN predictions but also have practical significance in building an effective yet fair GNN model. Extensive experiments on real-world datasets validate the effectiveness of the proposed framework towards delivering effective structural explanations for the bias of GNNs. Open-source code can be found at https://github.com/yushundong/REFEREE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "123918726",
                    "name": "Yushun Dong"
                },
                {
                    "authorId": "2117075272",
                    "name": "Song Wang"
                },
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                },
                {
                    "authorId": "1737121128",
                    "name": "Jundong Li"
                }
            ]
        },
        {
            "paperId": "58001ad6bf5c1ba3d4db1067158a481e88c49458",
            "title": "Degree-Related Bias in Link Prediction",
            "abstract": "Link prediction is a fundamental problem for network-structured data and has achieved unprecedented success in many real-world applications. Despite the significant progress being made towards improving its performance by characterizing underlined topological patterns or leveraging representation learning, few works have focused on the imbalanced performance among nodes of different degrees. In this paper, we propose a novel problem, degree-related bias and evaluation bias, on link prediction with an emphasis on recommender system applications. We first empirically demonstrate the performance differ-ence among nodes with different degrees and then theoretically prove that Recall is an unbiased evaluation metric compared with Fl, NDCG and Precision. Furthermore, we show that under the unbiased evaluation metric Recall, low-degree nodes tend to have higher performance than high-degree nodes in link prediction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "580f78af4bc37d28cbe4faaf4fc25d83b8bc8286",
            "title": "Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery",
            "abstract": "In computer-aided drug discovery, quantitative structure activity relation models are trained to predict biological activity from chemical structure. Despite the recent success of applying graph neural network to this task, important chemical information such as molecular chirality is ignored. To fill this crucial gap, we propose Molecular-Kernel Graph Neural Network (MolKGNN) for molecular representation learning, which features SE(3)-/conformation invariance, chiralityawareness, and interpretability. For our MolKGNN, we first design a molecular graph convolution to capture the chemical pattern by comparing the atom\u2019s similarity with the learnable molecular kernels. Furthermore, we propagate the similarity score to capture the higher-order chemical pattern. To assess the method, we conduct a comprehensive evaluation with nine well-curated datasets spanning numerous important drug targets that feature realistic high class imbalance and it demonstrates the superiority of MolKGNN over other GNNs in CADD. Meanwhile, the learned kernels identify patterns that agree with domain knowledge, confirming the pragmatic interpretability of this approach. Our codes are publicly available at https://github.com/meilerlab/MolKGNN.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2027660089",
                    "name": "Yunchao Liu"
                },
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "32540294",
                    "name": "Oanh Vu"
                },
                {
                    "authorId": "50285292",
                    "name": "Rocco Moretti"
                },
                {
                    "authorId": "143941894",
                    "name": "Bobby Bodenheimer"
                },
                {
                    "authorId": "1754226",
                    "name": "J. Meiler"
                },
                {
                    "authorId": "12524628",
                    "name": "Tyler Derr"
                }
            ]
        },
        {
            "paperId": "66c2ebc655e9cb4e2be96a8ed871a3d061502331",
            "title": "Fair Graph Representation Learning with Imbalanced and Biased Data",
            "abstract": "Graph-structured data is omnipresent in various fields, such as biology, chemistry, social media and transportation. Learning informative graph representations are crucial in effectively completing downstream graph-related tasks such as node/graph classification and link prediction. Graph Neural Networks (GNNs), due to their inclusiveness on handling graph-structured data and distinguished data-mining power inherited from deep learning, have achieved significant success in learning graph representations. Nonetheless, most existing GNNs are mainly designed with unrealistic data assumptions, such as the balanced and unbiased data distributions while abounding real-world networks exhibit skewed (i.e., long-tailed) node/graph class distributions and may also encode patterns of previous discriminatory decisions dominated by sensitive attributes. Even further, extensive research efforts have been invested in developing GNN architectures towards improving model utility while most of the time totally ignoring whether the obtained node/graph representations conceal any discriminatory bias, which could lead to prejudicial decisions as GNN-based machine learning models are increasingly being utilized in real-world applications. In light of the prevalence of the above two types of unfairness originated from quantity-imbalanced and discriminatory bias, my research expects to propose novel node/graph representation learning frameworks through constructing innovative GNN architectures and devising novel graph-mining algorithms to learn both fair and expressive node/graph representations that can enjoy a favorable fairness-utility tradeoff.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153607948",
                    "name": "Yu Wang"
                }
            ]
        }
    ]
}